<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Class-Balanced Distillation for Long-Tailed Visual Recognition Boqing Gong</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Iscen</surname></persName>
							<email>iscen@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Araujo</surname></persName>
							<email>andrearaujo@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
							<email>cordelias@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Research</surname></persName>
						</author>
						<title level="a" type="main">Class-Balanced Distillation for Long-Tailed Visual Recognition Boqing Gong</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>ISCEN ET AL.: CBD FOR LONG-TAILED VISUAL RECOGNITION 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Real-world imagery is often characterized by a significant imbalance of the number of images per class, leading to long-tailed distributions. An effective and simple approach to long-tailed visual recognition is to learn feature representations and a classifier separately, with instance and class-balanced sampling, respectively. In this work, we introduce a new framework, by making the key observation that a feature representation learned with instance sampling is far from optimal in a long-tailed setting. Our main contribution is a new training method, referred to as Class-Balanced Distillation (CBD), that leverages knowledge distillation to enhance feature representations. CBD allows the feature representation to evolve in the second training stage, guided by the teacher learned in the first stage. The second stage uses class-balanced sampling, in order to focus on under-represented classes. This framework can naturally accommodate the usage of multiple teachers, unlocking the information from an ensemble of models to enhance recognition capabilities. Our experiments show that the proposed technique consistently outperforms the state of the art on long-tailed recognition benchmarks such as ImageNet-LT, iNaturalist17 and iNaturalist18. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Most of the modern computer vision techniques require large amounts of labeled training data in order to learn effective models, e.g., for image classification <ref type="bibr" target="#b21">[21,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b48">49]</ref>, object detection <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b47">48]</ref>, image retrieval <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b46">47]</ref> or segmentation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b25">25]</ref>. Recently, much research has focused on learning with a smaller number of labels (e.g., few-shot learning <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b49">50]</ref> or semi-supervised methods <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b52">53]</ref>), or without any labels (e.g., selfsupervision <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b17">18]</ref>). While these works attempt at reducing the required annotations used for learning, they still tend to make the assumption that the training set is balanced, meaning that there exists a similar number of examples per category.  <ref type="figure">Figure 1</ref>: Overview of our Class-Balanced Distillation approach (CBD). In the first stage, we learn one or multiple teacher models with instance sampling. In the second stage, we use class-balanced sampling to distill the features extracted by the teacher model(s) into a student model (right). The backbone is re-trained from scratch with feature distillation and a classification loss in the second stage.</p><p>Long-tailed recognition aims to address the real-world setting where a few of the labels are observed with very high frequency (head), while most labels appear rarely (tail), with a continuum in-between. For example, in natural world datasets like iNaturalist <ref type="bibr">[27]</ref>, some species are more abundant and easier to photograph than others; similarly, for datasets of human-made and natural landmarks <ref type="bibr" target="#b56">[57]</ref>, some are much more popular destinations than others. This extreme imbalanced setting makes long-tailed visual recognition a challenging problem, where models often underfit the tail classes. Early works tackle this challenge by different sampling strategies <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11]</ref> or re-weighting the loss function <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b38">39]</ref>.</p><p>A very recent trend in this area is to (explicitly or implicitly) decouple the learning of the feature representation and the classifier into two stages <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b64">65]</ref>. Typically, these methods first train a model with the imbalanced training data in the first stage, then apply additional operations, such as meta-learning instance-wise weights <ref type="bibr" target="#b29">[30]</ref> or augmenting the feature representations of under-represented classes <ref type="bibr" target="#b9">[10]</ref>, while they fine-tune the model in the second stage. Kang et al. <ref type="bibr" target="#b32">[33]</ref> focus on the sampling strategies used in both stages and suggest that the feature representations are best learned with instance sampling (i.e., each image having the same probability of being sampled during training) in the first stage, while classifiers are best learned with class-balanced sampling (i.e., each class having the same probability of being sampled) in the second stage.</p><p>In our work, we propose a simple, flexible, and effective two-stage framework that makes a more aggressive decoupling of the two stages, allowing the second stage to learn a new feature extractor from scratch and the first stage to learn multiple, complementary models. More specifically, we address two key observations that affect the existing approaches. The first observation is that the features learned by the instance sampling in previous works are far from optimal for a long-tailed dataset, which we demonstrate in Section 4. The second observation is that the class-balanced classifier learning improves tail classes, but at the expense of penalizing head classes.</p><p>We approach both shortcomings by class-balanced knowledge distillation <ref type="bibr" target="#b23">[23]</ref>, which allows the feature representations to continue evolving in the second stage and benefit from different sampling strategies. <ref type="figure">Figure 1</ref> illustrates the main components of our method. We train an ensemble of teacher models with instance sampling in the first stage. In the sec-ond stage, we learn a student model with class-balanced sampling while distilling feature representations from the teachers. Compared with the training and fine-tuning strategy, our approach provides flexibility to the first stage, which can enhance the feature representation by ensembling, and a versatile distillation tool to the second stage, which essentially learns how to combine and evolve the features.</p><p>Our contributions are the following:</p><p>? A novel two-stage learning method, referred to as Class-Balanced Distillation (CBD), which is suitable for long-tailed recognition datasets, simple to implement, and effective in combining the advantages of instance sampling and class-balanced sampling.</p><p>? A feature distillation scheme for ensembling teachers, which efficiently combines feature representations of multiple teachers with different characteristics, including different data augmentations, to further improve its efficacy.</p><p>? An extensive experimental evaluation of state-of-the-art long-tailed recognition benchmarks, demonstrating that our model outperforms prior arts substantially, with improvements for both head and tail classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Long-Tailed Recognition. The need for handling long-tailed datasets has emerged in many applications, including but not limited to image classification <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b53">54]</ref>, face recognition <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b63">64]</ref>, object detection <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b45">46]</ref>, instance segmentation <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b54">55]</ref>, and multi-label learning <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b57">58]</ref>. This work focuses on long-tailed image classification, but the proposed approach is generic and may benefit other applications. Some recent approaches decouple representation and classifier learning in deep longtailed visual recognition <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b64">65]</ref>. The representation learning stage often employs instance sampling, followed by different classifier learning methods. Kang et al. <ref type="bibr" target="#b32">[33]</ref> studied several normalization techniques for the linear classifier layer. Jamal et al. <ref type="bibr" target="#b29">[30]</ref> proposed a meta-learning algorithm to re-weight both classes and instances. Zhou et al. <ref type="bibr" target="#b64">[65]</ref> employed an annealing factor to transition the learning from representations to a classifier continuously. Chu et al. <ref type="bibr" target="#b9">[10]</ref> augmented tail classes in the feature space. In contrast, we propose knowledge distillation <ref type="bibr" target="#b23">[23]</ref> as an efficient strategy for two-stage learning in long-tailed recognition, allowing the representation to evolve between different stages. Besides, this enables learning from not just one, but an ensemble of teacher model representations.</p><p>Xiang et al. <ref type="bibr" target="#b59">[60]</ref> have explored knowledge distillation in long-tailed classification for a different purpose from ours. The authors split the original long-tailed training set into a subset of more balanced training sets. An expert is learned for each subset, and distillation is used to fuse the experts into a single model. In our work, we instead use the entire dataset for training the model and employ distillation to fuse the information from different teachers and sampling strategies into a single model.</p><p>Another line of research in long-tailed recognition is to promote the tail classes when training deep models. These works include sampling the tail more frequently than the head <ref type="bibr" target="#b30">[31]</ref>, re-weighting losses <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>, balancing losses <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b50">51]</ref>, and changing the momentum <ref type="bibr" target="#b51">[52]</ref>. Convolutional neural networks with memory modules may better represent the tail <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b65">66]</ref>, and one can also transfer knowledge from the head to the tail <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b61">62]</ref>.</p><p>Wu et al. <ref type="bibr" target="#b58">[59]</ref> introduced a taxonomic classifier to avoid making severe errors at the tail. These methods are orthogonal to ours, and they could complement each other. Knowledge Distillation. Knowledge distillation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">23]</ref> refers to transferring information from a teacher model to a student model. It has been used in a variety of machine learning and computer vision tasks, such as image classification <ref type="bibr" target="#b23">[23]</ref>, object detection <ref type="bibr" target="#b6">[7]</ref>, semisupervised learning <ref type="bibr" target="#b52">[53]</ref> and few-shot learning <ref type="bibr" target="#b15">[16]</ref>. Typically this involves making the output (logits) of student model similar to the teacher model. In this work, we use a variant which transfers information directly at the feature level. Feature distillation has been successfully used in other tasks, such as asymmetric metric learning <ref type="bibr" target="#b1">[2]</ref>. It is also shown that feature distillation helps reduce catastrophic forgetting in incremental learning <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b28">29]</ref> and domain expansion <ref type="bibr" target="#b31">[32]</ref>. In our work, we extend feature distillation to the case of multiple teacher models with different data augmentation and sampling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Classifier Training</head><p>Problem Formulation. We are given a set of n instances (images) X := {x 1 , . . . , x n }. Each image is labeled according to Y := {y 1 , . . . , y n } with y i ? C, where C := {1, . . . , c} is a label set for c classes. Let C j denote the subset of instances labeled as class j, and n j = |C j | its cardinality. In this paper, the training set follows a long-tailed distribution. Despite the training set imbalance, the goal is to accurately recognize all classes, so we use a balanced test set to evaluate the classifier.</p><p>Model. The learned model (typically a convolutional neural network) takes an input image and outputs class confidence scores. We denote the model by ? ? ,W : X ? R c . It contains two components, corresponding to the learnable parameters ? and W , respectively: 1) a feature extractor, mapping each instance x i to a descriptor v i := f ? (x i ) ? R d ; 2) a classifier, typically consisting of a fully connected layer which output logits z i := g W (v i ) ? R c , denoting the class confidence scores.</p><p>In this work, we model g W as a cosine classifier <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b42">43]</ref>, where the feature descriptors and classifier weights are 2 -normalized before the prediction. Its output becomes z i := ? W T v i , where a is the 2 -normalized version of a, and ? is a scaling hyper-parameter. For simplicity, we omit the extra notation for 2 -normalization and refer to v i and W as the 2normalized versions for the rest of this paper. Training. The model parameters ? and W are typically learned by minimizing the loss of the model's predictions over the training set X:</p><formula xml:id="formula_0">L(X,Y ; ? ,W ) := n ? i=1 (? (z i ), y i ) ,<label>(1)</label></formula><p>where z i = ? ? ,W (x i ) is the output of the model, ? (.) is the softmax activation function, and (.) is the cross-entropy loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Sampling and Two-Stage Training</head><p>In the context of long-tailed problems, different sampling strategies have been used to adjust the data distribution at the training time. We briefly review two sampling methods, which are utilized in this work.</p><p>Instance sampling attributes each instance x i ? X with the same probability to a mini-batch. Hence, the instances from the head classes are sampled more frequently than those from the tail classes due to the long-tailed nature of the dataset, making the model prone to underfitting tail classes. Formally, let us denote by p j the probability of sampling an instance from class j. Under instance sampling, p j = n j /n.</p><p>Class-balanced sampling addresses the class imbalance by equalizing p j across classes. Under this strategy, each class has the same probability of being selected, i.e., p j = 1/c for all j = 1, . . . , c. Even though this strategy balances the data distribution, it also underutilizes the examples from the head classes. Tail classes are sampled much more frequently compared to head classes. As a result, the model tends to overfit the tail classes and exhibits sub-optimal performance. Two-stage approaches recently show improved performance for long-tailed recognition <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b64">65]</ref>. We briefly review a few methods in this section; please see Section 2 for a more thorough review.</p><p>Classifier Re-Training (cRT) learns the two components of the model ? ? ,W with different sampling strategies <ref type="bibr" target="#b32">[33]</ref>. The feature extractor f ? is first trained with instance sampling and then frozen, followed by learning the classifier g W with class-balanced sampling. The authors argue that the first stage produces generalizable features, while the second stage makes the classifier less biased.</p><p>Fine-tuning trains the model ? ? ,W with instance sampling in the first stage. Then the the entire model ? ? ,W is fine-tuned with class-balanced sampling, using a small learning rate for some number of epochs. The class-balanced sampling is vital for promoting the classifier's performance on the tail classes.</p><p>Discussion. Instance sampling produces better feature representations compared to other sampling strategies <ref type="bibr" target="#b32">[33]</ref>. However, the model's classifier is biased towards the head classes. Two-stage methods leverage instance and class-balanced sampling separately to find the right balance between the two sampling strategies. Classifier Re-Training learns the feature representations with instance and the classifier with class-balanced sampling, in this order <ref type="bibr" target="#b32">[33]</ref>. While being simple and efficient, it has at least two shortcomings: (1) the feature representations tend to mostly focus on the head classes due to the instance sampling in the first stage;</p><p>(2) the second-stage, class-balanced classifier learning, could overcompensate tail classes, leading to reduced performance for the head classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Class-Balanced Distillation (CBD)</head><p>To overcome the shortcomings in existing two-stage methods, we enhance the two-stage learning for long-tailed recognition by improving both (1) the feature representations for tail classes and (2) the classifier for head classes. We leverage distillation <ref type="bibr" target="#b23">[23]</ref> to do so. <ref type="figure">Figure 1</ref> illustrates our overall approach. In the first stage, we use instance sampling to train a teacher model ? ? , W . In the second stage, we adopt class-balanced sampling and yet learn our student model ? ? ,W from scratch by adding a feature distillation loss.</p><p>The feature distillation loss encourages the feature extractor f ? of the student to heed the teacher's feature extractor. It also amends the student's feature extractor to facilitate the classifier g W . It reuses but does not fully inherit the first-stage's knowledge, leaving room for improvement with the class-balanced training. The loss objective from Eq. (1) becomes:</p><formula xml:id="formula_1">L(X,Y ; ? ,W ) := n ? i=1 (1 ? ?) ? (? (z i ), y i ) + ? ? (? F (v i , v i )) ,<label>(2)</label></formula><p>where v i = f ? (x i ) is the feature descriptor produced by the teacher model, and F (v, x) = 1 ? cos(v, x) tries to minimize the cosine distance between two feature descriptors. The hyper-parameter ? controls the amount of distillation compared to the cross entropy loss, and ? is a scaling parameter. Feature-Level vs. Classifier-Level Distillations. Note that our objective function differs from the common knowledge distillation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">23]</ref>, which is applied to to the classifier level rather than the feature level:</p><formula xml:id="formula_2">L(X,Y ; ? ,W ) := n ? i=1 (1 ? ?) ? (? (z i ), y i ) + ? ? T 2 ? (? (z i /T ), ? ( z i /T )) ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">z i = ? ? , W (x i )</formula><p>is the teacher model's output, and T is the temperature parameter used for distillation <ref type="bibr" target="#b23">[23]</ref>.</p><p>We experimentally show that the feature-level distillation is advantageous over the conventional classifier-level distillation. In the context of long-tailed recognition, the teacher's classifier is highly biased towards the head classes. By distilling only at the feature level (Eq. <ref type="formula" target="#formula_1">(2)</ref>), we encourage the student to heed the teacher's feature extraction mechanism, not the classification function, to avoid learning a classifier that is significantly biased to the head. Distilling Ensemble of Teachers. Unlike the existing two-stage methods which learn a classifier (e.g., by cRT) or fine-tune the model, it is straightforward to use the proposed CBD to further transfer knowledge from multiple teacher models. The resulting student model, in this case, tends to have stronger regularization properties and reduced over-fitting <ref type="bibr" target="#b23">[23]</ref>.</p><p>To enable such capabilities, we train different teacher models with different characteristics. More specifically, we train two types of teacher models with different data augmentations. The Standard model relies on standard data-augmentation transformations during training, such as random crop and flip. The Data Augmentation model uses additional data transformations, such as color jitter and Gaussian noise (? = 0.01) in addition to random crop and flip. When training multiple models of the same type, we start from different initial random seeds. Different initial random seeds affect the initialization of the model parameters as well as the order of classes sampled during the training. Regardless of the teacher model type, the standard model is always used when training the student model in the second stage, according to our preliminary experiments.</p><p>Let ? k ? k , W k denote the k-th teacher model. When training the student model ? ? ,W in the second stage, we combine the knowledge from multiple teachers with the following objective: where</p><formula xml:id="formula_4">L(X,Y ; ? ,W ) := n ? i=1 (1 ? ?) ? (? (z i ), y i ) + ? ? ? F h(v i ), V i ,<label>(4)</label></formula><formula xml:id="formula_5">V i = [ v i 1 , . . . , v i K ]</formula><p>concatenates K feature descriptors output by the teacher models, and h : R d ? R d?K is a linear layer which maps the feature descriptor v i to a higher dimensional space where the cosine distance can be computed (the classifier g W is then stacked on top of h(v i )). We refer to this variant as CBD ENS in our experiments. The feature extractors of the teacher models account for the complementary information of the long-tailed training set. By jointly distilling knowledge from them, we transfer the enhanced feature representations to the student feature extractor f ? , which eases the learning of the classifier g W .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>Datasets. We experiment with three long-tailed datasets, namely, ImageNet-LT <ref type="bibr" target="#b40">[41]</ref>, iNat-uralist18 [27] and iNaturalist17 <ref type="bibr" target="#b53">[54]</ref>. Please refer to Section A.1 of the appendix for details of each dataset. Top-1 accuracy is the evaluation metric for all experiments. We also follow the protocol in <ref type="bibr" target="#b40">[41]</ref> to report the accuracies for many-shot classes (more than 100 images per class), mid-shot classes (between 20 and 100 images) and few-shot classes (less than 20 images), separately. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablation Study</head><p>We study the impact of some of the hyper-parameters and components of CBD. All experiments in this section are evaluated on the validation set of ImageNet-LT.</p><p>Distillation. We first evaluate different distillation techniques, i.e. feature distillation (Eq. (2)) and classification distillation (Eq. (3)) in <ref type="figure" target="#fig_0">Figure 2</ref>. We report classification distillation with different temperature T values. We also show the impact of the distillation coefficient ? in the same figure. This parameter controls the strength of distillation in the loss function, see Eq. (2).  <ref type="table">Table 1</ref>: Different ensembles of teachers. Comprehensive evaluation of different types of K teacher models on the ImageNet-LT validation set with ResNet-50. Each row corresponds to a different ensemble. Multiple refer to multiple models of the same type trained with different random seeds. <ref type="figure" target="#fig_0">Figure 2</ref> shows that T = 2 achieves the highest accuracy for classification distillation. Feature distillation outperforms all variants of classification distillation. It also outperforms a variant (Hybrid) which combines feature and classification distillation (T = 2) together. Feature distillation is also more stable for different ?. This is expected, as the first stage model (instance sampling) produces relatively good features but a sub-optimal classifier. Therefore, it is more beneficial to transfer information directly from the features, rather than the classifier. It is also shown that feature distillation remains relatively stable when ? &gt; 0. Note that ? = 0 means that no distillation loss term is used during the training, which is equivalent to class-balanced sampling. We set ? = 0.4, which gives the top performance in <ref type="figure" target="#fig_0">Figure 2</ref>, for the remainder of our experiments.</p><p>Number of teacher models. We train K teacher models when ensembling is used. The ensemble may contain teacher models of different types, i.e. standard and data augmentation. When using the same type multiple times, e.g. two standard models, each model is trained with different random seeds to achieve diversity between models. These teacher models are then fused into a single model with distillation -Eq. (4). We refer to this variant of our method as CBD ENS . <ref type="table">Table 1</ref> shows the impact of different number of standard and data augmentation models when used in an ensemble. We report all combinations for K = 1 and K = 2, but only show the variant with the highest accuracy for K &gt; 2. For K = 1, the data augmentation model achieves a better performance than the standard model. Nevertheless, we achieve the best accuracy with some combination of standard and data augmentation models for K &gt; 1. The validation accuracy saturates after K = 4, therefore we use the K = 4 for CBD ENS for the remainder of our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison with Baselines</head><p>We compare our method against various baselines. The results are reported on the ImageNet-LT test set. Please refer to Section 3.2 more detailed description of each baseline. For singlestage models, we evaluate standard and data augmentation models separately with instance and class balanced sampling strategies. For two-stage models, we evaluate fine-tuning 2 and  classifier-retraining, which is our re-implementation of cRT <ref type="bibr" target="#b32">[33]</ref> with the cosine classifier. We also evaluate the data augmentation version of two-stage baselines, where the first stage is trained with the data augmentation model and the second stage is trained with the standard model. Finally, we evaluate the Teacher Ensemble baseline, which simply takes the average output of teacher models during testing. <ref type="table" target="#tab_3">Table 2</ref> reports the comparisons against the baselines. We report the accuracy of manyshot, mid-shot, and few-shot classes separately, in addition to the overall accuracy for all classes. When compared to other two-stage models, both CBD and CBD ENS show significant improvements. This confirms that our method is a better option as a two-stage model, even if a single teacher model is used (CBD). Note that the two-stage baselines reduce the accuracy of many-shot classes in the second stage. Ensemble baselines improve the performance for many-shot classes, but show no improvements for mid-shot and few-shot classes. This is not the case for CBD ENS on ImageNet-LT, which shows improvements for all class types. We also observe that the data augmentation model does not show any significant improvements except for CBD ENS . This demonstrates that our method is capable of combining diverse models in the most effective way.</p><p>Longer training of baselines. In order to justify that the improvement is not only due to the longer training, we train the Standard -Instance model for two times the number of epochs. This means that the model is trained for 180 epochs on ImageNet-LT and 400 epochs on iNaturalist18, i.e. the total number of epochs it takes to train CBD. We obtain 47.1 and 64.7 overall accuracy for ImageNet-LT and iNaturalist18, respectively. When compared to the Standard -Instance model on <ref type="table" target="#tab_3">Table 2</ref>, the improvement is minimal, which confirms that the improvements of CBD are not due to longer training.</p><p>We also repeat the same procedure for the Classifier re-Training baseline, where we train the linear model for 90 (ImageNet-LT) and 200 (iNaturalist18) epochs in the second stage. We obtain 50.1 and 67.2 for ImageNet-LT and iNaturalist18, respectively. When compared to the Classifier re-Training model on <ref type="table" target="#tab_3">Table 2</ref>, the gains are again minimal. This again confirms that the efficacy of CBD and CBD ENS is not due to the longer training times.</p><p>Complexity. CBD requires higher training complexity compared to other baselines. A network is trained from scratch in each stage. We demonstrate that if other baselines (Instance  and Classifier re-Training ) are given the same amount of training resources, their performance is still lower than CBD. CBD ENS requires training multiple (K = 4) teacher models in the first stage, which further increases the training complexity. However, the teacher models do not interact with each other during the training, which means that all teacher models can be trained in parallel, which can significantly improve the overall time for training. Memory consumption does not depend on the scale of the dataset, as it is fixed (e.g. 4 ResNet-50 models) regardless of the size of the dataset. Note that both CBD and CBD ENS require a single model during the inference. Therefore, the test time efficiency remains the same as for all the other baselines. <ref type="table" target="#tab_5">Table 3</ref> compares CBD and CBD ENS with K = 4 teachers to the state of the art on ImageNet-LT, iNaturalist18 and iNaturalist17 datasets, respectively. Our method shows consistent improvement for all datasets with different network architectures. On ImageNet-LT, we observe 3.6% improvement with CBD ENS (ResNet-50) over the prior best. CBD ENS outperforms the state of the art on iNaturalist18 (iNaturalist17) by 3.8% (3.5%) with ResNet-50. Relative improvement is even higher when a larger network is used; we observe 5.5% improvement over state of the art with CBD ENS with ResNet-152 in ImageNet-LT, and 4.5% improvement over state of the art in iNaturalist18 with ResNet101. See Section A.7 of the Appendix for result for each class split separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparison with State of the Art</head><p>To investigate the compatibility of CBD with existing methods, we also include a variant where the loss function in CBD is replaced by the loss function proposed in the work of Menon et al. <ref type="bibr" target="#b43">[44]</ref>. On ImageNet-LT, CBD + Logit Adjustment <ref type="bibr" target="#b43">[44]</ref> gains 0.6% over CBD, i.e., it obtains 52.2 accuracy, and CBD ENS + <ref type="bibr" target="#b43">[44]</ref> improves 0.5% over CBD ENS , i.e., it achieves 56.1 accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we have introduced a new two-stage method for long-tailed recognition called CBD. Our approach leverages knowledge distillation to combine information from two sampling strategies. Both the feature representation and the classifier evolve between stages, leading to a more effective model. We thoroughly evaluate the effectiveness of our method by comparing it against baselines and previous work. Our experiments demonstrate that CBD significantly improves the state of the art in long-tailed recognition benchmarks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Dataset details</head><p>We use three long-tailed datasets in our experiments, namely, ImageNet-LT <ref type="bibr" target="#b40">[41]</ref>, iNatural-ist18 [27] and iNaturalist17 <ref type="bibr" target="#b53">[54]</ref>. ImageNet-LT is an artificially created subset of the original ImageNet dataset <ref type="bibr" target="#b12">[13]</ref> where the classes follow a long-tailed distribution. It has 1000 classes and the number of training images per class varies from 5 to 1280. iNaturalist17 and iNatu-ralist18 training sets are long-tailed by nature. iNaturalist17 contains 5, 089 classes with the range of 9 to 3919 images per class. iNaturalist18 contains 8, 142 classes with the range of 2 to 1000 images per class. The validation and test sets for ImageNet-LT and iNaturalist18 are balanced. The validation set of iNaturalist17 set is more balanced than the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Training details</head><p>Throughout our experiments, the networks are trained for 90 epochs on ImageNet-LT and 200 epochs on iNaturalist17 and iNaturalist18 in both stages, to make the results comparable with the existing work. We also report the performance with more epochs in Section 4.3. When training the model, we use a batch size of 256, learning rate of 0.2 which decays to 0 with cosine learning rate schedule <ref type="bibr" target="#b41">[42]</ref>, and SGD optimizer with momentum 0.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Impact of ?</head><p>We first demonstrate the impact of ? in Equation <ref type="formula" target="#formula_1">(2)</ref>. This parameter scales the feature distillation loss in the loss objective. <ref type="figure" target="#fig_2">Figure 3</ref> shows the accuracy for the ImageNet-LT validation set with different ? . We see that the accuracy is relatively stable for ? ? 10. We set ? = 100 for all of our experiments as this gives the highest accuracy for the validation set. <ref type="table" target="#tab_6">Table 4</ref> reports the comparisons against the baselines on iNaturalist18. Similar to <ref type="table" target="#tab_3">Table 2</ref>, we report the accuracy of many-shot, mid-shot, and few-shot classes separately, in addition to the overall accuracy for all classes. Our conclusions are similar to the baseline comparison on ImageNet-LT. When compared to other two-stage models, both CBD and CBD ENS show significant improvements. Teacher Ensemble improves the accuracy of many-shot classes  <ref type="table">Table 5</ref>: Evaluation with NCM. Classification accuracy with the non-parametric Nearest Centroid Mean <ref type="bibr" target="#b32">[33]</ref> classifier. ResNet-50 architecture is used for both datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Baseline comparison on iNaturalist18</head><p>at the expense of mid-shot and few-shot classes. This confirms that our method is a better option as a two-stage or ensemble model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Quality of the feature representation</head><p>We now investigate if our method indeed improves the feature representation. To this end, we measure the accuracy with a non-parametric classifier, i.e. NCM <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b32">33]</ref>. NCM computes the classification vectors for each class by taking the mean of all vectors belonging to that class. Thus, the classification accuracy is directly related to the feature representation quality. <ref type="table">Table 5</ref> shows the classification performance with the NCM classifier. We test our method against Instance, which is the same feature representation used by cRT, and also Fine-tuning, which also updates the feature representation in the second stage. It is shown that CBD and CBD ENS achieves higher accuracy, which validates our claims that the feature representation is also improved. <ref type="figure">Figure 4</ref> presents qualitative examples that demonstrate the quality of the feature representation produced by CBD, in comparison to the features of Instance, i.e., the same representation used in cRT method. For each test image, the top-5 nearest neighbor training images are depicted. CBD improves the challenging cases by learning a much improved feature representation for tail classes (white-sided dolphin). Features of dolphins and whales seem to be collapsed together with the feature representation used in Instance. Our method white-sided dolphin <ref type="formula" target="#formula_0">(19)</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 Upper-bound performance</head><p>Even though our method brings significant improvements over other baselines, we investigate whether there is further room for improvement. To illustrate the headroom for improvement in terms of feature learning, we propose an experiment where we assume to have the optimal feature representation for a long-tailed recognition problem. First, we train a ResNet-50 model ? * ? ,W on the full ImageNet <ref type="bibr" target="#b12">[13]</ref> dataset. We remove the classifier from this model, only keeping the feature extractor f * ? . This feature extractor produces the optimal feature representation for the ImageNet-LT <ref type="bibr" target="#b40">[41]</ref> dataset, in the sense that ImageNet-LT is a subset of ImageNet, where the classes follow a long-tailed distribution. By training f * ? on the full ImageNet, we essentially learn the best possible feature extractor for ImageNet-LT for a given architecture. We now fix f * ? and only train the classifier g W on ImageNet-LT with class-balanced sampling. The resulting model achieves 73.5% top-1 accuracy, which can be seen as an upper bound on ImageNet-LT with ResNet-50. On the other hand, CBD ENS achieves 55.6% top-1 accuracy. This suggests that there is still a lot of room for improvement on long-tailed datasets. <ref type="table" target="#tab_5">Table 3</ref> shows the overall accuracy for the ImageNet-LT, iNaturalist18, and iNaturalist17 datasets. We now show results separately for low-shot, mid-shot and many-shot classes on Tables 6, 7 and 8. Note that the other methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b64">65]</ref> do not report such detailed results on iNaturalist17, thus we could not include them in the comparison. Thus we compare our method with emphStandard Instance, our implementation of classifier re-training <ref type="bibr" target="#b32">[33]</ref>. Our method also outperforms the prior work for each class split (many-shot, mid-shot, fewshot) in all scenarios. We do not sacrifice the accuracy of many-shot classes to increase the overall accuracy; we achieve a higher overall accuracy by improving many-shot accuracy as well as the accuracy of other groups.   <ref type="table">Table 8</ref>: iNaturalist17 comprehensive comparison. Comparison of CBD variants against the other methods with ResNet-50 and ResNet-101. The accuracy for many-shot (&gt; 100 images), mid-shot (20-100 images) and few-shot (&lt; 20 images) classes are reported separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.7 Comprehensive comparison with State of the Art</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Impact of ? in different distillation techniques. Experiments are conducted with ResNet-50 on the ImageNet-LT validation set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Implementation Details.</head><label></label><figDesc>We use the ResNet-{50,152}<ref type="bibr" target="#b21">[21]</ref> architectures for ImageNet-LT, and ResNet-{50,101} for iNaturalist17 and iNaturalist18. See Section A.2 of the appendix for training details. The scaling parameter in Eq. (2) is set to ? = 100 based on the accuracy in the ImageNet-LT validation set (see Section A.3 in Appendix). Other parameters, such as ? and the number of teacher models K are chosen based on the experiments in Section 4.2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Impact of ? scaling hyperparameter for CBD. Experiments are conducted with ResNet-50 on ImageNet-LT validation set with ? = 0.4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Baseline comparison. Comprehensive evaluation on ImageNet-LT (test set) with the ResNet-50 architecture. The accuracy for many-shot , mid-shot and few-shot classes are reported separately.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>State-of-the-art comparison. Comparison of CBD variants against the state of the art with ResNet-50 and ResNet-152.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Baseline comparison.</figDesc><table><row><cell cols="3">Comprehensive evaluation on iNaturalist18 (validation set)</cell></row><row><cell cols="3">with the ResNet-50 architecture. The accuracy for many-shot , mid-shot and few-shot classes</cell></row><row><cell>are reported separately.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>ImageNet-LT</cell><cell>iNaturalist18</cell></row><row><cell>Instance -NCM</cell><cell>49.0</cell><cell>62.8</cell></row><row><cell>Fine-tuning -NCM</cell><cell>48.8</cell><cell>64.1</cell></row><row><cell>CBD-NCM</cell><cell>50.7</cell><cell>64.5</cell></row><row><cell>CBD ENS -NCM</cell><cell>54.0</cell><cell>69.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Instance Rank 1 Instance Rank 2 Instance Rank 3 Instance Rank 4 Instance Rank 5 Instance Rank 1 Instance Rank 2 Instance Rank 3 Instance Rank 4 Instance Rank 5Figure 4: Qualitative results. Test images from the iNaturalist18 dataset are depicted on the left, along with their class labels and associated number of training images. For each test image, we show its nearest neighbors from the training set using the feature representations of CBD (top) and Instance sampling (bottom). Green and red boundaries denote training images from the same or different classes, respectively.</figDesc><table><row><cell>Method</cell><cell></cell><cell cols="2">ResNet-50</cell><cell></cell><cell></cell><cell cols="2">ResNet-152</cell><cell></cell></row><row><cell></cell><cell>Many-shot</cell><cell>Mid-shot</cell><cell>Few-shot</cell><cell>All</cell><cell>Many-shot</cell><cell>Mid-shot</cell><cell cols="2">Few-shot</cell><cell>All</cell></row><row><cell>LWS [33]</cell><cell>57.1</cell><cell>45.2</cell><cell>29.3</cell><cell>47.7</cell><cell>60.6</cell><cell>47.8</cell><cell>31.4</cell><cell></cell><cell>50.5</cell></row><row><cell>cRT [33]</cell><cell>58.8</cell><cell>44.0</cell><cell>26.1</cell><cell>47.3</cell><cell>61.8</cell><cell>46.8</cell><cell>28.4</cell><cell></cell><cell>50.1</cell></row><row><cell>cRT+SSP [61]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>51.3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell></row><row><cell>Logit Adj. [44]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>51.1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>52.1</cell></row><row><cell>ELF(CE) [15]</cell><cell>60.7</cell><cell>45.5</cell><cell>27.7</cell><cell>48.9</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell></row><row><cell>ELF(LDAM) [15]</cell><cell>64.3</cell><cell>47.9</cell><cell>31.4</cell><cell>52.0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell></row><row><cell>Ours -CBD</cell><cell>65.2</cell><cell>48.0</cell><cell>25.9</cell><cell>51.6</cell><cell>68.1</cell><cell>50.1</cell><cell>27.1</cell><cell></cell><cell>53.9</cell></row><row><cell>Ours -CBD ENS</cell><cell>68.5</cell><cell>52.7</cell><cell>29.2</cell><cell>55.6</cell><cell>71.2</cell><cell>54.5</cell><cell>30.7</cell><cell></cell><cell>57.7</cell></row><row><cell></cell><cell cols="2">CBD Rank 1</cell><cell cols="2">CBD Rank 2</cell><cell>CBD Rank 3</cell><cell cols="2">CBD Rank 4</cell><cell cols="2">CBD Rank 5</cell></row><row><cell>mallard (1000)</cell><cell cols="2">CBD Rank 1</cell><cell cols="2">CBD Rank 2</cell><cell>CBD Rank 3</cell><cell cols="2">CBD Rank 4</cell><cell cols="2">CBD Rank 5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>ImageNet-LT state-of-the-art comparison. Comparison of CBD variants against the state of the art with ResNet-50 and ResNet-152.obtains improvements even for head classes, such as mallard, where our learned feature can more easily distinguish similar species based on very detailed information.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>iNaturalist18 state-of-the-art comparison. Comparison of CBD variants against the state of the art with ResNet-50 and ResNet-101.</figDesc><table><row><cell></cell><cell cols="2">ResNet-50</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Many-shot</cell><cell>Mid-shot</cell><cell>Few-shot</cell><cell>All</cell></row><row><cell>Standard Instance</cell><cell>74.2</cell><cell>55.8</cell><cell>42.9</cell><cell>62.5</cell></row><row><cell>Classifier Re-training</cell><cell>71.7</cell><cell>59.3</cell><cell>53.7</cell><cell>63.9</cell></row><row><cell>Ours -CBD</cell><cell>70.8</cell><cell>61.0</cell><cell>56.0</cell><cell>64.6</cell></row><row><cell>Ours -CBD ENS</cell><cell>74.3</cell><cell>66.4</cell><cell>62.0</cell><cell>69.3</cell></row><row><cell></cell><cell cols="2">ResNet-101</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Many-shot</cell><cell>Mid-shot</cell><cell>Few-shot</cell><cell>All</cell></row><row><cell>Standard Instance</cell><cell>75.2</cell><cell>57.7</cell><cell>45.7</cell><cell>64.1</cell></row><row><cell>Classifier Re-training</cell><cell>72.9</cell><cell>60.6</cell><cell>54.9</cell><cell>65.2</cell></row><row><cell>Ours -CBD</cell><cell>73.3</cell><cell>62.5</cell><cell>57.9</cell><cell>66.5</cell></row><row><cell>Ours -CBD ENS</cell><cell>76.8</cell><cell>68.1</cell><cell>63.2</cell><cell>71.3</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">? 2021. The copyright of this document resides with its authors. It may be distributed unchanged freely in print or electronic forms.<ref type="bibr" target="#b0">1</ref> The code is available at https://github.com/google-research/google-research/tree/ master/class_balanced_distillation</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The network is fine-tuned for 10 epochs with 0.01 learning rate in the second stage, which was the best setup for this method on ImageNet-LT</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Model compression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Bucilu?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandru</forename><surname>Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGKDD</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Asymmetric metric learning for knowledge transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Budnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Avrithis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16331</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Unifying deep local and global features for image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Sim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domain balancing: Face recognition on long-tailed domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning imbalanced datasets with label-distribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Ar?chiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Learning efficient object detection models with knowledge distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guobin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Feature space augmentation for long-tailed data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaopeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Ling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Large scale fine-grained categorization and domain-specific transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<title level="m">Class-balanced loss based on effective number of samples. CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Low-shot learning with large-scale diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Elf: An early-exiting framework for long-tailed classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Duggal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Freitas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunny</forename><surname>Dhamnani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duen</forename><surname>Horng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimeng</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.11979</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Diversity with cooperation: Ensemble methods for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Dvornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<imprint>
			<publisher>Mohammad</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent-a new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gheshlaghi</forename><surname>Azar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deepncm: Deep nearest class mean classifiers. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samantha</forename><surname>Guerriero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Worskhop Track</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Lvis: A dataset for large vocabulary instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning a unified classifier incrementally via rebalancing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saihui</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to segment every thing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronghang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to segment the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Yannis Avrithis, and Ondrej Chum. Label propagation for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Tolias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Memoryefficient incremental learning through feature adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Iscen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rethinking class-balanced methods for long-tailed visual recognition from a domain adaptation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Balanced meta-softmax for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename><surname>Jiawei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunjun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Less-forgetful learning for domain expansion in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heechul</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeongwoo</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minju</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Jiashi Feng, and Yannis Kalantidis. Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Striking the right balance with uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munawar</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbing</forename><surname>Syed Waqas Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">M2m: Imbalanced classification via major-to-minor translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehyung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongheon</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Overcoming classifier imbalance for long-tail object detection with balanced group softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jintao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep representation learning on long-tailed data: A learnable embedding augmentation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuchu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaopeng</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.03983</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Cosine normalization: Using cosine similarity instead of dot product in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohe</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICANN</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Andreas Veit, and Sanjiv Kumar. Long-tail learning via logit adjustment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadeep</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Singh Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Himanshu</forename><surname>Jain</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Largescale image retrieval with attentive deep local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonwoo</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Large-scale object detection in the wild from imbalanced multi-labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junran</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyuan</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Revisiting oxford and paris: Large-scale image retrieval benchmarking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Radenovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmet</forename><surname>Iscen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Giorgos Tolias, Yannis Avrithis, and Ond?ej Chum</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Faster r-cnn: Towards realtime object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for largescale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Equalization loss for long-tailed object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingru</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changbao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqing</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Long-tailed classification by keeping the good and removing the bad momentum causal effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Mean teachers are better role models: Weightaveraged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The iNaturalist species classification and detection dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><forename type="middle">Mac</forename><surname>Grant Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">The devil is in classification: A simple framework for long-tail instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhao</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.11978</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Google landmarks dataset v2-a large-scale benchmark for instance-level recognition and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Sim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Distribution-balanced loss for multi-label classification in long-tailed datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqiu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Solving long-tailed recognition with deep realistic taxonomic classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tz-Ying</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><surname>Morgado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Hui</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.09898</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning from multiple experts: Selfpaced knowledge distillation for long-tailed classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuyu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiguang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Rethinking the value of labels for improving class-imbalanced learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Feature transfer learning for face recognition with under-represented data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Range loss for deep face recognition with long-tailed training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Unequal-training for deep face recognition with long-tailed noisy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoyao</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihong</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiani</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianteng</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xunqiang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaohai</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Min</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Inflated episodic memory with region self-attention for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
