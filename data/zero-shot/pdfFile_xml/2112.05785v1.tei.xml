<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TempoQR: Temporal Question Reasoning over Knowledge Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-12-10">10 Dec 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Costas</forename><surname>Mavromatis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Minnesota</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasanna</forename><forename type="middle">Lakkur</forename><surname>Subramanyam</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Massachusetts Amherst</orgName>
								<address>
									<addrLine>3 Amazon Web Services</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><forename type="middle">?</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassilis</forename><forename type="middle">N</forename><surname>Ioannidis</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soji</forename><surname>Adeshina</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><forename type="middle">R</forename><surname>Howard</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Intel Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetiana</forename><surname>Grinberg</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Intel Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagib</forename><surname>Hakim</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Intel Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
						</author>
						<title level="a" type="main">TempoQR: Temporal Question Reasoning over Knowledge Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-12-10">10 Dec 2021</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Knowledge Graph Question Answering (KGQA) involves retrieving facts from a Knowledge Graph (KG) using natural language queries. A KG is a curated set of facts consisting of entities linked by relations. Certain facts include also temporal information forming a Temporal KG (TKG). Although many natural questions involve explicit or implicit time constraints, question answering (QA) over TKGs has been a relatively unexplored area. Existing solutions are mainly designed for simple temporal questions that can be answered directly by a single TKG fact. This paper puts forth a comprehensive embedding-based framework for answering complex questions over TKGs. Our method, called temporal question reasoning (TempoQR), exploits TKG embeddings to ground the question to the specific entities and time scope it refers to. It does so by augmenting the question embeddings with context, entity and time-aware information via three specialized modules. The first computes a textual representation of a given question, the second combines it with the entity embeddings for entities involved in the question, and the third generates question-specific time embeddings. Finally, a transformer-based encoder learns to fuse the generated temporal information with the question representation, which is used for answer predictions. Extensive experiments show that TempoQR improves accuracy by 25-45 percentage points on complex temporal questions over state-of-the-art approaches and it generalizes better to unseen question types.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A knowledge graph (KG) is a set of facts that are known to be true in the world or in a specific domain. The facts are usually represented as tuples <ref type="bibr">(subject, relation, object)</ref>, where the subject and object correspond to KG entities. Certain KGs include additional attributes such as temporal information forming a temporal knowledge graph (TKG). In TKGs, each fact is associated with a timestamp or time interval, and is represented as <ref type="bibr">(subject, relation, object, timestamp)</ref> or <ref type="bibr">(subject, relation, object, [start time, end time]</ref>), respectively.</p><p>Knowledge Graph Question Answering (KGQA) attempts to answer a natural question using the KG as a knowledge base . Natural questions often include temporal constraints, e.g., "Which movie won the Best Picture in 1973?" and to aid temporal question answering, TKGs are utilized. The first step is to identify and link the entities, relations and timestamps of the questions to the corresponding ones in the TKG, e.g., "Which movie won the Best <ref type="bibr">Picture in 1973</ref><ref type="bibr">?" to (Best Picture, WonBy, ?, 1973</ref>. This problem is known as entity linking <ref type="bibr" target="#b12">(Kolitsas, Ganea, and Hofmann 2018)</ref>.</p><p>Recently, <ref type="bibr" target="#b19">(Saxena, Chakrabarti, and Talukdar 2021)</ref> proposed CronKGQA that solves QA over TKGs by leveraging TKG embedding methods, e.g., TCom-plEx <ref type="bibr" target="#b13">(Lacroix, Obozinski, and Usunier 2020)</ref>. TKG embedding methods learn low-dimensional embeddings for the entities, relations and timestamps by minimizing a link prediction objective attuned at completing facts of the form <ref type="bibr">(subject, relation, ?, timestamps)</ref> and <ref type="bibr">(subject, relation, object, ?)</ref>. CronKGQA answers the mapped question <ref type="bibr">(Best Picture, WonBy, ?, 1973</ref>) as a link prediction task over the TKG. CronKGQA performs very well on simple questions that are answerable by a single TKG fact (Hits@1 of 0.988). However, on more complex questions, that involve additional temporal constraints and require information from multiple TKG facts (e.g., "Which movie won the Best Picture after The Godfather?"), CronKGQA performs poorly (Hits@1 of 0.392).</p><p>To effectively handle both simple and complex temporal questions, we design a new method called temporal question reasoning (TempoQR). TempoQR exploits TKG embeddings to ground the question to the specific entities and time scope the question refers to. To illustrate the key idea of our approach, consider the question "Which movie won the Best Picture after The Godfather?" which involves the TKG entities 'Best Picture' and 'The Godfather'. The highlevel approach of TempoQR is shown in <ref type="figure" target="#fig_1">Figure 1</ref>. The first reasoning step is to understand the context of the question (context-aware step). The context of the question here involves a movie ("Which movie..."). The next step is to ground the question to the entities it refers to (entity-aware step). The question refers to a movie that has won the Best Picture. Finally, the question needs to be grounded with certain temporal constraints (time-aware step). The movie won <ref type="bibr">'</ref>  <ref type="bibr">won,1972 won,1994 won,1973 actor,1972 actor,1979 actor,1994</ref> (a) The underlying TKG.  The representation is grounded to the correct time scope (after year 1972) and gives higher scores to the movies that won the Best Picture after 1972, i.e., 'The Sting'.</p><p>the Best Picture after The Godfather, i.e., after 1972. TempoQR performs the above reasoning steps using three specialized modules. First, it uses the question's text to generate a representation of the question by employing a language model (LM). Next, it fuses the text-derived representations with KG entity representations to ground the question to the entities it refers to. Third, it extracts from the TKG question-specific temporal information to enhance the question's representation with two complementary approaches. The first retrieves the relevant information from the underlying TKG based on the annotated entities of the question. The second infers temporal information by solving a link prediction problem obviating the need to access the TKG. A dedicated information fusion layer combines the context, entity and time-aware information together to a final question representation. We empirically show that TempoQR is able to model temporal constraints of the question and outperforms other time-unaware methods for complex questions (25-45 percentage points improvement at Hits@1). Our contributions are summarized below:</p><p>? We solve complex temporal question answering by learning context, entity and time-aware question representations.</p><p>? We develop two different approaches to recover questionspecific temporal information.</p><p>? We achieve state-of-the-art performance on temporal complex questions and provide additional strong baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>KGQA approaches typically leverage KG pretrained embeddings <ref type="bibr" target="#b0">(Bordes et al. 2013;</ref><ref type="bibr">Yang et al. 2014;</ref><ref type="bibr">Trouillon et al. 2017)</ref> to answer the questions <ref type="bibr" target="#b20">(Saxena, Tripathi, and Talukdar 2020)</ref>. Such approaches perform well for simple questions that can be easily mapped to incomplete facts in the KG but are challenged by complex questions. Addressing the limitations of the aforementioned approaches, <ref type="bibr" target="#b16">(Miller et al. 2016;</ref><ref type="bibr">Xu et al. 2019;</ref><ref type="bibr">Zhou, Huang, and Zhu 2018;</ref><ref type="bibr">Qiu et al. 2020;</ref><ref type="bibr" target="#b5">He et al. 2021</ref>) enhance the question representation to address complex questions. Such methods employ logical reasoning <ref type="bibr" target="#b16">(Miller et al. 2016;</ref><ref type="bibr">Xu et al. 2019;</ref><ref type="bibr">Zhou, Huang, and Zhu 2018;</ref><ref type="bibr">Qiu et al. 2020;</ref><ref type="bibr" target="#b5">He et al. 2021)</ref> or leverage available side information in the form of text documents <ref type="bibr" target="#b22">(Sun et al. 2018;</ref><ref type="bibr" target="#b22">Sun, Bedrax-Weiss, and Cohen 2019;</ref><ref type="bibr">Xiong et al. 2019;</ref><ref type="bibr" target="#b4">Han, Cheng, and Wang 2020)</ref>. Nevertheless, these approaches are not suited for handling temporal constraints.</p><p>TempQuestions <ref type="bibr" target="#b6">(Jia et al. 2018a</ref>) was introduced to benchmark the reasoning capabilities of existing with temporal constraints. Recently, additional benchmarks have been developed <ref type="bibr" target="#b9">(Jin et al. 2021;</ref><ref type="bibr" target="#b21">Souza Costa, Gottschalk, and Demidova 2020;</ref><ref type="bibr" target="#b1">Chen, Wang, and Wang 2021;</ref><ref type="bibr" target="#b17">Neelam et al. 2021</ref>) that model temporal information in various domains (including both KG and text data). <ref type="bibr" target="#b7">(Jia et al. 2018b</ref>) and <ref type="bibr" target="#b8">(Jia et al. 2021)</ref> are methods that tackle the temporal QA problem over KGs. However, they mostly employ hand crafted rules to handle temporal information which is not flexible for incomplete KGs. By leveraging TKG embeddings, CronKGQA <ref type="bibr" target="#b19">(Saxena, Chakrabarti, and Talukdar 2021)</ref> provides a learnable reasoning process for temporal KGQA, which does not rely on hand-crafted rules. Although CronKGQA performs extremely well for answering simple questions, it is challenged by complex questions that require inference of certain temporal constraints. Our work is motivated by this limitation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head><p>A TKG K := (E, R, T , F ) contains a set of entities E, a set of relations R, a set of timestamps T , and a set of facts F . Each fact (s, r, o, ? ) ? F is a tuple where s, o ? E denote the subject and object entities, respectively, r ? R denotes the relation between them, and ? ? T is the timestamp associated with that relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">TKG embeddings</head><p>Given a TKG K = (E, R, T , F ), TKG embedding methods typically learn D-dimensional vectors e ? , v r , t ? ? R D for each ? ? E, r ? R and ? ? T . These embedding vectors are learned such that each valid fact (s, r, o, ? ) ? F is scored higher than an invalid fact (s</p><formula xml:id="formula_0">? , r ? , o ? , ? ? ) / ? F through a scoring function ?(?), i.e., ?(e s , v r , e o , t ? ) &gt; ?(e s ? , v r ? , e o ? , t ? ? )</formula><p>. Please see <ref type="bibr" target="#b10">(Kazemi et al. 2020)</ref> for notable TKG embedding methods. TComplEx. TComplEx <ref type="bibr" target="#b13">(Lacroix, Obozinski, and Usunier 2020)</ref> is an extension of the ComplEx (Trouillon et al. 2017) KG embedding method designed for TKGs. TComplEx represents the embeddings as complex vectors in C D/2 and the scoring function ?(?) is given by</p><formula xml:id="formula_1">?(e s , v r ,? o , t ? ) = Re( e s , v r ? t ? ,? o )<label>(1)</label></formula><p>where Re(?) denotes the real part,(?) is the complex conjugate of the embedding vector and ? is the element-wise product. TComplEx employs additional regularizers to improve the quality of the learned embeddings such as enforcing close timestamps to have similar embeddings (closeness of time). The embedding learning procedure makes TComplEx a suitable method for inferring missing facts such as (s, r, ?, t) and (s, r, o, ?) over an incomplete TKG. Throughout the manuscript, we generate TKG embeddings via TComplEx due to its aforementioned benefits. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">QA over TKGs</head><p>Given a TKG K = (E, R, T , F ) and a natural language question q, the task of QA over a TKG (TKGQA) <ref type="bibr" target="#b19">(Saxena, Chakrabarti, and Talukdar 2021)</ref> is to extract an entity ? ? ? E or a timestamp ? ? ? T that correctly answers the question q. The entities ? ? E and timestamps ? ? T of the question are annotated, i.e., linked to the TKG. Please refer to <ref type="table" target="#tab_1">Table 1</ref> for examples of such questions. Note that a question, e.g., "Which movie won the Best Picture in 1973", could be answerable by a single TKG fact, i.e., <ref type="bibr">(Best Picture, WonBy, The Sting, 1973)</ref>. Thus, a common solution for TKGQA is to infer the relation 'WonBy' by the question's context and solve the problem as link prediction, i.e., <ref type="bibr">(Best Picture, q, ?, 1973)</ref>. CronKGQA. CronKGQA <ref type="bibr" target="#b19">(Saxena, Chakrabarti, and Talukdar 2021)</ref> is a typical method that solves TKGQA as a link prediction task. The idea is to use the question as a 'virtual relation' in the scoring function ?(?).</p><p>Suppose s and ? are respectively the annotated subject and timestamp in a given question (e.g., <ref type="bibr">'Best Picture' and '1973')</ref> and o * is the correct answer (e.g., 'The Sting').</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CronKGQA learns a question representation q such that</head><formula xml:id="formula_2">?(e s , q, e o * , t ? ) &gt; ?(e s , q, e o ? , t ? ) for all incorrect enti- ties o ? = o * , where e s , e o * , e o ? ,</formula><p>and t ? are pre-trained TKG embeddings, e.g., with TComplEx. Note that if either s or ? is not present in the question, a random one from the TKG (dummy) is used. The methodology is modified accordingly when the answer is a timestamp ? * by giving the maximum score to ?(e s , q, e o , t ? * ), where ? * is the correct timestamp and s, o are the annotated subject and object.</p><p>CronKGQA is designed for simple temporal questions that can be transformed to link predictions over TKGs. This limits the applicability of CronKGQA to more complex questions that involve additional temporal constraints, e.g., 'Before/After', 'First/Last' and 'Time Join' questions of <ref type="table" target="#tab_1">Table 1</ref>. This is confirmed by the experiments presented in <ref type="bibr" target="#b19">(Saxena, Chakrabarti, and Talukdar 2021)</ref>, where CronKGQA achieves a 65% performance improvement over non-TKG embedding methods for simple questions, but only a 15% improvement for complex questions as the ones here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method: TempoQR</head><p>TempoQR leverages pre-trained TKG embeddings of entities and timestamps that encode their temporal properties, i.e., TComplEx. Although TKG embeddings are designed for simple questions, our method overcomes this shortcoming by incorporating additional temporal information in the question representation q to better handle constraints. We design TempoQR by following the human reasoning steps to answer temporal questions; see also <ref type="figure" target="#fig_1">Figure 1</ref>. In the following subsections, we describe in detail the architecture of TempoQR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Context-aware question representation.</head><p>Given a question's text, we use pre-trained LMs, e.g., BERT <ref type="bibr" target="#b2">(Devlin et al. 2019)</ref>, to encode the question's context into an embedding vector. The [CLS] token is inserted into the question, e.g., "[CLS] Which movie won the Best Picture after The Godfather?", which is transformed to a tokenized vector q 0 . Then, we compute a representation for each token as</p><formula xml:id="formula_3">Q B = W B BERT(q 0 ) ,<label>(2)</label></formula><p>where </p><formula xml:id="formula_4">Q B := [q BCLS , q B1 , . . . , q BN ] is a D ? N embed- ding matrix where N</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Entity-aware question representation.</head><p>We utilize the TKG entity embeddings to ground the question to the specific entities it involves. Inspired by other approaches <ref type="bibr" target="#b18">(Zhang et al. 2019;</ref><ref type="bibr" target="#b3">F?vry et al. 2020</ref>) that compute entity-aware text representations, we replace the token embeddings of the entities and timestamps of Q B with their pre-trained TKG embeddings. Specifically, the ith column of the entity-aware token embedding matrix Q E is computed as</p><formula xml:id="formula_5">q Ei = ? ? ? W E e ? , if token i is linked to an entity ?, W E t ? , if token i is linked to a timestamp ? . q Bi , otherwise, (3) where W E is a D ? D learnable projection. As a result, the token embedding matrix Q E := [q ECLS , q E1 , . . . , q EN ]</formula><p>incorporates additional entity information from the TKG. This enriches the question with entity information from the TKG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Time-aware question representation.</head><p>A question may refer to a specific time scope which the answer needs to be associated, e.g., "after The Godfather" refers to "after 1972". We develop two alternatives that recover such temporal information. The first approach retrieves the question-specific time scope from the TKG based on the annotated entities. We call this approach hardsupervised, since it accesses available facts in the TKG. The second approach infers question-specific temporal information based on the question's representation. We term this approach soft-supervised, since it may recover missing temporal facts by operating in the embedding space. Hard Supervision: Retrieval from the TKG facts. We utilize the annotated entities of the question to retrieve the relative time scope from the underlying TKG. For the example question "Which movie won the Best Picture after The Godfather?", the entities 'Best Picture' and 'The Godfather' appear together in a TKG fact with timestamp 1972. Hence, the time embedding of 1972 can be utilized to further enhance the question representation.</p><p>First, we identify all facts that involve the annotated entities of the question. These facts involve specific timestamps which we collect together (retrieved timestamps). In some cases, we may retrieve multiple timestamps, but we only keep the start and end timestamps after we sort them (since we aim at recovering a question-specific time scope). We recover two temporal embeddings t 1 and t 2 that correspond to the TKG embedding for start and end timestamps, respectively. We term this method TempoQR-Hard. Soft Supervision: Inference in the TKG embedding space. Instead of retrieving timestamps from the TKG, we may directly obtain time embeddings by utilizing ? to infer missing temporal information. We generate a time-aware question embedding q time as</p><formula xml:id="formula_6">q time = W T q BCLS ,<label>(4)</label></formula><p>where q BCLS corresponds to the [CLS] token embedding of Q B and W T is a D ? D B learnable projection matrix. The time-aware q time is used as a 'virtual relation' in the scoring function ?. TComplEx assigns a score to a timestamp ? that potentially completes a fact (s, r, o, ?) as</p><formula xml:id="formula_7">Re(e s ) ? Re(u ro ) ? Im(e s ) ? Im(u ro ), Re(t ? ) + Re(e s ) ? Im(u ro ) + Im(e s ) ? Re(u ro ), Im(t ? ) ,<label>(5)</label></formula><p>where u ro = v r ?? o . Thus, the real Re(?) and imaginary Im(?) part of the time embedding t ? can be approximated by</p><formula xml:id="formula_8">Re(t ? ) ? Re(e s ) ? Re(u ro ) ? Im(e s ) ? Im(u ro ), Im(t ? ) ? Re(e s ) ? Im(u ro ) + Im(e s ) ? Re(u ro ).<label>(6)</label></formula><p>We follow the same computations to infer the real and imaginary part of the desired (soft-supervised) time embeddings. Here, we treat q time as a relation embedding v r and the annotated entities as subject s and object o interchangeably to generate t 1 and t 2 , respectively. If either s or o is not present, we use dummy ones. We term this method TempoQR-Soft. Note here that the difference of hard and soft supervision relies on the available facts given during QA, i.e., access to the TKG. Moreover, soft-supervision may generalize better since it infers the temporal information in the embedding space. In Section (6), we demonstrate the benefits and limitations of each approach. Fusing temporal information. After obtaining time embeddings t 1 and t 2 , we leverage them to enhance the question representation with temporal information. Specifically, we compute the ith collumn of the time-aware token embedding matrix Q T as q Ti = q Ei , if token i is not an entity, q Ei + t 1 + t 2 , if token i is an entity.</p><p>with</p><formula xml:id="formula_10">Q T := [q TCLS , q T1 , . . . , q TN ].</formula><p>Our intuition for summing the entity and time embeddings together follows the motivation of how transformer-based LMs, e.g., BERT use positional embedding for tokens <ref type="bibr">(Vaswani et al. 2017</ref>).</p><p>Here, time embeddings can be seen as entity positions in the time dimension. Q T contains text, entity and time-aware information. Next, we propose an information fusion layer to combine this information altogether into a single question representation q.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Answer Prediction</head><p>Following <ref type="bibr" target="#b3">(F?vry et al. 2020</ref>), we use an information fusion layer that consists of a dedicated learnable encoder f (?) which consists of l Transformer encoding layers <ref type="bibr">(Vaswani et al. 2017</ref>). This encoder allows the question's tokens to attend to each other, which fuses context, entity and time-aware information together. The final token embedding matrix Q is calculated as</p><formula xml:id="formula_11">Q = f (Q T ),<label>(8)</label></formula><p>where the columns of the embedding matrix correspond to the initial tokens Q := [q CLS , q 1 , . . . , q N ]. As a final question representation, we use the embedding of the [CLS] token q := q CLS . The final score of an entity ? ? E being the answer is given by</p><formula xml:id="formula_12">max ?(e s , P E q, e ? , t ? ), ?(e o , P E q, e ? , t ? ) ,<label>(9)</label></formula><p>where s, o and ? are the annotated subject, object and timestamp, respectively, and P E is a D ? D learnable matrix specific for entity predictions. Here, we treat the annotated subject and object interchangeably, and the max(?) function ensures that we ignore the scores when s or o is a dummy entity.</p><p>In addition, the final score of an timestamp ? ? T being the answer is given by</p><formula xml:id="formula_13">?(e s , P T q, e o , t ? ),<label>(10)</label></formula><p>where s, o are annotated entities in the question and P T is a D ? D learnable matrix specific for time predictions.</p><p>During training, the entity and time scores are concatenated and transformed to probabilities by a softmax function. The model's parameters are updated to assign higher probabilities to the correct answers by minimizing a cross entropy loss. We used the corrupted TKG to perform two experiments. In the first experiment, we substitute the original TKG with the corrupted one during the QA task. This affects only TempoQR-Hard since this is the only method that uses a TKG during QA. The second configuration is to substitute the original TKG with the corrupted one throughout the process. This means that TComplEx embeddings are generated on a corrupted TKG and, thus, may not encode important temporal information. All TKGQA embedding-based methods are affected by this configuration. Additional Complex Questions. Although CronQuestions includes different question types, we manually create additional complex types. The idea is to evaluate how different methods perform on complex questions that were unseen during training but include the same keywords (and temporal constraints) with the training questions. We create (i) 'before &amp; after' questions that include both 'before' and 'after' constraints and (ii) 'before/after &amp; first/last' questions that include both 'before/after' and 'first/last' constraints. We describe the details of generating these QA pairs in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Model Configuration</head><p>We learn TKG embeddings with the TComplEx method, where we set their dimensions D = 512. During, QA the pre-trained LM's parameters and the TKG embeddings are not updated. We set the number of transformer layers of the encoder f (?) to l = 6 with 8 heads per layer. We also observed the same performance when setting l = 3 with 4 heads per layer. The model's parameters are updated with Adam (Kingma and Ba 2014) with a learning rate of 0.0002. The model is trained for 20 maximum epochs and the final parameters are determined based on the best validation performance. The model is implemented with Pytorch <ref type="bibr" target="#b18">(Paszke et al. 2019)</ref>. For reproducibility, our code is available at: https://github.com/cmavro/TempoQR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Baseline methods and TempoQR variations</head><p>Pre-trained LMs. BERT <ref type="bibr" target="#b2">(Devlin et al. 2019</ref>) and RoBERTa <ref type="bibr" target="#b15">(Liu et al. 2019</ref>) are two well-established pre-trained LMs. To evaluate these models, we generate their LM-based question embedding and concatenate it with the annotated entity and time embeddings, followed by a learnable projection. The resulted embedding is scored against all entities and timestamps via dot-product. EaE and EntityQR. Entity as Experts (EaE) <ref type="bibr" target="#b3">(F?vry et al. 2020</ref>) is an entity-aware method similar to TempoQR. The key differences are that EaE does not utilize a TKG embedding-based scoring function for answer prediction and that it does not fuse additional temporal information as in Section 4.3. As a baseline, we experiment with EaE combined with TComplEx scoring function. Since this baseline is similar to TempoQR without the steps of Section (4.3), we call it EntityQR. CronKGQA and EmbedKGQA. CronKGQA is the TKGQA embedding-based method described in Section 3.2. EmbedKGQA <ref type="bibr" target="#b20">(Saxena, Tripathi, and Talukdar 2020)</ref> is similar to CronKGQA, but designed for regular KGs. In <ref type="bibr" target="#b19">(Saxena, Chakrabarti, and Talukdar 2021)</ref>, EmbedKGQA is implemented for TKGQA as follows. Timestamps are ignored during pre-training and random time embeddings are used during the QA task.   CronKGQA and EntityQR with hard and soft supervision. CronKGQA and EntityQR are extended to incorporate additional temporal information by the algorithmic steps in Section 4.3, which generate time embeddings t 1 and t 2 for TempoQR. Recall that TempoQR generates t 1 and t 2 by either accessing the TKG or by inferring them in the embedding space. For CronKGQA and EntityQR, we generate t 1 and t 2 in the same way, but we employ them directly to the TComplEx scoring function as follows. We modify (9), which scores an entity to be the answer, as max ?(e s , P E q, e ? , t 1 + t 2 ),</p><formula xml:id="formula_14">?(e o , P E q, e ? , t 1 + t 2 ) ,<label>(11)</label></formula><p>to replace the embedding of a dummy timestamp t ? (if no time is annotated in the question) with t 1 + t 2 . Based on how t 1 and t 2 are generated (hard or soft supervision), we term the methods CronKGQA-Hard and EntityQR-Hard or CronKGQA-Soft and EntityQR-Soft, respectively.  We also highlight that methods that score possible answers with the TComplEx function (TempoQR, EntityQR and CronKGQA) answer 99% of the simple questions correctly. The other methods (BERT, RoBERTa, EmbedKGQA and EaE) cannot answer correctly more the 35% (Hits@1) and 76% (Hits@10). Similarly, BERT, RoBERTa, Embed-KGQA and EaE have 35%-65% and 11%-40% worse overall accuracy for Hits@1 and Hits@10, respectively, compared to TempoQR, EntityQR and CronKGQA.  <ref type="table" target="#tab_5">Table 3</ref> shows how soft and hard supervision affect the performance of various methods for different question types. First, we see that both supervision approaches have a positive effect on CronKGQA, where the performance is improved by 2.5% and 6% over the original method (CronKGQA-Soft and CronKGQA-Hard, respectively, compared to CronKGQA). The same does not happen for En-tityQR, where its performance drops (EntityQR-Soft and EntityQR-Hard compared to EntityQR). This is an effect of over-using TKG embeddings, since EntityQR-Soft and EntityQR-Hard use this information multiple times for answer prediction. Moreover, TempoQR-Hard performs much better for 'first/last' questions compared to soft-supervision (27% absolute improvement). Since TempoQR-Hard always retrieves the start and end timestamps of the question entities, this provides more accurate temporal information to "When was the first/last time..." questions. On the other hand, this does not equally benefit 'before/after' questions; the improvement of hard-supervision over soft-supervision is only 3%. This indicates that both approaches handle such questions in a similar manner. Finally, TempoQR-Soft performs 8% worse in 'time join' questions compared to TempoQR-Hard. This indicates that might be some room for improvement for inferring more accurate time embeddings with softsupervision. <ref type="figure" target="#fig_4">Figure 2a</ref> shows the results when the given TKG is corrupted during the QA phase. TempoQR-Hard is the only method that depends on the quality of the TKG during QA and is greatly affected by a corrupted TKG. When a lot of facts are corrupted (p = 0.8) it performs similar to EntityQR, which does not use any additional temporal information. For 'before/after' questions, it performs worse than TempoQR-Soft even when the facts are corrupted by a probability p = 0.2. Finally, TempoQR-Hard is more robust for 'first/last' and 'time join' questions, where it better handles the noncorrupted timestamps of the facts. <ref type="figure" target="#fig_4">Figure 2b</ref> shows the results when a corrupted TKG is given for both TKG embedding and QA. We can see that methods that rely on TKG embeddings (TempoQR-Hard, TempoQR-Soft) are greatly affected, since they perform similar to each other as well to EntityQR when the corruption probability p is large, e.g., p = 0.5. CornKGQA is the least affected by a corrupted TKG, but, still, its performance is much lower. The largest performance drop is observed for TempoQR-Hard for 'first/last' questions, which indicates that it cannot generalize well to such questions under a corrupted TKG. Finally, depending on the information that is corrupted, some methods benefit over others, i.e., compare TempoQR-Hard to EntityQR for p = 0.33 at 'time join' questions. <ref type="figure" target="#fig_5">Figure 3</ref> shows the performance for unseen question types during training. As we can see, TempoQR-Soft performs the best for both generated question types. Since it learns to handle temporal constraints in the embedding space, it generalizes better than TempoQR-Hard which simply uses the TKG to answer such questions. In general, neither of these methods seems to be able to tackle unseen questions effectively, i.e., Hits@1 is below 20% for all the methods. This is also confirmed since the performance of the methods only increases when k is increased, i.e., the return more possible answers. This motivates the need for extending these methods in a way that ensures better performance for unseen questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Main Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Ablation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Robustness over Corrupted TKGs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Unseen Question Types</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>This paper puts forth a comprehensive embedding framework specialized in answering complex questions over TKGs. The benefit of TempoQR comes by learning context, entity and time-aware question representations. The latter relies either on hard or soft supervision. Extensive experiments confirmed the benefits of each step performed in our method. TempoQR outperforms existing methods for complex questions by 25-45%. The limitations and advantages of hard Trouillon, T.; Dance, C. R.;?ric Gaussier; Welbl, J.; <ref type="bibr">Riedel, S.;</ref><ref type="bibr">and Bouchard, G. 2017. Knowledge Graph Completion via Complex Tensor Factorization. JMLR. Vaswani, A.;</ref><ref type="bibr">Shazeer, N.;</ref><ref type="bibr">Parmar, N.;</ref><ref type="bibr">Uszkoreit, J.;</ref><ref type="bibr">Jones, L.;</ref><ref type="bibr">Gomez, A. N.;</ref><ref type="bibr">Kaiser, L.;</ref><ref type="bibr">and Polosukhin, I. 2017</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Generation of Additional Complex Questions</head><p>We create 'before &amp; after' questions that include both 'before' and 'after' constraints, e.g., "Which movies won The Best Picture after The Godfather and before Forrest Gump?". Additionally, we create 'before/after &amp; first/last' questions that include both 'before/after' and 'first/last' constraints, e.g., "Which is the last movie to win Best Picture after The Godfather?". For both new complex types, we end up with 261 QA pairs that are only used for inference (unseen during training). We also provide the QA pairs in the submission files. The two evaluation datasets were created as follows. The 'before &amp; after' dataset was generated by identifying all before/after questions in the original CronQuestions dataset which contained the 'position held' relation. These questions were then filtered to a subset derived from 14 templates which could be easily modified to contain both before and after conditions while remaining syntactically correct. For example, the template 'Who held the position of tail after head' was included in this set because it can be converted into a before &amp; after question by adding ' and before tail2' to the end of the sentence. All of the new before &amp; after questions were created in this manner by adding either ' and before tail2' or ' and after tail2' for questions which originally contained after or before conditions (respectively).</p><p>The 'tail2' and answer entities for these questions were selected by first identifying all answer entities from the original question which have a start time in the TKG which is strictly greater (less) than that of the start time of the 1head' entity for questions containing an after (before) condition. These entities were then sorted in ascending order of their closeness in time to the 1head' entity. The entity containing the third-closest distinct start time to that of the 'head' entity was selected as the 'tail2' entity while all other entities containing a start date between that of the 'head' and 'tail2' entities were used as answer entities.</p><p>The 'before/after &amp; first/last' questions were generated using a similar process. For questions originally containing an 'after' condition, we also add the word 'first' prior to the 'tail' relation. Likewise, we add the word 'last' prior to the 'tail' relation for questions which originally contained a 'before' condition. The answer set is then filtered to only contain the entity which has the closest start date in time to that of the 'head' entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3">Variants of TempoQR</head><p>Difference with TComplEx. TComplEx is a TKG embedding scoring function (decoder) and can only answer questions that involve a single fact, e.g., (s, r, ?, ? ), with a provided TKG relation r. TempoQR handles questions that involve multiple facts and does not rely on a specific relation r. The main contribution here is to encode semantic and temporal information from multiple facts to a single question representation q, which can be used as a virtual relation (Sec. 4.2 and 4.3). For scoring answers using q, different decoders can be implemented via Eq.(9) and (10), e.g., the TComplEx or a dot product decoder. For TempoQR-Soft, Eq.(6) should be adapted according to the decoder.</p><p>We also include the following Ensemble of Hard and Soft Supervision. When we add time embeddings of both approaches and measure the H@1(%) for complex questions, the ensemble improves by 2.1 points over TempoQR-Hard for 'before/after' questions where TempoQR-Hard cannot retrieve the accurate time from the TKG. For 'first/last' and 'time join' question, the soft supervision introduces noise and actually decreases the performance compared to TempoQR-Hard by 1.9 and 6.7 points, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4">Fusion of Time Embeddings</head><p>TempoQR-cat and TempoQR-att. TempoQR-cat and TempoQR-att are variations of TempoQR with different fusion implementations compared to the one in Section 4.3. In TempoQR-cat, we substitute the sum operator in (7) q Ti = q Ti + t 1 + t 2 by concatenating the entity and time embeddings followed by a learnable projection. In TempoQR-att, we append the time embeddings to the embedding matrix as new tokens of the sentence. This is equivalent to transforming the given sentence from, e.g., "Which movie won the Best Picture after The Godfather" to "Which movie won the Best Picture after The Godfather, 1972" and applying Enti-tyQR. We use TempoQR-att with hard-supervision only.  <ref type="table" target="#tab_9">Table 5</ref> shows the results for different strategies of fusing time embeddings with hard or soft supervision. As we can see, our implementation of summing entity and time embeddings (TempoQR) performs the best. We note that this is typically the way transformer-based architectures combine token and positional embeddings. Moreover, TempoQR-cat and TempoQR-att perform much worse for 'time join' and 'simple' questions. This means that a lot of important time information is ignored by their projection and attention layer, respectively. Whereas, by summing the time embeddings, we ensure that all the information is encoded. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.5">Training Size</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.6">Is Time All We Need?</head><p>In this experimental configuration, the goal is to evaluate TempoQR-Hard with different ways that generate time embeddings. First, we use TComplEx embeddings for the (i) start and end timestamps (Section 4.3) (TComplEx-Start&amp;End) and (ii) a randomly sampled timestamp between the start and end timestamp (TComplEx-Sampled). The second approach is instead of using TComplEx embeddings to use positional embeddings as in <ref type="bibr">(Vaswani et al. 2017)</ref>. The positional embedding are generated based on each timestamp's identifier and are ensured to preserve the ordering of the timestamps in the embedding space. We use positional embeddings of the start and end timestamp for TempoQR-Hard (PosEmb-Start&amp;End). Finally, we generate completely random time embeddings, which we use them for the start and end timestamps (RandEmb-Start&amp;End). This ensures that all time embeddings are well-separated. In all cases, the time embeddings are not updated during QA.  <ref type="table" target="#tab_10">Table 6</ref> shows the results for differently generated time embeddings for TempoQR-Hard. As we can see, using the start and end timestamps is a key decision that provides the best results (TComplEx-Sampled has the lowest performance). <ref type="table" target="#tab_10">Table 6</ref> indicates is that the time embeddings themselves do not play an important role. What TempoQR-Hard needs is to be able to associate given questions with different times. This is confirmed since RandEmb have the perform equally with TComplEx embeddings. Here, the random embeddings are nothing more than a unique identifier for each timestamp. They also perform the best for 'first/last' questions, since the timestamps are well-separated in the embedding space. On the other hand, PosEmb perform the best for 'before/after' questions. This happens because the timestamp ordering is preserved in the embedding space and allows for better 'before/after' reasoning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>'</head><label></label><figDesc>Time-aware question representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>(a) The underlying TKG for the question "Which movie won the Best Picture after The Godfather?"; Answer: 'The Sting'. (b) The context-aware question representation (dashed arrows) scores higher (numbers in parentheses) movie entities. (c) The representation is grounded to the entity 'Best Picture' and gives higher scores to movies that won the Best Picture. (d)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>is the number of tokens and D are the dimensions of the TKG embeddings. W B is a D ? D B learnable projection matrix where D B is the output the dimension of the LM (D B = 768 for BERT(?)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Corrupted TKG for both Pre-training and QA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Performance comparison when the underlying TKG is corrupted. x-axis corresponds to the probability p of a fact to be corrupted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>Evaluation for unseen complex types during inference. x-axis corresponds to k of Hits@k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 Figure 4 :</head><label>44</label><figDesc>shows the performance for complex questions for different training sizes. As the training size reduces, both TempoQR-Hard and TempoQR-Soft perform worse. We observe a slightly faster performance drop for TempoQR-Hard. Evaluation for different training size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Different types of temporal questions. {?} s , {?} o , {?} ? correspond to annotated entities s, o ? E and timestamps ? ? T .</figDesc><table><row><cell>Type</cell><cell>Example Questions</cell></row><row><cell>Simple Time</cell><cell>When did {Stoke} s have {Tom Holford} o in their team</cell></row><row><cell cols="2">Simple Entity Which movie won the {Best Picture} s in {1973} ?</cell></row><row><cell>Before/After</cell><cell>Which movie won the {Best Picture} s after {The Godfather} o</cell></row><row><cell>First/Last</cell><cell>Name the award that {Sydney Chapman} s first received</cell></row><row><cell>Time Join</cell><cell>Name a teammate of {Thierry Henry} s in {Arsenal} o</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>To illustrate how methods perform under incomplete TKGs, we provide a setting where the given WikiData TKG is corrupted at the time dimension. Specifically, for a fact (subject, relation, object, [start time, end time]) ? F , we remove the associated timestamps with probability p. If the timestamps are removed, the fact becomes (subject, relation, object, no time). Here, 'no time' denotes that there is no timestamp associated with (subject, relation, object) and we treat it as a special timestamp.</figDesc><table><row><cell>5 Experimental Setting</cell></row></table><note>Datasets. CronQuestions (Saxena, Chakrabarti, and Talukdar 2021) is a temporal QA benchmark based on the Wikidata TKG proposed in (Lacroix, Obozinski, and Usunier 2020). The WikiData TKG consists of 125k entities, 203 relations, 1.7k timestamps (timestamps correspond to years), and 328k facts. In this TKG, facts are represented as (subject, relation, object, [start time, end time]). CronQuestions consists of 410k unique question-answer pairs, 350k of which are for training and 30k for validation and for testing. Moreover, the entities and times present in the questions are annotated. CronQuestions includes both simple and complex temporal questions ( Table 1 for examples). Incomplete WikiData TKG.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparison against other methods.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Hits@1</cell><cell></cell><cell></cell><cell cols="2">Hits@10</cell><cell></cell></row><row><cell>Model</cell><cell>Overall</cell><cell cols="4">Question Type Complex Simple Entity Time Answer Type Overall</cell><cell cols="3">Question Type Complex Simple Entity Time Answer Type</cell></row><row><cell>BERT</cell><cell>0.243</cell><cell>0.239</cell><cell>0.249</cell><cell>0.277 0.179</cell><cell>0.620</cell><cell>0.598</cell><cell>0.649</cell><cell>0.628 0.604</cell></row><row><cell>RoBERTa</cell><cell>0.225</cell><cell>0.217</cell><cell>0.237</cell><cell>0.251 0.177</cell><cell>0.585</cell><cell>0.542</cell><cell>0.644</cell><cell>0.583 0.591</cell></row><row><cell>EmbedKGQA</cell><cell>0.288</cell><cell>0.286</cell><cell>0.290</cell><cell>0.411 0.057</cell><cell>0.672</cell><cell>0.632</cell><cell>0.725</cell><cell>0.850 0.341</cell></row><row><cell>EaE</cell><cell>0.288</cell><cell>0.257</cell><cell>0.329</cell><cell>0.318 0.231</cell><cell>0.678</cell><cell>0.623</cell><cell>0.753</cell><cell>0.688 0.698</cell></row><row><cell>CronKGQA</cell><cell>0.647</cell><cell>0.392</cell><cell>0.987</cell><cell>0.699 0.549</cell><cell>0.884</cell><cell>0.802</cell><cell>0.992</cell><cell>0.898 0.857</cell></row><row><cell>EntityQR</cell><cell>0.745</cell><cell>0.562</cell><cell>0.990</cell><cell>0.831 0.585</cell><cell>0.944</cell><cell>0.906</cell><cell>0.993</cell><cell>0.962 0.910</cell></row><row><cell>TempoQR-Soft</cell><cell>0.799</cell><cell>0.655</cell><cell>0.990</cell><cell>0.876 0.653</cell><cell>0.957</cell><cell>0.930</cell><cell>0.993</cell><cell>0.972 0.929</cell></row><row><cell>TempoQR-Hard</cell><cell>0.918</cell><cell>0.864</cell><cell>0.990</cell><cell>0.926 0.903</cell><cell>0.978</cell><cell>0.967</cell><cell>0.993</cell><cell>0.980 0.974</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>shows the results of our method compared to other</cell></row><row><cell>baselines on CronQuestions. First, by comparing EntityQR</cell></row><row><cell>to CronKGQA, we see that grounding the question to the</cell></row><row><cell>entities it refers (entity-aware step) significantly helps for</cell></row><row><cell>answering complex questions. In this case, the absolute im-</cell></row><row><cell>provement for complex questions is 17% and 10% at Hits@1</cell></row><row><cell>and Hits@10, respectively. Furthermore, comparing Tem-</cell></row><row><cell>poQR to EntityQR, we see the benefit of adding temporal</cell></row><row><cell>information to the question (time-aware step). The abso-</cell></row><row><cell>lute improvement of TempoQR-Soft over EntityQR is 9%</cell></row><row><cell>at Hits@1 for complex questions, while the respective im-</cell></row><row><cell>provement of TempoQR-Hard is more than 30%. More-</cell></row><row><cell>over, TempoQR-Hard outperforms TempoQR-Soft by 25%</cell></row><row><cell>at Hits@1 when the answer is a time. This confirms that</cell></row><row><cell>TempoQR-Hard provides accurate temporal information by</cell></row><row><cell>retrieving it from the TKG, while TempoQR-Soft sometimes</cell></row><row><cell>cannot infer as accurate information from the embedding</cell></row><row><cell>space.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Hits@1 for different complex type questions.</figDesc><table><row><cell></cell><cell cols="3">Complex Questions</cell><cell>All</cell></row><row><cell></cell><cell cols="3">Before/ First/ Time</cell></row><row><cell></cell><cell>After</cell><cell>Last</cell><cell>Join</cell></row><row><cell>CronKGQA</cell><cell>0.256</cell><cell cols="2">0.371 0.511 0.647</cell></row><row><cell>EntityQR</cell><cell>0.540</cell><cell cols="2">0.493 0.833 0.745</cell></row><row><cell>CronKGQA-Soft</cell><cell>0.341</cell><cell cols="2">0.375 0.671 0.672</cell></row><row><cell>EntityQR-Soft</cell><cell>0.430</cell><cell cols="2">0.468 0.766 0.708</cell></row><row><cell>TempoQR-Soft</cell><cell>0.670</cell><cell cols="2">0.570 0.894 0.799</cell></row><row><cell>CronKGQA-Hard</cell><cell>0.379</cell><cell cols="2">0.445 0.942 0.728</cell></row><row><cell>EntityQR-Hard</cell><cell>0.442</cell><cell cols="2">0.470 0.955 0.748</cell></row><row><cell>TempoQR-Hard</cell><cell>0.714</cell><cell cols="2">0.853 0.978 0.918</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>. Attention is All You Need. In NIPS. Xiong, W.; Yu, M.; Chang, S.; Guo, X.; and Wang, W. Y.</figDesc><table><row><cell>2019. Improving Question Answering over Incomplete KBs</cell></row><row><cell>with Knowledge-Aware Reader. In Proceedings of the 57th</cell></row><row><cell>Annual Meeting of the Association for Computational Lin-</cell></row><row><cell>guistics, 4258-4264. Florence, Italy: Association for Com-</cell></row><row><cell>putational Linguistics.</cell></row><row><cell>Xu, K.; Lai, Y.; Feng, Y.; and Wang, Z. 2019. Enhancing</cell></row><row><cell>Key-Value Memory Neural Networks for Knowledge Based</cell></row><row><cell>Question Answering. In Proceedings of the 2019 Confer-</cell></row><row><cell>ence of the North American Chapter of the Association for</cell></row><row><cell>Computational Linguistics: Human Language Technologies,</cell></row><row><cell>Volume 1 (Long and Short Papers), 2937-2947. Minneapo-</cell></row><row><cell>lis, Minnesota: Association for Computational Linguistics.</cell></row><row><cell>Yang, B.; Yih, W.-t.; He, X.; Gao, J.; and Deng, L. 2014.</cell></row><row><cell>Embedding entities and relations for learning and inference</cell></row><row><cell>in knowledge bases. arXiv preprint arXiv:1412.6575.</cell></row><row><cell>Zhang, Z.; Han, X.; Liu, Z.; Jiang, X.; Sun, M.; and Liu,</cell></row><row><cell>Q. 2019. ERNIE: Enhanced Language Representation with</cell></row><row><cell>Informative Entities. arXiv:1905.07129.</cell></row><row><cell>Zhou, M.; Huang, M.; and Zhu, X. 2018. An Interpretable</cell></row><row><cell>Reasoning Network for Multi-Relation Question Answer-</cell></row><row><cell>ing. In COLING.</cell></row><row><cell>8 Appendix</cell></row><row><cell>8.1 CronQuestions Statistics</cell></row><row><cell>Additional statistics of the CronQuestions dataset are shown</cell></row><row><cell>in Table 4. Simple Reasoning questions contains Simple En-</cell></row><row><cell>tity and Simple Time questions, while Complex Reason-</cell></row><row><cell>ing contain Before/After, First/Last, and Time Join ques-</cell></row><row><cell>tions. Entity Answer questions contain Simple Entity, Be-</cell></row><row><cell>fore/After, First/Last, and Time Join questions, while Time</cell></row><row><cell>Answer questions contain Simple Time and First/Last.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Number of questions in our dataset across different types of reasoning required and different answer types.</figDesc><table><row><cell></cell><cell>Train</cell><cell>Dev</cell><cell>Test</cell></row><row><cell>Simple Entity</cell><cell>90,651</cell><cell>7,745</cell><cell>7,812</cell></row><row><cell>Simple Time</cell><cell>61,471</cell><cell>5,197</cell><cell>5,046</cell></row><row><cell>Before/After</cell><cell>23,869</cell><cell>1,982</cell><cell>2,151</cell></row><row><cell>First/Last</cell><cell cols="3">118,556 11,198 11,159</cell></row><row><cell>Time Join</cell><cell>55,453</cell><cell>3,878</cell><cell>3,832</cell></row><row><cell>Simple Reasoning</cell><cell cols="3">152,122 12,942 12,858</cell></row><row><cell cols="4">Complex Reasoning 197,878 17,058 17,142</cell></row><row><cell>Entity Answer</cell><cell cols="3">225,672 19,362 19,524</cell></row><row><cell>Time Answer</cell><cell cols="3">124,328 10,638 10,476</cell></row><row><cell>Total</cell><cell cols="3">350,000 30,000 30,000</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Table to directly compare TComplEx with TempoQR and to evaluate the performance with other decoders for complex temporal questions (H@1). The TComplEx model is implemented via Eq.(1) by providing the ground-truth relation r of each question. The first row of theTable shows that TempoQR vastly outperforms TComplEx since the latter cannot handle complex questions.Moreover, the second row shows that our method is competitive across different decoders, such as the dot-product ? dot .</figDesc><table><row><cell>Model?</cell><cell>TComplEx</cell><cell cols="3">CronKGQA TempoQR-Soft TempoQR-Hard</cell></row><row><cell>Decoder?</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>?TComplEx</cell><cell>0.022</cell><cell>0.392</cell><cell>0.655</cell><cell>0.864</cell></row><row><cell>?dot</cell><cell>Not applicable</cell><cell>0.248</cell><cell>0.366</cell><cell>0.721</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Hits@1 for fusion strategies.</figDesc><table><row><cell></cell><cell cols="3">Complex Questions</cell><cell cols="2">Simple Questions</cell></row><row><cell></cell><cell cols="5">Before/ First/ Time Simple Simple</cell></row><row><cell></cell><cell>After</cell><cell>Last</cell><cell>Join</cell><cell>Entity</cell><cell>Time</cell></row><row><cell>Soft Super.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TempoQR-cat</cell><cell>0.605</cell><cell cols="3">0.518 0.794 0.985</cell><cell>0.867</cell></row><row><cell>TempoQR</cell><cell>0.670</cell><cell cols="3">0.570 0.894 0.991</cell><cell>0.987</cell></row><row><cell>Hard Super.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TempoQR-cat</cell><cell>0.692</cell><cell cols="3">0.847 0.866 0.989</cell><cell>0.940</cell></row><row><cell>TempoQR-att</cell><cell>0.683</cell><cell cols="3">0.835 0.871 0.989</cell><cell>0.881</cell></row><row><cell>TempoQR</cell><cell>0.714</cell><cell cols="3">0.853 0.978 0.992</cell><cell>0.988</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Hits@1 for different time embeddings of TempoQR-Hard.</figDesc><table><row><cell>TempoQR-Hard</cell><cell cols="3">Before/ First/ Time</cell></row><row><cell>Time Embeddings</cell><cell>After</cell><cell>Last</cell><cell>Join</cell></row><row><cell>TComplEx-Sampled</cell><cell>0.602</cell><cell cols="2">0.516 0.919</cell></row><row><cell>TComplEx-Start&amp;End</cell><cell>0.714</cell><cell cols="2">0.853 0.978</cell></row><row><cell>PosEmb-Start&amp;End</cell><cell>0.724</cell><cell cols="2">0.832 0.976</cell></row><row><cell>RandEmb-Start&amp;End</cell><cell>0.713</cell><cell cols="2">0.868 0.976</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>and soft supervision are also showcased. Future research includes extending existing methods to generalize better to unseen question types.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.06314</idno>
		<title level="m">A Dataset for Answering Time-Sensitive Questions</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Entities as Experts: Sparse Memory Access with Entity Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>F?vry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kwiatkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Open Domain Question Answering based on Text Enhanced Knowledge Graph with Hyperedge Infusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1475" to="1481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improving Multi-Hop Knowledge Base Question Answering by Learning Intermediate Supervision Signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM International Conference on Web Search and Data Mining, WSDM &apos;21</title>
		<meeting>the 14th ACM International Conference on Web Search and Data Mining, WSDM &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">9781450382977</biblScope>
			<biblScope unit="page" from="553" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tempquestions: A benchmark for temporal question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Saha Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Str?tgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Companion Proceedings of the The Web Conference</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1057" to="1062" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Tequila: Temporal question answering over knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abujabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Saha Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Str?tgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1807" to="1810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Complex Temporal Question Answering on Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pramanik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Saha Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 30th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="792" to="802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ForecastQA: A Question Answering Challenge for Event Forecasting with Temporal Text Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Khanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4636" to="4650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kobyzev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Poupart</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11485</idno>
		<title level="m">Representation Learning for Dynamic Graphs: A Survey</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kolitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O.-E</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.07699</idno>
		<title level="m">End-to-End Neural Entity Linking</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Tensor Decompositions for Temporal Knowledge Base Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lacroix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.06688</idno>
		<title level="m">Complex Knowledge Base Question Answering: A Survey</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>abs/1907.11692</idno>
	</analytic>
	<monogr>
		<title level="j">RoBERTa: A Robustly Optimized BERT Pretraining Approach. ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Key-Value Memory Networks for Directly Reading Documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-H</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1400" to="1409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Neelam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Karanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ikbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kapanipathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Abdelaziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mihindukulasooriya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pendus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.13430</idno>
		<title level="m">SYGMA: System for Generalizable Modular Question Answering Over-Knowledge Bases</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Stepwise Reasoning for Multi-Relation Question Answering over Knowledge Graph with Weak Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM International Conference on Web Search and Data Mining, WSDM &apos;20</title>
		<editor>Wallach, H.</editor>
		<editor>Larochelle, H.</editor>
		<editor>Beygelzimer, A.</editor>
		<editor>d&apos;Alch?-Buc, F.</editor>
		<editor>Fox, E.</editor>
		<editor>and Garnett, R.</editor>
		<meeting>the 13th ACM International Conference on Web Search and Data Mining, WSDM &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc. Qiu</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery. ISBN 9781450368223</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Question Answering over Temporal Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Improving Multi-hop Question Answering over Knowledge Graphs using Knowledge Base Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Event-QA: A dataset for event-centric question answering over knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Souza Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gottschalk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Demidova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 29th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3157" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">PullNet: Open Domain Question Answering with Iterative Retrieval on Knowledge Bases and Text. ArXiv, abs/1904.09537</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bedrax-Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mazaitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4231" to="4242" />
		</imprint>
	</monogr>
	<note>Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
