<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Non-linear Neurons with Human-like Apical Dendrite Activations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="20151">AUGUST 2015 1</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Journal Of L A T E X Class</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Files</surname></persName>
						</author>
						<title level="a" type="main">Non-linear Neurons with Human-like Apical Dendrite Activations</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">14</biblScope>
							<biblScope unit="issue">8</biblScope>
							<date type="published" when="20151">AUGUST 2015 1</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Pyramidal neurons</term>
					<term>activation function</term>
					<term>transfer function</term>
					<term>deep learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In order to classify linearly non-separable data, neurons are typically organized into multi-layer neural networks that are equipped with at least one hidden layer. Inspired by some recent discoveries in neuroscience, we propose a new neuron model along with a novel activation function enabling the learning of non-linear decision boundaries using a single neuron. We show that a standard neuron followed by the novel apical dendrite activation (ADA) can learn the XOR logical function with 100% accuracy. Furthermore, we conduct experiments on five benchmark data sets from computer vision, signal processing and natural language processing, i.e. MOROCO, UTKFace, CREMA-D, Fashion-MNIST, and Tiny ImageNet, showing that ADA and the leaky ADA functions provide superior results to Rectified Linear Units (ReLU), leaky ReLU, RBF and Swish, for various neural network architectures, e.g. one-hidden-layer or two-hidden-layer multi-layer perceptrons (MLPs) and convolutional neural networks (CNNs) such as LeNet, VGG, ResNet and Character-level CNN. We obtain further performance improvements when we change the standard model of the neuron with our pyramidal neuron with apical dendrite activations (PyNADA). Our code is available at: https://github.com/raduionescu/pynada.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>T HE power of neural networks in classifying linearly nonseparable data lies in the use of multiple (at least two) layers. We take inspiration from the recent study of Gidon et al. <ref type="bibr" target="#b0">[1]</ref> and propose a simpler yet more effective approach: a new computational model of the neuron, termed pyramidal neuron with apical dendrite activations (PyNADA), along with a novel activation function, termed apical dendrite activation (ADA), allowing us to classify linearly nonseparable data using an individual neuron. Biological motivation. Recently, Gidon et al. <ref type="bibr" target="#b0">[1]</ref> observed that the apical dendrites of pyramidal neurons in the human cerebral cortex have a different activation function than what was previously known from observations on rodents. The newly-discovered apical dendrite activation function produces maximal amplitudes for electrical currents close to threshold-level stimuli and dampened amplitudes for stronger electrical currents, as shown in <ref type="figure" target="#fig_0">Figure 1a</ref>. This new discovery indicates that an individual pyramidal neuron from the human cerebral cortex can classify linearly nonseparable data, contrary to the conventional belief that nonlinear problems require multi-layer neural networks. This is the main reason that motivated us to propose ADA and PyNADA. Psychological motivation. Remember the first time you ate your favorite dish. Was it better than the second or the last time you ate the same dish? According to <ref type="bibr">Knutson</ref>  a Activation function observed in apical dendrites of pyramidal neurons in the human cerebral cortex.</p><p>b Our leaky apical dendrite activation (ADA) function that can be expressed in closed form. This output is obtained by setting l = 0.005, ? = 1 and c = 1 in Equation (4). our brains provide higher responses to novel stimuli than to known (repetitive) stimuli. This means that our brains get bored while eating the same dish over and over again, although the dish might become our favorite. If we were to model the brain response over time for a certain stimulus, we would obtain the function illustrated in <ref type="figure" target="#fig_0">Figure 1a</ref>. This is yet another reason to propose and experiment with ADA and PyNADA in a computational framework based on deep neural networks, which try to mimic the brain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2003.03229v3 [cs.NE] 19 Nov 2021</head><p>Mathematical motivation. Despite the recent significant advances brought by deep learning <ref type="bibr" target="#b2">[3]</ref> in various application domains <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, state-of-the-art deep neural networks rely on an old and simple mathematical model of the neuron introduced by Rosenblatt <ref type="bibr" target="#b5">[6]</ref>. Minsky and Papert <ref type="bibr" target="#b6">[7]</ref> argued that a single artificial neuron is incapable of learning nonlinear functions, such as the XOR function. In order to classify linearly non-separable data, standard artificial neurons are typically organized in multi-layer neural networks that are equipped with at least one hidden layer. Contrary to the common belief, we propose an activation function (ADA) that transforms a single artificial neuron into a non-linear classifier. We also prove that the non-linear neuron can learn the XOR logical function with 100% accuracy. Hence, the ADA function can increase the computational power of individual artificial neurons. Empirical motivation. We provide empirical evidence in favor of replacing the commonly-used (e.g. Rectified Liner Units (ReLU) <ref type="bibr" target="#b7">[8]</ref> and leaky ReLU <ref type="bibr" target="#b8">[9]</ref>) or the recentlyproposed (e.g. Swish <ref type="bibr" target="#b9">[10]</ref>) activation functions with the ones proposed in this work, namely ADA and leaky ADA, in various neural network architectures ranging from onehidden-layer or two-hidden-layer multi-layer perceptrons (MLPs) to convolutional neural networks (CNNs) such as LeNet <ref type="bibr" target="#b10">[11]</ref>, VGG <ref type="bibr" target="#b11">[12]</ref>, ResNet <ref type="bibr" target="#b12">[13]</ref> and Character-level CNN <ref type="bibr" target="#b13">[14]</ref>. We attain accuracy improvements on several tasks: object class recognition on Fashion-MNIST <ref type="bibr" target="#b14">[15]</ref> and Tiny ImageNet <ref type="bibr" target="#b15">[16]</ref>, gender prediction and age estimation on UTKFace <ref type="bibr" target="#b16">[17]</ref>, voice emotion recognition on CREMA-D <ref type="bibr" target="#b17">[18]</ref> and Romanian dialect identification on MOROCO <ref type="bibr" target="#b18">[19]</ref>. We report further accuracy improvements when the standard artificial neurons are replaced with our pyramidal neurons with apical dendrite activations. Contribution. In summary, our contribution is threefold:</p><p>? We propose a new artificial neuron called pyramidal neurons with apical dendrite activations (PyNADA) along with a new activation function called apical dendrite activation (ADA).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>We demonstrate that, due to the novel apical dendrite activation, a single neuron can learn the XOR logical function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>We show that the proposed ADA and PyNADA provide superior results compared to standard neurons based on the notorious ReLU and leaky ReLU activations, for a broad range of tasks and neural architectures. In most cases, our improvements are statistically significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Activation Functions</head><p>Since activation functions have a large impact on the performance of deep neural networks (DNNs), studying and proposing new activation functions is an interesting topic <ref type="bibr" target="#b19">[20]</ref>. Nowadays, perhaps the most popular activation function is ReLU <ref type="bibr" target="#b7">[8]</ref>. Formally, ReLU is defined as max(0, x), where x is the input. Because ReLU is linear on the positive side (for x &gt; 0), its derivative is 1, so it does not saturate like sigmoid and tanh. On the negative side of the domain, ReLU is constant, so the gradient is 0. Hence, a neuron that uses ReLU as activation function cannot update its weights via gradient-based methods on examples for which the neuron is inactive. To eliminate the problem caused by inactivate neurons with ReLU activation, Maas et al. <ref type="bibr" target="#b8">[9]</ref> introduced leaky ReLU. The leaky ReLU function is defined as:</p><formula xml:id="formula_0">y = ReLU leaky (x, l) = l ? min(0, x) + max(0, x), (1)</formula><p>where l is a number between 0 and 1 (typically very close to 0), allowing the gradient to pass even if x &lt; 0. While in leaky ReLU the parameter l is kept fixed, He et al. <ref type="bibr" target="#b20">[21]</ref> proposed Parametric Rectified Linear Units (PReLU), in which the leak l is learned by back-propagation. Different from ReLU, the Exponential Linear Unit (ELU) <ref type="bibr" target="#b21">[22]</ref> outputs negative values, while still avoiding the vanishing gradient problem on the positive side of the domain. This helps in bringing the mean unit activation down to zero, enabling faster convergence times. Another generalization of ReLU is the Maxout unit <ref type="bibr" target="#b22">[23]</ref>, which instead of applying an element-wise function, divides the input into groups of k values and then outputs the maximum value of each group. In contrast to most recent (ReLU, PReLU, ELU, etc.) and historically-motivated (sign, sigmoid, tanh, etc.) activation functions, we propose an activation function that transforms a single artificial neuron into a non-linear classifier. To support our statement, we prove that a neuron followed by our apical dendrite activation function can learn the XOR logical function. We note that there are other activation functions, e.g. Swish <ref type="bibr" target="#b9">[10]</ref> and Radial Basis Function (RBF), that generate non-liner decision boundaries. Different from Swish and RBF, our activation function is supported by recent neuroscience discoveries <ref type="bibr" target="#b0">[1]</ref>. In addition, our experiments show that ADA and leaky ADA provide superior performance levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Models of Artificial Neurons</head><p>To our knowledge, the first mathematical model of the biological neuron is the perceptron <ref type="bibr" target="#b5">[6]</ref>. The Rosenblatt's perceptron was introduced along with a rule for updating the weights, which converges to a solution only if the data set is linearly separable. Although the perceptron is a simple and old model, it represents the foundation of modern DNNs. Different from the Rosenblatt's perceptron, the Adaptive Linear Neuron (ADALINE) <ref type="bibr" target="#b23">[24]</ref> updates its weights via stochastic gradient descent, back-propagating the error before applying the sign function. ADALINE has the same disadvantage as Rosenblatt's perceptron, namely that it cannot produce non-linear decision boundaries.</p><p>In contrast to Rosenblatt's perceptron and ADALINE, we propose an artificial neuron that has two input branches, the basal branch and the apical tuft. The apical tuft is particularly novel because it uses a novel activation function <ref type="bibr" target="#b0">[1]</ref> that can solve non-linearly separable problems.</p><p>There are a few works that studied various aspects of the modeling of pyramidal neurons, e.g. segregated dendrites in the context of deep learning <ref type="bibr" target="#b24">[25]</ref> or memorizing sequences with active dendrites and multiple integration zones <ref type="bibr" target="#b25">[26]</ref>. Inspired by the recent discovery of Gidon et al. <ref type="bibr" target="#b0">[1]</ref>, to our knowledge, we are the first to propose a human-like artificial pyramidal neuron. Different from previous studies, the apical tuft of our pyramidal neuron is equipped with the novel apical dendrite activation suggested by Gidon et al. <ref type="bibr" target="#b0">[1]</ref>. Furthermore, we integrate our pyramidal neuron into various deep neural architectures, showing its benefits over standard artificial neurons. We note that Gidon et al. <ref type="bibr" target="#b0">[1]</ref> have not presented the pyramidal neuron in a computational scenario, hence we are the first modeling it computationally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">NON-LINEAR NEURONS WITH APICAL DEN-DRITE ACTIVATIONS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">ADA: Apical Dendrite Activation Function</head><p>The activation function illustrated in <ref type="figure" target="#fig_0">Figure 1a</ref> and deduced from the experiments conducted by Gidon et al. <ref type="bibr" target="#b0">[1]</ref> can be formally expressed as follows:</p><formula xml:id="formula_1">y = 0, if x &lt; 0 exp(?x), if x ? 0 ,<label>(2)</label></formula><p>where x ? R is the input of the activation function and y is the output.</p><p>Since the function defined in Equation <ref type="formula" target="#formula_1">(2)</ref> is not useful in practice 1 , we propose a closed form definition that approximates the activation function defined in Equation <ref type="formula" target="#formula_1">(2)</ref>, as follows:</p><formula xml:id="formula_2">y = ADA(x, ?, c) = max(0, x) ? exp(?x?? + c), (3)</formula><p>where x ? R is the input of the activation function, ? &gt; 0 is a parameter that controls the width of the peak, c &gt; 0 is a constant that controls the height of the peak and y is the output. Similar to ReLU, our apical dendrite activation (ADA) is saturated on the negative side, i.e. its gradients are equal to zero for x &lt; 0. Thus, a neural model trained with back-propagation <ref type="bibr" target="#b28">[29]</ref> would not update the corresponding weights. We therefore propose leaky ADA, a more generic version that avoids saturation on the negative side, just as leaky ReLU. We formally extend the definition of ADA from Equation (3) to leaky ADA as follows: y = ADA leaky (x, ?, c, l) = l?min(0, x) + ADA(x, ?, c), <ref type="bibr" target="#b3">(4)</ref> where 0 ? l ? 1 is the leak parameter controlling the function steepness on the negative side and the other parameters are the same as in Equation <ref type="formula">(3)</ref>. By setting l = 0.005, ? = 1 and c = 1 in Equation <ref type="formula">(4)</ref>, we obtain the activation function illustrated in <ref type="figure" target="#fig_0">Figure 1b</ref>. By comparing Figures 1a and 1b, we observe that the (leaky) ADA function defined in Equation (4) has a similar shape to the transfer function defined in Equation <ref type="formula" target="#formula_1">(2)</ref>. Indeed, both functions have no activation or almost no activation when x &lt; 0. Then, there is a high activation peak for small but positive values of x. Finally, the activation damps along the horizontal axis, as x gets larger and larger. Lemma 1. There exists an artificial neuron followed by the apical dendrite activation from Equation (3) which can predict the labels for the XOR logical function, by rounding its output.</p><p>Proof. Given an input data sample represented as a row vector x ? R n , the output y ? R of an artificial neuron with ADA is obtained as follows:</p><formula xml:id="formula_3">y = ADA(x ? w + b, ?, c),<label>(5)</label></formula><p>1. Commonly-used deep learning frameworks such as TensorFlow <ref type="bibr" target="#b26">[27]</ref> and PyTorch <ref type="bibr" target="#b27">[28]</ref> do not cope well with functions containing if branches.</p><p>where ? and c are defined as in Equation <ref type="formula">(3)</ref>, w is the column weight vector and b is the bias term. The following equation shows how to obtain the rounded output:</p><formula xml:id="formula_4">y = ADA(x ? w + b, ?, c) ,<label>(6)</label></formula><p>where ? is the rounding function. Similarly, we can obtain the rounded outputs for an entire set of data samples represented as row vectors in an input matrix X:</p><formula xml:id="formula_5">Y = ADA(X ? w + b, ?, c) .<label>(7)</label></formula><p>Let X and T represent the data samples and the targets corresponding to the XOR logical function, i.e.:</p><formula xml:id="formula_6">X = ? ? ? ? 0 0 0 1 1 0 1 1 ? ? ? ? , T = ? ? ? ? 0 1 1 0 ? ? ? ? .<label>(8)</label></formula><p>We next provide an example of weights and parameters to prove our lemma. By setting w = 5 5 , b = ?4, ? = 1 and c = 1 in Equation <ref type="formula" target="#formula_5">(7)</ref>, we obtain the following output:</p><formula xml:id="formula_7">Y = ? ? ? ? ? ? ADA ? ? ? ? ? ? ? ? 0 0 0 1 1 0 1 1 ? ? ? ? ? 5 5 ? 4, 1, 1 ? ? ? ? ? ? ? ? ? ? = ? ? ? ? ? ? ADA ? ? ? ? ? ? ? ? ?4 1 1 6 ? ? ? ? , 1, 1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0 1 1 0.04 ? ? ? ? ? ? ? ? ? ? = ? ? ? ? 0 1 1 0 ? ? ? ? .<label>(9)</label></formula><p>Since the output Y computed in Equation <ref type="formula" target="#formula_7">(9)</ref> is equal to the target T defined in Equation <ref type="formula" target="#formula_6">(8)</ref>, it results that Lemma 1 is true.</p><p>Our proof is intuitively explained in <ref type="figure" target="#fig_1">Figure 2</ref>. The four data points from the XOR data set are represented on a plane and the output of the neuron followed by ADA is represented on the axis perpendicular to the plane in which the XOR points reside. The output for the red points (labeled as class 0) is 0 or close to 0, while the output for the green points (labeled as class 1) is 1. Applying the rounding function ? on top of the output depicted in <ref type="figure" target="#fig_1">Figure 2</ref> is equivalent to setting a threshold equal to 0.5, labeling all points above the threshold with class 1 and all points below the threshold with class 0. This gives us the labels for the XOR logical function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 2.</head><p>There exists an artificial neuron followed by the apical dendrite activation from Equation (3) which can predict the labels for the OR logical function, by rounding its output.</p><p>Proof. We can trivially prove Corollary 2 by following the proof for Lemma 1. We just have to set ? and c to different values, e.g. ? = 0.4 and c = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 3.</head><p>There exists an artificial neuron followed by the apical dendrite activation from Equation <ref type="formula">(3)</ref> which can predict the labels for the AND logical function, by rounding its output.</p><p>Proof. We can trivially prove Corollary 3 by following the proof for Lemma 1. We just have to set the bias term to a different value, e.g. b = ?9. From Lemma 1, Corollary 2 and Corollary 3, it results that an artificial neuron followed by ADA has more computational power than a standard artificial neuron followed by sigmoid, ReLU or other commonly-used activation functions. More precisely, the ADA function enables individual artificial neurons to classify both linearly and non-linearly separable data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">PyNADA: Pyramidal Neurons with Apical Dendrite Activations</head><p>Pyramidal neurons have two types of dendrites: apical dendrites and basal dendrites. Electrical impulses are sent to the neuron through both kinds of dendrites and the impulse is passed down the axon, if an action potential occurs. Prior to Gidon et al. <ref type="bibr" target="#b0">[1]</ref>, it was thought that apical and basal dendrites had identical activation functions. This is because experiments were usually conducted on pyramidal neurons extracted from rodents. In this context, proposing an artificial pyramidal neuron would not make much sense, because its mathematical model would be identical to a standard artificial neuron. Gidon et al. <ref type="bibr" target="#b0">[1]</ref> observed that the apical dendrites of pyramidal neurons in the human cerebral cortex have a different (previously unknown) activation function, while the basal dendrites exhibit the well-known hard-limit transfer function. This observation calls for a new model of artificial pyramidal neurons. We therefore propose pyramidal neurons with apical dendrite activations (PyNADA).</p><p>Given an input data sample x ? R n , the output y ? R of a PyNADA is obtained through the following equation: where ? and c are defined as in Equation <ref type="formula">(3)</ref>, w and w are column weight vectors and b and b are bias terms. A graphical representation of PyNADA is provided in <ref type="figure" target="#fig_2">Figure 3</ref>. In the proposed model, the input x is distributed to the basal dendrites represented by the weight vector w and the bias term b , and to the apical dendrites (apical tuft) represented by the weight vector w and the bias term b . For practical reasons, we replace the hard-limit transfer function, suggested by Gidon et al. <ref type="bibr" target="#b0">[1]</ref> for the basal dendrites, with the ReLU activation. This change ensures that we can optimize the weights w and the bias b through backpropagation, i.e. we have at least some non-zero gradients. Since the intensity of electrical impulses is always positive, the biological model proposed by Gidon et al. <ref type="bibr" target="#b0">[1]</ref> is defined for positive inputs and the thresholds for the activation functions are well above 0. However, an artificial neuron can also take as input negative values, i.e. x ? R n . Hence, the thresholds of the activation functions used in PyNADA are set to 0 (but the bias terms can shift these thresholds).</p><formula xml:id="formula_8">y = ReLU (x ? w + b ) + ADA(x ? w + b , ?, c),<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corollary 4.</head><p>There exists a pyramidal neuron with apical dendrite activation, as defined in Equation <ref type="formula" target="#formula_8">(10)</ref>, which can predict the labels for the XOR logical function, by rounding its output.</p><p>Proof. We can trivially prove Corollary 4 by following the proof for Lemma 1. For the apical tuft, we can simply set </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Sets</head><p>We conduct experiments on five data sets: MOROCO <ref type="bibr" target="#b18">[19]</ref>, UTKFace <ref type="bibr" target="#b16">[17]</ref>, CREMA-D <ref type="bibr" target="#b17">[18]</ref>, Fashion-MNIST <ref type="bibr" target="#b14">[15]</ref> and Tiny ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MOROCO.</head><p>We conduct text classification experiments on MOROCO <ref type="bibr" target="#b18">[19]</ref>, a data set of 33,564 news articles that are written in Moldavian or Romanian. Each text sample has an average of 309 tokens, the total number of tokens being over 10 millions. The main task is to discriminate between the Moldavian and the Romanian dialects. The data set comes with a training set of 21,719 text samples, a validation set of 5,921 text samples and a test set of 5,924 text samples. UTKFace. UTKFace <ref type="bibr" target="#b16">[17]</ref> is a large data set of 23,708 highresolution images. The images contain faces of people of various age, gender and ethnicity. We use the unaligned cropped faces in our experiments. We randomly divide the data set into a training set of 16,595 images (70%), a validation set of 3,556 images (15%) and a test set of 3,557 images (15%). We consider two tasks on UTKFace: gender recognition (binary classification) and age estimation (regression). CREMA-D. The CREMA-D multi-modal database <ref type="bibr" target="#b17">[18]</ref> contains 7,442 videoclips of 91 actors (48 male and 43 female) with different ethnic backgrounds. The actors were asked to convey particular emotions while producing, with different intonations, 12 particular sentences that evoke the target emotions. Six labels have been used to discriminate among different emotion categories: neutral, happy, anger, disgust, fear and sad. In our experiments, we consider only the audio modality. We split the audio samples into 70% for training, 15% for validation and 15% for testing. Fashion-MNIST. Fashion-MNIST <ref type="bibr" target="#b14">[15]</ref> is a recently introduced data set that shares the same structure as the more popular MNIST <ref type="bibr" target="#b10">[11]</ref> data set, i.e. it contains 60,000 training images and 10,000 test images that belong to 10 classes of fashion items. We use a subset of 10,000 images from the training set for validation. Tiny ImageNet. We present results with longer apical dendrites on Tiny ImageNet, a subset of ImageNet <ref type="bibr" target="#b15">[16]</ref>. The data set provides 500 training images, 50 validation images and 50 test images for 200 object classes. The size of each image is 64 ? 64 pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Setup</head><p>Evaluation metrics. For the classification tasks (object recognition, gender prediction, voice emotion recognition and dialect identification), we report the classification accuracy. For the regression task (age estimation), we report the mean absolute error (MAE). Baselines. We consider several neural architectures ranging from shallow MLPs to deep CNNs: one-hidden-layer MLP, two-hidden-layer MLP, LeNet, VGG-9, ResNet-18, ResNet-50 and character-level CNNs with and without Squeezeand-Excitation (SE) blocks <ref type="bibr" target="#b29">[30]</ref>. The baseline architectures are based on ReLU, leaky ReLU, RBF or Swish. The latter two activation functions are added because they share one property with ADA, namely the capability to solve XOR when plugged into a single artificial neuron. The goal of our experiments is to study the effect of (i) replacing ReLU and leaky ReLU with ADA and leaky ADA, respectively, and (ii) replacing the standard neurons with our PyNADA. The number of weights in PyNADA is twice as high, but the size of the activation maps is the same as in standard neurons (due to summation of the two branches in PyNADA). For a fair comparison, we included three baseline pyramidal neurons: one with ReLU on both branches (PyNReLU), one with ReLU and RBF (PyNRBF) and one with ReLU and Swish (PyNSwish). All neural models are trained using the Adam optimizer <ref type="bibr" target="#b30">[31]</ref>. With the exception of ResNet-18 and ResNet-50, which are implemented in PyTorch <ref type="bibr" target="#b27">[28]</ref>, all other neural networks are implemented in TensorFlow <ref type="bibr" target="#b26">[27]</ref>. Since we employ different architectures in each task, we describe them in more details in the corresponding subsections below.</p><p>In summary, we emphasize that our experiments aim to compare models within the following three groups: (i) ReLU, RBF, Swish versus ADA; (ii) leaky ReLU versus leaky ADA; (iii) PyNReLU, PyNRBF, PyNSwish versus PyNADA and leaky PyNADA. Note that for PyNADA we consider both standard and leaky activations. In leaky PyNADA, the basal dendrites are followed by leaky ReLU and the apical dendrites are followed by leaky ADA. Significance testing is performed within each group, considering the above organization. We also emphasize that the compared models within a group have the same number of parameters and the same computational complexity, e.g. we do not aim to compare ReLU with PyNADA directly. Generic hyperparameter tuning. We tune the basic hyperparameters such as the learning rate, the mini-batch size and the number of epochs, for each neural architecture using grid search on the validation set of the corresponding task. We consider learning rates between 10 ?3 and 10 ?5 , mini-batches of 10, 32, 64 or 128 samples and numbers of epochs between 10 and 100. Other parameters of the Adam optimizer are used with default values. The parameter tuning is performed using the baseline architectures based on ReLU. Once tuned, the same parameters are used for leaky ReLU, RBF, Swish, ADA, leaky ADA, PyNReLU, PyNRBF, PyNSwish, PyNADA and leaky PyNADA. Hence, we emphasize that the basic parameters are tuned in favor of ReLU. The leak parameter for leaky ReLU and leaky ADA is set to l = 0.01 in all the experiments, without further tuning. We note that (leaky) ADA and (leaky) PyNADA have two additional hyperparameters that require tuning on validation. For the constant c, we consider two possible values, either 0 or 1. For the parameter ?, we consider two options: (a) perform grid search in the range [0.1, 1] using a step of 0.1, or (b) learn ? using gradient descent during training. As recommended in <ref type="bibr" target="#b9">[10]</ref>, we used a learnable ? in Swish.</p><p>To avoid accuracy variations due to weight initialization or stochastic training, we trained each neural model in five consecutive trials, keeping the model with the highest validation performance. In the experiments, we report the performance level of the selected neural models on the heldout test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results on MOROCO</head><p>Neural architectures. For dialect identification, we consider the character-level CNN models presented in <ref type="bibr" target="#b18">[19]</ref>, which follow closely the model of Zhang et al. <ref type="bibr" target="#b13">[14]</ref>. The two CNNs share the same architecture, being composed of an embedding layer, followed by three convolutional and maxpooling blocks, two fully-connected layers with dropout 0.5 and the final softmax classification layer. The second architecture incorporates an attention mechanism in the form of Squeeze-and-Excitation (SE) blocks <ref type="bibr" target="#b29">[30]</ref> inserted after every convolutional layer. For the SE blocks, we set the reduction ratio to 64. For both architectures, we keep the same size for the embedding (256) and the same number of convolutional filters (128) as Butnaru et al. <ref type="bibr" target="#b18">[19]</ref>. In fact, our baseline architectures (CNN and CNN+SE) are identical to those of Butnaru et al. <ref type="bibr" target="#b18">[19]</ref>. Since ADA needs to compute the exponential function, it is more computational intensive than ReLU. Moreover, PyNADA has twice more weights than a standard neuron. Hence, in addition to the accuracy rates, we hereby report the training time (in seconds per epoch) in <ref type="table" target="#tab_1">Table 1</ref>.</p><p>With respect to (leaky) ReLU, it seems that (leaky) ADA requires 5 to 7 additional seconds per epoch, which means that the training times increases by 15% or 20%. The other activation functions that include the exponential function, e.g. RBF and Swish, have the same disadvantage as ADA. Meanwhile, (leaky) PyNADA seems to need about 25 to 30 extra seconds compared to (leaky) ReLU, increasing the training time by 60% to 100%. We thus conclude that the accuracy improvements brought by (leaky) ADA and (leaky) PyNADA come with a non-negligible computational cost with respect to ReLU or leaky ReLU. In the same time, RBF and Swish are slower than ReLU, while also attaining inferior accuracy levels.</p><p>As the time measurements are consistent across all benchmarks, we refrain from reporting and commenting on the running times in the subsequent experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results on UTKFace</head><p>Neural architecture. For gender prediction and age estimation, we employ the ResNet-50 architecture <ref type="bibr" target="#b12">[13]</ref>. Residual networks use batch normalization and skip connections to propagate information over convolutional layers, avoiding the vanishing or exploding gradient problem. This enables effective training of very deep models such as ResNet-50, which is formed of 50 layers. Specific hyperparameter tuning. All ResNet-50 variants are trained on mini-batches of 10 samples using a learning rate 2: Gender prediction accuracy rates (in %) and age estimation MAEs for ResNet-50 on UTKFace. Results are reported with various activations (ReLU, leaky ReLU, RBF, Swish, ADA, leaky ADA) and artificial neurons (standard, PyNReLU, PyNRBF, PyNSwish and PyNADA). Results that are significantly better than corresponding baselines, according to a paired McNemar's test <ref type="bibr" target="#b31">[32]</ref>, are marked with ? for the significance level 0.01. Best model within each group is highlighted in bold.</p><p>of 10 ?4 . The models are trained for 15 epochs on the gender prediction task, and for 100 epochs on the age estimation task. For (leaky) ADA and (leaky) PyNADA, we either validate or learn the parameter ?, in the same time, setting the parameter c = 0.</p><p>Results. We present the gender prediction and age estimation results in <ref type="table">Table 2</ref>. In the gender prediction task, we notice that ADA yields slightly lower results than ReLU, while leaky ADA attains slightly better results than leaky ReLU. Both RBF and Swish provide lower results than ReLU and ADA. Nevertheless, we observe significant improvements with PyNADA over PyNReLU. Our highest absolute gain (3.15%) in the gender prediction task is obtained when ResNet-50 is equipped with PyNADA (91.65%) instead of the baseline PyNReLU on both branches (88.50%). In the age estimation task, we notice that all versions of (leaky) ADA and (leaky) PyNADA surpass the corresponding baselines by significant margins. With an MAE of 5.74 on the test set, our PyNADA attains the best results in age estimation. With respect to the PyNReLU baseline, PyNADA reduces the average error by 1.61 years and the difference is statistically significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Results on CREMA-D</head><p>Neural architecture. For speech emotion recognition, we employ the ResNet-18 architecture <ref type="bibr" target="#b12">[13]</ref>. We modified the number of input channels of ResNet-18 from 3 to 2, in order to feed the network with the Short Time Fourier Transform of the raw audio signals, where the real and the imaginary parts are considered as separate input channels. 4: Object class recognition accuracy rates (in %) for four neural models (one-hidden-layer MLP, two-hidden-layer MLP, LeNet, VGG-9) on Fashion-MNIST. Results are reported with various activations (ReLU, leaky ReLU, RBF, Swish, ADA, leaky ADA) and artificial neurons (standard, PyNReLU, PyNRBF, PyNSwish and PyNADA). Results that are significantly better than corresponding baselines, according to a paired McNemar's test <ref type="bibr" target="#b31">[32]</ref>, are marked with ? or ? for the significance levels 0.05 or 0.01, respectively. As reference, the results with one-hidden-layer and two-hidden-layer MLPs reported by Xiao et al. <ref type="bibr" target="#b14">[15]</ref> are also included. Best model within each group is highlighted in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Activation Parameter Test Accuracy one-hidden-layer MLP <ref type="bibr" target="#b14">[15]</ref> ReLU -87.10 one-hidden-layer MLP <ref type="bibr" target="#b14">[15]</ref> tanh Results. We present the speech emotion recognition results in <ref type="table">Table 3</ref>. We observe that ADA and leaky ADA attain superior results compared with the other activation functions, when conventional neurons are employed in ResNet-18. The RBF activation function offers significantly lower results with respect to the most commonly-used activation function, ReLU, while the Swish function fails to converge for both standard and pyramidal neurons. We generally observe that the ResNet-18 based on pyramidal neurons outperforms the ResNet-18 based on conventional neurons, regardless of the activation function. This highlights the effectiveness of the pyramidal design. Our highest absolute gain (2.24%) is obtained for leaky ADA in comparison with leaky ReLU. Moreover, the performance gains brought by (leaky) ADA and (leaky) PyNADA are statistically significant with respect to the corresponding baselines. We notice that our accuracy rates for the audio modality on CREMA-D surpass the stateof-the-art accuracy levels reported in <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>. Given that we report significant improvements over baselines that are already superior to the state of the art, we consider that our results on CREMA-D are remarkable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Results on Fashion-MNIST</head><p>Neural architectures. For the Fashion-MNIST data set, we consider two MLPs and two CNNs (LeNet, VGG-9). We kept the same design choices as in the original paper <ref type="bibr" target="#b11">[12]</ref> for VGG-9, but for LeNet <ref type="bibr" target="#b10">[11]</ref>, we replaced the averagepooling layer with max-pooling. The first MLP architecture (MLP-1) is composed of one hidden layer with 100 units and one output layer with 10 units (the number of classes). The second MLP has two hidden layers with 100 units and 10 units, respectively, followed by the output layer with another 10 units. The considered MLP architectures are similar to those attaining better results among the MLP architectures evaluated by Xiao et al. <ref type="bibr" target="#b14">[15]</ref>. Specific hyperparameter tuning. We trained LeNet for 30 epochs, using a learning rate of 10 ?3 for the first 15 epochs and 10 ?4 for the last 15 epochs. We trained MLP-1 and MLP-2 in the same manner as LeNet. However, VGG-9 was trained for 100 epochs, starting with a learning rate of 10 ?4 in the first 50 epochs, decreasing it to 10 ?5 in the last 50 epochs. We trained all models on mini-batches of 64 images. In all the experiments with (leaky) ADA or (leaky) PyNADA, we either validated or learned ? and we set the parameter c = 0. Results. We present the Fashion-MNIST results with various neural architectures and activation functions in <ref type="table">Table 4</ref>. Our baseline MLP architectures obtain better accuracy rates than those of Xiao et al. <ref type="bibr" target="#b14">[15]</ref>, e.g. the difference obtained for MLP-1 with ReLU is 1.78% (we report 88.88%, while Xiao et al. <ref type="bibr" target="#b14">[15]</ref> report 87.10%). We notice that leaky ReLU obtains slightly lower accuracy rates than ReLU, the only exception being the result with LeNet. Nonetheless, for both MLP and CNN architectures, the accuracy of ADA on the test set is superior (by up to 0.5%) compared to the accuracy of ReLU. We obtain statistically significant improvements for the replacement of ReLU with ADA, from 90.84% to 91.34% using LeNet and from 93.39% to 93.84% using VGG-9, respectively. Interestingly, we also noticed that the value of the cross-entropy loss is always lower (on both validation and test sets) when we use ADA instead of ReLU. We observe that RBF converges only for small networks (MLP-1, MLP-2 or LeNet). When it converges, the results are below the ReLU and leaky ReLU baselines. For VGG-9, the accuracy of RBF is equal to the random choice baseline. Swish attains better results than ReLU for MLP-1 and MLP-2, but below ADA and leaky ADA. For LeNet and VGG-9, Swish surpasses only RBF (all other activation functions are better). When we employ our PyNADA, the accuracy rates improve for all the architectures. The largest improvement of leaky PyNADA on the test set (with respect to the baseline PyNReLU) is 0.73%, obtained with LeNet. The reported difference is statistically significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Results on Tiny ImageNet</head><p>We note that, in order to follow exactly the connectivity of pyramidal neurons, the apical dendrites should be longer, i.e. not connected to neurons in the immediately preceding layer i?1, but to neurons in layers i?2, i?3 or perhaps even further apart. With this design change, the apical dendrites will act as a kind of skip-connections. We hereby show some results in this direction, although this aspect can be studied considering various architecture configurations in future work. Our goal is to prove that the biological design of pyramidal neurons is viable for artificial neural networks as well. Neural architecture. For object recognition on Tiny Im-ageNet, we consider a ResNet-18 architecture <ref type="bibr" target="#b12">[13]</ref> without standard skip-connections. Instead of standard skipconnections, we use PyNADA with longer apical dendrites, closely modeling the biological pyramidal neurons. Using longer apical dendrites introduces new parameters (e.g., where to connect the apical dendrites) and constraints (the pyramidal design does not apply to every network architecture). The ResNet-18 model allows us to connect the apical dendrites to layer i ? 3 instead of the immediately preceding layer i?1. As a first baseline for this experiment, we use PyNReLU with equally-long apical dendrites, but with ReLU instead of ADA for the apical tuft. The ResNet-18 with PyNReLU is similar to ResNet-18 with standard skipconnections, the difference being that the skip-connections have learnable weights and ReLU activations. We additionally consider two more baselines with similar design: PyNRBF and PyNSwish. Specific hyperparameter tuning. The ResNet-18 models with PyNReLU, PyNRBF, PyNSwish and PyNADA are each trained for 120 epochs using a learning rate of 10 ?3 and minibatches of 200 samples. For PyNADA, we obtain optimal results with c = 0 and ? = 0.1 (obtained through validation). For Swish, the parameter ? is learnable. Results. We present the object recognition results on Tiny ImageNet in <ref type="table" target="#tab_5">Table 5</ref>. First of all, we note that, without pretraining on ImageNet, the accuracy rates on Tiny ImageNet reported in literature are typically around 50% or 60%. The baseline PyNReLU attains an accuracy of 51.54%. PyNADA brings a statistically significant improvement of 2.32% over the baseline. The accuracy rates reached by PyNRBF and PyNSwish are between the accuracy rates of PyNReLU and PyNADA. This experiment shows that it is useful to consider longer apical dendrites in conjunction with ADA, as observed in biology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION AND FUTURE WORK</head><p>In this paper, we proposed a biologically-inspired activation function and a new model of artificial neuron. The novel apical dendrite activation function (i) enables individual artificial neurons to solve non-linearly separable problems such as the XOR logical function and (ii) brings significant performance improvements for a broad range of neural architectures and tasks. Indeed, we observed consistent performance improvements over the most popular activation function, ReLU, across five benchmark data sets. The proposed ADA also outperformed other activations, RBF and Swish, that enable individual artificial neurons to solve XOR. Even though RBF and Swish share the capability of solving XOR with ADA, the accuracy rates of RBF and Swish across the five evaluation benchmarks are inconsistent, in some cases even failing to converge. Our pyramidal neural design is another way to further boost the performance. Importantly, we observed the largest performance improvements when we used ADA instead of ReLU, RBF or Swish for the apical tuft of the pyramidal neurons. In conclusion, we believe that the biologically-inspired ADA and PyNADA are useful additions to set of deep learning tools. We will release our code as open source subject to a favorable decision. Future work. Our research also opens a few directions for future research. Since the activation damps along the positive side of the domain, we believe it is worth investigating if ADA is more robust to out-of-distribution or adversarial examples. As the gradient saturates on the positive side, other directions of study are to inject noise into ADA to avoid saturation <ref type="bibr" target="#b34">[35]</ref> or to employ alternative optimization methods (that do not rely on gradients) in conjunction with ADA.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Original<ref type="bibr" target="#b0">[1]</ref> and proposed versions of the apical dendrite activation. The input corresponds to the horizontal axis and the output to the vertical axis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>The output of a neuron with apical dendrite activation, as defined in Equation(5), able to classify the XOR logical function. The output is obtained by setting the weights to w = 5 5 , the bias term to b = ?4 and the parameters of the ADA function to ? = 1 and c = 1. Large output values (closer to 1) correspond to the green data points labeled as class 1, while low output values (closer to 0) correspond to the red data points labeled as class 0. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>A pyramidal neuron with apical dendrite activations (PyNADA). The input x goes through the basal dendrites followed by ReLU and through the apical tuft followed by ADA. The results are summed up and passed through the axon. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>w = 5 5 ,</head><label>5</label><figDesc>b = ?4, ? = 1 and c = 1 in Equation (10), just as in the proof for Lemma 1. The demonstration results immediately when we simply drop out the basal dendrites by setting w = 0 0 and b = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>et al. [2], ? M.I. Georgescu and R.T. Ionescu are with SecurifAI and the Department of Computer Science, University of Bucharest, Romania. R.T. Ionescu is also affiliated with the Romanian Young Academy. E-mail: raducu.ionescu@gmail.com ? N.C. Ristea is with the Department of Telecommunications, University Politehnica of Bucharest, Romania.</figDesc><table /><note>? N. Sebe is with the Department of Information Engineering and Computer Science, University of Trento, Italy. Manuscript received April 19, 2005; revised August 26, 2015.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1 :.</head><label>1</label><figDesc>Dialect identification accuracy rates (in %) for two character-level neural models (CNN and CNN+SE) on MOROCO. Results are reported with various activations (ReLU, leaky ReLU, RBF, Swish, ADA, leaky ADA) and artificial neurons (standard, PyNReLU, PyNRBF, PyNSwish and PyNADA). Results that are significantly better than corresponding baselines, according to a paired McNemar's test<ref type="bibr" target="#b31">[32]</ref>, are marked with ? or ? for the significance levels 0.05 or 0.01, respectively. Training times are measured on a computer with Nvidia GeForce GTX 1080 GPU with 11GB of RAM. Best model within each group is highlighted in bold. Since Butnaru et al.<ref type="bibr" target="#b18">[19]</ref> already tuned the hyperparameters of the character-level CNNs on the MOROCO validation set, we decided to use the same parameters and skip the grid search. Hence, we set the learning rate to 5 ? 10 ?4 and use mini-batches of 128 samples. Each CNN is trained for 50 epochs in 5 trials, keeping the model with highest validation accuracy for evaluation on test. For (leaky) ADA and (leaky) PyNADA, we obtain optimal results with c = 1, while ? is either validated or optimized during training. We present the dialect identification results on MOROCO inTable 1. First, we observe the baseline CNN and CNN+SE models confirm the results reported by Butnaru et al.<ref type="bibr" target="#b18">[19]</ref>. For the character-level CNN (without SE blocks), we obtain the largest improvement on the test set when we replace ReLU (92.79%) with ADA (93.68%). Furthermore, the improvements of leaky ADA, PyNADA and leaky PyNADA are all higher than 0.6%, and the differences are statistically significant. The results are somewhat consistent among the two architectures, CNN and CNN+SE. For example, for the CNN+SE model, we report the largest improvement by replacing ReLU (92.99%) with ADA (93.99%), just as for the CNN without SE blocks. Our highest absolute gain on MOROCO is 1%. Overall, the results indicate that all variants of (leaky) ADA and (leaky) PyNADA attain significantly better results than the corresponding baselines. We observe</figDesc><table><row><cell>Model</cell><cell>Activation</cell><cell>Parameter</cell><cell cols="2">Test Accuracy Epoch Time (s)</cell></row><row><cell>CNN [19]</cell><cell>ReLU</cell><cell>-</cell><cell>92.79</cell><cell>27</cell></row><row><cell>CNN</cell><cell>RBF</cell><cell>-</cell><cell>54.10</cell><cell>34</cell></row><row><cell>CNN</cell><cell>Swish</cell><cell>? =learnable</cell><cell>86.96</cell><cell>33</cell></row><row><cell>CNN</cell><cell>ADA</cell><cell>? =learnable</cell><cell>93.68  ?</cell><cell>33</cell></row><row><cell>CNN</cell><cell>leaky ReLU</cell><cell>-</cell><cell>92.90</cell><cell>30</cell></row><row><cell>CNN</cell><cell>leaky ADA</cell><cell>? = 0.4</cell><cell>93.55  ?</cell><cell>37</cell></row><row><cell>CNN+PyNReLU</cell><cell>ReLU, ReLU</cell><cell>-</cell><cell>92.79</cell><cell>52</cell></row><row><cell>CNN+PyNRBF</cell><cell>ReLU, RBF</cell><cell>-</cell><cell>86.44</cell><cell>58</cell></row><row><cell>CNN+PyNSwish</cell><cell>ReLU, Swish</cell><cell>? =learnable</cell><cell>91.20</cell><cell>55</cell></row><row><cell>CNN+PyNADA</cell><cell>ReLU, ADA</cell><cell>? =learnable</cell><cell>93.61  ?</cell><cell>52</cell></row><row><cell>CNN+PyNADA</cell><cell cols="2">leaky ReLU, leaky ADA ? =learnable</cell><cell>93.53  ?</cell><cell>57</cell></row><row><cell>CNN+SE [19]</cell><cell>ReLU</cell><cell>-</cell><cell>92.99</cell><cell>42</cell></row><row><cell>CNN+SE</cell><cell>RBF</cell><cell>-</cell><cell>54.10</cell><cell>48</cell></row><row><cell>CNN+SE</cell><cell>Swish</cell><cell>? =learnable</cell><cell>87.99</cell><cell>47</cell></row><row><cell>CNN+SE</cell><cell>ADA</cell><cell>? =learnable</cell><cell>93.99  ?</cell><cell>47</cell></row><row><cell>CNN+SE</cell><cell>leaky ReLU</cell><cell>-</cell><cell>93.06</cell><cell>45</cell></row><row><cell>CNN+SE</cell><cell>leaky ADA</cell><cell>? =learnable</cell><cell>93.49  ?</cell><cell>51</cell></row><row><cell>CNN+SE+PyNReLU</cell><cell>ReLU, ReLU</cell><cell>-</cell><cell>92.97</cell><cell>52</cell></row><row><cell>CNN+SE+PyNRBF</cell><cell>ReLU, RBF</cell><cell>-</cell><cell>86.23</cell><cell>65</cell></row><row><cell cols="2">CNN+SE+PyNSwish ReLU, Swish</cell><cell>? =learnable</cell><cell>91.39</cell><cell>61</cell></row><row><cell>CNN+SE+PyNADA</cell><cell>ReLU, ADA</cell><cell>? = 0.5</cell><cell>93.72  ?</cell><cell>63</cell></row><row><cell>CNN+SE+PyNADA</cell><cell cols="2">leaky ReLU, leaky ADA ? =learnable</cell><cell>93.61  ?</cell><cell>60</cell></row><row><cell>Specific hyperparameter tuning. Results</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>that neither character-level CNN model is able to converge using RBF as activation. For RBF, we reported the test accuracy corresponding to the last model before the gradients explode. Interestingly, PyNRBF is able to converge, probably due to the basal tuft based on ReLU, but its performance level is not adequate. The networks converge with Swish and PyNSwish, but the corresponding results are much lower than those with (leaky) ReLU or (leaky) ADA. Running times.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 5 :</head><label>5</label><figDesc>Object class recognition accuracy rates (in %) for ResNet-18 on Tiny ImageNet. Results are reported with two artificial neurons, PyNReLU and PyNADA, respectively. Results significantly better than the baseline, according to a paired McNemar's test<ref type="bibr" target="#b31">[32]</ref>, are marked with ? for the significance level 0.01. Best model is highlighted in bold.</figDesc><table><row><cell>Model</cell><cell>Activation</cell><cell>Parameter</cell><cell>Test Accuracy</cell></row><row><cell cols="2">ResNet-18+PyNReLU ReLU, ReLU</cell><cell>-</cell><cell>51.54</cell></row><row><cell>ResNet-18+PyNRBF</cell><cell>ReLU, RBF</cell><cell>-</cell><cell>51.99</cell></row><row><cell cols="3">ResNet-18+PyNSwish ReLU, Swish ? =learnable</cell><cell>52.93</cell></row><row><cell>ResNet-18+PyNADA</cell><cell>ReLU, ADA</cell><cell>? = 0.1</cell><cell>53.86  ?</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by a grant of the Romanian Ministry of Education and Research, CNCS -UEFISCDI, project number PN-III-P1-1.1-TE-2019-0235, within PNCDI III. The article has also benefited from the support of the Romanian Young Academy, which is funded by Stiftung Mercator and the Alexander von Humboldt Foundation for the period 2020-2022.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dendritic action potentials and computation in human layer 2/3 cortical neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Zolnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fidzinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bolduan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Papoutsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Poirazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Holtkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Larkum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="issue">6473</biblScope>
			<biblScope unit="page" from="83" to="87" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Lure of the Unknown</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Knutson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="280" to="282" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Detecting anomalous events in videos by learning deep representations of appearance and motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page" from="117" to="127" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep appearance and motion learning for egocentric activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">275</biblScope>
			<biblScope unit="page" from="438" to="447" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The Perceptron: a probabilistic model for information storage and organization in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rosenblatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">386</biblScope>
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Perceptrons: An introduction to computational geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Papert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rectified Linear Units Improve Restricted Boltzmann Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of WDLASL</title>
		<meeting>WDLASL</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Searching for Activation Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR Workshops</title>
		<meeting>ICLR Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="649" to="657" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<title level="m">Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Age Progression/Regression by Conditional Adversarial Autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5810" to="5818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">CREMA-D: Crowd-sourced emotional multimodal actors dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Keutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nenkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Verma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="377" to="390" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">MOROCO: The Moldavian and Romanian Dialectal Corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Butnaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ionescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="688" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On the Impact of the Activation function on Deep Neural Networks Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hayou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rousseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-A</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Maxout Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1319" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">An Adaptive &apos;Adaline&apos; Neuron Using Chemical &apos;Memistors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Widrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stanford Electronics Laboratories, Tech. Rep</title>
		<imprint>
			<biblScope unit="page" from="1553" to="1555" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Towards deep learning with segregated dendrites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guerguiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Richards</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">22901</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">eLife</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Why Neurons Have Thousands of Synapses, a Theory of Sequence Memory in Neocortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahmad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neural Circuits</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">TensorFlow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of OSDI</title>
		<meeting>OSDI</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-Performance Deep Learning Library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NeurIPS</title>
		<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="issue">6088</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Squeeze-and-Excitation Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1895" to="1923" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Visually guided self-supervised learning of speech representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vougioukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICASSP, 2020</title>
		<meeting>ICASSP, 2020</meeting>
		<imprint>
			<biblScope unit="page" from="6299" to="6303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Image2Audio: Facilitating Semisupervised Audio Emotion Recognition with Facial Expression Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CVPR Workshops</title>
		<meeting>CVPR Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="912" to="913" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Noisy Activation Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moczulski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3059" to="3068" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
