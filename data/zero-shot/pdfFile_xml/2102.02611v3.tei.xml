<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CKCONV: CONTINUOUS KERNEL CONVOLUTION FOR SEQUENTIAL DATA</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Romero</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vrije Universiteit Amsterdam</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Kuzina</surname></persName>
							<email>a.kuzina@vu.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Vrije Universiteit Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><forename type="middle">M</forename><surname>Tomczak</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vrije Universiteit Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Hoogendoorn</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Vrije Universiteit Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CKCONV: CONTINUOUS KERNEL CONVOLUTION FOR SEQUENTIAL DATA</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Conventional neural architectures for sequential data present important limitations. Recurrent neural networks suffer from exploding and vanishing gradients, small effective memory horizons, and must be trained sequentially. Convolutional neural networks cannot handle sequences of unknown size and their memory horizon must be defined a priori. In this work, we show that these problems can be solved by formulating the convolutional kernels of CNNs as continuous functions. The resulting Continuous Kernel Convolution (CKConv) handles arbitrarily long sequences in a parallel manner, within a single operation, and without relying on any form of recurrence. We show that Continuous Kernel Convolutional Networks (CK-CNNs) obtain state-of-the-art results in multiple datasets, e.g., permuted MNIST, and, thanks to their continuous nature, are able to handle non-uniformly sampled datasets and irregularly-sampled data natively. CKCNNs match or perform better than neural ODEs designed for these purposes in a faster and simpler manner.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recurrent Neural Networks (RNNs) have long governed tasks with sequential data <ref type="bibr" target="#b52">(Rumelhart et al., 1985;</ref><ref type="bibr" target="#b27">Hochreiter &amp; Schmidhuber, 1997;</ref><ref type="bibr" target="#b10">Chung et al., 2014)</ref>. Their main ingredient are recurrent units: network components with a recurrence formulation which grants RNNs the ability to be unrolled for arbitrarily many steps and handle sequences of arbitrary size. In practice, however, the effective memory horizon of RNNs, i.e., the number of steps the network retains information from, has proven to be surprisingly small, most notably due to the vanishing gradients problem <ref type="bibr" target="#b26">(Hochreiter, 1991;</ref><ref type="bibr" target="#b6">Bengio et al., 1994)</ref>. Interstingly, it is the very recurrent nature of RNNs that allows them to be unrolled for arbitrarily many steps which is responsible for vanishing gradients <ref type="bibr" target="#b45">(Pascanu et al., 2013b)</ref>. This, in turn, hinders learning from the far past and induces a small effective memory horizon.</p><p>Convolutional Neural Networks (CNNs) <ref type="bibr" target="#b34">(LeCun et al., 1998)</ref> have proven a strong alternative to recurrent architectures as long as relevant input dependencies fall within their memory horizon, e.g., <ref type="bibr" target="#b11">Conneau et al. (2016)</ref>; <ref type="bibr" target="#b42">Oord et al. (2016)</ref>; <ref type="bibr" target="#b12">Dai et al. (2017)</ref>; <ref type="bibr" target="#b14">Dauphin et al. (2017)</ref>; <ref type="bibr" target="#b3">Bai et al. (2018a)</ref>. CNNs avoid the training instability and vanishing / exploding gradients characteristic of RNNs by avoiding back-propagation through time <ref type="bibr" target="#b65">(Werbos, 1990)</ref> altogether. However, these architectures model convolutional kernels as a sequence of independent weights. As a result, their memory horizon must be defined a-priori, and larger memory horizons induce a proportional growth of the model size.</p><p>In this work, we provide a solution to these limitations. We propose to view a convolutional kernel as a continuous function parameterized by a small neural network instead of a sequence of independent weights. The resulting Continuous Kernel Convolution (CKConv) enjoys the following properties:</p><p>? CKConvs can define arbitrarily large memory horizons within a single operation. Consequently, Continuous Kernel Convolutional Neural Networks (CKCNNs) detach their memory horizon from (i) the depth of the network, (ii) the dilation factors used, and (iii) the size of the network.</p><p>? CKConvs do not rely on any form of recurrence. As a result, CKCNNs (i) can be trained in parallel, and (ii) do not suffer from vanishing / exploding gradients or small effective memory horizons.</p><p>? Continuous convolutional kernels can be evaluated at arbitrary positions. Consequently, CKConvs and CKCNNs can be readily used on irregularly sampled data, and data at different resolutions. MLP ? receives a time-step and outputs the value of the convolutional kernel at that position. We sample convolutional kernels by passing a set of relative positions {?? i } to MLP ? , and perform convolution with the sampled kernel next. Since MLP ? is a continuous function, CKConvs can (i) construct arbitrarily large kernels, (ii) generate kernels at different resolutions, and (iii) handle irregular data.</p><p>We observe that continuous kernel parameterizations previously used to handle irregular data locally, e.g., <ref type="bibr" target="#b54">Sch?tt et al. (2017)</ref>; <ref type="bibr" target="#b66">Wu et al. (2019)</ref>, are not adequate to model long-term dependencies. This is due to the inability of their kernels to model long spatial complex functions (Sec. 4.2). Contrarily, CKConvs perfectly describe long complex non-linear, non-smooth functions by parameterizing their kernels as SIRENs <ref type="bibr" target="#b59">(Sitzmann et al., 2020)</ref>: implicit neural representations with Sine nonlinearities. Shallow CKCNNs match or outperform state-of-the-art approaches on several tasks comprising stress tests, continuous, discrete and irregular data, as well as resolution changes. To the best of our knowledge, we are first to observe the potential of continuous convolutional kernels to model long-term dependencies, and to provide an useful parameterization to this end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Continuous kernel formulation. Continuous formulations for convolutional kernels were introduced to handle irregularly sampled 3D data locally <ref type="bibr" target="#b54">(Sch?tt et al., 2017;</ref><ref type="bibr" target="#b58">Simonovsky &amp; Komodakis, 2017;</ref><ref type="bibr" target="#b63">Wang et al., 2018;</ref><ref type="bibr" target="#b66">Wu et al., 2019)</ref>. As discrete convolutions learn independent weights for specific relative positions, they cannot handle irregularly sampled data effectively. Following work focuses on point-cloud applications <ref type="bibr" target="#b20">(Fuchs et al., 2020;</ref><ref type="bibr" target="#b28">Hu et al., 2020;</ref><ref type="bibr" target="#b57">Shi et al., 2019;</ref><ref type="bibr" target="#b61">Thomas et al., 2018)</ref>. Other approaches include Monte Carlo approximations of continuous operations <ref type="bibr" target="#b18">(Finzi et al., 2020)</ref>. Our work proposes a new broad flavor of applications for which continuous kernels are advantageous.</p><p>Implicit neural representations. Implicit neural representations construct continuous data representations by encoding the input in the weights of a neural network <ref type="bibr" target="#b38">(Mescheder et al., 2019;</ref><ref type="bibr" target="#b43">Park et al., 2019;</ref><ref type="bibr" target="#b59">Sitzmann et al., 2020)</ref>. This leads to numerous advantages over conventional (discrete) data representations, e.g., memory efficiency, analytic differentiability, with interesting properties for several applications, e.g., generative modelling <ref type="bibr" target="#b17">(Dupont et al., 2021;</ref><ref type="bibr" target="#b55">Schwarz et al., 2020</ref>).</p><p>Since we model convolutional kernels as continuous functions and parameterize them via neural networks, our approach can be understood as implicitly representing the convolutional kernels of a conventional CNN. Different is the fact that these convolutional kernels are not known a-priori, but learned as a part of the optimization task of the CNN. Making the connection between implicit neural representations and continuous kernel formulations explicitly brings substantial insights for the construction of these kernels. In particular, it motivates the use of Sine nonlinearities <ref type="bibr" target="#b59">(Sitzmann et al., 2020)</ref> to parameterize them, which leads to significant improvements over the ReLU, LeakyReLU, and Swish nonlinearities used so far for this purpose (Sec. 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THE CONVOLUTION AND COMMON KERNEL PARAMETERIZATIONS</head><p>Notation.</p><p>[n] denotes the set {0, 1, . . . , n}. Bold capital and lowercase letters depict vectors and matrices, e.g., x, W, sub-indices index vectors, e.g., x={x c } N in c=1 , parentheses index time, e.g., x(? ) is the value of x at time-step ? , and calligraphic letters depict sequences, e.g., X={x(? )} N X ? =0 . Centered and causal convolutions. Let x ? R ? R N in and ? ? R ? R N in be a vector valued signal and kernel on R, such that x={x c } N in c=1 and ?={? c } N in c=1 . The convolution is defined as: <ref type="figure">Figure 2</ref>: Discrete centered, causal, and dilated causal convolutions.</p><formula xml:id="formula_0">(x * ?)(t) = N in c=1 R x c (? )? c (t ? ? ) d?.<label>(1)</label></formula><formula xml:id="formula_1">(a) (b) (c)</formula><p>In practice, the input signal x is gathered via some sampling procedure. Resultantly, the convolution is effectively performed between the sampled input signal described as a sequence of finite length X={x(? )} N X ? =0 and a convolutional kernel K={?(? )} N X ? =0 described the same way:</p><formula xml:id="formula_2">(x * ?)(t) = N in c=1 N X 2 ? =? N X 2 x c (? )? c (t ? ? ).<label>(2)</label></formula><p>Values x(? ) falling outside of X are padded by a constant value often defined as zero ( <ref type="figure">Fig. 2a</ref>).</p><p>The convolutional kernel is commonly centered around the point of calculation t. For sequence modeling this can be undesirable as future input values {x(t ? ? )} ?1 ? = ?N X 2 are considered during the operation. This is solved by providing a causal formulation to the convolution: a formulation in which the convolution at time-step t only depends on input values at time-steps (t ? ? ) ? t ( <ref type="figure">Fig. 2b)</ref>:</p><formula xml:id="formula_3">(x * ?)(t) = N in c=1 t ? =0 x c (? )? c (t ? ? ).<label>(3)</label></formula><p>In practice, causal convolutions are easily implemented via asymmetrical padding. In this work, we consider causal convolutions as default. Nevertheless, our analyses are also valid for centered ones.</p><p>Discrete convolutional kernels. By a large margin, most convolutional kernels ? in literature are parameterized as a finite sequence of N K + 1 independent learnable weights K={?(? )} N K ? =0 <ref type="figure">(Fig. 2</ref>). As these weights are independent of one another, N K must be kept small to keep the parameter count of the model tractable. Hence, the kernel size is often much smaller than the input length: N K ? N X . This parameterization presents important limitations:</p><p>? The memory horizon N K must be defined a priori.</p><p>? Since N K ? N X , this parameterization implicitly assumes that the convolution (x * ?) at position t only depends on input values at positions up to ? =N K steps in the past. Consequently, no functions depending on inputs x(t ? ? ) for ? &gt; N K can be modeled.</p><p>? The most general selection of N K is given by a global memory horizon: N K =N X . Unfortunately, as discrete convolutional kernels are modeled as a sequence of independent weights, this incurs an extreme growth of the model size and rapidly becomes statistically unfeasible.</p><p>Dilated convolutional kernels. To alleviate these limitations, previous works propose to interleave kernel weights with zeros in order to cover larger memory horizons without additional weights ( <ref type="figure">Fig. 2c</ref>). This formulation alleviates some of the previous limitations, but introduces additional ones:</p><p>? Dilated kernels are unable to model dependencies of input values falling in the interleaved regions.</p><p>? Several authors use dilated convolutions with varying dilation factors as a function of depth, e.g., <ref type="bibr" target="#b3">(Bai et al., 2018a;</ref><ref type="bibr" target="#b12">Dai et al., 2017;</ref><ref type="bibr" target="#b42">Oord et al., 2016;</ref>. By carefully selecting layer-wise dilation factors, one can assure that some kernel hits each input within the memory horizon of the network. However, due to the extreme sparsity of the formulation, it is difficult to estimate the effective amount of processing applied to the input. In addition, this layout ties together (i) the memory horizon, (ii) the depth, and (iii) the layer-wise dilation factors of the network, which effectively constraints the flexibility of the neural architecture design.</p><p>In contrast to the (dilated) discrete convolutions presented in this section, our proposed formulation allows handling arbitrarily long sequences with arbitrarily large, dense memory horizons in a single layer and under a fixed parameter budget. eigenvalues of W, ??1, recurrent units are restricted to exponentially decreasing (??1) or increasing (??1) functions <ref type="bibr">(Figs. 3a,</ref><ref type="bibr">3b)</ref>. Discrete convolutions can describe arbitrary functions within their memory horizon but are zero otherwise <ref type="figure" target="#fig_1">(Fig. 3c</ref>). Conversely, CKConvs define arbitrary long memory horizons, and thus are able to describe arbitrary functions upon the entire input sequence <ref type="figure" target="#fig_1">(Fig. 3d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">CONTINUOUS KERNEL CONVOLUTION</head><p>In this section, we introduce our approach. First, we define it formally, analyze its properties, illustrate its connection to recurrent units, and elaborate on the functional family they can describe. Next, we discuss concrete parameterizations of continuous convolutional kernels, illustrate their connection to implicit neural representations, and show that our final kernels are able to fit complex functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">FORMULATION AND PROPERTIES</head><p>Arbitrarily large convolutional kernels. We formulate the convolutional kernel ? as a continuous vector-valued function parameterized by a small neural network MLP ? ? R ? R Nout?N in <ref type="figure" target="#fig_0">(Fig. 1, left)</ref>. MLP ? receives a relative position (t?? ) and outputs the value of the convolutional kernel at that position ?(t?? ). As a result, an arbitrarily large convolutional kernel K={?(t?? )} N K ? =0 can be constructed by providing an equally large sequence of relative positions {t?? } N K ? =0 to MLP ? . For N K =N X , the size of the resulting kernel is equal to that of the input sequence X, and thus it is able to model (global) long-term dependencies. The Continuous Kernel Convolution (CKConv) is given by:</p><formula xml:id="formula_4">(x * ?)(t) = N in c=1 t ? =0 x c (? )MLP ? c (t ? ? ).<label>(4)</label></formula><p>Irregularly sampled data. CKConvs are able to handle irregularly-sampled and partially observed data. To this end, it is sufficient to sample MLP ? at positions for which the input signal is known and perform the convolution operation with the sampled kernel. For very non-uniformly sampled inputs, an inverse density function over the samples can be incorporated in order to provide an unbiased estimation of the convolution response (see Appx. A.1, <ref type="bibr" target="#b66">Wu et al. (2019)</ref> for details).</p><p>Data at different resolutions. CKConvs can also process data at different resolutions. Consider the convolution (x * ?) sr1 between an input signal x and a continuous convolutional kernel ? sampled at a sampling rate sr 1 . Now, if the convolution receives the same input signal sampled at a different sampling rate sr 2 , it is sufficient to sample the convolutional kernel at the sampling rate sr 2 in order to perform an "equivalent" operation: (x * ?) sr2 . As shown in Appx. A.2, it holds that:</p><formula xml:id="formula_5">(x * ?) sr2 (t) ? sr 2 sr 1 (x * ?) sr1 (t).<label>(5)</label></formula><p>That is, convolutions calculated at different resolutions sr 1 and sr 2 are approximately equal up to a factor given by the resolution change. As a result, CKCNNs (i) can be trained in datasets with data at varying resolutions, and (ii) can be deployed at resolutions other than those seen during training.</p><p>We note that the previous features are hardly attainable by regular architectures, with an exception being RNNs with continuous-time interpretations, e.g., <ref type="bibr" target="#b23">Gu et al. (2020a)</ref>; <ref type="bibr" target="#b30">Kidger et al. (2020)</ref>.</p><p>(Linear) recurrent units are continuous kernel convolutions. Consider a recurrent unit of the form:</p><formula xml:id="formula_6">h(? ) = ?(Wh(? ? 1) + Ux(? )) (6) y(? ) = softmax(Vh(? )),<label>(7)</label></formula><p>where U, W, V depict the input-to-hidden, hidden-to-hidden and hidden-to-output connections of the unit, h(? ),?(? ) the hidden representation and the output at time-step ? , and ? a pointwise nonlinearity. As shown in Appx. A.3, we can express the hidden representation h of a linear recurrent unit, i.e., with ?=Id, as a convolution between the input x and a convolutional kernel ?(? )=W ? U of size equal to the input. That is, as a continuous kernel convolution with an exponentially increasing or decreasing kernel ( <ref type="figure" target="#fig_1">Fig. 3</ref>). Different authors show that nonlinear recurrent units are also restricted to the same functional family <ref type="bibr" target="#b45">(Pascanu et al., 2013b;</ref><ref type="bibr" target="#b0">Arjovsky et al., 2016;</ref><ref type="bibr" target="#b68">Zhao et al., 2020)</ref>.</p><p>The functional family of continuous kernel convolutions. From the previous observation, we can conclude that CKConvs are not only more general than discrete convolutions, but that the functional family they describe is also more general than that of (linear) recurrent units ( <ref type="figure" target="#fig_1">Fig. 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">THE CONTINUOUS CONVOLUTIONAL KERNEL MLP ?</head><p>Convolutional kernels as point-wise MLPs. Let {?? i =(t?? i )} N i=0 be a sequence of relative positions. The continuous vector-valued convolutional kernel ? ? R ? R Nout?N in is parameterized as a neural network MLP ? which maps each relative position ?? i to the value of the convolutional kernel at that position ( <ref type="figure" target="#fig_0">Fig. 1, left)</ref>. We refer to the nonlinearity used in MLP ? as ?.</p><p>What kind of kernels can MLP ? generate? Our method relies on the assumption that the neural network MLP ? is able to model complex dependencies densely among all elements within the memory horizon. That is, it assumes that MLP ? is able to generate arbitrary convolutional kernels.</p><p>To test this hypothesis, we fit existing MLP parameterizations, i.e., with ReLU, LeakyReLU and Swish nonlinearities, to long target functions of varying level of smoothness and non-linearity ( <ref type="figure">Fig. 5</ref>). We observe that existing parameterizations can approximate simple functions, e.g., Gaussian, step functions, but for increasing levels of non-linearity and non-smoothness, they fail by a large margin. For our analysis, this means that CKConvs with ReLU, LeakyReLU and Swish parameterizations are not able to represent complex input dependencies. In our ablation studies (Appx. D) we verify that CKCNNs with these kernels consistently perform worse than our proposed parameterization.</p><p>Convolutional kernels as implicit neural representations. We notice that parameterizing a convolutional kernel with a neural network is equivalent to constructing an implicit neural representation of the kernel, with the subtle difference that our target objective is not known a-priori, but learned as part of the optimization task of the CNN. Implicit neural representations study generic ways to represent data living in low-dimensional spaces, e.g., R 2 , via neural networks, and thus, despite this difference, constitute an interesting starting point for the parameterization of continuous convolutional kernels. In particular, recent works noticed that neural networks with piece-wise activation functions are unable to model high-frequencies. To alleviate this limitation, they introduce random Fourier features  and Sine nonlinearities <ref type="bibr" target="#b59">(Sitzmann et al., 2020)</ref>.</p><p>Based on these observations, we repeat the fitting experiment for a SIREN <ref type="bibr" target="#b59">(Sitzmann et al., 2020)</ref>: a MLP with hidden layers of the form y = Sine(? 0 [Wx + b]). That is with Sine nonlinearities, and a non-learnable value ? 0 that serves as a prior for the oscillations of the output. We observe that a SIREN quickly approximates all target functions to near perfection regardless of their grade of smoothness or nonlinearity. Even a sequence of random noise. This implies that, contrary to other parameterizations, CKConvs with SIREN kernels have the ability to model complex input dependencies across large memory horizons. Our experimental results verify this statement. Our ablation studies in Appx. D show that SIREN kernels consistently outperform all other variants. In addition, our experimental results in Sec. 5 show that shallow CKCNNs with SIREN kernels achieve state-of-the-art across datasets of different nature, i.e., with continuous and discrete data.</p><p>The success of Sine nonlinearites: A spline basis interpretation. <ref type="bibr" target="#b59">Sitzmann et al. (2020)</ref> motivates the usage of Sine nonlinearities for implicit neural representations. However, there is no clear understanding as of why Sine nonlinearities are better suited for this task than (smooth) piece-wise nonlinearities. For the interested reader, we provide an interpretation to this phenomenon from a spline function approximation perspective in Appx. B.</p><p>Of most practical relevance from this analysis is the observation that proper initialization of the network parameters, particularly of the bias term {b (l) }, is important to create a well-spread set of basis functions suited for function approximation. For SIRENs, this is achieved by initializing the bias term uniformly across the period of each of the Sine components:</p><formula xml:id="formula_7">b i ? U(?? W i,? ?1 , ? W i,? ?1 )</formula><p>. We observe that this initialization leads to better results and faster convergence for all tasks considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>We validate our approach against several existing models and across several tasks selected from the corresponding papers. Specifically, we benchmark its ability to handle long-term dependencies, data at different resolutions and irregularly-sampled data. A complete description of the datasets used as well as additional experiments and ablation studies can be found in the Appendix (Appx. C, D). 1 Network details. We parameterize our convolutional kernels as 3-layer SIRENs. Weight normalization <ref type="bibr" target="#b53">(Salimans &amp; Kingma, 2016)</ref> leads to better and faster convergence when applied to the layers in MLP, and we use it across all experiments. All our CKCNNs follow the structure shown in <ref type="figure">Fig. 8</ref> and vary only in the number of blocks and channels. We use two residual blocks for all experiments reported in this section. Specifications on the architectures and hyperparameters used are given in Appx. E. We speed up the convolution operations in our networks via the convolution theorem:</p><formula xml:id="formula_8">(f * ?)= F ?1 F{f } ? F{?} , with F the Fourier transform.</formula><p>Stress experiments. First, we validate that CKCNNs can readily model memory horizons of different lengths. To this end, we evaluate if a shallow CKCNN is able to solve the Copy Memory and Adding Problem tasks <ref type="bibr" target="#b27">(Hochreiter &amp; Schmidhuber, 1997)</ref> for sequences of sizes in the range [100, 6000]. Success is achieved if 100% accuracy, or a loss ? 1e-4 are obtained, for the copy memory and adding problem, respectively. Random predictions for the adding problem lead to a loss of approx. 0.17.</p><p>Our results show that a shallow CKCNN is able to solve both problems for all sequence lengths considered without requiring structural modifications (Tab. 2). Recurrent architectures are not able not solve the copy problem at all and could solve the sum problem up to 200 steps. TCNs with k=7, n=7 were able to solve both tasks for up to 1000 steps. However, larger lengths were out of reach as their memory horizon is constrained a priori. To handle larger sequences, TCNs must modify their network structure based on prior knowledge regarding the expected length of the input sequence.</p><p>Discrete sequences. The continuous nature of our kernels might give the impression that CKCNNs are only suited for continuous data, i.e., time-series. However, Sine nonlinearities allow our convolutional kernels to model complex non-smooth non-linear functions <ref type="figure" target="#fig_2">(Fig. 4</ref>). Consequently, we validate whether CKCNNs can be applied for discrete sequence modeling on the following tasks: sMNIST, pMNIST <ref type="bibr" target="#b33">(Le et al., 2015</ref><ref type="bibr">), sCIFAR10 (Trinh et al., 2018</ref> and Char-level PTB <ref type="bibr" target="#b36">(Marcinkiewicz, 1994)</ref>. Shallow CKCNNs outperform recurrent, self-attention and convolutional models on sMNIST and pMNIST (Tab. 1). On sMNIST, a small CKCNN (100K params.) achieves state-of-the-art results with a model 80? smaller than the current state-of-the-art. A wider CKCNN (1M params.) slightly increases this result further. On pMNIST, we see an improvement of 0.8% over the best model of size ?100K, and our wider shallow CKCNN achieves state-of-the-art on this dataset. For sCIFAR10,   Time-series modeling. Next, we evaluate CKCNNs on time-series data. To this end, we consider the CharacterTrajectories (CT) <ref type="bibr" target="#b2">(Bagnall et al., 2018)</ref> and the Speech Commands (SC) <ref type="bibr" target="#b64">(Warden, 2018)</ref> datasets. We follow <ref type="bibr" target="#b30">Kidger et al. (2020)</ref> to obtain a balanced classification dataset with precomputed mel-frequency cepstrum coefficients. In addition, we evaluate the ability of CKCNNs to model long-term dependencies by training on the raw SC dataset (SC_raw), whose records have length 16k.</p><formula xml:id="formula_9">COPY MEMORY GRU 16K - - - - - TCN 16K - - CKCNN 16K ADDING PROBLEM (LOSS) GRU 70K - TCN 70K - - CKCNN 70K</formula><p>We compare CKCNNs with representative sequential models with continuous-time interpretations: GRU-ODE <ref type="bibr" target="#b15">(De Brouwer et al., 2019)</ref>, GRU-?t <ref type="bibr" target="#b30">(Kidger et al., 2020)</ref>, ODE-RNN <ref type="bibr" target="#b51">(Rubanova et al., 2019)</ref>, and NCDE <ref type="bibr" target="#b30">(Kidger et al., 2020)</ref>. Continuous-time sequential models were selected as they are only sequential methods also able to handle irregularly-sampled data, and data at different resolutions.</p><p>Our results show that shallow CKCNNs outperform all continuous-time models considered for both the CT and SC datasets (Tab. 3). In addition, CKCNNs obtain promising results on SC_raw, which validates their ability to handle very-long-term dependencies. In fact, CKCNNs trained on SC_raw are able outperform several Neural ODE models trained on the preprocessed data (SC).</p><p>In addition, we observed that neural ODE methods considered in Tab. 3 were prohibitively slow for long sequences. For instance, NCDEs were 228? slower than a CKCNN of equivalent size on SC_raw, taking 17 hours per epoch to train. Consequently, training a NCDE on SC_raw for a matching number of epochs would take more than 212 days to conclude. In order to provide results for these models, we train them under the same computational budget than CKCNNs. This is enough to train them for a single epoch. All obtained results are at best only marginally better than random.</p><p>Testing at different sampling rates. We now consider the case where a network is trained with data at a sampling rate sr 1 , and tested with data at a different sampling rate sr 2 . Our results show that the performances of CKCNNs remains stable for large sampling rate fluctuations (Tab. 5). This behaviour contrasts with most previous continuous-time models, whose performance rapidly decays upon these changes. CKCNNs outperform HiPPO <ref type="bibr" target="#b23">(Gu et al., 2020a)</ref> and set a new state-of-the-art in this setting. Importantly, depending on the sampling, additional care may be needed to account for spatial displacements and high-frequencies of our kernels (see Appx. E.2 for details).   <ref type="bibr" target="#b30">Kidger et al. (2020)</ref>. In addition, we provide results under the same methodology for the SC_raw dataset. As in <ref type="bibr" target="#b30">Kidger et al. (2020)</ref> we add an additional channel to the input to indicate whether the value at that position is known.</p><p>Our results show that CKCNNs outperform NCDEs and obtain state-of-the-art performance on the PhysioNet dataset. In addition, CKCNNs exhibit stable performance for varying quantities of missing data, and perform better than several models explicitly developed to this end (Tab. 4). On the CT dataset, NCDEs perform slightly better than CKCNNs for large data drop rates. However, we argue that our method is still advantageous due to the gains in training speed -see Section 6 for details-. High-frequency components. Interestingly, our kernels often contain frequency components higher than the resolution of the grid used during training <ref type="figure">(Fig. 9)</ref>. As a result, transitions to finer resolutions benefit from smoothing (see Appx. E.3). Nevertheless, we believe that, if tuned properly, these highfrequency components might prove advantageous for tasks such as super-resolution and compression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION AND LIMITATIONS</head><p>Faster continuous-time models. CKCNNs rely on convolutions, and thus can be executed in parallel. As a result, CKCNNs can be trained faster than recurrent architectures. This difference becomes more pronounced with concurrent continuous-time models for sequential data, which are based on neural ODEs and require at least 5? slower than RNNs <ref type="bibr" target="#b30">(Kidger et al., 2020)</ref>. At the cost of larger memory costs, CKCNNs can be further sped up by using the convolution theorem.</p><p>Neural networks parameterizing spatial functions should be able to model high-frequencies.</p><p>Our findings indicate that, common nonlinearities do not provide MLPs modelling spatial continuous functions the ability to model high-frequencies.</p><p>Consequently, architectures that model continuous spatial functions via neural networks should transition towards models endowed with this ability, e.g., MLPs with Sine nonlinearities. These models encompass convolutional networks with continuous kernels, e.g., <ref type="bibr" target="#b54">Sch?tt et al. (2017)</ref>; <ref type="bibr" target="#b61">Thomas et al. (2018)</ref>; <ref type="bibr" target="#b66">Wu et al. (2019)</ref>, positional encodings in transformers, e.g., Romero &amp; Cordonnier (2020); <ref type="bibr" target="#b29">Hutchinson et al. (2020)</ref>, and graph neural networks, e.g., <ref type="bibr" target="#b16">Defferrard et al. (2020)</ref>. Sine nonlinearities can be used to reduce the number of parameters needed to model local functions, or to extend the receptive field of the operations efficiently.</p><p>Memory requirements. Although, CKCNNs can be deployed and trained in parallel, CKCNNs must store the convolution responses at each layer and for all input positions. This induces a linear memory complexity with regard to the sequence length, and largely contrasts with recurrent continuous-time models, whose memory complexity is constant. The memory consumption of the operation is further incremented if the convolution theorem is applied because it requires multiplying the Fourier transform of the convolution and the kernel, and taking them back to the temporal representation. On the other hand, large convolutional kernels seem to allow CNNs to perform well without using many layers, which has a positive effect on memory consumption.</p><p>Selection of ? 0 . We observe that CKCNNs are very susceptible to the selection of ? 0 . For instance, performance on pMNIST may vary from 98.54 to 65.22 for values of ? 0 in [1, 100]. Consequently, finding a good value of ? 0 induces an important cost in hyperpararameter search (see <ref type="bibr">Appx. E.4)</ref>. ? 0 acts as a prior on the variability of the target function. However, it is not obvious which value of ? 0 is optimal for the internal (unknown) features of a network. Learning layer-wise ? 0 values yielded sub-optimal results, and better results were obtained by using a predefined ? 0 value across all layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION AND FUTURE WORK</head><p>We introduced the Continuous Kernel Convolution (CKConv), a simple, yet powerful approach able to model global long-term dependencies effectively in a parameter-efficient manner. Aside from the ability to get good accuracy, CKConvs are readily able to handle irregularly-sampled data, and data at different resolutions. CKCNNs achieve state-of-the-art results on multiple datasets, and often surpass neural architectures designed for particular settings, e.g., for irregularly-sampled data.</p><p>We are intrigued about the potential of CKCNNs for tasks in which (global) long-term dependencies play a crucial role, e.g., audio, video, reinforcement learning, (autoregressive) generative modeling. The usage of CKConvs to model long-term interactions in images is also very promising. In addition, CKConvs provide a convenient way to study the effect of the receptive field size of convolutional architectures, as no network modifications are required for different sizes. Our findings may also be useful for specific problems with irregularly-sampled data, e.g., medical, point clouds. We are also excited about structural advances of CKConvs. For instance, attentive versions of CKCNNs, or formulations that further improve computation and parameter efficiency Alleviating limitations. Reducing the memory consumption of CKConvs is vital for its application on a broad range of scenarios, e.g., embedded devices. Moreover, finding kernel parameterizations more stable to hyperparameter changes is desirable to reduce the need for hyperparameter search.</p><p>What is the best implicit kernel parameterization for convolutional kernels? Despite the success of SIRENs, we believe that better kernel parameterizations might still be constructed, e.g., with <ref type="bibr">Random Fourier Features (Tancik et al., 2020)</ref>. Aside from improvements in implicit neural representations, which are directly transferable to CKConvs, we consider important to analyze the effect that having unknown, changing target objectives has on the approximation. A thorough empirical study of possible kernel parameterizations is an important direction for future research. A parameterization with which additional desiderata, e.g., smoothness, can be imposed is also desirable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REPRODUCIBILITY STATEMENT</head><p>We believe in reproducibility. In order to make our paper reproducible, we have release the source code used in our experiments to the public. In addition to the code, our repository includes the explicit command lines used to execute each of our experiments, as well as the corresponding pretrained models. Appx. E provides the experimental details of our approach. This section includes details regarding the hardware used, the specification of neural architecture as well as the inputs of MLP ? . It also states the method used for hyperparameter tuning and the hyperparameters of our final models. Details regarding the smoothing of high-frequency artifacts are also provided in this section. Details regarding the datasets and any preprocessing steps used are provided in Appx. C. The proofs of our claims can be found in Appx. A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A PROPERTIES OF CKCONVS</head><p>A.1 VERY IRREGULARLY SAMPLED DATA CKConvs can readily handle irregularly-sampled, and partially observed data. This is a result of the convolutional kernel MLP ? being able to be sampled at arbitrary positions. For very non-uniformed sampled inputs, however, the corresponding sampling of the convolutional kernel can provide a biased estimation of the operation. To overcome this, one can follow the strategy proposed by <ref type="bibr" target="#b66">Wu et al. (2019)</ref>, which we summarize here for completeness.</p><p>For very non-uniformly sampled inputs, the continuous convolution (x * ?)(t) = ? R x(? )?(t ? ? ) d? , must account for the distribution of samples in the input. Specifically, it is reformulated as:</p><formula xml:id="formula_10">(x * ?)(t) = R s(? )x(? )?(t ? ? ) d?,<label>(8)</label></formula><p>where s(? ) depicts the inverse sample density of the input at point ? . Intuitively, s(? ) controls the contribution of points x(? ) to the output response. If multiple points are close to one another, their contribution should be smaller than the contribution of points in regions where the sample distribution is much sparser. This provides a Monte Carlo estimate of (x * ?) from biased samples. In particular, one has that:</p><formula xml:id="formula_11">f (? ) d? = f (? ) p(? ) p(? ) d? ? i f (? i ) p(? i ) , for ? i ? p(? ).</formula><p>With s(? ) = 1 p(? ) , Eq. 8 provides an unbiased estimation of (x * ?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 DATA SAMPLED AT DIFFERENT SAMPLING RATES</head><p>In addition, CKConvs are readily able to handle data at different resolutions. In particular, the continuous kernel convolution between an input signal x and a continuous convolutional kernel ? calculated at sampling rates sr 1 : (x * ?) sr1 , and sr 2 : (x * ?) sr2 , are approximately equal up to a normalization factor given by sr2 sr1 : (x * ?) sr2 (t) ? sr 2 sr 1 (x * ?) sr1 (t).</p><p>Consequently, CKCNNs (i) can be deployed at sampling rates different than those seen during training, and (ii) can be trained on data with varying spatial resolutions. The later is important for tasks in which data can be given at different resolutions such as super-resolution and segmentation.</p><p>Proof. To prove the previous statement, we start with the continuous definition of the convolution:</p><formula xml:id="formula_12">(x * ?)(t) = R x(? )?(t ? ? ) d?,</formula><p>where we assume for simplicity and without loss of generality that the functions x, ? are scalar-valued.</p><p>In practice, an integral on a continuous function f ? R ? R cannot be computed on finite time. Consequently, it is approximated via a Riemann integral defined on a finite grid {? sr,i } Nsr i=1 obtained by sampling ? at a sampling rate sr:</p><formula xml:id="formula_13">f (? ) d? ? Nsr i=1 f (? sr,i )? sr ,</formula><p>where ? sr = 1 sr depicts the distance between sampled points. For two sampling rates sr 1 , sr 2 , the convolution can be approximated through the corresponding Riemann integrals:</p><formula xml:id="formula_14">R x(? )? t ? ? ) d? ? Nsr 1 i=1 x(? sr1,i )? t ? ? sr1,i )? sr1 ? Nsr 2 i=1 x(? sr2,i )? t ? ? sr2,i )? sr2</formula><p>As a result, we have that both approximations are approximately equal to the continuous integral at positions t defined on both discrete grids. By equating both approximations, we obtain that:</p><formula xml:id="formula_15">Nsr 2 i=1 x(? sr2,i )? t ? ? sr2,i )? sr2 ? Nsr 1 i=1 x(? sr1,i )? t ? ? sr1,i )? sr1 Nsr 2 i=1 x(? sr2,i )? t ? ? sr2,i ) (x * ?)sr 2 (t) 1 sr2 ? Nsr 1 i=1 x(? sr1,i )? t ? ? sr1,i ) (x * ?)sr 1 (t) 1 sr1 (x * ?) sr2 (t) ? sr 2 sr 1 (x * ?) sr1 (t)</formula><p>which concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 LINEAR RECURRENT UNITS ARE CKCONVS</head><p>Interesting insights can be obtained by drawing connections between convolutions and recurrent units.</p><p>In particular, we can show that linear recurrent units are equal to a CKConv with a particular family of convolutional kernels: exponential functions. Besides providing a generalization to recurrent units, this equality provides a fresh and intuitive view to the analysis of vanishing and exploding gradients.</p><p>Recurrent unit. Given an input sequence X = {x(? )} N X ? =0 , a recurrent unit is constructed as:</p><formula xml:id="formula_16">h(? ) = ?(Wh(? ? 1) + Ux(? )) (9) y(? ) = softmax(Vh(? )),<label>(10)</label></formula><p>where U, W, V parameterize the input-to-hidden, hidden-to-hidden and hidden-to-output connections of the unit. h(? ),?(? ) depict the hidden representation and the output at time-step ? , and ? represents a point-wise non-linearity.</p><p>The hidden representation h of a linear recurrent unit, i.e., with ?=Id, can be written as a convolution. To see this, consider the hidden representation of the unit unrolled for t steps:</p><formula xml:id="formula_17">h(t) = W t+1 h(?1) + t ? =0 W ? Ux(t ? ? ).<label>(11)</label></formula><p>Here, h(?1) is the initial state of the hidden representation. We see that in fact it corresponds to a convolution between an input signal x and a convolutional kernel ? given by: 2</p><formula xml:id="formula_18">x = [x(0), x(1), ..., x(t ? 1), x(t)]<label>(12)</label></formula><formula xml:id="formula_19">? = [U, WU, ..., W t?1 U, W t U]<label>(13)</label></formula><formula xml:id="formula_20">h(t) = t ? =0 x(? )?(t ? ? ) = t ? =0 x(t ? ? )?(? ).<label>(14)</label></formula><p>Drawing this equality yields some important insights:</p><p>The cause of the exploding and vanishing gradients. Eqs. 12-14 intuitively depict the root of the exploding and vanishing gradient problem. It stems from sequence elements x(t ? ? ) ? steps back in the past being multiplied with an effective convolutional weight ?(? )=W ? U. For eigenvalues of W, ?, other than one, the resulting convolutional kernel ? can only represent functions that either grow (??1) or decrease (??1) exponentially as a function of the sequence length <ref type="figure" target="#fig_1">(Figs. 3a, 3b)</ref>. As a result, the contribution of input values in the past either rapidly fades away or governs the updates of the model parameters. As exponentially growing gradients lead to divergence, the eigenvalues of W for converging architectures are often smaller than 1. This explains the effective small effective memory horizon of recurrent networks.</p><p>Linear recurrent units are a subclass of CKConvs. Linear recurrent units can be described as a convolution between the input and a very specific class of convolutional kernels: exponential functions (Eq. 13). In general, however, convolutional kernels are not restricted to this functional class. This can be seen in conventional (discrete) convolutions, whose kernels are able to model complex functions within their memory horizon. Unfortunately, discrete convolutions use a predefined, small kernel size, and thus possess a restricted memory horizon. This is equivalent to imposing an effective magnitude of zero to all input values outside the memory horizon <ref type="figure" target="#fig_1">(Fig. 3c)</ref>. CKConvs, on the other hand, are able to define arbitrary large memory horizons. For memory horizons of size equal to the input length, CKConvs are able to model complex functions upon the entire input <ref type="figure" target="#fig_1">(Fig. 3d</ref>).</p><p>In conclusion, we illustrate that CKConvs are also a generalization of (linear) recurrent architectures which allows for parallel training and enhanced expressivity.</p><p>B AN SPLINE INTERPRETATION OF RELU AND SINE NETWORKS <ref type="bibr" target="#b59">Sitzmann et al. (2020)</ref> motivates the usage of Sine nonlinearities for implicit neural representations. However, there is no clear understanding as of why Sine nonlinearities are better suited for this task than (smooth) piece-wise nonlinearities. Here, we provide an interpretation to this phenomenon from a spline function approximation perspective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 KERNEL PARAMETERIZATION VIA ReLU NETWORKS</head><p>The importance of initialization. There is an important distinction between implicit neural representations and conventional neural applications regarding the assumed distribution of the input. Conventional applications assume the distribution of the input features to be centered around the origin. This is orthogonal to implicit neural representations, where the spatial distribution of the output, i.e., the value of the function being implicitly represented, is uniformly distributed. <ref type="figure">Figure 5</ref>: An step function approximated via a spline basis (left) and a periodic basis (right). As the target function is defined uniformly on a given interval, uniformly initializing the knots of the spline basis provides faster and better approximations. Periodic bases, on the other hand, periodically bend space, and thus can be tuned easier to approximate the target function at arbitrary points in space.</p><p>For ReLU networks, function approximation is equivalent to an approximation via a maxspline basis <ref type="bibr" target="#b5">(Balestriero &amp; Baraniuk, 2018)</ref>, and its expressiveness is determined by the number of knots the basis provides, i.e., places where a non-linearity bends the space. Naturally, the better the placing of these knots at initialization, the faster the approximation may converge. For applications in which the data is centered around zero, initializing the knots around zero is a good inductive bias. 3 However, for spatially uniform distributed inputs, the knots should be uniformly distributed <ref type="figure">(Fig. 5)</ref>. As a result, conventional initializations lead to very poor reconstructions (ReLU 0-Init, <ref type="figure" target="#fig_2">Fig. 4)</ref>, and explicitly aggregating positional encodings to the mappings leads to important improvements, e.g, .</p><p>For ReLU layers y=max{0, Wx + b} knots appear at the point where 0=Wx + b. To place the knots at x=0, it is sufficient to set the bias to zero: b=0. For uniformly distributed knots in a range [x min , x max ], however, one must solve the ReLU equation for uniformly distributed points in that range: 0=Wx unif + b. It results that b= ? Wx unif , for arbitrary values of W.</p><p>In multilayered networks, the approximation problem can be understood as reconstructing the target function in terms of a basis h (L?1) . Consequently, the expressivity of the network is determined by the number of knots in h (L?1) . In theory, each ReLU layer is able to divide the linear regions of the previous layer in exponentially many sub-regions <ref type="bibr" target="#b40">(Montufar et al., 2014;</ref><ref type="bibr" target="#b56">Serra et al., 2018)</ref>, or equivalently, to induce an exponential layer-wise increase in the number of knots. For the first layer, the positions of the knots are described by the bias term, and for subsequent layers, these positions also depend on W (l) . Unfortunately, as depicted by <ref type="bibr" target="#b25">Hanin &amp; Rolnick (2019)</ref>, slight modifications of {W (l) , b (l) } can strongly simplify the landscape of the linear regions, and thus the knots <ref type="figure">(Fig. 6</ref>). More importantly, <ref type="bibr" target="#b25">Hanin &amp; Rolnick (2019)</ref> showed that the number of linear regions at initialization is actually equal to a constant times the number of neurons in the network (with a constant very close <ref type="figure">Figure 6</ref>: The sensitivity of networks with layer-wise exponential growing to slight changes. Taken from <ref type="bibr" target="#b25">Hanin &amp; Rolnick (2019)</ref>. The sawtooth function with 2 n teeth (left) can be easily expressed via a ReLU network with 3n + 4 neurons (bottom). However, a slight perturbation of the network parameters -Gaussian noise with standard deviation 0.1greatly simplifies the linear regions captured by the network, and thus the distribution of the knots in the basis (right).</p><p>to one in their experiments). In addition, they show that this behavior barely changes throughout training.</p><p>An improved initialization scheme. Following the previous reasoning, we explore inducing a uniformly distributed initialization of the knots. However, we observe that finding an initialization with an exponential number of knots is a cumbersome and unstable procedure. In fact, it is not always possible, and, whenever possible, it strongly restricts the values the weights W (l) can assume.</p><p>Following the findings of <ref type="bibr" target="#b25">Hanin &amp; Rolnick (2019)</ref>, we instead employ an initialization procedure with which the total number of knots is equal to the number of neurons of the network. This is obtained by replicating the initialization procedure of the first layer throughout the network: For randomly initialized weights W (l) , the bias term b (l) is given by the equality b</p><formula xml:id="formula_21">(l) = ? W (l) h (l) (x unif )</formula><p>, where x unif is a vector of uniformly distributed points in [x min , x max ]. Interestingly, we observe that this initialization strategy consistently outperforms the standard initialization for a large range of target functions (ReLU Unif-Init, <ref type="figure">Fig. 7)</ref>. Unfortunately however, we note that ReLU networks still show large difficulties in representing very nonlinear and non-smooth functions. In <ref type="figure">Fig. 7</ref>, we illustrate that other popular nonlinearities: LeakyReLU, Swish, exhibit the same behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 KERNEL PARAMETERIZATION VIA Sine NETWORKS</head><p>Recently, <ref type="bibr" target="#b59">Sitzmann et al. (2020)</ref> proposed to replace ReLU nonlinearities by Sine for the task of implicit neural representation learning. Based on their relation with implicit neural representations, we explore using Sine networks to parameterize our continuous kernels. Intriguingly, we observe that this slight modification allows our kernels to approximate any provided function to near perfection, and leads to a consistent improvement for all tasks considered in this paper (Appx. <ref type="figure" target="#fig_0">D.1, Fig. 7)</ref>.</p><p>A possible explanation to these astonishing results can be provided via our prior analysis:</p><p>Periodic bending of the space. A Sine layer is given by:</p><formula xml:id="formula_22">y = Sin(? 0 [Wx + b]),</formula><p>where ? 0 works as a prior on the variability of the target function. Orthogonal to ReLU layers, Sine layers periodically bend the space. As a result, the same y value is obtained for all bias values b ? i =b i + n2? W i,? ?1 , ?n ? Z. This is important from a spline approximation perspective. While for ReLU layers a unique value of b exists that bends the space at a desired position, infinitely many values of b do so for Sine ones. Resultantly, Sine layers are much more robust to parameter selection, and can be tuned to benefit pattern approximation at arbitrary -or even multiple-positions in space <ref type="figure">(Fig. 5, right)</ref>. We conjecture that this behavior leads to much more reliable approximations and faster convergence.</p><p>An exponentially big Fourier basis. It is not surprising for a (large) basis of phase-shifted sinusoidal functions to be able to approximate arbitrary functions with high fidelity. This result was first observed over two centuries ago by <ref type="bibr" target="#b19">Fourier (1807)</ref> and lies at the core of the well-known Fourier transform: any integrable function can be described as a linear combination of a (possibly) infinite basis of phase-shifted sinusoidal functions. <ref type="bibr" target="#b59">Sitzmann et al. (2020)</ref> proposed an initialization of {W (l) } that allows for the construction of deep Sine networks able to periodically divide the space into exponentially many regions as a function of depth. Intuitively, approximations via Sine networks can be seen in terms of an exponentially large Fourier-like basis. We conjecture that this exponential growth combined with the periodicity of sine is what allows for astonishingly good approximations: the more terms in a Fourier transform, the better the approximation becomes.</p><p>Interestingly, we find that a uniformly distributed initialization of the bias term b i ? U(?? W i,? ?1 , ? W i,? ?1 ) also leads to better and faster convergence for Sine networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C DATASET DESCRIPTION</head><p>Copy Memory Problem. The copy memory task consists of sequences of length T +20, for which the first 10 values are chosen randomly among the digits {1, ..., 8}, the subsequent T ?1 digits are set to zero, and the last 11 entries are filled with the digit 9. The goal is to generate an output of the same size of the input filled with zeros everywhere except for the last 10 values, for which the model is expected to predict the first 10 elements of the input sequence.</p><p>The Adding Problem. The adding problem consists of input sequences of length T and depth 2. The first dimension is filled with random values in [0, 1], whereas the second dimension is set to zeros except for two elements marked by 1. The objective is to sum the random values for which the second dimension is equal to 1. Simply predicting the sum to be 1 results in a MSE of about 0.1767.</p><p>Sequential and Permuted MNIST. The MNIST dataset <ref type="bibr" target="#b34">(LeCun et al., 1998)</ref> consists of 70K grayscale 28?28 handwritten digits divided into training and test sets of 60K and 10K samples, respectively. The sequential MNIST dataset (sMNIST) presents MNIST images as a sequence of 784 pixels for digit classification. Consequently, good predictions require preserving long-term dependencies up to 784 steps in the past: much longer than most language modelling tasks <ref type="bibr" target="#b4">(Bai et al., 2018b)</ref>.</p><p>The permuted MNIST dataset (pMNIST) additionally permutes the order or the sMNIST sequences at random. Consequently, models can no longer rely on on local features to perform classification. As a result, the classification problem becomes more difficult and the importance of long-term dependencies more pronounced.</p><p>Sequential CIFAR10. The CIFAR10 dataset <ref type="bibr" target="#b32">(Krizhevsky et al., 2009)</ref> consists of 60K real-world 32 ? 32 RGB images uniformly drawn from 10 classes divided into training and test sets of 50K and 10K samples, respectively. Analogously to the sMNIST dataset, the sequential CIFAR10 (sCIFAR10) dataset presents CIFAR10 images as a sequence of 1024 pixels for image classification. This dataset is more difficult than sMNIST, as (i) even larger memory horizons are required to solve the task, and (ii) more complex structures and intra-class variations are present in the images <ref type="bibr" target="#b62">(Trinh et al., 2018)</ref>.</p><p>CharacterTrajectories. The CharacterTrajectories dataset is part of the UEA time series classification archive <ref type="bibr" target="#b2">(Bagnall et al., 2018)</ref>. It consists of 2858 time series of different lengths and 3 channels representing the x, y positions and the pen tip force while writing a Latin alphabet character in a single stroke The goal is to classify which of the different 20 characters was written using the time series data. The maximum length of the time-series is 182.</p><p>Speech Commands. The Speech Commands dataset <ref type="bibr" target="#b64">(Warden, 2018)</ref> consists of 105809 one-second audio recordings of 35 spoken words sampled at 16kHz. Following <ref type="bibr" target="#b30">Kidger et al. (2020)</ref>, we extract 34975 recordings from ten spoken words to construct a balanced classification problem. We refer to this dataset as SC_raw. In addition, we utilize the preprocessing steps of <ref type="bibr" target="#b30">Kidger et al. (2020)</ref> and extract mel-frequency cepstrum coefficients from the raw data. The resulting dataset, named SC, consists of time series of length 161 and 20 channels.</p><p>PhysioNet. The PhysioNet 2019 challenge on sepsis prediction <ref type="bibr" target="#b21">(Goldberger et al., 2000;</ref><ref type="bibr" target="#b48">Reyna et al., 2019)</ref> is a irregularly sampled, partially observed dataset consisting of 40335 time series of variable length describing the stay of patients within an ICU. Time-series are made out of 5 static features, e.g., age, and 34 time-dependent features, e.g., respiration rate, creatinine blood concentration, and 10.3% of the values are observed. We follow <ref type="bibr" target="#b30">Kidger et al. (2020)</ref> and consider the first 72 hours of a patient's stay to predict whether sepsis is developed over the course of their entire stay -which can extend for a month for some patients-.</p><p>PennTreeBank. The PennTreeBank (PTB) <ref type="bibr" target="#b36">(Marcinkiewicz, 1994)</ref> is a language corpus which consists of 5,095K characters for training, 396K for validation and 446K for testing. On a char  lever that we use in our experiment the vocabulary size is 50 characters (or the size of the alphabet, including end-of-string char). We follow <ref type="bibr" target="#b3">Bai et al. (2018a)</ref> in performing character-level language modeling task on this dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D ABLATION STUDIES</head><p>In this section, we perform an ablative study of our approach. Specifically, we analyze the effect of multiple components of our network, and provide additional comparisons with alternative architectures. Specifications on the architectures and hyperparameters used are given in Appx. E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 USING SINE NON-LINEARITIES OVER POPULAR ALTERNATIVES</head><p>As shown in Sec. 4.2, Sine nonlinearities provide astonishing improvements over equivalent networks with ReLU nonlinearities for function reconstruction. In this section, we provide additional experiments to highlight the suitability of Sine nonlinearities over other popular alternatives both for function approximation and the rest of the tasks considered in this work. The same architectures are used across all experiments and vary only in the nonlinearity used in MLP ? . We find that nonlinearities other than Sine benefit from layer normalization and thus we incorporate it in these variants.</p><p>Case I: Function Approximation via MLP ? . First, we evaluate the problem of function approximation in Sec. 4.2, <ref type="figure" target="#fig_2">Fig. 4</ref>, for nonlinearities other than ReLU and Sine. In particular, we approximate several functions with a MLP ? network which varies only in the type of nonlinearity used: ReLU <ref type="bibr" target="#b41">(Nair &amp; Hinton, 2010)</ref>, LeakyReLU <ref type="bibr" target="#b67">(Xu et al., 2015)</ref>, Swish <ref type="bibr" target="#b46">(Ramachandran et al., 2017)</ref>, and Sine <ref type="bibr" target="#b59">(Sitzmann et al., 2020)</ref>.</p><p>Our results <ref type="figure">(Fig. 7)</ref>, illustrate that Sine provides astonishing approximation capabilities over all other nonlinearities considered. In particular, we observe that Sine is the only nonlinearity able to reconstruct very nonlinear and very non-smooth functions, while all other alternatives fail poorly.</p><p>Case II: CKCNNs with nonlinearities other than Sine. Next, we consider the case in which CKCNNs with nonlinearities other than Sine are used to solve the tasks considered in Sec. 5. In particular, we train CKCNNs on sMNIST, pMNIST, SC and SC_raw for four different nonlinearities: ReLU, LeakyReLU, Swish, Sine. We utilize the same backbone architecture used in the main text for the corresponding dataset.</p><p>Our results (Tab. 6) indicate that Sine outperform CKCNNs using any of the other nonlinearities.</p><p>Analysis of the results. Our findings indicate Sine is much better suited to describe continuous spatial functions via neural networks than all other nonlinearities considered. This result motivates replacing popular nonlinearities by Sine for applications in which neural networks are used to describe continuous positional functions. This family of models encompass -but is not restricted to-continuous types of convolutions, e.g., <ref type="bibr" target="#b54">Sch?tt et al. (2017)</ref>; <ref type="bibr" target="#b61">Thomas et al. (2018);</ref><ref type="bibr" target="#b18">Finzi et al. (2020);</ref><ref type="bibr" target="#b20">Fuchs et al. (2020)</ref>, as well as positional encodings in transformers, e.g., <ref type="bibr" target="#b13">Dai et al. (2019)</ref>; <ref type="bibr" target="#b47">Ramachandran et al. (2019)</ref>; <ref type="bibr" target="#b49">Romero &amp; Cordonnier (2020)</ref>, and graph neural networks, e.g., <ref type="bibr" target="#b16">Defferrard et al. (2020)</ref>. We consider this result to be of large relevance to the deep learning community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 GOING DEEPER WITH CKCNNS</head><p>The experimental results shown in Sec. 5 are obtained with shallow CKCNNs composed of 2 residual blocks only. An interesting question is whether going deeper can be used to improve the performance Analysis of the results. The dynamics governing these results are not yet fully understood. However, our findings may lead to two different conclusions, both of which we consider important for the development and understanding of CKCNNs and deep learning in general:</p><p>Outcome I: Deep CKCNNs. The first possible outcome is that our current parameterization does not correctly leverage depth. In this case, efforts to construct proper deep CKCNNs will likely lead to performance improvements over the current architectures, and thus have the potential to advance the state-of-the-art further.</p><p>Outcome II: Depth is not needed when global memory horizons are provided with shallow networks. The second possible outcome is that depth is used mainly as a means to construct global memory horizons. Consequently, neural networks do not have to be very deep at all provided that global memory horizons are defined by shallow neural networks. Interestingly, this conclusion is in line with the predominant design of recurrent architectures, for which a moderate number of layers are used, e.g., <ref type="bibr" target="#b44">Pascanu et al. (2013a)</ref>; <ref type="bibr" target="#b22">Graves et al. (2013)</ref>; <ref type="bibr" target="#b24">Gu et al. (2020b;</ref><ref type="bibr">a)</ref>. This possible outcome is very exciting as depth is largely considered indispensable in the deep learning community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E EXPERIMENTAL DETAILS</head><p>In this section, we provide extended details over our implementation as well as the exact architectures and optimization schemes used in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 GENERAL REMARKS</head><p>Our models follow the structure shown in <ref type="figure">Fig. 8</ref> and vary only in the number of channels. We use layer normalization <ref type="bibr" target="#b1">(Ba et al., 2016)</ref> in our backbone network, and use the Adam optimizer (Kingma &amp; Ba, 2014) across all our experiments. Our code is implemented in PyTorch and is publicly available at link removed for the sake of the double-blind review. We utilize wandb <ref type="bibr" target="#b7">(Biewald, 2020)</ref> to log our results, and use NVIDIA TITAN RTX GPUs throughout our experiments.</p><p>Continuous Convolutional Kernel MLP ? . All our convolutional kernels are parameterized by a vector-valued 3-layer neural network with 32 hidden units and Sine nonlinearities:</p><formula xml:id="formula_23">1 ? 32 ? 32 ? N out ? N in ,</formula><p>where N in , N Cout are the number of input and output channels of the convolutional layer. We utilize weight normalization <ref type="bibr" target="#b53">(Salimans &amp; Kingma, 2016)</ref> in our MLP ? networks, and select a hidden size of 32 based on empirical evidence and findings from previous works, e.g., <ref type="bibr" target="#b18">Finzi et al. (2020)</ref>.</p><p>Normalized relative positions. The MLPs parameterizing our convolutional kenels receive relative positions as input. However, considering unitary step-wise relative positions, i.e., 0, 1, 2, ... , N, can be problematic from a numerical stability perspective as N may grow very large, e.g., N=16000 for the SC_raw dataset. Consequently, we follow good practices from works modelling continuous functions with neural networks, and map the largest unitary step-wise relative positions seen during training [0, N] to a uniform linear space in [?1, 1].</p><p>Hyperparameter tuning. We tune the hyperparameters of our models via the bayes method given in wandb Sweeps, which selects hyperparameter values via a Gaussian process over the results obtained so far. We perform tuning on a validation dataset until a predefined maximum number of runs of 100 is exhausted. Further improvements upon our results may be obtained by leveraging more sophisticated tuning methods as well as additional runs.</p><p>Selecting ? 0 . CKCNNs are very susceptible to the value of ? 0 . In order to obtain a reasonable ? 0 , we first perform a random search on a large interval ? 0 ? [0, 3000]. After a few runs, we stop the random search and select the subinterval in which the validation accuracy is most promising. Next, <ref type="figure">Figure 8</ref>: Graphical description of continuous kernel convolutional networks. Dot-lined blocks depict optional blocks, and blocks without borders depict variables. KernelNet blocks use Sine nonlinearities. We replace spatial convolutions by Fourier Convolutions (FFTConv), which leverages the convolution theorem to speed up computations.</p><p>we restart the random search on this sub-interval and repeat the process until a ? 0 value is obtained, for which the validation accuracy is sufficiently high. Surprisingly, we found optimal values of ? 0 to be always enclosed in the interval [1, 70] even for very long sequences as in SC_raw.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 ACCOUNTING FOR SPATIAL DISPLACEMENTS OF THE SAMPLED CONVOLUTIONAL KERNELS</head><p>We follow the sampling procedure of <ref type="bibr" target="#b23">Gu et al. (2020a)</ref> throughout our test sampling rate discrepancy experiments. Specifically, for a sequence seq of length N, subsampling by a factor n is performed by running seq[::n]. That is, by taking the n-th element of the sequence starting from its first element. For example, for a sequence of length N=182, different values of n would yield the following sequences:</p><p>(n = 1) ? <ref type="figure" target="#fig_0">[1, 2, 3, ... , 180, 181</ref>  <ref type="figure" target="#fig_0">[1, 9, 17, ... , 161, 169</ref>, 177]</p><p>Recall that MLP ? takes normalized relative positions in [?1, 1] as input, which are computed based on the max input length seen during training. However, some of these subsampling transitions change the max value of the sequence, e.g., for (n = 8) the maximum is given by 177, whereas for (n = 1) this value corresponds to 182. Consequently, a naive approach would consider the last position in each subsampled sequence to correspond to the maximum normalized relative position 1. This effectively induces an spatial displacement, and a re-scaling of the sampled convolutional kernel used during training.</p><p>This misalignment is automatically handled under the hood in our CKConv implementation. Nevertheless, we highlight this subtle phenomenon to prevent it in future applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 DEALING WITH HIGH-FREQUENCY COMPONENTS</head><p>Interestingly, our experiments revealed that our continuous kernels often contain frequency components of frequency higher than the resolution of the sampling grid used during training <ref type="figure">(Fig. 9</ref>). As these high-frequency components are not observed during training, we observe that they hurt performance when evaluated at higher resolutions. In order to neutralize their influence, we filter these components before performing the convolution by means of blurring. This is performed by applying a convolution upon the convolutional kernel with a Gaussian filter G of length 2 srtest sr train + 1 and parameters ?=0, ?=0.5:</p><p>G ? srtest sr train , G ? srtest sr train + 1 , ..., G 0 , ..., G srtest sr train ? 1 , G srtest sr train Note that blurring is only used when the test sampling rate is higher than the train sampling rate, as opposed to the normalization factor srtest sr train discussed in Eq. 5, Appx. A.2, which is applied whenever the sampling rates differ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.4 HYPERPARAMETERS AND EXPERIMENTAL DETAILS</head><p>In this section, we provide further specifications of the hyperparameter configurations with with our models are trained. An overview of these hyperparameters is provided in Tab. 8.</p><p>Copy Memory. We set the number of channels of our CKCNN as to roughly match the number of parameters of the GRU and TCN networks of <ref type="bibr" target="#b3">Bai et al. (2018a)</ref>. This is obtained with 10 hidden channels at every layer. We observe that the time to convergence grew proportional to the length of the sequence considered. Whereas for sequences of length 100 convergence was shown after as few as 10 epochs, for sequences of length 6000 approximately 250 epochs were required. The maximum number of epochs is set to 50, 50, 100, 200 and 300 for sequences of size 100, 200, 1000, 3000 and 6000. We observe that different values of ? 0 are optimal for different sequence lengths. The optimal ? 0 values found are <ref type="bibr">19.20, 34.71, 68.69, 43.65 and 69.97</ref> for the corresponding sequence lengths.</p><p>Adding Problem. We set the number of channels of our CKCNN as to roughly match the number of parameters of the GRU and TCN networks of <ref type="bibr" target="#b3">Bai et al. (2018a)</ref>. This is obtained with 25 hidden channels at every layer. Similarly to the Copy Memory task, we observe that the time to convergence grew proportional to the length of the sequence considered. Interestingly, this task was much easier to solve for our models, with convergence for sequences of length 6000 observed after 38 epochs. The maximum number of epochs is set to 20, 20, 30, 50 and 50 for sequences of size 100, 200, 1000, 3000 and 6000. We observe that different values of ? 0 are optimal for different sequence lengths. The optimal ? 0 values found are 14.55, 18.19, 2.03, 2.23 and 4.3 for the corresponding sequence lengths.</p><p>sMNIST, pMNIST and sCIFAR10. We construct two models of different sizes for these datasets: CKCNN and CKCNN-Big. The first is constructed to obtain a parameter count close to 100K. The second model, is constructed to obtain a parameter count close to 1M. The parameters utilized for these datasets are summarized in Tab. 8. Despite our efforts, we observed that our models heavily overfitted sCIFAR10. Combinations of weight decay, dropout and weight dropout were not enough to counteract overfitting.</p><p>CT, SC and SC_raw. The parameters utilized for classification on these datasets are summarized in Tab. 8. For hyperparameters regarding experiments with irregularly-sampled data please refer to Tab. 9. Any non-specified parameter value in Tab. 9 can be safely consider to be the one listed for corresponding dataset in Tab. 8.  <ref type="figure">Figure 9</ref>: High-frequency components in Sine continuous kernels. We observe that continuous kernels parameterized by Sine networks often contain frequency components of frequency higher than the resolution of the grid used during training. Here, for instance, the kernel looks smooth on the training grid. However, several high-frequency components appear when sampled on a finer grid. Though this may be a problematic phenomenon, we believe that, if tuned properly, these highfrequency components can prove advantageous to model fine details in tasks such as super-resolution and compression cheaply.</p><p>PennTreeBank For a character-level language modeling on PTB dataset we use hyperparameters specified in Tab. 8. We use embedding of size 100 following the TCN model from <ref type="bibr" target="#b3">Bai et al. (2018a)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Continuous Kernel Convolution (CKConv). CKConv views a convolutional kernel as a vector-valued continuous function ? ? R ? R Nout?N in parameterized by a small neural network MLP ? .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Functional family of recurrent units, discrete convolutions and CKConvs. For max.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Approximation quality of MLPs with ReLU, LeakyReLU, Swish, and Sine nonlinearities. Networks with (smooth) piece-wise nonlinearities are unable to approximate non-smooth, nonlinear functions. Sine networks, on the other hand, quickly approximate all target functions to near perfection. All networks share the same structure and vary only in the nonlinearity used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Test results on discrete sequential datasets. Model sizes are 3M for TCN, LSTM and GRU, 13.4M for TrellisNet and 1.8M for CKCNN-Big.</figDesc><table><row><cell>MODEL</cell><cell>SIZE</cell><cell>SMNIST Acc (%)</cell><cell>PMNIST Acc (%)</cell><cell>SCIFAR10 Acc (%)</cell><cell>CHAR-PTB bpc</cell></row><row><cell>TCN (Bai et al., 2018a)</cell><cell>70K</cell><cell>99.0</cell><cell>97.2</cell><cell>-</cell><cell>1.31  ?</cell></row><row><cell>LSTM (Bai et al., 2018a)</cell><cell>70K</cell><cell>87.2</cell><cell>85.7</cell><cell>-</cell><cell>1.36  ?</cell></row><row><cell>GRU (Bai et al., 2018a)</cell><cell>70K</cell><cell>96.2</cell><cell>87.3</cell><cell>-</cell><cell>1.37  ?</cell></row><row><cell>IndRNN (Li et al., 2018)</cell><cell>83K</cell><cell>99.0</cell><cell>96.0</cell><cell>-</cell><cell>-</cell></row><row><cell>DilRNN (Chang et al., 2017)</cell><cell>44K</cell><cell>98.0</cell><cell>96.1</cell><cell>-</cell><cell>-</cell></row><row><cell>HiPPO (Gu et al., 2020a)</cell><cell>0.5M</cell><cell>-</cell><cell>98.30</cell><cell>-</cell><cell>-</cell></row><row><cell>r-LSTM (Trinh et al., 2018)</cell><cell>0.5M</cell><cell>98.4</cell><cell>95.2</cell><cell>72.2</cell><cell>-</cell></row><row><cell cols="2">Self-Att. (Trinh et al., 2018) 0.5M</cell><cell>98.9</cell><cell>97.9</cell><cell>62.2</cell><cell>-</cell></row><row><cell>TrellisNet (Bai et al., 2018b)</cell><cell>8M</cell><cell>99.20</cell><cell>98.13</cell><cell>73.42</cell><cell>1.158  ?</cell></row><row><cell>CKCNN</cell><cell>98K</cell><cell>99.31</cell><cell>98.00</cell><cell>62.25</cell><cell>-</cell></row><row><cell>CKCNN-Big</cell><cell>1M</cell><cell>99.32</cell><cell>98.54</cell><cell>63.74</cell><cell>1.045  ?</cell></row><row><cell>?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Evaluation on stress tasks. marks if the problem has been solved.</figDesc><table><row><cell>MODEL SIZE</cell><cell>SEQ. LENGTH 100 200 1000 3000 6000</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Test accuracies on CT, SC and SC_raw.</figDesc><table><row><cell>MODEL</cell><cell>SIZE</cell><cell>CT</cell><cell>SC</cell><cell>SC_RAW</cell></row><row><cell>GRU-ODE (De Brouwer et al., 2019)</cell><cell>89K</cell><cell>96.2</cell><cell>44.8</cell><cell>? 10.0</cell></row><row><cell>GRU-?t (Kidger et al., 2020)</cell><cell>89K</cell><cell>97.8</cell><cell>20.0</cell><cell>? 10.0</cell></row><row><cell>GRU-D Che et al. (2018)</cell><cell>89K</cell><cell>95.9</cell><cell>23.9</cell><cell>? 10.0</cell></row><row><cell>ODE-RNN (Rubanova et al., 2019)</cell><cell>88K</cell><cell>97.1</cell><cell>93.2</cell><cell>? 10.0</cell></row><row><cell>NCDE (Kidger et al., 2020)</cell><cell>89K</cell><cell>98.8</cell><cell>88.5</cell><cell>? 10.0</cell></row><row><cell>CKCNN</cell><cell cols="3">100K 99.53 95.27</cell><cell>71.66</cell></row></table><note>our small CKCNN obtains similar results to a self-attention model 5? bigger, and our wider variant improves performance by an additional 1%. Our best results are obtained with an even wider model (2.5M params) with which an accuracy of 65.59% is obtained. On Char-level PTB a CKCNN with 3M parameters outperforms all models considered as well as the state-of-the-art: Mogrifier LSTMs (Melis et al., 2019), while being 13.3? smaller.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Test results on irregular data.</figDesc><table><row><cell>MODEL</cell><cell>PHYSIONET AUC</cell><cell cols="4">CHARACTERTRAJECTORIES (0%) (30%) (50%) (70%)</cell><cell cols="4">SPEECHCOMMANDS_RAW (0%) (30%) (50%) (70%)</cell></row><row><cell>GRU-ODE</cell><cell>0.852</cell><cell>96.2</cell><cell>92.6</cell><cell>86.7</cell><cell>89.9</cell><cell cols="2">? 10.0 ? 10.0</cell><cell>? 10.0</cell><cell>? 10.0</cell></row><row><cell>GRU-?t</cell><cell>0.878</cell><cell>97.8</cell><cell>93.6</cell><cell>91.3</cell><cell>90.4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GRU-D ODE-RNN</cell><cell>0.871 0.874</cell><cell>95.9 97.1</cell><cell>94.2 95.4</cell><cell>90.2 96.0</cell><cell>91.9 95.3</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell></row><row><cell>NCDE</cell><cell>0.880</cell><cell>98.8</cell><cell>98.7</cell><cell>98.8</cell><cell>98.6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CKCNN</cell><cell>0.895</cell><cell>99.53</cell><cell>99.30</cell><cell>98.83</cell><cell>98.14</cell><cell>71.66</cell><cell>63.46</cell><cell>60.55</cell><cell>57.50</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Results for different train and test resolutions. Fractions depict resolutions proportional to the original one of the dataset. The accuracy of all models on the original resolution surpasses 90%. To conclude, we validate CKCNNs for irregularly-sampled data. To this end, consider the PhysioNet sepsis challenge<ref type="bibr" target="#b48">(Reyna et al., 2019)</ref> as well as the CT dataset with drops of 30%, 50% and 70% of the data as in</figDesc><table><row><cell></cell><cell></cell><cell cols="3">CKCNN -SIZE=100K</cell><cell></cell><cell></cell></row><row><cell cols="3">DATASET TRAIN FREQ.</cell><cell></cell><cell cols="2">TEST FREQ.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>1</cell><cell>1 2</cell><cell>1 4</cell><cell>1 8</cell><cell>1 16</cell></row><row><cell></cell><cell>1</cell><cell cols="5">99.53 99.30 99.30 95.80 76.45</cell></row><row><cell>CT</cell><cell>1 2</cell><cell cols="5">98.83 99.07 98.37 96.97 80.42</cell></row><row><cell></cell><cell>1 4</cell><cell cols="5">96.74 96.97 99.30 98.83 84.85</cell></row><row><cell></cell><cell>1 8</cell><cell cols="5">96.97 97.44 97.20 99.30 73.43</cell></row><row><cell></cell><cell>1</cell><cell cols="5">71.66 65.96 52.11 40.33 30.87</cell></row><row><cell>SC_RAW</cell><cell>1 2</cell><cell cols="5">72.09 72.06 69.03 63.00 29.67</cell></row><row><cell></cell><cell>1 4</cell><cell cols="5">68.25 68.40 69.47 67.09 37.91</cell></row><row><cell></cell><cell>1 8</cell><cell cols="5">40.48 42.00 54.91 66.44 22.29</cell></row><row><cell cols="6">MODEL COMPARISON -CHARACTER TRAJECTORIES</cell><cell></cell></row><row><cell cols="7">MODEL GRU-D ODE-RNN LMU NCDE HIPPO CKCNN</cell></row><row><cell>1 ? 1 2</cell><cell>23.1</cell><cell>41.8</cell><cell>44.7</cell><cell>6.0</cell><cell>88.8</cell><cell>99.30</cell></row><row><cell>1 2 ? 1</cell><cell>25.5</cell><cell>31.5</cell><cell>11.3</cell><cell>13.1</cell><cell>90.1</cell><cell>98.83</cell></row><row><cell>Irregularly-sampled data.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Parameter-efficient large convolutional kernels. CKConvs construct large complex kernels with a fixed parameter budget. For large input sequences, this results in large savings in the number of parameters required to construct global kernels with conventional CNNs. For sequences from the pMNIST (length = 784) and SC_raw (length = 16000) datasets, a conventional CNN with global kernels would require 2.14M and 46.68M of parameters, respectively, for a model equivalent to our CKCNN (100K). In other words, our kernel parameterization allows us to construct CKCNNs that are 21, 84 and 445, 71 times smaller than corresponding conventional CNNs for these datasets. Detailed exploration on the effect of our efficient continuous kernel parameterizations in optimization, overfitting and generalization is an interesting direction for future research. Is depth important? Shallow global memory horizons. Our results are obtained with CKCNNs built with two residual blocks only. Additional experiments (Appx. D.2) indicate that our models do not benefit from larger depth, and suggest that CKCNNs do not rely on very deep features.</figDesc><table /><note>Though further analysis is required to draw consistent conclusions, it is intriguing to explore if it is sufficient to equip neural networks with global memory horizons even if this happens in a shallow manner.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Test accuracies of CKCNNs with multiple MLP ? nonlinearities. Model size = 100K.</figDesc><table><row><cell>NON-LINEARITY</cell><cell>SMNIST</cell><cell cols="2">DATASET PMNIST</cell><cell>SC</cell><cell>SC_RAW</cell></row><row><cell>RELU</cell><cell>81.21</cell><cell>59.15</cell><cell cols="2">94.97</cell><cell>49.15</cell></row><row><cell>LEAKYRELU</cell><cell>80.57</cell><cell>55.85</cell><cell cols="2">95.03</cell><cell>38.67</cell></row><row><cell>SWISH</cell><cell>85.20</cell><cell>61.77</cell><cell cols="2">93.43</cell><cell>62.23</cell></row><row><cell>SINE</cell><cell>99.31</cell><cell>98.00</cell><cell cols="2">95.27</cell><cell>71.66</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Test accuracy of CKCNNs for various depths and widths.</figDesc><table><row><cell></cell><cell></cell><cell>PMNIST</cell><cell></cell><cell></cell></row><row><cell>DEPTH</cell><cell cols="4">FIXED WIDTH SIZE ACC.(%) SIZE ACC.(%) FIXED SIZE</cell></row><row><cell>2 Blocks</cell><cell>98k</cell><cell>99.21</cell><cell>98k</cell><cell>99.21</cell></row><row><cell>4 Blocks</cell><cell>225k</cell><cell>99.26</cell><cell>95k</cell><cell>99.19</cell></row><row><cell>8 Blocks</cell><cell>480k</cell><cell>99.29</cell><cell>105k</cell><cell>99.12</cell></row><row><cell cols="2">16 Blocks 990k</cell><cell>99.19</cell><cell>107k</cell><cell>99.02</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Figure 7: Function approximation via ReLU, LeakyReLU, Swish and Sine networks. All network variants perform a decent job in approximating simple functions. However, for non-linear, nonsmooth functions, all networks using nonlinearities other than Sine provide very poor approximations. Interestingly, the uniform knot initialization proposed in Sec. 4.2 provides consistent improvements for all network variants. However, despite this improvement, the approximation results remain insufficient. Contrarily, Sine networks quickly and seamlessly approximate all functions. All network configurations are equal up to the non-linearities used.of CKCNNs. To analyze this, we compare deep and shallow CKCNNs with the same architecture for equal width, and equal number of parameters.Our results (Tab. 7) indicate that deep CKCNNs do not provide improvements over shallow CKCNNs. In fact, deep CKCNNs of fixed size underperform their shallow counterparts. This is an interesting results as shallow CKCNNs do not strongly rely on deep-wise compositionality of features, which is largely considered indispensable in deep learning.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>Hyperparameter specifications of the best performing CKCNN models. Hyperparameter values for the classification and varying sampling rate tasks. For hyperparameters w.r.t. irregularly-sampled data please see Tab. 9.</figDesc><table><row><cell>PARAMS.</cell><cell cols="2">COPY MEMORY ADDING PROBLEM</cell><cell>SMNIST Small / Big</cell><cell>PMNIST Small / Big</cell><cell>SCIFAR10 Small / Big</cell><cell>CT  ?</cell><cell>SC</cell><cell>SC_RAW  ?</cell><cell>PTB</cell></row><row><cell>Epochs</cell><cell>See Appx. E.4</cell><cell>See Appx. E.4</cell><cell>200</cell><cell>200</cell><cell>200</cell><cell>200</cell><cell>200</cell><cell>300</cell><cell>200</cell></row><row><cell>Batch Size</cell><cell>32</cell><cell>32</cell><cell>64</cell><cell>64</cell><cell>64</cell><cell>32</cell><cell>64</cell><cell>32</cell><cell>24</cell></row><row><cell>Optimizer</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell><cell>Adam</cell></row><row><cell>Learning Rate</cell><cell>5e-4</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.002</cell></row><row><cell># Blocks</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>2</cell></row><row><cell>Hidden Size</cell><cell>10</cell><cell>25</cell><cell>30 / 100</cell><cell>30 / 100</cell><cell>30 / 100</cell><cell>30</cell><cell>30</cell><cell>30</cell><cell>128</cell></row><row><cell>?0</cell><cell>See Appx. E.4</cell><cell>See Appx. E.4</cell><cell>31.09 / 30.5</cell><cell>43.46 / 42.16</cell><cell>25.67</cell><cell>21.45</cell><cell>30.90</cell><cell>39.45</cell><cell>25.78</cell></row><row><cell>Dropout</cell><cell>-</cell><cell>-</cell><cell>0.1 / 0.2</cell><cell>-</cell><cell>0.2 / 0.3</cell><cell>0.1</cell><cell>0.2</cell><cell>-</cell><cell>-</cell></row><row><cell>Input Dropout</cell><cell>-</cell><cell>-</cell><cell>0.1 / 0.2</cell><cell>0.1 / 0.2</cell><cell>0.0 / 0.0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.1</cell></row><row><cell>Embedding Dropout</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.1</cell></row><row><cell>Weight Dropout</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-/ 0.1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Weight Decay</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-/ 1e-4</cell><cell>-</cell><cell>-</cell><cell>1e-4</cell><cell>1e-6</cell></row><row><cell>Scheduler</cell><cell>-</cell><cell>-</cell><cell>Plateau</cell><cell>Plateau</cell><cell>Plateau</cell><cell>Plateau</cell><cell>Plateau</cell><cell>Plateau</cell><cell>Plateau</cell></row><row><cell>Patience</cell><cell>-</cell><cell>-</cell><cell>20</cell><cell>20</cell><cell>20</cell><cell>20</cell><cell>15</cell><cell>20</cell><cell>5</cell></row><row><cell>Scheduler Decay</cell><cell>-</cell><cell>-</cell><cell>5</cell><cell>5</cell><cell>5</cell><cell>5</cell><cell>5</cell><cell>5</cell><cell>5</cell></row><row><cell>Model Size</cell><cell>15.52K</cell><cell>70.59K</cell><cell cols="5">98.29K / 1.03M 98.29K / 1.03M 100.04K / 1.04M 100.67K 118.24K</cell><cell>98.29K</cell><cell>1.8M</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>?</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 :</head><label>9</label><figDesc>Hyperparameter values for experiments on irregularly sampled data. Non-listed parameters correspond to those in Tab. 8.</figDesc><table><row><cell>PARAMS.</cell><cell>PHYSIONET</cell><cell cols="6">CT (30%) (50%) (70%) (30%) (50%) (70%) SC_RAW</cell></row><row><cell>?0</cell><cell>4.38</cell><cell>17.24</cell><cell>12.00</cell><cell>4.24</cell><cell>35.66</cell><cell>31.70</cell><cell>25.29</cell></row><row><cell>Dropout</cell><cell>0.0</cell><cell>0.2</cell><cell>0.2</cell><cell>0.0</cell><cell>0.1</cell><cell>0</cell><cell>0</cell></row><row><cell>Weight Decay</cell><cell>0.0</cell><cell>0.0</cell><cell>1e-4</cell><cell>0.0</cell><cell>1e-4</cell><cell>1e-4</cell><cell>1e-4</cell></row><row><cell>Batch Size</cell><cell>1024</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model Size</cell><cell>175.71K</cell><cell></cell><cell>101.75K</cell><cell></cell><cell></cell><cell>99.34K</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Our code is publicly available at https://github.com/dwromero/ckconv.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We discard h(?1) as it only describes the initialization of h.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">This is why b=0 is common in regular initialization schemes.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We gratefully acknowledge Gabriel Dernbach for interesting analyses on the knot distribution of ReLU networks. We thank Emiel van Krieken and Ali el Hasouni as well for interesting questions and motivating comments at the beginning of this project. This work was carried out on the Dutch national einfrastructure with the support of SURF Cooperative</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unitary evolution recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amar</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1120" to="1128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The uea multivariate time series classification archive</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Bagnall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anh</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Dau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lines</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Large</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bostrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eamonn</forename><surname>Southam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Keogh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.00075</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">An empirical evaluation of generic convolutional and recurrent networks for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01271</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Trellis networks for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaojie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.06682</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Mad max: Affine spline insights into deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Randall</forename><surname>Balestriero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Baraniuk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.06576</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning long-term dependencies with gradient descent is difficult</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrice</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="166" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Experiment tracking with weights and biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Biewald</surname></persName>
		</author>
		<ptr target="https://www.wandb.com/.Softwareavailablefromwandb.com" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dilated recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Witbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Hasegawa-Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="77" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Recurrent neural networks for multivariate time series with missing values</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengping</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Purushotham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sontag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Empirical evaluation of gated recurrent neural networks on sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3555</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01781</idno>
		<title level="m">Lo?c Barrault, and Yann Lecun. Very deep convolutional networks for text classification</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Very deep convolutional neural networks for raw waveforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhui</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samarjit</forename><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="421" to="425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.02860</idno>
		<title level="m">Transformer-xl: Attentive language models beyond a fixed-length context</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Language modeling with gated convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grangier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="933" to="941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Gru-ode-bayes: Continuous modeling of sporadically-observed time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaak</forename><surname>Edward De Brouwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Simm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Arany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Moreau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7379" to="7390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Deepsphere: a graph-based spherical cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?l</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martino</forename><surname>Milani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?rick</forename><surname>Gusset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathana?l</forename><surname>Perraudin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15000</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emilien</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Doucet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.04776</idno>
		<title level="m">Generative models as distributions of functions</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Generalizing convolutional neural networks for equivariance to lie groups on arbitrary continuous data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Finzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.12880</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">M?moire sur la propagation de la chaleur dans les corps solides, pr?sent? le 21 d?cembre 1807 ? l&apos;institut national-nouveau bulletin des sciences par la soci?t? philomatique de paris. i</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fourier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Paris: First European Conference on Signal Analysis and Prediction</title>
		<imprint>
			<date type="published" when="1807" />
			<biblScope unit="page" from="17" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Se (3)-transformers: 3d roto-translation equivariant attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fabian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">E</forename><surname>Fuchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10503</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Luis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Glass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Plamen</forename><forename type="middle">Ch</forename><surname>Hausdorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ivanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">B</forename><surname>Mietus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Kang</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H Eugene</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stanley</surname></persName>
		</author>
		<title level="m">Physiobank, physiotoolkit, and physionet: components of a new research resource for complex physiologic signals. circulation</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="215" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Speech recognition with deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Abdel-Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE international conference on acoustics, speech and signal processing</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="6645" to="6649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atri</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.07669</idno>
		<title level="m">Recurrent memory with optimal polynomial projections</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Improving the gating mechanism of recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Paine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3800" to="3809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Hanin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rolnick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09021</idno>
		<title level="m">Complexity of linear regions in deep networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Untersuchungen zu dynamischen neuronalen netzen. Diploma, Technische Universit?t M?nchen</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">91</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Randla-net: Efficient semantic segmentation of large-scale point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhai</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Trigoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Markham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11108" to="11117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Lietransformer: Equivariant self-attention for lie groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charline</forename><forename type="middle">Le</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheheryar</forename><surname>Zaidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emilien</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjik</forename><surname>Kim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.10885</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Neural controlled differential equations for irregular time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Kidger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Morrill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Lyons</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.08926</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A simple way to initialize recurrent networks of rectified linear units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.00941</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Independently recurrent neural network (indrnn): Building a longer and deeper rnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanqing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbo</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5457" to="5466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Building a large annotated corpus of english: The penn treebank. Using Large Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page">273</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?bor</forename><surname>Melis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom??</forename><surname>Ko?isk?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.01792</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Mogrifier lstm. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Occupancy networks: Learning 3d reconstruction in function space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Oechsle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Niemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4460" to="4470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Mildenhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pratul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Tancik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nerf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.08934</idno>
		<title level="m">Representing scenes as neural radiance fields for view synthesis</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On the number of linear regions of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Guido F Montufar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2924" to="2932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Icml</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiga</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03499</idno>
	</analytic>
	<monogr>
		<title level="m">Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. Wavenet: A generative model for raw audio</title>
		<meeting><address><addrLine>Alex Graves</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deepsdf: Learning continuous signed distance functions for shape representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeong Joon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Florence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Straub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Lovegrove</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="165" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">How to construct deep recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6026</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.05941</idno>
		<title level="m">Searching for activation functions</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Stand-alone self-attention in vision models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwan</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05909</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Early prediction of sepsis from clinical data: the physionet/computing in cardiology challenge 2019</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Reyna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Josef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Seyedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Supreeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Shashikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Westover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shamim</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gari D</forename><surname>Nemati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing in Cardiology (CinC)</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2019" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Group equivariant stand-alone self-attention for vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Baptiste</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cordonnier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.00977</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">J</forename><surname>David W Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoogendoorn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.05259</idno>
		<title level="m">Wavelet networks: Scale equivariant learning from raw waveforms</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Latent ordinary differential equations for irregularly-sampled time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5320" to="5330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Learning internal representations by error propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>David E Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald J</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
		<respStmt>
			<orgName>California Univ San Diego La Jolla Inst for Cognitive Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Weight normalization: A simple reparameterization to accelerate training of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kingma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.07868</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Schnet: A continuous-filter convolutional neural network for modeling quantum interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristof</forename><surname>Sch?tt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huziel Enoc Sauceda</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Chmiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Tkatchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="991" to="1001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiyi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Niemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Graf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02442</idno>
		<title level="m">Generative radiance fields for 3d-aware image synthesis</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Bounding and counting linear regions of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thiago</forename><surname>Serra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Tjandraatmadja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikumar</forename><surname>Ramalingam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4558" to="4566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">From points to parts: 3d object detection from point cloud with part-aware and part-aggregation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.03670</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Dynamic edge-conditioned filters in convolutional neural networks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Simonovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3693" to="3702" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Implicit neural representations with periodic activation functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Sitzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Martel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lindell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Wetzstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Tancik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pratul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Mildenhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nithin</forename><surname>Fridovich-Keil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Utkarsh</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ren</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10739</idno>
		<title level="m">Fourier features let networks learn high frequency functions in low dimensional domains</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathaniel</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tess</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lusann</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Kohlhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Riley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08219</idno>
		<title level="m">Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Trieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Trinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.00144</idno>
		<title level="m">Learning longer-term dependencies in rnns with auxiliary losses</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Deep parametric continuous convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chiu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Pokrovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2589" to="2597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pete</forename><surname>Warden</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03209</idno>
		<title level="m">Speech commands: A dataset for limited-vocabulary speech recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Backpropagation through time: what it does and how to do it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Pointconv: Deep convolutional networks on 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fuxin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9621" to="9630" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Empirical evaluation of rectified activations in convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00853</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Do rnn and lstm have long memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiqing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjie</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangjian</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11365" to="11375" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
