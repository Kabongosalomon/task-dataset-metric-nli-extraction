<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SELECTIVE RESIDUAL M-NET FOR REAL IMAGE DENOISING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Mao</forename><surname>Fan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Jung</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan-Hsien</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National Taichung University of Science and Technology</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical Engineering and Graduate Institute of Communication Engineering</orgName>
								<orgName type="institution">National Chung Hsing University</orgName>
								<address>
									<country key="TW">Taiwan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SELECTIVE RESIDUAL M-NET FOR REAL IMAGE DENOISING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Image denoising</term>
					<term>selective kernel</term>
					<term>resid- ual block</term>
					<term>hierarchical architecture</term>
					<term>M-Net</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Image restoration is a low-level vision task which is to restore degraded images to noise-free images. With the success of deep neural networks, the convolutional neural networks surpass the traditional restoration methods and become the mainstream in the computer vision area. To advance the performance of denoising algorithms, we propose a blind real image denoising network (SRMNet) by employing a hierarchical architecture improved from U-Net. Specifically, we use a selective kernel with residual block on the hierarchical structure called M-Net to enrich the multi-scale semantic information. Furthermore, our SRMNet has competitive performance results on two synthetic and two real-world noisy datasets in terms of quantitative metrics and visual quality. The source code and pretrained model are available at https: //github.com/TentativeGitHub/SRMNet.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Image denoising is a challenging ill-posed problem which also plays an important role in the pre-process of high-level vision task. In general, a corrupted image Y could be represented as:</p><formula xml:id="formula_0">Y = D(X) + n,<label>(1)</label></formula><p>where X is a clean image, D(?) denotes the degradation function and n means the additive noise. Traditional model-based denoising methods, such as block-matching and 3D filtering (BM3D) <ref type="bibr" target="#b0">[1]</ref>, non-local means (NLM) <ref type="bibr" target="#b1">[2]</ref> are all based on the information of image priors. Although the conventional prior-based methods could handle most of denoising tasks and achieve acceptable performances, the key problems like computationally expensive and time-consuming hamper the efficiency of model-based methods.</p><p>In recent years, learning-based methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref> surpass traditional prior-based methods in terms of inference time and denoising performance. The performance gain of learningbased methods especially CNN over the others is mainly attributed to their elaborately designed model or block. For example, residual learning <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b2">3]</ref>, dense connection <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8]</ref>, residual dense block <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, attention mechanisms <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref>, channel attention block <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14]</ref>, and hierarchical architecture <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>. However, these complex architectures cause the restoration models to waste more computation and the improvement is only a little.</p><p>In this paper, we try to balance between the accuracy and computational efficiency of the model. First, we propose the hierarchical selective residual architecture which is based on the residual dense block with a more efficiency structure named selective residual block (SRB). Moreover, we use the multi-scale feature fusion with two different sampling methods (pixel shuffle <ref type="bibr" target="#b17">[18]</ref>, bilinear) based on the proposed M-Net to extract adequate and useful spatial feature information. For the reconstruction process, instead of using concatenation to fuse the feature maps with different resolutions, we adopt the selective kernel feature fusion (SKFF) <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref> to efficiently combine the features. Overall, the main contributions of this paper can be summarized as follows:</p><p>? We propose the novel hierarchical architecture (M-Net) to denoise for both synthesized additive white Gaussian noise (AWGN) and real-world noise.</p><p>? We propose the efficient feature extraction block called selective residual block which is improved from the residual dense block for image super-resolution.</p><p>? We experiment on two synthetic image datasets and two real-world noisy datasets to demonstrate that our proposed model achieves the state-of-the-art in image denoising quantitatively and qualitatively even with less computational complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>In this section, we first are going to discuss the development of denoising. Then, we will describe the hierarchical architecture and the selective kernel which we apply in our proposed selective residual block.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Image denoising</head><p>As aforementioned, traditional image denoising approaches are generally based on image priors or algorithms which are also called model-based methods, such as self-similarity <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b20">21]</ref>, spare coding <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref> and dictionary learning <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b23">24]</ref>. Currently, CNN-based denoisers have demonstrated state-of-the-art results <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>. Moreover, the denoise models from <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b24">25]</ref> only deal with signal-independent noise (e.g., AWGN, read noise), while the model from <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref> have the ability to process the real-world signal-dependent noise (e.g., shot noise, thermal noise).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Hierarchical architecture</head><p>The hierarchical architecture is used to enrich the spatial information by extracting different sizes of features and make semantic information have more diversity. The most wellknown hierarchical structure is the U-Net <ref type="bibr" target="#b14">[15]</ref> which has the great contribution from high-level to low-level vision tasks including image segmentation <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31]</ref>, image restoration <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b31">32]</ref>, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Selective Kernel Network</head><p>Li et al. proposed the selective kernel convolution that has two branches. One of the path utilizes normal naive 3?3 convolution kernel to extract features, and the other path adopts different kernel size (e.g. 5 ? 5, 7 ? 7) to obtain the larger receptive field. At the end of selective kernel convolution, they use softmax activation function to acquire the weights for two different features maps. Zamir et al. <ref type="bibr" target="#b19">[20]</ref> were inspired by <ref type="bibr" target="#b18">[19]</ref> and applied it to multi-scale feature fusion for image enhancement tasks, which also achieve good results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PROPOSED METHOD</head><p>In this section, we mainly introduce the proposed Selective Residual M-Net (SRMNet), and provide detailed explanations for each component of the model in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">M-Net</head><p>The M-Net architecture is first proposed for medical image segmentation <ref type="bibr" target="#b32">[33]</ref>. Adiga et al. <ref type="bibr" target="#b33">[34]</ref> use the same framework for fingerprint image denoising and also get good results. Compared with above two models, our proposed SRM-Net has two improvements. 1) More diversity and plentiful multi-scale cascading features. The original M-Net used 2 ? 2 max-pooling in both U-Net path and gatepost path, and then combined these two features together. Our SRMNet use pixel un-shuffle down-sampling in U-Net path and bilinear down-sampling for gatepost path, which makes the cascading features have more diversity. 2) Using different feature fusion methods to summarize the information in the decoder (reconstruction process). Actually, original M-Net has highdimensional cascading features, especially the shallow layer in the model, which makes the M-Net have large number of parameters and high computational complexity. Therefore, they use some techniques such as batch normalization, reducing the size of input images and the dimension of input feature maps. In other words, the original M-Net is inappropriate to be directly applied to image denoising. To solve this problem, we use the selective kernel feature fusion (SKFF) method <ref type="bibr" target="#b19">[20]</ref> which does not concatenate each feature map but aggregates the weighting features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">SRMNet</head><p>The proposed SRMNet for image denoising is shown in <ref type="figure" target="#fig_0">Fig.  1</ref>. We first use 3 ? 3 weight sharing convolution in each resolution of corrupted input image acquired by doing the bilinear down-sampling from original-resolution input. Each layer has the proposed selective residual block (SRB) to extract high-level semantic information (more structure details will be illustrated in the next subsection). Then, we choose pixel unshuffled method as our down-sampling module at the end of SRB to obtain multi-scale feature maps. After that, the feature maps are concatenated with previous shallow features from bilinear down-sampling and keep going as normal U-Net process. The main purpose of choosing two different down-sample methods (pixel unshuffled and bilinear) is to make the cascaded features have more semantic information. Finally, using the SKFF (upper part of <ref type="figure" target="#fig_1">Fig. 2</ref>) to integrate features with different scales to reconstruct the denoised image.</p><p>We optimize our SRMNet end-to-end with the Charbonnier loss <ref type="bibr" target="#b34">[35]</ref> for image denoising as follows:</p><formula xml:id="formula_1">L char = ||X ? X|| 2 + ? 2 ,<label>(2)</label></formula><p>whereX, X ? R B?C?H?W means the denoised and ground-truth images, respectively. B is the batch size of training data, C is the number of feature channels, H and W are the size of images. The constant ? in Eq.(2) are empirically set to 10 ?3 . <ref type="figure" target="#fig_1">Fig. 2</ref> shows the architecture of the proposed SRB which is improved from the residual dense block (RDB) <ref type="bibr" target="#b8">[9]</ref>. In the framework of SRB, each residual block has two input features (f r , f m ? R C?H?W in <ref type="figure" target="#fig_1">Fig. 2</ref>) which denote the residual feature and mainstream feature, respectively. These two features will do the SKFF by multiplying the corresponding feature descriptor vectors (v 1 , v 2 ? R C?1?1 which are generated from channel-wise statistics s ? R C?1?1 ) to get the weighted features (f r ,f m ? R C?1?1 ). Finally, we aggregate two channel-weighted featuresf r ,f m together to acquire the output feature f o of single residual block. After a few residual blocks (e.g., 3), we use a 3 ? 3 convolution and add the long skip connection with 1 ? 1 convolution between the input and output. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Selective Residual Block</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Resizing Module</head><p>As for resizing module, we simply use bilinear downsampling for input images Y ? R 3?H?W (Y is the same as Eq. (1)), and use pixel unshuffled module shown in <ref type="figure" target="#fig_2">Fig. 3</ref> for shallow features ? R C?H?W after 3 ? 3 convolution. Note that the size of the feature channel (C) before entering the resizing module is the same as output channel size but with smaller resolution (e.g. W/2 ? H/2). It should be noticed that the the feature map of lower layer contains both bilinear and pixel unshuffled features but the in-gredients of bilinear features are obvious less than pixel unshuffled features. It may cause the unbalanced problem. In fact, the above unbalanced feature map will be passed through the SRB which could solve the unbalanced problem by increasing the weight of bilinear features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiment Setup</head><p>Implementation Details. Our SRMNet is an end-to-end model and trained from scratch. The experiments conducted in this paper are implemented by PyTorch 1.8.0 with single NVIDIA GTX 1080Ti GPU. Evaluation Metrics. For the quantitative comparisons, we consider the Peak Signal-to-Noise Ratio (PSNR) and Structure Similarity (SSIM) Index metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experiment Datasets</head><p>Gaussian Color Image Denoising. For Gaussian denoising, we use the same experimental setup as image denoising <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref> and train our model on image super-resolution DIV2K <ref type="bibr" target="#b37">[38]</ref> dataset which has 800 and 100 high-quality (the average resolution is about 1920 ? 1080) images for training and validation, respectively. We randomly crop 100 patches with size 256?256 for each training image and randomly add AWGN to the patches with noise level from ? = 5 to 50. Evaluation is conducted on noise levels 10, 30, 50 on CBSD68 <ref type="bibr" target="#b35">[36]</ref> and Kodak24 <ref type="bibr" target="#b36">[37]</ref>. It should be noted that our model does not know the noise level in the testing, which means SRMNet is the blind denoising model. Real-World Image Denoising. To train our SRMNet for real-world denoising, we follow <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b31">32]</ref> to use 320 highresolution images of SIDD dataset <ref type="bibr" target="#b38">[39]</ref>. Evaluations also follow aforementioned methods, which is to perform the test on 1280 validation patches from the SIDD dataset <ref type="bibr" target="#b38">[39]</ref> and 1000 patches from the DND benchmark dataset <ref type="bibr" target="#b39">[40]</ref>. The resolution of all patches is 256 ? 256 in both training and testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Image Denoising Performance</head><p>Gaussian Color Image Denoising. In <ref type="table" target="#tab_0">Table 1</ref> and <ref type="figure">Fig. 4</ref>, we compare our SRMNet with the prior-based method (e.g., BM3D <ref type="bibr" target="#b0">[1]</ref>), CNN-based methods (e.g., DnCNN <ref type="bibr" target="#b2">[3]</ref>, IrCNN <ref type="bibr" target="#b4">[5]</ref>, FFDNet <ref type="bibr" target="#b3">[4]</ref>) and the models which are based on RDB (e.g., DHDN <ref type="bibr" target="#b15">[16]</ref>, DIDN <ref type="bibr" target="#b24">[25]</ref>, RDN <ref type="bibr" target="#b8">[9]</ref>, RDUNet <ref type="bibr" target="#b16">[17]</ref>). According to <ref type="table" target="#tab_0">Table 1</ref>, we could observe three things: 1) The proposed SRMNet achieves state-of-the-art quantitative scores, especially for the difficult Gaussian noise levels (e.g., 30, 50).</p><p>2) Compared to RDB-based methods <ref type="figure">(DHDN, DIDN, RDN,  RDUNet)</ref>, our SRMNet has the least FLOPs (? 20%) among the five models, and still keeps the best scores because of the efficient SRB design. 3) The SSIM scores of the SRMNet are the best in both CBSD68 and Kodak24 datasets for each noise level, which means that our denoised images are more perceptually faithful. We think it is attributed to the M-Net design which could gain more spatial details in the training process. Real-World Image Denoising. For real image denoising, we evaluate the performance of 13 image denoising approaches on real-world noise datasets (SIDD and DND) in <ref type="table" target="#tab_2">Table 2</ref>. Compared to the previous state-of-the-art CNN-based method <ref type="bibr" target="#b19">[20]</ref> in SIDD dataset, our model gains the same scores with MIRNet but less computational complexity (e.g., FLOPs) and time cost. More specifically, <ref type="table" target="#tab_3">Table 3</ref> shows our SRMNet only use 36.3% of MIRNet's FLOPs and about three times faster than MIRNet. <ref type="figure">Fig. 4</ref> also displays the visual results for real image denoising on SIDD. Our SRMNet effectively removes noise and the denoised images are visually closer to the ground-truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>In this paper, we present the SRMNet architecture and achieve state-of-the-art performances on image denoising. The M-Net design has the advantage of enriching features with different resolutions by concatenating the results after pixel unshuffle and bilinear down-sampling. Moreover, we proposed the SRB, which is an efficient block compared with the RDB. Our future works are going to focus on different restoration tasks such as image deblurring and image deraining.  <ref type="bibr" target="#b35">[36]</ref> and Kodak24 dataset <ref type="bibr" target="#b36">[37]</ref>. The best and second best scores are highlighted and underlined, respectively. All of scores are the average values of the whole dataset. The last column shows floating-point operations per second (FLOPs) which is conducted on 256 ? 256 color images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CBSD68 [36]</head><p>Kodak24 <ref type="bibr">[</ref>    <ref type="bibr" target="#b19">[20]</ref>, MPRNet <ref type="bibr" target="#b31">[32]</ref> and our method (SRMNet). We did the test on SIDD validation set which has 1,280 patches where FLOPs are estimated on the input with shape of 1 ? 3 ? 256 ? 256. The inference times are measured on the computer equipped with NVIDIA GTX 1080Ti GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PSNR FLOPs (G) Time (ms) Speedup</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Proposed Selective Residual M-Net (SRMNet) architecture. The source code and component structure of the model could be found in the provided URL indicated in the abstract. We set the initial channel in each resolution to 96 after 3 ? 3 convolution, and totally we have 4 layers in the proposed M-Net.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Illustration of the Selective Residual Block (SRB) in our SRMNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Resizing module with pixel (un)shuffle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Gaussian color image denoising. Image denoising results on CBSD68 dataset</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Visual comparisons of image denoising on the CBSD68<ref type="bibr" target="#b35">[36]</ref> (upper row) and SIDD<ref type="bibr" target="#b38">[39]</ref> (bottom row) datasets for color Gaussian and real image denoising, respectively. Due to the page limits, more visual results for different datasets could be found in our github page.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>37]</cell><cell></cell></row><row><cell></cell><cell cols="2">? = 10</cell><cell cols="2">? = 30</cell><cell cols="2">? = 50</cell><cell></cell><cell cols="2">? = 10</cell><cell></cell><cell cols="2">? = 30</cell><cell cols="2">? = 50</cell><cell>FLOPs</cell></row><row><cell></cell><cell cols="7">PSNR SSIM PSNR SSIM PSNR SSIM</cell><cell cols="7">PSNR SSIM PSNR SSIM PSNR SSIM</cell></row><row><cell>BM3D [1]</cell><cell>35.89</cell><cell>0.951</cell><cell>29.71</cell><cell>0.843</cell><cell>27.36</cell><cell cols="2">0.763</cell><cell>33.32</cell><cell cols="2">0.956</cell><cell>27.75</cell><cell>0.773</cell><cell>25.60</cell><cell>0.686</cell><cell>-</cell></row><row><cell>IrCNN [5]</cell><cell>36.06</cell><cell>0.953</cell><cell>30.22</cell><cell>0.861</cell><cell>27.86</cell><cell cols="2">0.789</cell><cell>36.70</cell><cell cols="2">0.945</cell><cell>31.24</cell><cell>0.858</cell><cell>28.92</cell><cell>0.794</cell><cell>27G</cell></row><row><cell>FFDNet [4]</cell><cell>36.14</cell><cell>0.954</cell><cell>30.31</cell><cell>0.860</cell><cell>27.96</cell><cell cols="2">0.788</cell><cell>36.80</cell><cell cols="2">0.946</cell><cell>31.39</cell><cell>0.860</cell><cell>29.10</cell><cell>0.795</cell><cell>18G</cell></row><row><cell>DnCNN [3]</cell><cell>36.12</cell><cell>0.951</cell><cell>30.32</cell><cell>0.861</cell><cell>27.92</cell><cell cols="2">0.788</cell><cell>36.58</cell><cell cols="2">0.945</cell><cell>31.28</cell><cell>0.858</cell><cell>28.94</cell><cell>0.792</cell><cell>36G</cell></row><row><cell>DHDN [16]</cell><cell>36.05</cell><cell>0.953</cell><cell>30.12</cell><cell>0.858</cell><cell>27.71</cell><cell cols="2">0.787</cell><cell>37.30</cell><cell cols="2">0.951</cell><cell>31.98</cell><cell>0.874</cell><cell>29.72</cell><cell>0.817</cell><cell>1019G</cell></row><row><cell>RNAN [13]</cell><cell>36.43</cell><cell>-</cell><cell>30.63</cell><cell>-</cell><cell>26.83</cell><cell>-</cell><cell></cell><cell>37.24</cell><cell>-</cell><cell></cell><cell>31.86</cell><cell>-</cell><cell>29.58</cell><cell>-</cell><cell>-</cell></row><row><cell>DIDN [25]</cell><cell>36.48</cell><cell>0.957</cell><cell>30.71</cell><cell>0.870</cell><cell>28.35</cell><cell cols="2">0.804</cell><cell>37.32</cell><cell cols="2">0.950</cell><cell>31.97</cell><cell>0.872</cell><cell>29.72</cell><cell>0.816</cell><cell>1121G</cell></row><row><cell>RDN [9]</cell><cell>36.47</cell><cell>-</cell><cell>30.67</cell><cell>-</cell><cell>28.31</cell><cell>-</cell><cell></cell><cell>37.31</cell><cell>-</cell><cell></cell><cell>31.94</cell><cell>-</cell><cell>29.66</cell><cell>-</cell><cell>1490G</cell></row><row><cell>RDUNet [17]</cell><cell>36.48</cell><cell>0.951</cell><cell>30.72</cell><cell>0.872</cell><cell>28.38</cell><cell cols="2">0.807</cell><cell>37.29</cell><cell cols="2">0.951</cell><cell>31.97</cell><cell>0.874</cell><cell>29.72</cell><cell>0.818</cell><cell>807G</cell></row><row><cell>SRMNet (Ours)</cell><cell>36.46</cell><cell>0.961</cell><cell>30.72</cell><cell>0.878</cell><cell>28.38</cell><cell cols="2">0.814</cell><cell>37.29</cell><cell cols="2">0.957</cell><cell>31.97</cell><cell>0.882</cell><cell>29.72</cell><cell>0.826</cell><cell>285G</cell></row><row><cell>15.26/0.414</cell><cell cols="2">15.26/0.414</cell><cell cols="2">PSNR/SSIM</cell><cell cols="2">27.59/0.840</cell><cell></cell><cell>28.18/0.850</cell><cell></cell><cell cols="2">28.25/0.858</cell><cell cols="2">28.31/0.866</cell><cell>28.39/0.874</cell></row><row><cell>Noisy Image</cell><cell cols="2">Noisy Patch</cell><cell>Reference</cell><cell></cell><cell cols="2">DnCNN [3]</cell><cell></cell><cell>DHDN [16]</cell><cell></cell><cell></cell><cell>DIDN [25]</cell><cell cols="2">RDUNet [17]</cell><cell>SRMNet (Ours)</cell></row><row><cell>18.25/0.239</cell><cell cols="2">PSNR/SSIM</cell><cell cols="2">25.75/0.833</cell><cell cols="2">20.76/0.261</cell><cell cols="3">28.84/0.0.858</cell><cell cols="2">35.57/0.934</cell><cell cols="2">36.75/0.950</cell><cell>36.86/0.952</cell></row><row><cell>Noisy</cell><cell>Reference</cell><cell></cell><cell>BM3D [1]</cell><cell></cell><cell cols="2">DnCNN [3]</cell><cell cols="3">CBDNet [26]</cell><cell cols="2">RIDNet [27]</cell><cell cols="3">CycleISP [14]</cell><cell>SRMNet (Ours)</cell></row><row><cell>Fig. 4:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Real-world image denoising. Image denoising result on SIDD<ref type="bibr" target="#b38">[39]</ref> and DND<ref type="bibr" target="#b39">[40]</ref> datasets. * denotes the method used additional training data. The proposed SRM-Net is only trained on the SIDD images and then tested on DND.</figDesc><table><row><cell>Methods</cell><cell cols="2">SIDD [39] PSNR SSIM</cell><cell cols="2">DND [40] PSNR SSIM</cell></row><row><cell>DnCNN [3]</cell><cell>23.66</cell><cell>0.583</cell><cell>32.43</cell><cell>0.790</cell></row><row><cell>BM3D [1]</cell><cell>25.65</cell><cell>0.685</cell><cell>34.51</cell><cell>0.851</cell></row><row><cell>CBDNet  *  [26]</cell><cell>30.78</cell><cell>0.801</cell><cell>38.06</cell><cell>0.942</cell></row><row><cell>RIDNet  *  [27]</cell><cell>38.71</cell><cell>0.951</cell><cell>39.26</cell><cell>0.953</cell></row><row><cell>DAGL [41]</cell><cell>38.94</cell><cell>0.953</cell><cell>39.77</cell><cell>0.956</cell></row><row><cell>AINDNet  *  [42]</cell><cell>38.95</cell><cell>0.952</cell><cell>39.37</cell><cell>0.951</cell></row><row><cell>VDN [28]</cell><cell>39.28</cell><cell>0.956</cell><cell>39.39</cell><cell>0.952</cell></row><row><cell>DeamNet  *  [43]</cell><cell>39.35</cell><cell>0.955</cell><cell>39.63</cell><cell>0.953</cell></row><row><cell>SADNet  *  [29]</cell><cell>39.46</cell><cell>0.957</cell><cell>39.59</cell><cell>0.952</cell></row><row><cell>CycleISP  *  [14]</cell><cell>39.52</cell><cell>0.957</cell><cell>39.56</cell><cell>0.956</cell></row><row><cell>DANet+  *  [44]</cell><cell>39.47</cell><cell>0.957</cell><cell>39.58</cell><cell>0.955</cell></row><row><cell>MPRNet [32]</cell><cell>39.71</cell><cell>0.958</cell><cell>39.80</cell><cell>0.954</cell></row><row><cell>MIRNet [20]</cell><cell>39.72</cell><cell>0.959</cell><cell>39.88</cell><cell>0.956</cell></row><row><cell>SRMNet (Ours)</cell><cell>39.72</cell><cell>0.959</cell><cell>39.44</cell><cell>0.951</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Comparison of the PSNR and FLOPs for MIRNet</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image denoising with block-matching and 3d filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Processing: Algorithms and Systems, Neural Networks, and Machine Learning. International Society for Optics and Photonics</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6064</biblScope>
			<biblScope unit="page">606414</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An optimized blockwise nonlocal means denoising filter for 3-d magnetic resonance images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierrick</forename><surname>Coup?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Yger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Prima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Hellier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Kervrann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Barillot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="425" to="441" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3142" to="3155" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ffdnet: Toward a fast and flexible solution for cnn-based image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4608" to="4622" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning deep cnn denoiser prior for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3929" to="3938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Condensenet: An efficient densenet using learned group convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shichen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2752" to="2761" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Residual dense network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yapeng</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2472" to="2481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-scale residual network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juncheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faming</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kangfu</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guixu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="517" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image super-resolution using very deep residual channel attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="286" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Second-order attention network for single image superresolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianrui</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu-Tao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11065" to="11074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Residual non-local attention networks for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunpeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10082</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cycleisp: Real image restoration via improved data synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Syed Waqas Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munawar</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2696" to="2705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Densely connected hierarchical network for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bumjun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songhyun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jechang</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A residual dense u-net neural network for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Gurrola-Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Dalmau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teresa</forename><forename type="middle">E</forename><surname>Alarc?n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="31742" to="31754" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>in Proceedings</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Selective kernel networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="510" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning enriched features for real image restoration and enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Syed Waqas Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munawar</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="492" to="511" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XXV 16</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartomeu</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sparsity-based image denoising via dictionary learning and structural clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weisheng</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangming</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011. IEEE</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unnatural l0 sparse representation for natural image deblurring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shicheng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1107" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Example-based super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>William T Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Thouis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Egon C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pasztor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer graphics and Applications</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="56" to="65" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep iterative down-up cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songhyun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bumjun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jechang</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Toward convolutional blind denoising of real photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifei</forename><surname>Shi Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1712" to="1722" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Real image denoising with feature attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Barnes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3155" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Variational denoising network: Toward blind noise modeling and removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongsheng</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.11314</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Spatialadaptive network for single image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huajun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihai</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="171" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">H-denseunet: hybrid densely connected unet for liver and tumor segmentation from ct volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaomeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2663" to="2674" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Syed Waqas Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munawar</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
		<title level="m">Multi-stage progressive image restoration</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">2102</biblScope>
		</imprint>
	</monogr>
	<note>arXiv eprints</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">M-net: A convolutional neural network for deep brain structure segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayanthi</forename><surname>Sivaswamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE 14th International Symposium on Biomedical Imaging</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="437" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fpd-m-net: Fingerprint image denoising and inpainting using m-net based convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sukesh</forename><surname>Adiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayanthi</forename><surname>Sivaswamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Inpainting and Denoising Challenges</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="51" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Two deterministic half-quadratic regularization algorithms for computed imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Charbonnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laure</forename><surname>Blanc-Feraud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Barlaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 1st International Conference on Image Processing</title>
		<meeting>1st International Conference on Image Processing</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="168" to="172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doron</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Eighth IEEE International Conference on Computer Vision. ICCV</title>
		<meeting>Eighth IEEE International Conference on Computer Vision. ICCV</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Kodak lossless true color image suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Franzen</surname></persName>
		</author>
		<ptr target="http://r0k.us/graphics/kodak" />
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ntire 2017 challenge on single image super-resolution: Dataset and study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eirikur</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition workshops</title>
		<meeting>the IEEE conference on computer vision and pattern recognition workshops</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="126" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A high-quality denoising dataset for smartphone cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelrahman</forename><surname>Abdelhamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1692" to="1700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Benchmarking denoising algorithms with real photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Plotz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1586" to="1595" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dynamic attentive graph learning for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoyuan</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="4328" to="4337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Transfer learning from synthetic to real-noise denoising with adaptive instance normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonsik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jae</forename><forename type="middle">Woong</forename><surname>Soh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nam</forename><forename type="middle">Ik</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3482" to="3492" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Adaptive consistency prior based deep network for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohai</forename><surname>Chao Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuncheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8596" to="8606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Dual adversarial network: Toward real-world noise removal and noise generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongsheng</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="41" to="58" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
