<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Continual Learning of Context-dependent Processing in Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-06-27">27 Jun 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanxiong</forename><surname>Zeng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">Brainnetome Center and National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">Brainnetome Center and National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Cui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">Brainnetome Center and National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>Yu</surname></persName>
							<email>shan.yu@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">Brainnetome Center and National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Center for Excellence in Brain Science and Intelligence Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Continual Learning of Context-dependent Processing in Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-06-27">27 Jun 2021</date>
						</imprint>
					</monogr>
					<note>* These authors contributed equally to this work. ? Correspondence</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep neural networks (DNNs) are powerful tools in learning sophisticated but fixed mapping rules between inputs and outputs, thereby limiting their application in more complex and dynamic situations in which the mapping rules are not kept the same but changing according to different contexts. To lift such limits, we developed a novel approach involving a learning algorithm, called orthogonal weights modification (OWM), with the addition of a context-dependent processing (CDP) module. We demonstrated that with OWM to overcome the problem of catastrophic forgetting, and the CDP module to learn how to reuse a feature representation and a classifier for different contexts, a single network can acquire numerous context-dependent mapping rules in an online and continual manner, with as few as ?10 samples to learn each. This should enable highly compact systems to gradually learn myriad regularities of the real world and eventually behave appropriately within it.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>One of the hallmarks of high-level intelligence is flexibility <ref type="bibr" target="#b0">[1]</ref>. Humans and non-human priamtes can respond differently to the same stimulus under different contexts, e.g., different goals, environments, and internal states <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>. Such an ability, named cognitive control, enables us to dynamically map sensory inputs to different actions in a context-dependent way <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>, thereby allowing primates to behave appropriately in an unlimited number of situations with limited behavioral repertoire <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. However, this flexible, context-dependent processing is quite different to that found in current artificial deep neural networks (DNNs). DNNs are very powerful in extracting high-level features from raw sensory data and learning sophisticated mapping rules for pattern detection, recognition, and classification <ref type="bibr" target="#b10">[11]</ref>. In most networks, however, the outputs are largely dictated by sensory inputs, exhibiting stereotyped inputoutput mappings that are usually fixed once training is complete. Therefore, current DNNs lack sufficient flexibility to work in complex situations in which 1) the mapping rules change according to context and 2) these rules need to be learned sequentially when encountered from a small number of learning trials. This constitutes a significant gap in the abilities between current DNNs and primate brains.</p><p>In the present study, we propose an approach, including an orthogonal weight modification (OWM) algorithm and a context-dependent processing (CDP) module, that enables a neural network to progressively learn various mapping rules in a context-dependent way. We demonstrate that with OWM to protect previously acquired knowledge, the networks could sequentially learn up to thousands of different mapping rules without interference, and needing as few as ?10 samples to learn each. In addition, by using the CDP module to enable contextual information to modulate the representation of sensory features, a network can learn different, context-specific mappings for even identical stimuli. Taken together, our proposed approach can teach a single network numerous context-dependent mapping rules in an online and continual manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">ORTHOGONAL WEIGHTS MODIFICATION (OWM)</head><p>The first step towards flexible context-dependent processing is to incorporate efficient and scalable continual learning, i.e., learning different mappings sequentially, one at a time. Such an ability is crucial to humans as well as artificial intelligence agents for two reasons: 1) there are too many possible contexts to learn concurrently, and 2) useful mappings cannot be pre-determined but must be learned when corresponding contexts are encountered. The main obstacle to achieve continual learning is that conventional neural network models suffer from catastrophic forgetting, i.e., training a model with new tasks interferes with previously learned knowledge and leads to significantly decreases on the performance of previously learned tasks <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref>. To avoid catastrophic forgetting, we developed the OWM method. Specifically, when training a network for new tasks, its weights can only be modified in the direction orthogonal to the subspace spanned by all previously learned inputs (termed the input space hereafter) ( <ref type="figure">Fig. 1a</ref> and <ref type="figure">Supplementary Fig. 1</ref>). This ensures that new learning processes do not interfere with previously learned tasks, as weight changes in the network as a whole do not interact with old inputs. Consequently, combined with a gradient descent-based search, the OWM helps the network to find a weight configuration that can accomplish new tasks while ensuring the performance of learned tasks remains unchanged <ref type="figure">(Fig. 1b</ref>). This is achieved by first constructing a projector used to find the direction orthogonal to the input space: P = I ? A A T A + ?I ?1 A, where matrix A consists of all previously trained input vectors as its columns A = [x 1 , ? ? ? , x n ] and I is a unit matrix multiplied by a relatively small constant ?. The learning-induced modification of weights is then determined by ?W = ?P?W BP , where ? is the learning rate and ?W BP is the weights adjustment calculated according to the standard backpropagation. To calculate P, an iterative method can be used (see Methods). Thus, the algorithm does not need to store all previous inputs A. Instead, only the current inputs and projector for the last task are needed. This iterative method is related to the Recursive Least Square (RLS) algorithm <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref> (see Supplementary Information for the discussion), which can be used to train feedforward and recurrent neural networks to achieve fast convergence <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>, tame chaotic activities <ref type="bibr" target="#b19">[20]</ref> and avoid interference between consecutively loaded patterns or tasks <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>.</p><p>We first tested the performance of the OWM on several benchmark tasks of continual learning. Shuffled and disjoint MNIST experiments, in which different tasks involving recognition of handwritten digits need to be learned sequentially (see Methods and Supplementary Information for details regarding the datasets used in this study), were conducted on the feedforward network with the rectified linear unit (ReLU) <ref type="bibr" target="#b22">[23]</ref>. The OWM was used to train the entire multi-layer networks. For 3-or 10-task shuffled and 2-task disjoint experiments, OWM resulted in either superior or equal performance in comparison to other continual learning methods without storage of previous task samples or dynamically adding new nodes to the network <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref>  <ref type="table">(Tables 1, 2</ref>). In the more challenging 10-task disjoint and 100-task shuffled experiments, OWM exhibited significant performance improvement over other methods ( <ref type="figure" target="#fig_1">Fig. 2</ref> and <ref type="table">Table  1</ref>). Interestingly, for the more difficult continual learning tasks, we found that the order of tasks mattered. As the performance for specific classes can be significantly influenced by the classes learned previously ( <ref type="figure" target="#fig_1">Fig. 2</ref> inset), suggesting that curriculum learning is a potentially important factor to consider in continual learning. <ref type="figure">Fig. 1</ref>. Schematic diagram of OWM. a, In the new task training process, the original weight modification calculated by the standard backpropagation (BP), ?W BP , is projected to the subspace (dark green surface), in which good performance for learned tasks has been achieved. As a result, the actual implemented weight modification is ?W OWM . This process ensures that the weights configuration after learning the new task is still within the same subspace. b, With the OWM, the training process searches for configurations that can accomplish Task 2 ( pale red area), within the subspace that enables the network to accomplish Task 1 ( blue area). A successful search necessarily stops at a position inside the overlapping subspace ( light green area). In comparison, the solution obtained by stochastic gradient descent search (SGD) is more likely to end outside this overlapping area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B</head><p>To examine whether the OWM is scalable, i.e., whether it can be applied to learn more sophisticated tasks, regarding both number of different mappings and complexity of inputs, we tested the network's ability in learning to classify thousands of hand-written Chinese characters (CASIA-HWDB1.1) and natural images (ImageNet). The Chinese character recognition task included a total of 3,755 characters forming the level I vocabulary, which constitutes more than 99% of the usage frequency in written Chinese literature <ref type="bibr" target="#b26">[27]</ref> (see <ref type="figure">Fig. 3a</ref> for exemplars of characters). In this task, a feature extractor was pre-trained to analyze the raw images. The feature vectors were fed into an OWM-trained classifier to learn the mapping between combinations of features and the labels of individual classes. We found that a classifier trained with the OWM could learn to recognize all 3,755 characters sequentially, with a final accuracy ? 92% closely approaching the results obtained in human performance when recognizing handwritten Chinese characters (? 96%) <ref type="bibr" target="#b27">[28]</ref>. Considering humans learn these characters over years and the learning necessarily contains revision, these results suggest that our method endows neural networks with a strong capability to continually learn new mappings between sensory features and class labels. Similar results were obtained with the ImageNet dataset, where the classifier trained by the OWM combined with a pretrained feature extractor, was able to learn 1000 classes of natural images sequentially ( <ref type="table">Supplementary  Table 1</ref>), with the final accuracy approaching the results obtained by training the system to classify all categories concurrently. These results suggest that, by using the OWM, the performance of the system in classification approached the limit set by the front-end feature extractor, with liability to the classifier caused by sequential learning itself effectively mitigated. In the results mentioned above, feature extractors pre-trained by the complete training sets in corresponding tasks were used to provide the feature vectors for the OWM-trained classifier. We next examined whether the classifier can learn categories on which the feature extractor has not been trained. Results were in the affirmative, as shown in <ref type="figure">Fig. 3b</ref>. For example, the feature extractor trained with 500 randomly selected Chinese characters (out of 3,755, less than 15% of categories) could already support the classifier to sequentially learn the remaining 3,255 characters with near 80% accuracy (chance  . For OWM-trained task, the sequence of learnt digits influenced recognition accuracy for specific classes. Inset: performance of recognizing digit "9" was significantly higher after learning digits "7" and "4"; two-sided t-test was applied to assess statistical significance. level of 1/3, 255), demonstrating that the network could sequentially learn new categories not previously encountered. However, we note that a higher degree of pre-taining was associated with better performance <ref type="figure">(</ref> Another important question is how quickly the OWM-trained classifier can learn. As shown in <ref type="figure">Fig.  3c</ref>, it only needed a small sample size to learn new mappings. For Chinese characters, &lt; 10 samples per class were sufficient to gain satisfactory performance. Comparison with other methods in the same task further confirmed the advantage of the OWM in achieving better performance with fewer training samples (see <ref type="figure" target="#fig_1">Supplementary Fig. 2</ref>). We note that the better performance achieved by the OWM with fewer samples is rooted in the well-known fact that the RLS algorithm, from which we derived the OWM, can converge more quickly than the least mean square (LMS) algorithm, which is equivalent to the standard backpropagation <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b18">19]</ref>.</p><p>With the dateset of Chinese characters, we also analyzed network capacity in the OWM-based continual learning. We tested two conditions, including reducing the size of the network for a given task and increasing the number of tasks for a given network. We observed that network performance remained stable until its size was reduced or the number of tasks was increased to a certain value, after which point performance declined, indicating an approach to network capacity ( <ref type="figure">Fig. 3d, e</ref>). Importantly, the changes in network performance were highly correlated with decreases in the rank of the orthogonal projector, which is consistent with our theoretical analysis regarding network capacity in OWM-based continual learning (see Methods for details).</p><p>In the experiments with Chinese characters, it is possible that although a class was never seen by the network, it shared features with other classes used in feature extractor pre-training. Thus, to further test Variance of test accuracy across classes in each case is reported in <ref type="table">Supplementary Table 2</ref>. c, Classification accuracy is plotted as a function of sample size used for sequential training, obtained with feature extractors having different degrees of pre-training (color-coded). Performances differed significantly (paired t-test, p &lt; 0.001) across different degrees of pre-training (see <ref type="table">Supplementary Table 3</ref> for variance in performance across all classes). (d-e), Relationship between network capacity for continual learning and rank of the orthogonal projector. In d, the task was to learn 100 classes of Chinese characters sequentially. Average accuracy achieved by the network (blue) and the corresponding value of (rank(?I) ? rank(P)) (red) are plotted with respect to the number of neurons in the hidden layer. In e, the same neural network with 50 neurons in the hidden layer was trained to recognize an increasing number of Chinese characters. Average accuracy (blue) achieved by the network and the corresponding value (red) of rank tot (see Methods) are plotted with respect to the number of tasks/characters. the ability of the OWM in continual learning without a pre-trained feature extractor, we examined its performance in the disjoint CIFAR-10 task. In this task, the network was trained to recognize two classes each time; thus, in a total of five consecutive tasks it learned to recognize all 10 classes. Importantly, the whole network, including both the feature extractor and classifier, was trained continually in an end-toend manner. In this task, the OWM outperformed other recently proposed continual learning methods by a large margin <ref type="table">(Table 3)</ref>, exhibiting great potential to improve the networks' ability to learn new classes "on the go" and with the feature extractor free of pre-training. Although the performance in an end-toend training setting was still inferior than that with a pre-trained feature extractor, this is an important step towards removing the usual distinction between the training and application phases of DNNs, thus allowing efficient online learning. We note that a continual learning method for classifiers with a pretrained feature extractor may also be useful. While the number of features in a given domain (e.g., human faces) is usually limited, the possible ways of combining different features to form a new object (e.g., individual faces) are almost infinite. Thus, given feature extractors pre-trained on sufficiently diverse sample sets, a classifier could greatly benefit from continual learning to recognize countless new classes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">CONTEXT DEPENDENT PROCESSING MODULE</head><p>Although a system that can learn many different mapping rules in an online and sequential manner is highly desirable, such a system cannot accomplish context-dependent learning by itself. To achieve that, contextual information needs to interact with sensory information properly. Here we adopted a solution inspired by the primate PFC. The PFC receives sensory inputs as well as contextual information, which enables it to choose sensory features most relevant to the present task to guide action <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b30">31]</ref>. To mimic this architecture, we added the context-dependent processing (CDP) module before the OWM-trained classifier, which was fed with both sensory feature vectors and contextual information <ref type="figure">(Fig. 4a</ref>). The CDP module consists of an encoder sub-module, which transforms contextual information to proper controlling signals, and a "rotator" sub-module, which uses controlling signals to manipulate the processing of sensory inputs. The encoder sub-module is trainable and learns in a continual way with the OWM. Mathematically, the context-dependent manipulation serves by rotating the sensory input space according to the contextual information <ref type="figure">(Fig. 4b, see Methods)</ref>, thereby changing the representation of sensory information without interfering with its content. The rotation of the input space allows for OWM to be applied for identical sensory inputs in different contexts. To demonstrate the effectiveness of this CDP module, we trained the system to classify a set of faces according to 40 different attributes <ref type="bibr" target="#b31">[32]</ref>, i.e., to learn 40 different mappings sequentially with the same sensory inputs. The contextual information was the embedding vectors <ref type="bibr" target="#b32">[33]</ref> of the corresponding task names, which were projected to control the rotation of the sensory inputs. As shown in <ref type="figure">Fig. 4c</ref>, the system sequentially learned all 40 different, context-specific mapping rules with a single classifier. The accuracy was very close to that achieved by multi-task training, in which the network was trained to classify all 40 attributes using 40 separate classifiers <ref type="figure">(Fig. 4d</ref>). In addition, similar to the results obtained in learning Chinese characters, the network was able to learn context-dependent processing quickly. Here, ?20 faces were enough to reach the learning plateau for both simple, e.g., male vs. female, and difficult, e.g., attractive vs unattractive, tasks <ref type="figure">(Fig. 4e</ref>). In the experiment, our approach achieved better performance with fewer samples in comparison with other methods for continual learning, indicating its potential to enable a system to adapt quickly in highly dynamic environments with regularities changing with contexts ( <ref type="figure" target="#fig_1">Supplementary Fig. 2b</ref>). Interestingly, we found that the CDP module was able to identify the meaningful signal from the contextual inputs with noise ( <ref type="figure">Supplementary Fig. 3</ref> and <ref type="table">Supplementary Table 4</ref>, see Methods for task details) and to learn how to use the contextual information effectively ( <ref type="figure">Supplementary Fig. 4</ref>). These results indicate that our approach allows the system to infer the correct context signal from experience and use it properly. Importantly, such an ability would open the door for an intelligent agent to explore environments and gradually learn its regularities in an autonomous way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>If we view traditional DNNs as powerful sensory processing modules, the current approach could be understood as adding a flexible cognitive module to the system. This architecture was inspired by the primate brain. For example, the primate visual pathway is dedicated to analyzing raw visual images and eventually representing ? 100 features in higher visual areas such as the inferotemporal cortex <ref type="bibr" target="#b33">[34]</ref>. The outputs of this "feature extractor" are then sent to the prefrontal cortex (PFC) for object identification and categorization <ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref>. The training of the feature extractor is difficult and time-consuming. In humans, it takes years or even decades for higher visual cortices to become fully developed and reach peak performance <ref type="bibr" target="#b37">[38]</ref>. However, with sufficiently developed visual cortices, humans can quickly learn new visual object categories, often by seeing just a few positive examples <ref type="bibr" target="#b38">[39]</ref>. By adding a cognitive module supporting continual learning to DNN-based feature extractors, we found a qualitatively similar behavior in neural networks. That is, although the training of the feature extractor is computationally difficult and requires a large number of samples, with a well-trained feature extractor, the learning of new categories can be achieved quickly. This suggests that the mechanisms underlying fast concept formation in humans may be understood, at least in part, from a connectionist perspective. In addition to the role of supporting the fast learning of new concepts, another function of the primate PFC is to represent contextual information <ref type="bibr" target="#b8">[9]</ref> and use it to select those sensory features most relevant for the current task <ref type="bibr" target="#b3">[4]</ref>. This gives rise to the flexibility exhibited in primate' behavior and here we demonstrated that similar architecture can do the same in artificial neural networks. Interestingly, we found that in the CDP module, the neuronal responses showed mixed selectivity to sensory features, contexts, and their combinations ( <ref type="figure">Supplementary Fig. 5</ref>), similar to that found for real PFC neurons <ref type="bibr" target="#b39">[40]</ref>. Thus, it would be informative to see whether the rotation of input space adopted in our CDP module captures the operation carried out in the real PFC. For tasks similar to the face classification tested above, one possible solution to achieve context-dependent processing is to add additional classifier outputs for each new task/context. However, this approach only works if there is no hidden layer between the feature extractor and final output layer. Otherwise the shared weights between different classifier outputs will suffer from catastrophic forgetting during continual learning, especially if the inputs are the same for all contexts. More importantly, adding additional classifier outputs (and all related weights) for each new task/context would lead to increasingly complex and bulky systems (cf. <ref type="figure">Fig. 4d left)</ref>. As the total number of possible contexts can be arbitrarily large, such a solution is clearly not scalable. As the total number of possible contexts can be arbitrarily large, such a solution is clearly not scalable. Finally, for artificial intelligence systems, the importance of the CDP-module would depend on application. In scenarios in which a compact system needs to learn numerous contexts "on the go", similar to what human individuals need to do within their lifetimes, the ability of the OWM-empowered CDP-module to reuse classifiers is of paramount importance.</p><p>As demonstrated in the present results, an efficient and scalable algorithm of continual learning is not only crucial for achieving flexible context-dependent processing, but also important to ensure, more generally, that the added cognitive module is able to learn new tasks when encountered. In continual learning, preserving previously acquired knowledge while maintaining plasticity for subsequent learning is the key <ref type="bibr" target="#b14">[15]</ref>. In the brain, the separation of synapses utilized for different tasks is essential for sequential learning <ref type="bibr" target="#b40">[41]</ref>, which inspired the development of algorithms to protect the important weights involved in previously learned tasks while training the network for new ones <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b25">26]</ref>. However, these "frozen" weights necessarily reduce the degrees of freedom of the system, i.e., they decrease the volume of parameter space to search for a configuration that can satisfy both old and new tasks. Here, by allowing the "frozen" weights to be adjustable again without erasing acquired knowledge, the OWM exhibited clear advantages in performance. However, further studies are required to investigate whether algorithms similar to the OWM are implemented in the brain. Recently, it has been suggested that a variant of backpropagation algorithm, i.e., the "conceptor-aided back-prop" (CAB) can be used for continual learning by shielding gradients against degradation of previously learned tasks <ref type="bibr" target="#b21">[22]</ref>. By providing more effective shielding of gradients through constructing an orthogonal projector, the OWM achieved much better protection of previously acquired knowledge, yielding highly competitive results in empirical tests compared with the CAB (see <ref type="table">Tables 1, 2</ref>, <ref type="figure" target="#fig_1">Fig. 2</ref> and Supplementary Information for details). The OWM and continual learning methods mentioned above are regularization approaches <ref type="bibr" target="#b14">[15]</ref>. Similar to other methods within this category, the OWM exhibits tradeoff between the performance of the old and new tasks, due to limited resources to consolidate the knowledge of previous tasks. In contrast to regularization approaches, other types of continual learning methods involve dynamically introducing extra neurons or layers along the learning process <ref type="bibr" target="#b41">[42]</ref>, which may help mitigate the tradeoff described above <ref type="bibr" target="#b14">[15]</ref>. However, regularization approaches require no extra resources to accommodate newly acquired knowledge during training and, therefore, are capable of producing compact yet versatile systems.</p><p>We note that a solution for continual learning based on context-dependent processing was suggested recently <ref type="bibr" target="#b28">[29]</ref>. In this work, a context-dependent gating mechanism was used to separate subnetworks for processing individual tasks during continual learning. However, for this approach to work, the same contextual information needs to be present during both the training and testing phases. As such information is rarely available in practical situations, this seriously limits the applicability of the method. Different from this approach, the CDP module in our work enables the network to modulate its processing according to the contextual information so that the same inputs can be treated differently in different contexts. This role is not related to continual learning, as the CDP module is needed in the same task as shown in <ref type="figure">Fig. 4</ref>, even if the system was trained concurrently. Importantly, as contextual information, e.g., environmental cues, the task at hand, etc. is always available for any input that needs context-dependent processing, the limitations of using context-dependent gating for continual learning is not a problem for our CDP module.</p><p>Other biologically inspired approaches for continual learning are based on complementary learning systems (CLS) theory <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>. Such systems involve interplay between two sub-systems similar to the mammalian hippocampus and neocortex, i.e., a task-solving network (neocortex) accompanied by a generative network (hippocampus) to maintain the memories of previous tasks <ref type="bibr" target="#b44">[45]</ref>. With the aid of the Learning without Forgetting (LwF) method <ref type="bibr" target="#b45">[46]</ref>, data for old tasks sampled by the generative module are interleaved with those for the current task to train the neural network to avoid catastrophic forgetting. Although here we used a completely different approach for continual learning, the CLS framework may also be instrumental for further development of our approach. Currently, the encoder of the CDP module has the ability to infer contextual information from the environment and also to learn how to use it effectively. Conceivably it could be further developed to recognize and classify complex contexts. Such a flexible module for recognizing proper contextual signals may be analogous to the hippocampus in the brain, which is related to the classification of different environmental cues via pattern separation and completion <ref type="bibr" target="#b43">[44]</ref>. Thus, it would be informative for future studies to investigate whether the current approach can be combined with the CLS framework to achieve more flexible and sophisticated context-dependent processing.</p><p>Taken together, our study demonstrated that it is possible to teach a highly compact network many context-dependent mappings sequentially. Although we demonstrated its effectiveness here with the supervised learning paradigm, the OWM has the potential to be applied to other training frameworks. Another regularization approach for overcoming catastrophic forgetting, i.e., the EWC, has been successfully implemented in reinforcement learning <ref type="bibr" target="#b23">[24]</ref>. As the EWC can be viewed as a special case of OWM in some circumstances (see Supplementary Information for details), it suggests that similar procedures could be extended for the use of the OWM and CDP module in unsupervised conditions, thereby enabling networks to learn different mapping rules for different contexts by reinforcement learning. We expect that such an approach, combined with effective methods of knowledge transfer, e.g., <ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b47">[48]</ref><ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref>, may eventually lead to systems with sufficient flexibility to work in complex and dynamic situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHODS</head><p>The OWM algorithm. Consider a feed-forward network of L + 1 layers, indexed by l = 0, 1, ? ? ? , L with l = 0 and l = L being the input and output layer, respectively. All hidden layers share the same activation function g(?). W l represents the connections between the (l ? 1)th and lth layer with W l ? R s?m . x l and y l denote the output and input of the lth layer, respectively, where x l = g(y l ) and y l = W T l x l?1 . x l?1 ? R s and y l ? R m .</p><p>In the OWM, the orthogonal projector P l defined in the input space of layer l for learned tasks is key for overcoming catastrophic interference in sequential learning. In practice, P l can be recursively updated for each task in a way similar to calculating the correlation-inverse matrix P (RLS) = ( n i=1 x(i)x T (i)+?I) ?1 in the RLS algorithm <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19]</ref> (see discussion on relationship of OWM and RLS in Supplementary Information). This method allows P l to be determined based on the current inputs and the P l for the last task. It also avoids matrix-inverse operation in the original definition of P l .</p><p>Below we provide the detailed procedure for the implementation of the OWM method. a. Initialization of parameters: randomly initialize W l (0) and set P l (0) = I l /? for l = 1, ? ? ? , L.</p><p>b. Forward propagate the inputs of the ith batch in the j th task, then back propagate the errors and calculate weight modifications ?W BP l (i, j) for W l (i ? 1, j) by the standard BP method. c. Update the weight matrix in each layer by</p><formula xml:id="formula_0">W l (i, j) = W l (i ? 1, j) + ?(i, j)?W BP l (i, j) if j = 1 W l (i, j) = W l (i ? 1, j) + ?(i, j)P l (j ? 1)?W BP l (i, j) if j = 2, 3, ? ? ?<label>(1)</label></formula><p>where ?(i, j) is the predefined learning rate.</p><p>d. Repeat steps (b) to (c) for the next batch. e. If the j th task is accomplished, forward propagate the mean of the inputs for each batch (i = 1, ? ? ? , n j ) in the j th task successively. Update P l for W l as P l (j) = P l (n j , j), where P l (j) = P l (n j , j) can be calculated iteratively according to:</p><formula xml:id="formula_1">P l (i, j) = P l (i ? 1, j) ? k l (i, j)x l?1 (i, j) T P l (i ? 1, j) k l (i, j) = P l (i ? 1, j)x l?1 (i, j)/[? +x l?1 (i, j) T P l (i ? 1, j)x l?1 (i, j)]<label>(2)</label></formula><p>in whichx l?1 (i) is the output of the l ? 1 th layer in response to the mean of the inputs in the i th batch of thej th task, and P l (0, j) = P l (j ? 1). f. Repeat steps (b) to (e) for the next task.</p><p>We note that the algorithm achieved the same performance if the orthogonal projector P l was updated for each batch according to Eq. 2, with ? decaying as ? i,j = ? 0 ? i/n j for the ith batch of data in the jth task. This method can be understood as treating each batch as a different task. It avoids the extra storage space as well as data reloading in (d) and, therefore, significantly accelerates processing. In this case, if the learning rate is set to ?(i) = 1/[1 +x l?1 (i) T P l (i ? 1)x l?1 (i)] and ? i,j is permanently set to ? i,j = 1, the procedure essentially uses RLS to train the neural network under the name of Enhanced Back Propagation (EBP), which is proposed to increase the speed of convergence in training <ref type="bibr" target="#b18">[19]</ref>. Therefore, our algorithm has the same computational complexity as EBP-O(N n N 2 w ), where N n is the total number of neurons and N w is the number of input weights per neuron <ref type="bibr" target="#b18">[19]</ref>.</p><p>In addition, we analyzed the capacity of the OWM, i.e., how many different tasks could be learned using this method. The capacity of one network layer can be measured by the rank of P i , which is defined as the orthogonal projector calculated after task i, with ?P i+1 then defined as the update in the next task satisfying P i+1 = P i ? ?P i+1 . As range(P i+1 ) ? range(?P i+1 ) = ?, rank(P i+1 ) = rank(P i ) ? rank(?P i+1 ). In the ideal case where each task consumes the capacity effectively, as the learning process continues, the rank of P l is approaching 0, indicating that this particular layer no longer has the capacity to learn new tasks. The capacity of the whole network can be approximated by the summation of the capacity of each layer: rank tot = L l=1 rank(P l )/rank(?I) where ?I is the initial value of matrix P. The rank is normalized to balance the contribution of each layer. We conducted two experiments <ref type="figure">(Fig. 3d,e</ref>) on the CASIA-HWDB1.1 dataset to verify the above analysis. In the experiments, to avoid influence by the tolerance value in the calculation of matrix rank, the rank was estimated as rank(P) = i=1 s i (P)/?, where s i (?) denotes the ith singular value of the matrix. If the capacity limit of the entire network is finally approached, two solutions can be considered: 1) introduction of a larger ? or the forgetting factor used in RLS <ref type="bibr" target="#b15">[16]</ref> and online EWC <ref type="bibr" target="#b49">[50]</ref>; and 2) addition of more layer(s), e.g., CDP module (see below for details), to provide more space to preserve previously learned knowledge.</p><p>The CDP module. In context-dependent learning, to change the representation of sensory inputs without distorting information content in different contexts, we added one layer of neurons after the output layer of the feature extractor (cf. <ref type="figure">Fig. 4a</ref>). Below we describe, from a mathematical point of view, how this CDP layer works, using the face classification task as an example.</p><p>In this task, the rotator sub-module was fed with feature vectors for different faces, F = [f 1 , f 2 ? ? ? , f k ] T ? R k , and modulated by non-negative controlling signals, C = [c 1 , c 2 , ..., c m ] T ? R m . The controlling signals C were drawn from the contextual information (word vector of corresponding task name) by the encoder sub-module. Then the CDP module outputted Y out = [y 1 , y 2 , ..., y m ] T ? R m , with y i = c i g((w in i ) T F), to a classifier for further processing. The input weight W in = [w in 1 , w in 2 , .., w in m ] ? R k?m of the CDP module was randomly initialized and fixed across all contexts. The rest weights in the CDP module, including the output weight W out and the weights in the encoder, were trained by the OWM method. The function of the CDP module can then be summarized as</p><formula xml:id="formula_2">Y out = g W in T F ? C = g w in 1 w in 2 ? ? ? w in m T F ? C = g c 1 F w in 1 cos? 1 , c 2 F w in 2 cos? 2 , ? ? ? , c m F w in m cos? m T = g c 1 w in 1 cos? 1 , c 2 w in 2 cos? 2 , ? ? ? , c m w in m cos? m T F<label>(3)</label></formula><p>where ? represents element-wise multiplication and ? i is the angle between w in i and F. Note that for any ? ? 0, g(?x) = max(0, ?x) = ?max(0, x) = ? g(x). The ReLU function was used in the current study for g(?) but this is not necessary. g(?) can also be chosen as a hyperbolic tangent function or logistic function. As W in was initialized by the Xavier method <ref type="bibr" target="#b50">[51]</ref> in most cases, w in i F was located in the linear range. Thus the Eq.(3) can approximately hold even for activation functions other than ReLU. We confirmed that the average accuracies for the same tasks in <ref type="figure">Fig. 4c</ref> with hyperbolic tangent function (90.93%) and logistic function (90.05%) were close to that with ReLU ( 90.38%).</p><p>For individual faces, given the same feature vector F and fixed W in , cos ? i is constant. Thus, output Y out is affected by the controlling signal C, which is different across tasks. If we normalize C by m i=1 c i w in i g (cos? i ) 2 , it is apparent from Eq. 3 that the CDP layer "rotates" the input vector in feature space, as illustrated in <ref type="figure">Fig. 4b</ref>. This explains why this added layer can change the representation of sensory inputs while keeping information contents unchanged. Importantly, it also enables the system to sequentially learn different tasks with the OWM for identical inputs.</p><p>To examine whether the CDP module can infer the correct context from distracting noise in the environment, four face recognition tasks were conducted continually with the OWM, except that the explicit context signal was not presented. The context signals and distracting noises were simultaneously fed to the CDP module. The noise was sampled from a Gaussian distribution with the same mean and variance as the context signal, and varied on a trial-by-trial basis. In the training phase for different tasks, the position of the context signal and noises could be swapped ( <ref type="figure">Supplementary Fig. 3</ref>). During the testing phase, either the corresponding context+noises or only noises were presented.</p><p>Shuffled MNIST experiment. The shuffled MNIST experiment <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref> usually consists of a number of sequential tasks. All tasks involve classifying handwritten digits from 0 to 9. However, for each new task, the pixels in the image are randomly shuffled, with the same randomization across all digits in the same task and different randomization across tasks. For this experiment, we trained 3-or 4-layer, feed-forward networks with [784-800-10] (3-layer) or [784-800/2000-800/2000-10] (4-layer) neurons (see <ref type="table">Table 1</ref> for details) to minimize cross entropy loss by the OWM method. The ReLU activation function <ref type="bibr" target="#b51">[52]</ref> was used in the hidden layer. During training, the L2 regularization coefficient was 0.001. Dropout was applied with a drop rate of 0.2. <ref type="table">Table 1</ref> shows the performance of the OWM method for the shuffled MNIST tasks in comparison with other continual learning algorithms. The accuracy of the OWM method was measured by repeating the experiments 10 times. The results of other algorithms were adopted from corresponding publications. The size of the network, regarding the number of layers and number of neurons in each layer, was the same as in previous publications for a fair comparison. Two-sided t-tests were used to compare performance between the OWM and other continual learning methods for both the shuffled and disjoint (see below) MNIST experiments. The t values were calculated according to the means and standard deviations across 10 experiments. Significance was considered at p &lt; 0.01 with results shown in <ref type="table">Table 1</ref>.</p><p>Disjoint MNIST experiment. In the 2-disjoint MNIST experiment <ref type="bibr" target="#b52">[53]</ref>, the original MNIST dataset was divided into two parts: The first contained digits from 0 to 4 and the second consisted of digits from 5 to 9. Correspondingly, the first task was to recognize digits among 0, 1, 2, 3 and 4 and the second task was to recognize digits among 5, 6, 7, 8 and 9. In the 10-disjoint MNIST task, 10 digits, from 0 to 9, were learned sequentially. Again, to facilitate comparison, network size and architecture were the same as in previous work <ref type="bibr" target="#b52">[53]</ref>. During training, momentum optimization was applied, and the learning rate for all layers remained the same during training. Performance was calculated based on 10 repeated experiments and is shown in <ref type="table">Table 2</ref>.</p><p>Sequential learning of classification tasks with Chinese characters and ImageNet. Classification tasks with ImageNet and Chinese handwritten characters are more challenging due to the complex structure in each image and more classes to "memorize" in a sequential learning task. In sequential learning, the training for a new task started only when the neural network accomplished the current task well enough, defined here as &lt; 1% accuracy gap between two successive training epochs. For these two tasks, we first trained a DNN as the feature extractor on the whole or partial dataset to extract features of each image. The extracted feature vectors were then fed into a 3-layer classifier with [1024-4000-3755] neurons for the Chinese characters task and [2048-4000-1000] neurons for the ImageNet task. The classifier was trained to recognize each of the classes sequentially using the OWM method, with results shown in <ref type="table">Supplementary  Table 1</ref>. We note that in these experiments, as in other tests mentioned above, no negative samples were used for training the network to recognize a new class. In other words, only positive samples of a particular class were presented to the network during training.</p><p>Disjoint CIFAR-10 experiment. In contrast to the pre-training of feature extractors in the tasks of Chinese characters and ImageNet, the feature extractor was trained together with the classifier in an end-to-end way using the OWM in this task. The CIFAR-10 dataset was divided into 5 groups. Each group included 2 classes of samples used to train the whole network in one task. The feature extractor consisted of three convolutional layers and the classifier consisted of three fully connected layers. The three convolutional layers had 64, 128, and 256 filters, respectively, and the size of the convolution kernel was 2 ? 2. A maxpooling layer with size of 2 ? 2 was attached to each convolutional layer. Dropout was applied to each maxpooling layer with a dropping probability of 0.2. The features extracted were flattened and then fed to the classifier of [1000-1000-10] neurons. The activation function for all layers was the ReLU function. The initial weights for all layers were in accordance with the Xavier initialization method proposed by Glorot and Bengio <ref type="bibr" target="#b50">[51]</ref>. Cross entropy loss was applied for the training. <ref type="table">Table 3</ref> compares the performance of the OWM with other methods using the same network structure and task.</p><p>Context-dependent face recognition with CelebA. In this experiment, we first trained a feature extractor using the architecture of ResNet50 <ref type="bibr" target="#b53">[54]</ref> on the whole training dataset and with the conventional multi-task training procedure. The outputs of the feature extractor were then fed into the CDP module, which also received contextual information (cf. <ref type="figure">Fig. 4a</ref> in the main text). The rotator layer contained 5000 neurons. The size of the encoder layer was [200-5000], with ReLU applied as the activation function. For the face classification task in the present study, rotated feature vectors were fed directly into the classifier by weights W out . Before training, all weights and biases were randomly initialized. W out and the weights in the encoder were modified by the OWM method. Detailed results of classifying individual attributes are listed in <ref type="table">Supplementary Table 5</ref>.</p><p>Network parameters. Weights in the hidden layers of the classifiers for the tasks other than disjoint CIFAR-10 task were initialized according to previously suggested method <ref type="bibr" target="#b54">[55]</ref>. The output layers were all initialized to zero. The biases of each layer were randomly initialized according to a uniform distribution within (0, 0.1). The ReLU neurons were applied to every hidden layer in all experiments. The momentum in all optimization algorithms was 0.9. The details of hyperparameters used for feature extractors are shown in <ref type="table">Supplementary Table 6</ref>. Early stopping was used for training both the feature extractors and classifiers. The hyperparameters for the OWM method are shown in <ref type="table">Supplementary Table 7</ref>. For tasks with MNIST and CelebA, the classifier was trained to minimize cross entropy loss, whereas for tasks with ImageNet and Chinese characters, the classifier was trained to minimize mean squared loss. Note that cross-entropy loss was also suitable for the latter datasets. However, mean squared loss is easier to compute and less time-consuming when many tasks are involved.</p><p>Mixed selectivity analysis. For classifying different facial attributes, responses of neurons in the CDP were analyzed to examine if they exhibited mixed selectivity similar to that of real PFC neurons. To this end, we chose two attributes with low correlation, i.e., Attractiveness (Task 1) and Smile (Task 2). Both has about 50% positive and 50% negative samples in the whole dataset. The responses of each neuron in the CDP module to different inputs as well as contextual signals were analyzed with the weights in the encoder sub-module fixed for both contexts. There were 19962 test pictures, with 90% correctly classified after training for both tasks. The threshold of excitation for each neuron was chosen as the average activity level across all neurons during the processing of all correctly-classified pictures. <ref type="figure">Supplementary Fig. 5</ref> shows the selectivity of three exemplar neurons. According to the criteria usually used in electrophysiological experiments, these three neurons belonged to different categories, including task-sensitive (Neuron 1) and attribute-sensitive (Neuron 2). Importantly, Neuron 3 exhibited complex selectivity towards combinations of task and sensory attributes, as well as combinations of different attributes. This mixed selectivity is commonly reported for real PFC neurons <ref type="bibr" target="#b55">[56]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Performance of OWM, CAB, and SGD in 10-disjoint MNIST task. Test accuracy was plotted as a function of number of classes learned. Results are presented as mean ? s.d.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Fig. 3band c), indicating the importance of training the feature extractor on as various classes as possible.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1 Fig. 3 .</head><label>13</label><figDesc>Continual learning with small sample size achieved by OWM in recognizing Chinese characters. a, Examples showing seven characters with five samples for each. b, Classification accuracy is plotted as a function of the number of classes used for pre-training the feature extractor. Performance was assessed based on classifying all characters (blue) or characters not included in pre-training (orange).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Achieving context-dependent sequential learning via the OWM algorithm and the CDP module. a, Schematic diagram of network architecture. The CDP module dynamically modulates the mapping between sensory inputs to network outputs according to the contextual information. The main figure and the inset illustrate the detailed internal structure of the module and the overall architecture, respectively. b, Schematic diagram showing the role of the CDP module in rotating inputs in feature space (see Methods for details). c, Performance of sequentially learning to classify faces by 40 different attributes, each associated with a unique contextual signal, compared with results obtained by multi-task training. Tasks were sorted by test accuracy. d, Schematic diagrams showing network architecture for multi-task (left) and sequential (right) training. CL, classifier. To achieve context-dependent processing, in multi-task training a switch module and n classifiers are needed, where n is the number of different attributes. e, Classification accuracies for a relatively easy task (gender; blue curve) and five more difficult, sequentially learned tasks (e.g., attractiveness; orange curve; mean results across all five tasks are shown) are plotted as a function of training sample size. Tasks and corresponding performance obtained by training on the full dataset are marked with arrows in c.</figDesc><table><row><cell>a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Context</cell><cell>b</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Feature Space</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">CDP</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Sensory Inputs</cell><cell></cell><cell cols="2">Output</cell><cell>Encoder</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>C</cell></row><row><cell></cell><cell></cell><cell>Sensory Inputs</cell><cell cols="2">Feature Extractor</cell><cell></cell><cell></cell><cell>W</cell><cell>in</cell><cell></cell><cell></cell><cell>W</cell><cell>out</cell><cell>Y lable</cell></row><row><cell>c</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Feature</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Rotator</cell></row><row><cell></cell><cell></cell><cell>100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Test Accuracy (%)</cell><cell>75</cell><cell></cell><cell></cell><cell></cell><cell cols="3">Multi-task Training Sequential Training</cell><cell></cell><cell></cell><cell>Hard Task Easy Task</cell></row><row><cell>d</cell><cell></cell><cell>50</cell><cell>E ye g la ss e s</cell><cell>W .H a t</cell><cell>B a ld</cell><cell>M a le G ra y H a ir S id e b u rn s</cell><cell cols="3">G o a te e P a le S ki n M u st a ch e W .N e ck tie D o u b le C h in</cell><cell>B lu rr y N o B e a rd</cell><cell>B a n g s B lo n d H a ir</cell><cell>C h u b b y R o sy C h e e ks 5 S h a d o w W .L ip st ic k M o u th S .O p e n R e ce d .H a ir lin e e</cell><cell>S m ili n g B u sh E .B ro w s H .M a ke u p W .E a rr in g s B la ck H a ir B ro w n H a ir Y o u n g H .C h e e kb o n e s N a rr o w E ye s W .N e ck la ce B a g s U n .E ye s W a vy H a ir B ig N o se S tr a ig h t H a ir A .E .B ro w s A tt ra ct iv e P o in ty N o se O va l F a ce B ig L ip s</cell></row><row><cell></cell><cell cols="4">Multi-task Training</cell><cell></cell><cell></cell><cell cols="4">Sequential Training</cell><cell>100</cell></row><row><cell>Feature Input</cell><cell>. . .</cell><cell></cell><cell cols="2">Switch Module</cell><cell></cell><cell>. . . CL 3 CL 2 CL 1</cell><cell>Feature Input</cell><cell>. . .</cell><cell>CDP Module</cell><cell></cell><cell>CL</cell><cell>Test Accuracy (%)</cell><cell>75</cell><cell>Easy Task Hard task</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CL n</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50</cell><cell>2</cell><cell>100</cell><cell>1000 2000</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Number of Pictures</cell></row><row><cell cols="3">Fig. 4.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>The authors thank Dr. Danko Nikoli? for helpful discussions. </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DATA AND CODE AVAILABILITY</head><p>All data used in this paper are publicly available and can be accessed at: http://yann.lecun.com/exdb/mni for the MNIST dataset; https://www.cs.toronto.edu/?kriz/cifar.html for the CIFAR dataset; http://image-net.org/index for the ILSVR2012 dataset; http://www.nlpr.ia.ac.cn/da for the CASIA-HWDB dataset; http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html for the CelebA dataset. For more details of the dataset, please refer to the references cited in the Dataset section of the Supplementary Information.</p><p>The source code can be accessed at https://github.com/beijixiong3510/OWM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>COMPETING INTERESTS</head><p>The Institute of Automation, Chinese Academy of Sciences has submitted the patent applications on the OWM algorithm (application No. PCT/CN2019/083355; invented by Chen Yang, Guanxiong Zeng and Shan Yu; pending) and the CDP module (application No. PCT/CN2019/083356; invented by Guanxiong Zeng, Chen Yang and Shan Yu; pending).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Unified theories of cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Newell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Harvard University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The intelligibility of speech as a function of the context of the test materials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Heise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lichten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="329" to="335" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Neural mechanisms of selective visual-attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Desimone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duncan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="193" to="222" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Context-dependent computation by recurrent dynamics in prefrontal cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sussillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Newsome</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">503</biblScope>
			<biblScope unit="page">78</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cortical information flow during flexible sensorimotor decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Buschman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">348</biblScope>
			<biblScope unit="page" from="1352" to="1355" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The prefrontal cortex: Complex neural properties for complex behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="15" to="17" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The frontal cortex basal ganglia system in primates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Wise</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Gerfen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Critical Reviews in Neurobiology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="317" to="356" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The frontal lobes and voluntary action. oxford psychology series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Passingham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An integrative theory of prefrontal cortex function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="167" to="202" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K J N</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The prefontral cortex and cognitive control</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">59</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Catastrophic interference in connectionist networks: The sequential learning problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Elsevier</publisher>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="109" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Connectionist models of recognition memory -constraints imposed by learning and forgetting functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="285" to="308" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">An empirical investigation of catastrophic forgetting in gradient-based neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6211</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">I</forename><surname>Parisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kemker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Part</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Wermter</surname></persName>
		</author>
		<title level="m">Continual lifelong learning with neural networks: A review</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Adaptive filter theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Haykin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Pearson Education India</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Golub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Van Loan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Matrix computations</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2012" />
			<publisher>JHU Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Training feed-forward networks with the extended kalman algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1989" />
			<biblScope unit="page" from="1187" to="1190" />
		</imprint>
	</monogr>
	<note>1989 International Conference on</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Optimal filtering algorithms for fast learning in feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Datum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="779" to="787" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Generating coherent patterns of activity from chaotic neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sussillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Abbott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="544" to="557" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Jaeger</surname></persName>
		</author>
		<title level="m">Controlling recurrent neural networks by conceptors</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic interference using conceptor-aided backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirkpatricka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="3521" to="3526" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting by incremental moment matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-T</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4652" to="4662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zenke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Ganguli</surname></persName>
		</author>
		<title level="m">Continual learning through synaptic intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Chinese handwriting recognition contest 2010</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition (CCPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Icdar 2013 chinese handwriting recognition competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis and Recognition (ICDAR), 2013 12th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1464" to="1470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Alleviating catastrophic forgetting using contextdependent gating and synaptic stabilization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">Y</forename><surname>Masse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Freedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="10467" to="10475" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting via model adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fuster</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
	<note>The prefrontal cortex</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep Learning Face Attributes in the Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ieee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3730" to="3738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Software framework for topic modelling with large corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>?eh??ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>ELRA</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Dimensionality of object representations in monkey inferotemporal cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Lehky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Esteky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2135" to="2162" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Categorical representation of visual stimuli in the primate prefrontal cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Freedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riesenhuber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">291</biblScope>
			<biblScope unit="page" from="312" to="316" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Fast readout of object identity from macaque inferior temporal cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kreiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Dicarlo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">310</biblScope>
			<biblScope unit="page" from="863" to="866" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The ventral visual pathway: an expanded neural framework for the processing of object quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kravitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Saleem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">I</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Ungerleider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mishkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="26" to="49" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Microstructural proliferation in human cortex is coupled with the development of face processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gomez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">355</biblScope>
			<biblScope unit="page">68</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Word learning as bayesian inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="245" to="272" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The importance of mixed selectivity in complex cognitive tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rigotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">497</biblScope>
			<biblScope unit="page" from="585" to="590" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Branch-specific dendritic ca2+ spikes cause persistent synaptic plasticity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cichon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-B</forename><surname>Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">520</biblScope>
			<biblScope unit="page" from="180" to="80" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progressive neural networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Why there are complementary learningsystems in the hippocampus and neocortex -insights from the successes and failures of connectionist models of learning and memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">L</forename><surname>Mcnaughton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Oreilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="419" to="457" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">T. i. c. s. What learning systems do intelligent agents need? complementary learning systems theory updated</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L J</forename><surname>Mcclelland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="512" to="534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Continual learning with deep generative replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2990" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">What helps where -and why? semantic relatedness for knowledge transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Szarvas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">How transferable are features in deep neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3320" to="3328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Progress &amp; compress: A scalable framework for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schwarz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.06370</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth international conference on artificial intelligence and statistics</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th international conference on machine learning (ICML-10)</title>
		<meeting>the 27th international conference on machine learning (ICML-10)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Compete to compute</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kazerounian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2310" to="2318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Q</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ieee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The role of prefrontal mixed selectivity in cognitive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramirez-Cardenas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Viswanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="9013" to="9015" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Z conceived the study and designed the experiments. G.Z. and Y.C. conducted computational experiments and theoretical analyses. C.B. assisted with some experiments and analyses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>and G.Z. wrote the paper</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
