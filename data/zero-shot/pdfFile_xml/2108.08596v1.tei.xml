<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Feature Stylization and Domain-aware Contrastive Learning for Do-main Generalization</title>
			</titleStmt>
			<publicationStmt>
				<publisher>ACM</publisher>
				<availability status="unknown"><p>Copyright ACM</p>
				</availability>
				<date>October 20-24, 2021. October 20-24, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seogkyu</forename><surname>Jeon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibeom</forename><surname>Hong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pilhyeon</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jewook</forename><surname>Lee</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeran</forename><surname>Byun</surname></persName>
							<email>hrbyun@yonsei.ac.kr</email>
							<affiliation key="aff5">
								<orgName type="laboratory">Also with Graduate school of Artificial Intelligence</orgName>
								<orgName type="institution">Yonsei University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seogkyu</forename><surname>Jeon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibeom</forename><surname>Hong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pilhyeon</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jewook</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeran</forename><forename type="middle">Byun</forename></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Yonsei University</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="laboratory">ACM Reference Format</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Feature Stylization and Domain-aware Contrastive Learning for Do-main Generalization</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 29th ACM International Conference on Multimedia (MM &apos;21)</title>
						<meeting>the 29th ACM International Conference on Multimedia (MM &apos;21)						</meeting>
						<imprint>
							<publisher>ACM</publisher>
							<date type="published">October 20-24, 2021. October 20-24, 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3474085.3475271</idno>
					<note>New York, NY, USA, 10 pages. https://</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T14:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS ? Computing methodologies ? Computer vision</term>
					<term>Image rep- resentations * Corresponding Author KEYWORDS Domain Generalization</term>
					<term>Deep learning</term>
					<term>Image Classification</term>
					<term>Fea- ture Stylization</term>
					<term>Contrastive Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Domain generalization aims to enhance the model robustness against domain shift without accessing the target domain. Since the available source domains for training are limited, recent approaches focus on generating samples of novel domains. Nevertheless, they either struggle with the optimization problem when synthesizing abundant domains or cause the distortion of class semantics. To these ends, we propose a novel domain generalization framework where feature statistics are utilized for stylizing original features to ones with novel domain properties. To preserve class information during stylization, we first decompose features into high and low frequency components. Afterward, we stylize the low frequency components with the novel domain styles sampled from the manipulated statistics, while preserving the shape cues in high frequency ones. As the final step, we re-merge both the components to synthesize novel domain features. To enhance domain robustness, we utilize the stylized features to maintain the model consistency in terms of features as well as outputs. We achieve the feature consistency with the proposed domain-aware supervised contrastive loss, which ensures domain invariance while increasing class discriminability. Experimental results demonstrate the effectiveness of the proposed feature stylization and the domain-aware contrastive loss. Through quantitative comparisons, we verify the lead of our method upon existing state-of-the-art methods on two benchmarks, PACS and Office-Home.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Since the remarkable advance of deep neural networks, they have become ubiquitous in various fields, especially computer vision systems. However, there still exist potential risks lying on the flip side of their success. One of the main concerns is their vulnerability against visual domain shift <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b39">40]</ref>. Concretely, deep models react unexpectedly when confronting data unaffiliated to the training distribution. For example, an auto-tagging model trained on clean product images shows poor performance when taking as inputs real product images which are under various viewpoints and light conditions.</p><p>To equip the models with the ability in coping with domain shift, previous studies tackle the problem of domain adaptation <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b60">60]</ref>. In this problem setting, two different domains sharing the same label space are prepared for training and test, which are referred to as the "source" and the "target" domains, respectively. During training, a model has access to both labeled images from the source domain and unlabeled (or partially labeled) images from the target domain. Being aware of the target domain, existing works successfully minimize the discrepancy between two distinct domains, thus leading to large performance boosts <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b60">60]</ref>.</p><p>However, the problem setting of domain adaptation is impractical in that domain shift is generally unpredictable in the real-world scenarios, i.e., we do not know the target domain at training time. To this end, a new task has attracted much attention recently, aiming to learn domain robustness without accessing the target domain data, namely domain generalization <ref type="bibr">[5-7, 11, 15, 21, 29-31, 37, 44, 55]</ref>. In this setting, multiple datasets from different source domains are typically utilized to learn domain invariant representations.</p><p>Previous methods <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b57">57,</ref><ref type="bibr" target="#b62">62]</ref> embrace the observation that domain robustness is proportional to the number of domains observable in the training stage <ref type="bibr" target="#b48">[49]</ref>. To that end, they utilize generative adversarial networks (GAN) <ref type="bibr" target="#b62">[62]</ref> or adaptive instance normalization (AdaIN) <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b34">35]</ref> for synthesizing novel (unseen) domains. Nonetheless, they have two clear limitations which are critical for domain generalization. First, GAN-based methods become prohibitively difficult to optimize as the number of novel domains increases, which limits the size of observable domain space. Next, AdaIN-based approaches fail to preserve the semantics of original images, as instance normalization (IN) tends to wash away class discriminative information <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b43">44]</ref>.</p><p>In this paper, we introduce a novel framework for domain generalization, overcoming the above limitations. Specifically, to synthesize novel domains without losing class discriminative information, we propose a novel feature stylization block. First, we calculate batch-wise feature statistics of source domains and sample novel domain styles from the feature distribution. We re-scale the standard deviation of the source feature distribution so that the outlying style statistics are more likely to be sampled. However, the original semantics can be distorted during the stylization process, which will disturb the training. To preserve the original semantics during stylization, inspired by a recent photo-realistic stylization method <ref type="bibr" target="#b59">[59]</ref>, we decompose original features into high and low frequency components which contain structural and textural information, respectively. Afterwards, we manipulate the low frequency components while remaining shape cues in high frequency ones to prevent semantics distortion. Lastly, we re-merge the stylized low frequency components and the high frequency ones, leading to the stylized features. By incorporating them in the training, our model is allowed to learn robust representation against domain shift.</p><p>Rather than naively utilizing stylized features for training, we seek for better strategies that can provide domain robustness guidance. Intuitively, a robust model against domain shift should yield consistent predictions for the stylized features and the original ones. In this point of view, we adopt the consistency loss to maximize the agreement between the model predictions for them. Concretely, we measure the KL divergence between two output distributions and minimize it with the consistency loss.</p><p>Moreover, we propose the domain-aware supervised contrastive loss to minimize distance between the stylized and the original features, in order to achieve feature-level consistency. Although the conventional supervised contrastive loss has proven to be effective, we found that it is unsuitable for domain generalization. The loss expels the samples from different domains and thus disturbs domain invariance, which conflicts with the goal of domain generalization. To this end, we introduce the novel domain-aware supervised contrastive loss which ignores negative samples from different domains, hence preserving domain invariance while empowering class discriminability.</p><p>The contributions of this paper can be summarized into three folds. Firstly, we propose a novel domain generalization framework, where diverse domain styles are generated and leveraged through the proposed feature stylization block. The stylized features are in turn used to enhance domain robustness by encouraging the model to produce consistent outputs. Secondly, we introduce the novel domain-aware supervised contrastive loss. The proposed loss strengthens the domain invariance by contrasting features with respect to domain and class labels. Lastly, we demonstrate the effectiveness of each component of our model through analyses and ablation studies. Furthermore, experimental results show that our method surpasses previous methods with obvious margins, achieving a new state-of-the-art on the widely used benchmarks: PACS and Office-Home. Even on the single-source domain generalization task, our method shows delightful performance improvements over the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS 2.1 Domain Adaptation</head><p>Domain adaptation aims to transfer learned knowledge from source domains to a target domain. In this setting, the source domain is usually a large scale dataset with annotations, and the target domain data is either partially labeled or completely unlabeled. They are referred to semi-supervised domain adaptation (SSDA) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b58">58]</ref> and unsupervised domain adaptation (UDA) <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b60">60]</ref>, respectively.</p><p>Semi-supervised domain adaptation methods impose constraints on both labeled and unlabeled instances of the target domain in various ways. Donahue et al. <ref type="bibr" target="#b8">[9]</ref> build a similarity graph to constrain unlabeled data and transfer knowledge with a projective model transfer method. Ao et al. <ref type="bibr" target="#b0">[1]</ref> distill knowledge from the source domain by generating pseudo labels for the unlabeled target data. Saito et al. <ref type="bibr" target="#b40">[41]</ref> estimate class-specific prototypes with sparsely labeled examples of the target domain, then update them by solving a minimax game on the unlabeled data.</p><p>In unsupervised domain adaptation, most methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50]</ref> conduct feature alignment between source and target domains. To this end, CORAL <ref type="bibr" target="#b47">[48]</ref> minimizes the distance between the covariance matrices, while ADDA <ref type="bibr" target="#b49">[50]</ref> employs a domain discriminator for adversarial learning. Meanwhile, CyCADA <ref type="bibr" target="#b19">[20]</ref> adopts an image-to-image translation framework to transfer the source domain data to the target domain data on image-level. Recently, domain randomization <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b60">60,</ref><ref type="bibr" target="#b61">61]</ref> is another generative stream which diversifies the textures of source domain images, allowing the model to learn texture invariant representations. Yue et al. <ref type="bibr" target="#b60">[60]</ref> manipulate images into an external class from ImageNet <ref type="bibr" target="#b26">[27]</ref>, and LTIR <ref type="bibr" target="#b25">[26]</ref> exploits an artistic style transfer method to alter the textures of the source and target domains.</p><p>Our method relates to the domain randomization approaches in that it aims to generate features with diverse domain characteristics. However, they are not suitable for domain generalization as they require external datasets <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b60">60]</ref>. On the contrary, our proposed feature stylization block is able to generate various stylized features based on the statistics of source domains, without access to additional data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Domain Generalization</head><p>The goal of domain generalization is to learn domain invariant representations based on only source domains. Different from unsupervised domain adaptation, target domain data is inaccessible during training, making the task more challenging. In addition, multiple domains are typically utilized to achieve domain-agnostic representation without having target domain data. Previous domain generalization methods can be roughly categorized into four groups: meta-learning, architectural modification, regularization, and generative approaches.</p><p>The first group exploits meta-learning techniques <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b38">39]</ref> to align different domains <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30]</ref>. These approaches borrow the powerful adaptability of meta-learning algorithms whose effectiveness is proven in the field of few-shot learning. Representatively, Li et al. <ref type="bibr" target="#b29">[30]</ref> separates the training set into multiple episodes, each of which handles only a single domain. During training, they update the backbone with aggregated regularization losses from domain specific networks. Meanwhile, MASF <ref type="bibr" target="#b10">[11]</ref> simulates domain shift using different episodes. They perform global alignment of class relationships while clustering local samples.</p><p>Secondly, some works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b54">55]</ref> try architectural changes to model a shared embedding space <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b32">33]</ref> or to build domain-specific networks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b43">44]</ref>. Exploiting auxiliary pretext tasks are also favored as a sub-stream <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b53">54]</ref>. As a pioneer, JiGen <ref type="bibr" target="#b4">[5]</ref> proposes to solve jigsaw puzzles as an auxiliary task to induce the model to learn the concepts of spatial correlation. Inheriting from JiGen, EIS-Net [54] employs a momentum metric learning task to provide extrinsic relationship supervision. Other approaches <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b52">53]</ref> apply diverse regularization during training. HEX <ref type="bibr" target="#b52">[53]</ref> employs the neural gray-Level co-occurrence matrix to find superficial representations related to the task. PAR <ref type="bibr" target="#b51">[52]</ref> penalizes the predictive power of earlier layers so that the model relies more on global representations from deeper layers. RSC <ref type="bibr" target="#b22">[23]</ref> masks out both spatial regions and channels which have high contributions to the task. RobustNet <ref type="bibr" target="#b6">[7]</ref> encourage model to utilize domain-invariant features by selectively whitening domain-variant feature channels in the gram matrix during training.</p><p>Lastly, based on the intuition that the generalization ability can be boosted with samples from more diverse domains <ref type="bibr" target="#b48">[49]</ref>, generative approaches arises <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b57">57,</ref><ref type="bibr" target="#b62">62]</ref>. They augment the training set with samples similar in semantics but different in domain characteristics. L2A-OT <ref type="bibr" target="#b62">[62]</ref> adopts generative adversarial networks to synthesize images which are distant from original ones in terms of the Wasserstein distance. Qiao et al. <ref type="bibr" target="#b37">[38]</ref> apply adversarial perturbations on the images to augment the source domains. From the perspective of frequency, FACT <ref type="bibr" target="#b54">[55]</ref> analyze the frequency components of the image with the fourier transformation, and conduct data augmentation by mixing the amplitude information.</p><p>Our method can be viewed as a harmonious combination of the generative method and the regularization-based approach. We generate features of novel domains via the novel feature stylization block during training, then apply regularization in terms of output consistency and feature similarity. The efficacy of our method is demonstrated through extensive experiments in Sec. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>In this section, we first describe the baseline setup of multi-source domain generalization for image classification, then introduce our novel feature stylization method and consistency learning process thereafter. The overall framework of our method is illustrated in <ref type="figure" target="#fig_0">Fig. 1 (a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Baseline</head><p>In the multi-source domain generalizaiton task, multiple datasets of source domains D = { 1 , 2 , ..., } are accessible during training. Each dataset contains a set of images = 1 , 2 , ..., with the corresponding class label set = 1 , 2 , ..., , where is the number of images in the -th dataset. Naturally, the domain label of can be obtained as = . We also note that all datasets share the same label space, i.e., ? Y. We train a neural network ? which consists of a feature extractor and a following classifier ?. The feature extractor is composed of multiple convolutional layers and we denote the output features of the -th convolutional layer by ? R ? ? ? , where is the cardinality of a mini-batch, and is the number of channels, while and are the height and width of the feature, respectively. The classifier is a single fully-connected layer. We train the network ? by minimizing the cross-entropy loss as follows.</p><formula xml:id="formula_0">L = ? 1 ?? =1 1 ?? =1 log( (?( ))),<label>(1)</label></formula><p>where (?) indicates the softmax function. Consequently, with the above baseline setup, the network ? is trained to classify an image into its corresponding label .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Feature Stylization</head><p>An intuitive way to improve the generalization ability of a model would be allowing it to see diverse samples from different domains <ref type="bibr" target="#b48">[49]</ref>. In this point of view, we augment the source domains by synthesizing novel domains by manipulating feature statistics. Before stylization, we note that it should be ensured that the generated feature should maintain the original semantics. To this end, we borrow the feature decomposition of a photo-realistic style transfer model <ref type="bibr" target="#b59">[59]</ref>, where structural features and textural features are separated into high frequency and low frequency components, respectively. The feature decomposition process is formulated as:</p><formula xml:id="formula_1">= UP(AvgPool( )), = ? ,<label>(2)</label></formula><p>where "AvgPool" denotes spatial average pooling operation with the kernel size of 2, and "UP" indicates nearest neighbor upsampling operation. After decomposition, we perform stylization on the low frequency feature only to preserve structural information.</p><p>Since neither extra datasets nor pre-trained networks are available in our setting, we stylize the feature by utilizing its batch-wise statistics. Firstly, the mean and variance are obtained as follows:</p><formula xml:id="formula_2">= 1 ?? =1 ( , ), ( ) 2 = 1 ?? =1 ( ( , ) ? ) 2 ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_3">(?) : R ? ? ? ? R ? indicates flattening</formula><p>operation, while , ? R denote the mean and the variance of feature style, respectively.</p><p>As thoroughly investigated in previous studies <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b35">36]</ref>, these batch-wise statistics are highly related to the domain characteristics. In order to generate the domain statistics, we model the prior distributions of both style vectors ( , ) as gaussians. For this purpose, we calculate the channel-wise mean and variance of style vectors as follows.</p><formula xml:id="formula_4">= 1 ?? =1 , , (?, ) 2 = 1 ?? =1 ( , ??) 2 , = 1 ?? =1 , , (?, ) 2 = 1 ?? =1 ( , ??) 2 ,<label>(4)</label></formula><p>where?and (?) 2 denote channel-wise statistics of , while? nd (?) 2 are statistics of . is the number of channels of . To generate the novel domain styles, we manipulate the variance of distributions with the scaling parameters and , then sample new style vectors from its distribution as:</p><formula xml:id="formula_5">new ? N (?, (?) 2 ), new ? N (?, (?) 2 ).<label>(5)</label></formula><p>As the variance increases, outlying style vectors, i.e., outliers, are more likely to be sampled from the distributions, whereas in-liers are sampled with higher probability in the opposite case. We show the effects of scale parameters through experiments in section 4.4.</p><p>After the sampling stage, the style vectors new and new are applied to the original low frequency component via the affine transformation as follows.</p><formula xml:id="formula_6">= new ? + new .<label>(6)</label></formula><p>We can interpret the sampling and transformation process as generating arbitrary domain statistics and applying on the original one. Notably, our affine transformation process is analogous to the batch normalization (BN) <ref type="bibr" target="#b23">[24]</ref> where the affine parameters are new and new . Compared to adaptive instance normalization (AdaIN) <ref type="bibr" target="#b21">[22]</ref> which washes away discriminative features <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b43">44]</ref>, our feature stylization process conserves them while generating novel domain styles. Lastly, the stylized low frequency feature?are then combined with the original high frequency feature via the following equation.?= +?.</p><p>We note that our feature stylization block can be inserted into any layer of the feature extractor . Analyses on the best location of the feature stylization block will be discussed through ablation studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Consistency Regularization</head><p>The augmented feature?is passed through the remaining layers, the same as the original feature . Given the stylized feature, we further encourage the model to output a consistent prediction with the original one. For this, we minimize the discrepancy between output predictions from the original and the stylized features, which is formulated as:  <ref type="figure">Figure 2</ref>: We illustrate the difference between the conventional supervised contrastive loss <ref type="bibr" target="#b24">[25]</ref> (L ) and the proposed domain-aware supervised contrastive loss (L ). L only considers the class label to compose the positive and negative sets. From the domain perspective, the sketch and cartoon domain images in ( ) are attracted to the anchor, but those domains included in the negatives are expelled. This is contradictory since the positives contribute to the domain invariance while the negatives cause the domain discrepancy. For this, we propose L where we exclude the samples with different domains from the negative set. Consequently, the class discriminative feature is attainable and the domain-invariance is also accomplished by attracting positive samples from different domains.</p><formula xml:id="formula_8">L = ? 1 ?? =1 1 ?? =1 (?( ), ) log( (?( ))), 0 ? ? 1,<label>(8)</label></formula><p>where (?) indicates the softmax function,?( ) denotes the neural network output in which feature stylization is performed on an intermediate layer, and is the temperature hyper-parameter.</p><p>The effect of the consistency loss is illustrated in <ref type="figure" target="#fig_0">Fig. 1 (b)</ref>. Through the consistency loss, the log-likelihood between the predictions is maximized. In addition, we apply temperature scaling with on the original prediction, denoted as (?( ), ), to encourage the prediction of stylized feature to have low entropy <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b18">19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Domain-aware Supervised Contrastive Loss</head><p>Furthermore, we bring another intuition that a robust feature extractor should embed stylized features adjacent to original ones. Hence, we minimize the distance between the original feature (anchor) and the stylized one in terms of the dot-product similarity. This is accomplished by contrasting stylized features (positives), with other samples (negatives) <ref type="bibr" target="#b16">[17]</ref>.</p><p>In addition, to encourage class discriminability, we adopt a supervised contrastive learning framework <ref type="bibr" target="#b24">[25]</ref> where output features from augmented samples and those from samples with the same class label are treated as positive. Meanwhile, the others in the minibatch are considered negative. The basic formulation of supervised contrastive learning is defined as:</p><formula xml:id="formula_9">L = ? ?? ? 1 | ( )| ?? ? ( ) log ( ? ? ? / ) ? ( ) ( ? ? ? / ) ,<label>(9)</label></formula><p>where ? {1...2 } indicates a set of indices of features and its stylized augmentation, ( ) ? { \ } contains the indices of all samples but the anchor, ( ) denotes the set of indices of all positives to the anchor, and ? denotes an output feature from the feature extractor after L2 normalization. The softmax function with temperature scaling is applied on the similarity matrix of the anchor.</p><p>As shown in <ref type="figure">Fig. 2 (a)</ref>, the loss induces the model to attract positive features while repulsing negative ones from the anchor. However, the performance degradation occurs when the loss is directly adopted for the the domain generalization task. Concretely, the feature space becomes domain-discriminative since the samples from different domains are pushed aside from the anchor. This is widely known to be detrimental for achieving the domaininvariance <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50]</ref>. To this end, we propose to modify Eq. (9) to be more suitable for domain generalization, namely a domain-aware supervised contrastive loss:</p><formula xml:id="formula_10">L = ? ?? ? 1 | ( )| ?? ? ( ) log ( ? ? ? / ) ? ( )? ( ) ( ? ? ? / ) ,<label>(10)</label></formula><p>where ( ) is a set containing the indices of samples sharing the same domain label with the anchor.</p><p>As shown in <ref type="figure">Fig. 2 (b)</ref>, ( ) ? ( ) , i.e., samples from the different domain which were included in the earlier negative set, are excluded. For example, when a anchor is a "photo dog", its positive set ( ) is {"stylized photo dog", "cartoon dog", "sketch dog", . . . }, whereas remaining negatives belongs to different classes in "photo" domain.</p><p>Consequently, with the proposed domain-aware supervised contrastive loss, our feature extractor produces features not only discriminative to class labels but also invariant by attracting samples from different domain, i.e., ( ) ? ( ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Overall Training and Inference</head><p>We train the neural network ? with the weighted sum of losses as follows:</p><formula xml:id="formula_11">L = L + L + L ,<label>(11)</label></formula><p>where * is the weighting factor. The overall training is conducted in end-to-end manner. The network ? is updated with respect to L and L , while L affects only the feature extractor . During the inference, we detach the feature stylization module from the forward path so that the model predicts based on the original feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS 4.1 Experiment Details</head><p>Datasets. As our evaluation benchmarks, we use PACS <ref type="bibr" target="#b27">[28]</ref> and Office-Home <ref type="bibr" target="#b12">[13]</ref> following conventional settings. PACS is made up of four domains, i.e., Photo (1,670 images), Art Painting (2,048 images), Cartoon (2,344 images) and Sketch (3,929 images). The total number of images is 9,991 and the image resolution is 227?227. The dataset contains 7 common categories: 'dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person'. Another benchmark is Office-Home which consists of images from four different domains, namely Artistic, Clip Art, Product, and Real world images. Each domain contains images of 65 object categories which are found in office and home. The total number of images is 15,500. Evaluation. A common evaluation protocol in domain generalization is leave-one-domain-out evaluation <ref type="bibr" target="#b27">[28]</ref>. Specifically, we first select one domain as the target domain. Then, the other domains are set as source domains. We train our model on the source domains and evaluate it on the target domain. We note that any sample from the target domain is not allowed during the training step. This procedure is repeated to ensure that every domain is chosen to be the source domain exactly once, and we report the averaged accuracy. Implementation details. For fair comparison with previous studies, we adopt ResNet-18 and ResNet-50 <ref type="bibr" target="#b17">[18]</ref> pre-trained on Ima-geNet <ref type="bibr" target="#b26">[27]</ref>. We optimize our network with Stochastic Gradient Descent (SGD) optimizer. We set an initial learning rate as 0.004 and train for 40 epochs. The decay rate is set to 0.0005 which is applied after 20 epochs. A single mini-batch contains a total of 126 images, 42 images for each source domain. Inspired by FixMatch <ref type="bibr" target="#b46">[47]</ref> and SupCon <ref type="bibr" target="#b24">[25]</ref>, the temperature parameters of L and L are set to 0.5 and 0.15, respectively. Considering the scale of loss fucntions, weighting factors ( , ) are set to (0.3, 12) and (0.9, 6) for ResNet-18 and ResNet-50, respectively. Besides, the scale parameters ( , ) are set to 10 and 20 for ResNet-18 and ResNet-50, respectively. Our model is built upon the popular implementation of Zhou et al. <ref type="bibr" target="#b63">[63]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison with State-of-the art Methods</head><p>Results on PACS. In <ref type="table" target="#tab_0">Table 1</ref>, we compare our method with previous domain generalization methods on PACS dataset <ref type="bibr" target="#b27">[28]</ref>. Recognizably, our method beats previous approaches and achieves a new state-of-the-art performance with the average accuracy of 85.86% with ResNet-18. Consistently, our method shows large improvements when adopting ResNet-50 as our backbone, accomplishing a new record with the average accuracy of 87.86% across the leaveone-domain-out scenarios.</p><p>Through the experiments, vivid performance gains are observed when art and sketch domains are set as target domains. This is reasonable since our method has the strength in generating novel  styles while preserving the shape cues which are essential for accurate classification in those domains. Despite the slight performance degradation in the photo domain, our method outperforms the competitors in terms of the average accuracy, validating the better domain generalization ability. We note that our feature stylization module does not require additional network parameters, which makes our model more competitive in terms of memory. Results on office-Home. We also provide the results on Office-Home benchmark <ref type="bibr" target="#b12">[13]</ref> in <ref type="table" target="#tab_1">Table 2</ref>. Again, our method breaks the record with ResNet-18, achieving the average accuracy of 66.2%. Conspicuously, ours makes the performance improvements regardless of the target domain. Overall comparisons verify the effectiveness of our feature stylization strategy and the proposed contrastive loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Single-source Domain Generalization</head><p>In <ref type="table" target="#tab_2">Table 3</ref>, we present the single source domain generalization results with ResNet18 on PACS benchmark. In this setting, only a single domain is selected as a source dataset and the trained model is tested on other target domains. Rows and columns indicate source and target domains, respectively. We use the same hyperparameter settings described in the previous section, except for the scale parameters , both of which are scaled down to 5. In addition, since the source domain is single in this setting, ( ) in L is naturally ignored. Except for the diagonal elements where train and test domains are the same, we achieve improvements on the most of domain generalization scenarios. We can observe remarkable performance gain on "Photo-to-Sketch", "Art-to-Cartoon", "Sketch-to-Art", and "Sketch-to-Cartoon" settings. Especially, a huge performance improvement is observed when the sketch is used for the source domain, i.e., only coarse shape information is available for training. This demonstrates the style diversification ability of our feature stylization block. The "Art-to-Photo" setting is the only generalization scenario where a performance degradation is observed but still in an acceptable margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis</head><p>In this section, we analyze our method and conduct ablation studies on the PACS benchmark with ResNet-18 backbone. To be specific, we first analyze the effect of each loss function, then we investigate the correlation between the performance and the scale parameter . Thereafter, we examine the most suitable location of the feature stylization block followed by the analysis on the feature decomposition with frequency components. We note that all remaining hyper-parameters are fixed through ablation studies.</p><p>Ablation study on components. We conduct an ablation study to inspect the contribution of the feature stylization along with loss functions. As shown in <ref type="table" target="#tab_3">Table 4</ref>, every single component enlarges the generalization capacity of the model compared to the baseline. In detail, the effectiveness of feature stylization is observable with the overall performance improvement of ?4.08%, in terms of the average accuracy. Specifically, the performance gain on the sketch domain is delightful, reaching ?8.71%. In addition, it is verified that the consistency loss boosts domain robustness by regularizing the output discrepancy between original and stylized features. Moreover, the proposed domain-aware contrastive loss enhances the performance by pursuing feature similarities between different domains but with the same category. Consequently, with the harmonious combination of aforementioned components, we can find that all components are complementary and have a positive effect in the domain generalization task. Acc.(%) <ref type="bibr" target="#b27">[28]</ref> Figure 3: Ablation of scale parameter. The value of scale parameters and the accuracy is on the x and y axis, respectively. We also draw the average accuracy of baseline as a dotted line for better comparison.</p><p>The scale parameter. In <ref type="figure">Fig. 3</ref>, we compare different scale parameters in the feature stylization block. We adjust scale parameters ( , ) in {1, 5, 10, 15, 20}. With the scale parameters of 1, augmented style vectors follow the original style distribution, leading to a marginal improvement. As the scale parameter increases, the outlying style vectors are more likely to be sampled, thus increasing the generalization ability. However, excessive scale values produce too distant features and outputs from the original one, resulting in high favoritism on shape cues. This is undesirable since shape cues are not sufficient for visual recognition and texture cues still contains class-discriminative information as in the human visual system <ref type="bibr" target="#b42">[43]</ref>. The best performance is found at the scale parameter of 10, which may be the "sweet spot" of exploiting both shape and textural cues.</p><p>Feature decomposition strategy. We verify the effect of decomposing the feature into high frequency and low frequency components. In <ref type="table" target="#tab_4">Table 5</ref>, we compare between exploiting whole feature without decomposition (-), high frequency components , and low frequency components for feature stylization. As shown in Table 5, the best performance is achieved when the feature stylization is applied only on low frequency components. Applying stylization on high frequency feature falls behind the other strategies, since only the shape information is partially distorted. Meanwhile, although transforming the whole feature seems to be a good strategy overall, it shows inferior performances on the domains where shape cues are crucial, such as art and sketch domains.</p><p>Location of the feature stylization block. We discuss on where the proposed feature stylization block should be located. We denote these stack of residual blocks by re-grouping the ResNet architecture into 5 groups of layers, Conv and ResBlock 1-4, where Conv denotes the first convolutional layer before residual blocks.</p><p>As shown in <ref type="table" target="#tab_5">Table 6</ref>, the best spot of the proposed feature stylization is right after the second residual blocks. This is quite reasonable considering the nature of deep neural networks <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b45">46]</ref>, where  features at this level adequately represent low-level structural information as well as high-level semantic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we proposed a novel framework for domain generalization, where the features are stylized into diverse domains. In detail, we sampled domain style vectors from the manipulated distribution of batch-wise feature statistics, then utilized the style vectors for affine transformation. To achieve the domain robustness, we exploited stylized features for regularization in terms of output consistency and feature similarity via consistency loss and novel domain-aware supervised contrastive loss, respectively. Through comparisons and extensive analyses on two popular benchmarks, we demonstrated the effectiveness of the proposed feature stylization and two losses.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The overview of our proposed methods. We illustrate the overall architecture on (a). The backbone consists of multiple convolutional layers, and we stylize the feature on the intermediate layer of backbone. Both origianl and stylized features follow the same forward path, producing class predictions (?( )) and (?( )). The predictions and features are exploited with the consistency regularization (L ) and domain-aware supervised contrastive loss (L ) which are described in (b) and (c), respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Photo</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Quantitative leave-one-domain-out results on PACS. Entries are sorted in the chronological order and separated based on the backbones.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Accuracy(%)</cell></row><row><cell></cell><cell>Method</cell><cell>Photo</cell><cell>Art</cell><cell cols="2">Cartoon Sketch Avg.</cell></row><row><cell></cell><cell cols="3">Baseline [28] 95.19 77.87</cell><cell>75.89</cell><cell>69.27</cell><cell>76.56</cell></row><row><cell></cell><cell>D-SAM [12]</cell><cell cols="2">95.30 77.33</cell><cell>72.43</cell><cell>77.83</cell><cell>80.72</cell></row><row><cell></cell><cell>MetaReg [2]</cell><cell cols="2">95.50 83.70</cell><cell>77.20</cell><cell>70.30</cell><cell>81.68</cell></row><row><cell></cell><cell>JiGen [5]</cell><cell cols="2">96.03 79.42</cell><cell>75.25</cell><cell>71.35</cell><cell>80.51</cell></row><row><cell></cell><cell>MASF [11]</cell><cell cols="2">94.99 80.29</cell><cell>77.17</cell><cell>71.69</cell><cell>81.04</cell></row><row><cell></cell><cell cols="3">Epi-FCR [30] 93.90 82.10</cell><cell>77.00</cell><cell>73.00</cell><cell>81.50</cell></row><row><cell>ResNet-18</cell><cell cols="3">InfoDrop [46] 96.11 80.27 DMG [6] 93.35 76.90 EISNet [54] 95.93 81.89 L2A-OT [62] 96.20 83.30</cell><cell>76.54 80.38 76.44 78.20</cell><cell>76.38 75.21 74.33 73.60</cell><cell>82.33 81.46 82.15 82.83</cell></row><row><cell></cell><cell>DSON [44]</cell><cell cols="2">95.87 84.67</cell><cell>77.65</cell><cell>82.23 85.11</cell></row><row><cell></cell><cell>RSC [23]</cell><cell cols="2">95.99 83.43</cell><cell>80.31</cell><cell>80.85</cell><cell>85.15</cell></row><row><cell></cell><cell cols="3">MixStyle [64] 96.10 84.10</cell><cell>78.80</cell><cell>75.90</cell><cell>83.73</cell></row><row><cell></cell><cell cols="3">pAdaIN [35] 96.29 81.74</cell><cell>76.91</cell><cell>75.13</cell><cell>82.52</cell></row><row><cell></cell><cell>Ours</cell><cell cols="2">95.63 85.30</cell><cell>81.31</cell><cell>81.19 85.86</cell></row><row><cell></cell><cell cols="3">Baseline [28] 97.66 86.20</cell><cell>78.70</cell><cell>70.63</cell><cell>83.30</cell></row><row><cell></cell><cell>MetaReg [2]</cell><cell cols="2">97.60 87.20</cell><cell>79.20</cell><cell>70.30</cell><cell>83.58</cell></row><row><cell></cell><cell>MASF [11]</cell><cell cols="2">95.01 82.89</cell><cell>80.49</cell><cell>72.29</cell><cell>82.67</cell></row><row><cell>ResNet-50</cell><cell>DMG [6] EISNet [54] DSON [44] RSC [23]</cell><cell cols="2">94.49 82.57 97.11 86.64 95.99 87.04 97.92 87.89</cell><cell>78.11 81.53 80.62 82.16</cell><cell>75.21 78.07 82.90 83.35 87.83 82.60 85.84 86.64</cell></row><row><cell></cell><cell>pAdaIN [35]</cell><cell cols="2">97.17 85.82</cell><cell>81.06</cell><cell>77.37</cell><cell>85.36</cell></row><row><cell></cell><cell>Ours</cell><cell cols="2">96.59 88.48</cell><cell>83.83</cell><cell>82.92 87.96</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Quantitative leave-one-domain-out results on Office-home. Entries are sorted in the chronological order.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Accuracy(%)</cell><cell></cell></row><row><cell></cell><cell>Method</cell><cell>Art</cell><cell cols="3">Clipart Product Real</cell><cell>Avg.</cell></row><row><cell></cell><cell>Baseline [51]</cell><cell>52.15</cell><cell>45.86</cell><cell>70.86</cell><cell cols="2">73.15 60.51</cell></row><row><cell></cell><cell>CCSA [33]</cell><cell>59.90</cell><cell>49.9</cell><cell>74.10</cell><cell>75.7</cell><cell>64.90</cell></row><row><cell></cell><cell>D-SAM [12]</cell><cell>58.03</cell><cell>44.37</cell><cell>69.22</cell><cell cols="2">71.45 60.77</cell></row><row><cell>ResNet-18</cell><cell cols="3">CrossGrad [45] 58.40 MMD-AAE [31] 56.50 JiGen [5] 53.04 L2A-OT [62] 60.60 50.10 49.40 47.30 47.51 DSON [44] 59.37 45.70</cell><cell>73.90 72.10 71.47 74.80 71.84</cell><cell cols="2">75.80 64.38 74.80 62.68 72.79 61.20 77.00 65.63 74.68 62.90</cell></row><row><cell></cell><cell>RSC [23]</cell><cell>58.42</cell><cell>47.90</cell><cell>71.63</cell><cell cols="2">74.54 63.12</cell></row><row><cell></cell><cell>MixStyle [64]</cell><cell>58.70</cell><cell>53.40</cell><cell>74.20</cell><cell cols="2">75.90 65.55</cell></row><row><cell></cell><cell>Ours</cell><cell cols="2">60.24 53.54</cell><cell>74.36</cell><cell cols="2">76.66 66.20</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results of single source domain generalization on PACS. Each row and column indicates the source and target domain, respectively. We report the accuracy with the absolute gain from baseline in brackets. Positive and negative gains are colored green and red, respectively.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Accuracy (%)</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">(Absolute gain from baseline)</cell></row><row><cell></cell><cell cols="4">Photo Art painting Cartoon Sketch</cell></row><row><cell>Photo</cell><cell>99.88 (+0.00)</cell><cell>63.18 (+5.61)</cell><cell>21.84 (+2.43)</cell><cell>54.71 (+28.59)</cell></row><row><cell>Art painting</cell><cell>96.53 (-0.06)</cell><cell>99.46 (+0.00)</cell><cell>67.79 (+11.56)</cell><cell>53.59 (+9.60)</cell></row><row><cell>Cartoon</cell><cell>84.97 (+0.54)</cell><cell>70.56 (+9.09)</cell><cell>99.57 (+0.12)</cell><cell>70.90 (+8.50)</cell></row><row><cell>Sketch</cell><cell>41.56 (+9.16)</cell><cell>43.07 (+13.53)</cell><cell>60.20 (+15.96)</cell><cell>99.36 (-0.08)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Ablation study on each component. ? denotes that stylized features are aggregated for cross-entropy loss (L ).</figDesc><table><row><cell>Accuracy(%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Ablation study on feature decomposition strategies. The column "Frequency component" denotes the component where feature stylization is applied. "-" denotes use of the original feature , while and indicate the high frequency and low frequency features respectively.</figDesc><table><row><cell>Accuracy(%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Ablation study on the location of feature stylization block. Conv 94.91 81.25 79.10 77.85 83.28 ResBlock 1 96.11 83.74 80.33 76.02 84.05 ResBlock 2 95.63 85.30 81.31 81.19 85.86 ResBlock 3 95.99 82.19 78.67 68.13 81.24 ResBlock 4 95.39 82.18 79.14 70.77 81.87</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Accuracy(%)</cell><cell></cell><cell></cell></row><row><cell>Layer</cell><cell>P</cell><cell>A</cell><cell>C</cell><cell>S</cell><cell>Avg.</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast generalized distillation for semi-supervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Ao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Metareg: Towards domain generalization using meta-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="998" to="1008" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">Wortman</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koby</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">137</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fabio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio D&amp;apos;</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvia</forename><surname>Innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2229" to="2238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Learning to Balance Specificity and Invariance for In and Out of Domain Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Prithvijit Chattopadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoffman</surname></persName>
		</author>
		<idno>abs/2008.12839</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">RobustNet: Improving Domain Generalization in Urban-Scene Segmentation via Instance Selective Whitening</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungha</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghun</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiwon</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanne</forename><forename type="middle">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungryong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="11580" to="11590" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daum?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<idno type="arXiv">arXiv:0907.1815</idno>
		<title level="m">Frustratingly easy domain adaptation</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semi-supervised domain adaptation with instance constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Rodner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="668" to="675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="647" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Domain generalization via model-agnostic learning of semantic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Kamnitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Glocker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.13580</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Domain generalization with domain-specific aggregation modules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Antonio D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="187" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Model-agnostic metalearning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. PMLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image style transfer using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">S</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2414" to="2423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2551" to="2559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Neural Information Processing Systems</title>
		<meeting>the 17th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="529" to="536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cycada: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Fsdr: Frequency space domain randomization for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dayan</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoran</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijian</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6891" to="6902" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Arbitrary style transfer in real-time with adaptive instance normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1501" to="1510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Self-Challenging Improves Cross-Domain Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Supervised Contrastive Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prannay</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Maschinot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning texture invariant representation for domain adaptation of semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeongjin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeran</forename><surname>Byun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12975" to="12984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deeper, Broader and Artier Domain Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5543" to="5551" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning to Generalize: Meta-Learning for Domain Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Episodic Training for Domain Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Da Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1446" to="1455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5400" to="5409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Revisiting batch normalization for practical domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naiyan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodi</forename><surname>Hou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04779</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Unified Deep Supervised Domain Adaptation and Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5716" to="5726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonseob</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyo-Eun</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="2558" to="2567" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Nuriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sagie</forename><surname>Benaim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<title level="m">Permuted AdaIN: Enhancing the Representation of Local Cues in Image Classifiers. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Two at once: Enhancing learning and generalization capacities via ibn-net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV</title>
		<meeting>the European Conference on Computer Vision (ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="464" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Uncertainty-guided model generalization to unseen domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengchun</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6790" to="6800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning to learn single domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengchun</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12556" to="12565" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><forename type="middle">Darrell</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Semi-supervised domain adaptation via minimax entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniaki</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8050" to="8058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Maximum classifier discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniaki</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kohei</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3723" to="3732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Perception of object shape and texture in human newborns: evidence from cross-modal transfer tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Coralie</forename><surname>Sann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arlette</forename><surname>Streri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Developmental science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="399" to="410" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning to Optimize Domain Specific Normalization for Domain Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seonguk</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yumin</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongwoo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Generalizing Across Domains via Cross-Gradient Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Informative dropout for robust representation learning: A shapebias perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baifeng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinghuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning. PMLR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8828" to="8839" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<title level="m">and Colin Raffel. 2020. Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Return of frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Domain randomization for transferring deep neural networks from simulation to the real world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tobin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE/RSJ international conference on intelligent robots and systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7167" to="7176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hemanth</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shayok</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sethuraman</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5018" to="5027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songwei</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.13549</idno>
		<title level="m">Learning robust global representations by penalizing local predictive power</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning Robust Representations by Projecting Superficial Statistics Out</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zexue</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zachary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning from Extrinsic and Intrinsic Supervisions for Domain Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lequan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caizi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A Fourier-based Framework for Domain Generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruipeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="14383" to="14392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Deep Cocktail Network: Multi-source Unsupervised Domain Adaptation with Category Shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
				<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3964" to="3973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Robust and generalizable visual representation learning via random convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenlin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junlin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Niethammer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Semi-supervised domain adaptation with subspace learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingwei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong-Wah</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houqiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2142" to="2150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Photorealistic Style Transfer via Wavelet Transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaejun</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjung</forename><surname>Uh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byeongkyu</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung-Woo</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9035" to="9044" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Domain randomization and pyramid consistency: Simulation-to-real generalization without accessing target domain data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sicheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Sangiovanni-Vincentelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2100" to="2110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Deceptionnet: Networkdriven domain randomization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zakharov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wadim</forename><surname>Kehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="532" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Learning to generate novel domains for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="561" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.07325</idno>
		<title level="m">Domain Adaptive Ensemble Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Domain generalization with mixstyle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
