<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Robust Global Representations by Penalizing Local Predictive Power</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
							<email>haohanw@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songwei</forename><surname>Ge</surname></persName>
							<email>songweig@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
							<email>epxing@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
							<email>zlipton@cs.cmu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Carnegie Mellon University Pittsburgh</orgName>
								<address>
									<postCode>15213</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Robust Global Representations by Penalizing Local Predictive Power</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T18:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite their well-documented predictive power on i.i.d. data, convolutional neural networks have been demonstrated to rely more on high-frequency (textural) patterns that humans deem superficial than on low-frequency patterns that agree better with intuitions about what constitutes category membership. This paper proposes a method for training robust convolutional networks by penalizing the predictive power of the local representations learned by earlier layers. Intuitively, our networks are forced to discard predictive signals such as color and texture that can be gleaned from local receptive fields and to rely instead on the global structure of the image. Across a battery of synthetic and benchmark domain adaptation tasks, our method confers improved generalization. To evaluate cross-domain transfer, we introduce ImageNet-Sketch, a new dataset consisting of sketch-like images and matching the ImageNet classification validation set in categories and scale.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Consider the task of determining whether a photograph depicts a tortoise or a sea turtle. A human might check to see whether the shell is dome-shaped (indicating tortoise) or flat (indicating turtle). She might also check to see whether the feet are short and bent (indicating tortoise) or fin-like and webbed (indicating turtle). However, the pixels corresponding to the turtle (or tortoise) itself are not alone in offering predictive value. As easily confirmed through a Google Image search, sea turtles tend to be photographed in the sea while tortoises tend to be photographed on land.</p><p>Although an image's background may indeed be predictive of the category of the depicted object, it nevertheless seems unsettling that our classifiers should depend so precariously on a signal that is in some sense irrelevant. After all, a tortoise appearing in the sea is still a tortoise and a turtle on land is still a turtle. One reason why we might seek to avoid such a reliance on correlated but semantically unrelated artifacts is that they might be liable to change out-of-sample. Even if all cats in a training set appear indoors, we might require a classifier capable of recognizing an outdoors cat at test time. Indeed, recent papers have attested to the tendency of neural networks to rely on surface statistical regularities rather than learning global concepts <ref type="bibr" target="#b23">(Jo and Bengio, 2017;</ref><ref type="bibr" target="#b15">Geirhos et al., 2019)</ref>. A number of papers have demonstrated unsettling drops in performance when convolutional neural networks are applied to out-of-domain testing data, even in the absence of adversarial manipulation.</p><p>The problem of developing robust classifiers capable of performing well on out-of-domain data is broadly known as Domain Adaptation <ref type="bibr">(DA)</ref>. While the problem is known to be impossible absent any restrictions on the relationship between training and test distributions <ref type="bibr" target="#b3">(Ben-David et al., 2010b)</ref>, progress is often possible under reasonable assumptions. Theoretically-principled algorithms have been proposed under a variety of assumptions, including covariate shift <ref type="bibr" target="#b48">(Shimodaira, 2000;</ref><ref type="bibr" target="#b17">Gretton et al., 2009)</ref> and label shift <ref type="bibr" target="#b49">(Storkey, 2009;</ref><ref type="bibr" target="#b47">Sch?lkopf et al., 2012;</ref><ref type="bibr" target="#b58">Zhang et al., 2013;</ref>  </p><formula xml:id="formula_0">C x L M x N x L logits</formula><p>C inputs for every patch <ref type="figure">Figure 1</ref>: In addition to the primary classifier, our model consists of a number of side classifiers, applied at each 1 ? 1 location in a designated early layer. The side classifiers result in one prediction per spatial location. The goal of patch-wise adversarial regularization is to fool all of them (via reverse gradient) while nevertheless outputting the correct class from the topmost layer. 2018). Despite some known impossibility results for general DA problems <ref type="bibr" target="#b3">(Ben-David et al., 2010b)</ref>, in practice, humans exhibit remarkable robustness to a wide variety of distribution shifts, exploiting a variety of invariances, and knowledge about what a label actually means.</p><p>Our work is motivated by the intuition that for the classes typically of interest in many image classification tasks, the larger-scale structure of the image is what makes the class apply and while small local patches might be predictive of the label, Such local features, considered independently, should not (vis-a-vis robustness desiderata) comprise the basis for outputting a given classification. Instead, we posit that classifiers that are required to (in some sense) discard this local signal (i.e., patches of an images correlated to the label within a data collection), basing predictions instead on global concepts (i.e., concepts that can only be derived by combining information intelligently across regions), may better mimic the robustness that humans demonstrate in visual recognition.</p><p>In this paper, in order to coerce a convolutional neural network to focus on the global concept of an object, we introduce Patch-wise Adversarial Regularization (PAR), a learning scheme that penalizes the predictive power of local representations in earlier layers. The method consists of a patch-wise classifier applied at each spatial location in low-level representation. Via the reverse gradient technique popularized by <ref type="bibr" target="#b13">Ganin et al. (2016)</ref>, our network is optimized to fool the side classifiers and simultaneously optimized to output correct predictions at the final layer. Design choices of PAR include the layer on which the penalty is applied, the regularization strength, and the number of layers in the patch-wise network-in-network classifier.</p><p>In extensive experiments across a wide spectrum of synthetic and real data sets, our method outperforms the competing ones, especially when the domain information is not available. We also take measures to evaluate our model's ability to learn concepts at real-world scale despite the small scale of popular domain adaptation benchmarks. Thus we introduce a new benchmark dataset that resembles ImageNet in the choice of categories and size, but consists only of images with the aesthetic of hand-drawn sketches. Performances on this new benchmark also endorse our regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A broad set of papers have addressed various formulations of DA <ref type="bibr" target="#b6">(Bridle and Cox, 1991;</ref><ref type="bibr" target="#b2">Ben-David et al., 2010a)</ref> dating in the ML and statistics literature to early works on covariate shift <ref type="bibr" target="#b48">Shimodaira (2000)</ref> with antecedents classic econometrics work on sample selection bias <ref type="bibr" target="#b18">(Heckman, 1977;</ref><ref type="bibr" target="#b37">Manski and Lerman, 1977)</ref>. Several modern works address principled learning techniques under covariate shift (when p(y|x) does not change) <ref type="bibr" target="#b17">(Gretton et al., 2009</ref>) and under label shift (when p(x|y) doesn't change) <ref type="bibr" target="#b49">(Storkey, 2009;</ref><ref type="bibr" target="#b58">Zhang et al., 2013;</ref><ref type="bibr" target="#b33">Lipton et al., 2018)</ref>, and various other assumptions (e.g. bounded divergences between source and target distributions) <ref type="bibr" target="#b38">(Mansour et al., 2009;</ref><ref type="bibr" target="#b22">Hu et al., 2016</ref>).</p><p>With the recent success of deep learning methods, a number of heuristic domain adaptation methods have been proposed that despite lacking theoretical backing nevertheless confer improvements on a number of benchmarks, even when traditional assumptions break down (e.g., no shared support).</p><p>At a high level these methods comprise two subtypes: fine-tuning over target domain <ref type="bibr" target="#b34">(Long et al., 2016;</ref><ref type="bibr" target="#b39">Motiian et al., 2017a;</ref><ref type="bibr" target="#b14">Gebru et al., 2017;</ref><ref type="bibr" target="#b51">Volpi et al., 2018)</ref> and coercing domain invariance via adversarial learning (or further extensions) <ref type="bibr" target="#b13">(Ganin et al., 2016;</ref><ref type="bibr" target="#b5">Bousmalis et al., 2017;</ref><ref type="bibr" target="#b57">Xie et al., 2018;</ref><ref type="bibr" target="#b21">Hoffman et al., 2018;</ref><ref type="bibr" target="#b35">Long et al., 2018;</ref><ref type="bibr" target="#b60">Zhao et al., 2018b;</ref><ref type="bibr" target="#b26">Kumar et al., 2018;</ref><ref type="bibr" target="#b32">Li et al., 2018b;</ref><ref type="bibr" target="#b59">Zhao et al., 2018a;</ref><ref type="bibr" target="#b46">Schoenauer-Sebag et al., 2019)</ref>. While some methods have justified domain-adversarial learning by appealing to theoretical bounds due to <ref type="bibr" target="#b2">Ben-David et al. (2010a)</ref>, the theory does not in fact guarantee generalization (recently shown by <ref type="bibr" target="#b24">Johansson et al. (2019)</ref> and ) and sometimes guarantees failure. For a general primer, we refer to several literature reviews <ref type="bibr" target="#b55">(Weiss et al., 2016;</ref><ref type="bibr" target="#b9">Csurka, 2017;</ref><ref type="bibr" target="#b54">Wang and Deng, 2018)</ref>.</p><p>In contrast to the typical unsupervised DA setup, which requires access to both labeled source data and unlabeled target data, several recent papers propose deep learning methods that confer robustness to a variety of natural-seeming distribution shifts (in practice) without requiring any data (even unlabeled data) from the target distribution. In domain generalization (DG) methods ) (or sometimes known as "zero shot domain adaptation" <ref type="bibr" target="#b25">(Kumagai and Iwata, 2018;</ref><ref type="bibr" target="#b42">Niu et al., 2015;</ref><ref type="bibr" target="#b12">Erfani et al., 2016;</ref><ref type="bibr" target="#b31">Li et al., 2017c)</ref>) one possesses domain identifiers for a number of known in-sample domains, and the goal is to generalize to a new domain. More recent DG approaches incorporate adversarial (or similar) techniques <ref type="bibr" target="#b16">(Ghifary et al., 2015;</ref><ref type="bibr" target="#b40">Motiian et al., 2017b;</ref><ref type="bibr" target="#b30">Li et al., 2018a;</ref><ref type="bibr" target="#b7">Carlucci et al., 2018)</ref>, or build ensembles of per-domain models that are then fused representations together <ref type="bibr" target="#b4">(Bousmalis et al., 2016;</ref><ref type="bibr" target="#b11">Ding and Fu, 2018;</ref><ref type="bibr" target="#b36">Mancini et al., 2018)</ref>. Meta-learning techniques have also been explored <ref type="bibr" target="#b29">(Li et al., 2017b;</ref><ref type="bibr" target="#b1">Balaji et al., 2018)</ref>.</p><p>More recently, <ref type="bibr" target="#b53">Wang et al. (2019)</ref> demonstrated promising results on a number of benchmarks without using domain identifiers. Their method achieves addresses distribution shift by incorporating a new component intended to be especially sensitive to domain-specific signals. Our paper extends the setup of <ref type="bibr" target="#b53">(Wang et al., 2019)</ref> and empirically studies the problem of developing image classifiers robust to a variety of natural shifts without leveraging any domain information at training or deployment time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>We use X, y to denote the samples and f (g(?; ?); ?) to denote a convolutional neural network, where g(?; ?) denotes the output of the bottom convolutional layers (e.g., the first layer), and ? and ? are parameters to be learned. The traditional training process addresses the optimization problem</p><formula xml:id="formula_1">min ?,? E (X,y) [l(f (g(X; ?); ?), y)],<label>(1)</label></formula><p>where l(?, ?) denotes the loss function, commonly cross-entropy loss in classification problems.</p><p>Following the standard set-up of a convolutional layer, ? is a tensor of c ? m ? n parameters, where c denotes the number of convolutional channels, and m ? n is the size of the convolutional kernel. Therefore, for the i th sample, g(X i ; ?) is a representation of X i of the dimension c ? m ? n , where m (or n ) is a function of the image dimension and m (or n). 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Patch-wise Adversarial Regularization</head><p>We first introduce a new classifier, h(?; ?) that takes the input of a c-length vector and predicts the label. Thus, h(?; ?) can be applied onto the representation g(X i ; ?) and yield m ? n predictions. Therefore, each of the m ? n predictions can be seen as a prediction made only by considering a small image patch corresponding to each of the receptive fields in g(X i ; ?). If any of the image patches are predictive and g(?; ?) summarizes the predictive representation well, h(?; ?) can be trained to achieve a high prediction accuracy.</p><p>On the other hand, if g(?; ?) summarizes the patch-wise predictive representation well, higher layers (f (?; ?)) can directly utilize these representation for prediction and thus may not be required to learn a global concept. Our intuition is that by regularizing g(?; ?) such that each fiber (i.e., representation at the same location from every channel) in the activation tensor should not be individually predictive of the label, we can prevent our model from relying on local patterns and instead force it to learn a pattern that can only be revealed by aggregating information across multiple receptive fields.</p><p>As a result, in addition to the standard optimization problem (Eq. 1), we also optimize the following term:</p><formula xml:id="formula_2">min ? max ? E (X,y) [ m ,n i,j l(h(g(X; ?) i,j ; ?), y)]<label>(2)</label></formula><p>where the minimization consists of training h(?; ?) to predict the label based on the local features (at each spatial location) while the maximization consists of training g(?; ?) to shift focus away from local predictive representations.</p><p>We hypothesize that by jointly solving these two optimization problems (Eq. 1 and Eq. 2), we can train a model that can predict the label well without relying too strongly on local patterns. The optimization can be reformulated into the following two problems:</p><formula xml:id="formula_3">min ?,? E (X,y) [l(f (g(X; ?); ?), y) ? ? m n m ,n i,j l(h(g(X; ?) i,j ; ?), y)] min ? E (X,y) [ ? m n m ,n i,j l(h(g(X; ?) i,j ; ?), y)]</formula><p>where ? is a tuning hyperparameter. We divide the loss by m n to keep the two terms at a same scale.</p><p>Our method can be implemented efficiently as follows: In practice, we consider h(?; ?) as a fullyconnected layer. ? consists of a c ? k weight matrix and a k-length bias vector, where k is the number of classes. The m ? n forward operations as fully-connected networks can be efficiently implemented as a 1 ? 1 convolutional operation with c input channels and k output channels operating on the m ? n representation.</p><p>Note that although the input has m ? n vectors, h(?; ?) only has one set of parameters that is used for all these vectors, in contrast to building a set of parameter for every receptive field of the m ? n dimension. Using only one set of parameters can not only help to reduce the computational load and parameter space, but also help to identify the predictive local patterns well because the predictive local pattern does not necessarily appear at the same position across the images. Our idea of our method is illustrated in <ref type="figure">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Other Extensions and Training Heuristics</head><p>There can be many simple extensions to the basic PAR setting we discussed above. Here we introduce three extensions that we will experiment with later in the experiment section.</p><p>More Powerful Pattern Classifier: We explore the space of discriminator architectures, replacing the single-layer network h(?; ?) with a more powerful network architecture, e.g. a multilayer perceptron (MLP). In this paper, we consider three-layer MLPs with ReLU activation functions. We name this variant as PAR M .</p><p>Broader Local Pattern: We can also extend the 1 ? 1 convolution operation to enlarge the concept of "local". In this paper, we experiment with a 3 ? 3 convolution operation, thus the number of parameters in ? is increased. We refer to this variant as PAR B .</p><p>Higher Level of Local Concept: Further, we can also build the regularization upon higher convolutional layers. Building the regularization on higher layers is related to enlarging the patch of image, but also considering higher level of abstractions. In this paper, we experiment the regularization on the second layer. We refer this method as PAR H .</p><p>Training Heuristics: Finally, we introduce the training heuristic that plays an important role in our regularization technique, especially in modern architectures such as AlexNet or ResNet. The training heuristic is simple: we first train the model conventionally until convergence (or after a certain number of epochs), then train the model with our regularization. In other words, we can also directly work on pretrained models and continue to fine-tune the parameters with our regularization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we test PAR over a variety of settings, we first test with perturbed MNIST under the domain generalization setting, and then test with perturbed CIFAR10 under domain adaptation setting. Further, we test on more challenging data sets, with PACS data under domain generalization setting and our newly proposed ImageNet-Sketch data set. We compare with previous state-of-the-art when available, or with the most popular benchmarks such as DANN <ref type="bibr" target="#b13">(Ganin et al., 2016)</ref>, InfoDrop <ref type="bibr" target="#b0">(Achille and Soatto, 2018)</ref>, and HEX <ref type="bibr" target="#b53">(Wang et al., 2019)</ref> on synthetic experiments. 2,3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">MNIST with Perturbation</head><p>We follow the set-up of <ref type="bibr" target="#b53">Wang et al. (2019)</ref> in experimenting with MNIST data set with different superficial patterns. There are three different superficial patterns (radial kernel, random kernel, and original image). The training/validation samples are attached with two of these patterns, while the testing samples are attached with the remaining one. As in <ref type="bibr" target="#b53">Wang et al. (2019)</ref>, training/validation samples are attached with patterns following two strategies: 1) independently: the pattern is independent of the digit, and 2) dependently: images of digit 0-4 have one pattern while images of digit 5-9 have the other pattern.</p><p>We use the same model architecture and learning rate as in <ref type="bibr" target="#b53">Wang et al. (2019)</ref>. The extra hyperparameter ? is set as 1 as the most straightforward choice. Methods in <ref type="bibr" target="#b53">Wang et al. (2019)</ref> are trained for 100 epochs, so we train the model for 50 epochs as pretraining and 50 epochs with our regularization. The results are shown in <ref type="figure" target="#fig_0">Figure 2</ref>. In addition to the direct message that our proposed method outperforms competing ones in most cases, it is worth mentioning that the proposed methods behave differently in the "dependent" settings. For example, PAR M performs the best in the "original" and "radial" settings, but almost the worst among proposed methods in the "random" setting, which may indicate that the pattern attached by "random" kernel can be more easily detected and removed by PAR M during training (Notice that the name of the setting ("original", "radial" or "random") indicates the pattern attached to testing images, and the training samples are attached with the other two patterns). More information about hyperparameter choice is in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">CIFAR with Perturbation</head><p>We continue to experiment on CIFAR10 data set by modifying the color and texture of test dataset with four different schemas: 1) greyscale; 2) negative color; 3) random kernel; 4) radial kernel. Some examples of the perturbed data are shown in Appendix B. In this experiment, we use ResNet-50 as our base classifier, which has a rough 92% prediction accuracy on original CIFAR10 test data set.</p><p>As for PAR, we first train the base classifier for 250 epochs and then train with the adversarial loss for another 150 epochs. As for the competing models, we also train for 400 epochs with carefully selected hyperparameters. The overall performances are shown in <ref type="table" target="#tab_1">Table 1</ref>. In general, PAR and its variants achieve the best performances on all four test data sets, even when DANN has an unfair advantage over others by seeing unlabelled testing data during training. To be specific, PAR achieves the best performances on the greyscale and radial kernel settings; PAR M is the best on the negative color and random kernel settings. One may argue that the numeric improvements are not significant and PAR may only affect the model marginally, but a closer look at the training process of the methods indicates that our regularization of local patterns benefits the robustness significantly while minimally impacting the original performance. More detailed discussions are in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">PACS</head><p>We test on the PACS data set <ref type="bibr" target="#b28">(Li et al., 2017a)</ref>, which consists of collections of images over four domains, including photo, art painting, cartoon, and sketch. Many recent methods have been tested on this data set, which offers a convenient way for PAR to be compared with the previous state-of-the-art. Following <ref type="bibr" target="#b28">Li et al. (2017a)</ref>, we use AlexNet as baseline and build PAR upon it. We compare with recently reported state-of-the-art on this data set, including DSN <ref type="bibr" target="#b4">(Bousmalis et al., 2016)</ref>, LCNN <ref type="bibr" target="#b28">(Li et al., 2017a)</ref>, MLDG <ref type="bibr" target="#b29">(Li et al., 2017b)</ref>, Fusion <ref type="bibr" target="#b36">(Mancini et al., 2018)</ref>, MetaReg <ref type="bibr" target="#b1">(Balaji et al., 2018)</ref>, Jigen <ref type="bibr" target="#b8">(Carlucci et al., 2019)</ref>, and HEX <ref type="bibr" target="#b53">(Wang et al., 2019)</ref>, in addition to the baseline reported in <ref type="bibr" target="#b28">(Li et al., 2017a)</ref>. We are also aware that methods that explicitly use domain knowledge (e.g., <ref type="bibr" target="#b27">Lee et al., 2018</ref>) may be helpful, but we do not directly compare with them numerically, as the methods deviate from the central theme of this paper. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>! !</head><p>Following the training heuristics we introduced, we continue with trained AlexNet weights 4 and fine-tune on training domain data of PACS for 100 epochs. We notice that once our regularization is plugged in, we can outperform the baseline AlexNet with a 2% improvement. The results are  <ref type="table" target="#tab_2">Table 2</ref>, where we separate the results of techniques relying on domain identifications and techniques free of domain identifications.</p><formula xml:id="formula_4">(a) (b) (c) (d) (e) (f) (g) (h) (i)</formula><p>We also report the results based on the training schedule used by <ref type="bibr" target="#b8">(Carlucci et al., 2019)</ref> as shown in the bottom part of <ref type="table" target="#tab_2">Table 2</ref>. Note that <ref type="bibr" target="#b8">(Carlucci et al., 2019)</ref> used the random training-test split that are different from the official split used by the other baselines. In addition, they used another data augmentation technique to convert image patch to grayscale which could benefit the adaptation to Sketch domain.</p><p>While our methods are in general competitive, it is worth mentioning that our methods improve upon previous methods with a relatively large margin when Sketch is the testing domain. The improvement on Sketch is notable because Sketch is the only colorless domain out of the four domains in PACS. Therefore, when tested with the other three domains, a model may learn to exploit the color information, which is usually local, to predict, but when tested with Sketch domain, the model has to learn colorless concepts to make good predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">ImageNet-Sketch</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">The ImageNet-Sketch Data</head><p>Inspired by the Sketch data of <ref type="bibr" target="#b28">(Li et al., 2017a)</ref> with seven classes, and several other Sketch datasets, such as the Sketchy dataset <ref type="bibr" target="#b45">(Sangkloy et al., 2016)</ref> with 125 classes and the Quick Draw! dataset (QuickDraw, 2018) with 345 classes, and motivated by absence of a large-scale sketch dataset fitting the shape and size of popular image classification benchmarks, we construct the ImageNet-Sketch data set for evaluating the out-of-domain classification performance of vision models trained on ImageNet.</p><p>Compatible with standard ImageNet validation data set for the classification task <ref type="bibr" target="#b10">(Deng et al., 2009</ref>), our ImageNet-Sketch data set consists of 50000 images, 50 images for each of the 1000 ImageNet classes. We construct the data set with Google Image queries "sketch of ", where is the standard class name. We only search within the "black and white" color scheme. We initially query 100 images for every class, and then manually clean the pulled images by deleting the irrelevant images and images that are for similar but different classes. For some classes, there are less than 50 images after manually cleaning, and then we augment the data set by flipping and rotating the images.</p><p>We expect ImageNet-Sketch to serve as a unique ImageNet-scale out-of-domain evaluation dataset for image classification. Also, notably, different from perturbed ImageNet validation sets <ref type="bibr" target="#b15">(Geirhos et al., 2019;</ref><ref type="bibr" target="#b19">Hendrycks and Dietterich, 2019)</ref>, the images of ImageNet-Sketch are collected independently from the original validation images. The independent collection procedure is more similar to <ref type="bibr" target="#b44">(Recht et al., 2019)</ref>, who collected a new set of standard colorful ImageNet validation images. However, while their goal was to assess overfitting to the benchmark validation sets, and thus they tried replicate  the ImageNet collection procedure exactly, our goald is to collect out-of-domain black-and-white sketch images with the goal of testing a model's ability to extrapolate out of domain. 5 Sample images are shown in <ref type="figure" target="#fig_1">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Experiment Results</head><p>We use AlexNet as the baseline and test whether our method can help improve the out-of-domain prediction. We start with ImageNet pretrained AlexNet and continue to use PAR to tune AlexNet for another five epochs on the original ImageNet training dataset. The results are reported in <ref type="table" target="#tab_3">Table 3</ref>.</p><p>We are particularly interested in how PAR improves upon AlexNet, so we further investigate the top-1 prediction results. Although the numeric results in <ref type="table" target="#tab_3">Table 3</ref> seem to show that PAR only improves the upon AlexNet by predicting a few more examples correctly, we notice that these models share 5025 correct predictions, while AlexNet predicts another 1098 images correctly and PAR predicts a different set of 1617 images correctly.</p><p>We first investigate the examples that are correctly predicted by the original AlexNet, but wrongly predicted by PAR. We notice some examples that help verify the performance of PAR. For examples, PAR incorrectly predicts three instances of "keyboard" as "crossword puzzle," while AlexNet predicts these samples correctly. It is notable that two of these samples are "keyboards with missing keys" and hence look similar to a "crossword puzzle."</p><p>We also investigate the examples that are correctly predicted by PAR, but wrongly predicted by the original AlexNet. Interestingly, we notice several samples that are wrongly predicted by AlexNet because the model may only focus on the local patterns. Some of the most interesting examples are reported in <ref type="table" target="#tab_4">Table 4</ref>: The first example is a stethoscope, PAR predicts it correctly with 0.66 confidence, while AlexNet predicts it to be a hook. We conjecture the reason to be that AlexNet tends to only focus on the curvature which resembles a hook. The second example tells a similar story, PAR predicts tricycle correctly with 0.92 confidence, but AlexNet predicts it as a safety pin with 0.51 confidence. We believe this is because part of the image (likely the seat-supporting frame) resembles the structure of a safety pin. For the third example, PAR correctly predicts it to be an Afghan hound with 0.89 confidence, but AlexNet predicts it as a mop with 0.73 confidence. This is likely because the fur of the hound is similar to the head of a mop. For the last example, PAR correctly predicts the object to be red wine with 0.59 confidence, but AlexNet predicts it to be a goblet with 0.74 confidence. This is likely because part of the image is indeed part of a goblet, but PAR may learn to make predictions based on the global concept considering the bottle, the liquid, and part of the goblet together. <ref type="table" target="#tab_4">Table 4</ref> only highlights a few examples, and more examples are shown in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we introduced patch-wise adversarial regularization, a technique that regularizes models, encouraging them to learn global concepts for classifying objects by penalizing the model's ability to make predictions based on representations of local patches. We extended our basic set-up with several different variants and conducted extensive experiments, evaluating these methods with several datasets for domain adaptation and domain generalization tasks. The experimental results favored our methods, especially when domain information is unknown to the methods. In addition to the superior performances we achieved through these experiments, we expected to further challenge our method at real-world scale. Therefore, we also constructed a dataset that matches the ImageNet classification validation set in classes and scales but contains only sketch-alike images. Our new ImageNet-Sketch data set can serve as new territory for evaluating models' ability to generalize to out-of-domain images at an unprecedented scale.</p><p>While our method often confers benefits on out-of-domain data, we note that it may not help (or can even hurt) in-domain accuracy when local patterns are truly predictive of the labels. However, we argue that the local patterns, while predictive in-sample, may be less reliable out-of-domain as compared to larger-scale patterns, which motivates this paper. For the three variations we introduced, our experiments indicate that different variants are applicable to different scenarios. We recommend that users decide which variant to use given their understanding of the problem and hope in future work, to develop clear principles for guiding these choices. While we did not give a clear choice of which PAR to use, we note that none of the variants of PAR outperform the vanilla PAR consistently. However, the vanilla PAR outperforms most comparable baselines in the vast majority of our experiments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Other Hyperparameter Choices for MNIST experiment</head><p>We also experimented with the parameter choices of the method in the MNIST experiment. We varied the ? in {0.01, 0.1, 1, 10, 100} in PAR and reported the performance to guide further usage of the method.</p><p>As we can see from <ref type="figure" target="#fig_2">Figure 4</ref>, PAR seems to prefer the cases when ? is relatively smaller, although what we reported in the main manuscript for the MNIST experiment is ? = 1 as the most straightforward choice, to demonstrate the method's strength.</p><p>Later in other experiments, especially the ImageNet-Sketch experiment, we notice that ? = 1 is too strong (unless the learning rate is set to be much smaller) for the method to work. We observe that a too-strong ? usually immediate deteriorates the performance during first epoches of training. Therefore, in practice, we recommend the users to set the ? (or learning rate) to be smaller if the users observe that our method deteriorates the training performance.   <ref type="figure">Figure 9</ref>: Evaluation with different sizes of convolutional filters. Note that all the local pattern classifiers contain one layer and 10 channels but different filter sizes. In general, the performances with different filter sizes on the test datasets are very similar except for RandomKernel.  <ref type="figure">Figure 10</ref>: Evaluation on adversarial training with multiple levels and the different decays. Note that all the layers are used for extracting local concepts with a decay, i.e. adding weights 1, ?, ? 2 and ? 3 to the adversarial losses of four layers. Smaller decay (larger ?) leads to unstable performances. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Cifar10 discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C More results of ImageNet-Sketch</head><p>We conducted a detailed analysis of ImageNet-Sketch results with the following rules:</p><p>? The samples are correctly predicted by one model, but wrongly predicted by the other.</p><p>? When a model makes wrong predictions, the samples in the class tend to be predicted into a same another class. Therefore, we can exclude some random prediction errors. ? For class A and B, if one model tends to predict samples in class A into class B, and the other model has the reverse tendency, we investigate neither of these classes, because the different prediction results may only be due to the similarity of these two classes. <ref type="table" target="#tab_6">Table 5</ref> shows more samples that are correctly predicted by PAR but wrongly predicted by the original AlexNet, because (as we conjecture) the original AlexNet focuses on local patterns.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Prediction accuracy with standard deviation for MNIST with patterns. Notations: V: vanilla baseline, E: HEX, D: DANN, I: InfoDrop, P: PAR, B: PAR B , M: PAR M , H: PAR H</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Sample Images from ImageNet-Sketch. Corresponding classes: (a) magpie (b) box turtle (c) goldfish (d) golden retriever (e) parachute (f) bookshop (g) acoustic guitar (h) racer (i) giant panda reported in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Prediction accuracy with standard deviation for MNIST with superficial statistics perturbation data set. Notations: V: vanilla baseline, A: PAR with ? = 0.01, B: PAR with ? = 0.1, C: PAR with ? = 1, D: PAR with ? = 10, E: PAR with ? = 100</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Examples of Cifar10 images with perturbed color and texture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>:1905.13549v2 [cs.CV] 5 Nov 2019</figDesc><table><row><cell>C channels</cell><cell></cell></row><row><cell>M x N patches</cell><cell>L logits</cell></row><row><cell>(Reverse Gradient)</cell><cell></cell></row></table><note>33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.arXiv</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Test accuracy of PAR and variants on Cifar10 datasets with perturbed color and texture. ResNet DANN InfoDrop HEX PAR PAR B PAR M PAR H</figDesc><table><row><cell>Greyscale</cell><cell>87.7</cell><cell>87.3</cell><cell>86.4</cell><cell>87.6 88.1</cell><cell>87.9</cell><cell>87.8</cell><cell>86.9</cell></row><row><cell>NegColor</cell><cell>62.8</cell><cell>64.3</cell><cell>57.6</cell><cell>62.4 66.2</cell><cell>65.3</cell><cell>67.6</cell><cell>62.7</cell></row><row><cell>RandKernel</cell><cell>43.0</cell><cell>33.4</cell><cell>41.3</cell><cell>42.5 47.0</cell><cell>40.5</cell><cell>47.5</cell><cell>40.8</cell></row><row><cell>RadialKernel</cell><cell>62.4</cell><cell>63.3</cell><cell>60.3</cell><cell>61.9 63.8</cell><cell>63.2</cell><cell>63.2</cell><cell>61.4</cell></row><row><cell>Average</cell><cell>63.9</cell><cell>62.0</cell><cell>61.4</cell><cell>63.6 66.3</cell><cell>64.2</cell><cell>66.5</cell><cell>62.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell>, 2019) (e.g.,</cell></row></table><note>Prediction accuracy of PAR and variants on PACS data set in comparison with the previously reported state-of-the-art results. Bold numbers indicate the best performance (three sets, one for each scenario). We use to denote the methods that use the training setting in (Carlucci et al.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Testing accuracy of competing methods on the ImageNet-Sketch data. The bottom half denotes the method that has extra advantages: ? denotes the method that has access to unlabelled target domain data, and denotes the method that use extra data augmentation.</figDesc><table><row><cell></cell><cell cols="2">AlexNet InfoDrop</cell><cell>HEX</cell><cell>PAR</cell><cell>PAR B</cell><cell>PAR M</cell><cell>PAR H</cell></row><row><cell>Top 1</cell><cell>0.1204</cell><cell>0.1224</cell><cell cols="4">0.1292 0.1306 0.1273 0.1287 0.1266</cell></row><row><cell>Top 5</cell><cell>0.2480</cell><cell>0.2560</cell><cell cols="4">0.2654 0.2627 0.2575 0.2603 0.2544</cell></row><row><cell></cell><cell></cell><cell cols="2">DANN  ? JigGen</cell><cell>PAR</cell><cell>PAR B</cell><cell>PAR M</cell><cell>PAR H</cell></row><row><cell>Top 1</cell><cell></cell><cell>0.1360</cell><cell cols="4">0.1469 0.1494 0.1494 0.1501 0.1499</cell></row><row><cell>Top 5</cell><cell></cell><cell>0.2712</cell><cell cols="4">0.2898 0.2949 0.2945 0.2957 0.2954</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Some examples that are predicted correctly with our method but wrongly with the original AlexNet because the original model seems to focus on the local patterns.</figDesc><table><row><cell cols="2">AlexNet-PAR</cell><cell cols="2">AlexNet</cell></row><row><cell>prediction</cell><cell>confidence</cell><cell>prediction</cell><cell>confidence</cell></row><row><cell>stethoscope</cell><cell>0.6608</cell><cell>hook</cell><cell>0.3903</cell></row><row><cell>tricycle</cell><cell>0.9260</cell><cell>safety pin</cell><cell>0.5143</cell></row><row><cell>Afghan hound</cell><cell>0.8945</cell><cell>swab (mop)</cell><cell>0.7379</cell></row><row><cell>red wine</cell><cell>0.5999</cell><cell>goblet</cell><cell>0.7427</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>The solid lines represent the test accuracy of PAR with different levels of local patterns during the training process. For a better comparison, we use the dashed lines to represent the test accuracy at 250 epoch when the adversarial training is firstly added. The default PAR is shown in (a), we can see a small jitter after 250 epoch when the model is coerced to forget the information of local patterns. Then the performances on the perturbed dataset start to increase while the performance on the original dataset is not greatly impacted. In addition, when higher level of local patterns are used, little improvement can be observed, except for using level 2 on the negative color.</figDesc><table><row><cell>0.4 0.06 0.08 0.10 0.12 0.14 0.16 0.18 0.20 0.5 0.6 0.7 0.8 0.9 accuracy on different test domains acc on training and vlidation set</cell><cell>0 0</cell><cell cols="3">50 50 Normal Acc 100 150 200 250 300 350 400 number of epochs 100 150 200 250 300 350 400 number of epochs Normal Acc Greyscale Acc Negative Acc Randomkernel Acc Radiokernel Acc Greyscale Acc Negative Acc Randomkernel Acc Radiokernel Acc</cell><cell cols="2">0.08 0.4 0.10 0.12 0.14 0.16 0.18 0.20 0.5 0.6 0.7 0.8 0.9 accuracy on different test domains acc on training and vlidation set</cell><cell>0 0</cell><cell>50 50 Normal Acc 100 150 200 250 300 350 400 number of epochs number of epochs 100 150 200 250 300 350 400 Normal Acc Greyscale Acc Negative Acc Randomkernel Acc Radiokernel Acc Greyscale Acc Negative Acc Randomkernel Acc Radiokernel Acc</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(a) Layer 1 (a) level 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b) Layer 2 (b) level 2</cell></row><row><cell>0.14 0.16 0.18 0.20 0.22 0.24 0.5 0.6 0.7 0.8 0.9 accuracy on different test domains acc on training and vlidation set</cell><cell></cell><cell cols="2">Normal Acc Greyscale Acc Negative Acc Randomkernel Acc Radiokernel Acc</cell><cell>Normal Acc Greyscale Acc Negative Acc Randomkernel Acc Radiokernel Acc</cell><cell>acc on training and vlidation set accuracy on different test domains</cell><cell>0.2 0.3 0.4 0.5 0.6 0.4 0.5 0.6 0.7 0.8 0.9</cell><cell></cell><cell>Normal Acc Greyscale Acc Negative Acc Randomkernel Acc Radiokernel Acc</cell><cell>Normal Acc Greyscale Acc Negative Acc Randomkernel Acc Radiokernel Acc</cell></row><row><cell>0.12 0.4</cell><cell>0 0</cell><cell>50 50</cell><cell cols="2">100 150 200 250 300 350 400 number of epochs 100 150 200 250 300 350 400 number of epochs</cell><cell></cell><cell>0.1</cell><cell>0 0</cell><cell>50 50</cell><cell>100 150 200 250 300 350 400 number of epochs 100 150 200 250 300 350 400 number of epochs</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(c) Layer 3 (c) level 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(d) Layer 4 (d) level 4</cell></row><row><cell cols="9">Figure 7: Prediction accuracy of patch-wise classifier. The regularization is introduced at Epoch 250. we ran experiments to validate the patch-wise classifier. Without (PAR) regularization, the patch-wise classifier can achieve roughly 20% accuracy on in-domain test data ((a), orange, before epoch 250). It achieves 12% accuracy on texture-altered out-of-domain data ((a), magenta and green, before epoch 250) and 5% accuracy color-altered out-of-domain data ((a), maroon, before epoch 250). With PAR, the patch-wise classifier achieves 15% in-domain prediction accuracy (5% drop) ((a), orange, after epoch 250), and 10% on texture-altered out-of-domain data ((a), magenta and green, after epoch 250) and 8% on color-altered out-of-domain data ((a), maroon, after epoch 250). Greyscale Negative RandomKernel RadialKernel 0.0 0.2 0.4 0.6 0.8 1.0 Accuracy 1x1 5x5 Figure 8: Original 3x3 7x7</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Test Category</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>More prediction comparisions between AlexNet-PAR and AlexNet</figDesc><table><row><cell></cell><cell cols="2">AlexNet-PAR</cell><cell>AlexNet</cell><cell></cell><cell cols="2">AlexNet-PAR</cell><cell>AlexNet</cell><cell></cell></row><row><cell>Image</cell><cell>Prediction</cell><cell>Conf.</cell><cell>Prediction</cell><cell>Conf. Image</cell><cell>Prediction</cell><cell>Conf.</cell><cell>Prediction</cell><cell>Conf.</cell></row><row><cell></cell><cell>Afghan hound</cell><cell>0.89</cell><cell>swab (mop)</cell><cell>0.74</cell><cell>sunglass</cell><cell>0.42</cell><cell>strainer</cell><cell>0.27</cell></row><row><cell></cell><cell>Afghan hound</cell><cell>0.92</cell><cell>swab (mop)</cell><cell>0.82</cell><cell>sunglass</cell><cell>0.31</cell><cell>strainer</cell><cell>0.19</cell></row><row><cell></cell><cell>Afghan hound</cell><cell>0.80</cell><cell>swab (mop)</cell><cell>0.20</cell><cell>sunglass</cell><cell>0.38</cell><cell>strainer</cell><cell>0.32</cell></row><row><cell></cell><cell>bull mastiff</cell><cell>0.42</cell><cell>shower cap</cell><cell>0.23</cell><cell>totem pole</cell><cell>0.30</cell><cell>envelope</cell><cell>0.39</cell></row><row><cell></cell><cell>bull mastiff</cell><cell>0.33</cell><cell>shower cap</cell><cell>0.37</cell><cell>totem pole</cell><cell>0.43</cell><cell>envelope</cell><cell>0.27</cell></row><row><cell></cell><cell>bull mastiff</cell><cell>0.57</cell><cell>shower cap</cell><cell>0.77</cell><cell>totem pole</cell><cell>0.50</cell><cell>envelope</cell><cell>0.40</cell></row><row><cell></cell><cell>ashcan</cell><cell>0.17</cell><cell>safety pin</cell><cell>0.41</cell><cell>totem pole</cell><cell>0.45</cell><cell>envelope</cell><cell>0.39</cell></row><row><cell></cell><cell>ashcan</cell><cell>0.38</cell><cell>safety pin</cell><cell>0.26</cell><cell>tricycle</cell><cell>0.17</cell><cell>safety pin</cell><cell>0.42</cell></row><row><cell></cell><cell>ashcan</cell><cell>0.16</cell><cell>safety pin</cell><cell>0.53</cell><cell>tricycle</cell><cell>0.66</cell><cell>safety pin</cell><cell>0.49</cell></row><row><cell></cell><cell>car mirror</cell><cell>0.42</cell><cell>buckle</cell><cell>0.89</cell><cell>tricycle</cell><cell>0.07</cell><cell>safety pin</cell><cell>0.12</cell></row><row><cell></cell><cell>car mirror</cell><cell>0.57</cell><cell>buckle</cell><cell>0.43</cell><cell>tricycle</cell><cell>0.93</cell><cell>safety pin</cell><cell>0.51</cell></row><row><cell></cell><cell>car mirror</cell><cell>0.88</cell><cell>buckle</cell><cell>0.63</cell><cell>whiskey jug</cell><cell>0.20</cell><cell>perfume</cell><cell>0.14</cell></row><row><cell></cell><cell>stethoscope</cell><cell>0.46</cell><cell>hook</cell><cell>0.37</cell><cell>whiskey jug</cell><cell>0.65</cell><cell>perfume</cell><cell>0.37</cell></row><row><cell></cell><cell>stethoscope</cell><cell>0.58</cell><cell>hook</cell><cell>0.55</cell><cell>whiskey jug</cell><cell>0.49</cell><cell>perfume</cell><cell>0.51</cell></row><row><cell></cell><cell>stethoscope</cell><cell>0.77</cell><cell>hook</cell><cell>0.58</cell><cell>head cabbage</cell><cell>0.44</cell><cell>shower cap</cell><cell>0.31</cell></row><row><cell></cell><cell>stethoscope</cell><cell>0.75</cell><cell>hook</cell><cell>0.42</cell><cell>head cabbage</cell><cell>0.78</cell><cell>shower cap</cell><cell>0.79</cell></row><row><cell></cell><cell>stethoscope</cell><cell>0.46</cell><cell>hook</cell><cell>0.59</cell><cell>head cabbage</cell><cell>0.34</cell><cell>shower cap</cell><cell>0.39</cell></row><row><cell></cell><cell>stethoscope</cell><cell>0.66</cell><cell>hook</cell><cell>0.39</cell><cell>red wine</cell><cell>0.32</cell><cell>goblet</cell><cell>0.84</cell></row><row><cell></cell><cell>stethoscope</cell><cell>0.56</cell><cell>hook</cell><cell>0.46</cell><cell>red wine</cell><cell>0.60</cell><cell>goblet</cell><cell>0.74</cell></row><row><cell></cell><cell>stethoscope</cell><cell>0.56</cell><cell>hook</cell><cell>0.49</cell><cell>red wine</cell><cell>0.82</cell><cell>goblet</cell><cell>0.67</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The exact function depends on padding size and stride size, and is irrelevant to the discussion of this paper.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Clean demonstration of the implementation can be found at: https://github.com/HaohanWang/PAR 3 Source code for replication can be found at : https://github.com/HaohanWang/PAR_experiments</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://www.cs.toronto.edu/~guerzhoy/tf_alexnet/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The ImageNet-Sketch data can be found at: https://github.com/HaohanWang/ImageNet-Sketch</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>Haohan Wang is supported by NIH R01GM114311, NIH P30DA035778, and NSF IIS1617583. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Institutes of Health or the National Science Foundation. Zachary Lipton thanks the Center for Machine Learning and Health, a joint venture of Carnegie Mellon University, UPMC, and the University of Pittsburgh for supporting our collaboration with Abridge AI to develop robust models for machine learning in healthcare. He is also grateful to Salesforce Research, Facebook Research, and Amazon AI for faculty awards supporting his lab's research on robust deep learning under distribution shift.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Information dropout: Learning optimal representations through noisy computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2897" to="2905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Metareg: Towards domain generalization using meta-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="998" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A theory of learning from different domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulesza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="151" to="175" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Impossibility theorems for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>P?l</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="343" to="351" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised pixel-level domain adaptation with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<idno type="DOI">10.1109/cvpr.2017.18</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recnorm: Simultaneous normalisation and classification applied to speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Bridle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="234" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Agnostic domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.01102</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Domain adaptation for visual applications: A comprehensive survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.05374</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep domain generalization with structured low-rank constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Image Processing</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="304" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Robust domain generalisation by enforcing distribution invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baktashmotlagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moshtaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leckie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kotagiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Fifth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1455" to="1461" />
		</imprint>
	</monogr>
	<note>/International Joint Conferences on Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fine-grained recognition in the wild: A multi-task domain adaptation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1109/iccv.2017.151</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Brendel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2551" to="2559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Covariate shift by kernel mean matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmittfull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Sample selection bias as a specification error (with an application to the estimation of labor supply functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Heckman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Simultaneous deep transfer across domains and tasks. Advances in Computer Vision and Pattern Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-58347-1_9</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="173" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">CyCADA: Cycle-consistent adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>J. Dy and A. Krause</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsm?ssan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02041</idno>
		<title level="m">Does distributionally robust supervised learning give robust classifiers? arXiv preprint</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Measuring the tendency of cnns to learn surface statistical regularities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.11561</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.03448</idno>
		<title level="m">Support and invertibility in domain-invariant representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Zero-shot domain adaptation without domain semantic descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumagai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Iwata</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.02927</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Coregularized alignment for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sattigeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wadhawan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Karlinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wornell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9345" to="9356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A simple unified framework for detecting out-of-distribution samples and adversarial attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1019" to="1030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5543" to="5551" />
		</imprint>
	</monogr>
	<note>Computer Vision (ICCV</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.03463</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Domain generalization with adversarial feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Kot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. Comput. Vis. Pattern Recognit.(CVPR)</title>
		<meeting>IEEE Conf. Comput. Vis. Pattern Recognit.(CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Domain generalization and adaptation using low rank exemplar svms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Extracting relationships by multi-domain matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Dawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carlson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6798" to="6809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Detecting and correcting for label shift with black box predictors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation with residual transfer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="136" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Conditional adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1640" to="1650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Best sources forward: domain generalization through source-specific nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mancini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ricci</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.05810</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The estimation of choice probabilities from choice based samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Manski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Lerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica: Journal of the Econometric Society</title>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0902.3430</idno>
		<title level="m">Domain adaptation: Learning bounds and algorithms</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
		<idno type="DOI">10.1109/iccv.2017.609</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Multi-view domain generalization for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4193" to="4201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Quick draw! the data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Quickdraw</surname></persName>
		</author>
		<ptr target="https://quickdraw.withgoogle.com/data" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Do imagenet classifiers generalize to imagenet?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shankar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The sketchy database: Learning to retrieve badly drawn bunnies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sangkloy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Burnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Multi-domain adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schoenauer-Sebag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Heinrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schoenauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sebag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Altschuler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">On causal and anticausal learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sgouritsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Coference on International Conference on Machine Learning (ICML-12)</title>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="459" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Improving predictive inference under covariate shift by weighting the log-likelihood function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shimodaira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of statistical planning and inference</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">When training and test sets are different: characterizing learning transfer. Dataset shift in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="DOI">10.1109/cvpr.2017.316</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5334" to="5344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Select-additive learning: Improving generalization in multimodal sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Meghawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.05244</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning robust representations by projecting superficial statistics out</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep visual domain adaptation: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2018.05.083</idno>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">312</biblScope>
			<biblScope unit="page" from="135" to="153" />
			<date type="published" when="2018-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A survey of transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Domain adaptation with asymmetrically-relaxed distribution alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Winston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Learning semantic representations for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>J. Dy and A. Krause</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsm?ssan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Domain adaptation under target and conditional shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Domain-invariant projection learning for zero-shot recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-R</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1019" to="1030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Adversarial multiple source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M F</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8559" to="8570" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
