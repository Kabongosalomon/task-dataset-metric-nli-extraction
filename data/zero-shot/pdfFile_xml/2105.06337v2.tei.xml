<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vadim</forename><surname>Popov</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Vovk</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Gogoryan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tasnima</forename><surname>Sadekova</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Kudinov</surname></persName>
						</author>
						<title level="a" type="main">Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, denoising diffusion probabilistic models and generative score matching have shown high potential in modelling complex data distributions while stochastic calculus has provided a unified point of view on these techniques allowing for flexible inference schemes. In this paper we introduce Grad-TTS, a novel text-to-speech model with score-based decoder producing melspectrograms by gradually transforming noise predicted by encoder and aligned with text input by means of Monotonic Alignment Search. The framework of stochastic differential equations helps us to generalize conventional diffusion probabilistic models to the case of reconstructing data from noise with different parameters and allows to make this reconstruction flexible by explicitly controlling trade-off between sound quality and inference speed. Subjective human evaluation shows that Grad-TTS is competitive with state-of-the-art text-to-speech approaches in terms of Mean Opinion Score. The code is publicly available at https://github.com/ huawei-noah/Speech-Backbones/ tree/main/Grad-TTS.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep generative modelling proved to be effective in various machine learning fields, and speech synthesis is no exception. Modern text-to-speech (TTS) systems often consist of two parts designed as deep neural networks: the first part converts the input text into time-frequency domain acoustic features (feature generator), and the second one synthesizes raw waveform conditioned on these features <ref type="bibr">(vocoder)</ref>. Introduction of the conventional state-of-the-art autoregressive models such as Tacotron2 <ref type="bibr" target="#b26">(Shen et al., 2018)</ref>  used as vocoder marked the beginning of the neural TTS era. Later, other popular generative modelling frameworks such as Generative Adversarial Networks <ref type="bibr" target="#b7">(Goodfellow et al., 2014)</ref> and Normalizing Flows <ref type="bibr" target="#b24">(Rezende &amp; Mohamed, 2015)</ref> were used in the design of TTS engines for a parallel generation with comparable quality of the synthesized speech.</p><p>Since the publication of the WaveNet paper (2016), there have been various attempts to propose a parallel nonautoregressive vocoder, which could synthesize high-quality speech. Popular architectures based on Normalizing Flows like Parallel WaveNet (van den <ref type="bibr" target="#b32">Oord et al., 2018)</ref> and Wave-Glow <ref type="bibr" target="#b21">(Prenger et al., 2019)</ref> managed to accelerate inference while keeping synthesis quality at a very high level but demonstrated fast synthesis on GPU devices only. Eventually, parallel GAN-based vocoders such as Parallel Wave-GAN <ref type="bibr" target="#b33">(Yamamoto et al., 2020)</ref>, MelGAN <ref type="bibr" target="#b16">(Kumar et al., 2019)</ref>, and HiFi-GAN  greatly improved the performance of waveform generation on CPU devices. Furthermore, the latter model is reported to produce speech samples of state-of-the-art quality outperforming WaveNet.</p><p>Among feature generators, Tacotron2 <ref type="bibr" target="#b26">(Shen et al., 2018)</ref> and Transformer-TTS <ref type="bibr">(Li et al., 2019)</ref> enabled highly natural speech synthesis. Producing acoustic features frame by frame, they achieve almost perfect mel-spectrogram reconstruction from input text. Nonetheless, they often suffer from computational inefficiency and pronunciation issues coming from attention failures. Addressing these problems, such models as FastSpeech <ref type="bibr" target="#b23">(Ren et al., 2019)</ref> and Parallel Tacotron  substantially improved inference speed and pronunciation robustness by utilizing nonautoregressive architectures and building hard monotonic alignments from estimated token lengths. However, in order to learn character duration, they still require pre-computed alignment from the teacher model. Finally, the recently proposed Non-Attentive Tacotron framework  managed to learn durations implicitly by employing the Variational Autoencoder concept.</p><p>Glow-TTS feature generator  based on Normalizing Flows can be considered as one of the most successful attempts to overcome pronunciation and computational latency issues typical for autoregressive solutions. Glow-TTS model made use of Monotonic Alignment Search algorithm (an adoption of Viterbi training <ref type="bibr" target="#b22">(Rabiner, 1989)</ref> finding the most likely hidden alignment between two sequences) proposed to map the input text to melspectrograms efficiently. The alignment learned by Glow-TTS is intentionally designed to avoid some of the pronunciation problems models like Tacotron2 suffer from. Also, in order to enable parallel synthesis, Glow-TTS borrows encoder architecture from Transformer-TTS <ref type="bibr">(Li et al., 2019)</ref> and decoder architecture from Glow <ref type="bibr" target="#b12">(Kingma &amp; Dhariwal, 2018)</ref>. Thus, compared with Tacotron2, Glow-TTS achieves much faster inference making fewer alignment mistakes. Besides, in contrast to other parallel TTS solutions such as FastSpeech, Glow-TTS does not require an external aligner to obtain token duration information as Monotonic Alignment Search (MAS) operates in an unsupervised way.</p><p>Lately, another family of generative models called Diffusion Probabilistic Models (DPMs) <ref type="bibr" target="#b28">(Sohl-Dickstein et al., 2015)</ref> has started to prove its capability to model complex data distributions such as images <ref type="bibr" target="#b9">(Ho et al., 2020)</ref>, shapes <ref type="bibr">(Cai et al., 2020)</ref>, graphs <ref type="bibr" target="#b20">(Niu et al., 2020)</ref>, handwriting <ref type="bibr" target="#b19">(Luhman &amp; Luhman, 2020)</ref>. The basic idea behind DPMs is as follows: we build a forward diffusion process by iteratively destroying original data until we get some simple distribution (usually standard normal), and then we try to build a reverse diffusion parameterized with a neural network so that it follows the trajectories of the reverse-time forward diffusion. Stochastic calculus offers a continuous easy-touse framework for training DPMs <ref type="bibr" target="#b31">(Song et al., 2021)</ref> and, which is perhaps more important, provides a number of flexible inference schemes based on numerical differential equation solvers.</p><p>As far as text-to-speech applications are concerned, two vocoders representing the DPM family showed impressive results in raw waveform reconstruction: WaveGrad <ref type="bibr" target="#b3">(Chen et al., 2021)</ref> and DiffWave <ref type="bibr" target="#b15">(Kong et al., 2021)</ref> were shown to reproduce the fine-grained structure of human speech and match strong autoregressive baselines such as WaveNet in terms of synthesis quality while at the same time requiring much fewer sequential operations. However, despite such a success in neural vocoding, no feature generator based on diffusion probabilistic modelling is known so far. This paper introduces Grad-TTS, an acoustic feature generator with a score-based decoder using recent diffusion probabilistic modelling insights. In Grad-TTS, MAS-aligned encoder outputs are passed to the decoder that transforms Gaussian noise parameterized by these outputs into a melspectrogram. To cope with the task of reconstructing data from Gaussian noise with varying parameters, we write down a generalized version of conventional forward and reverse diffusions. One of the remarkable features of our model is that it provides explicit control of the trade-off between output mel-spectrogram quality and inference speed. In particular, we find that Grad-TTS is capable of generating mel-spectrograms of high quality with only as few as ten iterations of reverse diffusion, which makes it possible to outperform Tacotron2 in terms of speed on GPU devices. Additionally, we show that it is possible to train Grad-TTS as an end-to-end TTS pipeline (i.e., vocoder and feature generator are combined in a single model) by replacing its output domain from mel-spectrogram to raw waveform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Diffusion probabilistic modelling</head><p>Loosely speaking, a process of the diffusion type is a stochastic process that satisfies a stochastic differential equation (SDE)</p><formula xml:id="formula_0">dX t = b(X t , t)dt + a(X t , t)dW t ,<label>(1)</label></formula><p>where W t is the standard Brownian motion, t ? [0, T ] for some finite time horizon T , and coefficients b and a (called drift and diffusion correspondingly) satisfy certain measurability conditions. A rigorous definition of the diffusion type processes, as well as other notions from stochastic calculus we use in this section, can be found in <ref type="bibr" target="#b18">(Liptser &amp; Shiryaev, 1978)</ref>.</p><p>It is easy to find such a stochastic process that terminal distribution Law(X T ) converges to standard normal N (0, I) when T ? ? for any initial data distribution Law(X 0 ) (I is n ? n identity matrix and n is data dimensionality). In fact, there are lots of such processes as it follows from the formulae given later in this section. Any process of the diffusion type with such property is called forward diffusion and the goal of diffusion probabilistic modelling is to find a reverse diffusion such that its trajectories closely follow those of the forward diffusion but in reverse time order. This is, of course, a much harder task than making Gaussian noise out of data, but in many cases it still can be accomplished if we parameterize reverse diffusion with a proper neural network. In this case, generation boils down to sampling random noise from N (0, I) and then just solving the SDE describing dynamics of the reverse diffusion with any numerical solver (usually a simple first-order Euler-Maruyama scheme <ref type="bibr" target="#b13">(Kloeden &amp; Platen, 1992)</ref> is used). If forward and reverse diffusion processes have close trajectories, then the distribution of resulting samples will be very close to that of the data Law(X 0 ). This approach to generative modelling is summarized in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>Until recently, score-based and denoising diffusion probabilistic models were formalized in terms of Markov chains <ref type="bibr" target="#b28">(Sohl-Dickstein et al., 2015;</ref><ref type="bibr" target="#b29">Song &amp; Ermon, 2019;</ref><ref type="bibr" target="#b9">Ho et al., 2020;</ref>. A unified approach introduced by <ref type="bibr" target="#b31">Song et al. (2021)</ref> has demonstrated that these Markov chains actually approximated trajectories of stochastic processes satisfying certain SDEs. In our work, we follow this paper and define our DPM in terms of SDEs rather than Markov chains. As one can see later in Section 3, the task we are solving suggests generalizing DPMs described in <ref type="bibr" target="#b31">(Song et al., 2021)</ref> in such a way that for infinite time horizon forward diffusion transforms any data distribution into N (?, ?) instead of N (0, I) for any given mean ? and diagonal covariance matrix ?. So, the rest of this section contains the detailed description of the generalized forward and reverse diffusions we utilize as well as the loss function we optimize to train the reverse diffusion. All corresponding derivations can be found in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Forward diffusion</head><p>First, we need to define a forward diffusion process that transforms any data into Gaussian noise given infinite time horizon T . If n-dimensional stochastic process X t satisfies the following SDE:</p><formula xml:id="formula_1">dX t = 1 2 ? ?1 (? ? X t )? t dt + ? t dW t , t ? [0, T ] (2)</formula><p>for non-negative function ? t , which we will refer to as noise schedule, vector ?, and diagonal matrix ? with positive elements, then its solution (if it exists) is given by</p><formula xml:id="formula_2">X t = I ? e ? 1 2 ? ?1 t 0 ?sds ? + e ? 1 2 ? ?1 t 0 ?sds X 0 + t 0 ? s e ? 1 2 ? ?1 t s ?udu dW s .<label>(3)</label></formula><p>Note that the exponential of a diagonal matrix is just an element-wise exponential. Let</p><formula xml:id="formula_3">?(X 0 , ?, ?, t) = I ? e ? 1 2 ? ?1 t 0 ?sds ? + e ? 1 2 ? ?1 t 0 ?sds X 0<label>(4)</label></formula><p>and</p><formula xml:id="formula_4">?(?, t) = ? I ? e ?? ?1 t 0 ?sds .<label>(5)</label></formula><p>By properties of It?'s integral conditional distribution of X t given X 0 is Gaussian:</p><formula xml:id="formula_5">Law(X t |X 0 ) = N (?(X 0 , ?, ?, t), ?(?, t)).<label>(6)</label></formula><p>It means that if we consider infinite time horizon then for any noise schedule ? t such that lim t?? e ? t 0 ?sds = 0 we have</p><formula xml:id="formula_6">X t |X 0 d ? ? N (?, ?).<label>(7)</label></formula><p>So, random variable X t converges in distribution to N (?, ?) independently of X 0 , and it is exactly the property we need: forward diffusion satisfying SDE (2) transforms any data distribution Law(X 0 ) into Gaussian noise N (?, ?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Reverse diffusion</head><p>While in earlier works on DPMs reverse diffusion was trained to approximate the trajectories of forward diffusion, <ref type="bibr" target="#b31">Song et al. (2021)</ref> proposed to use the result by <ref type="bibr" target="#b0">Anderson (1982)</ref>, who derived an explicit formula for reverse-time dynamics of a wide class of stochastic processes of the diffusion type. In our case, this result leads to the following SDE for the reverse diffusion:</p><formula xml:id="formula_7">dX t = 1 2 ? ?1 (? ? X t ) ? ? log p t (X t ) ? t dt + ? t d W t , t ? [0, T ],<label>(8)</label></formula><p>where W t is the reverse-time Brownian motion and p t is the probability density function of random variable X t . This SDE is to be solved backwards starting from terminal condition X T .</p><p>Moreover, <ref type="bibr" target="#b31">Song et al. (2021)</ref> have shown that instead of SDE (8), we can consider an ordinary differential equation</p><formula xml:id="formula_8">dX t = 1 2 ? ?1 (? ? X t ) ? ? log p t (X t ) ? t dt.<label>(9)</label></formula><p>Forward Kolmogorov equations corresponding to <ref type="formula">(2)</ref> and <ref type="formula" target="#formula_8">(9)</ref> are identical, which means that the evolution of probability density functions of stochastic processes given by <ref type="formula">(2)</ref> and <ref type="formula" target="#formula_8">(9)</ref> is the same.</p><p>Thus, if we have a neural network s ? (X t , t) that estimates the gradient of the log-density of noisy data ? log p t (X t ), then we can model data distribution Law(X 0 ) by sampling X T from N (?, ?) and numerically solving either (8) or (9) backwards in time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Loss function</head><p>Estimating gradients of log-density of noisy data X t is often referred to as score matching, and in recent papers <ref type="bibr" target="#b29">(Song &amp; Ermon, 2019</ref>; 2020) L 2 loss was used to approximate these gradients with a neural network. So, in our paper, we use the same type of loss.</p><p>Due to the formula (6), we can sample noisy data X t given only initial data X 0 without sampling intermediate val-</p><formula xml:id="formula_9">ues {X s } s&lt;t . Moreover, Law(X t |X 0 )</formula><p>is Gaussian, which means that its log-density has a very simple closed form. If we sample t from N (0, ?(?, t)) and then put</p><formula xml:id="formula_10">X t = ?(X 0 , ?, ?, t) + t<label>(10)</label></formula><p>in accordance with <ref type="formula" target="#formula_5">(6)</ref>, then the gradient of log-density of noisy data in this point X t is given by</p><formula xml:id="formula_11">? log p 0t (X t |X 0 ) = ??(?, t) ?1 t ,<label>(11)</label></formula><p>where p 0t (?|X 0 ) is the probability density function of the conditional distribution (6). Thus, loss function corresponding to estimating the gradient of log-density of data X 0 corrupted with noise accumulated by time t is</p><formula xml:id="formula_12">L t (X 0 ) = E t s ? (X t , t) + ?(?, t) ?1 t 2 2 ,<label>(12)</label></formula><p>where t is sampled from N (0, ?(?, t)) and X t is calculated by formula (10).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Grad-TTS</head><p>The acoustic feature generator we propose consists of three modules: encoder, duration predictor, and decoder. In this section, we will describe their architectures as well as training and inference procedures. The general approach is illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>. Grad-TTS has very much in common with Glow-TTS , a feature generator based on Normalizing Flows. The key difference lies in the principles the decoder relies on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Inference</head><p>An input text sequence x 1:L of length L typically consists of characters or phonemes, and we aim at generating melspectrogram y 1:F where F is the number of acoustic frames. In Grad-TTS, the encoder converts an input text sequence x 1:L into a sequence of features? 1:L used by the duration predictor to produce hard monotonic alignment A between encoded text sequence? 1:L and frame-wise features ? 1:F . The function A is a monotonic surjective mapping between [1, F ] ? N and [1, L] ? N, and we put ? j =? A(j) for any integer j ? [1, F ]. Informally speaking, the duration predictor tells us how many frames each element of text input lasts. Monotonicity and surjectiveness of A guarantee that the text is pronounced in the correct order without skipping any text input. As in all TTS models with duration predictor, it is possible to control synthesized speech tempo by multiplying predicted durations by some factor.</p><p>The output sequence ? = ? 1:F is then passed to the decoder, which is a Diffusion Probabilistic Model. A neural network s ? (X t , ?, t) with parameters ? defines an ordinary differential equation (ODE)</p><formula xml:id="formula_13">dX t = 1 2 (? ? X t ? s ? (X t , ?, t))? t dt,<label>(13)</label></formula><p>which is solved backwards in time using the first-order Euler scheme. The sequence ? is also used to define the terminal condition X T ? N (?, I). Noise schedule ? t and time horizon T are some pre-defined hyperparameters whose choice mostly depends on the data, while step size h in the Euler scheme is a hyperparameter that can be chosen after Grad-TTS is trained. It expresses the trade-off between the quality of output mel-spectrograms and inference speed.</p><p>Reverse diffusion in Grad-TTS evolves according to equation (13) for the following reasons:</p><p>? We obtained better results in practice when using dynamics (9) instead of (8): for small values of step size h, they performed equally well, while for larger values the former led to much better sounding results.</p><p>? We chose ? = I to simplify the whole feature generation pipeline.</p><p>? We used ? as an additional input to the neural network s ? (X t , ?, t). It follows from (11) that the neural network s ? essentially tries to predict Gaussian noise added to data X 0 observing only noisy data X t . So, if for every time t we supply s ? with an additional knowledge of how the limiting noise lim T ?? Law(X T |X 0 ) looks like (note that it is different for different text input), then this network can make more accurate predictions of noise at time t ? [0, T ].</p><p>We also found it beneficial for the model performance to introduce a temperature hyperparameter ? and to sample terminal condition X T from N (?, ? ?1 I) instead of N (?, I). Tuning ? can help to keep the quality of output mel-spectrograms at the same level when using larger values of step size h. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Training</head><p>One of Grad-TTS training objectives is to minimize the distance between aligned encoder output ? and target melspectrogram y because the inference scheme that has just been described suggests to start decoding from random noise N (?, I). Intuitively, it is clear that decoding is easier if we start from noise, which is already close to the target y in some sense.</p><p>If aligned encoder output ? is considered to parameterize an input noise the decoder starts from, it is natural to regard encoder output? as a normal distribution N (?, I), which leads to a negative log-likelihood encoder loss:</p><formula xml:id="formula_14">L enc = ? F j=1 log ?(y j ;? A(j) , I),<label>(14)</label></formula><p>where ?(?;? i , I) is a probability density function of N (? i , I). Although other types of losses are also possible, we have chosen L enc (which actually reduces to Mean Square Error criterion) because of this probabilistic interpretation. In principle, it is even possible to train Grad-TTS without any encoder loss at all and let the diffusion loss described further do all the job of generating realistic mel-spectrograms, but in practice we observed that in the absence of L enc Grad-TTS failed to learn alignment.</p><p>The encoder loss L enc has to be optimized with respect to both encoder parameters and alignment function A. Since it is hard to do a joint optimization, we apply an iterative approach proposed by <ref type="bibr" target="#b11">Kim et al. (2020)</ref>. Each iteration of optimization consists of two steps: (i) searching for an optimal alignment A * given fixed encoder parameters; (ii) fixing this alignment A * and taking one step of stochastic gradient descent to optimize loss function with respect to encoder parameters. We use Monotonic Alignment Search at the first step of this approach. MAS utilizes the concept of dynamic programming to find an optimal (from the point of view of loss function L enc ) monotonic surjective alignment. This algorithm is described in detail in .</p><p>To estimate the optimal alignment A * at inference, Grad-TTS employs the duration predictor network. As in , we train the duration predictor DP with Mean Square Error (MSE) criterion in logarithmic domain:</p><formula xml:id="formula_15">d i = log F j=1 I {A * (j)=i} , i = 1, .., L, L dp = M SE(DP (sg[?]), d),<label>(15)</label></formula><p>where I is an indicator function,? =? 1:L , d = d 1:L and stop gradient operator sg[?] is applied to the inputs of the duration predictor to prevent L dp from affecting encoder parameters.</p><p>As for the loss related to the DPM, it is calculated using formulae from Section 2. As already mentioned, we put ? = I, so the distribution of noisy data (6) simplifies, and its covariance matrix becomes just an identity matrix I multiplied by a scalar</p><formula xml:id="formula_16">? t = 1 ? e ? t 0 ?sds .<label>(16)</label></formula><p>The overall diffusion loss function L dif f is the expectation of weighted losses associated with estimating gradients of log-density of noisy data at different times t ? [0, T ]:</p><formula xml:id="formula_17">L dif f = E X0,t ? t E ?t s ? (X t , ?, t) + ? t ? ? t 2 2 ,<label>(17)</label></formula><p>where X 0 stands for target mel-spectrogram y sampled from training data, t is sampled from uniform distribution on [0, T ], ? t -from N (0, I) and the formula</p><formula xml:id="formula_18">X t = ?(X 0 , I, ?, t) + ? t ? t<label>(18)</label></formula><p>is used to get noisy data X t according to the distribution (6). The above formulae <ref type="formula" target="#formula_0">(17)</ref> and <ref type="formula" target="#formula_0">(18)</ref> follow from <ref type="formula" target="#formula_0">(12)</ref> and <ref type="formula" target="#formula_0">(10)</ref> by substitution t = ? ? t ? t . We use losses (12) with weights ? t according to the common heuristics that these weights should be proportional to 1/E ? log p 0t (X t |X 0 ) 2 2 .</p><p>To sum it up, the training procedure consists of the following steps:</p><p>? Fix the encoder, duration predictor, and decoder parameters and run MAS algorithm to find the alignment A * that minimizes L enc .</p><p>? Fix the alignment A * and minimize L enc +L dp +L dif f with respect to encoder, duration predictor, and decoder parameters.</p><p>? Repeat the first two steps till convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Model architecture</head><p>As for the encoder and duration predictor, we use exactly the same architectures as in Glow-TTS, which in its turn borrows the structure of these modules from Transformer-TTS <ref type="bibr">(Li et al., 2019)</ref> and FastSpeech <ref type="bibr" target="#b23">(Ren et al., 2019)</ref> correspondingly. The duration predictor consists of two convolutional layers followed by a projection layer that predicts the logarithm of duration. The encoder is composed of a pre-net, 6 Transformer blocks with multi-head selfattention, and the final linear projection layer. The pre-net consists of 3 layers of convolutions followed by a fullyconnected layer.</p><p>The decoder network s ? has the same U-Net architecture <ref type="bibr" target="#b25">(Ronneberger et al., 2015)</ref> used by <ref type="bibr" target="#b9">Ho et al. (2020)</ref> to generate 32 ? 32 images, except that we use twice fewer channels and three feature map resolutions instead of four to reduce model size. In our experiments we use 80-dimensional mel-spectrograms, so s ? operates on resolutions 80 ? F , 40 ? F/2 and 20 ? F/4. We zero-pad mel-spectrograms if the number of frames F is not a multiple of 4. Aligned encoder output ? is concatenated with U-Net input X t as an additional channel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>LJSpeech dataset <ref type="bibr" target="#b10">(Ito, 2017)</ref> containing approximately 24 hours of English female voice recordings sampled at 22.05kHz was used to train the Grad-TTS model. The test set contained around 500 short audio recordings (duration less than 10 seconds each). The input text was phonemized before passing to the encoder; as for the output acoustic features, we used conventional 80-dimensional mel-spectrograms. We tried training both on original and normalized mel-spectrograms and found that the former performed better. Grad-TTS was trained for 1.7m iterations on a single GPU (NVIDIA RTX 2080 Ti with 11GB memory) with mini-batch size 16. We chose Adam optimizer and set the learning rate to 0.0001. We would like to mention several important things about Grad-TTS training:</p><p>? We chose T = 1, ? t = ? 0 + (? 1 ? ? 0 )t, ? 0 = 0.05 and ? 1 = 20.</p><p>? As in <ref type="bibr" target="#b1">(Bi?kowski et al., 2020;</ref><ref type="bibr" target="#b5">Donahue et al., 2021)</ref>, we use random mel-spectrogram segments of fixed length (2 seconds in our case) as training targets y to allow for memory-efficient training. However, MAS and the duration predictor still use whole melspectrograms.</p><p>? Although diffusion loss L dif f seems to converge very slowly after the beginning epochs, as shown on <ref type="figure" target="#fig_2">Figure 3</ref>, such long training is essential to get a good model because the neural network s ? has to learn to estimate gradients accurately for all t ? [0, 1]. Two models with almost equal diffusion losses can produce mel-spectrograms of very different quality: inaccurate predictions for a small subset S ? [0, 1] may have a small impact on L dif f but be crucial for the output melspectrogram quality if ODE solver involves calculating s ? in at least one point belonging to S.</p><p>Once trained, Grad-TTS enables the trade-off between quality and inference speed due to the ability to vary the number of steps N the decoder takes to solve ODE (13) at inference. So, we evaluate four models which we denote by <ref type="bibr">Grad-TTS-N where N ? [4, 10, 100, 1000]</ref>. We use ? = 1.5 at synthesis for all four models. As baselines, we take an official implementation of Glow-TTS , the model which resembles ours to the most extent among the existing feature generators, FastSpeech <ref type="bibr" target="#b23">(Ren et al., 2019)</ref>, and state-of-the-art Tacotron2 <ref type="bibr" target="#b26">(Shen et al., 2018)</ref>. Recently proposed HiFi-GAN  is known to provide excellent sound quality, so we use this vocoder with all models we compare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Subjective evaluation</head><p>To make subjective evaluation of TTS models, we used the crowdsourcing platform Amazon Mechanical Turk. For Mean Opinion Score (MOS) estimation we synthesized 40 sentences from the test set with each model. The assessors were asked to estimate the quality of synthesized speech on a nine-point Likert scale, the lowest and the highest scores being 1 point ("Bad") and 5 points ("Excellent") with a step of 0.5 point. To ensure the reliability of the obtained results, only Master assessors were assigned to complete the listening test. Each audio was evaluated by 10 assessors. A small subset of speech samples used in the test is available at https://grad-tts.github.io/. MOS results with 95% confidence intervals are presented in <ref type="table" target="#tab_2">Table 2</ref>. It demonstrates that although the quality of the synthesized speech gets better when we use more iterations of the reverse diffusion, the quality gain becomes marginal starting from a certain number of iterations. In particular, there is almost no difference between Grad-TTS-1000 and Grad-TTS-10 in terms of MOS, while the gap between Grad-TTS-10 and Grad-TTS-4 (4 was the smallest number of iterations leading to satisfactory quality) is much more significant. As for other feature generators, Grad-TTS-10 is competitive with all compared models, including state-of-the-art Tacotron2. Furthermore, Grad-TTS-1000 achieves almost natural synthesis with MOS being less than that for ground truth recordings by only 0.1. We would like to note that the relatively low results of FastSpeech could possibly be explained by the fact that we used its unofficial implementation https://github.com/xcmyz/FastSpeech.</p><p>To verify the benefits of the proposed generalized DPM framework we trained the model with the same architecture as Grad-TTS to reconstruct mel-spectrograms from N (0, I) instead <ref type="figure">of N (?, I)</ref>. The preference test provided in <ref type="table" target="#tab_1">Table 1</ref> shows that Grad-TTS-10 is significantly better (p &lt; 0.005 in sign test) than this model taking 10, 20 and even 50 iterations of the reverse diffusion. It demonstrates that the model trained to generate from N (0, I) needs more steps of ODE solver to get high-quality mel-spectrograms than Grad-TTS we propose. We believe this is because the task of reconstructing mel-spectrogram from pure noise N (0, I) is more difficult than the one of reconstructing it from its noisy copy N (?, I). One possible objection could be that the model trained with N (0, I) as terminal distribution can just add ? to this noise at the first step of sampling (it is possible because s ? has ? as its input) and then repeat the same steps as our model to generate data from N (?, I). In this case, it would generate mel-spectrograms of the same quality as our model taking only one step more. However, this argument is wrong, since reverse diffusion removes noise not arbitrarily, but according to the reverse trajectories of the forward diffusion. Since forward diffusion adds noise gradually, reverse diffusion has to remove noise gradually as well, and the first step of the reverse diffusion cannot be adding ? to Gaussian noise with zero mean because the last step of the forward diffusion is not a jump from ? to zero. We also made an attempt to estimate what kinds of mistakes are characteristic of certain models. We compared Tacotron2, Glow-TTS, and Grad-TTS-10 as the fastest version of our model with high synthesis quality. Each record was estimated by 5 assessors. <ref type="figure" target="#fig_3">Figure 4</ref> demonstrates the results of the multiple-choice test whose participants had to choose which kinds of errors (if any) they could hear: sonic artifacts like clicking sounds or back- ground noise ("sonic" in the figure), mispronunciation of words/phonemes ("mispron"), unnatural pauses ("pause"), monotone speech ("monotonic"), robotic voice ("robotic"), wrong word stressing ("stress") or others. It is clear from the figure that Glow-TTS frequently stresses words in a wrong way, and the sound it produces is perceived as "robotic" in around a quarter of cases. These are the major factors that make Glow-TTS performance inferior to that of Grad-TTS and Tacotron2, which in their turn have more or less the same drawbacks in terms of synthesis quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Objective evaluation</head><p>Although DPMs can be shown to maximize weighted variational lower bound <ref type="bibr" target="#b9">(Ho et al., 2020)</ref> on data log-likelihood, they do not explicitly optimize exact data likelihood. In spite of this, <ref type="bibr" target="#b31">Song et al. (2021)</ref> show that it is still possible to calculate it using the instantaneous change of variables formula <ref type="bibr" target="#b4">(Chen et al., 2018)</ref> if we look at DPMs from the "continuous" point of view. However, it is necessary to use Hutchinson's trace estimator to make computations feasible, so in <ref type="table" target="#tab_2">Table 2</ref> log-likelihood for Grad-TTS comes with a 95% confidence interval.</p><p>We randomly chose 50 sentences from the test set and calculated their average log-likelihood under two probabilistic models we consider -Glow-TTS and Grad-TTS. Interestingly, Grad-TTS achieves better log-likelihood than Glow-TTS even though the latter has a decoder with 3x larger capacity and was trained to maximize exact data likelihood. Similar phenomena were observed by <ref type="bibr" target="#b31">Song et al. (2021)</ref> in the image generation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Efficiency estimation</head><p>We assess the efficiency of the proposed model in terms of Real-Time Factor (RTF is how many seconds it takes to generate one second of audio) computed on GPU and the number of parameters. <ref type="table" target="#tab_2">Table 2</ref> contains efficiency information for all models under comparison. Additional information regarding absolute inference speed dependency on the input text length is given in <ref type="figure">Figure 5</ref>.</p><p>Due to its flexibility at inference, Grad-TTS is capable of real-time synthesis on GPU: if the number of decoder steps is less than 100, it reaches RTF &lt; 0.37. Moreover, although it cannot compete with Glow-TTS and FastSpeech in terms of inference speed, it still can be approximately twice faster than Tacotron2 if we use 10 decoder iterations sufficient for getting high-fidelity mel-spectrograms. Besides, Grad-TTS has around 15m parameters, thus being significantly smaller than other feature generators we compare. <ref type="figure">Figure 5</ref>. Inference speed comparison. Text length is given in characters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">End-to-end TTS</head><p>The results of our preliminary experiments show that it is also possible to train an end-to-end TTS model as a DPM. In brief, we moved from U-Net to WaveGrad <ref type="bibr" target="#b3">(Chen et al., 2021)</ref> in Grad-TTS decoder: the overall architecture resembles WaveGrad conditioned on the aligned encoder output ? instead of ground truth mel-spectrograms y as in original WaveGrad. Although synthesized speech quality is fair enough, it cannot compete with the results reported above, so we do not include our end-to-end model in the listening test but provide demo samples at https://grad-tts.github.io/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Future work</head><p>End-to-end speech synthesis results reported above show that it is a promising future research direction for text-tospeech applications. However, there is also much room for investigating general issues regarding DPMs.</p><p>In the analysis in Section 2, we always assume that both forward and reverse diffusion processes exist, i.e., SDEs <ref type="formula">(2)</ref> and <ref type="formula" target="#formula_7">(8)</ref> have strong solutions. It applies some Lipschitz-type constraints <ref type="bibr" target="#b18">(Liptser &amp; Shiryaev, 1978)</ref> on noise schedule ? t and, what is more important, on the neural network s ? . Wasserstein GANs offer an encouraging example of incorporating Lipschitz constraints into neural networks training <ref type="bibr" target="#b8">(Gulrajani et al., 2017)</ref>, suggesting that similar techniques may improve DPMs.</p><p>Little attention has been paid so far to the choice of the noise schedule ? t -most researchers use a simple linear schedule. Also, it is mostly unclear how to choose weights for losses (12) at time t in the global loss function optimally. A thorough investigation of such practical questions is crucial as it can facilitate applying DPMs to new machine learning problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We have presented Grad-TTS, the first acoustic feature generator utilizing the concept of diffusion probabilistic modelling. The main generative engine of Grad-TTS is the diffusion-based decoder that transforms Gaussian noise parameterized with the encoder output into mel-spectrogram while alignment is performed with Monotonic Alignment Search. The model we propose allows to vary the number of decoder steps at inference, thus providing a tool to control the trade-off between inference speed and synthesized speech quality. Despite its iterative decoding, Grad-TTS is capable of real-time synthesis. Moreover, it can generate mel-spectrograms twice faster than Tacotron2 while keeping synthesis quality competitive with common TTS baselines.</p><p>We include an appendix with detailed derivations, proofs and additional information. Our proposed diffusion probabilistic framework employs generalized terminal distribution N (?, ?) instead of N (0, I) as proposed by <ref type="bibr" target="#b31">Song et al. (2021)</ref>. The derivation for the solution (3) of SDE (2) that transforms the original data distribution to the terminal distribution is described in Appendix A. In Appendix B we also derive the distribution which the solution (3) for the diffused data X t follows. Then, the goal of diffusion probabilistic modelling is to reconstruct the reverse-time trajectories of the forward diffusion process, and <ref type="bibr" target="#b31">Song et al. (2021)</ref> showed that these dynamics can follow two different differential equations: either SDE (8) proposed by <ref type="bibr" target="#b0">Anderson (1982)</ref> or ODE (9). So, Appendix C contains these differential equations for N (?, ?) serving as terminal distribution. They depend on time-dependent gradient field ? log p 0t (X t |X 0 ) supposed to be modelled using neural network. In order to train it, we show how to compute the gradient in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Solving forward diffusion SDE</head><p>Forward diffusion SDE is given by</p><formula xml:id="formula_19">dX t = 1 2 ? ?1 (? ? X t )? t dt + ? t dW t , t ? [0, T ],<label>(19)</label></formula><p>where X t is n-dimensional stochastic process, W t is the standard n-dimensional Brownian motion, ? = (? 1 ...? n ) T is n-dimensional vector, ? is n ? n diagonal matrix with positive diagonal elements {? 2 ii } n 1 and noise schedule ? t is non-negative function [0, T ] ? R + . Consider change of variables Y t = X t ? ?. Then we can rewrite forward diffusion SDE as</p><formula xml:id="formula_20">dY t = ? 1 2 ? ?1 Y t ? t dt + ? t dW t .<label>(20)</label></formula><p>For every i = 1, .., n we have</p><formula xml:id="formula_21">d e 1 2? 2 ii t 0 ?sds Y i t = e 1 2? 2 ii t 0 ?sds ? 1 2? 2 ii ? t Y i t dt + e 1 2? 2 ii t 0 ?sds ? ? 1 2? 2 ii Y i t ? t dt + ? t dW i t = = e 1 2? 2 ii t 0 ?sds ? t dW i t .<label>(21)</label></formula><p>Exponential of a diagonal matrix is just element-wise exponential, so we can rewrite it in multidimensional form as</p><formula xml:id="formula_22">d e 1 2 ? ?1 t 0 ?sds Y t = ? t e 1 2 ? ?1 t 0 ?sds dW t =? e 1 2 ? ?1 t 0 ?sds Y t ? Y 0 = t 0 ? s e 1 2 ? ?1 s 0 ?udu dW s ,<label>(22)</label></formula><p>or writing this down in terms of X t :</p><formula xml:id="formula_23">X t = e ? 1 2 ? ?1 t 0 ?sds X 0 + I ? e ? 1 2 ? ?1 t 0 ?sds ? + t 0 ? s e ? 1 2 ? ?1 t s ?udu dW s ,<label>(23)</label></formula><p>where I is n ? n identity matrix. . Assume a ii (s) ? L 2 [0, T ] for each i. It?'s integral t 0 a ii (s)dW i s is defined as the limit of integral sums when mesh of partition ? tends to zero:</p><formula xml:id="formula_24">t 0 a ii (s)dW i s = lim ??0 k a ii (s k )?W i s k d = lim ??0 N 0, k a 2 ii (s k )?s k d = d = N 0, lim ??0 k a 2 ii (s k )?s k = N 0, t 0 a 2 ii (s)ds ,<label>(24)</label></formula><p>where the first equality in distribution holds due to the properties of Brownian motion and the fact that a ii (s k ) are deterministic (implying that a ii (s k )?W i s k = a ii (s k )(W i s k+1 ? W i s k ) are independent normal random variables with mean 0 and variance a 2 ii (s k )(s k+1 ? s k ) = a 2 ii (s k )?s k ) and the second equality in distribution follows from L?vy's continuity theorem (it is easy to check that the sequence of characteristic functions of random variables on the left-hand side converges point-wise to the characteristic function of the random variable on the right-hand side). Then, simple integration gives </p><p>It implies that in multidimensional case we have: </p><p>and it follows from (23) that</p><p>Law(X t |X 0 ) = N (?(X 0 , ?, ?, t), ?(?, t)), ?(X 0 , ?, ?, t) = e ? 1 2 ? ?1 t 0 ?sds X 0 + I ? e ? 1 2 ? ?1 t 0 ?sds ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Reverse dynamics</head><p>The result by <ref type="bibr" target="#b0">Anderson (1982)</ref> implies that if n-dimensional process of the diffusion type X t satisfies dX t = f (X t , t)dt + g(t)dW t , t ? [0, T ],</p><p>where g(t) is a function [0, T ] ? R, then its reverse-time dynamics is given by dX t = (f (X t , t) ? g 2 (t)? log p t (X t ))dt + g(t)d W t , t ? [0, T ],</p><p>where p t (?) is the probability density function of random variable X t and W t is the reverse-time standard Brownian motion such that X t is independent of its past increments W s ? W t for s &lt; t. Reverse-time dynamics means that all the integrals associated with reverse-time differentials have t as their lower limit (e.g. dX t relates to T t dX s = X T ? X t ). Anderson's result is obtained under the assumption that Kolmogorov equations (for probability density functions) associated with all considered processes have unique smooth solutions. On the other hand, <ref type="bibr" target="#b31">Song et al. (2021)</ref> argued that SDE (28) has the same forward Kolmogorov equation as the following ODE:</p><formula xml:id="formula_30">dX t = (f (X t , t) ? 1 2 g 2 (t)? log p t (X t ))dt, t ? [0, T ],<label>(30)</label></formula><p>which means that processes following (28) and (30) are equal in distribution if they start from the same initial distribution Law(X 0 ). In our case f (X t , t) = 1 2 ? ?1 (X t ? ?)? t and g(t) = ? ? t , so we have two equivalent reverse diffusion dynamics:</p><formula xml:id="formula_31">dX t = 1 2 ? ?1 (X t ? ?) ? ? log p t (X t ) ? t dt + ? t d W t<label>(31)</label></formula><p>and</p><formula xml:id="formula_32">dX t = 1 2 ? ?1 (X t ? ?) ? ? log p t (X t ) ? t dt,<label>(32)</label></formula><p>where both differential equations are to be solved backwards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Score estimation</head><p>If X 0 is known, then (27) implies that log p 0t (X t |X 0 ) = ? n 2 log (2?) ? 1 2 det ?(?, t) ? 1 2 (X t ? ?(X 0 , ?, ?, t)) T ?(?, t) ?1 (X t ? ?(X 0 , ?, ?, t)) =? ? log p 0t (X t |X 0 ) = ??(?, t) ?1 (X t ? ?(X 0 , ?, ?, t)),</p><p>where p 0t (?|X 0 ) is the probability density function of conditional distribution Law(X t |X 0 ). So, if we sample X t by the formula X t = ?(X 0 , ?, ?, t) + t where t ? N (0, ?(?, t)), then ? log p 0t (X t |X 0 ) = ??(?, t) ?1 t . In the simplified case when ? = I we have ?(I, t) = ? t I where ? t = 1 ? e ? t 0 ?sds . In this case gradient of noisy data log-density reduces to ? log p 0t (X t |X 0 ) = ? t /? t . If t = ? ? t ? t , then we have X t = ?(X 0 , I, ?, t) + ? t ? t , ? t ? N (0, I), ? log p 0t (X t |X 0 ) = ?? t / ? t .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Diffusion probabilistic modelling for mel-spectrograms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Grad-TTS inference scheme.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Diffusion loss at training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Typical errors occurrence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>B</head><label></label><figDesc>. Derivation of conditional distribution of X t Let A(s) = ? ? s e ? 1 2 ? ?1 t s ?udu . It is a diagonal matrix and its i-th diagonal element a ii (s) equals ?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>)dW s ? N (0, ?(?, t)) , ?(?, t) = ? I ? e ?? ?1 t 0 ?sds ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>used for feature generation and WaveNet (van den Oord et al., 2016) Equal contribution 1 Huawei Noah's Ark Lab, Moscow, Russia 2 Higher School of Economics, Moscow, Russia. Correspondence to: Vadim Popov &lt;vadim.popov@huawei.com&gt;, Ivan Vovk &lt;vovk.ivan@huawei.com&gt;. Proceedings of the 38 th International Conference on Machine Learning, PMLR 139, 2021. Copyright 2021 by the author(s).</figDesc><table /><note>*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Ablation study of proposed generalized diffusion framework. Grad-TTS reconstructing data from N (0, I) for N reverse diffusion iterations is compared with the baseline Grad-TTS-10the model reconstructing data from N (?, I) for 10 iterations.</figDesc><table><row><cell cols="4">N Worse, % Identical, % Better, %</cell></row><row><cell>10</cell><cell>93.8</cell><cell>0.5</cell><cell>5.7</cell></row><row><cell>20</cell><cell>82.3</cell><cell>2.9</cell><cell>14.8</cell></row><row><cell>50</cell><cell>60.3</cell><cell>5.7</cell><cell>34.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Model comparison.</figDesc><table><row><cell>Model</cell><cell cols="2">Enc params 1 Dec params</cell><cell>RTF</cell><cell>Log-likelihood</cell><cell>MOS</cell></row><row><cell>Grad-TTS-1000</cell><cell></cell><cell></cell><cell>3.663</cell><cell></cell><cell>4.44 ? 0.05</cell></row><row><cell>Grad-TTS-100 Grad-TTS-10</cell><cell>7.2m</cell><cell>7.6m</cell><cell>0.363 0.033</cell><cell>0.174 ? 0.001</cell><cell>4.38 ? 0.06 4.38 ? 0.06</cell></row><row><cell>Grad-TTS-4</cell><cell></cell><cell></cell><cell>0.012</cell><cell></cell><cell>3.96 ? 0.07</cell></row><row><cell>Glow-TTS</cell><cell>7.2m</cell><cell>21.4m</cell><cell>0.008</cell><cell>0.082</cell><cell>4.11 ? 0.07</cell></row><row><cell>FastSpeech</cell><cell>24.5m</cell><cell></cell><cell>0.004</cell><cell>?</cell><cell>3.68 ? 0.09</cell></row><row><cell>Tacotron2</cell><cell>28.2m</cell><cell></cell><cell>0.075</cell><cell>?</cell><cell>4.32 ? 0.07</cell></row><row><cell>Ground Truth</cell><cell>?</cell><cell></cell><cell>?</cell><cell>?</cell><cell>4.53 ? 0.06</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Encoder and duration predictor parameters are calculated together.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Reverse-time diffusion equation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Anderson</surname></persName>
		</author>
		<idno>0304-4149</idno>
	</analytic>
	<monogr>
		<title level="m">Stochastic Processes and their Applications</title>
		<imprint>
			<date type="published" when="1982" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="313" to="326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">High Fidelity Speech Synthesis with Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bi?kowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning Gradient Fields for Shape Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Averbuch-Elor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Estimating Gradients for Waveform Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wavegrad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural Ordinary Differential Equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="6571" to="6583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">End-to-end Adversarial Text-to-Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Binkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Elias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<title level="m">Parallel Tacotron: Non-Autoregressive and Controllable TTS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generative Adversarial Nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improved Training of Wasserstein GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5767" to="5777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Denoising Diffusion Probabilistic Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>The Lj Speech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dataset</surname></persName>
		</author>
		<ptr target="https://keithito.com/LJ-Speech-Dataset/" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Generative Flow for Text-to-Speech via Monotonic Alignment Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Glow-Tts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generative flow with invertible 1x1 convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Glow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10236" to="10245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Numerical Solution of Stochastic Differential Equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Kloeden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Platen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Springer-Verlag</publisher>
			<biblScope unit="volume">23</biblScope>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
	<note>of Stochastic Modelling and Applied Probability</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hifi-Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">DiffWave: A Versatile Diffusion Model for Audio Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative Adversarial Networks for Conditional Waveform Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Boissiere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gestin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="14910" to="14921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural Speech Synthesis with Transformer Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Statistics of Random Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liptser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shiryaev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stochastic Modelling and Applied Probability</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="1978" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Diffusion models for Handwriting Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Luhman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Luhman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Permutation Invariant Graph Generation via Score-Based Generative Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Waveglow: A Flow-based Generative Network for Speech Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Prenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Valle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Catanzaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-05" />
			<biblScope unit="page" from="3617" to="3621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Tutorial on Hidden Markov Models and Selected Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">FastSpeech: Fast, Robust and Controllable Text to Speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ruan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="3171" to="3180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06-11" />
			<biblScope unit="page" from="1530" to="1538" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">U-Net: Convolutional Networks for Biomedical Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Medical Image Computing and Computer-Assisted Intervention -MICCAI 2015</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2018-04" />
			<biblScope unit="page" from="4779" to="4783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chrzanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Elias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno>abs/2010.04301</idno>
	</analytic>
	<monogr>
		<title level="m">Non-Attentive Tacotron: Robust and Controllable Neural TTS Synthesis Including Unsupervised Duration Modeling</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep Unsupervised Learning using Nonequilibrium Thermodynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Maheswaranathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning, Proceedings of Machine Learning Research</title>
		<meeting>the 32nd International Conference on Machine Learning, Machine Learning Research</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2256" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Generative Modeling by Estimating Gradients of the Data Distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="11918" to="11930" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improved Techniques for Training Score-Based Generative Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Score-Based Generative Modeling through Stochastic Differential Equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wavenet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="125" to="125" />
		</imprint>
	</monogr>
	<note>9th ISCA Speech Synthesis Workshop</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Parallel WaveNet: Fast High-Fidelity Speech Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Parallel Wavegan: A Fast Waveform Generation Model Based on Generative Adversarial Networks with Multi-Resolution Spectrogram</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6199" to="6203" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
