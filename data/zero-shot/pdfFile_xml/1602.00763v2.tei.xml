<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SIMPLE ONLINE AND REALTIME TRACKING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2017-07-07">7 Jul 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Bewley</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Queensland University of Technology ?</orgName>
								<orgName type="institution" key="instit2">University of Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongyuan</forename><surname>Ge</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Queensland University of Technology ?</orgName>
								<orgName type="institution" key="instit2">University of Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lionel</forename><surname>Ott</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Queensland University of Technology ?</orgName>
								<orgName type="institution" key="instit2">University of Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Ramos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Queensland University of Technology ?</orgName>
								<orgName type="institution" key="instit2">University of Sydney</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Upcroft</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Queensland University of Technology ?</orgName>
								<orgName type="institution" key="instit2">University of Sydney</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SIMPLE ONLINE AND REALTIME TRACKING</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-07-07">7 Jul 2017</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Computer Vision</term>
					<term>Multiple Object Track- ing</term>
					<term>Detection</term>
					<term>Data Association</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper explores a pragmatic approach to multiple object tracking where the main focus is to associate objects efficiently for online and realtime applications. To this end, detection quality is identified as a key factor influencing tracking performance, where changing the detector can improve tracking by up to 18.9%. Despite only using a rudimentary combination of familiar techniques such as the Kalman Filter and Hungarian algorithm for the tracking components, this approach achieves an accuracy comparable to state-of-the-art online trackers. Furthermore, due to the simplicity of our tracking method, the tracker updates at a rate of 260 Hz which is over 20x faster than other state-of-the-art trackers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>This paper presents a lean implementation of a tracking-bydetection framework for the problem of multiple object tracking (MOT) where objects are detected each frame and represented as bounding boxes. In contrast to many batch based tracking approaches <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>, this work is primarily targeted towards online tracking where only detections from the previous and the current frame are presented to the tracker. Additionally, a strong emphasis is placed on efficiency for facilitating realtime tracking and to promote greater uptake in applications such as pedestrian tracking for autonomous vehicles.</p><p>The MOT problem can be viewed as a data association problem where the aim is to associate detections across frames in a video sequence. To aid the data association process, trackers use various methods for modelling the motion <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref> and appearance <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b2">3]</ref> of objects in the scene. The methods employed by this paper were motivated through observations made on a recently established visual MOT benchmark <ref type="bibr" target="#b5">[6]</ref>. Firstly, there is a resurgence of mature data association techniques including Multiple Hypothesis Tracking (MHT) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b2">3]</ref> and Joint Probabilistic Data Association (JPDA) <ref type="bibr" target="#b1">[2]</ref> which occupy many of the top positions of the MOT benchmark. Secondly, the only tracker that does not use the Aggregate Channel Filter (ACF) <ref type="bibr" target="#b7">[8]</ref> detector is also Thanks to ACARP for funding. Benchmark performance of the proposed method (SORT) in relation to several baseline trackers <ref type="bibr" target="#b5">[6]</ref>. Each marker indicates a trackers accuracy and speed measured in frames per second (FPS) [Hz], i.e. higher and more right is better.</p><p>the top ranked tracker, suggesting that detection quality could be holding back the other trackers. Furthermore, the trade-off between accuracy and speed appears quite pronounced, since the speed of most accurate trackers is considered too slow for realtime applications (see <ref type="figure">Fig. 1</ref>). With the prominence of traditional data association techniques among the top online and batch trackers along with the use of different detections used by the top tracker, this work explores how simple MOT can be and how well it can perform. Keeping in line with Occam's Razor, appearance features beyond the detection component are ignored in tracking and only the bounding box position and size are used for both motion estimation and data association. Furthermore, issues regarding short-term and long-term occlusion are also ignored, as they occur very rarely and their explicit treatment intro-duces undesirable complexity into the tracking framework. We argue that incorporating complexity in the form of object re-identification adds significant overhead into the tracking framework -potentially limiting its use in realtime applications.</p><p>This design philosophy is in contrast to many proposed visual trackers that incorporate a myriad of components to handle various edge cases and detection errors <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref>. This work instead focuses on efficient and reliable handling of the common frame-to-frame associations. Rather than aiming to be robust to detection errors, we instead exploit recent advances in visual object detection to solve the detection problem directly. This is demonstrated by comparing the common ACF pedestrian detector <ref type="bibr" target="#b7">[8]</ref> with a recent convolutional neural network (CNN) based detector <ref type="bibr" target="#b12">[13]</ref>. Additionally, two classical yet extremely efficient methods, Kalman filter <ref type="bibr" target="#b13">[14]</ref> and Hungarian method <ref type="bibr" target="#b14">[15]</ref>, are employed to handle the motion prediction and data association components of the tracking problem respectively. This minimalistic formulation of tracking facilitates both efficiency and reliability for online tracking, see <ref type="figure">Fig. 1</ref>. In this paper, this approach is only applied to tracking pedestrians in various environments, however due to the flexibility of CNN based detectors <ref type="bibr" target="#b12">[13]</ref>, it naturally can be generalized to other objects classes.</p><p>The main contributions of this paper are:</p><p>? We leverage the power of CNN based detection in the context of MOT. ? A pragmatic tracking approach based on the Kalman filter and the Hungarian algorithm is presented and evaluated on a recent MOT benchmark. ? Code will be open sourced to help establish a baseline method for research experimentation and uptake in collision avoidance applications. This paper is organised as follows: Section 2 provides a short review of related literature in the area of multiple object tracking. Section 3 describes the proposed lean tracking framework before the effectiveness of the proposed framework on standard benchmark sequences is demonstrated in Section 4. Finally, Section 5 provides a summary of the learnt outcomes and discusses future improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">LITERATURE REVIEW</head><p>Traditionally MOT has been solved using Multiple Hypothesis Tracking (MHT) <ref type="bibr" target="#b6">[7]</ref> or the Joint Probabilistic Data Association (JPDA) filters <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b1">2]</ref>, which delay making difficult decisions while there is high uncertainty over the object assignments. The combinatorial complexity of these approaches is exponential in the number of tracked objects making them impractical for realtime applications in highly dynamic environments. Recently, Rezatofighi et al. <ref type="bibr" target="#b1">[2]</ref>, revisited the JPDA formulation <ref type="bibr" target="#b15">[16]</ref> in visual MOT with the goal to address the combinatorial complexity issue with an efficient approximation of the JPDA by exploiting recent developments in solv-ing integer programs. Similarly, Kim et al. <ref type="bibr" target="#b2">[3]</ref> used an appearance model for each target to prune the MHT graph to achieve state-of-the-art performance. However, these methods still delay the decision making which makes them unsuitable for online tracking.</p><p>Many online tracking methods aim to build appearance models of either the individual objects themselves <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b11">12]</ref> or a global model <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref> through online learning. In addition to appearance models, motion is often incorporated to assist associating detections to tracklets <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b10">11]</ref>. When considering only one-to-one correspondences modelled as bipartite graph matching, globally optimal solutions such as the Hungarian algorithm <ref type="bibr" target="#b14">[15]</ref> can be used <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20]</ref>.</p><p>The method by Geiger et al. <ref type="bibr" target="#b19">[20]</ref> uses the Hungarian algorithm <ref type="bibr" target="#b14">[15]</ref> in a two stage process. First, tracklets are formed by associating detections across adjacent frames where both geometry and appearance cues are combined to form the affinity matrix. Then, the tracklets are associated to each other to bridge broken trajectories caused by occlusion, again using both geometry and appearance cues. This two step association method restricts this approach to batch computation. Our approach is inspired by the tracking component of <ref type="bibr" target="#b19">[20]</ref>, however we simplify the association to a single stage with basic cues as described in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">METHODOLOGY</head><p>The proposed method is described by the key components of detection, propagating object states into future frames, associating current detections with existing objects, and managing the lifespan of tracked objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Detection</head><p>To capitalise on the rapid advancement of CNN based detection, we utilise the Faster Region CNN (FrRCNN) detection framework <ref type="bibr" target="#b12">[13]</ref>. FrRCNN is an end-to-end framework that consists of two stages. The first stage extracts features and proposes regions for the second stage which then classifies the object in the proposed region. The advantage of this framework is that parameters are shared between the two stages creating an efficient framework for detection. Additionally, the network architecture itself can be swapped to any design which enables rapid experimentation of different architectures to improve the detection performance.</p><p>Here we compare two network architectures provided with FrRCNN, namely the architecture of Zeiler and Fergus (FrRCNN(ZF)) <ref type="bibr" target="#b20">[21]</ref> and the deeper architecture of Simonyan and Zisserman (FrRCNN(VGG16)) <ref type="bibr" target="#b21">[22]</ref>. Throughout this work, we apply the FrRCNN with default parameters learnt for the PASCAL VOC challenge. As we are only interested in pedestrians we ignore all other classes and only pass person detection results with output probabilities greater than 50% to the tracking framework. In our experiments, we found that the detection quality has a significant impact on tracking performance when comparing the FrRCNN detections to ACF detections. This is demonstrated using a validation set of sequences applied to both an existing online tracker MDP <ref type="bibr" target="#b11">[12]</ref> and the tracker proposed here. <ref type="table" target="#tab_0">Table 1</ref> shows that the best detector (FrRCNN(VGG16)) leads to the best tracking accuracy for both MDP and the proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Estimation Model</head><p>Here we describe the object model, i.e. the representation and the motion model used to propagate a target's identity into the next frame. We approximate the inter-frame displacements of each object with a linear constant velocity model which is independent of other objects and camera motion. The state of each target is modelled as:</p><formula xml:id="formula_0">x = [u, v, s, r,u,v,?] T ,</formula><p>where u and v represent the horizontal and vertical pixel location of the centre of the target, while the scale s and r represent the scale (area) and the aspect ratio of the target's bounding box respectively. Note that the aspect ratio is considered to be constant. When a detection is associated to a target, the detected bounding box is used to update the target state where the velocity components are solved optimally via a Kalman filter framework <ref type="bibr" target="#b13">[14]</ref>. If no detection is associated to the target, its state is simply predicted without correction using the linear velocity model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Data Association</head><p>In assigning detections to existing targets, each target's bounding box geometry is estimated by predicting its new location in the current frame. The assignment cost matrix is then computed as the intersection-over-union (IOU) distance between each detection and all predicted bounding boxes from the existing targets. The assignment is solved optimally using the Hungarian algorithm. Additionally, a minimum IOU is imposed to reject assignments where the detection to target overlap is less than IOU min .</p><p>We found that the IOU distance of the bounding boxes implicitly handles short term occlusion caused by passing targets. Specifically, when a target is covered by an occluding object, only the occluder is detected, since the IOU distance appropriately favours detections with similar scale. This allows both the occluder target to be corrected with the detection while the covered target is unaffected as no assignment is made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Creation and Deletion of Track Identities</head><p>When objects enter and leave the image, unique identities need to be created or destroyed accordingly. For creating trackers, we consider any detection with an overlap less than IOU min to signify the existence of an untracked object. The tracker is initialised using the geometry of the bounding box with the velocity set to zero. Since the velocity is unobserved at this point the covariance of the velocity component is initialised with large values, reflecting this uncertainty. Additionally, the new tracker then undergoes a probationary period where the target needs to be associated with detections to accumulate enough evidence in order to prevent tracking of false positives.</p><p>Tracks are terminated if they are not detected for T Lost frames. This prevents an unbounded growth in the number of trackers and localisation errors caused by predictions over long durations without corrections from the detector. In all experiments T Lost is set to 1 for two reasons. Firstly, the constant velocity model is a poor predictor of the true dynamics and secondly we are primarily concerned with frame-to-frame tracking where object re-identification is beyond the scope of this work. Additionally, early deletion of lost targets aids efficiency. Should an object reappear, tracking will implicitly resume under a new identity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS</head><p>We evaluate the performance of our tracking implementation on a diverse set of testing sequences as set by the MOT benchmark database <ref type="bibr" target="#b5">[6]</ref> which contains both moving and static camera sequences. For tuning the initial Kalman filter covariances, IOU min , and T Lost parameters, we use the same training/validation split as reported in <ref type="bibr" target="#b11">[12]</ref>. The detection architecture used is the FrRCNN(VGG16) <ref type="bibr" target="#b21">[22]</ref>. Source code and sample detections from <ref type="bibr" target="#b21">[22]</ref> are available online. <ref type="bibr" target="#b0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Metrics</head><p>Since it is difficult to use one single score to evaluate multitarget tracking performance, we utilise the evaluation metrics defined in <ref type="bibr" target="#b23">[24]</ref>, along with the standard MOT metrics <ref type="bibr" target="#b24">[25]</ref>:</p><p>? MOTA(?): Multi-object tracking accuracy <ref type="bibr" target="#b24">[25]</ref>.</p><p>? MOTP(?): Multi-object tracking precision <ref type="bibr" target="#b24">[25]</ref>. ? ID sw(?): number of times an ID switches to a different previously tracked object <ref type="bibr" target="#b23">[24]</ref>. ? Frag(?): number of fragmentations where a track is interrupted by miss detection. Evaluation measures with (?), higher scores denote better performance; while for evaluation measures with (?), lower scores denote better performance. True positives are considered to have at least 50% overlap with the corresponding ground truth bounding box. Evaluation codes were downloaded from <ref type="bibr" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Performance Evaluation</head><p>Tracking performance is evaluated using the MOT benchmark <ref type="bibr" target="#b5">[6]</ref> test server where the ground truth for 11 sequences is withheld. <ref type="table" target="#tab_1">Table 2</ref> compares the proposed method SORT with several other baseline trackers. For brevity, only the most relevant trackers, which are state-of-the-art online trackers in terms of accuracy, such as (TDAM <ref type="bibr" target="#b17">[18]</ref>, MDP <ref type="bibr" target="#b11">[12]</ref>), the fastest batch based tracker (DP NMS <ref type="bibr" target="#b22">[23]</ref>), and all round near online method (NOMT <ref type="bibr" target="#b10">[11]</ref>) are listed. Additionally, methods which inspired this approach (TBD <ref type="bibr" target="#b19">[20]</ref>, ALEx-TRAC <ref type="bibr" target="#b4">[5]</ref>, and SMOT <ref type="bibr" target="#b0">[1]</ref>) are also listed. Compared to these other methods, SORT achieves the highest MOTA score for the online trackers and is comparable to the state-of-theart method NOMT which is significantly more complex and uses frames in the near future. Additionally, as SORT aims to focus on frame-to-frame associations the number of lost targets (ML) is minimal despite having similar false negatives to other trackers. Furthermore, since SORT focuses on frame-to-frame associations to grow tracklets, it has the lowest number of lost targets in comparison to the other methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Runtime</head><p>Most MOT solutions aim to push performance towards greater accuracy, often, at the cost of runtime performance. While slow runtime may be tolerated in offline processing tasks, for robotics and autonomous vehicles, realtime performance is essential. <ref type="figure">Fig. 1</ref> shows a number of trackers on the MOT benchmark <ref type="bibr" target="#b5">[6]</ref> in relation to both their speed and accuracy. This shows that methods which achieve the best accuracy also tend to be the slowest (bottom right in <ref type="figure">Figure 1</ref>). On the opposite end of the spectrum the fastest methods tend to have lower accuracy (top left corner in <ref type="figure">Figure 1</ref>). SORT combines the two desirable properties, speed and accuracy, without the typical drawbacks (top right in <ref type="figure">Figure 1</ref>). The tracking component runs at 260 Hz on single core of an Intel i7 2.5GHz machine with 16 GB memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>In this paper, a simple online tracking framework is presented that focuses on frame-to-frame prediction and association. We showed that the tracking quality is highly dependent on detection performance and by capitalising on recent developments in detection, state-of-the-art tracking quality can be achieved with only classical tracking methods. The presented framework achieves best in class performance with respect to both speed and accuracy, while other methods typically sacrifice one for the other. The presented framework's simplicity makes it well suited as a baseline, allowing for new methods to focus on object re-identification to handle long term occlusion. As our experiments highlight the importance of detection quality in tracking, future work will investigate a tightly coupled detection and tracking framework.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 1. Benchmark performance of the proposed method (SORT) in relation to several baseline trackers [6]. Each marker indicates a trackers accuracy and speed measured in frames per second (FPS) [Hz], i.e. higher and more right is better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of tracking performance by switching the detector component. Evaluated on Validation sequences as listed in<ref type="bibr" target="#b11">[12]</ref>.</figDesc><table><row><cell>Tracker</cell><cell>Detector</cell><cell cols="2">Detection</cell><cell cols="2">Tracking</cell></row><row><cell></cell><cell></cell><cell cols="4">Recall Precision ID Sw MOTA</cell></row><row><cell></cell><cell>ACF</cell><cell>36.6</cell><cell>75.8</cell><cell>222</cell><cell>24.0</cell></row><row><cell>MDP [12]</cell><cell>FrRCNN(ZF)</cell><cell>46.2</cell><cell>67.2</cell><cell>245</cell><cell>22.6</cell></row><row><cell></cell><cell>FrRCNN(VGG16)</cell><cell>50.1</cell><cell>76.0</cell><cell>178</cell><cell>33.5</cell></row><row><cell></cell><cell>ACF</cell><cell>33.6</cell><cell>65.7</cell><cell>224</cell><cell>15.1</cell></row><row><cell>Proposed</cell><cell>FrRCNN(ZF)</cell><cell>41.3</cell><cell>72.4</cell><cell>347</cell><cell>24.0</cell></row><row><cell></cell><cell>FrRCNN(VGG16)</cell><cell>49.5</cell><cell>77.5</cell><cell>274</cell><cell>34.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Performance of the proposed approach on MOT benchmark sequences<ref type="bibr" target="#b5">[6]</ref>.</figDesc><table><row><cell>Method</cell><cell>Type</cell><cell cols="3">MOTA? MOTP? FAF?</cell><cell>MT?</cell><cell>ML?</cell><cell>FP?</cell><cell>FN?</cell><cell cols="2">ID sw? Frag?</cell></row><row><cell>TBD [20]</cell><cell>Batch</cell><cell>15.9</cell><cell>70.9</cell><cell>2.6%</cell><cell>6.4%</cell><cell cols="3">47.9% 14943 34777</cell><cell>1939</cell><cell>1963</cell></row><row><cell>ALExTRAC [5]</cell><cell>Batch</cell><cell>17.0</cell><cell>71.2</cell><cell>1.6%</cell><cell>3.9%</cell><cell>52.4%</cell><cell cols="2">9233 39933</cell><cell>1859</cell><cell>1872</cell></row><row><cell>DP NMS [23]</cell><cell>Batch</cell><cell>14.5</cell><cell>70.8</cell><cell>2.3%</cell><cell>6.0%</cell><cell cols="3">40.8% 13171 34814</cell><cell>4537</cell><cell>3090</cell></row><row><cell>SMOT [1]</cell><cell>Batch</cell><cell>18.2</cell><cell>71.2</cell><cell>1.5%</cell><cell>2.8%</cell><cell>54.8%</cell><cell cols="2">8780 40310</cell><cell>1148</cell><cell>2132</cell></row><row><cell>NOMT [11]</cell><cell>Batch</cell><cell>33.7</cell><cell>71.9</cell><cell cols="3">1.3% 12.2% 44.0%</cell><cell cols="2">7762 32547</cell><cell>442</cell><cell>823</cell></row><row><cell>RMOT [4]</cell><cell>Online</cell><cell>18.6</cell><cell>69.6</cell><cell>2.2%</cell><cell>5.3%</cell><cell cols="3">53.3% 12473 36835</cell><cell>684</cell><cell>1282</cell></row><row><cell>TC ODAL [17]</cell><cell>Online</cell><cell>15.1</cell><cell>70.5</cell><cell>2.2%</cell><cell>3.2%</cell><cell cols="3">55.8% 12970 38538</cell><cell>637</cell><cell>1716</cell></row><row><cell>TDAM [18]</cell><cell>Online</cell><cell>33.0</cell><cell>72.8</cell><cell cols="5">1.7% 13.3% 39.1% 10064 30617</cell><cell>464</cell><cell>1506</cell></row><row><cell>MDP [12]</cell><cell>Online</cell><cell>30.3</cell><cell>71.3</cell><cell cols="3">1.7% 13.0% 38.4%</cell><cell cols="2">9717 32422</cell><cell>680</cell><cell>1500</cell></row><row><cell cols="2">SORT (Proposed) Online</cell><cell>33.4</cell><cell>72.1</cell><cell cols="5">1.3% 11.7% 30.9% 7318 32615</cell><cell>1001</cell><cell>1764</cell></row><row><cell cols="4">? FAF(?): number of false alarms per frame.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">? MT(?): number of mostly tracked trajectories. I.e. tar-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">get has the same label for at least 80% of its life span.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">? ML(?): number of mostly lost trajectories. i.e. target is</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">not tracked for at least 20% of its life span.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">? FP(?): number of false detections.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">? FN(?): number of missed detections.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/abewley/sort</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The way they move: Tracking multiple targets with similar appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dicle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sznaier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Camps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Joint Probabilistic Data Association Revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Multiple Hypothesis Tracking Revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ciptadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bayesian Multi-Object Tracking Using Motion Context from Multiple Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Winter Conference on Applications of Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ALEx-TRAC: Affinity Learning by Exploring Temporal Reinforcement within Association Chains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Upcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Robotics and Automation</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<title level="m">MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An Algorithm for Tracking Multiple Targets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatic Control</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="843" to="854" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Fast Feature Pyramids for Object Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Appel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">36</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Markov Chain Monte Carlo Data Association for General Multiple-Target Tracking Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Decision and Control</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="735" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multi-Object Tracking Through Simultaneous Long Occlusions and Split-Merge Conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hoogs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Brooksby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Near-Online Multi-target Tracking with Aggregated Local Flow Descriptor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning to Track : Online Multi-Object Tracking by Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A New Approach to Linear Filtering and Prediction Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kalman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Basic Engineering</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="35" to="45" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
	<note>no. Series D</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistics Quarterly</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Tracking and data association</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bar-Shalom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
			<publisher>Academic Press Professional, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Robust Online Multi-Object Tracking based on Tracklet Confidence and Online Discriminative Appearance Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Temporal Dynamic Appearance Modeling for Online Multi-Person Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yunde</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Online Self-Supervised Multi-Instance Segmentation of Dynamic Objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Guizilini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Upcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Robotics and Automation</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wojek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<title level="m">3D Traffic Scene Understanding from Movable Platforms</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Pattern Analysis and Machine Intelligence</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visualizing and Understanding Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Globallyoptimal greedy algorithms for tracking a variable number of objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to associate: HybridBoosted multi-target tracker for crowded scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bernardin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image and Video Processing</title>
		<imprint>
			<date type="published" when="2008-05" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
