<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fast Dynamic Routing Based on Weighted Kernel Density Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suofei</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nanjing University of Post and Telecommunication</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhao</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">SIAT</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofu</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nanjing University of Post and Telecommunication</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nanjing University of Post and Telecommunication</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Fast Dynamic Routing Based on Weighted Kernel Density Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>capsule</term>
					<term>dynamic-routing</term>
					<term>clustering</term>
					<term>kernel-density-estimation</term>
					<term>deep-learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Capsules as well as dynamic routing between them are most recently proposed structures for deep neural networks. A capsule groups data into vectors or matrices as poses rather than conventional scalars to represent specific properties of target instance. Besides of pose, a capsule should be attached with a probability (often denoted as activation) for its presence. The dynamic routing helps capsules achieve more generalization capacity with many fewer model parameters. However, the bottleneck that prevents widespread applications of capsule is the expense of computation during routing. To address this problem, we generalize existing routing methods within the framework of weighted kernel density estimation, and propose two fast routing methods with different optimization strategies. Our methods prompt the time efficiency of routing by nearly 40% with negligible performance degradation. By stacking a hybrid of convolutional layers and capsule layers, we construct a network architecture to handle inputs at a resolution of 64 ? 64 pixels. The proposed models achieve a parallel performance with other leading methods in multiple benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>During the last decade, deep learning algorithms, especially Convolutional Neural Networks (CNNs) have achieved remarkable progress on numerous practical vision tasks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3]</ref>. However, the stack of convolutional filters and non-linearity units still implies difficulty of understanding the internal organization of neural networks. It brings a reputation of "black box" to current neural networks <ref type="bibr" target="#b3">[4]</ref>. Conversely, human vision systems always show much higher interpretability during the procedure of recognition. We can explicitly tell the specific cues such as shape, color, texture or intermediate semantic concepts, and build the part-whole relationship as proofs to our final decisions. The capsule structure introduces an analogous way to construct neural networks with higher interpretability. It uses grouped scalars as pose to represent specific properties of current part. Based on the multi-dimensional representation, it finds clusters within a "routing-byagreement" framework as an interpretable representation during forward inference of network. arXiv:1805.10807v2 [cs.CV] 1 Sep 2018 <ref type="figure">Fig. 1</ref>. Capsule structures and dynamic routing between them. A capsule consists of a group of 16 scalars as pose, as well as an 1D activation as magnitude. The pose of capsule can have the format as either vector <ref type="bibr" target="#b4">[5]</ref> or matrix <ref type="bibr" target="#b5">[6]</ref>. Here routing between capsules occurs in a <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b2">3]</ref> grid including a sum of 72 capsules. It finally results in new capsules with their activations from clusters of candidate samples as output of whole procedure. Here only one output capsule is illustrated.</p><p>Dynamic routing has been proven as an effective approach with higher generalization capacity and fewer parameters <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. However, it relies on intensive computation of clustering during inference. The expense of computation prevents capsules from widespread applications in practical vision tasks. To address this problem, we model dynamic routing from the perspective of nonparametric clustering and Kernel Density Estimation (KDE), proposing a target function to explain the procedure of routing. The main contributions of this paper are twofold: <ref type="bibr" target="#b0">(1)</ref> We equip two simplified routing methods with different optimization strategies. Comparisons in different benchmarks empirically prove that our fast methods significantly prompt the efficiency of routing with negligible performance degradation. <ref type="bibr" target="#b1">(2)</ref> We propose a hybrid network structure consisting of both convolutional layers and capsules. The network can efficiently handle images with a resolution of 64 ? 64 pixels. Experiments in multiple benchmarks show that our models achieve a parallel performance with other leading methods. We believe our research of simplified routing methods prompts the potentiality of capsule networks to be extensively applied in practical vision tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Dynamic routing between capsules</head><p>Capsule structure is originally proposed in <ref type="bibr" target="#b7">[8]</ref>. Differing from a convolutional neural unit, each layer here is divided into small groups of neurons called capsules. As an instance in <ref type="figure">Figure 1</ref>, an 128D vector of data is grouped into 8 capsules with 16D data as poses. Normally, an 1D activation is combined with the pose to represent the magnitude of current capsule. Based on such multidimensional representation, a dynamic routing mechanism over capsules <ref type="bibr" target="#b4">[5]</ref> is designed between layers.</p><p>Dynamic routing is a reminiscent of the unsupervised clustering, which is purely based on the divergence between samples. Hence, different clustering methods were considered here as nonparametric routing framework <ref type="bibr" target="#b5">[6]</ref>. Finally, the activations of capsules can be exploited for solving typical machine learning problems directly. Meanwhile, the pose of capsule can also be mapped to some specific properties as regularization. The capsule structure comes with attractive features such as higher interpretability and generalization capacity. However, the high complexity of clustering method also leads to low efficiency for both training and inference. This drawback prevents the structure from applications on large scale vision tasks such as ImageNet <ref type="bibr" target="#b8">[9]</ref>.</p><p>2 Kernel density estimation KDE, also known as Parzen Window method, is a nonparametric technique for describing underlying empirical distribution over given samples. Since the calculation of KDE is only related to specific form of kernel function and distance metric, it normally leads to less computation as well as higher efficiency. Given n samples {u i |i = 1, . . . , n} in the D-dimensional space R D , the multivariate KDE of random variable v can be defined a?</p><formula xml:id="formula_0">f (v) 1 nz k n i=1 k(d(v ? u i )),<label>(1)</label></formula><p>where k(x) is a bounded function called profile function with support in univariate space R. z k is the normalization constant only related to specific k(?). Some instances of k(x) can be illustrated as <ref type="bibr" target="#b9">[10]</ref> Gaussian :</p><formula xml:id="formula_1">k(x) exp (? x 2 ), Epanechnikov : k(x) 1 ? x x ? [0, 1) 0 x ? 1.<label>(2)</label></formula><p>The distance metric between samples d(v ? u i ) can be replaced by different definitions of distance, e.g., 2 norm:</p><formula xml:id="formula_2">d(v ? u i ) = ||v ? u i || 2 , and Mahalanobis distance: (v ? u i ) T ? ?1 (v ? u i )</formula><p>. Intuitively,f (v) reflects the average distance between current point v and surrounding samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dynamic routing based on weighted KDE</head><p>KDE is the basic technique of various clustering methods <ref type="bibr" target="#b10">[11]</ref>. Despite the relationship between dynamic routing and clustering, there still exists two major problems preventing using KDE for dynamic routing directly. First, eq. 1 only considers the case of density estimation for one cluster, rather than routing between samples and multiple clusters. Second, there is no mechanism for including activation in the framework of KDE. To address these problems, we extend the density estimation from one cluster to mixture of clusters a?</p><formula xml:id="formula_3">f (v, r) 1 n l z k n l+1 j=1 n l i=1 r ij a u i k(d(v j ? u i )),<label>(3)</label></formula><p>where n l and n l+1 are number of capsules at layer l and l + 1, respectively. We rewritef (v) asf (v, r) given weights r as parameters of model. {v j |j = 1, . . . , n l+1 } are poses of capsule at layer l + 1, i.e. the resulting clusters, while {u i |i = 1, . . . , n l } are candidate samples at layer l. Note that as shown in <ref type="figure">Figure 1</ref>, we actually use the transformed votes u i|j instead of u i for clustering. However, since the clustering only takes place in the scope of v j and its corresponding votes {u i|j | i|j = 1, . . . , n l }, such change of notation will not break the following derivation. We will still use u i for simplicity. Activation a u i of input capsule is introduced here as prior knowledge from below layer. It is a straightforward way to let samples with higher activations give more impact to final position of cluster. We introduce r ij here to measures how much u i contributes to the position of v j , namely routing weight between 2 capsules.</p><p>Since in the case of dynamic routing, clustering jointly takes place between samples and multiple clusters now. For the diversity of clusters, we want one sample can contribute to clusters in different proportions. Furthermore, the total contribution from each sample to final mixture of capsules should be equivalent. Therefore, we propose to model the procedure of dynamic routing as solving the following optimization question. </p><p>We will propose two different strategies to solve eq. 4 in the following parts, and discuss the relationship between the proposed methods and other existing routing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Routing based on mean shift</head><p>Mean shift <ref type="bibr" target="#b11">[12]</ref> is a typical clustering method based on the framework of KDE. It is extensively applied in the fields of feature analysis and related vision tasks such as segmentation and object tracking <ref type="bibr" target="#b12">[13]</ref>. The original mean shift method iteratively maximizesf (v) in eq. 1 by solving the following equation</p><formula xml:id="formula_5">f (v) = 1 nz k n i=1 k (d(v ? u i )) ?d(v ? u i ) ?v = 0.<label>(5)</label></formula><p>By replacingf (v) withf (v, r), we propose to optimize variables v and r alternately. First, v ? j can be updated by analogously solving eq. 5 with fixed r ?</p><formula xml:id="formula_6">ij as v ? +1 j = n l i=1 r ? ij a u i k (d(v ? j ? u i ))u i n l i=1 r ? ij a u i k (d(v ? j ? u i )) .<label>(6)</label></formula><p>This form of v j intuitively shows that the cluster can be explained as normalized weighted summation of candidate samples. The weight consists of the coefficient r ij , the prior knowledge of candidate sample and the derivate of kernel function.</p><p>Then, with updated v ? j , we optimize r ij with the standard gradient descent method as</p><formula xml:id="formula_7">r ? +1 ij = r ? ij + ?a u i k(d(v ? j ? u i )),<label>(7)</label></formula><p>where ? is the hyper parameter to control step size. In experiments we directly use ? = 1 as a common configuration. To satisfy the constraints in eq. 4, we simply normalize r ij as r ij = r ij / n l+1 j=1 r ij for further calculation. Combining eq. 6 and eq. 7, a dynamic routing method can be obtained as algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Dynamic routing based on mean shift.</head><p>Require: poses ui, activations a u i Initialize ?i, j: rij = 1/n l+1 for r iterations do</p><formula xml:id="formula_8">1. ?i, j: r ij ? r ij j r ij 2. ?j: vj ? i r ij a u i k (d(v j ?u i ))u i i r ij a u i k (d(v j ?u i ))</formula><p>3. ?i, j: rij ? rij + a u i k(d(vj ? ui)) end for return capsules with poses vj Here we omit ? in algorithm 1. Note that the proposed routing method maximizesf (v, r) by following a framework of coordinate descent <ref type="bibr" target="#b13">[14]</ref>. Variables v and r are optimized alternately towards the direction of partial gradient. The value off (v, r) is ensured to get increased or unchanged after each iteration. Exploiting different kernel functions and distance metrics in algorithm 1 can lead to specific instances of routing methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Routing based on expectation maximization</head><p>Eq. 4 can be optimized within an Expectation Maximization (EM) framework <ref type="bibr" target="#b14">[15]</ref> as well. Due to the symmetry of kernel function, k(d(v j ? u i )) can also be explained as the likelihood of sample u i given the assumption of variable v j . From this point of view, Eq. 3 can be treated as an approximation of the log-likelihood function given samples from the mixture model which consists of v j as components and r ij as hidden weights. The EM algorithm can be exploited here to maximizef (v, r) by alternately optimizing v j and updating r ij as its expectation. In analog to the standard EM algorithm, we explicitly introduce the mixture coefficient ? j to calculate the expectation of r ij , getting algorithm 2 as another strategy to solve eq. 4.</p><p>Algorithm 2 Dynamic routing based on EM algorithm.</p><p>Require: poses ui, activations a u i Initialize ?i, j: rij = 1/n l+1 for r iterations do</p><formula xml:id="formula_9">1. ?i, j: r ij ? r ij j r ij 2. ?j: vj ? i r ij a u i u i i r ij a u i 3. ?j: ?j ? i r ij j i r ij 4. ?i, j: rij ? ?jk(d(vj ? ui))</formula><p>end for return capsules with poses vj Algorithm 2 basically follows the standard EM algorithm to maximizef (v, r). Comparing with another well-known application scenario of EM algorithm, the Gaussian Mixture Model (GMM), our proposed mixture model based on KDE can be treated as a simplified version of standard GMM. The simplification mainly comes from that KDE is based on nonparametric kernel function, rather than the normal distribution configured by expectation ? and variance ?. Hence the calculation of k(d(v j ? u i )) requires much less computation than Gaussian function N (?, ?). Also, the update of model in step 2 of algorithm 2 only requires calculation about v without the variance ? as in GMM. We will empirically prove that such simplification can still provide acceptable performance for dynamic routing.</p><p>Activation of capsule. For generic machine learning tasks, the activation of capsule is required as final result to reflect the magnitude of current capsule. It also appears in the routing procedure at above layer as prior knowledge. For the resulting capsule at layer l + 1, we propose a unified form of activation a v j for both routing methods as</p><formula xml:id="formula_10">a v j sof tmax( n l i=1 r ij a u i (k( D d=1 d(u id ? ? jd v jd ) + ? j0 )),<label>(8)</label></formula><p>where r ij is the normalized version of r ij as the result of step 1 in algorithm 1 and 2. Here the distance metric is calculated at each dimension d separately. If we ignore the linear coefficients ? j ? R D+1 , one can see from eq. 3 that activation is the absolute value of resulting density at v j after routing. It is consistent with the original purpose of combining activation to capsule. Parameters ? ? R D+1 at each dimension are learned by standard back propagation to provide a linear combination rather than the rigid connection between pose and activation. Finally, a softmax function is exploited here as the guarantee of a probability distribution over activations.</p><p>Relationship between two routing methods. We propose two dynamic routing methods by maximizing the weighted KDE functionf (v, r) with different strategies. The proposed methods can be instantiated with different kernel functions and distance metrics. For generic cases without any specific background knowledge, we propose to directly adopt Epanechnikov kernel for simplification. Note that the Epanechnikov kernel can result in an identical format of step 2 in both algorithm 1 and 2. From this point of view, the only difference between two routing methods is the strategy for update of weights r. One is based on gradient descent while the other is expectation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Network architecture</head><p>Dynamic routing has already been proven as an effective mechanism for classification tasks on datasets with small images such as MNIST <ref type="bibr" target="#b15">[16]</ref> and small-NORB <ref type="bibr" target="#b16">[17]</ref>. Our main concern here is about the efficiency and generality of dynamic routing. According to the observation of our implementation, they are the main bottleneck preventing dynamic routing from widespread utilization in practical vision tasks. Hence, we designed a relatively big network architecture for 64 ? 64 image as in <ref type="figure" target="#fig_1">Figure 2</ref>. The proposed network is a hybrid architecture of convolutional layers and capsules with dynamic routing. For all convolutional layers, we adopt a stride of 1 for sliding kernels, and a padding of features to keep the feature map size.</p><p>The network starts from convolutional layers for initialization of poses and activations of capsules. Then the primary dynamic routing takes place to represent 16 capsules with 8 capsules at every 2 ? 2 field with a stride of 2. The feature maps are downsampled here with doubled number of capsules at every position.</p><p>For the rest part of the network, we stacked a homogeneous structure sequentially as shown in <ref type="figure" target="#fig_1">Figure 2</ref>. The proposed structure consists of a capsule layer and a residual block. The residual block is analog to the structure in ResNet <ref type="bibr" target="#b17">[18]</ref>. It takes poses from below layer as input. The poses are summed with their residual maps to ReLU functions as output. We exploit such structure to integrate convolutional layer and capsules as a generic building block for deeper and larger networks. The feature map will only be downsampled at capsule layer, along with the increase of capsules at each position. The residual structure ensures an identical or better version of pose to adapt the propagation of corresponding activation in the following dynamic routing. We have tested different structures in our experiments, founding that the proposed residual block ensures most stable training for stack of capsules, especially in deeper networks.</p><p>We compose the pose of all capsules with 4?4 matrix as <ref type="bibr" target="#b5">[6]</ref>. It requires many fewer parameters for transformation matrices during routing. This structure of pose leads to a network as in <ref type="figure" target="#fig_1">Figure 2</ref> with 1.2M parameters, in which nearly 90K parameters come from dynamic routing procedure. Differing from the stack of "ConvCaps" in <ref type="bibr" target="#b5">[6]</ref>, our network shares parameters for routing at different positions without overlap between neighboring receptive fields. So although our proposed network has more parameters than network in <ref type="bibr" target="#b5">[6]</ref>, it consumes less time for both training and inference.</p><p>For comparison, we also implement an analogous CNN to the architecture in <ref type="figure" target="#fig_1">Figure 2</ref> as baseline. The network consists of 5 convolutional layers without residual structure and a global average pooling to 5-way softmax output. Except for the 1 ? 1 filters for initialization of activations, the structures of other 4 convolutional layers in <ref type="figure" target="#fig_1">Figure 2</ref> are all shared into the baseline CNN. The 5th convolutional layer contains a 3 ? 3 kernel with 5 channels and a stride of 1. Capsule layers are replaced by direct max pooling between convolutional layers. All hidden layers are connected to the ReLU non-linearity. We designed the baseline CNN with an approximately equivalent amount of parameters as well as similar structures to our proposed network, ensuring a fair comparison between them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Implementation details</head><p>We compared three routing methods and a CNN baseline in different benchmarks. Here the Fast Routing based on Mean Shift (FRMS), Fast Routing based on EM (FREM), and EM routing from <ref type="bibr" target="#b5">[6]</ref> are implemented within the proposed network architecture for consideration. During the training of these routing methods, we also integrate the reconstruction error from pose of resulting capsule as regularization in loss function. The structure of decoder from pose to original image is analogous to <ref type="bibr" target="#b4">[5]</ref>. We resize the input to 32 ? 32 image as ground truth in reconstruction to control the scale of fully connected layers.</p><p>In practical implementation, we use softmax function instead of standard normalization for the calculation of r ij in step 1 of above algorithms. This modification can relax the kernel bandwidth restriction in KDE with only trivial increase of computation. With these modifications, we adopt the Epanechnikov kernel and 1 norm: d(v ? u i ) = |v ? u i | as the default configuration for all experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation on smallNORB</head><p>We started our experiments from comparison of different routing methods on smallNORB dataset, which contains 5 categories of targets with an amount of 24,300 96 ? 96 images. During training we randomly cropped 64 ? 64 patches and augment data with random brightness and contrast. During test we directly cropped a 64 ? 64 patch from the center of image. The image is centralized with unit deviation as input to the network. We implemented all the algorithms with TensorFlow 1.2.0 <ref type="bibr" target="#b18">[19]</ref> on a hardware with Intel Xeon E5-2680 CPU at 2.4GHz and NVIDIA Tesla P40 GPU. We train the network for 50 epochs with minibatches of size 50.</p><p>We report the results of different methods in <ref type="table" target="#tab_0">Table 1</ref>. All the models are trained with 2 routing iterations for clustering. The best result is achieved by exploiting FREM within our proposed network architecture. The test error 2.2% is in-par with state-of-the-art performance gained by another routing method <ref type="bibr" target="#b5">[6]</ref>. Note that our method achieves the results at a higher resolution with much higher efficiency.</p><p>From the perspective of efficiency, one can see that although routing methods consume more time for both training and inference than baseline CNN, they significantly reduce the test error by 80% with similar network architecture. Moreover, the FREM and FRMS methods reduce the time consumption by nearly 40% from EM routing. FREM slightly outperforms EM routing with our architecture. Ablation study. We evaluated the influences of varying different configurations to routing methods on smallNORB in <ref type="table" target="#tab_1">Table 2</ref>. One can see that different number of iterations for dynamic routing severely impacts the final performance of models. Setting iteration number to 1 leads to failures of training for all methods. For the number of iterations as 3, we observed a side effect brought by long paths between capsules. We assume that this is because the training of transformation matrices relies on the back propagation of gradients from every u i at different step of iterations. Routing with more iterations tends to be impacted by the vanishing gradient problem <ref type="bibr" target="#b17">[18]</ref>. Hence, we recommend to use 2 iterations as the default configuration for routing.</p><p>Meanwhile, we also evaluated the influence of different initialization configurations. We adopt the Truncated Normal Distribution (TND) with 0 mean and 0.01 standard deviation as the common initialization for all trainable weights. However, for transformation matrices, we tried higher standard deviation as initialization. One can see from <ref type="table" target="#tab_1">Table 2</ref> that, TND with standard deviation as 0.1 or 1.0 provides much better performances than 0.01. We assume that higher deviation can lead to more differences between transformation matrices, which can serve as better initialization of the clustering. Training loss. We illustrate the curves of training loss in <ref type="figure" target="#fig_2">Figure 3</ref>. Our training loss consists of output loss defined on activations and reconstruction loss defined on poses. For the output loss function, we tried margin loss <ref type="bibr" target="#b4">[5]</ref> and spread loss <ref type="bibr" target="#b5">[6]</ref> for all candidate methods. We implement the spread loss by increasing the margin from 0.2 to 0.9 within 5 epochs. It turns out FREM can be well trained with both kinds of loss functions, while the training of FRMS and EM routing seriously relies on the relaxation from spread loss to ensure the diversity of capsules. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Other datasets</head><p>We also tested the proposed methods on MNIST, Fashion-MNIST <ref type="bibr" target="#b19">[20]</ref> and CI-FAR10 <ref type="bibr" target="#b20">[21]</ref>. To adapt the size of images in these datasets, we removed the second capsule layer as well as the residual block from the network in <ref type="figure" target="#fig_1">Figure 2</ref>. With four capsule layers the network can process an input image with 32 ? 32 pixels. We resize all images to this resolution in the experiments. We listed all results on different datasets for comparison in <ref type="table" target="#tab_2">Table 3</ref>. For MNIST, all methods approximately achieve the same accuracy, since the results are nearly saturated. For Fashion-MNIST, our methods outperform another implementation of routing-by-agreement method with 8M parameters <ref type="bibr" target="#b19">[20]</ref>. The FRMS method slightly outperforms the FREM on this dataset. For CIFAR10, we modified the first 5 ? 5 convolutional layer of network as 256 output channels with 3 color channels as input. The reported results are achieved by an ensemble of 5 models with the same hyper parameters as in the experiments on small-NORB. We omit the comparison of time consumptions of methods here since it is basically consistent to Table 1. In the case of lower resolution, there is a trivial gap between our methods and the EM routing. However, our efficient methods for routing still show high potentiality to prompt the performance of baseline CNN. We also illustrate some reconstruction samples on different datasets in <ref type="figure">Figure 4</ref>. One can see that routing methods result in reasonable reconstruction on MNIST and Fashion-MNIST. In contrast, they can only reconstruct an implicit prior of input on smallNORB, despite that the reconstruction errors do reduce in <ref type="figure" target="#fig_2">Figure 3</ref>. The training of model on smallNORB seems not impacted by this failure. We assume that smallNORB mainly consists of target models from different azimuths without any noise from background. The mechanism of routing can handle such affine transformation fairly well. We met the same failures of reconstruction on CIFAR10 as well. It seriously impacts the final performance of capsule networks. Structures with higher complexity rather than only fully connected layers in decoder could be a potential way to mitigate this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and Related Work</head><p>We treat dynamic routing as an advanced compression of knowledge from capsules at layer l to l + 1. Features from candidate capsules are represented by a mixture of less capsules with corresponding magnitudes. The compression mainly relies on the unsupervised clustering as well as transformation matrices. Conventional clustering methods for mixture models normally start from randomized samples as initialization, while dynamic routing relies on transformation matrices as guarantee of diversity over different clusters. The learning of transformation matrices by back propagation thus can be modeled as the procedure of compressing knowledge into new clusters for a more efficient representation. Based on these principles, we proposed two simplified routing methods for better cooperation with back propagation learning. Our methods can also be treated as a generalized version of existing routing methods.</p><p>FRMS and routing-by-agreement <ref type="bibr" target="#b4">[5]</ref>. We use the term "Routing-byagreement" to represent the original routing method in <ref type="bibr" target="#b4">[5]</ref>. By a non-linear "squashing" function, all lengths of capsules here are compressed into [0, 1) in analog to probabilities. Since routing-by-agreement is only deployed once at the "DigitCaps" layer, no prior from below layer is considered, i.e. a u i can be omitted from algorithm 1. With the same modification, it can be shown that by using the Epanechnikov kernel function and a non-strict distance metric from the cosine similarity as</p><formula xml:id="formula_11">u, v 1 ? u T v,<label>(9)</label></formula><p>a quite similar routing method to routing-by-agreement can be derived from FRMS as algorithm 3. Here we replace d(u ? v) by u, v due to its specific form.</p><p>Routing-by-agreement directly assigns length of pose as the activation of capsule without any linear coefficient ?. We can analogously modify the definition of activation in eq. 8 as </p><formula xml:id="formula_12">a v j sof tmax( n l i=1 r ij u T i v j ).<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Variant of FRMS.</head><p>Require: poses ui, activations a u i Initialize ?i, j: rij = 1/n l+1 for r iterations do 1. ?i, j: r ij ? sof tmax(rij) 2. ?j: vj ? i r ij ui 3. ?i, j: rij ? rij + u T i vj end for return capsules with poses vj Here we also remove a u i from the equation for an easier comparison. Note that since we update v j here as v j ? n l i=1 r ij u i , eq. 8 can be rewritten as the squared length of v j directly.</p><p>However, from eq. 5 we can see that the derivation of step 2 in algorithm 3 is suspicious due to the specific form of u, v . The convergence of whole algorithm is not well ensured. During our experiments, we also observed that stack of algorithm 3 can easily lead to failures of training. So we remove the method from comparison.</p><p>FREM and EM routing <ref type="bibr" target="#b5">[6]</ref>. The proposed FREM can be treated as a simplified version of EM routing. The detailed analysis of the relationship between KDE based mean shift and EM could be referred to <ref type="bibr" target="#b21">[22]</ref>. EM routing addresses the clustering question completely within the framework of GMM, maximizing the log-likelihood function with Gaussian function as the divergence metric. The differences between FREM and EM routing can be mainly summarized as follows: (1) EM routing exploits activation a v j in the update of weight r ij as prior knowledge of cluster. We use the mixture coefficient ? j as standard EM algorithm for simplification. According to our implementation, this modification only brings trivial impact to routing performance. (2) Gaussian function provides asymmetrical kernels with the variance ? at each dimension of cluster. Our KDE based kernel is symmetrical at all dimensions. This simplification leads to non-trivial influence to the performance of our routing method. However, with the utilization of convolutional layers, the impact is significantly mitigated to an acceptable level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we propose two efficient routing methods by generalizing existing methods within the framework of weighted KDE. Rather than constructing network with capsule structures independently for higher performance, we propose to exploit capsules and dynamic routing as effective complements with convolutional units. Experimental results show that such hybrid structure is promising to provide efficient solutions with much higher capacity for large scale vision tasks. In our future work, we plan to further prompt the performance of capsule networks on practical image datasets with higher resolution, e.g., STL-10 <ref type="bibr" target="#b22">[23]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>v, r = arg max v,rf (v, r) s.t. ?i, j : r ij &gt; 0, n l+1 j=1 r ij = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>The proposed network architecture for a 64 ? 64 image. It contains 5 capsule layers where dynamic routing occurs. Except the last one, the dynamic routing at each capsule layer takes place within a 2 ? 2 field with a stride of 2. At each block for dynamic routing, the number of input capsules is listed as width?height?number of capsules at each position. The number of output capsules is listed under the arrow. The side lengths of feature maps after each capsule layer are 32, 16, 8 and 4, respectively. The final dynamic routing takes all capsules within a 4 ? 4 feature maps into account, resulting in 5 capsules as output. Here we take the smallNORB dataset for instance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>The tendencies of output loss and reconstruction loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Performance evaluation on smallNORB.</figDesc><table><row><cell>Method</cell><cell cols="2">Inference time Training time Test error rate</cell></row><row><cell>FRMS</cell><cell>0.158 ? 0.001s 0.470 ? 0.002s</cell><cell>2.6%</cell></row><row><cell>FREM</cell><cell>0.158 ? 0.003s 0.471 ? 0.002s</cell><cell>2.2%</cell></row><row><cell cols="2">EM routing 0.252 ? 0.003s 0.744 ? 0.003s</cell><cell>2.3%</cell></row><row><cell cols="2">Baseline CNN 0.043 ? 0.003s 0.064 ? 0.001s</cell><cell>11.3%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Ablation study on smallNORB. Here we omit variances of time consumption for simplicity. "Stddev" represents the standard deviation of TND for initialization.</figDesc><table><row><cell cols="4">Method Routing iterations Stddev Test error rate</cell></row><row><cell>FRMS</cell><cell>1</cell><cell>0.1</cell><cell>76.9%</cell></row><row><cell>FRMS</cell><cell>2</cell><cell>0.01</cell><cell>5.9%</cell></row><row><cell>FRMS</cell><cell>2</cell><cell>0.1</cell><cell>2.6%</cell></row><row><cell>FRMS</cell><cell>2</cell><cell>1.0</cell><cell>2.7%</cell></row><row><cell>FRMS</cell><cell>3</cell><cell>0.1</cell><cell>7.1%</cell></row><row><cell>FREM</cell><cell>1</cell><cell>0.1</cell><cell>77.8%</cell></row><row><cell>FREM</cell><cell>2</cell><cell>0.01</cell><cell>5.6%</cell></row><row><cell>FREM</cell><cell>2</cell><cell>0.1</cell><cell>2.2%</cell></row><row><cell>FREM</cell><cell>2</cell><cell>1.0</cell><cell>2.3%</cell></row><row><cell>FREM</cell><cell>3</cell><cell>0.1</cell><cell>6.0%</cell></row><row><cell>EM routing</cell><cell>1</cell><cell>0.1</cell><cell>70.2%</cell></row><row><cell>EM routing</cell><cell>2</cell><cell>0.01</cell><cell>6.2%</cell></row><row><cell>EM routing</cell><cell>2</cell><cell>0.1</cell><cell>2.3%</cell></row><row><cell>EM routing</cell><cell>2</cell><cell>1.0</cell><cell>2.3%</cell></row><row><cell>EM routing</cell><cell>3</cell><cell>0.1</cell><cell>5.8%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Results of proposed methods on datasets.</figDesc><table><row><cell>Method</cell><cell cols="3">MNIST Fashion-MNIST CIFAR10</cell></row><row><cell>FRMS</cell><cell>0.42%</cell><cell>6.0%</cell><cell>15.6%</cell></row><row><cell>FREM</cell><cell>0.38%</cell><cell>6.2%</cell><cell>14.3%</cell></row><row><cell cols="2">EM routing 0.32%</cell><cell>5.8%</cell><cell>11.6%</cell></row><row><cell cols="2">Baseline CNN 0.65%</cell><cell>7.6%</cell><cell>19.2%</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">2012</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Largescale video classification with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Toderici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1725" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Understanding intermediate layers using linear classifier probes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Alain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.01644</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Dynamic routing between capsules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Frosst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3859" to="3869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Matrix capsules with em routing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sabour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Frosst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Conference</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Investigating capsule networks with dynamic routing for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jianbo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zeyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Suofei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Empirical Methods on Natural Language Processing</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Transforming auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Kernel smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Wand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Crc Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning mixtures by simplifying kernel density estimators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Schwander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nielsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Matrix Information Geometry</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="403" to="426" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mean shift: A robust approach toward feature space analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="603" to="619" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Real-time tracking of non-rigid objects using mean shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="142" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Coordinate descent algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Wright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="34" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the em algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the royal statistical society. Series B (methodological</title>
		<imprint>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning methods for generic object recognition with invariance to pose and lighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2004 IEEE Computer Society Conference on</title>
		<meeting>the 2004 IEEE Computer Society Conference on</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
	<note>Computer Vision and Pattern Recognition</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<title level="m">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>18 submission ID ***</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gaussian mean-shift is an em algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Carreira-Perpinan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="767" to="776" />
			<date type="published" when="2007-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics</title>
		<meeting>the fourteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
