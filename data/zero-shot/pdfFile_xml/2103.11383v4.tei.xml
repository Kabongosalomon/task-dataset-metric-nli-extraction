<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MULTI-LEVEL METRIC LEARNING FOR FEW-SHOT IMAGE RECOGNITION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxing</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxiong</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaohui</forename><surname>Li</surname></persName>
							<email>yaohuili@smail.nju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunlin</forename><surname>Chen</surname></persName>
							<email>clchen@nju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Nanjing University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MULTI-LEVEL METRIC LEARNING FOR FEW-SHOT IMAGE RECOGNITION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Multi-level</term>
					<term>metric-learning</term>
					<term>few-shot</term>
					<term>image recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Few-shot learning is devoted to training a model on few samples. Most of these approaches learn a model based on a pixel-level or global-level feature representation. However, using global features may lose local information, and using pixel-level features may lose the contextual semantics of the image. Moreover, such works can only measure the relations between them on a single level, which is not comprehensive and effective. And if query images can simultaneously be well classified via three distinct level similarity metrics, the query images within a class can be more tightly distributed in a smaller feature space, generating more discriminative feature maps. Motivated by this, we propose a novel Part-level Embedding Adaptation with Graph (PEAG) method to generate task-specific features. Moreover, a Multilevel Metric Learning (MML) method is proposed, which not only calculates the pixel-level similarity but also considers the similarity of part-level features and global-level features. Extensive experiments on popular few-shot image recognition datasets prove the effectiveness of our method compared with the state-of-the-art methods. Our code is available at https://github.com/chenhaoxing/M2L.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Humans can learn novel concepts and objects with just a few samples. Recently, many methods were proposed to learn new concepts with limited labeled data, such as semi-supervised learning <ref type="bibr" target="#b0">[1]</ref>, zero-shot learning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, and few-shot learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>. Facing with the problem of data scarcity, these three paradigms propose solutions from different perspectives. Semi-supervised learning aims to train a model with few labeled data and a large amount of unlabeled data, and zero-shot learning devoted to identifying unseen categories with no labeled data, while few-shot learning focuses on learning new concepts with few labeled data. We propose a novel few-shot learning method to address the problem of data scarcity in this paper.</p><p>The few-shot learning methods can be roughly classified into two categories: meta-learning based methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref> and metric-learning based methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref>. Metric-based few-shot learning methods have achieved remarkable success due to their fewer parameters and effectiveness. In this work, we focus on this branch.</p><p>The basic idea of the metric-learning based few-shot learning method is to learn a good metric to calculate the similarity between query images and the support set. Therefore, how to learn good feature embedding representation and similarity metric are the key problem of metric-learning based few-shot learning method. For feature embedding representation, Prototypical Networks <ref type="bibr" target="#b4">[5]</ref> and Relation Networks <ref type="bibr" target="#b5">[6]</ref> adopt image-level feature representations. However, due to the scarcity of data, it is not sufficient to measure the relation at the image-level <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Recently, CovaMNet <ref type="bibr" target="#b10">[11]</ref>, DN4 <ref type="bibr" target="#b6">[7]</ref> and MATANet <ref type="bibr" target="#b8">[9]</ref> introduce local representations (LRs) into few-shot learning and utilize these LRs to represent the image features, which can achieve better recognition results.</p><p>For similarity metrics, these existing methods calculate similarities by different metrics. For example, Relation Networks <ref type="bibr" target="#b5">[6]</ref> proposes a network to learn the most suitable image-level similarity metric functions. DN4 <ref type="bibr" target="#b8">[9]</ref> proposes a cosine-based image-to-class metric to measure the similarity on pixel-level.</p><p>However, global-level features lose local semantic information and pixel-level features lose contextual semantics, thus all methods mentioned above are not effective for fewshot learning. Moreover, these methods only calculate similarities on a single level, i.e., pixel-level or image-level, which is not effective enough. Intuitively, under the few-shot learning setting, the features obtained by adopting a single similarity measure are not comprehensive, and the single similarity measure may lead to a certain similarity deviation, thus reducing the generalization ability of the model. It is necessary to adopt multi-level similarity metric, generating more discriminative features rather than using a single measure.</p><p>To this end, we propose part-level embedding adaptation with graph (PEAG) method and multi-level metric learning method (MML). In PEAG, we divide each image into patches and get part-level features. Then, we utilize Graph Convolutional Network (GCN) to generate task-spcific features. Finally, we adpot a nearest neighbor matching module to get part-level similarity. In MML, in addition to component-level measures, we also use global-level measures and pixel-level measures to provide complementary information for a more compact measurement space. In MML, we also use globallevel and pixel-level metrics to provide complementary information, and images within a class can be more tightly distributed in a smaller feature space.</p><p>The main contributions are summarized as follows:</p><p>? We propose a novel part-level embedding adatation with graph method, which can generate task-specific part-level features and capture the part-level semantic similarity between query images and support images. ? We propose a novel multi-level metric learning method by computing the semantic similarities on pixel-level, part-level, and global-level simultaneously, aiming to find more comprehensive semantic similarities. ? We conduct sufficient experiments on popular benchmark datasets to verify the advancement of our model and the performance of our model achieves the stateof-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORKS</head><p>In this section, we focus on related works on metric-learning based few-shot learning model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Learning feature embedding representation</head><p>Koch et al. <ref type="bibr" target="#b11">[12]</ref> used a Siamese Neural Network to tackle the one-shot learning problem, in which the feature extractor is of VGG styled structure and L 1 distance is used to measure the similarity between query images and support images. Snell et al. <ref type="bibr" target="#b4">[5]</ref> proposed Prototypical Networks, in which the Euclidean distance is used to compute the distance between class-specific prototypes. Li et al. <ref type="bibr" target="#b6">[7]</ref> proposed an image-toclass mechanism to find the relation at pixel-level, in which the image features are represented as a local descriptor collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Learning similarity metric</head><p>Sung et al. <ref type="bibr" target="#b5">[6]</ref> replaced the existing metric with the Relation Network, which measures the similarity between each query instance and support classes. Li et al. <ref type="bibr" target="#b6">[7]</ref> proposed a Deep Nearest Neighbor Neural Network (DN4) to learn an imageto-class metric by measuring the cosine similarity between the deep local descriptors of a query instance and its neighbors from each support class. Li et al. <ref type="bibr" target="#b10">[11]</ref>explored the distribution consistency-based metric by introducing local covariance representation and deep covariance metric. Unlike these methods, the proposed MML measures the similarity at three different feature levels, i.e., pixel-level, part-level, and distribution-level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">PROBLEM DEFINITION AND FORMULATION</head><p>Standard few-shot image recognition problems are often formalized as N-way M-shot classification problem, in which models are given M seen images from each of N classes, and required to correctly classify unseen images. Different from traditional image recognition tasks, few-shot learning aims to classify novel classes after training. This requires that samples used for training, validation, and testing should come from disjoint label space. To be more specific, given a dataset of visual concepts C, we devide it into three parts: C train , C val and C test , and their label space satisfy</p><formula xml:id="formula_0">L train ? L val ? L test = ?.</formula><p>To obtain a trained model, we train our model in an episodic way. That is, in each episode, a new task is randomly sampled from the training set C train to train the current model. Each task consists of two subsets, including support set A S and query set A Q . The A S contains N previously unseen classes, with M samples for each class. We focus on training our model to correctly determine which category each image in the A Q belongs to. Similarly, we randomly sample tasks from C val and C test for meta-validation and meta-testing scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MULTI-LEVEL METRIC LEARNING</head><p>As shown in <ref type="figure">Figure 2</ref>, our MML is mainly composed of two modules: a feature extractor F ? , a multi-level metric-learning module. All images are first fed into the F ? to get feature embeddings. Then, the multi-level metric-learning module calculates similarities on part-level, pixel-level, and distributionlevel simultaneously. Finally, we fuse these three similarities together. All the modules can be trained jointly in an end-toend manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Part-level Metric</head><p>We divide each image into H ? W patches evenly, and input each patch into F ? separately to generate part-level descriptors. In order to further enhance the representation ability of features, we adopt a pyramid structure. Thus, under N-way M-shot few-shot learning setting, given a query image q and support class S n , n = {1, ..., N }, through F ? and global-average pooling (GAP) layer, we can get the part-level descriptors: X part q ? R C?K and X part Sn ? R C?M K . Specifically, we adopt two image patch division strategies of size 2?2 and 3?3 to obtain 13 part-level descriptors.</p><p>To generate task-specific support features, we propose a novel part-level embedding adaptation with graph (PEAG) method. Specifically, we concatenate all support features and get X part S ? R C?N M K . Then, we construct the degree matrix A ? R N M K?N M K to represent the similarity between patches in the support set. If two patches p i and p j have the same semantics, then we set the corresponding element A ij to 1, otherwise to 0. Based on A, we build the adjacency matrix S:</p><formula xml:id="formula_1">S = D ? 1 2 (A + I)D ? 1 2 (1) where I ? R N M K?N M K is the identity matrix and D is the diagonal matrix (D ii = j A ij + 1). Let ? 0 = X part S</formula><p>, the relationship between patches could be propagated based on S:</p><formula xml:id="formula_2">? t+1 = ReLU(S? t W ), t = {0, ..., T ? 1}<label>(2)</label></formula><p>where W is a learned feature transformation matrix. After propagate the embedding set T times, we can get the final propagated embedding set ? T = X part S . Then, for each class X part S n , we calculate the correlation matrix R part ? R K?M K between the query image and the support class n on part-level:</p><formula xml:id="formula_3">R part = (X part q ) X part S n X part q ? X part S n (3) R part i,j</formula><p>is (i, j) element of R part reflecting the distance between the i-th descriptors of the query image and the j-th descriptor of support clss n. Each row in R part represents the semantic relation of each descriptor in the query image to all descriptors of all images in the support class. For each patch of the query image q, we find its most similar descriptor. Then, we sum K selected part-level descriptors as the part-level similarity between the query image and the support class n:</p><formula xml:id="formula_4">D part (q, S n ) = K i=1 Top1(R part i )<label>(4)</label></formula><p>where Top(?) means selecting the largest elements in each row of the R part .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Pixel-level Metric</head><p>Following <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b8">9]</ref>, given a query image q and a certain support class S n , through feature extractor F ? , we can get the feature representation F ? (q) ? R C?H?W and F ? (S n ) ? R M ?C?H?W , respectively. The F ? (q) can be regard as a set of H ? W C-dimensional LRs:</p><formula xml:id="formula_5">L pixel q = [u pixel 1 , ..., u pixel HW ] ? R C?HW<label>(5)</label></formula><p>Also, the F ? (S n ) can be regards as</p><formula xml:id="formula_6">L pixel Sn = [v pixel 1 , ..., v pixel M HW ] ? R C?M HW<label>(6)</label></formula><p>Then, we calculate the correlation matrix R pixel ? R HW ?M HW between the query image and the support class on pixel-level and select the largest element in each row of the correlation matrix:</p><formula xml:id="formula_7">R pixel = (u pixel i ) v pixel j u pixel i ? v pixel j (7) D pixel (q, S n ) = HW i=1 Top1(R pixel i )<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Global-level Metric</head><p>We adpot Prototypical Networks <ref type="bibr" target="#b4">[5]</ref>  mean of global convulution embeddings as the prototype representation of each category n:</p><formula xml:id="formula_8">c n = 1 M i=1 M GAP(F ? (S i n ))<label>(9)</label></formula><p>where p n ? R K . Similarly, given a query image Q, we can get its global convulution embeddings X global Q ? R K . Then, Prototypical Networks utilized Euclidean distance as the distance metric and assigns a probability over class n:</p><formula xml:id="formula_9">D global (q, S n ) = ?d(X global Q , c n )<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Fusion Layer</head><p>Since three different level similarities have been calculated, we need to design a fusion module to integrate them. Specifically, the final similarity and probability over any class n can be obtained by the following equation:</p><formula xml:id="formula_10">P part (y = n|q) = D part (q, S n ) N i=1 D part (q, S n ) (11) P pixel (y = n|q) = D pixel (q, S n ) N i=1 D pixel (q, S n )<label>(12)</label></formula><formula xml:id="formula_11">P global (y = n|q) = D global (q, S n ) N i=1 D global (q, S n )<label>(13)</label></formula><p>P (y = n|q) =?P part (y = n|q) + ?P global (y = n|q)</p><formula xml:id="formula_12">+ ?P pixel (y = n|q)<label>(14)</label></formula><p>where y is the label of q, ?, ? and ? are superparameters. If y = n , then we can define the loss function as follows: L = ? ?log(p part (y = n |q)) ? ?log(p pixel (y = n |q)) ? ?log(p global (y = n |q)) (15)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EXPERIMENTS</head><p>In this section, we perform extensive experiments to verify the advance and effectiveness of MML.  <ref type="table">Table 2</ref>. Ablation study on miniImageNet. (Top two performances are in bold font.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Datasets</head><p>To verify the advance and effectiveness of our proposed MML, we performed experiments on four benchmark datasets.</p><p>ImageNet derivatives: Both miniImageNet [13] dataset and tieredImageNet <ref type="bibr" target="#b13">[14]</ref> dataset are subsets of ImageNet <ref type="bibr" target="#b14">[15]</ref>. The miniImageNet dataset consists 100 classes, each of which contains 600 samples, and the tieredImageNet contains 608 classes.</p><p>CIFAR derivatives: Both CIFAR-FS <ref type="bibr" target="#b15">[16]</ref> dataset and FC100 <ref type="bibr" target="#b16">[17]</ref> dataset are subsets of CIFAR-100. Both of them consist 100 classes.</p><p>The partition of all data sets is shown in <ref type="table" target="#tab_0">Table 1</ref>. All images are resized to 84 ? 84.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Implementation Details</head><p>In order to make a fair comparison with other works, we adopt the ResNet-12 network <ref type="bibr" target="#b17">[18]</ref> as our feature extrator F ? .</p><p>ResNet-12 has four residual blocks, each residual block has 3 convolutional layers with 3?3 kernel, and a 2 ? 2 maxpooling layer is added in the first residual block.</p><p>We conduct our experiments on a series of N-way M-shot tasks, i.e., 5-way 1-shot and 5-way 5-shot. Following <ref type="bibr" target="#b18">[19]</ref>, we first pre-trained F ? with an MLP consisting of a single hidden layer. Then we meta-train the whole model by momentum SGD for 40 epochs. In each epoch, we randomly sampled 200 tasks. Our batch size is set to 4, the initial learning rate is 5 ? 10 ?4 , and multiplied by 0.5 every 10 epochs. During the test stage, we report the average accuracy as well as the corresponding 95% confidence interval over these 10,000 tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Ablation Study</head><p>To explore the effect of the multi-level metric learning module, we prune any of three similarity branches in the multi- level metric-learning module. Specifically, we change the values of ?, ? and ?, and experiment on the miniImageNet.</p><p>As seen in <ref type="table">Table 2</ref>, each part of the MML is indispensable. It can be observed that the accuracy of few-shot image recognition using only one level of features is very low. The results were significantly improved when two or three levels of features were used together, and the results were best when all three levels were used together. Specifically, compared with the method that only using pixel-level features, our MML gains 5.4% and 3.7% improvements. Note that it is important to choose the appropriate hyperparameters. When ? and ? become larger, the accuracy of the model will become worse. Appropriate ? and ? can provide useful auxiliary information for part-level metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Comparison Against Related Approaches</head><p>Results on ImageNet derivatives. As seen from <ref type="table">Table 3</ref>, our MML achieves the highest accuracy on miniImageNet with 67.58% and 81.41% on 5-way 1-shot and 5-way 5-shot tasks respectively, which make a great improvement compared to the previous single level metric-learning based methods. For example, our MML is 4.6% and 8.0% better than DSN-MR <ref type="bibr" target="#b7">[8]</ref> and Prototypical Networks [5] on the 5-way 1shot task, respectively. And our MML achieves 71.38% and 84.65% on tieredImageNet under 5-way 1-shot and 5-way 5-shot few-shot learning setting respectively, which achieves competitive performance.</p><p>Results on CIFAR derivatives. <ref type="table">Table 4</ref> evaluates our method on two CIFAR derivatives, i.e., CIFAR-FS and FC100. It can be seen that the proposed MML obtains sig-nificant improvements compared with previous state-of-theart methods. Specifically, compared with global-level metriclearning based methods (i.e., Relation Networks <ref type="bibr" target="#b5">[6]</ref>, Prototypical Networks <ref type="bibr" target="#b4">[5]</ref> and Fine-tuning <ref type="bibr" target="#b22">[23]</ref>), MML is 20.3% and 3.5% better than the best one of them on CIFAR-FS and FC100 under 5-way 5-shot setting.</p><p>Moreover, we can also see that the proposed PEAG achieved competitive results. For example, our PEAG is 0.8% and 1.8% better than FEAT <ref type="bibr" target="#b18">[19]</ref> and GLoFA <ref type="bibr" target="#b19">[20]</ref> on miniImageNet under the 5-way 1-shot setting, respectively.</p><p>The reason why our MML can achieve these state-of-theart performances is that MML can measure the semantic similarities on multiple levels, i.e., part-level, pixel-level, and global-level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>In this paper, we revisit the metric-learning based method and proposed novel Part-level Embedding Adaptation with Graph (PEAG) method and Multi-level Metric Learning (MML) method for few-shot image recognition, aiming to capture more comprehensive semantic similarities. Specifically, PEAG can generate task-specific part-level features and capture the part-level semantic similarity between query images and support images, and MML can measure the semantic similarities on multiple levels and produce more discriminative features. Extensive experiments show the effectiveness and the superiority of both PEAG and MML.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>The framework of MML under the 3-way 2-shot image classification setting. (Best view in color.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Dataset N all N train N val N test The splits of evaluation datasets. N all is the number of all classes. N train , N val and N test indicate the number of classes in training set, validation set and test set.</figDesc><table><row><cell>miniImageNet</cell><cell>100</cell><cell>64</cell><cell>16</cell><cell>20</cell></row><row><cell cols="2">tieredImageNet 608</cell><cell>351</cell><cell>97</cell><cell>160</cell></row><row><cell>CIFAR-100</cell><cell>100</cell><cell>64</cell><cell>16</cell><cell>20</cell></row><row><cell>FC100</cell><cell>100</cell><cell>60</cell><cell>20</cell><cell>20</cell></row></table><note>as our global-level sim- ilarity metric. Prototypical Networks computes the empirical</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .Table 4 .</head><label>34</label><figDesc>Comparison with other state-of-the-art methods with 95% confidence intervals on miniImageNet and tieredImageNet. -10 76.58?0.68 85.79?0.50 43.16?0.59 57.57 ?0.55 PEAG ResNet-12 74.27?0.23 83.89?0.20 43.99?0.21 56.47?0.24 MML ResNet-12 75.28?0.23 85.95?0.19 44.43?0.21 59.56?0.25 Experimental results compared with other methods on CIFAR-FS and FC100. (Top two performances are in bold font.)</figDesc><table><row><cell>Model</cell><cell>Backbone</cell><cell cols="2">miniImageNet</cell><cell cols="2">tieredImageNet</cell></row><row><cell></cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>Prototypical Networks [5]</cell><cell>Conv-64F</cell><cell cols="4">49.42?0.78 68.20?0.66 53.31?0.89 72.69?0.74</cell></row><row><cell>Relation Networks [6]</cell><cell>Conv-64F</cell><cell cols="4">50.44 ?0.82 65.32?0.77 54.48?0.93 71.32?0.78</cell></row><row><cell>DN4 [7]</cell><cell>Conv-64F</cell><cell cols="4">51.24 ?0.74 71.02?0.64 53.37?0.86 74.45?0.70</cell></row><row><cell>Prototypical Networks [5]</cell><cell>ResNet-12</cell><cell cols="4">62.59?0.85 78.60?0.16 68.37?0.23 83.43?0.16</cell></row><row><cell>TADAM [17]</cell><cell>ResNet-12</cell><cell cols="2">58.50?0.30 76.70?0.30</cell><cell>-</cell><cell>-</cell></row><row><cell>MeaOptNet [18]</cell><cell>ResNet-12</cell><cell cols="4">62.64?0.61 78.63?0.46 65.99?0.72 81.56?0.53</cell></row><row><cell>DSN-MR [8]</cell><cell>ResNet-12</cell><cell cols="4">64.60?0.72 79.51?0.50 67.39?0.82 82.85?0.56</cell></row><row><cell>FEAT [19]</cell><cell>ResNet12</cell><cell cols="4">66.78?0.20 82.05?0.14 67.39?0.82 82.85?0.56</cell></row><row><cell>GLoFA [20]</cell><cell>ResNet12</cell><cell cols="4">66.12?0.42 81.37?0.33 69.75?0.33 83.58?0.42</cell></row><row><cell>Fine-tuning [4]</cell><cell cols="5">WRN-28-10 57.73?0.62 78.17?0.49 66.58?0.70 85.55?0.48</cell></row><row><cell>AWGIM [21]</cell><cell cols="5">WRN-28-10 63.12?0.08 78.40?0.11 67.69?0.11 82.82?0.13</cell></row><row><cell>PEAG</cell><cell>ResNet-12</cell><cell cols="4">67.29?0.23 78.49?0.21 68.89?0.25 82.08?0.21</cell></row><row><cell>MML</cell><cell>ResNet-12</cell><cell cols="4">67.58?0.23 81.41?0.20 71.38?0.25 84.65?0.20</cell></row><row><cell>(Top two performances are in bold font.)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>Backbone</cell><cell cols="2">CIFAR-FS</cell><cell>FC100</cell></row><row><cell></cell><cell></cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell>Prototypical Networks [5]</cell><cell>Conv-64F</cell><cell cols="4">55.50?0.70 72.00?0.60 35.30?0.60 48.60?0.60</cell></row><row><cell>Relation Networks [6]</cell><cell cols="3">Conv-256F 55.00?1.00 69.30?0.80</cell><cell>-</cell><cell>-</cell></row><row><cell>R2D2 [16]</cell><cell cols="3">Conv-512F 65.30?0.20 79.40?0.10</cell><cell>-</cell><cell>-</cell></row><row><cell>Prototypical Networks [5]</cell><cell>ResNet-12</cell><cell cols="4">72.20?0.70 83.50?0.50 37.50?0.60 52.50?0.60</cell></row><row><cell>TADAM [17]</cell><cell>ResNet-12</cell><cell>-</cell><cell>-</cell><cell cols="2">40.10?0.40 56.10?0.40</cell></row><row><cell>MeaOptNet [18]</cell><cell>ResNet-12</cell><cell cols="4">72.60?0.70 84.30?0.50 41.10?0.60 55.50?0.60</cell></row><row><cell>MABAS [22]</cell><cell>ResNet-12</cell><cell cols="4">73.51?0.92 85.49?0.68 42.31?0.75 57.56?0.78</cell></row><row><cell>Fine-tuning [23]</cell><cell>WRN-28</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semisupervised learning for few-shot image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abel</forename><surname>Gonzalez-Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad Shahbaz</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4452" to="4461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Episode-based prototype generating network for zero-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunlong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongfei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14032" to="14041" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Self-supervised domain-aware generative network for generalized zeroshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiamin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianzhu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Jun</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12764" to="12773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in CVPR</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Revisiting local descriptor based image-to-class measure for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinglin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Adaptive subspaces for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrtash</forename><surname>Harandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Multi-scale adaptive task attention network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxiong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaohui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunlin</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.14479</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Meta-transfer learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoyao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Distribution consistency based covariance metric networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinglin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AAAI</publisher>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshops</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3630" to="3638" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICLR</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable closed-form solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">TADAM: task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Pau Rodr?guez L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in NeurIPS</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note>Avinash Ravichandran, and Stefano Soatto</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Few-shot learning via embedding adaptation with setto-set functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hexiang</forename><surname>Han-Jia Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>De-Chuan Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Tailoring embedding function to heterogeneous few-shot tasks by global and local feature adaptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han-Jia</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De-Chuan</forename><surname>Zhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>AAAI</publisher>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Attentive weights generation for few shot learning via information maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiluan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai-Man</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13496" to="13505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Model-agnostic boundary-adversarial sampling for test-time generalization in few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaekyeom</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyoungseok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunhee</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">12346</biblScope>
			<biblScope unit="page" from="599" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A baseline for fewshot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guneet</forename><surname>Singh Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
