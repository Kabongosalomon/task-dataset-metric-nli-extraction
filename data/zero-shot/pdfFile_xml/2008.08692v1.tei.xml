<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Virtual Event</publisher>
				<availability status="unknown"><p>Copyright Virtual Event</p>
				</availability>
				<date>October 19-23, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Deng</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
							<email>penghao@act.buaa.edu.cn</email>
							<affiliation key="aff2">
								<orgName type="department">Beijing Advanced Innovation Center for Big Data and Brain Computing</orgName>
								<orgName type="institution">Beihang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
							<email>psyu@uic.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtong</forename><surname>Dou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Illinois at Chicago</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Deng</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Peng</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Beijing Advanced Innovation Center for Big Data and Brain Computing</orgName>
								<orgName type="institution">Beihang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
						</author>
						<title level="a" type="main">Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters</title>
					</analytic>
					<monogr>
						<title level="m">CIKM &apos;20</title>
						<meeting> <address><addrLine>Ireland</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Virtual Event</publisher>
							<date type="published">October 19-23, 2020</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3340531.3411903</idno>
					<note>ACM Reference Format: 1 . 2020. Enhancing Graph Neural Network-based Fraud Detectors against Camouflaged Fraudsters. In Proceedings of the 29th ACM International ACM ISBN 978-1-4503-6859-9/20/10. . . $15.00 Conference on Information and Knowledge Management (CIKM &apos;20), October 19-23, 2020, Virtual Event, Ireland. ACM, New York, NY, USA, 10 pages.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Graph Neural Networks</term>
					<term>Fraud Detection</term>
					<term>Reinforcement Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph Neural Networks (GNNs) have been widely applied to fraud detection problems in recent years, revealing the suspiciousness of nodes by aggregating their neighborhood information via different relations. However, few prior works have noticed the camouflage behavior of fraudsters, which could hamper the performance of GNNbased fraud detectors during the aggregation process. In this paper, we introduce two types of camouflages based on recent empirical studies, i.e., the feature camouflage and the relation camouflage. Existing GNNs have not addressed these two camouflages, which results in their poor performance in fraud detection problems. Alternatively, we propose a new model named CAmouflage-REsistant GNN (CARE-GNN), to enhance the GNN aggregation process with three unique modules against camouflages. Concretely, we first devise a label-aware similarity measure to find informative neighboring nodes. Then, we leverage reinforcement learning (RL) to find the optimal amounts of neighbors to be selected. Finally, the selected neighbors across different relations are aggregated together. Comprehensive experiments on two real-world fraud datasets demonstrate the effectiveness of the RL algorithm. The proposed CARE-GNN also outperforms state-of-the-art GNNs and GNN-based fraud detectors. We integrate all GNN-based fraud detectors as an opensource toolbox 1 . The CARE-GNN code and datasets are available at https://github.com/YingtongDou/CARE-GNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Security and privacy ? Web application security; ? Computing methodologies ? Neural networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>As Internet services thrive, they also incubate various kinds of fraudulent activities <ref type="bibr" target="#b13">[14]</ref>. Fraudsters disguise as regular users to bypass the anti-fraud system and disperse disinformation <ref type="bibr" target="#b43">[44]</ref> or reap end-users' privacy <ref type="bibr" target="#b31">[32]</ref>. To detect those fraudulent activities, graph-based methods have become an effective approach in both academic <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b37">38]</ref> and industrial communities <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b49">50]</ref>. Graphbased methods connect entities with different relations and reveal the suspiciousness of these entities at the graph level, since fraudsters with the same goal tend to connect with each other <ref type="bibr" target="#b0">[1]</ref>.</p><p>Recently, as the development of Graph Neural Networks (GNNs) (e.g., GCN <ref type="bibr" target="#b16">[17]</ref>, GAT <ref type="bibr" target="#b33">[34]</ref>, and GraphSAGE <ref type="bibr" target="#b11">[12]</ref>), many GNN-based fraud detectors have been proposed to detect opinion fraud <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b38">39]</ref>, financial fraud <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b36">37]</ref>, mobile fraud <ref type="bibr" target="#b40">[41]</ref>, and cyber criminal <ref type="bibr" target="#b47">[48]</ref>. In contrast to traditional graph-based approaches, GNN-based methods aggregate neighborhood information to learn the representation of a center node with neural modules. They can be trained in an end-to-end and semi-supervised fashion, which saves much feature engineering and data annotation cost.</p><p>However, existing GNN-based fraud detection works only apply GNNs in a narrow scope while ignoring the camouflage behaviors of fraudsters, which have been drawing great attention from both researchers <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b48">49]</ref> and practitioners <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b40">41]</ref>. Meanwhile, theoretical studies prove the limitations and vulnerabilities of GNNs when graphs have noisy nodes and edges <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b32">33]</ref>. Therefore, failing to tackle the camouflaged fraudsters would sabotage the performance of GNN-based fraud detectors. Though some recent works <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b40">41]</ref> have noticed similar challenges, their solutions either fail to fit the fraud detection problems or break the end-to-end learning fashion of GNNs.</p><p>To demonstrate the challenges induced by camouflaged fraudsters during the neighbor aggregation of GNNs, as shown in <ref type="figure">Figure 1</ref>, we construct a graph with two relations and two types of entities. The relation can be any common attributes supposing to be shared by similar entities (e.g., the User-IP-User relation connects entities with the same IP address). There are two types of camouflages as follows: 1) Feature camouflage: smart fraudsters may adjust their behaviors <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref>, add special characters in reviews <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b40">41]</ref> (so-called spamouflage), or employ deep language generation models <ref type="bibr" target="#b14">[15]</ref> to gloss over explicit suspicious outcomes. Like <ref type="figure">Figure 1</ref> shows, a fraudster can add some special characters to a fake review, which helps to bypass feature-based detectors <ref type="bibr" target="#b40">[41]</ref>. <ref type="bibr" target="#b1">2)</ref> arXiv:2008.08692v1 [cs.SI] <ref type="bibr" target="#b18">19</ref> Aug 2020</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Click this l1nk to win 200</head><p>Relation I Relation II Fraudster Benign User <ref type="figure">Figure 1</ref>: Two types of fraudster camouflage. (1) Feature camouflage: fraudsters add special characters to the text and make it delusive for feature-based spam detectors. (2) Relation camouflage: center fraudster connects to many benign entities under Relation II to attenuate its suspiciousness.</p><p>Relation camouflage: previous works <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b48">49]</ref> show that crowd workers are actively committing opinion fraud on online social networks. They can probe the graphs used by defenders <ref type="bibr" target="#b42">[43]</ref> and adjust their behavior to alleviate the suspiciousness <ref type="bibr" target="#b43">[44]</ref>. Specifically, these crafty fraudsters camouflage themselves via connecting to many benign entities (i.e., posting regular reviews or connecting to reputable users). As <ref type="figure">Figure 1</ref> shows, under Relation II, there are more benign entities than fraudsters.</p><p>Directly applying GNNs to graphs with camouflaged fraudsters will hamper the neighbor aggregation process of GNNs. As <ref type="figure">Figure 1</ref> shows, if we aggregate neighbors with the intriguing reviews as node features, it will probably smooth out the suspiciousness of the center fraudster <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25]</ref>. Similarly, if we aggregate all neighbors under Relation II, where there are more dissimilar neighbors, it will eliminate the suspiciousness of the center fraudster.</p><p>Considering the agility of real-world fraudsters <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref>, designing GNN-based detectors that exactly capture these camouflaged fraudsters is impractical. Therefore, based on the outcomes of two camouflages and the aggregation process of GNNs, we propose three neural modules to enhance the GNNs against the camouflages. 1) For the feature camouflage, we propose a label-aware similarity measure to find the most similar neighbors based on node features. Specifically, we design a neural classifier as a similarity measure, which is directly optimized according to experts with domain knowledge (i.e., annotated data). 2) For the relation camouflage, we devise a similarity-aware neighbor selector to select the similar neighbors of a center node within a relation. Furthermore, we leverage reinforcement learning (RL) to adaptively find the optimal neighbor selection threshold along with the GNN training process. 3) We utilize the neighbor filtering thresholds learned by RL to formulate a relation-aware neighbor aggregator which combines neighborhood information from different relations and obtains the final center node representation.</p><p>We integrate above three modules together with general GNN frameworks and name our model as CAmouflage REsistant Graph Neural Network (CARE-GNN). Experimental results on two realworld fraud datasets demonstrate that our model boosts the GNN performance on graphs with camouflaged fraudsters. The proposed neighbor selector can find optimal neighbors and CARE-GNN outperforms state-of-the-art baselines under various settings. Edge set under relation r at the l-th layer</p><formula xml:id="formula_0">h (l ) v</formula><p>The embedding of node v at the l-th layer</p><formula xml:id="formula_1">h (l ) v,r</formula><p>The embedding of node v under relation r at the l-th layer</p><formula xml:id="formula_2">D (l ) (v, v ? )</formula><p>The distance between node v and v ? at the l-th layer</p><formula xml:id="formula_3">S (l ) (v, v ? )</formula><p>The similarity between node v and v ? at the l-th layer p (l ) r ? P The filtering threshold for relation r at the l-th layer a We highlight the advantages of CARE-GNN as follows:</p><p>? Adaptability. CARE-GNN adaptively selects best neighbors for aggregation given arbitrary multi-relation graph. ? High-efficiency. CARE-GNN has a high computational efficiency without attention and deep reinforcement learning. ? Flexibility. Many other neural modules and external knowledge can be plugged into the CARE-GNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM DEFINITION</head><p>In this section, we first define the multi-relation graph and the graph-based fraud detection problem. Then, we introduce how to apply GNN to fraud detection problems. All important notations in this paper are summarized in <ref type="table" target="#tab_0">Table 1</ref>.</p><formula xml:id="formula_4">Definition 2.1. Multi-relation Graph.</formula><p>We define a multi-relation graph as G = V, X, {E r }| R r =1 , Y , where V is the set of nodes {v 1 , . . . , v n }. Each node v i has a d-dimensional feature vector x i ? R d and X = {x 1 , . . . , x n } represents a set of all node features. e r i, j = (v i , v j ) ? E r is an edge between v i and v j with a relation r ? {1, ? ? ? , R}. Note that an edge can be associated with multiple relations and there are R different types of relations. Y is the a set of labels for each node in V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2.2. Fraud Detection on Graph.</head><p>For the fraud detection problem, the node v represents the target entity whose suspiciousness needs to be justified. For example, it can be a review on the review website <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b28">29]</ref> or a transaction in the trading system <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b36">37]</ref>. The node has a label y v ? {0, 1} ? Y where 0 represents benign and 1 represents suspicious. The relations R are rules, interactions, or shared attributes between nodes, e.g., two reviews from the same user <ref type="bibr" target="#b24">[25]</ref> or transactions from the same devices <ref type="bibr" target="#b23">[24]</ref>. The graph-based fraud detection problem is a semi-supervised binary node classification problem on the graph. Graph-based fraud detectors are trained based on the labeled node information along with the graph composed of multi-relations. The trained models are then used to predict the suspiciousness of unlabeled nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 2.3. GNN-based Fraud Detection. A Graph Neural</head><p>Network (GNN) is a deep learning framework to embed graphstructured data via aggregating the information from its neighboring nodes <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b33">34]</ref>. Based on the defined multi-relation graph in Definition 2.2, we unify the formulation of GNNs from the perspective of neighbor aggregation (as shown in the left side of <ref type="figure" target="#fig_1">Figure 2</ref>):</p><formula xml:id="formula_5">h (l ) v = ? h (l ?1) v ? AGG (l ) {h (l ?1) v ? ,r : (v, v ? ) ? E (l ) r }| R r =1 . (1)</formula><p>For a center node v, h v ? ,r is the embedding of neighboring node v ? under relation r . AGG represents the aggregation function that mapping the neighborhood information from different relations into a vector, e.g., mean aggregation <ref type="bibr" target="#b11">[12]</ref> and attention aggregation <ref type="bibr" target="#b33">[34]</ref>. ? is the operator that combines the information of v and its neighboring information, e.g., concatenation or summation <ref type="bibr" target="#b11">[12]</ref>.</p><p>For fraud detection problems, we first construct a multi-relation graph based on domain knowledge. Then, the GNN is trained with partially labeled nodes supervised by binary classification loss functions. Instead of directly aggregating the neighbors for all relations, we separate the aggregation part as intra-relation aggregation and inter-relation aggregation process. During the intra-relation aggregation process, the embedding of neighbors under each relation is aggregated simultaneously. Then, the embeddings for each relation are combined during the inter-relation aggregation process. Finally, the node embeddings at the last layer are used for prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROPOSED MODEL 3.1 Model Overview</head><p>The proposed CARE-GNN has three neural modules and its pipeline is shown in <ref type="figure" target="#fig_1">Figure 2</ref>. For a center node v, we first compute its neighbor similarities based with proposed label-aware similarity measure (Section 3.2). Then we filter the dissimilar neighbors under each relation with the proposed neighbor selector (Section 3.3). The neighbor selector is optimized using reinforcement learning during training the GNN (purple module in <ref type="figure" target="#fig_1">Figure 2</ref>). At the aggregation step, we first use the intra-relation aggregator to aggregate neighbor embeddings under each relation. Then, we combine embeddings across different relations with the inter-relation aggregator (Section 3.4). The optimization steps and the algorithm procedure are presented in Section 3.5 and Algorithm 1, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Label-aware Similarity Measure</head><p>Previous studies have introduced various fraudster camouflage types from behavior <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref> and semantic <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b40">41]</ref> perspectives. Those camouflages could make the features of fraudsters and benign entities similar to each other, and further mislead GNNs to generate uninformative node embeddings. To tackle those node feature camouflages, we deem that an effective similarity measure is needed to filter the camouflaged neighbors before applying GNNs. Previous works have proposed unsupervised similarity metrics like Cosine Similarity <ref type="bibr" target="#b24">[25]</ref> or Neural Networks <ref type="bibr" target="#b44">[45]</ref>. However, many fraud problems like financial fraud and opinion fraud require extra domain knowledge to identify fraud instances. For example, in opinion fraud, unsupervised similarity measures could not identify the camouflaged fake reviews, which are even indistinguishable by humans <ref type="bibr" target="#b14">[15]</ref>. Therefore, we need a parameterized similarity measure to compute node similarity with supervised signals from domain experts (e.g., high-fidelity data annotations).</p><p>For the parameterized similarity measure, AGCN [20] employs a Mahalanobis distance plus a Gaussian kernel, and DIAL-GNN <ref type="bibr" target="#b5">[6]</ref> uses the parameterized cosine similarity. However, those two types of measures suffer from high time complexity O(|V |Dd), whereD is the average degree of nodes which is extremely high in real-world graphs (see <ref type="table" target="#tab_2">Table 2</ref>) and d is the feature dimension.</p><p>Label-aware Similarity Measure. Inspired by LAGCN <ref type="bibr" target="#b3">[4]</ref> which uses a Multi-layer Perceptron (MLP) as the edge label predictor, we employ a one-layer MLP as the node label predictor at each layer and use the l 1 -distance between the prediction results of two nodes as their similarity measure. For a center node v under relation r at the l-th layer and edge (v, v ? ) ? E (l ?1) r , the distance between v and v ? is the l 1 -distance of two embeddings:</p><formula xml:id="formula_6">D (l ) (v, v ? ) = ? MLP (l ) (h (l ?1) v ) ? ? MLP (l ) (h (l ?1) v ? ) 1 ,<label>(2)</label></formula><p>and we can define the similarity measure as:</p><formula xml:id="formula_7">S (l ) (v, v ? ) = 1 ? D (l ) (v, v ? ),<label>(3)</label></formula><p>where each layer has its own similarity measure. The input of MLP at the l-th layer is the node embedding at the previous layer, and the output of MLP is a scalar which is then fed into a nonlinear activation function ? (we use tanh in our work). To save the computational cost, we only take the embedding of the node itself as the input instead of using combined embeddings like the LAGCN <ref type="bibr" target="#b3">[4]</ref>. Therefore, taking the S</p><formula xml:id="formula_8">(1) r (v, v ? )</formula><p>as an example where the input is the raw feature, the time complexity of the proposed similarity measure reduces significantly from O(|V |Dd) to O(|V |d) since it predicts the node label solely based on its feature.</p><p>Optimization. To train the similarity measure together with GNNs, a heuristic approach is to append it as a new layer before the aggregation layer of GCN <ref type="bibr" target="#b19">[20]</ref>. However, if the similarity measure could not effectively filter the camouflaged neighbors at the first layer, it will hamper the performance of following GNN layers. Consequently, the MLP parameters cannot be well-updated through the back-propagation process. To train the similar measure with a direct supervised signal from labels, like <ref type="bibr" target="#b34">[35]</ref>, we define the cross-entropy loss of the MLP at l-layer as:</p><formula xml:id="formula_9">L (l ) Simi = v ?V ? log y v ? ? MLP (l ) (h (l ) v ) .<label>(4)</label></formula><p>During the training process, the similarity measure parameters are directly updated through the above loss function. It guarantees similar neighbors can be quickly selected within the first few batches and help regularize the GNN training process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Similarity-aware Neighbor Selector</head><p>Given the similarity scores between the center node and its neighbors with Eq.</p><p>(3), we should select similar neighbors (i.e., filter camouflaged ones) to improve the capability of GNNs. According to the relation camouflage, fraudsters may connect to different amounts of benign entities under different relations <ref type="bibr" target="#b43">[44]</ref>. However, since data annotation is costly for real-world fraud detection problems, computing the number of similar neighbors under each relation through data labeling is impossible. We should devise an adaptive filtering/sampling criteria to select an optimal amount of similar neighbors automatically. Thus, we design a similarity-aware neighbor selector. It selects similar neighbors under each relation using top-p sampling with an adaptive filtering threshold. We also devise a reinforcement learning (RL) algorithm to find optimal thresholds during the GNN training process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Top-p Sampling.</head><p>We employ top-p sampling to filter camouflaged neighbors under each relation. The filtering threshold for relation r at the l-th layer is p</p><formula xml:id="formula_10">(l ) r ? [0, 1].</formula><p>The closed interval means we could discard or keep all neighbors of a node under a relation. Specifically, during the training phase, for a node v in current batch under relation r , we first compute a set of similarity scores</p><formula xml:id="formula_11">{S (l ) (v, v ? )} using Eq. (3) at the l-th layer where (v, v ? ) ? E (l ) r . E (l ) r</formula><p>is a set of edges under relation r at the l-th layer. Then we rank its neighbors based on {S (l ) (v, v ? )} in descending order and take the first p (l ) r ? |{S (l ) (v, v ? )}| neighbors as the selected neighbors at the l-th layer. All other nodes are discarded at the current batch and will not attend the aggregation process. The top-p sampling process is applied to the center node at every layer for each relation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.3.2</head><p>Finding the Optimal Thresholds with RL. Previous works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b24">25]</ref> set the filtering threshold as a hyperparameter and tune it with validation to find the optimal value. However, their models are built upon homogeneous benchmark graphs, and without noise induced by camouflaged fraudsters. However, owing to the multi-relation graph of fraud problems as well as the relation camouflage problem, we need an automatic approach to find the optimal threshold p (l ) r for each relation. Since p (l ) r is a probability and has no gradient, we cannot use back-propagation from the classification loss to update it. Meanwhile, given a p (l ) r , it is infeasible to estimate the quality of selected neighbors solely based on the similarity scores under the current batch/epoch. To overcome the above challenges, we propose to employ a reinforcement learning (RL) framework to find optimal thresholds.</p><p>Concretely, we formulate the RL process as a Bernoulli Multiarmed Bandit (BMAB) B(A, f ,T ) between the neighbor selector and the GNN with the similarity measure. A is the action space, f is the reward function, and T is the terminal condition <ref type="bibr" target="#b35">[36]</ref>. Given an initial p (l ) r , the neighbor selector choose to increase or decrease p (l ) r as actions and the reward is dependent on the average distance differences between two consecutive epochs. Next, we introduce the details of each BMAB component: r is expected to find the most similar (i.e., minimum distances in Eq. (2)) neighbors of a center node under relation r at the l-th layer. We cannot sense the state of GNN due to its black-box nature; thus, we design a binary stochastic reward solely based on the average distance differences between two consecutive epochs. The average neighbor distances for relation r at the l-th layer for epoch e is:</p><formula xml:id="formula_12">G(D (l ) r ) (e) = v ?V t r ain D (l ) r (v, v ? ) (e) |V t r ain | .<label>(5)</label></formula><p>Then, we can define the reward for epoch e as:</p><formula xml:id="formula_13">f (p (l ) r , a (l ) r ) (e) = +1, G(D (l ) r ) (e?1) ? G(D (l ) r ) (e) ? 0, ?1, G(D (l ) r ) (e?1) ? G(D (l ) r ) (e) &lt; 0. (6)</formula><p>The reward is positive when the average distance of newly selected neighbors at epoch e is less than that of the previous epoch, and vice versa. It is not easy to estimate the cumulative reward. Thus, we use the immediate reward to update the action greedily without exploration. Concretely, we increase p (l ) r with a positive reward and decrease it vice versa.</p><p>? Terminal. We define the terminal condition for RL as:</p><formula xml:id="formula_14">e e?10 f (p (l ) r , a (l ) r ) (e) ? 2, where e ? 10.<label>(7)</label></formula><p>It means that the RL converges in the recent ten epochs and indicates an optimal threshold p (l ) r is discovered. After the RL module terminates, the filtering thresholds are fixed as the optimal one until the convergence of GNN.</p><p>Discussion. Different node classes may have different amounts of similar neighbors under the same relation. For instance, as <ref type="table" target="#tab_2">Table 2</ref> shows, under the R-S-R relation of the Yelp dataset, for positive nodes, only 5% of their neighbors have the same label. This is due to the class-imbalance nature of fraud problems and the relation camouflage of fraudsters. According to the cost-sensitive learning research <ref type="bibr" target="#b29">[30]</ref>, misclassifying a fraudster has a much higher cost to defenders than misclassifying a benign entity. Meanwhile, a large number of benign entities already fuel sufficient information for the classifier. Therefore, to accelerate the training process, we compute the filtering thresholds by only considering positive center nodes (i.e., fraudsters) and apply them for all node classes. The complete RL process is shown in Lines 15-19 of Algorithm 1. The experiment results in Section 4.4 verify the RL effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Relation-aware Neighbor Aggregator</head><p>After filtering neighbors under each relation, the next step is to aggregate the neighbor information from different relations. Previous methods adopt attention mechanism <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b47">48]</ref> or devise weighting parameters <ref type="bibr" target="#b23">[24]</ref> to learn the relation weights during aggregating information from different relations. However, supposing we have selected the most similar neighbors under each relation, the attention coefficients or weighting parameters should be similar among different relations. Thus, to save the computational cost while retaining the relation importance information, we directly apply the optimal filtering threshold p (l ) r learned by the RL process as the inter-relation aggregation weights. Formally, under relation r at the l-th layer, after applying the top-p sampling, for node v, we define the intra-relation neighbor aggregation as follows:</p><formula xml:id="formula_15">h (l ) v,r = ReLU AGG (l ) r h (l ?1) v ? : (v, v ? ) ? E (l ) r ,<label>(8)</label></formula><p>where a mean aggregator is used for all AGG (l ) r . Then, we define the inter-relation aggregation as follows:</p><formula xml:id="formula_16">h (l ) v = ReLU AGG (l ) all h (l ?1) v ? {p (l ) r ? h (l ) v,r }| R r =1 ,<label>(9)</label></formula><p>where h</p><formula xml:id="formula_17">(l ?1) v</formula><p>is the center node embedding at the previous layer,</p><formula xml:id="formula_18">h (l )</formula><p>v,r is the intra-relation neighbor embedding at the l-th layer and p (l ) r is filtering threshold of relation r which is directly used as its inter-relation aggregation weight. ? denotes the embedding summation operation. AGG l all can be any type of aggregator, and we test them in Section 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Proposed CARE-GNN</head><p>Optimization. For each node v, its final embedding is the output of the GNN at the last layer z v = h (L) v . We can define the loss of GNN as a cross-entropy loss function:</p><formula xml:id="formula_19">L GNN = v ?V ? log (y v ? ? (MLP(z v ))) .<label>(10)</label></formula><p>Together with the loss function of the similarity measure in Eq. (4), we define the loss of CARE-GNN as:</p><formula xml:id="formula_20">L CARE = L GNN + ? 1 L (1) Simi + ? 2 ||?|| 2 ,<label>(11)</label></formula><p>where ||?|| 2 is the L2-norm of all model parameters, ? 1 and ? 2 are weighting parameters. Since the neighbor filtering process at the first layer is critical to both GNN and similarity measures in the following layers, we only use the similarity measure loss at the first layer to update the parameterized similarity measure in Eq. (3).</p><p>Algorithm Description. Algorithm 1 shows the training process of the proposed CARE-GNN. Given a multi-relational fraud graph, we employ the mini-batch training technique <ref type="bibr" target="#b10">[11]</ref> as the result of its large scale. In the beginning, we randomly initialize the parameters of the similarity measure module and GNN module. We initialize all filtering thresholds as 0.5 (Line 2). For each batch of nodes, we first compute the neighbor similarities using Eq. for l = 1, ? ? ? , L do 6 for r = 1, ? ? ? , R do 7 </p><formula xml:id="formula_21">S (l ) (v, v ? ) ? Eq. (3) , ?(v, v ? ) ? E (l ?1) r ; 8 E (l ) r ? top-p sampling (Section 3.3.1); 9 h (l ) v,r ? Eq. (8) ?v ? V b ; // Intra-R AGG 10 h (l ) v ? Eq. (9) ?v ? V b ; // Inter-R AGG 11 L (1) Simi ? Eq. (4); // Simi loss 12 z v ? h (L) v , ?v ? V b ; // Batch</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In the experiment section, we mainly present:</p><p>? how we construct multi-relation graphs upon different fraud data (Section 4.   <ref type="bibr" target="#b28">[29]</ref> and Amazon review dataset <ref type="bibr" target="#b25">[26]</ref> to study the fraudster camouflage and GNNbased fraud detection problem. The Yelp dataset includes hotel and restaurant reviews filtered (spam) and recommended (legitimate) by Yelp. The Amazon dataset includes product reviews under the Musical Instruments category. Similar to <ref type="bibr" target="#b46">[47]</ref>, we label users with more than 80% helpful votes as benign entities and users with less than 20% helpful votes as fraudulent entities. Though previous works have proposed other fraud datasets like Epinions <ref type="bibr" target="#b17">[18]</ref> and Bitcoin <ref type="bibr" target="#b39">[40]</ref>, they only contain graph structures and compacted features, with which we cannot build meaningful multi-relation graphs. In this paper, we conduct a spam review detection (fraudulent user detection resp.) task on the Yelp dataset (Amazon dataset resp.), which is a binary classification task. We take 32 handcrafted features from <ref type="bibr" target="#b28">[29]</ref> (25 handcrafted features from <ref type="bibr" target="#b46">[47]</ref> resp.) as the raw node features for Yelp (Amazon resp.) dataset. <ref type="table" target="#tab_2">Table 2</ref> shows the dataset statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Graph Construction.</head><p>Yelp: based on previous studies <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b28">29]</ref> which show that opinion fraudsters have connections in user, product, review text, and time, we take reviews as nodes in the graph and design three relations: 1) R-U-R: it connects reviews posted by the same user; 2) R-S-R: it connects reviews under the same product with the same star rating (1-5 stars); 3) R-T-R: it connects two reviews under the same product posted in the same month. Amazon: similarly, we take users as nodes in the graph and design three relations: 1) U-P-U : it connects users reviewing at least one same product; 2) U-S-V : it connects users having at least one same star rating within one week; 3) U-V-U : it connects users with top 5% mutual review text similarities (measured by TF-IDF) among all users. The number of edges belonging to each relation is shown in <ref type="table" target="#tab_2">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Baselines.</head><p>To verify the ability of CARE-GNN in alleviating the negative influence induced by camouflaged fraudsters, we compare it with various GNN baselines under the semi-supervised learning setting. We select GCN <ref type="bibr" target="#b16">[17]</ref>, GAT <ref type="bibr" target="#b33">[34]</ref>, RGCN <ref type="bibr" target="#b30">[31]</ref>, and GraphSAGE <ref type="bibr" target="#b11">[12]</ref> to represent general GNN models. We choose Ge-niePath <ref type="bibr" target="#b22">[23]</ref>, Player2Vec <ref type="bibr" target="#b47">[48]</ref>, SemiGNN <ref type="bibr" target="#b36">[37]</ref>, and GraphConsis <ref type="bibr" target="#b24">[25]</ref> as four state-of-the-art GNN-based fraud detectors. Their detailed introduction can be found in Section 5. We also implement several variants of CARE-GNN: CARE-Att, CARE-Weight, and CARE-Mean, and they differ from each other in Attention <ref type="bibr" target="#b33">[34]</ref>, Weight <ref type="bibr" target="#b23">[24]</ref>, and Mean <ref type="bibr" target="#b11">[12]</ref> inter-relation aggregator respectively. Among those baselines, GCN, GAT, GraphSAGE, and GeniePath are run on homogeneous graphs (i.e., Relation ALL in <ref type="table" target="#tab_2">Table 2</ref>) where all relations are merged together. Other models are run on multi-relation graphs where they handle information from different relations in their approaches. <ref type="table" target="#tab_2">Table 2</ref>, we can see that the percentage of fraudsters are small in both datasets. Meanwhile, realworld graphs usually have great scales. To improve the training efficiency and avoid overfitting, we employ mini-batch training <ref type="bibr" target="#b10">[11]</ref> and under-sampling <ref type="bibr" target="#b21">[22]</ref> techniques to train CARE-GNN and other baselines. Specifically, under each mini-batch, we randomly sample the same number of negative instances as the number of positive instances. We also study the sample ratio sensitivity in Section 4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.4">Experimental Setting. From</head><p>We use unified node embedding size (64), batch size (1024 for Yelp, 256 for Amazon), number of layers(1), learning rate (0.01), optimizer (Adam), and L2 regularization weight (? 2 = 0.001) for all models. For CARE-GNN and its variants, we set the RL action step size (? ) as 0.02 and the similarity loss weight (? 1 ) as 2. In Section 4.5, we present the sensitivity study for the number of layers, embedding size, and ? 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.5">Implementation.</head><p>For the GCN, GAT, RGCN, GraphSAGE, Ge-niePath, we use the source code provided by authors. For Player2Vec, SemiGNN, and GraphConsis, we use the open-source implementations 2 . We implement CARE-GNN with Pytorch. All models are running on Python 3.7.3, 2 NVIDIA GTX 1080 Ti GPUs, 64GB RAM, 3.50GHz Intel Core i5 Linux desktop.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.6">Evaluation Metric.</head><p>Since the Yelp dataset has imbalanced classes, and we focus more on fraudsters (positive instances), like previous work <ref type="bibr" target="#b28">[29]</ref>, we utilize ROC-AUC (AUC) and Recall to evaluate the overall performance of all classifiers. AUC is computed based on the relative ranking of prediction probabilities of all instances, which could eliminate the influence of imbalanced classes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Camouflage Evidence</head><p>We analyze fraudster camouflage using two metrics introduced in <ref type="bibr" target="#b24">[25]</ref>. For the feature camouflage, we compute the feature similarity of neighboring nodes based on their feature vectors' Euclidean distance, ranging from 0 to 1. The average feature similarity is normalized w.r.t. the total number of edges, which is presented in <ref type="table" target="#tab_2">Table 2</ref>. We observe that the averaged similarity scores under all relations are high. High feature similarity implies that fraudsters camouflage their features in a similar way to benign nodes. Moreover, the minor feature similarity difference across different relations proves that the unsupervised similarity measure cannot effectively discriminate fraudsters and benign entities. For instance, the label similarity difference between R-U-R and R-T-R is 0.85, but the feature similarity difference is only 0.04. For the relation camouflage, we study it by calculating the label similarity based on whether two connected nodes have the same label. The label similarity is normalized w.r.t. the total number of edges. The average label similarity for each relation is shown in <ref type="table" target="#tab_2">Table 2</ref>. High label similarity score implies that the fraudsters fail to camouflage, and low score implies that fraudsters camouflage successfully. We observe that only R-U-R relation has a high label similarity score, while the other relations have label similarity scores less than 20%. It suggests that we need to select different amounts of neighbors for different relations to facilitate the GNN aggregation process. Meanwhile, we should distinguish relations in order to prevent fraudsters from camouflaging. <ref type="table" target="#tab_3">Table 3</ref> shows the performance of proposed CARE-GNN and various GNN baselines under the fraud detection task on two datasets. We report the best testing results after thirty epochs. We observe that CARE-GNN outperforms other baselines under most of the training proportions and metrics. <ref type="table" target="#tab_3">Table 3</ref>, GCN, GAT, GraphSAGE, and GeniePath run on singlerelation (i.e., homogeneous) graph where all relations are merged together (ALL in <ref type="table" target="#tab_2">Table 2</ref>). Other baselines are built upon multirelation graphs. The performances of single-relation GNNs are better than Player2Vec and SemiGNN, which indicates previously designed fraud detection methods are not suitable for multi-relation graphs. Among the multi-relation GNNs, GraphConsis outperforms all other multi-relation GNNs. The reason is that GraphConsis samples the neighbors based on the node features before aggregating them. Better than GraphConsis, CARE-GNN and its variants adopt parameterized similarity measure and adaptive sampling thresholds, which could better identify and filter camouflaged fraudsters. It demonstrates that neighbor filtering is critical to GNNs when the graph contains many noises (i.e., dissimilar/camouflaged neighbors). Also, CARE-GNN has higher scores than all single-relation GNNs, suggesting that a noisy graph undermines the performance of multi-relation GNNs. A possible reason is the higher complexity of multi-relation GNNs comparing to single-relation ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Overall Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Single-relation vs. Multi-relation. Among all GNN baselines in</head><p>Training Percentage. From <ref type="table" target="#tab_3">Table 3</ref>, there is little performance gain for GNNs when increasing the training percentages. It demonstrates the advantage of semi-supervised learning, where a small amount of supervised signals is enough to train a good model. Meanwhile, with informative handcraft features as inputs for two datasets, GNNs are much easier to learn high-quality embeddings. <ref type="table" target="#tab_3">Table 3</ref> show the performance of CARE-GNN and its variants with different interrelation aggregators. It is observed that those four models have similar performances under most training percentages and metrics. It verifies our assumption in Section 3.4 that the attention coefficients and relation weights will become unnecessary when we select similar neighbors under all relations. Moreover, for the Yelp dataset, the CARE-Att has worse performances under a smaller training percentage (e.g., 5%). While for CARE-GNN, since it does not need to train extra attention weights, it attains the best performance against other variants. The first column of <ref type="figure" target="#fig_6">Figure 3</ref> presents more evidence that the relation weights finally become equal for all relations under both datasets. The better performance of CARE-GNN comparing to CARE-Mean shows that keeping the filtering threshold as inter-relation aggregation weights could enhance the GNN performance and reduce model complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CARE-GNN Variants. The last four columns of</head><p>GNN vs. Similarity Measure <ref type="figure" target="#fig_6">(Figure 3</ref> Column 4). <ref type="figure" target="#fig_6">Figure 3</ref> Column 4 shows the testing performances solely based on the outputs of the GNN module and similarity measure module during training. For the Yelp dataset, GNN has better AUC and Recall than the similarity measure, which suggests that leveraging the structural information benefits the model to classify fraud and benign entities. For Amazon, the performance of GNN and the similarity measure are comparable with each other. It is because the input features provide enough information to discriminate fraudsters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">RL Process Analysis</head><p>In this paper, we jointly train the similarity measure and GNN together and employ RL to find the neighbor filtering thresholds adaptively. To present the RL process from different perspectives, in <ref type="figure" target="#fig_6">Figure 3</ref>, we plot the updating process of three parameters without terminating the RL process during training CARE-Weight. Since CARE-Weight learns the aggregation weight for each relation, plotting its training process instead of CARE-GNN could help understand the effects of our proposed GNN enhancement modules. During training, we also test the model every three epochs for Yelp (four epochs for Amazon) and plot the testing performance for both GNN and similarity measure at the last column of <ref type="figure" target="#fig_6">Figure 3</ref>.</p><p>Relation Weights <ref type="figure" target="#fig_6">(Figure 3</ref> Column 1). We observe that the randomly initialized relation aggregation weights gradually converge to the same value as the neighbor selector updates its filtering thresholds and selects more similar neighbors under each relation.</p><p>When neighbors under each relation provide similar information, their aggregation weights will be similar as well.</p><p>Relation Distance <ref type="figure" target="#fig_6">(Figure 3</ref> Column 2). As the training epoch increases, it is clearly that the differences between neighbor distances under each relation (computed by Eq. <ref type="formula" target="#formula_12">(5)</ref>) become larger and comparable to each other. The reason is that the GNN projects the node embeddings to a broader range of space and makes them more distinguishable. As the model filters more noisy neighbors, the average distance across different relations become closer.</p><p>Neighbor Filtering Threshold <ref type="figure" target="#fig_6">(Figure 3</ref> Column 3). We take 0.02 as the action step size; all thresholds are updated and converge to different values. When the filtering threshold oscillates for several rounds, it reaches the terminal condition in Eq. <ref type="bibr" target="#b6">(7)</ref>. For different datasets, the proposed RL algorithm could adaptively find the optimal filtering thresholds. To demonstrate the advantage of the optimal neighbor filtering thresholds found by RL, in <ref type="figure" target="#fig_7">Figure 4</ref>, we plot the testing performances of three different neighbor selection criteria under two datasets. Adaptive filters neighbors using converged thresholds found by RL (as shown in <ref type="figure" target="#fig_6">Figure 3</ref> Column 3); Fixed-Half keeps the top 50% similar neighbors under each relation and Fixed-All keeps all neighbors without filtering. It is illustrated that CARE-GNN with adaptive filtering thresholds is optimized faster than the other two neighbor selectors. Meanwhile, it has a better and smoother performance during training. It verifies the effectiveness of the proposed RL algorithm, which is able to find informative neighbors under each relation. <ref type="figure" target="#fig_9">Figure 5</ref> shows the testing performance of CARE-GNN regarding four hyper-parameters on the Yelp dataset. From <ref type="figure" target="#fig_9">Figure 5</ref>(a), we observe that increasing the number of layers barely improves the performance of CARE-GNN. For the three-layer model, the CARE-GNN suffers the overfitting problem (Recall = 0.5). Therefore, the one-layer model is not only able to save the computational cost but also achieve better classification results. <ref type="figure" target="#fig_9">Figure 5</ref>  <ref type="figure" target="#fig_9">Figure 5(c)</ref> shows the influence of different embedding sizes. Embedding sizes with 16, 32, and 64 have comparable performance. <ref type="figure" target="#fig_9">Figure 5(d)</ref> illustrates the effects of different weighting values for the similarity loss (? 1 in Eq. <ref type="formula" target="#formula_20">(11)</ref>). When the weight of similarity loss is doubled compared to which of GNN loss, CARE-GNN reaches the best performance. Therefore, the similarity measure is crucial for GNN training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Hyper-parameter Sensitivity</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Discussion</head><p>Since the multi-relation graphs used in the experiments are very dense (average node degree &gt; 150), one-layer CARE-GNN (which aggregates one-hop neighbors) has already utilized abundant information and thus can achieve excellent performance. CARE-GNN with more layers is suitable for sparse graphs. We improve the computational efficiency using multiple approaches: the light-weight similarity measure, the classic and fast RL framework, positive-node based neighbor selector, no attention mechanism, and mini-batch training with under-sampling. For CARE-GNN, each epoch only takes 17 seconds on Yelp (3 seconds on Amazon), and it has a great performance gain comparing to other baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>GNN and Its Enhancement. As the most popular deep learning framework on graph data, GNNs have two major types <ref type="bibr" target="#b41">[42]</ref>: 1) Spectral-based GNNs (GCN <ref type="bibr" target="#b16">[17]</ref>, AGCN <ref type="bibr" target="#b19">[20]</ref>): they turn a graph into a Laplacian matrix and make convolutional operations in the spectral domain. 2) Spatial-based GNNs (GAT <ref type="bibr" target="#b33">[34]</ref>, GraphSAGE <ref type="bibr" target="#b11">[12]</ref>): they propagate the information based on the spatial relation (i.e., the adjacent nodes). Since spatial-based GNNs are more flexible, many GNN variants belong to this type. The proposed CARE-GNN is a spatial-based GNN as well.</p><p>To enhance the GNN performance on graphs with noisy nodes. One approach is the graph structure learning (GSL) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b19">20]</ref>. Those works learn new graph structures from original graphs, which could better render the latent connections between nodes. Comparing to our work, those papers only investigate the single-relation benchmark datasets without camouflaged fraudsters. Our model filters dissimilar neighbors instead of learning new structures. Another approach is the metric learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b12">13]</ref>. Those works devise new metrics to measure the similarity between connect nodes and aggregate neighbors according to the metrics. Among those works, <ref type="bibr" target="#b3">[4]</ref> proposes a neural network to predict the labels of neighboring nodes. <ref type="bibr" target="#b12">[13]</ref> devises two metrics to measure the average neighborhood similarity and label similarity in a graph. However, those methods either have weak similarity metrics or fixed neighbor filtering thresholds, which need to be calibrated empirically. CARE-GNN proposed by us is more flexible which could learn the similarity metric based on domain knowledge. The relation filtering thresholds of CARE-GNN are optimized during training GNN which retains the end-to-end learning fashion.</p><p>GNN sampling methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b50">51]</ref> also filter the neighbors. While these works only consider selecting representative nodes to accelerate GNN training. For our work, taking account of domain knowledge and relational information, our goal is to filter dissimilar neighbors before aggregation, which could alleviate the negative effect of camouflaged fraudsters. GNN-based Fraud Detection. Many GNN-based fraud detectors transfer the heterogeneous data into homogeneous data before applying GNNs. Fdgars <ref type="bibr" target="#b38">[39]</ref> and GraphConsis <ref type="bibr" target="#b24">[25]</ref> construct a single homo-graph based on multiple relations and employ GNNs to aggregate neighborhood information. GeniePath [23] learns convolutional layers and neighbor weights using LSTM and the attention mechanism <ref type="bibr" target="#b33">[34]</ref>. GEM <ref type="bibr" target="#b23">[24]</ref>, SemiGNN <ref type="bibr" target="#b36">[37]</ref>, ASA <ref type="bibr" target="#b40">[41]</ref>, and Player2Vec <ref type="bibr" target="#b47">[48]</ref> all construct multiple homo-graphs based on node relations in corresponding datasets. After aggregating neighborhood information with GNNs on each homo-graph, SemiGNN and Player2Vec adopt attention mechanism to aggregate node embeddings across multiple homo-graphs; while GEM learns weighting parameters for different homo-graphs, and ASA directly sums information from each homo-graph. Player2Vec leverages GCN &amp; GAT to encode the intra-&amp; inter-relation neighbor information. GAS <ref type="bibr" target="#b18">[19]</ref> learns unique aggregators for different node types and updates the embeddings of each node types iteratively.</p><p>In this paper, CARE-GNN constructs multiple homo-graphs with only one node type like GEM and ASA. Among the above works, only two works <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b40">41]</ref> have noticed the camouflage behaviors of fraudsters. While <ref type="bibr" target="#b40">[41]</ref> only crafts new but inflexible features, and <ref type="bibr" target="#b24">[25]</ref> suffers from unsupervised similarity measures and fixed filtering thresholds. CARE-GNN remedies those shortcomings by filtering neighbors based on label-aware similarity measures with adaptive filtering thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>This paper investigates the camouflage behavior of fraudsters and their negative influence on GNN-based fraud detectors. To enhance the GNN-based fraud detectors against the feature camouflage and relation camouflage of fraudsters, we propose a label-aware similarity measure and a similarity-aware neighbor selector using reinforcement learning. Along with two neural modules, we further propose a relation-aware aggregator to maximize the computational utility. Experiment results on real-world fraud datasets present evidence of fraudster camouflage and demonstrate the effectiveness and efficiency of proposed enhancement modules, especially the reinforcement learning module.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>r</head><label></label><figDesc>? A; ? RL action space; Action step size G(D (l ) r ) Average neighbor distances for relation r at the l-th layer f (p (l ) r , a (l ) r ) RL reward function AGG (l ) r Intra-relation aggregator for relation r at the l-th layer AGG (l ) all Inter-relation aggregator at the l-th layer z v Final embedding for node v</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The aggregation process of proposed CARE-GNN at the training phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>v</head><label></label><figDesc>is the hidden embedding at l-th layer and h (0) v = x i is the input feature. E (l ) r denotes edges under relation r at the l-th layer. h (l ?1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>?</head><label></label><figDesc>Action. The action represents how RL updates the p (l ) r based on the reward. Since p (l ) r ? [0, 1], we define the action a (l ) r as plus or minus a fixed small value ? ? [0, 1] from p (l ) r . ? Reward. The optimal p (l )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>r</head><label></label><figDesc>(3) (Line 7) and Algorithm 1: CARE-GNN: Camouflage Resistant GNN. Input : An undirected multi-relation graph with node features and labels: G = V, X, {E r }| R r =1 , Y ; Number of layers, batches, epochs: L, B, E; Parameterized similarity measures: {S (l ) (?, ?)}| L l =1 ; Filtering thresholds: P = {p (l ) 1 , . . . , p (l ) R }| L l =1 ; Intra-R aggregators: {AGG (l ) r }| R r =1 , ?l ? {1, . . . , L}; Inter-R aggregators: {AGG (l ) all }, ?l ? {1, . . . , L}. Output : Vector representations z v , ?v ? V t r ain . 1 // Initialization 2 h 0 v ? x v , ?v ? V; p = E, ?r ? {1, . . . , R}; 3 for e = 1, ? ? ? , E do // Train CARE-GNN 4 for b = 1, ? ? ? , B do 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>1.2); ? camouflage evidences in real-world fraud data (Section 4.2); ? the performance comparison over baselines and CARE-GNN variants (Section 4.3); ? the learning process and explanation of the RL algorithm (Section 4.4); ? the sensitivity study of hyper-parameters and their effects on model designing (Section 4.5).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>The training process and testing performance of CARE-Weight on Yelp (upper) and Amazon (lower) dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>The testing AUC and Recall for CARE-GNN with different neighbor filtering methods during training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>(b) presents the CARE-GNN performance under different under-sampling ratios as introduced in Section 4.1.4. Note that CARE-GNN is tested on an imbalanced test set. Moreover, CARE-GNN is overfitted when negative instances are less than positive ones (under 1:0.2 and 1:0.5, Recalls are equal to 0.5). An equal under-sampling ratio guarantees a good and fair performance of CARE-GNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>Parameter Sensitivity. For each parameter configuration, only the best results among 30 epochs are recorded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Glossary of Notations. Graph; Node set; Edge set; Node feature set y Training epoch number; Total number of epochs V t r ain ; V b Nodes in the training set; Node set at batch b</figDesc><table><row><cell>Symbol Definition</cell></row><row><cell>(l ) G; V; E; X E r</cell></row></table><note>v ; Y Label for node v; Node label set r ; R Relation; Total number of relations l; L GNN layer number; Total number of layers b; B Training batch number; Total number of batches e; E</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>; then filter the neighbors using top-p sampling (Line 8). Then, we can compute the intra-relation embeddings (Line 9), inter-relation embeddings (Line 10), loss functions (Lines 11-14) for the current batch, respectively. As for the RL process, we assign random actions for the first epoch since it has no reference. From the second epoch, we update p</figDesc><table><row><cell>(l )</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>node embeddings</cell></row><row><cell>13</cell><cell cols="5">L GNN ? Eq. (10);</cell><cell>// GNN loss</cell></row><row><cell>14</cell><cell cols="5">L CARE ? Eq. (11);</cell><cell>// CARE-GNN loss</cell></row><row><cell>15</cell><cell cols="3">for l = 1, ? ? ? , L do</cell><cell></cell><cell></cell><cell>// RL Module</cell></row><row><cell>16</cell><cell cols="5">for r = 1, ? ? ? , R do</cell></row><row><cell>17</cell><cell cols="6">if Eq. (7) is False then</cell></row><row><cell>18</cell><cell cols="2">f (p</cell><cell>(l ) r , a</cell><cell cols="3">(l ) r ) (e) ? Eqs.(5) and (6);</cell></row><row><cell>19</cell><cell>p</cell><cell cols="3">(l ) r ? p</cell><cell>(l ) r + f (p</cell><cell>(l ) r , a</cell><cell>(l )</cell></row></table><note>r ) (e) ? ?r according to Lines 15-19.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Dataset and graph statistics.</figDesc><table><row><cell></cell><cell>#Nodes (Fraud%)</cell><cell>Relation</cell><cell>#Edges</cell><cell>Avg. Feature Similarity</cell><cell>Avg. Label Similarity</cell></row><row><cell></cell><cell></cell><cell>R-U-R</cell><cell>49,315</cell><cell>0.83</cell><cell>0.90</cell></row><row><cell>Yelp</cell><cell>45,954 (14.5%)</cell><cell>R-T-R R-S-R</cell><cell>573,616 3,402,743</cell><cell>0.79 0.77</cell><cell>0.05 0.05</cell></row><row><cell></cell><cell></cell><cell>ALL</cell><cell>3,846,979</cell><cell>0.77</cell><cell>0.07</cell></row><row><cell>Amazon</cell><cell>11,944 (9.5%)</cell><cell>U-P-U U-S-U U-V-U ALL</cell><cell>175,608 3,566,479 1,036,737 4,398,392</cell><cell>0.61 0.64 0.71 0.65</cell><cell>0.19 0.04 0.03 0.05</cell></row></table><note>4.1.1 Dataset. We use the Yelp review dataset</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Fraud detection performance (%) on two datasets under different percentage of training data.</figDesc><table><row><cell></cell><cell cols="4">Metric Train% GCN GAT RGCN</cell><cell>Graph-SAGE</cell><cell>Genie-Path</cell><cell>Player-2Vec</cell><cell>Semi-GNN</cell><cell>Graph-Consis</cell><cell>CARE-Att</cell><cell>CARE-Weight</cell><cell>CARE-Mean</cell><cell>CARE-GNN</cell></row><row><cell></cell><cell></cell><cell>5%</cell><cell>54.98 56.23</cell><cell>50.21</cell><cell>53.82</cell><cell>56.33</cell><cell>51.03</cell><cell>53.73</cell><cell>61.58</cell><cell>66.08</cell><cell>71.10</cell><cell>69.83</cell><cell>71.26</cell></row><row><cell></cell><cell>AUC</cell><cell>10% 20%</cell><cell>50.94 55.45 53.15 57.69</cell><cell>55.12 55.05</cell><cell>54.20 56.12</cell><cell>56.29 57.32</cell><cell>50.15 51.56</cell><cell>51.68 51.55</cell><cell>62.07 62.31</cell><cell>70.21 73.26</cell><cell>71.02 74.32</cell><cell>71.85 73.32</cell><cell>73.31 74.45</cell></row><row><cell>Yelp</cell><cell></cell><cell>40% 5%</cell><cell>52.47 56.24 53.12 54.68</cell><cell>53.38 50.38</cell><cell>54.00 54.25</cell><cell>55.91 52.33</cell><cell>53.65 50.00</cell><cell>51.58 52.28</cell><cell>62.07 62.60</cell><cell>74.98 63.52</cell><cell>74.42 66.64</cell><cell>74.77 68.09</cell><cell>75.70 67.53</cell></row><row><cell></cell><cell>Recall</cell><cell>10% 20%</cell><cell>51.10 52.34 53.87 53.20</cell><cell>51.75 50.92</cell><cell>52.23 52.69</cell><cell>54.35 54.84</cell><cell>50.00 50.00</cell><cell>52.57 52.16</cell><cell>62.08 62.35</cell><cell>67.38 68.34</cell><cell>68.35 69.07</cell><cell>68.92 69.48</cell><cell>67.77 68.60</cell></row><row><cell></cell><cell></cell><cell>40%</cell><cell>50.81 54.52</cell><cell>50.43</cell><cell>52.86</cell><cell>50.94</cell><cell>50.00</cell><cell>50.59</cell><cell>62.08</cell><cell>71.13</cell><cell>70.22</cell><cell>69.25</cell><cell>71.92</cell></row><row><cell></cell><cell></cell><cell>5%</cell><cell>74.44 73.89</cell><cell>75.12</cell><cell>70.71</cell><cell>71.56</cell><cell>76.86</cell><cell>70.25</cell><cell>85.46</cell><cell>89.49</cell><cell>89.36</cell><cell>89.35</cell><cell>89.54</cell></row><row><cell>Amazon</cell><cell>AUC Recall</cell><cell>10% 20% 40% 5% 10% 20%</cell><cell>75.25 74.55 75.13 72.10 74.34 75.16 65.54 63.22 67.81 65.84 66.15 67.13</cell><cell>74.13 75.58 74.68 64.23 67.22 65.08</cell><cell>73.97 73.97 75.27 69.09 69.36 70.30</cell><cell>72.23 71.89 72.65 65.56 66.63 65.08</cell><cell>75.73 74.55 56.94 50.00 50.00 50.00</cell><cell>76.21 73.98 70.35 63.29 63.32 61.28</cell><cell>85.29 85.50 85.50 85.49 85.38 85.59</cell><cell>89.58 89.58 89.70 88.22 87.87 88.40</cell><cell>89.37 89.68 89.69 88.31 88.36 88.60</cell><cell>89.43 89.34 89.52 88.02 88.12 88.00</cell><cell>89.44 89.45 89.73 88.34 88.29 88.27</cell></row><row><cell></cell><cell></cell><cell>40%</cell><cell>67.45 65.51</cell><cell>67.68</cell><cell>70.16</cell><cell>65.41</cell><cell>50.00</cell><cell>62.89</cell><cell>85.53</cell><cell>88.41</cell><cell>88.45</cell><cell>88.22</cell><cell>88.48</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/safe-graph/DGFraud</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work is supported by NSF under grants III-1526499, III-1763325, III-1909323, and CNS-1930941. For any correspondence, please refer to Hao Peng.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Graph based anomaly detection and description: a survey. Data mining and knowledge discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Akoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koutra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Friend or Faux: Graph-Based Early Detection of Fake Accounts on Social Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Breuer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Eilat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Weinsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Measuring and Relieving the Over-smoothing Problem for Graph Neural Networks from the Topological View</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Label Aware Graph Convolutional Network-Not All Edges Deserve Your Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.04707</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fastgcn: fast learning with graph convolutional networks via importance sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Zaki</surname></persName>
		</author>
		<title level="m">Deep Iterative and Adaptive Learning for Graph Neural Networks. AAAI Workshops</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Spotting Collusive Behaviour of Online Fraud Groups in Customer Reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dhawan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C R</forename><surname>Gangireddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Robust Spammer Detection by Nash Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning discrete structures for graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Franceschi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Securing behavior-based opinion spam detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Big Data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Measuring and Improving the Use of Graph Information in Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Suspicious behavior detection: Current trends and future directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Intelligent Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Wide-Ranging Review Manipulation Attacks: Model, Empirical Study, and Countermeasures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kaghazgaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alfifi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caverlee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Combating crowdsourced review manipulators: A neighborhood-based approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kaghazgaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caverlee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Squicciarini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rev2: Fraudulent user prediction in rating platforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Makhija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Subrahmanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Spam Review Detection with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adaptive graph convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>In AAAI</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">FlowScope: Spotting Money Laundering Based on Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Exploratory undersampling for class-imbalance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TSMC</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Geniepath: Graph neural networks with adaptive receptive paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Heterogeneous Graph Neural Networks for Malicious Account Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Alleviating the Inconsistency Problem of Applying Graph Neural Network to Fraud Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>SIGIR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">What Yelp Fake Review Filter Might Be Doing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Venkataraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Glance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICWSM</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">SilceNDice: Mining Suspicious Multi-attribute Entity Groups with Multi-view Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nilforoshan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>In DSAA</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Collective Opinion Spam Detection: Bridging Review Networks and Metadata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rayana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Akoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A cost-sensitive decision tree approach for fraud detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sahin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bulkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert Systems with Applications</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESWC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">KOLLECTOR: Detecting Fraudulent Activities on Mobile Devices Using Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Srisa-An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Leow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Checkoway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TMC</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.10528</idno>
		<title level="m">Adversarial Attack and Defense on Graph Data: A Survey</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11715</idno>
		<title level="m">GraphMix: Regularized Training of Graph Neural Networks for Semi-Supervised Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Multi-armed bandit algorithms and empirical evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vermorel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A Semi-supervised Graph Attentive Network for Fraud Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep structure learning for fraud detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">FdGars: Fraudster Detection via Graph Convolutional Networks in Online App Review System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW Workshops</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Anti-money laundering in bitcoin: Experimenting with graph convolutional networks for financial forensics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Domeniconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K I</forename><surname>Weidele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bellei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Leiserson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD Workshops</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">ASA: Adversary Situation Awareness via Heterogeneous Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW Workshops</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">2020. A comprehensive survey on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TNNLS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00455</idno>
		<title level="m">Secure Network Release with Link Privacy</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Rumor Detection on Social Media with Graph Structured Adversarial Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Unsupervised Anomaly Detection via Deep Metric Learning with End-to-End Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kozat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.05865</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Graphsaint: Graph sampling based inductive learning method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Prasanna</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">GCN-Based User Representation Learning for Unifying Robust Recommendation and Fraudster Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V N</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Key Player Identification in Underground Forums over Attributed Heterogeneous Information Network Embedding Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Smoke screener or straight shooter: Detecting elite sybil attacks in user-review social networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NDSS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Financial Defaulter Detection on Online Credit Payment via Multi-View Attributed Heterogeneous Information Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Layer-dependent importance sampling for training deep and large graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
