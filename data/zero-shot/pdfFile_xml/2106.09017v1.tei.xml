<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bridging Multi-Task Learning and Meta-Learning: Towards Efficient Training and Effective Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021">2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxiang</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
						</author>
						<title level="a" type="main">Bridging Multi-Task Learning and Meta-Learning: Towards Efficient Training and Effective Adaptation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 38 th International Conference on Machine Learning</title>
						<meeting>the 38 th International Conference on Machine Learning						</meeting>
						<imprint>
							<date type="published" when="2021">2021</date>
						</imprint>
					</monogr>
					<note>1 University of Illinois at Urbana-Champaign, Urbana, IL, USA. Correspondence to: Haoxiang Wang &lt;hwang264@illinois.edu&gt;, Han Zhao &lt;hanzhao@illinois.edu&gt;, Bo Li &lt;lbo@illinois.edu&gt;.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-task learning (MTL) aims to improve the generalization of several related tasks by learning them jointly. As a comparison, in addition to the joint training scheme, modern meta-learning allows unseen tasks with limited labels during the test phase, in the hope of fast adaptation over them. Despite the subtle difference between MTL and meta-learning in the problem formulation, both learning paradigms share the same insight that the shared structure between existing training tasks could lead to better generalization and adaptation. In this paper, we take one important step further to understand the close connection between these two learning paradigms, through both theoretical analysis and empirical investigation. Theoretically, we first demonstrate that MTL shares the same optimization formulation with a class of gradient-based meta-learning (GBML) algorithms. We then prove that for over-parameterized neural networks with sufficient depth, the learned predictive functions of MTL and GBML are close. In particular, this result implies that the predictions given by these two models are similar over the same unseen task. Empirically, we corroborate our theoretical findings by showing that, with proper implementation, MTL is competitive against state-of-the-art GBML algorithms on a set of few-shot image classification benchmarks. Since existing GBML algorithms often involve costly second-order bi-level optimization, our first-order MTL method is an order of magnitude faster on large-scale datasets such as mini-ImageNet. We believe this work could help bridge the gap between these two learning paradigms, and provide a computationally efficient alternative to GBML that also supports fast task adaptation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Multi-task learning has demonstrated its efficiency and effectiveness on learning shared representations with training data from multiple related tasks simultaneously <ref type="bibr" target="#b11">(Caruana, 1997;</ref><ref type="bibr" target="#b27">Ruder, 2017;</ref><ref type="bibr" target="#b39">Zhang &amp; Yang, 2017)</ref>. Such shared representations could transfer to many real-world applications, such as object detection <ref type="bibr" target="#b41">(Zhang et al., 2014)</ref>, image segmentation <ref type="bibr">(Kendall et al., 2018)</ref>, multi-lingual machine translation <ref type="bibr">(Dong et al., 2015)</ref>, and language understanding evaluation . On the other hand, in addition to the joint training scheme, modern meta-learning can leverage the shared representation to fast adapt to unseen tasks with only minimum limited data during the test phase <ref type="bibr">(Hospedales et al., 2020)</ref>. As a result, meta-learning has drawn increasing attention and been applied to a wide range of learning tasks, including few-shot learning <ref type="bibr" target="#b29">(Snell et al., 2017;</ref><ref type="bibr" target="#b33">Vinyals et al., 2016;</ref><ref type="bibr">Lee et al., 2019b)</ref>, meta reinforcement learning <ref type="bibr">(Finn et al., 2017)</ref>, speech recognition <ref type="bibr">(Hsu et al., 2020)</ref> and bioinformatics <ref type="bibr" target="#b15">(Luo et al., 2019)</ref>.</p><p>Despite their subtle differences in problem formulation and objectives, both MTL and meta-learning aim to leverage the correlation between different tasks to enable better generalization to either seen or unseen tasks. However, a rigorous exploration of this intuitive observation is severely lacking in the literature. As a result, while being effective on fast adaptation to unseen tasks, many meta-learning algorithms still suffer from expensive computational costs <ref type="bibr" target="#b17">(Nichol et al., 2018a;</ref><ref type="bibr" target="#b1">Antoniou et al., 2019;</ref><ref type="bibr">Hospedales et al., 2020)</ref>. On the other hand, while being efficient in training, due to its problem formulation, MTL does not allow adaptation to unseen tasks, at least in a straightforward manner. Hence, a natural question to ask is, Can we combine the best of both worlds from MTL and meta-learning, i.e., fast adaptation to unseen tasks with efficient training?</p><p>To answer this question, one needs to first understand the relationship between MTL and meta-learning in greater depth. To this end, in this paper, we take the first attempt with the goal to bridge these two learning paradigms. In particular, we focus on a popular class of meta-learning methods, gradient-based meta-learning (GBML), which takes a arXiv:2106.09017v1 <ref type="bibr">[cs.</ref>LG] 16 Jun 2021 bi-level optimization formulation inspired from the Model-Agnostic Meta-Learning (MAML) <ref type="bibr">(Finn et al., 2017)</ref>. From an optimization perspective, we first show that MTL and a class of GBML algorithms share the same optimization formulation. Inspired by this simple observation, we then prove that, for sufficiently wide neural networks, these two methods lead to close predictors: on any test task, the predictions given by these two methods are similar, and the gap is inversely proportional to the network depth. Our theoretical results imply that, in principle, it is possible to improve the existing MTL methods to allow fast adaptation to unseen tasks, without loss in its training efficiency, and thus provide an affirmative answer to the above question.</p><p>Empirically, to corroborate our findings, we first conduct a series of experiments on synthetic data to show the increasing closeness between the predictors given by MTL and GBML, as the network depth grows. We then perform extensive experiments to show that with proper implementation, MTL can achieve similar or even better results than the state-of-the-art GBML algorithms, while enjoys significantly lower computational costs. This indicates that MTL could be potentially applied as a powerful and efficient alternative to GBML for meta-learning applications.</p><p>Our contributions could be briefly summarized as follows:</p><p>? Bridging MTL and GBML from the optimization perspective: We show that MTL and a class of GBML algorithms share the same optimization formulation. In particular, GBML takes a regularized bi-level optimization while MTL adopts the simple joint training. ? Closeness in the function space: we prove that for over-parameterized neural nets with sufficient width, the learned predictive functions of MTL and a GBML algorithm are close in the function space, indicating their predictions are similar on unseen (test) tasks. Furthermore, we empirically validate this theoretical result on synthetic data. ? Empirical performance and efficiency: Motivated by our theoretical results, we implement MTL with modern deep neural nets, and show that the performance of MTL is competitive against MetaOptNet (Lee et al., 2019b), a state-of-the-art GBML algorithm, on few-shot image classification benchmarks. Notably, the training of MTL is an order of magnitude faster than that of MetaOptNet, due to its first-order optimization. The code is released at https://github.com/AI-secure/ multi-task-learning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Multi-Task Learning Multi-task learning (MTL) is a method to jointly learn shared representations from multiple training tasks <ref type="bibr" target="#b11">(Caruana, 1997)</ref>. Past research on MTL is abundant. Theoretical results on learning shared representation with MTL have shown that the joint training scheme is more sample efficient than single-task learning, at least under certain assumptions of task relatedness, linear features and model classes <ref type="bibr" target="#b16">(Maurer et al., 2016;</ref><ref type="bibr" target="#b32">Tripuraneni et al., 2020)</ref>. Other works on MTL include designing more efficient optimization methods to explore the task and feature relationships <ref type="bibr">(Evgeniou &amp; Pontil, 2007;</ref><ref type="bibr" target="#b2">Argyriou et al., 2008;</ref><ref type="bibr" target="#b40">Zhang &amp; Yeung, 2010;</ref><ref type="bibr" target="#b42">Zhao et al., 2020)</ref>.</p><p>Meta-Learning Meta-learning, or learning-to-learn, is originally proposed for few-shot learning tasks <ref type="bibr" target="#b30">(Thrun &amp; Pratt, 1998;</ref><ref type="bibr" target="#b8">Baxter, 1998)</ref>, where the goal is fast adaptation to unseen tasks. Among various meta-learning methods, a line of works following MAML, termed as gradientbased meta-learning (GBML) <ref type="bibr">(Finn et al., 2017;</ref><ref type="bibr" target="#b25">Rajeswaran et al., 2019)</ref>, has been increasingly applied in many downstream application domains. Recent works on understanding GBML have shown that MAML is implicitly performing representation learning, which is the key to its empirical success <ref type="bibr" target="#b24">(Raghu et al., 2020)</ref>. In particular, <ref type="bibr" target="#b28">Saunshi et al. (2020)</ref> compares MTL and Reptile <ref type="bibr" target="#b18">(Nichol et al., 2018b)</ref>, a first-order variant of MAML, in a toy setting of 1d subspace learning with 2-layer linear models, and shows the upper bounds of their sample complexity are of the same order. In contrast, our theory is compatible with non-linear neural nets of any depth and has no restriction on the input dimension, which is a more realistic and practical setting. In addition to GBML, the considered MTL implementation shares some similarities with metric-based meta-learning (i.e., metric learning) methods in few-shot learning scenarios <ref type="bibr" target="#b29">(Snell et al., 2017;</ref><ref type="bibr" target="#b33">Vinyals et al., 2016)</ref>, since here we also only keep the trained hidden layers for test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries</head><p>We first provide a brief discussion to the common network architectures, training algorithms, and evaluation protocols for MTL and GBML.</p><p>case, the shared hidden layers are treated as the shared representations. Formally, denote a L-layer N -head neural network asf? :</p><formula xml:id="formula_0">R d ? [N ] ? R k , s.t. for any input x ? R d and head index i ? [N ], the network output i? f?(x, i) = ? ?&lt;L (x)? (i) ,<label>(1)</label></formula><p>where ?? &lt;L (x) is the last hidden layer output,? &lt;L is the parameters of first L ? 1 layers, and w i is the i-th head in the output layer. Note that the network parameters are the union of parameters in the hidden layers and multi-head output layer, i.e.,? = {? &lt;L } ? {? (i) } i? <ref type="bibr">[N ]</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Multi-Task Learning</head><p>In MTL, a multi-head neural net with N heads is trained over N training tasks each with n samples <ref type="bibr" target="#b27">(Ruder, 2017)</ref>.</p><formula xml:id="formula_1">For i ? [N ]</formula><p>, denote the data for the i-th task as</p><formula xml:id="formula_2">(X i , Y i ), where X i ? R n?d and Y i ? R n?k .</formula><p>The training of MTL is to minimize the following objective given loss function ,</p><formula xml:id="formula_3">min ? L MTL (?) := i?[N ] ? ?&lt;L (X i )? (i) , Y i (2) where ? ?&lt;L (X i ) := ? ? (x) x?[Xi] ? R n?h L?1 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Gradient-Based Meta-Learning and ANIL</head><p>Here we introduce a representative algorithm of GBML, Almost-No-Inner-Loop (ANIL) <ref type="bibr" target="#b24">(Raghu et al., 2020)</ref>, which is a simplification of MAML. The setup is the same as Sec. 3.2, where N training tasks each with n sample-label pairs are provided, i.e.,</p><formula xml:id="formula_4">{X i , Y i } N i=1 .</formula><p>In practice, a training protocol, query-support split (cf. Appendix A for more details), is often adopted. However, recent work has shown that such a split is not necessary <ref type="bibr" target="#b6">(Bai et al., 2021)</ref>. Hence, we do not consider the query-support split through this work.</p><p>ANIL minimizes the following loss over ? = {? &lt;L , w},</p><formula xml:id="formula_5">min ? L ANIL (?) := i?[N ] (? ? &lt;L (X i ) w * i , Y i ) (3) s.t. w * i = InnerLoop(w, ? ? &lt;L (X i ), Y i , ?, ?) (4)</formula><p>where <ref type="formula">(4)</ref> is the common inner-loop optimization of GBML, which runs ? steps of gradient descent w.r.t. w on the loss</p><formula xml:id="formula_6">(? ? &lt;L (X i )w, Y i ), with learning rate ?.</formula><p>Notably, <ref type="bibr" target="#b13">Lin et al. (2021)</ref> empirically shows that with a frozen head w across training, ANIL has no performance drop, indicating that optimizing over w in the outer loop (3) is insignificant. Thus, the corresponding training objective of this ANIL without the outer-loop optimization of w is</p><formula xml:id="formula_7">min ? &lt;L L ANIL (?) := i?[N ] (? ? &lt;L (X i ) w * i , Y i )<label>(5)</label></formula><p>with w * i defined in the same way as (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Fine-Tuning for Test Task Adaptation</head><p>In the test phase of few-shot learning, an arbitrary test task T consists of (X, Y, X , Y ) ? R n?d ? R n?k ? R n ?d ? R n ?k , where (X, Y ) are query data and (X , Y ) are support data. Note that the original formulation of MTL with multi-head network structures does not support adaptation to unseen tasks. To compare MTL and GBML on an equal footing, in this work, we adopt the following same test protocol on both MTL and GBML. First, a randomly initialized head w test is appended to the last hidden layer of networks trained under MTL or GBML. Then, the head w test is fine-tuned on labelled support samples (X , Y ), and the network makes predictions on the query samples X. Specifically, for a trained MTL model with parameters?, its prediction on X after fine-tuning w test on (X , Y ) for? steps is</p><formula xml:id="formula_8">F MTL (X, X , Y ) = ? ?&lt;L (X) w * test (6) s.t. w * test = InnerLoop(w test , ? ?&lt;L (X ), Y ,? , ?) (7) where w *</formula><p>test is the fined-tuned test head after? steps of gradient descent on w test , and InnerLoop is defined in the same way as (4). Similarly, the prediction of a trained ANIL model with parameters ? on X is</p><formula xml:id="formula_9">F ANIL (X, X , Y ) = ? ? &lt;L (X) w * test (8) s.t. w * test = InnerLoop(w test , ? ? &lt;L (X ), Y ,? , ?) (9)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Theoretical Analysis</head><p>In this section, we compare MTL with a class of GBML algorithms, and show that (i) essentially, they optimize the same objective with different optimization approaches, (ii) the learned predictors from both algorithms are close under a certain norm in the function space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">A Taxonomy of Gradient-Based Meta-Learning</head><p>Various GBML methods often differ in the way on how to design the inner-loop optimization in Eq. (4). For example, MAML, ANIL and some other MAML variants usually take a few gradient descent steps (typically 1?10 steps), which is treated as an early stopping type of regularization <ref type="bibr" target="#b25">(Rajeswaran et al., 2019;</ref><ref type="bibr">Grant et al., 2018)</ref>. As a comparison, another line of GBML algorithms uses the explicit 2 regularization in the inner loop instead <ref type="bibr" target="#b25">(Rajeswaran et al., 2019;</ref><ref type="bibr">Lee et al., 2019b;</ref><ref type="bibr" target="#b9">Bertinetto et al., 2019;</ref><ref type="bibr" target="#b44">Zhou et al., 2019b;</ref><ref type="bibr">Goldblum et al., 2020)</ref>. In addition to regularization, variants of GBML methods also differ in the exact layers to optimize in the inner loop: While MAML optimizes all network layers in the inner loop, some other GBML algorithms are able to achieve state-of-the-art performance (Lee et al., 2019b) by only optimizing the last layer in the inner loop.</p><p>Based on the different regularization strategies and optimized layers in the inner-loop, we provide a taxonomy of GBML algorithms in <ref type="table" target="#tab_0">Table 1</ref>.  <ref type="bibr" target="#b9">(Bertinetto et al., 2019)</ref> All Layers MAML <ref type="bibr">(Finn et al., 2017)</ref> iMAML <ref type="bibr" target="#b25">(Rajeswaran et al., 2019)</ref> Meta-MinibatchProx <ref type="bibr" target="#b44">(Zhou et al., 2019b</ref>) <ref type="table">Table 2</ref>. Typical instantiations of the problem (10). ? ? R + controls the strength of the regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ANIL MetaOptNet R2D2</head><p>Cross-Entropy SVM Loss Squared Loss</p><formula xml:id="formula_10">R(w i ) Early Stopping ? w i 2 2 ? w i 2 2</formula><p>For algorithms that only optimize the last layer in the innerloop, we formulate their training objectives in a unified framework:</p><formula xml:id="formula_11">min ? &lt;L i?[N ] ? ? &lt;L (X i ) w * i , Y i (10) s.t. w * i = arg min wi ? ? &lt;L (X i ) w i , Y i + R(w i ) (11)</formula><p>Certainly, there are abundant choices for the loss function and the regularization R(w i ), and we summarize the typical choices used in the literature in <ref type="table">Table 2</ref>. For algorithms that optimize all layers in the inner loop, a unified framework similar to <ref type="formula" target="#formula_0">(10)</ref> and <ref type="formula" target="#formula_0">(11)</ref> is provided in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Equivalence Between GBML and MTL from an Optimization Perspective</head><p>In this section, we provide a simple observation that, surprisingly, the optimization objective of MTL shares the same formulation as that of GBML algorithms, (10). Specifically, the objective function of MTL, (2), can be re-written as</p><formula xml:id="formula_12">min ? &lt;L ,{? (i) } N i=1 L MTL (?) i?[N ] ? ?&lt;L (X i )? (i) , Y i<label>(12)</label></formula><p>where {? (i) } N i=1 are heads of a multi-head neural net, and</p><formula xml:id="formula_13">? = {? &lt;L } ? {? (i) } N i=1</formula><p>. As a comparison, if we plug (11) into (10), the GBML objective (10) can be simplified as</p><formula xml:id="formula_14">min ? &lt;L L GBML (? &lt;L ) min {wi} N i=1 i?[N ] ? ? &lt;L (X i ) w i , Y i + R(w i )<label>(13)</label></formula><p>Note that different from (12), the heads {w i } N i=1 in (13) are transient, in the sense that GBML algorithms do not explicitly save them during training. On the other hand, ? &lt;L contains all parameters to optimize in (13), and ? &lt;L is optimized over GBML (? &lt;L ), which is obtained by plugging in the minimizer of {w i } N i=1 on the regularized loss. In other words, (13) is a bi-level optimization problem, with outer-loop optimization on network parameters ? &lt;L and inner-loop optimization on the transient heads {w i } N i=1 . Clearly, up to the regularization term, the optimization problems (12) and (13) share the same structure and formulation. In terms of the algorithms used to solve these two optimization problems, it is worth pointing out that GBML usually solves (13) as a bi-level program where for each fixed ? &lt;L , the algorithm will first compute the optimal heads {w i } N i=1 as a function of ? &lt;L , whereas in MTL, (12) is solved by the simple joint optimization over both? &lt;L and {? (i) } N i=1 . From the discussions above, we conclude that the optimization formulation of GBML is equivalent to that of MTL, where the only difference lies in the optimization algorithms used to solve them. Motivated by this observation, in the next section, we explore the equivalence of these two algorithms in terms of the predictors obtained after convergence, when the networks are sufficiently wide.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Closeness Between MTL and GBML from a Functional Perspective</head><p>In this section, we theoretically analyze MTL and a representative GBML algorithm, ANIL <ref type="bibr" target="#b24">(Raghu et al., 2020)</ref>, from a functional perspective, and show that the learned predictors of MTL and ANIL after convergence are close under a certain norm. Due to the page limit, we defer detailed proofs to appendix, and mainly focus on discussing the implications of our theoretical results. Before we proceed, we first formally introduce the problem setup and training protocol used in the following analysis.</p><p>Problem Setup To simplify our analysis and presentation, we consider the squared loss, i.e., (?, y) = 1 2 ? ? y 2 2 . Note that the use of squared loss is standard for theoretical analyses of neural net optimization <ref type="bibr">(Jacot et al., 2018;</ref><ref type="bibr" target="#b4">Du et al., 2019;</ref><ref type="bibr" target="#b0">Allen-Zhu et al., 2019)</ref>. <ref type="bibr">Furthermore, recently, Hui &amp; Belkin (2021)</ref> has also empirically demonstrated the effectiveness of squared loss in classification tasks from various domains. For the activation function and initialization scheme of neural nets, we focus on networks with ReLU activation and He's initialization 1 <ref type="bibr">(He et al., 2016)</ref>, which is also standard in practice.</p><p>With the squared loss, the objectives of MTL and ANIL, i.e., (2) and (3), can be simplifed to</p><formula xml:id="formula_15">L MTL (? t ) = 1 2 i?[N ] vec ? ?&lt;L (X i )? (i) ? Y i 2 2 , L ANIL (? t ) = 1 2 i?[N ] vec ? ? &lt;L (X i ) w * i ? Y i 2 2 ,</formula><p>where vec(?) is the vectorizaton operation and <ref type="bibr">?, ?)</ref>. During the test phase, for networks trained by MTL and ANIL, the predictions on any test task are obtained by fine-tuning an output head and predicting with this fine-tuned head (cf. Sec. 3.4).</p><formula xml:id="formula_16">w * i = InnerLoop(w, ? ? &lt;L (X i ), Y i ,</formula><p>Training Dynamics We consider gradient flow (i.e., continuous-time gradient descent) for the training of both MTL and ANIL, which is a common setting used for theoretical analysis of neural nets with more than two layers <ref type="bibr">(Jacot et al., 2018;</ref><ref type="bibr">Lee et al., 2019a;</ref><ref type="bibr" target="#b4">Arora et al., 2019)</ref>. In more detail, let ? be the learning rate, then the training dynamics of MTL and ANIL can be described by</p><formula xml:id="formula_17">d? t dt = ???? t L MTL (? t ), d? t dt = ??? ?t L ANIL (? t ) (14)</formula><p>where ? t and? t are network parameters at training step t.</p><p>NTK and NNGP Kernels Our forthcoming theoretical analysis involves both the Neural Tangent Kernel (NTK) <ref type="bibr">(Jacot et al., 2018;</ref><ref type="bibr" target="#b4">Du et al., 2019;</ref><ref type="bibr" target="#b0">Allen-Zhu et al., 2019)</ref> and the Neural Network Gaussian Process (NNGP) kernel <ref type="bibr">(Lee et al., 2018;</ref><ref type="bibr" target="#b19">Novak et al., 2019)</ref>, which are tools used to understand the training trajectories of neural nets by reduction to classic kernel machines. For completeness, here we provide a brief introduction to both, so as to pave the way for our following presentation. Let the kernel functions of NTK and NNGP be ?(?, ?) and K(?, ?), respectively. Analytically, the NTK and NNGP for networks of L layers can be computed recursively layer by layer <ref type="bibr">(Lee et al., 2019a;</ref><ref type="bibr" target="#b4">Arora et al., 2019)</ref>. Numerically, both kernels can be computed by using the Neural Tangents package <ref type="bibr" target="#b20">(Novak et al., 2020)</ref>. Furthermore, without loss of generality, we assume the inputs are normalized to have unit variance, following <ref type="bibr" target="#b20">(Xiao et al., 2020)</ref>, and we adopt the NTK parameterization <ref type="bibr">(Lee et al., 2019a)</ref>, which is the same with the standard neural net parameterization in terms of network output and training dynamics. More details about the parametrization can be found in Appendix A.</p><p>With the above discussions clearly exposed, now we are ready to state the following main lemma, which serves as the basic for our main result in this section. In particular, by leveraging tools from <ref type="bibr">Lee et al. (2019a)</ref> and , we are able to prove that for sufficiently wide neural nets trained under gradient flow of ANIL or MTL (i.e., by (14)), their predictions on any test task are equivalent to a special class of kernel regression, with kernels that we name as (i) ANIL Kernel ? ANIL and (ii) MTL Kernel ? MTL . Notice that both ? ANIL and ? MTL are composite kernels built on the NTK ? and NNGP kernels K. Lemma 1 (Test Predictions of MTL &amp; ANIL). Consider an arbitrary test task T = (X, Y, X , Y ), as defined in Sec. 3.4. For arbitrarily small ? &gt; 0, there exists ? * , h * ? R + such that for networks with width greater than h * and trained under gradient flow with learning rate ? &lt; ? * , with probability at least 1 ? ? over random initialization, the test predictions on T (i.e., Eq. <ref type="formula">(6)</ref> and <ref type="formula">(8)</ref>) are</p><formula xml:id="formula_18">F MTL (X, X , Y ) = G? (X, X , Y )<label>(15)</label></formula><formula xml:id="formula_19">+ ? MTL ((X, X ,? ), X )? ?1 MTL (X , X ) ? Y, F ANIL (X, X , Y ) = G? (X, X , Y )<label>(16)</label></formula><formula xml:id="formula_20">+ ? ANIL ((X, X ,? ), X )? ?1 ANIL (X , X ) Y ? G ? (X , X , Y) , up to an error of O( 1 ? h * ) measured in 2 norm. In above equations, we used shorthand X = (X i ) N i=1 ? R N n?d and Y = vec((Y i ) N i=1 ) ? R N nk . Besides, the function G, kernels ? MTL &amp; ? ANIL , and their variants ? MTL &amp; ? ANIL , are defined below. ? Function G. The function G is defined as G? (X, X , Y ) = K(X, X )K(X , X ) ?1 (I ? e ??K(X ,X )? )Y and G ? (X , X , Y ) = vec((G ? (X i , X i , Y i )) N i=1 ). ? MTL Kernels. The kernel ? MTL (X , X ) is a block matrix of N ? N blocks. Its (i, j)-th block for any i, j ? [N ] is [? MTL (X , X )] ij = ?(X i , X j ) ? 1[i = j]K(X i , X j ) . Besides, ? MTL is variant of the kernel function ? MTL , and ? MTL ((X, X ,? ), X ) is also a block matrix, of 1 ? N blocks, with the (1, j)-th block as [? MTL ((X, X ,? ), X )] 1j = ?(X, X j ) ? K(X, X j ) ? K(X, X )T? K (X ) ?(X , X j ) ? K(X , X j )</formula><p>where the function T is defined as</p><formula xml:id="formula_21">T? K (X ) = K(X , X ) ?1 I ? e ??K(X )? (17) ? ANIL kernels. ? ANIL (X , X ) is also a block matrix of N ? N blocks. Its (i, j)-th block for any i, j ? [N ] is [? ANIL (X , X )] ij = e ??K(Xi,Xi)? ?(X i , X j )e ??K(Xj ,Xj )? , while ? ANIL ((X, X ,? ), X ) is a block matrix of 1 ? N blocks, with the (1, j)-th block as [? ANIL ((X, X ,? ), X )] 1j = ?(X, X j )e ??K(Xj ,Xj )? ? K(X, X )T? K (X )?(X , X j )e ??K(Xj ,Xj )?</formula><p>Remark The function G is implicitly related to task adaptation. For instance, on the test task T = (X, Y, X , Y ), G? (X, X , Y ) is equivalent to the output of a trained wide network on X, where the network is trained on data (X , Y ) with learning rate ? for? steps from the initialization.</p><p>Proof Sketch. Lemma 1 is a key lemma used in our analysis, hence we provide a high-level sketch of its proof. The main idea is that, for over-parametrized neural nets, we could approximate the network output function by its firstorder Taylor expansion with the corresponding NTKs and NNGPs (Lee et al., 2019a), provided the network parameters do not have a large displacement during training. Under this case, we can further prove the global convergence of both MTL and ANIL by leveraging tools from . The last step is then to analytically compute the corresponding kernels, as shown in Lemma 1.</p><p>With Lemma 1, we proceed to derive the main result in this section. Namely, the predictions given by MTL and ANIL over any test task are close. Intuitively, from <ref type="formula" target="#formula_0">(15)</ref> and <ref type="formula" target="#formula_0">(16)</ref>, we can see the test predictions of MTL and ANIL admit a similar form, even though they use different kernels. Inspired by this observation, a natural idea is to bound the difference between the MTL and ANIL kernels by analyzing their spectra, which leads to the following theorem:</p><formula xml:id="formula_22">Theorem 1. Consider an arbitrary test task, T = (X, Y, X , Y ) ? R n?d ? R n?k ? R n ?d ? R n ?k . For any &gt; 0, there exists a constant h * = O( ?2 ) s.t.</formula><p>if the network width h is greater than h * , for ReLU networks with He's initialization, the average difference between the predictions of ANIL and MTL on the query samples X is bounded by</p><formula xml:id="formula_23">F ANIL (X, X , Y ) ? F MTL (X, X , Y ) 2 ? O ?? + 1 L + .<label>(18)</label></formula><p>Remark The bound (18) is dominated by O(?? + 1 L ). Notice that ? and ? are the inner-loop learning rate and adaptation steps of ANIL. In practical implementations, ?? ? [0.01, 0.5], which is small. In the state-of-the-art metalearning models, the network depth L ? 12, hence 1/L is also small. Since the bound holds for any test data, it implies that the average discrepancy between the learned predictors of MTL and ANIL is small. Notice that we only study the effect of hyperparameters of models and algorithms (e.g., L, ?, ? ), and consider dataset-specific parameters (e.g., N, n, k, d) as constants.</p><p>Proof Sketch. The first step is to apply the analytic forms of F ANIL and F MTL in Lemma 1 to compute their difference. We then prove that the norm of the difference is bounded as</p><formula xml:id="formula_24">F ANIL (X, X , Y ) ? F MTL (X, X , Y ) 2 ? O L ?(X , X ) ?1 ? ? ?1 MTL (X , X ) op + O(?? + 1 ? h )</formula><p>Then, by leveraging theoretical tools from <ref type="bibr" target="#b20">Xiao et al. (2020)</ref>, we obtain an in-depth structure of the spectrum of the MTL kernel ? MTL for deep ReLU nets, in order to prove that</p><formula xml:id="formula_25">?(X , X ) ?1 ? ? ?1 MTL (X , X ) op ? O( 1 L 2 ),</formula><p>with a fine-grained analysis. Finally, defining h * = O(? ?2 ), we obtain the bound (18) for networks with h &gt; h * .</p><p>Theorem 1 could also be extended to ResNets, which have been widely adopted in modern meta-learning applications: </p><formula xml:id="formula_26">e L ? MTL ((X, X ,? ), X ) ? (e L ? MTL (X , X )) ?1 = ? MTL ((X, X ,? ), X )? MTL (X , X ) ?1 .</formula><p>Similar observation also holds for ? ANIL and F ANIL . Thus, Theorem 1 applies to residual ReLU networks as well.</p><p>For residual ReLU nets with LayerNorm, ? MTL and ? ANIL have identical kernel spectra and structures as the regular ReLU nets, up to a difference of a negligible order. Hence, Theorem 1 also applies to this class of networks.</p><p>See Appendix B for the full proof of Lemma 3, Theorem 1 and Corollary 1.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In this section, we first provide an empirical validation of Theorem 1 on synthetic data. Then, we perform a largescale empirical study of MTL with unseen task adaptation on few-shot image classification benchmarks to compare with state-of-the-art meta-learning algorithms. The code is released at https://github.com/AI-secure/ multi-task-learning We vary L in the first figure with fixed ?? = 0, and vary ?? in the two figures with fixed L = 10, to observe the corresponding trends in the prediction difference FANIL(X, X , Y ) ? FMTL(X, X , Y ) 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Closeness between MTL and GBML predictions</head><p>Problem Setting We consider a few-shot regression problem to verify the theoretical claims in Theorem 1, and adopt the notation defined in Sec. 3. For each training task i with data (X i , Y i ), it has two task-specific parameters ? i ? R d and ? i ? R+. The data points in X i are sampled i.i.d. from N (? i , ? 2 i I), and the label of each point x is generated by a quadratic function y = ? i (x ? ? i ) 2 . Similarly, any test task T = (X, Y, X , Y ) also has its task-specific parameters (? test , ? test ), and the points from its query and support set X, X are drawn i</p><formula xml:id="formula_27">.i.d. from N (? test , ? 2 test I), with the label of each point x following y = ? test (x ? ? test ) 2 .</formula><p>Dataset Synthesis We fix the input dimension d = 10 and generate N = 20 training tasks each with n = 10 data points. In each test task, there are 5 support and 10 query data points. For each training or test task, its taskspecific parameters (?, ?) are generated by ? ? N (0, I) and ? ? Unif(1.3, 1.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation Details</head><p>We implement the functions F MTL and F ANIL in <ref type="formula" target="#formula_0">(15)</ref> and (16) by using the empirical kernel functions of NTK and NNGP provided by Neural Tangents <ref type="bibr" target="#b20">(Novak et al., 2020)</ref>. As suggested by <ref type="bibr" target="#b20">Novak et al. (2020)</ref>, we construct neural nets with width as 512 to compute kernels. Following Sec. 4.3, the networks use the ReLU activation and He's initialization <ref type="bibr">(He et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We generate 20 test tasks over 5 runs for the empirical evaluation, and we vary the values of ?? and L appearing in the bound (18) of Theorem 1. <ref type="figure" target="#fig_0">Figure 1</ref> shows that as ?? decreases or L increases, the norm of the prediction difference F MTL (X, X , Y ) ? F ANIL (X, X , Y ) 2 decreases correspondingly, which is in agreement with (18). More experimental details can be found in Appendix C.</p><p>Note that Theorem 1 is built on fully connected nets, thus it is not directly applicable to modern convolutional neural nets (ConvNets) with residual connections, max pooling, BatchNorm, and Dropout, which are commonly used in meta-learning practice. Hence, we perform another empirical study on modern ConvNets in Sec. 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Few-Shot Learning Benchmarks</head><p>We conduct experiments on a set of widely used benchmarks for few-shot image classification: mini-ImageNet, tiered-ImageNet, CIFAR-FS and FC100. The first two are derivatives of ImageNet <ref type="bibr" target="#b12">(Deng et al., 2009)</ref>, while the last two are derivatives of CIFAR-100 <ref type="bibr">(Krizhevsky, 2009</ref>  Feature Normalization Following a previous work on fewshot image classification <ref type="bibr" target="#b31">(Tian et al., 2020)</ref>, we normalize features (i.e., last hidden layer outputs) in the meta-test and meta-validations stages. Besides, we also find the feature normalization is effective to the training of MTL on most benchmarks 5 , which might be due to the effectiveness of feature normalization for representation learning .</p><p>Fine-Tuning for Task Adaptation In the meta-validation and meta-testing stages, following Sec. 3.4, we fine-tune a linear classifier on the outputs of the last hidden layer with the cross-entropy loss. We use the logistic regression classifier with 2 regularization from scikit-learn for the fine-tuning <ref type="bibr" target="#b23">(Pedregosa et al., 2011</ref>). An ablation study on the 2 regularization is provided in Appendix C.2.</p><p>Implementation Details Our implementation is built on the learn2learn 6 package <ref type="bibr" target="#b3">(Arnold et al., 2020)</ref>, which provides data loaders and other utilities for meta-learning in PyTorch <ref type="bibr" target="#b22">(Paszke et al., 2019)</ref>. We implement MTL on a multi-head version of ResNet-12. Notice that the number of distinct training tasks is combinatorial for 5-way classifica-5 It is effective on mini-ImageNet, tiered-ImageNet, and CIFAR-FS, while being ineffective on FC100. 6 http://learn2learn.net/ tion on the considered benchmarks, e.g., 64 5 = 7.6 ? 10 6 for mini-ImageNet and 351 5 = 4.3 ? 10 9 for tiered-ImageNet. Hence, due to memory constraints, we cannot construct separate heads for all tasks. Thus, we devise a memory-efficient implementation of the multi-head structure. For instance, on tiered-ImageNet with 351 training classes, we construct a 351-way linear classifier on top of the last hidden layer. Then, for each training task of 5 classes, we select the 5 corresponding row vectors in the weight matrix of the 351-way linear classifier, and merge them to obtain a 5-way linear classifier for this training task.</p><p>Empirical Results During meta-testing, we evaluate MTL over 3 runs with different random seeds, and report the mean accuracy with the 95% confidence interval in <ref type="table" target="#tab_3">Table 3</ref>. The accuracy for each run is computed as the mean accuracy over 2000 tasks randomly sampled from the test set. The model selection is made on the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance Comparison</head><p>In <ref type="table" target="#tab_3">Table 3</ref>, we compare MTL with a set of popular meta-learning algorithms on the four benchmarks, in the common setting of 5-way few-shot classification. Notice that MetaOptNet is a state-of-the-art GBML algorithm, and MTL is competitive against it on these benchmarks: across the 8 columns/settings of <ref type="table" target="#tab_3">Table 3</ref>, MTL is worse than MetaOptNet in 2 columns, comparable with MetaOptNet in 2 columns, and outperforms MetaOpt-Net in 4 columns. Therefore, we can conclude that MTL is competitive with the state-of-the-art of GBML algorithms on few-shot image classification benchmarks. Training Efficiency GBML algorithms are known to be computationally expensive due to the costly second-order bi-level optimization they generally take <ref type="bibr">(Hospedales et al., 2020)</ref>. In contrast, MTL uses first-order optimization, and as a result, the training of MTL is significantly more efficient.</p><p>To illustrate this more concretely, we compare the training cost of MTL against MetaOptNet on a AWS server with 4x Nvidia V100 GPU cards 7 . For MetaOptNet (Lee et al., 2019b), we directly run the official PyTorch code 8 with the optimal hyper-parameters 9 provided by the authors. Since the implementations of MetaOptNet and MTL are both written in PyTorch with the same network structure and similar data loaders (both adopting TorchVision dataset wrappers), we believe the efficiency comparison is fair. Note that the two ImageNet derivatives (i.e., mini-ImageNet of 7.2 GB and tiered-ImageNet of 29 GB) are much bigger than that of the two CIFAR-100 derivatives (i.e., CIFAR-FS of 336 MB and FC100 of 336 MB). It is more practically meaningful to reduce the training cost on big datasets like the ImageNet derivatives, thus we only perform the efficiency comparison on mini-ImageNet and tiered-ImageNet.</p><p>In <ref type="table" target="#tab_4">Table 4</ref>, we present the GPU hours for the training of MetaOptNet and MTL with optimal hyper-parameters on mini-ImageNet, showing that the training of MTL is 23x times faster compared with MetaOptNet. <ref type="figure" target="#fig_1">Figure 2</ref> shows the efficiency-accuracy tradeoff of MTL vs. MetaOptNet on tiered-Imagenet. The training of MetaOpt-Net takes 63 GPU hours, while MTL has various training costs depending on the batch size and the number of epochs. From <ref type="figure" target="#fig_1">Figure 2</ref> we can see that, even though MTL is only 3.6x faster when achieving the optimal test accuracy, we can train MTL with a smaller number of epochs or batch size, which reduces the training time at the cost of a small performance drop (? 2.2%). As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, while the training of MTL is 11x faster compared with MetaOpt-Net, its test accuracy (81.55%) can still match MetaOptNet (81.56%). <ref type="bibr">7</ref> The p3.8xlarge instance in AWS EC2: https://aws. amazon.com/ec2/instance-types/p3/ 8 https://github.com/kjunelee/MetaOptNet/ 9 The optimal hyperparameters of MetaOptNet for mini-ImageNet and tiered-Imagenet involve a large batch size that requires 4 GPUs. Remarks on the Empirical Results Traditionally, the training tasks and test tasks for MTL are the same. Our empirical results on few-shot learning reveal that, even as the test tasks are distinct from the training tasks, MTL can still be quite powerful. Recent theoretical studies on MTL show that the joint training of MTL over diverse tasks can learn representations useful for unseen tasks <ref type="bibr" target="#b32">(Tripuraneni et al., 2020;</ref><ref type="bibr">Du et al., 2021)</ref>, and our few-shot learning experiment supports these theories with positive empirical results. On the other hand, the MTL model we implemented is quite simple, which can be viewed as the original MTL proposal <ref type="bibr" target="#b11">(Caruana, 1997)</ref> with a new memory-efficient trick. It is likely that more advanced variants of MTL could achieve even better performance on few-shot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we take an important step towards bridging the gap between MTL and meta-learning, both theoretically and empirically. Theoretically, we show that MTL and gradientbased meta-learning (GBML) share the same optimization formulation. We then further prove that, with sufficiently wide neural networks, the learned predictors from both algorithms give similar predictions on unseen tasks, which implies that it is possible to achieve fast adaptation and efficient training simultaneously. Inspired by our theoretical findings, empirically, we develop a variant of MTL that allows adaptation to unseen tasks, and show that it is competitive against the state-of-the-art GBML algorithms over a set of few-shot learning benchmarks while being significantly more efficient. We believe our work contributes to opening a new path towards models that simultaneously allow efficient training and fast adaptation. The appendix mainly consists of three parts. In Section A we provide more detailed introduction to the set up of metalearning as well as neural tangent kernels that are missing from the main text due to page limit. In Section B we provide all the missing proofs of the lemmas and theorems presented in the main paper. In Section C we discuss in depth about the experiments in the paper. For the convenience of readers, we also provide a copy of the reference at the end of this appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. More on Meta-Learning and Neural Net Setup</head><p>In this section, we will provide more information on</p><p>? Appendix A.1: Query-support split of meta-learning.</p><p>? Appendix A.2: Unified framework for gradient-based meta-learning that optimizes all layers in the inner loop.</p><p>? Appendix A.3: NTK parameterization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Query-Support Split</head><p>Sec. 3.2 introduces meta-training in the setting without query-support split. In this section, we adopt the notation of Sec. 3.2, and describe meta-training in the setting with query-support split below.</p><p>The n labelled samples in each training task is divided into two sets, n q query samples and n s support samples, i.e., for i ? [N ], the i-th task consists of n q Query Samples &amp; Labels:</p><formula xml:id="formula_28">X q i ? R nq?d , Y q i ? R nqk n s Support Samples &amp; Labels: X s i ? R ns?d , Y s i ? R nqk</formula><p>The optimization objective of ANIL on the training data</p><formula xml:id="formula_29">{X q i , Y q i , X s i , Y s i } N i=1 is min ? L ANIL (?) := i?[N ] (? ? &lt;L (X q i ) w i , Y q i ) (19) s.t. w i = InnerLoop(w, ? ? &lt;L (X s i ), Y s i , ?, ?)<label>(20)</label></formula><p>It is clear that the InnerLoop operation is performed on support data (X s i , Y s i ), while the loss evaluation is on the query data (X q i , Y q i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Unified Framework for Gradient-Based Meta-Learning that Optimizes All Layers in the Inner Loop</head><p>For GBML algorithms that optimize all layers in the inner loop, their objectives can be summarized into the following unified framework. In contrast to (13), we have</p><formula xml:id="formula_30">min ? L GBML (?) min {?i} N i=1 i?[N ] f ?i (X i ), Y i + R(? i ) .<label>(21)</label></formula><p>Note that similar to (13), the parameters {? i } N i=1 in (21) are transient, in the sense that GBML algorithms do not explicitly save them during training. In contrast, ? contains all parameters to optimize in (21), and ? is optimized over GBML (?), which is obtained by plugging in the minimizer of {? i } N i=1 on the regularized loss. In other words, (21) is a bi-level optimization problem, with outer-loop optimization on network parameters ? and inner-loop optimization on the transient parameters</p><formula xml:id="formula_31">{? i } N i=1 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. NTK Parameterization</head><p>NTK parameterization is a neural net parameterization that can be used to provide theoretical analyses of neural net optimization and convergence <ref type="bibr">(Lee et al., 2019a;</ref><ref type="bibr" target="#b20">Xiao et al., 2020)</ref>. The training dynamics and predictions of NTKparameterized neural nets are the same as those of standard neural nets <ref type="bibr">(Lee et al., 2019a)</ref>, up to a width-dependent factor in the learning rate. In what follows, we take a single-head neural net as an example to describe the NTK parameterization. Notice that multi-head networks share the same parameterization with single-head networks, and the only difference is that N -head networks have N copies of the output heads (parameterized in the same way as the output heads of single-head networks).</p><p>In this paper, we consider a fully-connected feed-forward network with L layers. Each hidden layer has width l i , for i = 1, ..., L ? 1. The readout layer (i.e., output layer) has width l L = k. At each layer i, for arbitrary input x ? R d , we denote the pre-activation and post-activation functions by h i (x), z i (x) ? R li . The relations between layers in this network are</p><formula xml:id="formula_32">h i+1 = z i W i+1 + b i+1 z i+1 = ? h i+1 and W i ?,? = ? i ?? ? N (0, ?? ? li ) b i ? = ? i ? ? N (0, ? b ) ,<label>(22)</label></formula><p>where W i+1 ? R li?li+1 and b i+1 ? R li+1 are the weight and bias of the layer, ? l ?? and b l ? are trainable variables drawn i.i.d. from zero-mean Gaussian distributions at initialization (i.e., </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proof</head><p>We present all the missing proofs from the main paper, summarized as follows: Shorthand. As described in Sec. 3.4, for both MTL and ANIL, we randomly initialize a test head w test for fine-tuning in the test phase. Now, we define the following shorthand for convenience.</p><p>? ? test = {? &lt;L , w test }: a parameter set including first L ? 1 layers' parameters of ? and the test head w test . ?? test = {? &lt;L , w test }: a parameter set including first L ? 1 layers' parameters of ? and the test head w test .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Global Convergence of ANIL and MTL with Over-parameterized Deep Neural Nets</head><p>Throughout the paper, we use the squared loss as the objective function of training neural nets: (?, y) := 1 2 ? ? y 2 2 . To ease the presentation, we define the following meta-output functions. Definition 2 (Meta-Output Functions). On any task T = (X, Y, X , Y ), for the given adaptation steps ? , we define the meta-output function as</p><formula xml:id="formula_33">F ? ? (X, X , Y ) = f ? test (X) ? R nk (23)</formula><p>where the adapted parameters ? test is obtained as follows: use ? as the initial parameter and update it by ? steps of gradient descent on support samples and labels (X , Y ), with learning rate ? and loss function . Mathematically, ?j = 0, ..., ? ? 1, we have</p><formula xml:id="formula_34">? = ? 0 , ? test = ? ? , and ? j+1 = ? j ? ?? ?j (f ?j (X ), Y )<label>(24)</label></formula><p>Shorthand To make the notation uncluttered, we define some shorthand for the meta-output function,</p><formula xml:id="formula_35">? F ? ? (X , X , Y) (F ? ? (X i , X i , Y i )) N i=1</formula><p>: the concatenation of meta-outputs on all training tasks. ? F ? t F ? ?t : shorthand for the meta-output function with parameters ? t at training time t.</p><p>ANIL Loss With the squared loss function, the training objective of ANIL is expressed as</p><formula xml:id="formula_36">L ANIL (?) = N i=1 (F ? ? (X i , X i , Y i ), Y i ) = 1 2 N i=1 F ? ? (X i , X i , Y i ) ? Y i 2 2 = 1 2 F ? ? (X , X , Y) ? Y 2 2 (25)</formula><p>MTL Loss With the squared loss function, the objective of MTL is</p><formula xml:id="formula_37">L MTL (?) = N i=1 (f?(X i , i), Y i ) = 1 2 N i=1 f? (X i , i) ? Y i 2 2 = 1 2 f? (X ) ? Y 2 2<label>(26)</label></formula><p>where we define the notationf?(X ) to be vec({f?</p><formula xml:id="formula_38">(X i , i)} N i=1 ).</formula><p>Tangent Kernels Now, we define tangent kernels for MTL and ANIL, following . Denote h as the minimum width across hidden layers, i.e., h = min l?[L?1] h l . Then, the tangent kernels of MTL and ANIL are defined as</p><formula xml:id="formula_39">? MTL = lim h?? ?? 0f?0 (X ) ? ?? 0f?0 (X ) (27) ? ANIL = lim h?? ? ?0 F ? ?0 (X , X , Y) ? ? ?0 F ? ?0 (X , X , Y)<label>(28)</label></formula><p>Notice that by , we know both kernels are deterministic positive-definite matrices, independent of the initializations ? 0 and? 0 .</p><p>Next, we present the following theorem that characterizes the global convergence of the above two algorithms on overparametrized neural networks. Theorem 3 (Global Convergence of ANIL and MTL with Over-parameterized Deep Neural Nets). Define</p><formula xml:id="formula_40">? 0 = min 2 ? min (? MTL ) + ? max (? ANIL ) , 2 ? min (? MTL ) + ? max (? ANIL )</formula><p>.</p><p>For arbitrarily small ? &gt; 0, there exists constants R, ? 0 , h * &gt; 0 such that for networks with width greater than h * , running gradient descent on L MTL and L ANIL with learning rate ? &gt; ? 0 and inner-loop learning rate ? &lt; ? 0 , the following bounds on training losses hold true with probability at least 1 ? ? over random initialization,</p><formula xml:id="formula_41">L ANIL (? t ) ? 1 ? 1 3 ? 0 ? ? min (? ANIL ) 2t R (29) L MTL (? t ) ? 1 ? 1 3 ? 0 ? ? min (? MTL ) 2t R (30)</formula><p>where t ? N is the number of training steps. Furthermore, the displacement of the parameters during the training process can be bounded by</p><formula xml:id="formula_42">sup t?0 1 ? h ? t ? ? 0 2 = O(h ? 1 2 ), sup t?0 1 ? h ? t ?? 0 2 = O(h ? 1 2 )<label>(31)</label></formula><p>Remarks. Notice the bounds in <ref type="formula" target="#formula_0">(31)</ref>  </p><formula xml:id="formula_43">sup t?0 ? t ? ? 0 2 = O(h ? 1 2 ), sup t?0 ? t ?? 0 2 = O(h ? 1 2 ),<label>(32)</label></formula><p>indicating a closeness between the initial and trained parameters as the network width h is large.</p><p>Proof. For ANIL, the global convergence can be straightforwardly obtained by following the same steps of Theorem 4 of , which proves the global convergence for MAML in the same setting 10 .</p><p>For MTL, it can be viewed as a variant of MAML with multi-head neural nets and inner-loop learning rate ? = 0, since it only has the outer-loop optimization. Then, the global convergence of MTL can also be straightforwardly obtained by following the proof steps of Theorem 4 from .</p><p>Linearization at Large Width. The following corollary provides us a useful toolkit to analyze the training dynamics of both ANIL and MTL in the over-parametrization regime, which is adopted and rephrased from  and <ref type="bibr">Lee et al. (2019a)</ref>.</p><p>Corollary 3.1 (Linearized (Meta) Output Functions). For arbitrarily small ? &gt; 0, there exists h * &gt; 0 s.t. as long as the network width h is greater than h * , during the training of ANIL and MTL, with probability at least 1 ? ? over random initialization, the network parameters stay in the neighbourhood of the initialization s.t.</p><formula xml:id="formula_44">? t ? {? : ? ? ? 0 2 ? O(1/h 2 )} or? t ? {? : ? ?? 0 2 ? O(1/h 2 )}, where ? 0 = {? &lt;L 0 , w 0 } and? 0 = {? &lt;L 0 } ? {? (i) 0 } i?[N ]</formula><p>are the initial parameters of networks trained by ANIL and MTL, respectively. Then, for any network trained by ANIL, its output on any x ? R d is effectively linearized, i.e.,</p><formula xml:id="formula_45">f ? (x) = f ?0 (x) + ? ?0 f ?0 (x)(? ? ? 0 ) + O( 1 ? h )<label>(33)</label></formula><p>Similarly, for any network trained by MTL, the output of the multi-head neural net on x with head index i ? [N ] is characterized byf?</p><formula xml:id="formula_46">(x, i) =f? 0 (x, i) + ?? 0f?0 (x, i)(? ?? 0 ) + O( 1 ? h )<label>(34)</label></formula><p>Besides, the meta-output function is also effectively linearized, i.e., for any task T = (X, Y, X , Y ),</p><formula xml:id="formula_47">F ? ? (X, X , Y ) = F ? ?0 (X, X , Y ) + ? ?0 F ? ?0 (X, X , Y )(? ? ? 0 ) + O( 1 ? h ),<label>(35)</label></formula><p>where F ? ?0 (X, X , Y ) can be expressed as</p><formula xml:id="formula_48">F ? ?0 (X, X , Y ) = f ?0 (X) +K w0 (X, X )K ?1 w0 (X , X ) I ? e ??Kw 0 (X ,X )? [Y ? f ?0 (X )] + O( 1 ? h ),<label>(36)</label></formula><p>and the gradient ? ?0 F ? ?0 (X, X , Y ) as 11</p><formula xml:id="formula_49">? ?0 F ? ?0 (X, X , Y ) = ? ?0 f ?0 (X) ?K w0 (X, X )K ?1 w0 (X , X ) I ? e ??Kw 0 (X ,X )? ? ?0 f ?0 (X ) + O( 1 ? h ),<label>(37)</label></formula><p>withK w0 defined asK</p><formula xml:id="formula_50">w0 (?, * ) = ? w f ?0 (?) ? ? w f ?0 ( * )</formula><p>Remarks. One can replace ? 0 in (35) with {? &lt;L 0 , w test } or {? &lt;L 0 , w test }, and similar results apply.</p><p>Proof. Notice that the proof of Theorem 3 above is based on Theorem 4 of , which also proves that the trained parameters stay in the neighborhood of the initialization with radius of O( 1 ? h ). Hence, following the proof steps of Theorem 4 of , one can also straightforwardly prove the same result for ANIL and MTL.</p><p>With the global convergence and the neighborhood results above, we can directly invoke Theorem H.1 of <ref type="bibr">Lee et al. (2019a)</ref>, and obtain <ref type="formula" target="#formula_45">(33)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Training Dynamics of MTL and ANIL</head><p>Definition 4 (Empirical Tangent Kernels of ANIL and MTL). We define the following empirical tangent kernels of ANIL and MTL, in a similar way to <ref type="bibr">Lee et al., 2019a)</ref>:</p><formula xml:id="formula_51">? ANIL (X , X ) = ? ?0 F ? ?0 (X , X , Y) ? ? ?0 F ? ?0 (X , X , Y) ? R N n?N n (38) ? MTL (X , X ) = ? ?0f? 0 (X ) ? ? ?0f? 0 (X ) ? R N n?N n<label>(39)</label></formula><p>Shorthand. To simplify expressions, we define the following shorthand. For any kernel function?, learning rate ? and optimization steps t, we have</p><formula xml:id="formula_52">T ?,t ? (?) =? ?1 (?, ?) I ? e ???(?,?)t<label>(40)</label></formula><p>Lemma 2 (ANIL and MTL in the Linearization Regime). With linearized output functions shown in Corollary 3.1, the training dynamics of ANIL and MTL under gradient descent on squared losses can be characterized by analytically solvable ODEs, giving rise to the solutions:</p><p>? ANIL. Trained parameters at time t:</p><formula xml:id="formula_53">? t = ? 0 + ? ?0 F ? ?0 (X , X , Y) ? ?1 ANIL (X , X ) I ? e ??? ANIL (X ,X )t Y ? F ? ?0 (X , X , Y) + O( 1 ? h )<label>(41)</label></formula><p>Prediction on any test task T = (X, Y, X , Y ) with adaptation steps? (i.e., we take the hidden layers of the trained network ? &lt;L and append a randomly initialized head w test to fine-tune):</p><formula xml:id="formula_54">F? ? test t (X, X , Y ) (42) = F? ? test 0 (X, X , Y ) + ? ? &lt;L 0 F? ? test 0 (X, X , Y )? ? &lt;L 0 F ? ?0 (X , X , Y) T ?,t ? ANIL (X ) Y ? F ? ?0 (X , X , Y) + O( 1 ? h ) where? test t = {? &lt;L t , w test } and? test 0 = {? &lt;L 0 , w test }. ? MTL.</formula><p>Trained parameters:?</p><formula xml:id="formula_55">t =? 0 + ?? 0f?0 (X ) T ?,t ? MTL (X ) Y ?f? 0 (X ) + O( 1 ? h )<label>(43)</label></formula><p>Prediction on test task T = (X, Y, X , Y ) with adaptation steps? (i.e., we take the hidden layers of the trained network? &lt;L and append a randomly initialized head w test to fine-tune):</p><formula xml:id="formula_56">F? ? test t (X, X , Y ) = F? ? test 0 (X, X , Y ) + ??&lt;L 0 F? ? test 0 (X, X , Y )??&lt;L 0f? 0 (X ) T ?,t ? MTL (X ) Y ?f? 0 (X ) + O( 1 ? h )<label>(44)</label></formula><formula xml:id="formula_57">where? test t = {? &lt;L t , w test },? test 0 = {? &lt;L 0 , w test }.</formula><p>Proof. Similar to Sec. ? Training dynamics of ANIL.</p><formula xml:id="formula_58">d? t dt = ??? ?0 F ?0 (X , X , Y) (F ?t (X , X , Y) ? Y) (45) dF ?t (X , X , Y) dt = ??? ANIL (X , X ) (F ?t (X , X , Y) ? Y)<label>(46)</label></formula><p>Solving the set of ODEs, we obtain the solution to ? t as ? Training dynamics of MTL.</p><formula xml:id="formula_59">? t = ? 0 ? ? ?0 F ?0 (X , X , Y) ? ANIL (X , X ) ?1 I ? e ??? ANIL (X ,X )t (F ?0 (X , X , Y) ? Y)<label>(47)</label></formula><formula xml:id="formula_60">d? t dt = ???? 0f?0 (X ) f ?t (X ) ? Y (48) df ?t (X ) dt = ??? MTL (X , X ) f ?0 (X ) ? Y<label>(49)</label></formula><p>Solving the set of ODEs, we obtain the solution to? t a?  <ref type="formula" target="#formula_46">(34)</ref> and <ref type="formula" target="#formula_7">(35)</ref> to obtain the outputs of trained ANIL and MTL models. Notice that during test, the predictions of ANIL and MTL are obtained from a fine-tuned test head that are randomly initialized (see Sec. 3.4 for details). Thus, we need to take care of the test heads when plugging trained parameters into the linearized functions. Specifically, for an arbitrary test task T = (X, Y, X , Y ), the test predictions of ANIL and MTL are derived below.</p><formula xml:id="formula_61">? t =? 0 ? ?? 0f?0 (X ) ? MTL (X , X ) ?1 I ? e ??? MTL (X ,X )t f ?t (X ) ? Y<label>(50)</label></formula><p>? Test predictions of ANIL. For notational simplicity, we defin?</p><formula xml:id="formula_62">K t (?, * ) = ? wtest f ? test t (?)? wtest f ? test t ( * )</formula><p>Then, since the fine-tuning is on the test head w test , following the Sec. 2.3.1. of Lee et al. (2019a), we know</p><formula xml:id="formula_63">F? ? test t (X, X , Y ) = f ? test t (X) +K t (X, X )T ?,? Kt (X ) Y ? f ? test t (X ) + O( 1 ? h ) (51) where f ? test t (X) (52) = f ? test 0 (X) + ? ? test 0 f ? test 0 (X)(? test t ? ? test 0 ) + O( 1 ? h ) = f ? test 0 (X) + ? ? &lt;L 0 f ? test 0 (X)(? &lt;L t ? ? &lt;L 0 ) + ? wtest f ? test 0 (X)(w test ? w test ) + O( 1 ? h ) = f ? test 0 (X) + ? ? &lt;L 0 f ? test 0 (X)(? &lt;L t ? ? &lt;L 0 ) + O( 1 ? h ) = f ? test 0 (X) + ? ? &lt;L 0 f ? test 0 (X)? ? &lt;L 0 F ?0 (X , X , Y) ? ANIL (X , X ) ?1 I ? e ??? ANIL (X ,X )t (Y ? F ?0 (X , X , Y)) + O( 1 ? h ) = f ? test 0 (X) + ? ? &lt;L 0 f ? test 0 (X)? ? &lt;L 0 F ?0 (X , X , Y) T ?,t ? ANIL (X ) (Y ? F ?0 (X , X , Y)) + O( 1 ? h )</formula><p>and</p><formula xml:id="formula_64">? wtest f ? test t (X) = ? wtest f ? test 0 (X) + O( 1 ? h )<label>(53)</label></formula><p>Pluging in everything, we have</p><formula xml:id="formula_65">F? ? test t (X, X , Y ) (54) = f ? test 0 (X) + ? ? &lt;L 0 f ? test 0 (X)? ? &lt;L 0 F ?0 (X , X , Y) T ?,t ? ANIL (X ) (Y ? F ?0 (X , X , Y)) +K 0 (X, X )T ?,? K0 (X ) Y ? f ? test t (X ) + O( 1 ? h ) = f ? test 0 (X) +K 0 (X, X )T ?,? K0 (X )(Y ? f ? test 0 (X )) + ? ? &lt;L 0 f ? test 0 (X) ?K 0 (X, X )T ?,? K0 (X )? ? &lt;L 0 f ? test 0 (X ) ? ? &lt;L 0 F ?0 (X , X , Y) T ?,t ? ANIL (X ) (Y ? F ?0 (X , X , Y)) + O( 1 ? h ) = F? ? test 0 (X, X , Y ) + ? ? &lt;L 0 F? ? test 0 (X, X , Y )? ? &lt;L 0 F ? ?0 (X , X , Y) T ?,t ? ANIL (X ) Y ? F ? ?0 (X , X , Y) + O( 1 ? h )</formula><p>? Test prediction of MTL. Following the derivation for the test prediction of ANIL above, one can straightforwardly derive that</p><formula xml:id="formula_66">F? ? test t (X, X , Y ) = F? ? test 0 (X, X , Y ) + ??&lt;L 0 F? ? test 0 (X, X , Y )??&lt;L 0f? 0 (X ) T ?,t ? MTL (X ) Y ?f? 0 (X ) + O( 1 ? h )</formula><p>B.3. Derivation of Kernels and Outputs for ANIL and MTL.</p><p>Notation 1 (NTK and NNGP). We denote</p><p>? ?(?, * ): kernel function of Neural Tangent Kernel (NTK).</p><p>? K(?, * ): kernel function of Neural Network Gaussian Process (NNGP). <ref type="bibr">Lee et al. (2019a)</ref> shows that as the network width h approaches infinity, for parameter initialization ? 0 = {? &lt;L 0 , w 0 }, we have the following equivalence relations,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Equivalence to Kernels</head><formula xml:id="formula_67">? ?0 f ?0 (?)? ?0 f ?0 ( * ) = ?(?, * ) (55) ? w f ?0 (?)? ?0 f w ( * ) = K(?, * )<label>(56)</label></formula><p>Lemma 3 (ANIL and MTL Kernels). As the width of neural nets increases to infinity, i.e., h ? ?, we define the following kernels for ANIL and MTL, and they converge to corresponding analytical expressions shown below.</p><p>? ANIL kernels.</p><formula xml:id="formula_68">? ANIL (X , X ) = ? ?0 F ? ?0 (X , X , Y) ? ? ?0 F ? ?0 (X , X , Y) is a block matrix of N ? N blocks. ?i, j ? [N ], its (i, j)-th block is [? ANIL (X , X )] ij = e ??K(Xi,Xi)? ?(X i , X j )e ??K(Xj ,Xj )? , ? ANIL ((X, X ,? ), X ) = ? ? &lt;L 0 F? ? test 0 (X, X , Y )? ? &lt;L 0 F ? ?0 (X , X , Y) is a block matrix of 1 ? N blocks, with the (1, j)-th block as [? ANIL ((X, X ,? ), X )] 1j = ?(X, X j ) ? K(X, X )T? K (X )?(X , X j ) e ??K(Xj ,Xj )? ? MTL Kernels. ? MTL (X , X ) = ?? 0f?0 (X ) ? ?? 0f?0 (X ) is also a block matrix of N ? N blocks. ?i, j ? [N ], its (i, j)-th block is [? MTL (X , X )] ij = ?(X i , X j ) ? 1[i = j]K(X i , X j ), ? MTL ((X, X ,? ), X ) = ??&lt;L 0 F? ? test 0 (X, X , Y )??&lt;L 0f? 0 (X ) is a block matrix of 1?N blocks, with the (1, j)-th block as [? MTL ((X, X ,? ), X )] 1j = ?(X, X j ) ? K(X, X j ) ? K(X, X )T? K (X ) ?(X , X j ) ? K(X , X j ) (57) = ?(X, X j ) ? K(X, X )T? K (X )?(X , X j ) ? K(X, X )e ??K(X ,X )? K(X , X j )</formula><p>Proof. The proof is presented in the same structure as the lemma statement above.</p><p>? ANIL Kernels ? ANIL (X , X ). With (37), we know</p><formula xml:id="formula_69">? ?0 F ? ?0 (X , X , Y) = ? ?0 F ? ?0 (X i , X i , Y i ) N i=1 = ? ?0 f ?0 (X i ) ? K(X i , X i )K ?1 (X i , X i ) I ? e ??K(Xi,Xi)? ? ?0 f ?0 (X i ) N i=1 = e ??K(Xi,Xi)? ? ?0 f ?0 (X i ) N i=1 (58) Thus, the (i, j)-th block of ? ANIL (X , X ) = ? ?0 F ? ?0 (X , X , Y) ? ? ?0 F ? ?0 (X , X , Y) is [? ANIL (X , X )] ij = ? ?0 F ? ?0 (X i , X i , Y i )? ?0 F ? ?0 (X j , X j , Y j ) = e ??K(Xi,Xi)? ? ?0 f ?0 (X i )f ?0 (X j ) e ??K(Xj ,Xj )? = e ??K(Xi,Xi)? ?(X i , X j )e ??K(Xj ,Xj )?<label>(59)</label></formula><p>Then, the whole matrix can be expressed as</p><formula xml:id="formula_70">? ANIL (X , X ) = diag {e ??K(Xi,Xi)? } N i=1 ? ?(X , X ) ? diag {e ??K(Xj ,Xj )? } N j=1<label>(60)</label></formula><p>where diag {e ??K(Xi,Xi)? } N i=1 is a diagonal block matrix with the i-th block as e ??K(Xi,Xi)? . ? ANIL ((X, X ,? ), X ). With (37), we can derive that</p><formula xml:id="formula_71">[? ANIL ((X, X ,? ), X )] 1j = ? ? &lt;L 0 F? ? test 0 (X, X , Y )? ? &lt;L 0 F ? ?0 (X j , X j , Y j ) = ? ? &lt;L 0 f ? test 0 (X) ? K(X, X )K ?1 (X , X ) I ? e ??K(X ,X )? ? ? &lt;L 0 f ? &lt;L 0 (X ) ? ? ? &lt;L 0 f ?0 (X j ) ? K(X j , X j )K ?1 (X j , X j ) I ? e ??K(Xj ,Xj )? ? ? &lt;L 0 f ?0 (X j ) = ? ? &lt;L 0 f ? test 0 (X) ? K(X, X )K ?1 (X , X ) I ? e ??K(X ,X )? ? ? &lt;L 0 f ?0 (X ) ? ? ? &lt;L 0 f ?0 (X j ) e ??K(Xj ,Xj )? = (?(X, X j ) ? K(X, X j )) ? K(X, X )K ?1 (X , X ) I ? e ??K(X ,X )? (?(X , X j ) ? K(X , X j )) e ??K(Xj ,Xj )? = (?(X, X j ) ? K(X, X j )) ? K(X, X )T ?,? K (X ) (?(X , X j ) ? K(X , X j )) e ??K(Xj ,Xj )?<label>(61)</label></formula><p>where we used the equivalence</p><formula xml:id="formula_72">? ? &lt;L 0 f ? test 0 (?) ? ? ? &lt;L 0 f ?0 ( * ) = ?(?, * ) ? K(?, * )<label>(62)</label></formula><p>in the infinite width limit at initialization. ? MTL ? MTL (X , X ) = ?? 0f?0 (X ) ? ?? 0f?0 (X ) . Notice that for any input with head index i, we have</p><formula xml:id="formula_73">?? 0f?0 (?, i) = ??&lt;L 0f? 0 (?, i) + N +1 j=1 ??(j)f? 0 (?, i) = ??&lt;L 0f? 0 (?, i) + ??(i)f? 0 (?, i)<label>(63)</label></formula><p>since for j = i, we have ??(j)f? 0 (x, i) = 0 based on the multi-head structure. Thus, we can write down the (i, j)-th block of ? MTL (X , X ) as</p><formula xml:id="formula_74">[? MTL (X , X )] ij = ?? 0f?0 (X i , i)?? 0f?0 (X j , j) = ??&lt;L 0f? 0 (X i , i)??&lt;L 0f? 0 (X j , j) + ??(i)f? 0 (X i , i)??(j)f? 0 (X j , j)</formula><p>Note that for i = j, we have ??(i)f? 0 (X i , i)??(j)f? 0 (X j , j) = 0, since? (i) and? (j) are in different dimensions of?. Thus, * as i = j, we have 12</p><formula xml:id="formula_75">[? MTL (X , X )] ij = ??&lt;L 0f? 0 (X i , i)??&lt;L 0f? 0 (X j , j) = ?(X i , X j ) ? K(X i , X j ) * as i = j, we have [? MTL (X , X )] ii = ??&lt;L 0f? 0 (X i , i)??&lt;L 0f? 0 (X i , i) + ??(i)f? 0 (X i , i)??(i)f? 0 (X i , i) = ?(X i , X i ) In conclusion, for i, j ? [N ], we have [? MTL (X , X )] ij = ?(X i , X j ) ? 1[i = j]K(X i , X j ) Thus, ? MTL (X , X ) = ?(X , X ) ? K(X , X ) + diag {K(X i , X i )} N i=1<label>(64)</label></formula><p>? ? MTL ((X, X ,? ), X ) = ??&lt;L 0F? ?0 (X, X , Y )??&lt;L 0f? 0 (X ) . Based on (63), following (61), we can express the (1, j)-th block of ? MTL ((X, X ,? ), X ) as</p><formula xml:id="formula_76">[? MTL ((X, X ,? ), X )] 1j = ??&lt;L 0 F? ? test 0 (X, X , Y )??&lt;L 0f? 0 (X ) = ??&lt;L 0 f? test (X) ? K(X, X )K ?1 (X , X ) I ? e ??K(X ,X )? ??&lt;L 0 f? test (X ) ? ??&lt;L 0f? 0 (X j , j) = ??&lt;L 0 f? test (X)??&lt;L 0f? 0 (X j , j) ? K(X, X )K ?1 (X , X ) I ? e ??K(X ,X )? ??&lt;L 0 f? test (X )??&lt;L 0f? 0 (X j , j) = ?(X, X j ) ? K(X, X j ) ? K(X, X )K ?1 (X , X ) I ? e ??K(X ,X )? ?(X , X j ) ? K(X , X j ) = ?(X, X j ) ? K(X, X )T? K (X )?(X , X j ) ? K(X, X )K ?1 (X , X )e ??K(X ,X )? K(X , X j )<label>(65)</label></formula><p>Remarks. Notice that <ref type="formula" target="#formula_0">(61)</ref> and <ref type="formula" target="#formula_7">(65)</ref> indicate the following relation:</p><formula xml:id="formula_77">[? ANIL ((X, X ,? ), X )] 1j = [? MTL ((X, X ,? ), X )] 1j e ??K(Xj ,Xj )?</formula><p>Furthermore, it is straightforward to show that</p><formula xml:id="formula_78">? ANIL ((X, X ,? ), X ) = ? MTL ((X, X ,? ), X ) ? diag {e ??K(Xj ,Xj )? } N j=1<label>(66)</label></formula><p>where diag {e ??K(Xj ,Xj )? } N j=1 is a diagonal block matrix with the j-th block as e ??K(Xj ,Xj )? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3.1. PROOF OF LEMMA 1</head><p>Now, we can prove Lemma 1 shown in Sec. 4.3, by leveraging Lemma 2 and Lemma 3 that we just proved. In particular, without loss of generality, following <ref type="bibr" target="#b4">Arora et al. (2019)</ref>, we assume the outputs of randomly initialized networks have a much smaller magnitude compared with the magnitude of training labels such that f ?0 (x) 2 ? y 2 ? O(h ? 1 2 ). Notice this can be always achieved by choosing smaller initialization scale or scaling down the neural net output <ref type="bibr" target="#b4">(Arora et al., 2019)</ref>, without any effect on the training dynamics and the predictions, up to a width-dependent factor on the learning rate. Below, we present the steps of the proof in detail.</p><p>Proof of Lemma 1. Plugging the kernels expressions derived by Lemma 3 into <ref type="formula">(42)</ref> and <ref type="formula" target="#formula_56">(44)</ref>, and combining with the fact that lim h??Kw0 ? K (proved by Corollary 1 of Lee et al. <ref type="formula" target="#formula_0">(2019a)</ref>), we obtain the expressions of (16) and <ref type="formula" target="#formula_0">(15)</ref> in Lemma 1 in the infinite width limit. Notice that we consider sufficiently large width h, then the discrepancy between the infinite-width kernels and their finite-width counter-parts (i.e., the finite-width correction) is bounded by O( 1 ? h ) with arbitrarily large probability, indicated by Theorem 1 of <ref type="bibr">Hanin &amp; Nica (2020)</ref>. Thus, the finite-width correction terms are absorbed into the O( 1 ? h ) error terms in <ref type="formula">(42)</ref> and (44).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3.2. DISCREPANCY BETWEEN PREDICTIONS OF ANIL AND MTL</head><p>Based on (60), (64), and (66), for small ?? , the discrepancy between ANIL and MTL predictions can be written as (Note: we consider neural nets trained under ANIL and MTL for infinite time t = ?, then take their parameters ? ? and? ? for test on any task T = (X, Y, X , Y )), <ref type="bibr">Remarks. (67)</ref> indicates that for small ?? , the discrepancy between ANIL's and MTL's test predictions is determined by</p><formula xml:id="formula_79">F ANIL (X, X , Y ) ? F MTL (X, X , Y ) = F ? test ? (X, X , Y ) ? F? test ? (X, X , Y ) = ? ANIL ((X, X ,? ), X )? ?1 ANIL (X , X ) ? ? MTL ((X, X ,? ), X )? ?1 MTL (X , X ) Y ? ? ANIL ((X, X ,? ), X )? ?1 ANIL (X , X ) =O(?? ?max(K)) G ? (X , X , Y ) +O( 1 ? h ) = ? MTL ((X, X ,? ), X ) ? diag {e ??K(Xj ,Xj )? } N j=1 diag {e ??K(Xi,Xi)? } N i=1 ?1 ?(X , X ) ?1 diag {e ??K(Xi,Xi)? } N i=1 ?1 ? ? MTL ((X, X ,? ), X )? ?1 MTL (X , X ) Y + O(?? ) + O( 1 ? h ) = ? MTL ((X, X ,? ), X ) ?(X , X ) ?1 diag {e ??K(Xi,Xi)? } N i=1 ?1 ? ? ?1 MTL (X , X ) Y + O(?? ) + O( 1 ? h ) = ? MTL ((X, X ,? ), X ) ?(X , X ) ?1 diag {e ??K(Xi,Xi)? } N i=1 ?1 =I+O(?? ?max(K)) ?? ?1 MTL (X , X ) Y + O(?? ? max (K)) + O( 1 ? h ) = ? MTL ((X, X ,? ), X ) ?(X , X ) ?1 ? ? ?1 MTL (X , X ) Y + O(?? ? max (K)) + O( 1 ? h ) (67) where ? max (K) max {? max (K(X i , X i ))} N i=1 .</formula><formula xml:id="formula_80">?(X , X ) ?1 ? ? ?1 MTL (X , X ).<label>(68)</label></formula><p>Thus, if this difference vanishes in some limit, ANIL and MTL will output almost the same predictions on any test task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4. Kernel Structures for Deep ReLU Nets</head><p>Setup. As described by Sec. 4.3, we focus on networks that adopt ReLU activation and He's initialization, and we consider the inputs are normalized to have unit variance, without loss of generality. Besides, we also assume any pair of samples in the training set are distinct.</p><p>NTK and NNGP Kernel Structures. <ref type="bibr" target="#b20">Xiao et al. (2020)</ref> shows that for ReLU networks with He's initialization and unit-variance inputs, the corresponding NTK and NNGP kernels have some special structures. Specifically, at large depth, the spectra of these kernels can be characterized explicitly, as shown by Lemma 4 below, which is adopted and rephrased from the Appendix C.1 of <ref type="bibr" target="#b20">Xiao et al. (2020)</ref>.</p><p>Lemma 4 (Kernel Structures of NTK and NNGP). For sufficiently large depth L, NTK and NNGP kernels have the following expressions 13 (Note: we use the superscript (L) to mark the kernels' dependence on the depth L)</p><formula xml:id="formula_81">? (L) (X , X ) = L 1 4 1 N n 1 N n + 3 4 I + A (L) X ,X<label>(69)</label></formula><formula xml:id="formula_82">K (L) (X , X ) = 1 N n 1 N n + 1 L 2 B (L) X ,X<label>(70)</label></formula><p>where A</p><formula xml:id="formula_83">(L) X ,X , B<label>(L)</label></formula><p>X ,X ? R N n?N n is a symmetric matrix with elements of O(1).</p><p>The eigenvalues of ? (L) (X , X ) and K (L) (X , X ) are all positive since ? and K are guaranteed to be positive definite, and these eigenvalues can be characterized as</p><formula xml:id="formula_84">? max (?(X , X )) = N n+3 4 L + O(1) ? bulk (?(X , X )) = 3 4 L + O(1) ? max (K(X , X )) = N n + O( 1 L 2 ) ? bulk (K(X , X )) = O( 1 L 2 )<label>(71)</label></formula><p>where ? bulk (?) denotes the eigenvalues besides the largest eigenvalue.</p><p>Discrepancy between Kernel Inverses. As shown by Appendix B.3.2, the discrepancy between the predictions of ANIL and MTL is controlled by (68), i.e., ? ?1 (X , X ) ? ? ?1 MTL (X , X ). In the lemma below, we study (68) in the setting of ReLU nets with He's initialization, and prove a bound over the operator norm of (68).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lemma 5 (Discrepancy between Kernel Inverses). There exists L</head><formula xml:id="formula_85">* ? N + s.t. for L ? L * , ? ? ? ? ? ? max ? (L) (X , X ) O(N nL) ? 2 ? (L) (X , X ) 1 N n 1 N n ? (L) (X , X )1 N n O(N nL) ? 2 ? (L) (X , X ) ? max ? (L) (X , X ) ? O(L) ? ? max K (L) (X , X )<label>(72)</label></formula><p>where ? 2 (?) denotes the second largest eigenvalue. Then, we have</p><formula xml:id="formula_86">?(X , X ) ?1 ? ? ?1 MTL (X , X ) op ? O( 1 L 2 )<label>(73)</label></formula><p>Proof. From <ref type="formula" target="#formula_75">(64)</ref>, we know (Note: we omit the superscript (L) for simplicity in this proof)</p><formula xml:id="formula_87">? MTL (X , X ) = ?(X , X ) ? K(X , X ) + diag {K(X i , X i )} N i=1 = ?(X , X ) ? K(X , X ) where we denote K(X , X ) = K(X , X ) + diag {K(X i , X i )} N i=1</formula><p>for simplicity. Case I: n = 1.</p><p>In this case, obviously, for each i ? [N ], we have K(X i , X i ) = 1 + O( 1 L 2 ) ? R. We can define a perturbed NNGP matrix as</p><formula xml:id="formula_88">K(X , X ) = K(X , X ) ? diag {K(X i , X i )} N i=1 (74) = 1 N 1 N ? I + 1 L 2 B (L) X ,X<label>(75)</label></formula><p>13 Notice that we use the little-o notation here: f (x) = o(g(x)) indicates that g(x) grows much faster than f (x). Thus the o(?) terms are negligible here.</p><p>where we define B</p><formula xml:id="formula_89">(L) X ,X = B (L) X ,X ? diag {K(X i , X i )} N i=1 ? I , i.e., B (L) X ,X with the O( 1 L 2 ) terms from diag {K(X i , X i )} N i=1</formula><p>. For convenience, let us define a perturbed NTK matrix as ?(X , X ) = ?(X , X ) ? K(X , X ) ? 1 N 1 N = ?(X , X )</p><formula xml:id="formula_90">+ I ? 1 L 2 B (L) X ,X .<label>(76)</label></formula><p>Obviously, we have</p><formula xml:id="formula_91">?(X , X ) ?1 ? ? ?1 MTL (X , X ) op = ?(X , X ) ?1 ? ? ?1 (X , X ) + ? ?1 (X , X ) ? ? ?1 MTL (X , X ) op ? ?(X , X ) ?1 ? ? ?1 (X , X ) op + ? ?1 (X , X ) ? ? ?1 MTL (X , X ) op<label>(77)</label></formula><p>Thus, we can prove (73) by providing bounds for ?(X , X ) ?1 ? ? ?1 (X , X ) op and ? ?1 (X , X ) ? ? ?1 (X , X ) op separately.</p><p>? Bound ? ?1 MTL ? ? ?1 (X , X ) op . By the Woodbury identity, we have</p><formula xml:id="formula_92">? ?1 MTL (X , X ) = ?(X , X ) ? K(X , X ) ?1 = ?(X ,X ) ?(X , X ) + I ? 1 L 2 B (L) X ,X ? o( 1 L 2 ) ? 1 N 1 N ?1 = ?(X , X ) ? 1 N 1 N ?1 = ?(X , X ) ?1 ? ? ? ?(X , X ) ?1 1 N 1 N ?(X , X ) ?1</formula><p>where ? = 1 1 ? 1 N ?(X , X ) ?1 1 N By (72) and some eigendecomposition analysis, we can easily derive that</p><formula xml:id="formula_93">? = 1 1 ? 1 N ?(X , X ) ?1 1 N 1 1 ? O( 1 L ) ?(X , X ) ?1 1 N 1 N ?(X , X ) ?1 O 1 N 2 L 2 1 N 1 N Thus ? ?1 MTL (X , X ) = ?(X , X ) ?1 ? O 1 N 2 L 2 (1 ? O( 1 L )) 1 N 1 N<label>(78)</label></formula><p>where the last term is negligible since its maximum eigenvalue is O( 1 N L 2 (1?O( 1 L ) )), while the minimum eigenvalue for the first term is O( 1 N L ). Thus, we can write</p><formula xml:id="formula_94">? ?1 MTL (X , X ) ? ?(X , X ) ?1 op = O 1 N 2 L 2 (1 ? O( 1 L )) 1 N 1 N op ? O( 1 N L 2 )<label>(79)</label></formula><p>? Bound ? ?1 (X , X ) ? ? ?1 (X , X ) op By <ref type="formula">(</ref> X ,X has minimal effect, e.g., the spectrum of ?(X , X ) is almost identical to ?(X , X ). Now, let us bound the inverse of the perturbed matrix ?(X , X ) formally. Leveraging the identity (A + B) ?1 = A ?1 A ?1 B(A + B) ?1 from <ref type="bibr">(Henderson &amp; Searle, 1981)</ref>. Definin? ? = ?(X , X ) ? ?(X , X ) = 1 N 1 N ? I + 1 L 2 B (L) X ,X then we have</p><formula xml:id="formula_95">?(X , X ) ?1 ? ?(X , X ) ?1 op = ?(X , X ) +? ?1 op = ?(X , X ) ?1 + ?(X , X ) ?1? (?(X , X ) + ?) ?1 ? ?(X , X ) ?1 op = ?(X , X ) ?1? ?(X , X ) ?1 op = ?(X , X ) ?1 1 N 1 N ? I + 1 L 2 B (L) X ,X ?(X , X ) ?1 op ? ?(X , X ) ?1 1 N 1 N ?(X , X ) ?1 op + ?(X , X ) ?1 I ?(X , X ) ?1 op + 1 L 2 ?(X , X ) ?1 B (L) X ,X ?(X , X ) ?1 op (80) ? O 1 N L 2 + O 1 L 2 + O 1 L 4 ? O 1 L 2<label>(81)</label></formula><p>Finally, combining <ref type="formula" target="#formula_91">(77)</ref>, <ref type="formula" target="#formula_94">(79)</ref> and <ref type="formula" target="#formula_0">(81)</ref>, we have</p><formula xml:id="formula_96">?(X , X ) ?1 ? ? ?1 MTL (X , X ) op ? ?(X , X ) ?1 ? ? ?1 (X , X ) op + ? ?1 (X , X ) ? ? ?1 MTL (X , X ) op ? O( 1 N L 2 ) + O( 1 L 2 ) = O( 1 L 2 )<label>(82)</label></formula><p>Case II: n &gt; 1.</p><p>Compared to the case of n = 1, the only difference with (82) is caused by the term ?(X , X ) ?1 I ?(X , X ) ?1 op in (80) is</p><formula xml:id="formula_97">converted to ?(X , X ) ?1 diag {1 n 1 n } N i=1 ?(X , X ) ?1 op Since diag {1 n 1 n } N i=1 op = 1 n 1 n op = n = O(1) , we have ?(X , X ) ?1 diag {1 n 1 n } N i=1 ?(X , X ) ?1 op ? ?(X , X ) ?1 2 op diag {1 n 1 n } N i=1 op ? O( 1 L 2 )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5. Proof of Theorem 1</head><p>The proof of Theorem 1 can be straightforwardly derived based on Lemma 5.</p><p>Bridging Multi-Task Learning and Meta-Learning</p><p>Proof. By (67), (73), we have</p><formula xml:id="formula_98">F ANIL (X, X , Y ) ? F MTL (X, X , Y ) 2 ? ? MTL ((X, X ,? ), X ) op ?(X , X ) ?1 ? ? ?1 MTL (X , X ) op Y 2 + O(?? ? max (K)) + O( 1 ? h ) ? O( 1 L ) + O(?? ) + O( 1 ? h )</formula><p>where we used the facts that ? MTL ((X, X ,? ), X ) op = O(L), which can be straightforwardly derived from Lemma 3 and 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.6. Extension to Residual ReLU Networks</head><p>Corollary 1.1 states that the theoretical results of Theorem 1 apply to residual ReLU networks and residual ReLU networks with LayerNorm. The proof of this corollary is simply derived from Appendix C.2 and C.4 of <ref type="bibr" target="#b20">Xiao et al. (2020)</ref>.</p><p>Proof. For residual ReLU networks, the corresponding NTK and NNGP have a factor of e L compared <ref type="formula" target="#formula_81">(69)</ref> and <ref type="formula" target="#formula_82">(70)</ref>, which has no effect on the predictors F ANIL and F MTL , since the factors from the kernel and kernel inverse cancel out (e.g., e L ? MTL ((X, X ,? ), X ) ? (e L ? MTL (X , X )) ?1 = ? MTL ((X, X ,? ), X )? MTL (X , X ) ?1 ). Thus, Theorem 1 applies to this class of networks.</p><p>For residual ReLU networks with LayerNorm, Appendix C.3 of <ref type="bibr" target="#b20">Xiao et al. (2020)</ref> shows the kernel structures of NTK and NNGP is the same as ReLU networks without residual connections. Thus, Theorem 1 directly applies to this class of networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Details of Experiments</head><p>In this section, we will provide more details about the experiment in Sec. 5. Specifically,</p><p>? Appendix C.1: presents more experimental details about Sec. 5.1, the empirical validation of Theorem 1.</p><p>? Appendix C.2: presents more experimental details about Sec. 5.2, the empirical study on few-shot image classification benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Empirical Validation of Theorem 1</head><p>Implementation. We implement MTL and ANIL kernels with Neural Tangents <ref type="bibr" target="#b20">(Novak et al., 2020)</ref>, a codebase built on JAX <ref type="bibr" target="#b10">(Bradbury et al., 2018)</ref>, which is a package designed for high-performance machine learning research in Python. Since MTL and ANIL kernel functions are composite kernel functions built upon NTK and NNGP functions, we directly construct NTKs and NNGPs using Neural Tangents and then compose them into MTL and ANIL kernels.</p><p>About <ref type="figure" target="#fig_0">Figure 1</ref>. Note that the value at L = 10 in the first image is a little smaller than the value at ?? = 0 in the second image. That is because the random seeds using in the two images are different. Even though we take an average over 5 random seeds when plotting each image, there still exists some non-negligible variance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Experiments on Few-Shot Image Classification Benchmarks</head><p>Fine-Tuning in Validation and Test. In the meta-validation and meta-testing stages, following Sec. 3.4, we fine-tune a linear classifier on the features (i.e., outputs of the last hidden layer) with the cross-entropy loss and a 2 regularization. Specifically, similar to <ref type="bibr" target="#b31">Tian et al. (2020)</ref>, we use the logistic regression classifier from sklearn for the fine-tuning <ref type="bibr" target="#b23">(Pedregosa et al., 2011)</ref>, and we set the 2 regularization strength to be 0.33 based on the following ablation study on 2 penalty (i.e., <ref type="table">Table 5</ref>.</p><p>2 Penalty 0.0001 0.001 0.01 0.1 0.33 1 3</p><p>Test Accuracy(%) 76.86 77.02 77.28 77.61 77.72 77.55 76.82 <ref type="table">Table 5</ref>. Ablation study of the 2 penalty on the fine-tuned linear layer. Evaluated on mini-ImageNet (5-way 5-shot classification).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>anil (X , X , Y ) ? F mtl (X , X , Y )Empirical validation of Theorem 1 on synthetic data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Efficiency comparison on tiered-ImageNet for 5-way 5shot classification. The x-axis is the speedup of MTL compared with MetaOptNet, and the y-axis is the mean test accuracy. Notice that we only tune the batch size and number of training epochs for MTL in this comparison.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>? 2 ?</head><label>2</label><figDesc>li and ? 2 b are variances for weight and bias, and ? is a point-wise activation function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>?</head><label></label><figDesc>Appendix B.1: Proves the global convergence of MTL and ANIL, and demonstrates that neural net output and meta-output functions are linearized under over-parameterization. ? Appendix B.2: Studies the training dynamics of MTL and ANIL, and derives analytic expressions for their predictors. ? Appendix B.3: Derives the expression of kernels for MTL and ANIL, and proves Lemma 1. ? Appendix B.4: Characterizes the structures and spectra of ANIL and MTL kernels for deep ReLU nets. ? Appendix B.5: Proves our main theorem, i.e., Theorem 1. ? Appendix B.6: Extends Theorem 1 to residual ReLU networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>, (34) and (35). Notice, the expressions in (36) and (37) are derived in Sec. 2.3.1 of Lee et al. (2019a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>2.2 of Lee et al. (2019a), with linearized functions (34) and (35), the training dynamics of MTL and ANIL under gradient flow with squared losses are governed by the ODEs,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>up to an error of O( 1 ? h ). See Theorem H.1 of Lee et al. (2019a) for the bound on the error across training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>up to an error of O( 1 ? h ). See Theorem H.1 of Lee et al. (2019a) for the bound on the error across training. Now, with the derived expressions of trained parameters, we can certainly plug them in the linearized functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Learning and Meta-Learning    By observation, it is obvious that for relatively large L, the perturbation 1 N 1 N ? I + 1 L 2 B(L)    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>A taxonomy of gradient-based meta-learning algorithms based on the algorithmic design of Eq. (4).</figDesc><table><row><cell cols="2">Inner-Loop Optimized Layers Early Stopping</cell><cell>2 Regularizer</cell></row><row><cell>Last Layer</cell><cell>ANIL (Raghu et al., 2020)</cell><cell>MetaOptNet (Lee et al., 2019b) R2D2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Lee et al., 2019b;<ref type="bibr" target="#b21">Oreshkin et al., 2018;</ref><ref type="bibr" target="#b31">Tian et al., 2020)</ref>, we use ResNet-12 as the backbone, which is a residual neural network with 12 layers(He et al., 2016). Augmentation In training, we adopt the data augmentation used in Lee et al. (2019b) that consists of random cropping, color jittering, and random horizontal flip.Optimization Setup We use RAdam<ref type="bibr" target="#b14">(Liu et al., 2020)</ref>, a variant of Adam(Kingma &amp; Ba, 2015), as the optimizer for MTL. We adopt a public PyTorch implementation 2 , and use the default hyper-parameters. Besides, we adopt the ReduceOnPlateau learning rate scheduler 3 with the early stopping regularization 4 .</figDesc><table><row><cell>). Bench-</cell></row><row><cell>marks.</cell></row><row><cell>? mini-ImageNet (Vinyals et al., 2016): It contains 60,000</cell></row><row><cell>colored images of 84x84 pixels, with 100 classes (each</cell></row><row><cell>with 600 images) split into 64 training classes, 16 valida-</cell></row><row><cell>tion classes and 20 test classes.</cell></row><row><cell>? tiered-ImageNet (Ren et al., 2018): It contains 779,165</cell></row><row><cell>colored images of 84x84 pixels, with 608 classes split</cell></row><row><cell>into 351 training, 97 validation and 160 test classes.</cell></row><row><cell>? CIFAR-FS (Bertinetto et al., 2019): It contains 60,000 col-</cell></row><row><cell>ored images of 32x32 pixels, with 100 classes (each with</cell></row><row><cell>600 images) split into 64 training classes, 16 validation</cell></row><row><cell>classes and 20 test classes.</cell></row><row><cell>? FC100 (Oreshkin et al., 2018): It contains 60,000 colored</cell></row><row><cell>images of 32x32 pixels, with 100 classes split into 60</cell></row><row><cell>training classes, 20 validation classes and 20 test classes.</cell></row><row><cell>Network Architecture Following previous meta-learning</cell></row><row><cell>works (Data Model Selection. At the end of each training epoch, we</cell></row><row><cell>evaluate the validation accuracy of the trained MTL model</cell></row><row><cell>2 https://github.com/jettify/</cell></row><row><cell>pytorch-optimizer</cell></row></table><note>3 https://pytorch.org/docs/stable/ optim.html#torch.optim.lr_scheduler. ReduceLROnPlateau4 We stop the training if the validation accuracy does not in- crease for several epochs.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Comparison on four few-shot image classification benchmarks. Average few-shot test classification accuracy (%) with 95% confidence intervals. 32-32-32-32 denotes a 4-layer convolutional neural net with 32 filters in each layer. In each column, bold values are the highest accuracy, or the accuracy no less than 1% compared with the highest one. and save a model checkpoint. After training, we select the model checkpoint with the highest validation accuracy, and evaluate it on the test set to obtain the test accuracy.</figDesc><table><row><cell>mini-ImageNet 5-way</cell><cell>tiered-ImageNet 5-way</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Efficiency Comparison on mini-ImageNet for 5-way 5shot classification.</figDesc><table><row><cell></cell><cell cols="2">Test Accuracy GPU Hours</cell></row><row><cell>MetaOptNet</cell><cell>78.63%</cell><cell>85.6 hrs</cell></row><row><cell>MTL</cell><cell>77.72%</cell><cell>3.7 hrs</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Dong, D., Wu, H., He, W., Yu, D., and Wang, H. Multi-task learning for multiple language translation. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 1723-1732, 2015. Du, S. S., Lee, J. D., Li, H., Wang, L., and Zhai, X. Gradient descent finds global minima of deep neural networks. Henderson, H. V. and Searle, S. R. On deriving the inverse of a sum of matrices. Siam Review, 23(1):53-60, 1981. Hospedales, T., Antoniou, A., Micaelli, P., and Storkey, A. Meta-learning in neural networks: A survey, 2020. Lee, K., Maji, S., Ravichandran, A., and Soatto, S. Metalearning with differentiable convex optimization. In CVPR, 2019b.</figDesc><table><row><cell>Hsu, J.-Y., Chen, Y.-J., and Lee, H.-y. Meta learning for</cell><cell></cell></row><row><cell>end-to-end low-resource speech recognition. In ICASSP</cell><cell></cell></row><row><cell>2020-2020 IEEE International Conference on Acoustics,</cell><cell></cell></row><row><cell>Speech and Signal Processing (ICASSP), pp. 7844-7848.</cell><cell>International Conference on Machine Learning, 2019.</cell></row><row><cell>IEEE, 2020.</cell><cell></cell></row><row><cell></cell><cell>Du, S. S., Hu, W., Kakade, S. M., Lee, J. D., and Lei, Q.</cell></row><row><cell>Hu, Y., Zhang, S., Chen, X., and He, N. Biased stochastic</cell><cell>Few-shot learning via learning the representation, prov-</cell></row><row><cell>gradient descent for conditional stochastic optimization.</cell><cell>ably. In International Conference on Learning Represen-</cell></row><row><cell>arXiv preprint arXiv:2002.10790, 2020.</cell><cell>tations, 2021. URL https://openreview.net/</cell></row><row><cell></cell><cell>forum?id=pW2Q2xLwIMD.</cell></row><row><cell>Hui, L. and Belkin, M. Evaluation of neural architectures</cell><cell></cell></row><row><cell>trained with square loss vs cross-entropy in classification</cell><cell>Evgeniou, A. and Pontil, M. Multi-task feature learning.</cell></row><row><cell>tasks. In ICLR, 2021.</cell><cell>Advances in neural information processing systems, 19:</cell></row><row><cell></cell><cell>41, 2007.</cell></row><row><cell>Jacot, A., Gabriel, F., and Hongler, C. Neural tangent kernel:</cell><cell></cell></row><row><cell>Convergence and generalization in neural networks. In</cell><cell></cell></row><row><cell>Advances in neural information processing systems, pp.</cell><cell></cell></row><row><cell>8571-8580, 2018.</cell><cell></cell></row><row><cell>Ji, K., Yang, J., and Liang, Y. Multi-step model-agnostic</cell><cell></cell></row><row><cell>meta-learning: Convergence and improved algorithms.</cell><cell></cell></row><row><cell>arXiv preprint arXiv:2002.07836, 2020.</cell><cell></cell></row><row><cell>Kendall, A., Gal, Y., and Cipolla, R. Multi-task learning</cell><cell></cell></row><row><cell>using uncertainty to weigh losses for scene geometry and</cell><cell></cell></row><row><cell>semantics. In Proceedings of the IEEE conference on</cell><cell>Finn, C., Rajeswaran, A., Kakade, S., and Levine, S. Online</cell></row><row><cell>computer vision and pattern recognition, pp. 7482-7491,</cell><cell>meta-learning. In International Conference on Machine</cell></row><row><cell>2018.</cell><cell>Learning, pp. 1920-1930, 2019.</cell></row><row><cell>Khodak, M., Balcan, M.-F. F., and Talwalkar, A. S. Adaptive</cell><cell>Goldblum, M., Reich, S., Fowl, L., Ni, R., Cherepanova,</cell></row><row><cell>gradient-based meta-learning methods. In Advances in</cell><cell>V., and Goldstein, T. Unraveling meta-learning: Under-</cell></row><row><cell>Neural Information Processing Systems, pp. 5915-5926,</cell><cell>standing feature representations for few-shot tasks. In</cell></row><row><cell>2019.</cell><cell>International Conference on Machine Learning, pp. 3607-</cell></row><row><cell></cell><cell>3616. PMLR, 2020.</cell></row><row><cell>Kingma, D. P. and Ba, J. Adam: A method for stochastic</cell><cell></cell></row><row><cell>optimization. In ICLR, 2015.</cell><cell>Grant, E., Finn, C., Levine, S., Darrell, T., and Griffiths, T.</cell></row><row><cell></cell><cell>Recasting gradient-based meta-learning as hierarchical</cell></row><row><cell>Krizhevsky, A. Learning multiple layers of features from</cell><cell>bayes. In International Conference on Learning Represen-</cell></row><row><cell>tiny images. 2009.</cell><cell>tations, 2018. URL https://openreview.net/</cell></row><row><cell></cell><cell>forum?id=BJ_UL-k0b.</cell></row><row><cell>Lee, J., Sohl-dickstein, J., Pennington, J., Novak, R.,</cell><cell></cell></row><row><cell>Schoenholz, S., and Bahri, Y. Deep neural networks</cell><cell>Hanin, B. and Nica, M. Finite depth and width corrections</cell></row><row><cell>as gaussian processes. In International Conference</cell><cell>to the neural tangent kernel. In International Conference</cell></row><row><cell>on Learning Representations, 2018. URL https://</cell><cell>on Learning Representations, 2020. URL https://</cell></row><row><cell>openreview.net/forum?id=B1EA-M-0Z.</cell><cell>openreview.net/forum?id=SJgndT4KwB.</cell></row></table><note>Fallah, A., Mokhtari, A., and Ozdaglar, A. On the con- vergence theory of gradient-based model-agnostic meta- learning algorithms. In International Conference on Arti- ficial Intelligence and Statistics, pp. 1082-1092, 2020. Finn, C., Abbeel, P., and Levine, S. Model-agnostic meta- learning for fast adaptation of deep networks. In Proceed- ings of the 34th International Conference on Machine Learning-Volume 70, pp. 1126-1135. JMLR. org, 2017.He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learn- ing for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, 2016.Lee, J., Xiao, L., Schoenholz, S. S., Bahri, Y., Sohl- Dickstein, J., and Pennington, J. Wide neural networks of any depth evolve as linear models under gradient descent. NeurIPS, 2019a.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>are derived in the setting of NTK parameterization (see Appendix A.3). When switching to the standard parameterization, as shown by Theorem G.2 of Lee et al. (2019a), (31) is transformed to</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">This is the common and default initialization scheme in Keras and PyTorch.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">Notice the only difference between ANIL and MAML is the layers to optimize in the inner loop, where ANIL optimizes less layers than MAML. Hence, bounds on the inner loop optimization in Theorem 4 of cover that of ANIL, and the proof steps of that theorem applies to the case of ANIL.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">The proof of the gradient expression can be straightforwardly obtained by Lemma 6 of.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">The following equivalence can be straightforwardly dervied based on Appendix D and E of (Lee et al., 2019a).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>Haoxiang Wang would like to thank S?bastien Arnold and Ruoyu Sun for helpful discussions. This work is partially supported by NSF grant No.1910100, NSF CNS 20-46726  CAR, and Amazon Research Award.   </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>Overview of the Appendix</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A convergence theory for deep learning via over-parameterization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Allen-Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">How to train your MAML</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HJGven05Y7" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convex multitask feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Argyriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="243" to="272" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bunner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Zarkias</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.12284</idno>
		<title level="m">A library for meta-learning research</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">On exact computation with an infinitely wide neural net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">E. Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How important is the train-validation split in meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Provable guarantees for gradient-based meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-F</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="424" to="433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Theoretical models of learning to learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning to learn</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="71" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable closed-form solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HyxnZh0ct7" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">JAX: composable transformations of Python+NumPy programs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Necula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wanderman-Milne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<ptr target="http://github.com/google/jax" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Multitask</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Learning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="75" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">To learn effective features: Understanding the taskspecific adaptation of {maml}</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Baoxing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=FPpZrRfz6Ss" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the variance of the adaptive learning rate and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Learning Representations (ICLR 2020)</title>
		<meeting>the Eighth International Conference on Learning Representations (ICLR 2020)</meeting>
		<imprint>
			<date type="published" when="2020-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mitigating data scarcity in protein binding prediction using meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">T</forename><surname>Ideker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Research in Computational Molecular Biology: 23rd Annual International Conference, RECOMB 2019</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">11467</biblScope>
			<biblScope unit="page">305</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The benefit of multitask representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Romera-Paredes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2853" to="2884" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Bayesian deep convolutional networks with many channels are gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Abolafia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=B1g30j0qF7" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural tangents: Fast and easy infinite neural networks in python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<ptr target="https://github.com/google/neural-tangents" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodr?guez L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2018/file/" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Cesa-Bianchi, N., and Garnett, R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="721" to="731" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8026" to="8037" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rapid learning or feature reuse? towards understanding the effectiveness of maml</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Meta-learning with implicit gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="113" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Metalearning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HJcSzz-CZ" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">An overview of multi-task learning in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A sample complexity separation between non-convex and convex meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4077" to="4087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to learn: Introduction and overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pratt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning to learn</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="3" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Rethinking few-shot image classification: a good embedding is all you need?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On the theory of transfer learning: The importance of task diversity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tripuraneni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/59587bffec1c7846f3e34230141556ae-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Lin, H.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7852" to="7862" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJ4km2R5t7" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Global convergence and induced kernels of gradient-based meta-learning with neural nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.14606</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Disentangling trainability and generalization in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karbasi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10921</idno>
		<title level="m">Meta learning in the continuous time limit</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An overview of multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1093/nsr/nwx105</idno>
		<ptr target="https://doi.org/10.1093/nsr/nwx105" />
	</analytic>
	<monogr>
		<title level="j">National Science Review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="43" />
			<date type="published" when="2017-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A convex formulation for learning task relationships in multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Y</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence, UAI 2010</title>
		<meeting>the 26th Conference on Uncertainty in Artificial Intelligence, UAI 2010</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">733</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Facial landmark detection by deep multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="94" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Efficient multitask feature and relationship learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Stretcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Uncertainty in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="page" from="777" to="787" />
			<date type="published" when="2020" />
			<publisher>PMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Efficient meta learning via minibatch proximal update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Efficient meta learning via minibatch proximal update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1534" to="1544" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
