<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Gauge Equivariant Convolutional Networks and the Icosahedral CNN</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taco</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Weiler</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berkay</forename><surname>Kicanaoglu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
						</author>
						<title level="a" type="main">Gauge Equivariant Convolutional Networks and the Icosahedral CNN</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The principle of equivariance to symmetry transformations enables a theoretically grounded approach to neural network architecture design. Equivariant networks have shown excellent performance and data efficiency on vision and medical imaging problems that exhibit symmetries. Here we show how this principle can be extended beyond global symmetries to local gauge transformations. This enables the development of a very general class of convolutional neural networks on manifolds that depend only on the intrinsic geometry, and which includes many popular methods from equivariant and geometric deep learning.</p><p>We implement gauge equivariant CNNs for signals defined on the surface of the icosahedron, which provides a reasonable approximation of the sphere. By choosing to work with this very regular manifold, we are able to implement the gauge equivariant convolution using a single conv2d call, making it a highly scalable and practical alternative to Spherical CNNs. Using this method, we demonstrate substantial improvements over previous methods on the task of segmenting omnidirectional images and global climate patterns.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>By and large, progress in deep learning has been achieved through intuition-guided experimentation. This approach is indispensable and has led to many successes, but has not produced a deep understanding of why and when certain architectures work well. As a result, every new application requires an extensive architecture search, which comes at a significant labor and energy cost. <ref type="figure">Figure 1</ref>. A gauge is a smoothly varying choice of tangent frame on a subset U of a manifold M . A gauge is needed to represent geometrical quantities such as convolutional filters and feature maps (i.e. fields), but the choice of gauge is ultimately arbitrary. Hence, the network should be equivariant to gauge transformations, such as the change between red and blue gauge pictured here.</p><p>Although a theory that tells us which architecture to use for any given problem is clearly out of reach, we can nevertheless come up with general principles to guide architecture search. One such rational design principle that has met with substantial empirical success <ref type="bibr" target="#b51">(Winkels &amp; Cohen, 2018;</ref><ref type="bibr" target="#b54">Zaheer et al., 2017;</ref><ref type="bibr" target="#b29">Lunter &amp; Brown, 2018)</ref> maintains that network architectures should be equivariant to symmetries.</p><p>Besides the ubiquitous translation equivariant CNN, equivariant networks have been developed for sets, graphs, and homogeneous spaces like the sphere (see Sec. 3). In each case, the network is made equivariant to the global symmetries of the underlying space. However, manifolds do not in general have global symmetries, and so it is not obvious how one might develop equivariant CNNs for them.</p><p>General manifolds do however have local gauge symmetries, and as we will show in this paper, taking these into account is not just useful but necessary if one wishes to build manifold CNNs that depend only on the intrinsic geometry. To this end, we define a convolution-like operation on general manifolds M that is equivariant to local gauge transformations ( <ref type="figure">Fig. 1</ref>). This gauge equivariant convolution takes as input a number of feature fields on M of various types (analogous to matter fields in physics), and produces as output new feature fields. Each field is represented by a number of feature maps, whose activations are interpreted as the coefficients of a geometrical object <ref type="bibr">(e.g. scalar, vector, tensor, etc.)</ref> relative to a spatially varying frame (i.e. gauge). The network is constructed such that if the gauge is changed, arXiv:1902.04615v3 <ref type="bibr">[cs.</ref>LG] 13 May 2019 the coefficients change in a predictable way so as to preserve their geometrical meaning. Thus, the search for a geometrically natural definition of "manifold convolution", a key problem in geometric deep learning, leads inevitably to gauge equivariance.</p><p>Although the theory of gauge equivariant networks developed in this paper is very general, we apply it to one specific manifold: the icosahedron. This manifold has some global symmetries (discrete rotations), which nicely shows the difference between and interplay of local and global symmetries. In addition, the regularity and local flatness of this manifold allows for a very efficient implementation using existing deep learning primitives (i.e. conv2d). The resulting algorithm shows excellent performance and accuracy on segmentation of omnidirectional signals.</p><p>Gauge theory plays a central role in modern physics, but has a reputation for being abstract and difficult. So in order to keep this article accessible to a broad machine learning audience, we have chosen to emphasize geometrical intuition over mathematical formality.</p><p>The rest of this paper is organized as follows. In Sec. 2, we motivate the need for working with gauges, and define gauge equivariant convolution for general manifolds and fields. In section 3, we discuss related work on equivariant and geometrical deep learning. Then in section 4, we discuss the concrete instantiation and implementation of gauge equivariant CNNs for the icosahedron. Results on IcoM-NIST, climate pattern segmentation, and omnidirectional RGB-D image segmentation are presented in Sec. 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Gauge Equivariant Networks</head><p>Consider the problem of generalizing the classical convolution of two planar signals (e.g. a feature map and a filter) to signals defined on a manifold M . The first and most natural idea comes from thinking of planar convolution in terms of shifting a filter over a feature map. Observing that shifts are symmetries of the plane (mapping the plane onto itself while preserving its structure), one is led to the idea of transforming a filter on M by the symmetries of M . For instance, replacing shifts of the plane by rotations of the sphere, one obtains Spherical CNNs <ref type="bibr" target="#b10">(Cohen et al., 2018b)</ref>. This approach works for any homogeneous space, where by definition it is possible to move from any point p ? M to any other point q ? M using an appropriate symmetry transformation <ref type="bibr">Cohen et al., 2018c;</ref><ref type="bibr">a)</ref>. On less symmetrical manifolds however, it may not be possible to move the filter from any point to any other point by symmetry transformations. Hence, transforming filters by symmetry transformations will in general not provide a recipe for weight sharing between filters at all points in M . <ref type="figure">Figure 2</ref>. On curved spaces, parallel transport is path dependent. The black vector is transported to the same point via two different curves, yielding different results. The same phenomenon occurs for other geometric objects, including filters.</p><p>Instead of symmetries, one can move the filter by parallel transport <ref type="bibr" target="#b40">(Schonsheck et al., 2018)</ref>, but as shown in <ref type="figure">Fig. 2</ref>, this leaves an ambiguity in the filter orientation, because parallel transport is path dependent. This can be addressed by using only rotation invariant filters <ref type="bibr" target="#b6">Bruna et al., 2014)</ref>, albeit at the cost of limiting expressivity.</p><p>The key issue is that on a manifold, there is no preferred gauge (tangent frame), relative to which we can position our measurement apparatus (i.e. filters), and relative to which we can describe measurements (i.e. responses). We must choose a gauge in order to numerically represent geometrical quantities and perform computations, but since it is arbitrary, the computations should be independent of it.</p><p>This does not mean however that the coefficients of the feature vectors should be invariant to gauge transformations, but rather that the feature vector itself should be invariant. That is, a gauge transformation leads to a change of basis e i ?? i of the feature space (fiber) at p ? M , so the feature vector coefficients f i should change equivariantly to ensure that the vector i f i e i = if i?i itself is unchanged.</p><p>Before showing how this is achieved, we note that on nonparallelizable manifolds such as the sphere, it is not possible to choose a smooth global gauge. For instance, if we extend the blue gauge pictured in <ref type="figure">Fig. 1</ref> to the whole sphere, we will innevitably create a singularity where the gauge changes abruptly. Hence, in order to make the math work smoothly, it is standard practice in gauge theory to work with multiple gauges defined on overlapping charts, as in <ref type="figure">Fig. 1</ref>.</p><p>The basic idea of gauge equivariant convolution is as follows. Lacking alternative options, we choose arbitrarily a smooth local gauge on subsets U ? M (e.g. the red or blue gauge in <ref type="figure">Fig. 1</ref>). We can then position a filter at each point p ? U , defining its orientation relative to the gauge. Then, we match an input feature map against the filter at p to obtain the value of the output feature map at p. For the output to transform equivariantly, certain linear constraints are placed on the convolution kernel. We will now define this formally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Gauges, Transformations, and Exponential Maps</head><p>We define a gauge as a position-dependent invertible linear map w p :</p><formula xml:id="formula_0">R d ? T p M , where T p M is the tangent space of M at p. This determines a frame w p (e 1 ), . . . , w p (e d ) in T p M , where {e i } is the standard frame of R d .</formula><p>A gauge transformation <ref type="figure">(Fig. 1)</ref> is a position-dependent change of frame, which can be described by maps g p ? GL(d, R) (the group of invertible d ? d matrices). As indicated by the subscript, the transformation g p depends on the position p ? U ? M . To change the frame, simply compose w p with g p , i.e. w p ? w p g p . It follows that com-</p><formula xml:id="formula_1">ponent vectors v ? R d transform as v ? g ?1 p v, so that the vector (w p g p )(g ?1 p v) = w p v ? T p M itself is invariant.</formula><p>If we derive our gauge from a coordinate system for M (as shown in <ref type="figure">Fig. 1)</ref>, then a change of coordinates leads to a gauge transformation (g p being the Jacobian of the coordinate transformation at p). But we can also choose a gauge w p independent of any coordinate system.</p><p>It is often useful to restrict the kinds of frames we consider, for example to only allow right-handed or orthogonal frames. Such restrictions limit the kinds of gauge transformations we can consider. For instance, if we allow only right-handed frames, g p should have positive determinant (i.e. g p ? GL + (d, R)), so that it does not reverse the orientation. If in addition we allow only orthogonal frames, g p must be a rotation, i.e. g p ? SO(d).</p><p>In mathematical terms, G = GL(d, R) is called the structure group of the theory, and limiting the kinds of frames we consider corresponds to a reduction of the structure group <ref type="bibr" target="#b17">(Husem?ller, 1994)</ref>. Each reduction corresponds to some extra structure that is preserved, such as an orientation (GL + (d, R)) or Riemannian metric (SO(d)). In the Icosahedral CNN ( <ref type="figure">Fig. 4</ref>), we will want to preserve the hexagonal grid structure, which corresponds to a restriction to grid-aligned frames and a reduction of the structure group to G = C 6 , the group of planar rotations by integer multiples of 2?/6. For the rest of this section, we will work in the Riemannian setting, i.e. use G = SO(d).</p><p>Before we can define gauge equivariant convolution, we will need the exponential map, which gives a convenient parameterization of the local neighbourhood of p ? M . This map exp p : T p M ? M takes a tangent vector V ? T p M , follows the geodesic (shortest curve) in the direction of V with speed V for one unit of time, to arrive at a point q = exp p V (see <ref type="figure">Fig. 3</ref>, (Lee)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Gauge Equivariant Convolution: Scalar Fields</head><p>Having defined gauges, gauge transformations, and the exponential map, we are now ready to define gauge equivariant convolution. We begin with scalar input and output fields.</p><p>We define a filter as a locally supported function K : R d ? R, where R d may be identified with T p M via the gauge w p . Then, writing q v = exp p w p (v) for v ? R d , we define the scalar convolution of K and f : M ? R at p as follows:</p><formula xml:id="formula_2">(K f )(p) = R d K(v)f (q v )dv.</formula><p>(1) <ref type="figure">Figure 3</ref>. The exponential map and the gauge wp.</p><p>The gauge was chosen arbitrarily, so we must consider what happens if we change it. Since the filter K : R d ? R is a function of a coordinate vector v ? R d , and v gets rotated by gauge transformations, the effect of a gauge transformation is a position-dependent rotation of the filters. For the convolution output to be called a scalar field, it has to be invariant to gauge transformations (i.e. v ? g ?1 p v and w p ? w g g p ). The only way to make (K f )(p) (Eq. 1) invariant to rotations of the filter, is to make the filter rotation-invariant:</p><formula xml:id="formula_3">?g ? G : K(g ?1 v) = K(v)<label>(2)</label></formula><p>Thus, to map a scalar input field to a scalar output field in a gauge equivariant manner, we need to use rotationally symmetric filters. Some geometric deep learning methods, as well as graph CNNs do indeed use isotropic filters. However, this is very limiting and as we will now show, unnecessary if one considers non-scalar feature fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Feature Fields</head><p>Intuitively, a field is an assignment of some geometrical quantity (feature vector) f (p) of the same type to each point p ? M . The type of a quantity is determined by its transformation behaviour under gauge transformations. For instance, the word vector field is reserved for a field of tangent vectors v, that transform like v(p) ? g ?1 p v(p) as we saw before. It is important to note that f (p) is an element of a vector space ("fiber") F p R C attached to p ? M (e.g. the tangent space T p M ). All F p are similar to a canonical feature space R C , but f can only be considered a function U ? R C locally, after we have chosen a gauge, because there is no canonical way to identify all feature spaces F p .</p><p>In the general case, the transformation behaviour of a Cdimensional geometrical quantity is described by a representation of the structure group G. This is a mapping ? : G ? GL(C, R) that satisfies ?(gh) = ?(g)?(h), where gh denotes the composition of transformations in G, and ?(g)?(h) denotes multiplication of C ?C matrices ?(g) and ?(h). The simplest examples are the trivial representation ?(g) = 1 which describes the transformation behaviour of scalars, and ?(g) = g, which describes the transformation behaviour of (tangent) vectors. A field f that transforms like f (p) ? ?(g ?1 p )f (p) will be called a ?-field.</p><p>In Section 4 on Icosahedral CNNs, we will consider one more type of representation, namely the regular representation of C 6 . The group C 6 can be described as the 6 planar rotations by k ? 2?/6, or as integers k with addition mod 6.</p><p>Features that transform like the regular representation of C 6 are 6-dimensional, with one component for each rotation.</p><p>One can obtain a regular feature by taking a filter at p, rotating it by k ? 2?/6 for k = 0, . . . , 5, and matching each rotated filter against the input signal. When the gauge is changed, the filter and all rotated copies are rotated, and so the components of a regular C 6 feature are cyclically shifted. Hence, ?(g) is a 6 ? 6 cyclic permutation matrix that shifts the coordinates by k steps for g = k ? 2?/6. Further examples of representations ? that are useful in convolutional networks may be found in <ref type="bibr" target="#b9">(Cohen &amp; Welling, 2017;</ref><ref type="bibr" target="#b48">Weiler et al., 2018a;</ref><ref type="bibr" target="#b46">Thomas et al., 2018;</ref><ref type="bibr" target="#b18">Hy et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Gauge Equivariant Convolution: General Fields</head><p>Now consider a stack of C in input feature maps on M , which represents a C in -dimensional ? in -field (e.g. C in = 1 for a single scalar, C in = d for a vector, C in = 6 for a regular C 6 feature, or any multiple of these, etc.). We will define a convolution operation that takes such a field and produces as output a C out -dimensional ? out -field. For this we need a filter bank with C out output channels and C in input channels, which we will describe mathematically as a matrix-valued kernel K :</p><formula xml:id="formula_4">R d ? R Cout?Cin .</formula><p>We can think of K(v) as a linear map from the input feature space ("fiber") at p to the output feature space at p, these spaces being identified with R Cin resp. R Cout by the choice of gauge w p at p. This suggests that we need to modify Eq. 1 to make sure that the kernel matrix K(v) is multiplied by a feature vector at p, not one at q v = exp p w p (v). This is achieved by transporting f (q v ) to p along the unique 1 geodesic connecting them, before multiplying by K(v).</p><p>As f (q v ) is transported to p, it undergoes a transformation which will be denoted g p?qv ? G (see <ref type="figure">Fig. 2</ref>). This transformation acts on the feature vector f (q v ) ? R Cin via the representation ? in (g p?qv ) ? R Cin?Cin . Thus, we obtain the generalized form of Eq. 1 for general fields:</p><formula xml:id="formula_5">(K f )(p) = R d K(v)? in (g p?qv )f (q v )dv.<label>(3)</label></formula><p>Under a gauge transformation, we have:</p><formula xml:id="formula_6">v ? g ?1 p v, f (q v ) ? ? in (g ?1 qv )f (q v ), w p ? w p g p , g p?qv ? g ?1 p g p?qv g qv .<label>(4)</label></formula><p>For K f to be well defined as a ? out -field, we want it to</p><formula xml:id="formula_7">transform like (K f )(p) ? ? out (g ?1 p )(K f )(p).</formula><p>Or, in other words, should be gauge equivariant. This will be the case if and only if K satisfies</p><formula xml:id="formula_8">?g ? G : K(g ?1 v) = ? out (g ?1 )K(v)? in (g).<label>(5)</label></formula><p>One may verify this by making the substitutions of Eq. 4 in Eq. 3 and simplifying using ?(gh) = ?(g)?(h) and Eq. 5, to find that</p><formula xml:id="formula_9">(K f )(p) ? ? out (g ?1 p )(K f )(p)</formula><p>. We note that equations 1 and 2 are special cases of 3 and 5 for ? in (g) = ? out (g) = 1, i.e. for scalar fields.</p><p>This concludes our presentation of the general case. A gauge equivariant ? 1 ? ? 2 convolution on M is defined relative to a local gauge by Eq. 3, where the kernel satisfies the equivariance constraint of Eq. 5. By defining gauges on local charts U i ? M that cover M and convolving inside each one, we automatically get a globally well-defined operation, because switching charts corresponds to a gauge transformation ( <ref type="figure">Fig. 1)</ref>, and the convolution is gauge equivariant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Locally Flat Spaces</head><p>On flat regions of the manifold, the exponential parameterization can be simplified to ?</p><formula xml:id="formula_10">(exp p w p (v)) = ?(p) + v if we use an appropriate local coordinate ?(p) ? R d of p ? M .</formula><p>Moreover, in such a flat chart, parallel transport is trivial, i.e. g p?qv equals the identity. Thus, on a flat region, our convolution boils down to a standard convolution / correlation:</p><formula xml:id="formula_11">(K f )(x) = R d K(v)f (x + v)dv.<label>(6)</label></formula><p>Moreover, we can recover group convolutions, spherical convolutions, and convolution on other homogeneous spaces as special cases as well (see supplementary material).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Related work</head><p>Equivariant Deep Learning Equivariant networks have been proposed for permutation-equivariant analysis and prediction of sets <ref type="bibr" target="#b54">(Zaheer et al., 2017;</ref><ref type="bibr" target="#b14">Hartford et al., 2018)</ref>, graphs <ref type="bibr" target="#b24">(Kondor et al., 2018b;</ref><ref type="bibr" target="#b18">Hy et al., 2018;</ref><ref type="bibr" target="#b31">Maron et al., 2019)</ref>, translations and rotations of the plane and 3D space <ref type="bibr" target="#b35">(Oyallon &amp; Mallat, 2015;</ref><ref type="bibr" target="#b8">Cohen &amp; Welling, 2016;</ref><ref type="bibr" target="#b30">Marcos et al., 2017;</ref><ref type="bibr" target="#b49">Weiler et al., 2018b;</ref><ref type="bibr">a;</ref><ref type="bibr" target="#b53">Worrall et al., 2017;</ref><ref type="bibr" target="#b52">Worrall &amp; Brostow, 2018;</ref><ref type="bibr" target="#b51">Winkels &amp; Cohen, 2018;</ref><ref type="bibr" target="#b47">Veeling et al., 2018;</ref><ref type="bibr" target="#b46">Thomas et al., 2018;</ref><ref type="bibr" target="#b1">Bekkers et al., 2018;</ref><ref type="bibr" target="#b16">Hoogeboom et al., 2018)</ref>, and the sphere (see below). <ref type="bibr" target="#b38">Ravanbakhsh et al. (2017)</ref> studied finite group equivariance. Equivariant CNNs on homogeneous spaces were studied by ) (scalar fields) and <ref type="bibr">(Cohen et al., 2018c</ref>;a) (general fields). In this paper we generalize G-CNNs from homogeneous spaces to general manifolds.</p><p>Geometric Deep Learning Geometric deep learning <ref type="bibr" target="#b5">(Bronstein et al., 2017)</ref> is concerned with the generalization of (convolutional) neural networks to manifolds. Many definitions of manifold convolution have been proposed, and some of them (those called "intrinsic") are gauge equivariant (although to the best of our knowledge, the relevance of gauge theory has not been observed before). However, these methods are all limited to particular feature types ? (typically scalar), and/or use a parameterization of the kernel that is not maximally flexible. <ref type="bibr" target="#b6">Bruna et al. (2014)</ref>; <ref type="bibr" target="#b3">Boscaini et al. (2015)</ref> propose to use isotropic (spectral) filters (i.e. scalar field features), while  define a convolution that is essentially the same as our scalar-to-regular convolution, followed by a max-pooling over orientations, which in our terminology maps a regular field to a scalar field. As shown experimentally in <ref type="bibr" target="#b8">(Cohen &amp; Welling, 2016;</ref> and in this paper, it is often more effective to use convolutions that preserve orientation information (e.g. regular to regular convolution).</p><p>Another solution is to align the filter with the maximum curvature direction <ref type="bibr" target="#b4">(Boscaini et al., 2016)</ref>, but this approach is not intrinsic and does not work for flat surfaces or uniformly curved spaces like spheres. <ref type="bibr" target="#b37">(Poulenard &amp; Ovsjanikov, 2018</ref>) define a multi-directional convolution for "directional functions" (somewhat similar to what we call regular fields), but they parameterize the kernel by a scalar function on the tangent space, which is very limited compared to our matrix-valued kernel (which is the most general kernel mapping ? 1 fields to ? 2 fields).</p><p>Spherical CNNs Besides the general theoretical framework of gauge equivariant convolution, we present in this paper a specific model (the Icosahedral CNN), which can be viewed as a fast and simple alternative to Spherical CNNs <ref type="bibr" target="#b10">(Cohen et al., 2018b;</ref><ref type="bibr" target="#b13">Esteves et al., 2018;</ref><ref type="bibr" target="#b2">Boomsma &amp; Frellsen, 2017;</ref><ref type="bibr" target="#b45">Su &amp; Grauman, 2017;</ref><ref type="bibr" target="#b36">Perraudin et al., 2018;</ref><ref type="bibr" target="#b20">Jiang et al., 2018;</ref><ref type="bibr" target="#b23">Kondor et al., 2018a)</ref>. <ref type="bibr" target="#b28">Liu et al. (2019)</ref> use a spherical grid based on a subdivision of the icosahedron, and convolve over it using a method that is similar to the one presented in Sec. 4 (and thus ignores curvature), but this method is not equivariant and does not take into account gauge transformations. We show in Sec. 5 that both are important for optimal performance.</p><p>Mathematics &amp; physics To deeply understand gauge equivariant networks, we recommend studying the mathematics of gauge theory: principal &amp; associated fiber bundles <ref type="bibr" target="#b41">(Schuller, 2016;</ref><ref type="bibr" target="#b17">Husem?ller, 1994;</ref><ref type="bibr" target="#b44">Steenrod, 1951)</ref>. The work presented in this paper can be understood as replacing the principal G-bundle H ? H/G used in G-CNNs over homogeneous spaces H/G  by the frame bundle of M , which is another principal G-bundle.</p><p>More details can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Icosahedral CNNs</head><p>In this section we will describe a concrete method for performing gauge equivariant convolution on the icosahedron. The very special shape of this manifold makes it possible to implement gauge equivariant convolution in a way that is both numerically convenient (no interpolation is required), and computationally efficient (the heavy lifting is done by a single conv2d call).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The Icosahedron</head><p>The icosahedron is a regular solid with 20 faces, 30 edges, and 12 vertices (see <ref type="figure">Fig. 4</ref>, left). It has 60 rotational symmetries. This symmetry group will be denoted 2 I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">The Hexagonal Grid</head><p>Whereas general manifolds, and even spheres, do not admit completely regular and symmetrical pixelations, we can define an almost perfectly regular grid of pixels on the icosahedron. This grid is constructed through a sequence of grid-refinement steps. We begin with a grid H 0 consisting of the corners of the icosahedron itself. Then, for each triangular face, we subdivide it into 4 smaller triangles, thus introducing 3 new points on the center of the edges of the original triangle. This process is repeated r times to obtain a grid H r with N = 5 ? 2 2r+1 + 2 points ( <ref type="figure">Fig. 4, left)</ref>.</p><p>Each grid point (pixel) in the grid has 6 neighbours, except for the corners of the icosahedron, which have 5. Thus, one can think of the non-corner grid points as hexagonal pixels, and the corner points as pentagonal pixels.</p><p>Notice that the grid H r is perfectly symmetrical, which means that if we apply an icosahedral symmetry g ? I to a point p ? H r , we will always land on another grid point, i.e. gp ? H r . Thus, in addition to talking about gauge equivariance, for this manifold / grid, we can also talk about (exact) equivariance to global transformations (3D rotations in I). Because these global symmetries act by permuting the pixels and changing the gauge, one can see that a gauge equivariant network is automatically equivariant to global transformations. This will be demonstrated in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">The Atlas of Charts</head><p>We define an atlas consisting of 5 overlapping charts on the icosahedron, as shown in <ref type="figure">Fig. 4</ref>. Each chart is an invertible map ? i :</p><formula xml:id="formula_12">U i ? V i , where U i ? H r ? M and V i ? Z 2 .</formula><p>The regions U i and V i are shown in <ref type="figure">Fig. 4</ref>. The maps themselves are linear on faces, and defined by hard-coded correspondences ? i (c j ) = x j between the corner points c j in H r and points x j in the planar grid Z 2 . <ref type="figure">Figure 4</ref>. The Icosahedron with grid Hr for r = 2 (left). We define 5 overlapping charts that cover the grid (center). Chart V5 is highlighted in gray (left). Colored edges that appear in multiple charts are to be identified. In each chart, we define the gauge by the standard axis aligned basis vectors e1, e2 ? Vi. For points p ? Ui ? Uj, the transition between charts involves a change of gauge, shown as +1 ? 2?/6 and ?1 ? 2?/6 (elements of G = C6). On the right we show how the signal is represented in a padded array of shape 5 ? (2 r + 2) ? (2 r+1 + 2).</p><p>Each chart covers all the points in 4 triangular faces of the icosahedron. Together, the 5 charts cover all 20 faces of the icosahedron.</p><p>We divide the charts into an exterior V i ? V i , consisting of border pixels, and an interior V ? i ? V i , consisting of pixels whose neighbours are all contained in chart i. In order to ensure that every pixel in H r (except for the 12 corners) is contained in the interior of some chart, we add a strip of pixels to the left and bottom of each chart, as shown in <ref type="figure">Fig.  4 (center)</ref>. Then the interior of each chart (plus two exterior corners) has a nice rectangular shape 2 r ? 2 r+1 , and every non-corner is contained in exactly one interior V ? i . So if we know the values of the field in the interior of each chart, we know the whole field (except for the corners, which we ignore). However, in order to compute a valid convolution output at each interior pixel (assuming a hexagonal filter with one ring, i.e. a 3 ? 3 masked filter), we will still need the exterior pixels to be filled in as well (introducing a small amount of redundancy). See Sec. 4.6.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">The Gauge</head><p>For the purpose of computation, we fix a convenient gauge in each chart. This gauge is defined in each V i as the constant orthogonal frame e 1 = (1, 0), e 2 = (0, 1), aligned with the x and y direction of the plane (just like the red and blue gauge in <ref type="figure">Fig. 1)</ref>. When mapped to the icosahedron via (the Jacobian of) ? ?1 i , the resulting frames are aligned with the grid, and the basis vectors make an angle of 2 ? 2?/6. Some pixels p ? U i ? U j are covered by multiple charts. Although the local frames e 1 = (1, 0), e 2 = (0, 1) are numerically constant and equal in both charts V i and V j , the corresponding frames on the icosahedron (obtained by pushing them though ? ?1 i and ? ?1 j ) may not be the same. In other words, when switching from chart i to chart j, there may be a gauge transformation g ij (p), which rotates the frame at p ? U i ? U j (see <ref type="figure">Fig. 1</ref>).</p><p>For the particular atlas defined in Sec. 4.3, the gauge transformations g ij (p) are always elements of the group C 6 (i.e. rotations by k ? 2?/6), so G = C 6 and we have a C 6 -atlas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">The Signal Representation</head><p>A stack of C feature fields is represented as an array of shape (B, C, R, 5, H, W ), where B is the batch size, C the number of fields, R is the dimension of the fields (R = 1 for scalars and R = 6 for regular features), 5 is the number of charts, and H, W are the height and width of each local chart (H = 2 r + 2 and W = 2 r+1 + 2 at resolution r, including a 1-pixel padding region on each side, see <ref type="figure">Fig. 4</ref>). We can always reshape such an array to shape (B, CR, 5H, W ), resulting in a 4D array that can be viewed as a stack of CR rectangular feature maps of shape (5H, W ). Such an array can be input to conv2d.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Gauge Equivariant Icosahedral Convolution</head><p>Gauge equivariant convolution on the icosahedron is implemented in three steps: G-Padding, kernel expansion, and 2d convolution / HexaConv <ref type="bibr" target="#b16">(Hoogeboom et al., 2018)</ref>. 4.6.1. G-PADDING In a standard CNN, we can only compute a valid convolution output at positions (x, y) where the filter fits inside the input image in its entirety. If the output is to be of the same size as the input, one uses zero padding. Likewise, the Ico-Conv requires padding, only now the padding border V i of a chart consists of pixels that are also represented in the interior of another chart (Sec. 4.3). So instead of zero padding, we copy the pixels from the neighbouring chart. We always use hexagonal filters with 1 ring, which can be represented as a 3 ? 3 filter on a square grid, so we pad by 1 pixel.</p><p>As explained in Sec. 4.4, when transitioning between charts one may have to perform a gauge transformation on the features. Since scalars are invariant quantities, transition padding amounts to a simple copy in this case. Regular C 6 features (having 6 orientation channels) transform by cyclic shifts ?(g ij (p)) (Sec. 2.3), where g ij ? {+1, 0, ?1} ? 2?/6 ( <ref type="figure">Fig. 4)</ref>, so we must cyclically shift the channels up or down before copying to get the correct coefficients in the new chart. The whole padding operation is implemented by four indexing + assignment operations <ref type="bibr">(top, bottom, left, right)</ref> using fixed pre-computed indices (see Supp. Mat.). For the convolution to be gauge equivariant, the kernel must satisfy Eq. 5. The kernel K : R 2 ? R RoutCout?RinCin is stored in an array of shape (R out C out , R in C in , 3, 3), with the top-right and bottom-left pixel of each 3 ? 3 filter fixed at zero so that it corresponds to a 1-ring hexagonal kernel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.2.">WEIGHT SHARING &amp; KERNEL EXPANSION</head><p>Eq. 5 says that if we transform the input channels (columns) by ? in (g) and the ouput channels (rows) by ? out (g), the result should equal the original kernel where each channel is rotated by g ? C 6 . This will the case if we use the weight-sharing scheme shown in <ref type="figure" target="#fig_1">Fig. 6</ref>.</p><p>Weight sharing can be implemented in two ways. One can construct a basis of kernels, each of which has shape (R out , R in , 3, 3) and has value 1 at all pixels of a certain color/shade, and 0 elsewhere. Then one can construct the full kernel by linearly combining these basis filters using learned weights (one for each C in ?C out input/output channels and basis kernel) <ref type="bibr" target="#b9">(Cohen &amp; Welling, 2017;</ref><ref type="bibr" target="#b48">Weiler et al., 2018a)</ref>. Alternatively, for scalar and regular features, one can use a set of precomputed indices to expand the kernel as shown in <ref type="figure" target="#fig_1">Fig. 6</ref>, using a single indexing operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.3.">COMPLETE ALGORITHM</head><p>The complete algorithm can be summarized as GConv(f, w) = conv2d(GPad(f), expand(w)).</p><p>Where f and GPad(f ) both have shape (B, C in R in , 5H, W ), the weights w have shape (C out , C in R in , 7), and expand(w) has shape (C out R out , C in R in , 3, 3). The output of GConv has shape (B, C out R out , 5H, W ).</p><p>On the flat faces, being described by one of the charts, this algorithm coincides exactly with the hexagonal regular convolution introduced in <ref type="bibr" target="#b16">(Hoogeboom et al., 2018)</ref>. The non-zero curvature of the icosahedron requires us to do the additional step of padding between different charts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">IcoMNIST</head><p>In order to validate our implementation, highlight the potential benefits of our method, and determine the necessity of each part of the algorithm, we perform a number of experiments with the MNIST dataset, projected to the icosahedron.</p><p>We generate three different versions of the training and test sets, differing in the transformations applied to the data. In the N condition, No rotations are applied to the data. In the I condition, we apply all 60 Icosahedral symmetries (rotations) to each digit. Finally, in the R condition, we apply 60 random continuous rotations g ? SO(3) to each digit before projecting. All signals are represented as explained in Sec. 4.5 / <ref type="figure">Fig. 4 (right)</ref>, using resolution r = 4, i.e. as an array of shape (1, 5 ? (16 + 2), 32 + 2).</p><p>Our main model consists of one gauge equivariant scalarto-regular (S2R) convolution layer, followed by 6 regularto-regular (R2R) layers and 3 FC layers (see Supp. Mat. for architectural details). We also evaluate a model that uses only S2R convolution layers, followed by orientation pooling (a max over the 6 orientation channels of each regular feature, thus mapping a regular feature to a scalar), as in . Finally, we consider a model that uses only rotation-invariant filters, i.e. scalar-to-scalar (S2S) convolutions, similar to standard graph CNNs <ref type="bibr" target="#b21">Kipf &amp; Welling, 2017)</ref>. We also compare to the fully SO(3)-equivariant but computationally costly Spherical CNN (S2CNN). See supp. mat. for architectural details and computational complexity analysis.</p><p>In addition, we perform an ablation study where we disable each part of the algorithm. The first baseline is obtained from the full R2R network by disabling gauge padding (Sec. 4.6.1), and is called the No Pad (NP) network. In the second baseline, we disable the kernel Expansion (Sec. 4.6.2), yielding the NE condition. The third baseline, called NP+NE uses neither gauge padding nor kernel expansion, and amounts to a standard CNN applied to the same input representation. We adapt the number of channels so that all networks have roughly the same number of parameters. As shown in <ref type="table">Table 1</ref>, icosahedral CNNs achieve excellent performance with a test accuracy of up to 99.43%, which is a strong result even on planar MNIST, for non-augmented and non-ensembled models. The full R2R model performs best in all conditions (though not significantly in the N/N condition), showing that both gauge padding and kernel expansion are necessary, and that our general (R2R) formulation works better in practice than using scalar fields (S2S or S2R). We notice also that non-equivariant models (NP+NE, NP, NE) do not generalize well to transformed data, a problem that is only partly solved by data augmentation. On the other hand, the models S2S, S2R, and R2R are exactly equivariant to symmetries g ? I, and so generalize perfectly to I-transformed test data, even when these were not seen during training. None of the models automatically generalize to continuously rotated inputs (R), but the equivariant models are closer, and can get even closer (&gt; 99%) when using SO(3) data augmentation during training. The fully SO(3)-equivariant S2CNN scores slightly worse than R2R, except in N/R and I/R, as expected. The slight decrease in performance of S2CNN for rotated training conditions is likely due to the fact that it has lower grid resolution near the equator. We note that the S2CNN is slower and less scalable than Ico CNNs (see supp. mat.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Climate Pattern Segmentation</head><p>We evaluate our method on the climate pattern segmentation task proposed by <ref type="bibr" target="#b33">Mudigonda et al. (2017)</ref>. The goal is to segment extreme weather events (Atmospheric Rivers (AR) and Tropical Cyclones (TC)) in climate simulation data.</p><p>We use the exact same data and evaluation methodology as . The preprocessed data as released by  consists of 16-channel spherical images at resolution r = 5, which we reinterpret as icosahedral signals (introducing slight distortion). See <ref type="bibr" target="#b33">(Mudigonda et al., 2017)</ref> for a detailed description of the data.</p><p>We compare an R2R and S2R model (details in Supp. Mat.). As shown in <ref type="table">Table 2</ref>, our models outperform both competing methods in terms of per-class and mean accuracy. The difference between our R2R and S2R model seems small in terms of accuracy, but when evaluated in terms of mean average precision (a more appropriate evaluation metric for segmentation tasks), the R2R model clearly outperforms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Stanford 2D-3D-S</head><p>For our final experiment, we evaluate icosahedral CNNs on the 2D-3D-S dataset <ref type="bibr" target="#b0">(Armeni et al., 2017)</ref>, which consists of 1413 omnidirectional RGB+D images with pixelwise semantic labels in 13 classes. Following <ref type="bibr" target="#b20">Jiang et al. (2018)</ref>, we sample the data on a grid of resolution r = 5 using bilinear interpolation, while using nearest-neighbour interpolation for the labels. Evaluation is performed by mean intersection over union (mIoU) and pixel accuracy (mAcc).</p><p>The network architecture is a residual U-Net <ref type="bibr" target="#b39">(Ronneberger et al., 2015;</ref><ref type="bibr" target="#b15">He et al., 2016)</ref> with R2R convolutions. The network consists of a downsampling and upsampling network. The downsampling network takes as input a signal at resolution r = 5 and outputs feature maps at resolutions r = 4, . . . , 1, with 8, 16, 32 and 64 channels. The upsampling network is the reverse of this. We pool over orientation channels right before applying softmax.</p><p>As shown in table 3, our method outperforms the method of , which in turn greatly outperforms standard planar methods such as U-Net on this dataset. mAcc mIoU  0.547 0.383 Ours (R2R-U-Net) 0.559 0.394 <ref type="table">Table 3</ref>. Mean accuracy and intersection over union for 2D-3D-S omnidirectional segmentation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper we have presented the general theory of gauge equivariant convolutional networks on manifolds, and demonstrated their utility in a special case: learning with spherical signals using the icosahedral CNN. We have demonstrated that this method performs well on a range of different problems and is highly scalable.</p><p>Although we have only touched on the connections to physics and geometry, there are indeed interesting connections, which we plan to elaborate on in the future. From the perspective of the mathematical theory of principal fiber bundles, our definition of manifold convolution is entirely natural. Indeed it is clear that gauge invariance is not just nice to have, but necessary in order for the convolution to be geometrically well-defined.</p><p>In future work, we plan to implement gauge CNNs on general manifolds and work on further scaling of spherical CNNs. Our chart-based approach to manifold convolution should in principle scale to very large problems, thus opening the door to learning from high-resolution planetary scale spherical signals that arise in the earth and climate sciences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Recommended reading</head><p>For more information on manifolds, fiber bundles, connections, parallel transport, the exponential map, etc., we highly recommend the lectures by <ref type="bibr" target="#b41">Schuller (2016)</ref>, as well as the book <ref type="bibr" target="#b34">Nakahara (2003)</ref> which explain these concepts very clearly and at a useful level of abstraction.</p><p>For further study, we recommend <ref type="bibr" target="#b42">(Sharpe, 1997;</ref><ref type="bibr" target="#b43">Shoshichi Kobayashi, 1963;</ref><ref type="bibr" target="#b17">Husem?ller, 1994;</ref><ref type="bibr" target="#b44">Steenrod, 1951;</ref><ref type="bibr" target="#b50">Wendl, 2008;</ref><ref type="bibr" target="#b11">Crane, 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Mathematical Theory &amp; Physics Analogy</head><p>From the perspective of the theory of principal fiber bundles, our work can be understood as follows. A fiber bundle E is a space consisting of a base space B (the manifold M in our paper), with at each point p ? B a space F p called the fiber at p. The bundle is defined in terms of a projection map ? : E ? B, which determines the fibers as F p = ? ?1 (p). A principal bundle is a fiber bundle where the fiber F carries a transitive and free right action of a group G (the structure group).</p><p>One can think of the fiber F p of a principal bundle as a (generalized) space of frames at p. Due to the free and transitive action of G on F p , we have that F p is isomoprhic to G as a G-space, meaning that it looks like G except that it does not have a distinguished origin or identity element as G does (i.e. there is no natural choice of frame).</p><p>A gauge transformation is then defined as a principal bundle automorphism, i.e. a map from P ? P that maps fibers to fibers in a G-equivariant manner. Sometimes the automorphism is required to fix the base space, i.e. project down to the identity map via ?. Such a B-automorphism will map each fiber onto itself, so it restricts to a G-space automorphism on each fiber.</p><p>Given a principal bundle P and a vector space V with representation ? of G, we can construct the associated bundle P ? ? V , whose elements are the equivalence classes of the following equivalence relation on P ? V :</p><formula xml:id="formula_14">(p, v) ? (pg, ?(g ?1 )v).<label>(8)</label></formula><p>The associated bundle is a fiber bundle over the same base space as P , with fiber isomorphic to V .</p><p>A (matter) field is described as a section of the associated bundle A, i.e. a map ? : B ? A that satisfies ? ? ? = 1 B . Locally, one can describe a section as a function B ? V (as we do in the paper), but globally this is not possible unless the bundle is trivial.</p><p>The group of automorphisms of P (gauge transformations) acts on the space of fields (sections of the associated bundle). It is this group that we wish to be equivariant to.</p><p>From this mathematical perspective, our work amounts to replacing the principal G bundle 3 H ? H/G used in the work on regular and steerable G-CNNs of <ref type="bibr" target="#b7">Cohen et al. (2018a;</ref><ref type="bibr" target="#b50">c)</ref>, by another principal G bundle, namely the frame bundle of M . Hence, this general theory can describe in a unified way the most prominent and geometrically natural methods of geometrical deep learning <ref type="bibr" target="#b4">Boscaini et al., 2016)</ref>, as well as all G-CNNs on homogeneous spaces.</p><p>Indeed, if we build a gauge equivariant CNN on a homogeneous space H/G (e.g. the sphere S 2 = SO(3)/ SO(2)), it will (under mild conditions) automatically be equivariant to the left action of H also. To see this, note that the left action of H on itself (the total space of the principal G bundle) can be decomposed into an action on the base space H/G (permuting the fibers), and an action on the fibers (cosets) that factors through G (see e.g. Sec. 2.1 of <ref type="bibr">(Cohen et al., 2018c)</ref>). The action on the base space preserves the local neighbourhoods from which we compute filter responses, and equivariance to the action of G is ensured by the kernel constraint. Since G-CNNs  and gauge equivariant CNNs employ the most general equivariant map, we conclude that they are indeed the same, for bundles H ? H/G. Thus, "gauge theory is all you need".</p><p>(We plan to expand this argument in a future paper)</p><p>Most modern theories of physics are gauge theories, meaning they are based on this mathematical framework. In such theories, any construction is required to be gauge invariant (i.e. the coefficients must be gauge equivariant), for otherwise the predictions will depend on the way in which we choose to represent physical quantities. This logic applies not just to physics theories, but, as we have argued in the paper, also to neural networks and other models used in machine learning. Hence, it is only natural that the same mathematical framework is applicable in both fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Deriving the kernel constraint</head><p>The gauge equivariant convolution is given by</p><formula xml:id="formula_15">(K f )(p) = R d K(v)? in (g p?qv )f (q v )dv.<label>(9)</label></formula><p>Under a gauge transformation, we have:</p><formula xml:id="formula_16">v ? g ?1 p v, f (q v ) ? ? in (g ?1 qv )f (q v ), w p ? w p g p , g p?qv ? g ?1 p g p?qv g qv .<label>(10)</label></formula><p>It follows that q v is unchanged, because q v = exp p w p v ? exp p (w p g p )(g ?1 p v) = q v . Substituting the rest in the convolution equation, we find</p><formula xml:id="formula_17">R d K(g ?1 p v)? in (g ?1 p g p?qv g qv )? in (g ?1 qv )f (q v )dv = R d K(g ?1 p v)? in (g ?1 p )? in (g p?qv )f (q v )dv (11) Now if K(g ?1 p v) = ? out (g ?1 p )K(v)? in (g p ) (i.e.</formula><p>K satisfies the kernel constraint), then we get</p><formula xml:id="formula_18">(K f )(p) ? ? out (g ?1 p )(K f )(p),<label>(12)</label></formula><p>i.e. K f transforms as a ? out -field under gauge transformations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.">Additional information on experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.1.">MNIST experiments</head><p>Our main model consists of 7 convolution layers and 3 linear layers. The first layer is a scalar-to-regular gauge equivariant convolution layer, and the following 6 layers are regularto-regular layers. These layers have 8, <ref type="bibr">16,</ref><ref type="bibr">16,</ref><ref type="bibr">24,</ref><ref type="bibr">24,</ref><ref type="bibr">32,</ref><ref type="bibr">64</ref> output channels, and stride 1, 2, 1, 2, 1, 2, 1, respectively.</p><p>In between convolution layers, we use batch normalization <ref type="bibr" target="#b19">(Ioffe &amp; Szegedy, 2015)</ref> and ReLU nonlinearities. When using batch normalization, we average over groups of 6 feature maps, to make sure the operation is equivariant. Any pointwise nonlinearity (like ReLU) is equivariant, because we use only trivial and regular representations realized by permutation matrices.</p><p>After the convolution layers, we perform global pooling over spatial and orientation channels, yielding an invariant representation. We map these through 3 FC layers (with 64, 32, 10 channels) before applying softmax.</p><p>The other models are obtained from this one by replacing the convolution layers by scalar-to-regular + orientation pooling (S2R) or scalar-to-scalar (S2S) layers, or by disabling G-padding (NP) and/or kernel expansion (NE), always adjusting the number of channels to keep the number of parameters roughly the same.</p><p>The <ref type="figure">Spherical CNN (S2CNN)</ref> is obtained from the R2R model by replacing the S2R and R2R layers by spherical and SO(3) convolution layers, respectively, keeping the number of channels and strides the same. The Spherical CNN uses a different grid than the Icosahedral CNN, so we adapt the resolution / bandwidth parameter B to roughly match the resolution of the Icosahedral CNN. We use B = 26, to get a spherical grid of size 2B ? 2B = 52 ? 52. Note that this grid has higher resolution at the poles, and lower resolution near the equator, which explains why the S2CNN performs a bit worse when trained on rotated data instead of digits projected onto the north-pole. To implement strides, we reduce the output bandwidth by 2 at each layer with stride.</p><p>The spherical convolution takes a scalar signal on the sphere as input, and outputs scalar signals on SO(3), which is analogous to a regular field over the sphere. SO(3) convolutions are analogous to R2R layers. We note that this is a stronger Spherical CNN architecture than the one used by <ref type="bibr" target="#b10">(Cohen et al., 2018b)</ref>, which achieves only 96% accuracy on spherical MNIST.</p><p>The models were trained for 60 epochs, or 1 epoch of the 60? augmented dataset (where each instance is transformed by each icosahedron symmetry g ? I, or by a random rotation g ? SO(3)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.2.">Climate experiments</head><p>For the climate experiments, we used a U-net with regularto-regular convolutions. The first layer is a scalar-to-regular convolution with 16 output channels. The downsampling path consists of 5 regular-to-regular layers with stride 2, and 32, 64, 128, 256, 256 output channels. The downsampling path takes as input a signal with resolution r = 5 (i.e. 10242 pixels), and outputs one at r = 0 (i.e. 12 pixels).</p><p>The decoder is the reverse of the encoder in terms of resolution and number of channels. Upsampling is performed by bilinear interpolation (which is exactly equivariant), before each convolution layer (which uses stride 1). As usual in the U-net architecture, each layer in the upsampling path takes as input the output of the previous layer, as well as the output of the encoder path at the same resolution.</p><p>Each convolution layer is followed by equivariant batchnorm and ReLU.</p><p>The model was trained for 15 epochs with batchsize 15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10.3.">2D-3D-S experiments</head><p>For the 2D-3D-S experiments, we used a residual U-Net with the following architecture.</p><p>The input layer is a scalar-to-regular layer with 8 channels, followed by batchnorm and relu. Then we apply 4 residual blocks with 16, 32, 64, 64 output channels, each of which uses stride=2. In the upsampling stream, we use 32, 16, 8, 8 channels, for the residual blocks, respectively. Each upsampling layer receives input from the corresponding downsampling layer, as well as the previous layer. Upsampling is performed using bilinear interpolation, and downsampling by hexagonal max pooling.</p><p>The input resolution is r = 5, which is downsampled to r = 1 by the downsampling stream.</p><p>Each residual block consists of a convolution, batchnorm, skipconnection, and ReLU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11.">Computational complexity analysis of Spherical and Icosahedral CNNs</head><p>One of the primary motivations for the development of the Icosahedral CNN is that it is faster and more scalable than Spherical CNNs as originally proposed. The Spherical CNN as implemented by <ref type="bibr" target="#b10">(Cohen et al., 2018b)</ref> uses feature maps on the sphere S 2 and rotation group SO(3) (the latter of which can be thought of a regular field on the sphere), sampled on the SOFT grids defined by <ref type="bibr" target="#b25">(Kostelec &amp; Rockmore, 2007)</ref>, which have shape 2B ? 2B and 2B ? 2B ? 2B, respectively (here B is the bandwidth / resolution parameter). Specifically, the grid points are:</p><formula xml:id="formula_19">? j1 = 2?j 1 2B , ? k = ?(2k + 1) 4B , ? j2 = 2?j 2 2B ,<label>(13)</label></formula><p>where (? j1 , ? k ) form a spherical grid and (? j1 , ? k , ? j2 ) form an SO(3) grid (for j 1 , k, j 2 = 0, . . . 2B ? 1). These grids have two downsides.</p><p>Firstly, because the SOFT grid consists of equal-lattitude rings with a fixed number of points (2B), the spatial density of points is inhomogeneous, with a higher concentration of points near the poles. To get a sufficiently high sampling near the equator, we are forced to oversample the poles, and thus waste computational resources. For almost all applications, a more homogeneous grid is more suitable.</p><p>The second downside of the SOFT grid on SO(3) is that the spatial resolution (2B ? 2B; ?, ?) and angular resolution (2B; ?) are both coupled to the same resolution / bandwidth parameter B. Thus, as we increase the resolution of the spherical image, the number of rotations applied to each filter is increased as well, which is undesirable.</p><p>The grid used in the Icosahedral CNN addresses both concerns. It is spatially very homogeneous, and we apply the filters in 6 orientations, regardless of spatial resolution.</p><p>The generalized FFT algorithm used by  only works on the SOFT grid. Generalized FFTs for other grids exist <ref type="bibr" target="#b26">(Kunis &amp; Potts, 2003)</ref>, but are harder to implement. Moreover, although the (generalized) FFT can improve the asymptotic complexity of convolution for large input signals, the FFT-based convolution actually has worse complexity if we assume a fixed filter size. That is, the SO(3) convolution (used in most layers of a typical Spherical CNN) has complexity O(B 3 log B) which compares favorably to the naive O(B 6 ) spatial implementation. However, if we use filters with a fixed (and usually small) size, the complexity of a naive spatial implementation reduces to O(B 3 ), which is slightly better than the FFT-based im-plementation. Furthermore, because the Icosahedral CNN uses a fixed number of orientations per filter (i.e. 6), its computational complexity is even better: it is linear in the number of pixels of the grid, and so comparable to O(B 2 ) for the SOFT grid.</p><p>The difference in complexity is clearly visible in <ref type="figure" target="#fig_2">Figures 7  and 8</ref>, below. On the horizonal axis, we show the grid resolution r for the icosahedral grid H r (for the spherical CNN, we a SOFT grid with roughly the same number of spatial points). On the vertical axis, we show the amount of wallclock time (averaged over 100 runs) and memory required to run an SO(3) convolution (S2CNN) or a regular-to-regular gauge equivariant convolution (IcoNet) at that resolution. Note that since the number of grid pionts is exponential in r, and we use a logarithmic vertical axis, the figures can be considered log-log plots. Both plots were generated by running a single regular to regular convolution layer at the corresponding resolution r with 12 input and output channels. For a fair comparison with IcoCNNs we chose filter grid parameters so3 near identity grid(n alpha=6, max beta=np.pi/16, n beta=1, max gamma=2*np.pi, n gamma=6) for the spherical convolution layer. To guarantee a full GPU utilization, results were measured on an as large as possible batch size per datapoint and subsequently normalized by that batch size. As can be seen in <ref type="figure" target="#fig_2">Figure 7</ref>, the computational cost of running the S2CNN dramatically exceeds the cost of running the IcoCNN, particularly at higher resolutions. We did not run the spherical CNN beyond resolution r = 6, because the network would not fit in GPU memory even when using batch size 1.</p><p>As shown in <ref type="figure" target="#fig_3">Figure 8</ref>, the Spherical CNN at resolution r = 6 uses about 10GB of memory, whereas the Icosahedral CNN uses only about 1GB. Since we used the maximum batch size with subsequent normalization for each resolution the reported memory consumption mainly reflects the memory cost of the feature maps, not the constant memory cost of the filter banks.</p><p>Aside from the theoretical asymptotic complexity, the actual computational cost depends on important implementation details. Because the heavy lifting of the Icosahedral CNN is all done by a single conv2d call, our method benefits from the extensive optimization of, and hardware support for this operation. By contrast, the generalized FFT used in the original Spherical CNN uses a conventional FFT, as well as matrix multiplcations with spectral matrices of size 1, 3, 5, 7, . . . , 2L + 1 (the SO(3) spectrum is matrixvalued, instead of the scalar valued spectrum for commutative groups). Implementing this in a way that is fast in practice is more challenging.</p><p>A final note on scalability. For some problems, such as the analysis of high resolution global climate or weather data, it is unlikely that even a single feature map will fit in memory at once on current or near-term future hardware. Hence, it may be useful to split large feature maps into local charts, and process each one on a separate compute node. For the final results to be globally consistent (so that each compute node makes equivalent predictions for points in the overlap of charts), gauge equivariance is indispensable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="12.">Details on G-Padding</head><p>In a conventional CNN, one has to pad the input feature map in order to compute an output of the same size. Although the icosahedron itself does not have a boundary, the charts do, and hence require padding before convolution. However, in order to faithfully simulate convolution on the icosahedron via convolution in the charts, the padding values need to be copied from another chart instead of e.g. padding by zeros. In doing so, a gauge transformation may be required.</p><p>To see why, note that the conv2d operation, which we use to perform the convolution in the charts, implicitly assumes that the signal is expressed relative to a fixed global gauge in the plane, namely the frame defined by the x and y axes. This is because the filters are shifted along the x and y directions by conv2d, and as they are shifted they are not rotated. So the meaning of "right" and "up" doesn't change as we move over the plane; the local gauge at each position is aligned with the global x and y axes.</p><p>Hence, it is this global gauge that we must use inside the charts shown in <ref type="figure">Figure 4</ref> (right) of the main paper. It is important to note that although all frames have the same numerical expression e 1 = (1, 0), e 2 = (0, 1) relative to the x and y axes, the corresponding frames on the icosahedron itself are different for different charts. Since feature vectors are represented by coefficients that have a meaning only relative to a frame, they have a different numerical expression in different charts in which they are contained. The numerical representations of a feature vector in two charts are related by a gauge transformation.</p><p>To better understand the gauge transformation intuitively, consider a pixel p on a colored edge in <ref type="figure">Fig. 4</ref> of the main paper, that lies in multiple charts. Now consider a vector attached at this pixel (i.e. in T p M ), pointing along the colored edge. Since the colored edge may have different orientations when pictured in different charts, the vector (which is aligned with this edge) will also point in different directions in the charts, when the charts are placed on the plane together as in <ref type="figure">Figure 4</ref>. More specifically, for the choice of charts we have made, the difference in orientation is always one "click", i.e. a rotation by plus or minus 2?/6. This is the gauge transformation g ij (p), which describes the transformation at p when switching between chart i and j.</p><p>The transformation g ij (p) acts on the feature vector at p via the matrix ?(g ij (p)), where ? is the representation of G = C 6 associated with the feature space under consideration. In this work we only consider two kinds of representations: scalar features with ?(g) = 1, and regular features with ? equal to the regular representation: </p><p>That is, a cyclic permutation of 6 elements. Since 2?/6 is a generator of C 6 , the value of ? at the other group elements is determined by this matrix: ?(k ? 2?/6) = ?(2?/6) k . If the feature vector consists of multiple scalar or regular features, we would have a block-diagonal matrix ?(g ij (p)).</p><p>We implement G-padding by indexing operations on the feature maps. For each position p to be padded, we precompute g ij (p), which can be +1 ? 2?/6 or 0 or ?1 ? 2?/6. We use these to precompute four indexing operations (for the top, bottom, left and right side of the charts).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 5 .</head><label>5</label><figDesc>G-Padding (scalar  signal)    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 6 .</head><label>6</label><figDesc>Kernel expansion for scalar-to-regular (Rin = 1, Rout = 6; left) and regular-to-regular (Rin = Rout = 6; right) convolution. Top: free parameters. Bottom: expanded kernel used in conv2d.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 7 .</head><label>7</label><figDesc>Comparison of computational cost (in wallclock time) of Icosahedral CNNs (IcoNet) and Spherical CNNs (S2CNN,<ref type="bibr" target="#b10">(Cohen et al., 2018b)</ref>), at increasing grid resolution r.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 8 .</head><label>8</label><figDesc>Comparison of memory usage of Icosahedral CNNs (IcoNet) and Spherical CNNs (S2CNN,<ref type="bibr" target="#b10">(Cohen et al., 2018b)</ref>), at increasing grid resolution r.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For points that are close enough, there is always a unique geodesic. Since the kernel has local support, p and qv will be close for all non-zero terms.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">As an abstract group, I A5 (the alternating group A5), but we use I to emphasize that it is realized by a set of 3D rotations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Cohen, T. S., Geiger, M., and Weiler, M. Intertwiners   between Induced Representations (with Applications to the Theory of Equivariant Neural Networks). 2018c.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">It is more common to use the letter G for the supergroup and H for the subgroup, but that leads to a principal H-bundle G ? G/H, which is inconsistent with the main text, where we use a principal G bundle. So we swap H and G here.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Chiyu "Max" Jiang and Mayur Mudigonda for help obtaining and interpreting the climate data, and Erik Verlinde for helpful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Joint 2D-3D-Semantic Data for Indoor Scene Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-02" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Roto-Translation Covariant Convolutional Networks for Medical Image Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Lafarge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A J</forename><surname>Eppenhof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P W</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spherical convolutions and their application in molecular modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Boomsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Frellsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Melzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Castellani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning shape correspondence with anisotropic convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodol?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Geometric deep learning: Going beyond Euclidean data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Spectral Networks and Deep Locally Connected Networks on Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A General Theory of Equivariant CNNs on Homogeneous Spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Group equivariant convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Steerable</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cnns</surname></persName>
		</author>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Koehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cnns</surname></persName>
		</author>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Discrete Differential Geometry: An Applied Introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">30664</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>The climate dataset released by</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<title level="m">Stanford 2D-3D-S datasets were downloaded and evaluated by QUvA researchers</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning SO(3) equivariant representations with spherical cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Esteves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Allen-Blanchette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep models of interactions across sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Hartford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Leyton-Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravanbakhsh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W T</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hexaconv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Fibre</forename><surname>Husem?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bundles</surname></persName>
		</author>
		<idno>978-0-387-94087-8</idno>
		<title level="m">Number 20 in Graduate Texts in Mathematics</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note>3rd ed edition</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Predicting molecular properties with covariant compositional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Hy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="issue">24</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
			<affiliation>
				<orgName type="collaboration">cs</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
			<affiliation>
				<orgName type="collaboration">cs</orgName>
			</affiliation>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<idno>arXiv: 1502.03167</idno>
		<ptr target="http://arxiv.org/abs/1502.03167" />
		<imprint>
			<date type="published" when="2015-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kashinath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Prabhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niessner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Spherical CNNs on Unstructured Grids. In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Clebsch-Gordan Nets: A Fully Fourier Space Spherical Convolutional Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Covariant Compositional Networks For Learning Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Trivedi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">SOFT: SO(3) Fourier Transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Kostelec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Rockmore</surname></persName>
		</author>
		<ptr target="https://www.cs.dartmouth.edu/?geelong/soft/soft20_fx.pdf" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Fast spherical Fourier algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kunis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Potts</surname></persName>
		</author>
		<idno>0377-0427</idno>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">161</biblScope>
			<biblScope unit="page" from="75" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Introduction to Riemannian Manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<idno>978-3-319-91754-2</idno>
		<imprint>
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
	<note>Graduate Texts in Mathematics. 2 edition</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep Learning 3D Shapes using Alt-Az Anisotropic 2-Sphere Convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Karthik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">An Equivariant Bayesian Convolutional Network predicts recombination hotspots and accurately resolves binding motifs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Rotation equivariant vector field networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marcos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Invariant and Equivariant Graph Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ben-Hamu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lipman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.09902</idno>
	</analytic>
	<monogr>
		<title level="j">Cs</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<title level="m">Geodesic convolutional neural networks on riemannian manifolds</title>
		<imprint>
			<publisher>ICCVW</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Segmenting and Tracking Extreme Climate Events using Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mudigonda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mahesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kashinath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>O&amp;apos;brien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Prabhat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nakahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Topology</forename><surname>Geometry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Physics</forename></persName>
		</author>
		<idno>978-0-7503-0606-5</idno>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep roto-translation scattering for object classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oyallon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Perraudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kacprzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sgier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deepsphere</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.12186</idno>
		<title level="m">Efficient spherical Convolutional Neural Network with HEALPix sampling for cosmological applications</title>
		<imprint>
			<date type="published" when="2018-10" />
		</imprint>
	</monogr>
	<note>astro-ph</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multi-directional geodesic neural networks via equivariant convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Poulenard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Equivariance through parameter-sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P?czos</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Schonsheck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.07857</idno>
		<title level="m">Parallel Transport Convolution: A New Tool for Convolutional Neural Networks on Manifolds</title>
		<imprint>
			<date type="published" when="2018-05" />
		</imprint>
	</monogr>
	<note>cs, math, stat</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schuller</surname></persName>
		</author>
		<title level="m">Lectures on the Geometrical Anatomy of Theoretical Physics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Differential Geometry: Cartan&apos;s Generalization of Klein&apos;s Erlangen Program</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Sharpe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Shoshichi Kobayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of Differential Geometry</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">The Topology of Fibre Bundles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Steenrod</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning spherical convolution for fast features from 360 imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Flat2sphere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Tensor Field Networks: Rotation-and Translation-Equivariant Neural Networks for 3D Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kohlhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riley</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2018-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Rotation Equivariant CNNs for Digital Pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Veeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Linmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winkens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In MICCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning Rotationally Equivariant Features in Volumetric Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Boomsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>3d Steerable</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cnns</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning Steerable Filters for Rotation Equivariant CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Storath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Lecture Notes on Bundles and Connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wendl</surname></persName>
		</author>
		<ptr target="https://www.mathematik.hu-berlin.de/?wendl/connections.html" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">3D G-CNNs for Pulmonary Nodule Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Winkels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Imaging with Deep Learning (MIDL)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Equivariance to 3d rotation and translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Brostow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cubenet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Harmonic Networks: Deep Translation and Rotation Equivariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Garbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Turmukhambetov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poczos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J ;</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garnett</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Guyon, I</title>
		<editor>R.</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
