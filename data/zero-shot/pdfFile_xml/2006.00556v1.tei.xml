<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Virtual Event</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Virtual Event, China. ACM</publisher>
				<availability status="unknown"><p>Copyright Virtual Event, China. ACM</p>
				</availability>
				<date>July 25-30, 2020. July 25-30, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoji</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
							<email>xiangnanhe@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyang</forename><surname>Gao</surname></persName>
							<email>jinyang.gjy@alibaba-inc.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Li</forename><surname>Zhang</surname></persName>
							<email>zhzhang@cs.umn.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoji</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyang</forename><surname>Gao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Li</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<country>Twin Cities</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Twin Cities</orgName>
								<orgName type="institution">University of Minnesota</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Virtual Event</title>
					</analytic>
					<monogr>
						<title level="m">China In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;20)</title>
						<meeting> <address><addrLine>New York, NY, USA</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Virtual Event, China. ACM</publisher>
							<biblScope unit="volume">10</biblScope>
							<date type="published">July 25-30, 2020. July 25-30, 2020</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3397271.3401066</idno>
					<note>CCS CONCEPTS ? Information systems ? Recommender systems. KEYWORDS Next-basket recommendation, k-nearest neighbors, item frequency, recurrent neural networks * Xiangnan He is the corresponding author. ACM ISBN 978-1-4503-8016-4/20/07. . . $15.00</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Next-basket recommendation (NBR) is prevalent in e-commerce and retail industry. In this scenario, a user purchases a set of items (a basket) at a time. NBR performs sequential modeling and recommendation based on a sequence of baskets. NBR is in general more complex than the widely studied sequential (session-based) recommendation which recommends the next item based on a sequence of items. Recurrent neural network (RNN) has proved to be very effective for sequential modeling, and thus been adapted for NBR. However, we argue that existing RNNs cannot directly capture item frequency information in the recommendation scenario.</p><p>Through careful analysis of real-world datasets, we find that personalized item frequency (PIF) information (which records the number of times that each item is purchased by a user) provides two critical signals for NBR. But, this has been largely ignored by existing methods. Even though existing methods such as RNN based methods have strong representation ability, our empirical results show that they fail to learn and capture PIF. As a result, existing methods cannot fully exploit the critical signals contained in PIF. Given this inherent limitation of RNNs, we propose a simple item frequency based k-nearest neighbors (kNN) method to directly utilize these critical signals. We evaluate our method on four public real-world datasets. Despite its relative simplicity, our method frequently outperforms the state-of-the-art NBR methods -including deep learning based methods using RNNs -when patterns associated with PIF play an important role in the data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Recommendation systems have been applied in many different applications <ref type="bibr" target="#b0">[1]</ref>. NBR is a type of recommendation problem that aims to recommend a set of items to a user based on his/her historical purchased baskets <ref type="bibr" target="#b36">[36]</ref> <ref type="bibr" target="#b45">[45]</ref> <ref type="bibr" target="#b44">[44]</ref> <ref type="bibr" target="#b46">[46]</ref>, which is prevalent in E-commerce and retail industry. Unlike top-n recommendation (whose historical record is a set of items) <ref type="bibr" target="#b33">[33]</ref> and sequential recommendation (whose historical record is a sequence of items) <ref type="bibr" target="#b31">[31]</ref>, the historical record of the next-basket recommendation is a sequence of sets or sequential sets (whose element is a set). Considering the historical records, top-n recommendation and sequential/session-based recommendation can be seen as special cases of NBR when the NBR only has one basket and has a sequence of baskets whose size are all of 1, respectively. But in recommendation step, top-n recommendation only recommends new items that are not contained in the user's historical records, whereas both sequential/session-based recommendation and NBR recommend new and old items. Even though sequential/session-based recommendation is similar to NBR, we cannot directly apply sequential/session-based recommendation method to do NBR without messing up the information existing in the sequential sets <ref type="bibr" target="#b0">1</ref> .</p><p>The challenging part in NBR is how to model the relation between the historical records and recommended items. Existing NBR methods use different ways to model the information in the historical records as the user profile and capture user-item interactions for predicting the next basket. RNNs have become one of the mainstream choices as it is easy to be tweaked for sequential modeling. However, we argue that existing RNNs cannot directly capture item frequency information in the recommendation scenario.</p><p>Recently, repeated behaviors are found to bring considerable performance improvement in both sequential/session-based recommendation <ref type="bibr" target="#b42">[42]</ref> <ref type="bibr" target="#b35">[35]</ref> and NBR <ref type="bibr" target="#b19">[20]</ref>. It is based on the observation that repeated purchases widely exist in the users' records. However, our analysis shows that PIF contains more information than repeated purchase pattern. We observe that similar users' PIF also contains collaborative purchase pattern. This new pattern shows that if a user repeatedly purchases a item, similar users are likely to purchase the same item. Existing methods fail to fully utilize this useful information contained in PIF.</p><p>In this paper, we propose a simple k-nearest neighbors (kNN) based method which directly captures the two useful patterns associated with PIF. To demonstrate the effectiveness, we also observe and analyze the limitation of existing methods to capture the important patterns associated with PIF as they cannot learn the vector addition well. In summary, our contributions are as follows:</p><p>? We analyze two patterns associated with PIF and the target basket. The collaborative purchase pattern that PIF can contribute to the NBR in a collaborative way is discovered. ? We discover the difficulty of RNNs in learning vector addition in recommendation setting. To our best knowledge, we are the first to present and analyze this phenomenon. ? We propose a simple and effective kNN based method to directly capture the two useful patterns associated with PIF. The temporal dynamics is also considered in the proposed method. ? We perform experiments on four real-world data sets to demonstrate the effectiveness of the proposed method. The rest of the paper is organized as follows: Section 2 presents the preliminaries. In section 3, we describe our proposed method. In section 4, we discuss the related work. In section 5, we evaluate our method. Section 6 provides some concluding remarks and future directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>In this section, the NBR problem is first formally defined. Next, we analyze the patterns associated with PIF for NBR. Our analysis towards real-world data sets reveals that PIF contains two important signals for the next target basket. Finally, we summarize the existing methods, and discuss the their difficulty in learning PIF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Definition</head><p>Given the historical purchase records of a user {v 1 , v 2 , ..., v i , ..., v t }, where a set of items (a basket) at the i-th time step is represented as a 0/1 vector v i whose entry c j (j ? [0, d]) is set to 1 if the corresponding item appears in the basket, our goal is to predict the next set of items (next basket)v t+1 .</p><p>Following the literature <ref type="bibr" target="#b36">[36]</ref>[46], we consider a fixed-size set with s items as the recommendation for the next basket.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Relation between PIF and Target Basket</head><p>In this section, we discuss two important patterns associated with PIF that can help predict the target next basket: repeated purchase pattern and collaborative purchase pattern.</p><p>Repeated purchase behavior in grocery shopping and online activities has been studied in the areas of economics and psychology theoretically and empirically <ref type="bibr" target="#b1">[2]</ref>[5][9] <ref type="bibr" target="#b21">[22]</ref>. This pattern has been used in recent sequential/session-based recommendation method <ref type="bibr" target="#b35">[35]</ref> <ref type="bibr" target="#b42">[42]</ref> and NBR method <ref type="bibr" target="#b19">[20]</ref> <ref type="bibr" target="#b41">[41]</ref>, and is shown to get considerable performance gain. Specifically, a simple baseline which recommends the user-specific most frequent items can sometimes outperform many existing methods <ref type="bibr" target="#b19">[20]</ref>. The good performance of this baseline comes from the assumption that the next target basket often contains items that have appeared in the user's historical records. And the higher PIF is associated with a higher probability of the corresponding item to appear in the target basket again. However, this assumption has a limitation that the PIF only helps the target user. It ignores the collaboration among different users. This is the core idea of collaborative filter <ref type="bibr" target="#b25">[26]</ref>. A natural question is whether PIF can help in a collaborative manner. To verify this, we investigate the co-occurrence of the same item to simultaneously appear in the past baskets of the similar users and the next basket of the target user on four real-world data sets (the details of the data are in section 5.1.1). To compare with repeated purchase pattern, we also investigate the co-occurrence of the same item to simultaneously appear in the past baskets of the target user and the next basket of the target user. We simply use the PIF vector (PI F vector = t i=1 v i ) to represent each user. For each user, his/her top 300 nearest neighbors (the total number of users in all data sets is no less than 10,000) are found based on the PIF vector. Denote the set of all items in target user's past baskets as P. Denote the set of all items in the neighbors' past baskets as set N . The target basket is denoted as T . We calculate the following four ratios:</p><p>? Recall P : The average recall of using P to retrieve items in T . Formally, Recall P = |P ?T | |T | . It represents the ratio of items captured by repeated purchase pattern. . It represents the ratio of items not captured by repeated purchase pattern and collaborative purchase pattern. From <ref type="table" target="#tab_0">Table 1</ref>, we can make several observations. First, Recall P indicates that the repeated purchase pattern plays a considerable role in four data sets but varies dramatically across different data sets. Second, Recall N indicates that the collaborative purchase pattern plays much more important role in all four data sets. It can help retrieve more than half items in the target basket. Surprisedly, this ratio can increase to more than 0.8 in three data sets. Note that, here we only use 300 nearest neighbors. It is expected that Recall N will increase if we increase the number of neighbors. Third, Recall P ?N indicates that these two patterns have overlap. Based on Recall N ? Recall P ?N , we can also infer that the collaborative purchase pattern provides extra signal related to the target basket. Fourth, Recall P ?N indicates that only a small part of items are not covered by the two patterns. It implies that the unseen patterns are only a small part in the next basket. Based on 1 ? Recall P ?N , we find that combining both patterns can achieve better performance than any single pattern. Note that above analysis is based on complete P and N whose size is still large. In general, we only recommend a small number of items in NBR. Nonetheless this analysis demonstrates the potential incorporating PIF in NBR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Existing NBR Methods</head><p>MC based methods: Rendle et al. <ref type="bibr" target="#b36">[36]</ref> propose the classical NBR method which is based on factorization and Markov chain. Their method models the personalized item-item transition matrix between any pair of consecutive baskets. Wang et al. <ref type="bibr" target="#b44">[44]</ref> propose a similar Markov chain model. Instead of using tensor factorization, they propose to use pooling to aggregate the items in the recent basket as the recent basket representation and predict the next basket based on the aggregated representation. Ying et al. <ref type="bibr" target="#b45">[45]</ref> enhance the structure in <ref type="bibr" target="#b44">[44]</ref> and use attention mechanism to replace the pooling operation. The attention mechanism can focus on the most relevant items, which brings performance improvement. Also, they partition historical items into two sets. The items in the recent basket represent the short-term set and the items in the baskets before the recent one represent the long-term set. Separated attention mechanisms are applied on both sets to generate the hybrid user representation. The prediction is based on the hybrid user representation and the item embedding. RNN based methods: The assumption behind MC based methods is that the next basket is mainly decided by the last (or few last) baskets. However, MC based methods miss to capture the high-order dependency from long time ago. In order to capture the whole historical baskets, RNNs are used to model the whole history <ref type="bibr" target="#b46">[46]</ref> <ref type="bibr" target="#b19">[20]</ref>. Both of them use the same structure as <ref type="bibr" target="#b44">[44]</ref> at each time step. The item embedding is first aggregated to generate the basket representation and then a RNN is used to model the temporal relation across all the baskets. The hidden state of the last step of RNN is the user representation. And the next basket is predicted based on the generated user representation and target item embedding. Sets2Sets <ref type="bibr" target="#b19">[20]</ref> also uses attention mechanism to focus on the most relevant baskets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Difficulty in Learning Item Frequency</head><p>As PIF contains critical information for NBR, an immediate question is: can existing methods capture this information? We argue that whether existing methods cannot capture this information, it will be hard for them to exploit this critical information. Formally, we investigate if existing methods can learn the result of vector addition t i=1 v i given the purchase recrods of a user. It is obvious that MC based methods cannot capture PIF, which is a type of high-order information, as MCs only record last or last few baskets. RNN based methods have strong representation ability as RNNs can approximate any computable function <ref type="bibr" target="#b40">[40]</ref>. If RNNs can aggregate the vectors in the same way that vector addition aggregates the vectors, the last hidden state of the RNNs should contain the PIF information 2 . In this section, we investigate if RNN can learn PIF.</p><p>In the following, we demonstrate that it is hard for RNNs to learn PIF due to the difficulty in the optimization. Our demonstration is as follows: First, we analyze that the phenomenon is related to the difficulty of searching the global optimal solution for RNNs. As many elements can lead to this problem, we approach this by eliminating other possible causes. Second, we derive a closed-form solution for RNNs to learn the vector addition. Based on these two steps, we conclude that even though RNNs have the general ability to learn, the training process sticks into a local minimum in current recommendation setting. Finally, we discuss if we can overcome this difficulty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Difficulty in Learning Vector</head><p>Addition. We use a synthetic data set to illustrate this phenomenon. (1) We generate 2500 sequences of vectors as the training data set. The dimensionality of all the vectors is 100. Each vector is a one-hot vector. The reason we only generate one-hot vectors is that any q-hot vector can be converted into q one-hot vectors. But if we generate q-hot vectors, we cannot simulate the case of addition for one-hot vectors. Thus, it is the simple but general case. Each sequence of vectors represents the vectors to be summed up. For simplicity, we fix the length of all the sequences as 10. Fixing the length to 10 can also avoid the difficulty of RNNs in handling long-term dependency <ref type="bibr" target="#b34">[34]</ref>. <ref type="formula" target="#formula_1">(2)</ref> To make sure we obtain vectors that have repeated items, we randomly select 2 out of the first 8 vectors as the last two vectors in each sequence of vectors.</p><p>Existing RNN based method <ref type="bibr" target="#b19">[20]</ref>[46] use a common module to aggregate the historical baskets as a user representation in <ref type="figure" target="#fig_1">Figure 1</ref>. Each basket is first input into the set embedding layer and then transformed into set embedding. After that, a RNN is used to aggregate all the set embeddings at different time steps to generate the final user representation as a summarized vector. This is the only part that has the potential to learn PIF as it goes through all the past records and aggregates them into a user representation. So we apply this module to learn vector addition on the synthetic data set. As only one-hot vectors are generated in the data, the set embedding layer is reduced to an item embedding layer that is to learn vector addition. The embedding size and RNN units are set to 64 (as our item space is 100, 64 is the max value we tried for compressed representation setting to handle the sparsity in the input data). Batch size is set to 64. The training loss is the average mean square error (MSE) between the output of the last step (the final predicted sum vector) and the ground truth (the real sum vector). GRU is used. Adam <ref type="bibr" target="#b24">[25]</ref> is used for optimization. The learning rate is set to 0.001. All the parameters of different layers are randomly initialized by the default setting of Pytorch.</p><p>widely used existing deep learning based recommendation methods. Note that the item embedding, which is the input of the RNN, and hidden state of RNN unit are usually of much smaller dimensionality (usually is 2 z ? <ref type="bibr" target="#b7">[8,</ref><ref type="bibr">128]</ref>, z ? Z) compared to the original one-hot vector (whose dimensionality is of at least several thousands). This can help avoid the parameter exploding and resolve the sparsity in the original one-hot vector space. So we need to project user representation back to the original space to get the predicted sum vector for t i=1 v i . The training process is shown in <ref type="figure" target="#fig_2">Figure 2</ref>. The training loss converges to 4 which is far from the optimal error 0. To further show this is a large training error, we consider a very simple baseline that directly predicts all the sum vectors as zero vectors. This baseline can achieve an average MSE of (1?0) 2 * 8+(2?0) 2 * 2) 10 = 1.6. Usually, we may speculate that the embedding results in information loss. Thus, we remove the embedding layer and directly forward the one-hot vector as the input of the RNN unit. Now the module shown in the <ref type="figure" target="#fig_1">Figure 1</ref> is simplified to a RNN. But this yields a similar training error. Considering that optimizer may also affect the results, we also check other two widely-used optimizers SGD <ref type="bibr" target="#b6">[7]</ref> and RMSprop 3 . However, the training error does not change with different optimizers.</p><p>A common concern for the failure of deep learning methods is that we do not have enough data for training. By increasing the training set size, the training loss is expected to decrease. To verify this, we double the data size. We generate 2500 additional sequences of vectors and merge them with the previous training data. However, the converged training error still remains the same.</p><p>Another common speculation for large training error is that the model's capability is not enough. We should continue to increase the dimensionality. However, we argue small dimensionality is able to learn the optimal solution as we will present a closed-form solution that is not related to the dimensionality in the next subsection.  2.4.2 Closed-form Solution for Vector Addition with RNN. There are many different variants of RNNs <ref type="bibr" target="#b11">[12]</ref>. Vanilla RNN <ref type="bibr" target="#b32">[32]</ref>, long shortterm memory (LSTM) <ref type="bibr" target="#b18">[19]</ref> and gated recurrent unit (GRU) <ref type="bibr" target="#b7">[8]</ref> are the most popular ones. LSTM and GRU are the extensions of vanilla RNN for handling long-term dependency problem. For simplicity, we focus on the vanilla RNN as other variants are built upon it. The extension to LSTM and GRU will be similar. The formalization of vanila RNN is as follows:</p><formula xml:id="formula_0">h t +1 = tanh(W h h t + W x x t +1 ),<label>(1)</label></formula><formula xml:id="formula_1">y t = f (W o h t ),<label>(2)</label></formula><p>where</p><formula xml:id="formula_2">W h ? R m?m , W x ? R m?n , and W o ? R l ?m are the coeffi- cient matrix.</formula><p>The activation function f is chosen according to the task.</p><p>As the length of the historical records varies, the RNN that learns the vector addition should output the cumulative sum at each step. Thus, y t should be the predicted sum of input x 1 , ..., x t . The corresponding ground truth is t i=1</p><p>x i . As our goal is to learn a linear operation addition, the nonlinear layer is not necessary. Thus, we remove all the nonlinear layers and rewrite Formula 1 and 2 as follows:</p><formula xml:id="formula_3">h t +1 = W h h t + W x x t +1 ,<label>(3)</label></formula><formula xml:id="formula_4">y t = W o h t ,<label>(4)</label></formula><p>If we recursively apply Equations 3 and 4, we obtain</p><formula xml:id="formula_5">y t = t i=1 W o W t ?i h W x x i ,<label>(5)</label></formula><p>where h 0 is the initial state which is a zero vector. Thus, the closedform solution is W o W x = I n?n = I l ?l and W h = I m?m . This closed-form solution indicates that the vanilla RNN can represent the vector addition without too many parameters if we can meet the constraints in the closed-form solution. A single layer RNN with hidden state of small dimensionality has enough representation ability. As the nonlinear activation function may affect the learning process, we also re-conduct the experiments to learn the vector addition with the simplified RNN version described by Equation 3 and 4. Other configurations are the same as before. The training process is shown in <ref type="figure" target="#fig_4">Figure 3</ref>. The training error still converges around 4. Thus, our results imply that the vanilla RNN has the ability to learn vector addition in theory, but in practice the optimizers cannot find this global minimal (or unable to do so in feasible time). To this end, we demonstrate the RNN based methods fail to capture PIF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">How to</head><p>Overcome the Difficulty. The closed-form solution provides a direct solution to overcome this difficulty by initializing the parameters in the RNN with the optimal solution. However, the closed-form solution forces the weighted matrices to be correlated to each others, which violates the effect of random and orthogonal weight initializations. Recent literature shows that the neural networks trained by stochastic gradient descent (SGD) from random initialization almost never suffer from non-smoothness or non-convexity, and can avoid local minima <ref type="bibr" target="#b10">[11]</ref>. And orthogonal weight initializations improve the convergence <ref type="bibr" target="#b20">[21]</ref>. Even though our closed-form solution is easy for the RNNs to learn the vector addition, it brings difficulty in training the RNNs to learn other objectives, e.g. temporal dynamics which is also important in NBR. We believe the solution to overcome the difficulty in training RNNs from the optimization perspective is not trivial. So we think PIF should be carefully captured as it is hard to learn PIF with RNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROPOSED METHOD</head><p>Model-based methods have been considered as better solution for traditional collaborative filter recommendation problem than neighbor-based methods as model-based methods can better generalize to unseen patterns <ref type="bibr" target="#b33">[33]</ref>. However, our empirical results in section 2.2 show that the unseen patterns only account for a small part in the target basket. Thus, we propose to resort to the classical and direct neighbor-based methods. To our best knowledge, even though kNN methods have been developed in collaborative filter for top n recommendation <ref type="bibr" target="#b25">[26]</ref>[10] and sequential/session recommendation <ref type="bibr" target="#b22">[23]</ref>, the kNN based method for NBR has not been explored.</p><p>We will leave the model-based methods as our future work. In the following, we introduce a simple and effective kNN based method called temporal-item-frequency-based user-KNN (TIFU-KNN). The proposed method directly utilizes the two important patterns associated with PIF. In addition, temporal dynamics is also considered to help select the items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Integrating Temporal Dynamics</head><p>PIF contains important information as we discuss in Section 2.2. However, there is a limitation: it cannot provide discriminative information for items with the same item frequency. Consequently, it is hard to distinguish items only with item frequency, which affects both neighbors searching and items selection in kNN-based method. To address this issue, we propose to consider the temporal dynamics of the repeated purchase. <ref type="figure" target="#fig_5">Figure 4</ref> shows the gap distribution of repeated purchase on four data sets used in our experiments. The gap value means that after how many baskets, the next purchase for the same item occurs again. We can observe that the short gaps dominate the repeated purchase. However, the gap distribution varies dramatically across different data sets. For ValuedShopper data set, the percentage of different gaps decreases slowly while other three data sets decreases faster. Generally, we can observe that recent purchases have more impact to trigger a repeated purchase than the behavior long time ago. Thus, we propose to assign decayed weights to the same item appearing at different time steps. The earlier the item appears, the smaller weight the item contributes to the final frequency. We will describe the details in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Nearest Neighbors based Method</head><p>Our kNN method consists of two parts: the similarity calculation (between the target user and other users) and the prediction (based on the target user and his neighbors). User Similarity Calculation: Considering each user's historical records are sequential sets of variable length, we propose to aggregate the historical records into one vector which is easy for similarity calculation. The direct way to aggregate the historical records is to sum them up. But this way has a limitation that we have shown in the last section. Also, it ignores that the users' preferences for products are drifting over time <ref type="bibr" target="#b27">[28]</ref>. This drifting suggests that recent records have more impact than the records long time ago. Thus, we make the items bought recently contribute more in the similarity calculation than the items bought long time ago. However, a single time decayed weight is not flexible to model another property of temporal dynamics that consecutive steps have small changes while steps far from each others have large changes. To capture both temporal dynamics, we propose to use hierarchical time decayed weights. Our user vector representation generation process is as follows (which is shown in the <ref type="figure" target="#fig_6">Figure 5</ref>): (1) We partition the historical t baskets (vectors) into m groups equally. Denote the group size as x = t m . The j-th vector (in temporal order) within each group is multiplied by a time-decayed weight r</p><p>x ?j b , where r b is the time-decayed ratio within group. Then, we calculate the average vector of the weighted vectors within each group as the corresponding group vector v ?r oup . If the vectors cannot be equally partitioned, the group size x is calculated by ? t m ? except for the first group whose size is t ? x ? (m ? 1).</p><p>(2) The i-th group vector v ?r oup i is multiplied by a time-decayed weight r m?i ? , where r ? is the time-decayed ratio across the groups. Then, we calculate the average vector of the weighted group vectors as the user vector representation u.</p><p>After we obtain the user vector representation, we can use different methods <ref type="bibr" target="#b38">[38]</ref> to calculate the similarity. Here we use the Euclidean distance to help calculate the similarity between users. The small(large) distance means large(small) similarity. We will leave the exploration of other similarity functions as our future work. We search the k nearest neighbors for each target user. Prediction: Our prediction is a combination of following two parts:</p><p>? Repeated purchase component: Denote the user representation of the target user as u t . It is corresponding to repeated purchase pattern. The final prediction is:</p><formula xml:id="formula_6">P = ? ? u t + (1 ? ?) ? u n ,</formula><p>where the ? is a hyper-parameter to balance two parts. The s items corresponding to the largest s entries in P are recommended.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORK</head><p>The related works include (1) Traditional collaborative recommendation methods that model user preferences without considering the temporal dynamics and have a set of items as the historical record; (2) Sequential recommendation methods that deal with a sequence of items or actions (each element is an item or action) as the user profile; and (3) NBR methods that deal with a sequence of baskets (each element is a set of items) as the user profile. Traditional collaborative recommendation: Collaborative Filtering (CF) <ref type="bibr" target="#b37">[37]</ref> is the classical recommendation method. CF usually learns from user-item ratings matrix and predict only based on this matrix. Existing CF methods can be classified into two categories: neighborhood-and model-based methods. Neighborhood-based methods are widely studied in traditional collaborative recommendation <ref type="bibr" target="#b33">[33]</ref>. The neighborhood-based methods contain two ways: user-based or item-based recommendation. User-based method like GroupLens <ref type="bibr" target="#b25">[26]</ref> predicts the interest of a target user for an item using the ratings for this item by the most similar users. The itembased method like itemKNN <ref type="bibr" target="#b9">[10]</ref> predicts the user-item rating based on the ratings of the target user for similar items. Model-based approaches use these ratings to learn a predictive model <ref type="bibr" target="#b26">[27]</ref>  <ref type="bibr" target="#b47">[47]</ref>. Due to the sequence structure in the historical records, natural language processing methods, like RNNs, attention mechanism, and Markov chain, can be applied to model the data <ref type="bibr" target="#b13">[14]</ref>[24] <ref type="bibr" target="#b17">[18]</ref>. Session-based Recommendation also belongs to this type as each session is a short sequence of behaviors or items <ref type="bibr" target="#b30">[30]</ref> <ref type="bibr" target="#b22">[23]</ref>. A kNN-based method shows competitive performance when it is compared to RNN-based method GRU4rec <ref type="bibr" target="#b22">[23]</ref>. Our kNN-based method is different from this method in both similarity calculation step and prediction step. Also, their method cannot be directly applied to NBR as discussed in the introduction.</p><p>Next-basket recommendation: NBR aims at predicting a set of items based on a sequence of past baskets (sets) <ref type="bibr">[</ref>  <ref type="bibr" target="#b34">[34]</ref>. We present another phenomenon that it is difficult for RNNs to learn a simple operation-vector addition. Even though we know training a deep neural network is np-complete in the worst case <ref type="bibr" target="#b5">[6]</ref>, the phenomenon discovered in this paper is different as we provide a closed-form solution. There is a need for more theoretical analysis to understanding this kind of difficulty in training RNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head><p>In this section, we conduct extensive experiments to answer the following research questions: RQ1: How is the effectiveness of the proposed methods? Can they outperform the state-of-the-art NBR methods? RQ2: How is the effectiveness of the temporal dynamics? RQ3: How is the effectiveness of each component to predict the target basket in the TIFU-KNN? RQ4: How do the hyper parameters affect the performance? Does each factor in the TIFU-KNN bring benefits? All the items bought in the same order are treated as a basket. We remove all the customers who have baskets less than 3 to ensure that temporal patterns exist in the past records. In Dunnhumby, we use the 50k users sampled data. In ValuedShopper data set, we use the sampled transactions data. In Instacart and TaFeng data sets, we remove the least frequent items. The left items retain more than 95% item purchase of all the transactions. The statistics of the data sets after pre-processing is shown in the <ref type="table" target="#tab_4">Table 2</ref>. We use recall and NDCG to evaluate our methods. Recall is a wildly-used measurement in the NBR <ref type="bibr" target="#b45">[45]</ref>. NDCG is a ranking based measure which takes into account the order of elements in a list <ref type="bibr" target="#b14">[15]</ref>. We calculate the NDCG for each basket based on the top s sorted elements list. All the measurements are calculated across all predicted next set of items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Settings</head><p>We use the past baskets of a given customer to predict his/her last basket. All the data sets are partitioned across users. The data is randomly partitioned into 5 folds across users. And 4 folds is used for training and 1 fold is used for test. We reserve the data of 10% users in the training set as the validation set for hyper parameters searching in all the methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Compared Methods.</head><p>Simple baselines:</p><p>? Top-n frequent (TopFreq): It uses the most frequent s items that appear in all the baskets of the training data as the predicted next baskets for all persons. ? Personalized Top-n frequent (PersonTopFreq): It uses the most frequent s items that appear in the past baskets of a given person as the prediction for the next basket. It directly use the PIF.</p><p>Tweaked methods:</p><p>? userKNN: It is classical collaborative filter based on kNN <ref type="bibr" target="#b25">[26]</ref>. In order to apply this method, we merge all the items in the historical baskets as a set of items. We recommend the top s items as the next basket. This baseline can show the difference between the proposed method and the existing user-based kNN method. ? RepeatNet: The latest RNN-based model for session-based recommendation which captures the repeated behaviors <ref type="bibr" target="#b35">[35]</ref>.</p><p>To apply this method to solve our problem, we transfer each basket into a sequence based on the ID's order. Then, we concatenate the sequences from different baskets in temporal order and get a sequence of items for each user.</p><p>Existing NBR methods:</p><p>? FPMC: The classical factorization based method for next basket recommendation. It use Markov chain and factorization method to represent the past baskets <ref type="bibr" target="#b36">[36]</ref>. Both sequential behaviors and users' personal tastes are taken into account for prediction. ? DREAM: A deep model based on embedding and RNN for next basket recommendation <ref type="bibr" target="#b46">[46]</ref>. It considers personal dynamic interests at different time and the global interactions of all baskets of the user over time. ? SHAN: A deep model based on hierarchical attention networks <ref type="bibr" target="#b45">[45]</ref> . It partitions the historical baskets into longterm and short-term parts to learn the long-term preference and short-term preference based on the corresponding items attentively. It can be directly applied in NBR and sequential/session-based recommendation as it treats the historical records as two sets. ? Sets2Sets: The state-of-the-art end-to-end method for following multiple baskets prediction based on RNN <ref type="bibr" target="#b19">[20]</ref>. Repeated purchase pattern is also integrated into the method. We focus on comparing with existing NBR methods. Other techniques used in top n recommendation and sequential/session-based recommendation are not the focus of this paper. We tune the hyper parameters in all the compared methods with grid search to achieve their best performance. For userKNN, the number of nearest neighbors is searched from the set of values [100, 300,500, 700, 900, 1100, 1300]. For FPMC, the dimension of factor is searched from the set of values <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr">64,</ref><ref type="bibr">128]</ref>. For RepeatNet, DREAM, SHAN, and Sets2Sets, the embedding size is searched from the set of values <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr">64,</ref><ref type="bibr">128]</ref>.  <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23]</ref> in ValuedShopper data set and from the set of values <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref> in other data sets, respectively. The parameters associated with the results reported in the methods comparison are shown in the <ref type="table" target="#tab_5">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Performance Comparison (RQ1)</head><p>The comparisons with baselines and existing methods are shown in the <ref type="table" target="#tab_6">Table 4</ref>. Several observations can be made. First, the simple top-n frequent baseline achieves reasonable performance compared to other existing methods in recall. It indicates that some popular items are commonly purchased by different users. But this simple baseline almost produces the worst performance across different data sets. It implies that users also have their distinct items which cannot be obtained through this simple baseline. Second, personalized top-n frequent method achieves competitive performance across all data sets. This verifies that the impact of the repeated purchase pattern from the target users plays an important role in the prediction.</p><p>Third, the existing NBR methods (excluding Sets2Sets) is surpassed by the baseline personalized top-n frequent method in Val-uedShopper, Instacart, and Dunnhumby data sets by a large margin. The reason is that existing methods (excluding Sets2Sets) cannot capture PIF. Even though Sets2Sets captures PIF explicitly, it is still worse than the personalized top-n frequent method in first two data sets. We believe the reason is that the learned coefficients cannot perfectly control Sets2Sets to rely on the PIF and RNN based module.</p><p>Fourth, the tweaked top-n recommendation method userKNN and session-based recommnedation method RepeatNet are worse than the state-of-the-art method Sets2Sets. The reason is that they ignore the important information existing in the sequential sets. For userKNN, it discards the PIF. RepeatNet outperforms other method without repeated purchase pattern when the repeated purchase affects a lot in the data (excluding TaFeng data set). But it performs worse than other methods with repeated purchase pattern (personalized top-n frequent baseline and Sets2Sets) as it also captures the non-existing order among the items within each basket.</p><p>Fifth, the proposed TIFU-KNN is better than other methods in ValuedShopper, Instacart and TaFeng data sets, which verifies the superiority of the proposed method. There is an exception in Dunnhumby data set that Sets2Sets achieves better NDCG while the proposed method achieves a little better recall. We believe the reason is that the embedding method used in Sets2Sets can help generalize to some unseen user-item patterns in the training set beyond the repeated purchase pattern and collaborative purchase pattern. It is consistent with our analysis in the section 2.2 that Dunnhumby has much more unseen patterns than other three data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Effectiveness of Temporal Dynamics (RQ2)</head><p>In this section, we investigate if the temporal dynamics brings positive effectiveness. For simplicity, we set the time decayed weights r b and r ? to the same ratio. We denote the set of the nonzero entries in repeated purchase component and collaborative purchase component as P and N , respectively. Then, we use the items in P ? N to retrieve items in the target basket and calculate the recall Recall P ?N . Recall P ?N quantifies the amount of unseen patterns.</p><p>The small value means large coverage by the repeated purchase pattern and collaborative purchase pattern. From <ref type="figure" target="#fig_8">Figure 6</ref>, we can observe that without the temporal dynamics, which is represented by ratio = 1, the proposed method usually has the largest number of unseen patterns. It implies that the temporal dynamics can help reduce the unseen patterns as better neighbors are searched.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Effectiveness of Different Components (RQ3)</head><p>In this section, we investigate the contributions from two patterns associated with PIF. The comparison between our full TIFU-KNN and a single component as prediction is shown in the <ref type="table" target="#tab_7">Table 5</ref>.</p><p>Obviously, the combination achieves the best performance, which verifies the effectiveness of the combination of the target user's PIF and the most similar users' PIF. Also, we observe that target user's repeated purchase pattern dominates the prediction. The collaborative purchase pattern provides discriminative information to further improve the prediction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Sensitivity of the Hyperparameters (RQ4)</head><p>In this section, we investigate how the hyper parameters affect the performance. When we investigate on one or two parameters, we set other parameters just as the value shown in <ref type="table" target="#tab_5">Table 3</ref>. We report the recall on the test set in Instacart data set when the predicted basket size s = 20. The results are shown in the <ref type="figure" target="#fig_9">Figure 7</ref>. As the decayed weights r b and r ? may have some correlation, we investigate them together and the results are shown in the <ref type="table" target="#tab_8">Table 6</ref>. We have several observations. First, all the hyperparameters should be chosen with a proper value in order to achieve the best performance. Second, the parameters selected with the validation set are close to the optimal configuration for the test set. Third, the two time decayed weights r b and r ? should both be smaller than 1 in order to achieve the best performance. It verifies that our two-level decayed weight design is better than any single decayed weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we introduce a simple kNN-based method <ref type="bibr" target="#b7">8</ref> . Despite its simplicity, the proposed method generally outperforms the stateof-the art deep learning based methods. We study the reason why RNNs cannot approximate vector addition well, which provides the insight why our proposed method can outperform existing methods. Even though the deep learning model has strong representation power, there is no guarantee that we can find the solution which meets our expectation due to the complexity of non-convex optimization in RNNs. We believe this difficulty is different from the <ref type="bibr" target="#b7">8</ref> The code is available at https://github.com/HaojiHu/TIFUKNN.   well-known vanishing and the exploding gradient problems <ref type="bibr" target="#b34">[34]</ref>. More theoretical analysis is needed. A new optimizer that has the theoretical guarantee to find the global optimal like <ref type="bibr" target="#b43">[43]</ref> is also needed for RNNs. Beyond this work, we believe that there are two directions that deserve to be explored. First, a direct extension is whether there are other commonly-used functions which are hard to be learned by existing widely-used deep models. This direction can help us better understand how to apply deep learning based methods in recommendation systems as we observe that recent publications <ref type="bibr" target="#b31">[31]</ref> show a worry about the unclear progress in sequential/session-based recommendation. We believe different types of methods should have different advantages in different tasks and data sets. And a deep understanding about the boundary of the deep learning methods can bring benefits not only to recommendation systems but also to other machine learning areas. Second, another direct extension is to investigate if there are other patterns associated with PIF or other patterns that are associated with different types of item frequency, e.g., global item frequency, local item frequency (the item frequency associated with a small group of users or a small group of items), and inverse item frequency <ref type="bibr" target="#b39">[39]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>?</head><label></label><figDesc>Recall N : The average recall of using N to retrieve items in T . Formally, Recall N = |N ?T | |T | . It represents the ratio of items captured by collaborative purchase pattern. ? Recall P ?N : The average recall of using P ? N to retrieve items in T . Formally, Recall N = |P ?N ?T | |T | . It represents the ratio of items captured by both repeated purchase pattern and collaborative purchase pattern. ? Recall P ?N : The average recall of using P ? N to retrieve items in T . Formally, Recall P ?N = |P ?N ?T | |T |</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Existing RNN based NBR Module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>The training loss of using the component fromFigure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>3 http://www.cs.toronto.edu/tijmen/csc321/slides/lecture_slides_lec6.pdf</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Without nonlinear activation functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Gap distribution of repeated purchase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :?</head><label>5</label><figDesc>User vector representation generation process. Collaborative purchase component: Denote the set of target user's nearest neighbors vector representations as U nei?hbor . Denote the average vector of all vectors belong to U nei?hbor as u n . u n is corresponding to collaborative purchase pattern.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>5. 1 . 4</head><label>14</label><figDesc>Configuration of the Proposed Method. We perform an extensive search over the parameter space to achieve the best performance on the validation set. The number of nearest neighbors k is chosen from the set of values [100, 300, 500, 700, 900, 1100, 1300]. The the within-basket time-decayed ratio r b and the group time-decayed ratio r ? are chosen from the set of values [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]. The fusion weight ? is searched from the set of values [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]. The number of groups m is searched from the set of values</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Recall P ?N distribution on different data sets. The r b and r ? are set to the same ratio. Different lines represent different numbers of neighbors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 :</head><label>7</label><figDesc>Sensitivity of hyperparameters: the number of nearest neighbors k, the number of groups m, and the combining weight ? at Instacart data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The importance of two patterns.</figDesc><table><row><cell>Data</cell><cell cols="4">Recall P Recall N Recall P ?N Recall P ?N</cell></row><row><cell>ValuedShopper</cell><cell>0.6570</cell><cell>0.9808</cell><cell>0.6490</cell><cell>0.0111</cell></row><row><cell>Instacart</cell><cell>0.5711</cell><cell>0.8338</cell><cell>0.5056</cell><cell>0.1007</cell></row><row><cell>Dunnhumby</cell><cell>0.2777</cell><cell>0.5580</cell><cell>0.2432</cell><cell>0.4075</cell></row><row><cell>TaFeng</cell><cell>0.1378</cell><cell>0.8614</cell><cell>0.1256</cell><cell>0.1262</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Statistic information after pre-processing.</figDesc><table><row><cell>Data</cell><cell>#items</cell><cell>#users</cell><cell>average</cell><cell>average</cell></row><row><cell></cell><cell></cell><cell></cell><cell>basket size</cell><cell>#baskets</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>/user</cell></row><row><cell cols="2">ValuedShopper 7,907</cell><cell>10,000</cell><cell>8.71</cell><cell>56.85</cell></row><row><cell>Instacart</cell><cell>8,000</cell><cell>19,935</cell><cell>8.97</cell><cell>7.97</cell></row><row><cell>Dunnhumby</cell><cell>4,997</cell><cell>36,241</cell><cell>7.33</cell><cell>7.99</cell></row><row><cell>TaFeng</cell><cell>12,062</cell><cell>13,949</cell><cell>6.27</cell><cell>5.69</cell></row><row><cell cols="2">5.1.2 Evaluation Protocol.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Parameters of our methods in different data sets.</figDesc><table><row><cell>Data</cell><cell>k</cell><cell>m</cell><cell>r b</cell><cell>r ?</cell><cell>?</cell></row><row><cell cols="2">ValuedShopper 300</cell><cell>7</cell><cell>1</cell><cell>0.6</cell><cell>0.7</cell></row><row><cell>Instacart</cell><cell>900</cell><cell>3</cell><cell>0.9</cell><cell>0.7</cell><cell>0.9</cell></row><row><cell>Dunnhumby</cell><cell>900</cell><cell>3</cell><cell>0.9</cell><cell>0.6</cell><cell>0.2</cell></row><row><cell>TaFeng</cell><cell>300</cell><cell>7</cell><cell>0.9</cell><cell>0.7</cell><cell>0.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Comparison with different methods. The bold is the maximum in (a)-(b). The underline is the maximum in (c)-(h).</figDesc><table><row><cell>Data</cell><cell>Metric</cell><cell cols="11">(a) TopFreq PersonTopFreq userKNN RepeatNet FPMC DREAM SHAN Sets2Sets TIFU-KNN (a)-(b) (b) (c) (d) (e) (f) (g) (h) (i) improvement vs. (c)-(h)</cell></row><row><cell></cell><cell>recall@10</cell><cell>0.0982</cell><cell>0.2109</cell><cell>0.0988</cell><cell>0.1031</cell><cell>0.0951</cell><cell>0.0991</cell><cell>0.0847</cell><cell>0.1259</cell><cell>0.2162</cell><cell>2.5%</cell><cell>71.7%</cell></row><row><cell>ValuedShopper</cell><cell>recall@20 NDCG@10</cell><cell>0.0904 0.0779</cell><cell>0.2969 0.2128</cell><cell>0.1329 0.1415</cell><cell>0.1485 0.1439</cell><cell>0.1391 0.1188</cell><cell>0.1448 0.1231</cell><cell>0.1220 0.1032</cell><cell>0.1774 0.1626</cell><cell>0.3028 0.2171</cell><cell>2.7% 2.1%</cell><cell>70.6% 33.5%</cell></row><row><cell></cell><cell>NDCG@20</cell><cell>0.0904</cell><cell>0.2544</cell><cell>0.1662</cell><cell>0.1693</cell><cell>0.1253</cell><cell>0.1287</cell><cell>0.1074</cell><cell>0.1884</cell><cell>0.2589</cell><cell>1.7%</cell><cell>37.4%</cell></row><row><cell></cell><cell>recall@10</cell><cell>0.0724</cell><cell>0.3426</cell><cell>0.0720</cell><cell>0.2107</cell><cell>0.0763</cell><cell>0.0866</cell><cell>0.0902</cell><cell>0.3021</cell><cell>0.3952</cell><cell>15.3%</cell><cell>30.8%</cell></row><row><cell>Instacart</cell><cell>recall@20 NDCG@10</cell><cell>0.1025 0.0641</cell><cell>0.4652 0.3618</cell><cell>0.1260 0.1020</cell><cell>0.2637 0.2285</cell><cell>0.1073 0.0946</cell><cell>0.1128 0.1063</cell><cell>0.1246 0.1152</cell><cell>0.3654 0.3487</cell><cell>0.4875 0.3825</cell><cell>4.8% 5.7%</cell><cell>33.4% 9.6%</cell></row><row><cell></cell><cell>NDCG@20</cell><cell>0.0689</cell><cell>0.4155</cell><cell>0.1394</cell><cell>0.2513</cell><cell>0.0992</cell><cell>0.1157</cell><cell>0.1212</cell><cell>0.3626</cell><cell>0.4384</cell><cell>5.5%</cell><cell>20.9%</cell></row><row><cell></cell><cell>recall@10</cell><cell>0.0819</cell><cell>0.1853</cell><cell>0.1135</cell><cell>0.1324</cell><cell>0.0919</cell><cell>0.0915</cell><cell>0.1007</cell><cell>0.2068</cell><cell>0.2087</cell><cell>12.6%</cell><cell>0.9%</cell></row><row><cell>Dunnhumby</cell><cell>recall@20 NDCG@10</cell><cell>0.1077 0.0601</cell><cell>0.2366 0.1771</cell><cell>0.1648 0.1707</cell><cell>0.1989 0.1545</cell><cell>0.1186 0.1025</cell><cell>0.1087 0.1009</cell><cell>0.1201 0.1149</cell><cell>0.2653 0.2134</cell><cell>0.2692 0.1983</cell><cell>13.7% 11.9%</cell><cell>1.4% -7.0%</cell></row><row><cell></cell><cell>NDCG@20</cell><cell>0.0609</cell><cell>0.2016</cell><cell>0.2052</cell><cell>0.1732</cell><cell>0.1057</cell><cell>0.1022</cell><cell>0.1167</cell><cell>0.2385</cell><cell>0.2302</cell><cell>14.1%</cell><cell>-3.5%</cell></row><row><cell></cell><cell>recall@10</cell><cell>0.0773</cell><cell>0.0704</cell><cell>0.1089</cell><cell>0.0645</cell><cell>0.0868</cell><cell>0.0902</cell><cell>0.0878</cell><cell>0.1190</cell><cell>0.1301</cell><cell>33.7%</cell><cell>9.3%</cell></row><row><cell>TaFeng</cell><cell>recall@20 NDCG@10</cell><cell>0.1151 0.0519</cell><cell>0.1203 0.0766</cell><cell>0.1278 0.0832</cell><cell>0.0919 0.0592</cell><cell>0.1056 0.0667</cell><cell>0.1149 0.0763</cell><cell>0.1065 0.0813</cell><cell>0.1767 0.0844</cell><cell>0.1810 0.1011</cell><cell>50.4% 31.9%</cell><cell>2.4% 8.4%</cell></row><row><cell></cell><cell>NDCG@20</cell><cell>0.0608</cell><cell>0.0896</cell><cell>0.1064</cell><cell>0.0679</cell><cell>0.0743</cell><cell>0.0841</cell><cell>0.0892</cell><cell>0.1071</cell><cell>0.1206</cell><cell>34.5%</cell><cell>12.6%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>The effect of each component in the TIFU-KNN.</figDesc><table><row><cell></cell><cell></cell><cell>recall@10</cell><cell></cell><cell></cell><cell>NDCG@10</cell><cell></cell></row><row><cell>Data</cell><cell>u t</cell><cell>u n</cell><cell>u t &amp;u n</cell><cell>u t</cell><cell>u n</cell><cell>u t &amp;u n</cell></row><row><cell cols="2">ValuedShopper 0.1801</cell><cell>0.1251</cell><cell cols="2">0.2161 0.1716</cell><cell>0.1287</cell><cell>0.2171</cell></row><row><cell>Instacart</cell><cell>0.3698</cell><cell>0.1290</cell><cell cols="2">0.3952 0.3686</cell><cell>0.1381</cell><cell>0.3825</cell></row><row><cell>Dunnhumby</cell><cell>0.2070</cell><cell>0.1344</cell><cell cols="2">0.2087 0.1968</cell><cell>0.1270</cell><cell>0.1983</cell></row><row><cell>TaFeng</cell><cell>0.0921</cell><cell>0.0904</cell><cell cols="2">0.1301 0.0891</cell><cell>0.0766</cell><cell>0.1011</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Sensitivity of hyperparameters: time-decayed ratio r b within each group and time-decayed ratio r ? across the groups at Instacart data set.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For example, we can convert each basket into a sequence and concatenate the sequences from different baskets in temporal order. This introduces a non-existing order among items within the same basket.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Vector addition is a more general case than two numbers addition which is shown in https://machinelearningmastery.com/learn-add-numbers-seq2seq-recurrent-neuralnetworks/. To our best knowledge, RNN is the most direct way for deep model to learn this operation as the number of vectors varies and the operation is repeated.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://www.dunnhumby.com/careers/engineering/sourcefiles 5 https://www.kaggle.com/c/acquire-valued-shoppers-challenge/overview 6 https://www.kaggle.com/c/instacart-market-basket-analysis 7 https://www.kaggle.com/chiranjivdas09/ta-feng-grocery-dataset</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgement: This research was supported part by NSF under grants CNS-1814322, CNS-1831140, CNS-1901103, US DoD DTRA DTRA grant HDTRA1-14-1-0040, and National Natural Science Foundation of China (61972372, U19A2079). Also, thanks to the constructive suggestions from the reviewers.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Charu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aggarwal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The dynamics of repeat consumption</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashton</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tomkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergei</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on World wide web</title>
		<meeting>the 23rd international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="419" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An attribute-aware neural attentive model for next basket recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wayne</forename><forename type="middle">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 41st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1201" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modeling relationships at multiple scales to improve accuracy of large recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Volinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 13th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Modeling user consumption sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Austin R Benson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tomkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 25th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="519" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Training a 3-node neural network is NP-complete</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avrim</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald L</forename><surname>Rivest</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="494" to="501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COMPSTAT&apos;2010</title>
		<meeting>COMPSTAT&apos;2010</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">On the properties of neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1259</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Encoder-decoder approaches. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Has brand loyalty declined? A longitudinal analysis of repeat purchase behavior in the UK and the USA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Dawes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Meyer-Waarden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Driesener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business Research</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="425" to="432" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Item-based top-n recommendation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mukund</forename><surname>Deshpande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="143" to="177" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew M</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saxe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6544</idno>
		<title level="m">Qualitatively characterizing neural network optimization problems</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">LSTM: A search space odyssey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rupesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koutn?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Steunebrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2222" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Translation-based Recommendation: A Scalable Method for Modeling Sequential Behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5264" to="5268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fusing similarity models with markov chains for sparse sequential recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruining</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE 16th International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="191" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Trirank: Reviewaware explainable recommendation by modeling aspects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min-Yen</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1661" to="1670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 43st International ACM SIGIR Conference on Research &amp; Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizi</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="173" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Linas Baltrunas, and Domonkos Tikk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bal?zs</forename><surname>Hidasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06939</idno>
	</analytic>
	<monogr>
		<title level="m">Session-based recommendations with recurrent neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sets2Sets: Learning from Sequential Sets with Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoji</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1491" to="1499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Provable Benefit of Orthogonal Initialization in Optimizing Deep Linear Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Brand loyalty vs. repeat purchasing behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Jacoby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kyner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Marketing research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">When recurrent neural networks meet the neighborhood for session-based recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietmar</forename><surname>Jannach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Ludewig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM Conference on Recommender Systems</title>
		<meeting>the Eleventh ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="306" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Self-attentive sequential recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang-Cheng</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="197" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">GroupLens: applying collaborative filtering to Usenet news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Joseph A Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">L</forename><surname>Maltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Herlocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lee R Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="77" to="87" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Factorization meets the neighborhood: a multifaceted collaborative filtering model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="426" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Collaborative filtering with temporal dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehuda</forename><surname>Koren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 15th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="447" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Variational autoencoders for collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jebara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<title level="m">World Wide Web Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<imprint>
			<biblScope unit="page" from="689" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Evaluation of session-based recommendation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Ludewig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietmar</forename><surname>Jannach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">User Modeling and User-Adapted Interaction</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="331" to="390" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Performance comparison of neural and non-neural approaches to session-based recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Ludewig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noemi</forename><surname>Mauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Latifi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dietmar</forename><surname>Jannach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM Conference on Recommender Systems</title>
		<meeting>the 13th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="462" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Recurrent neural networks for prediction: learning algorithms, architectures and stability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Danilo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Mandic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chambers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>John Wiley &amp; Sons, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A comprehensive survey of neighborhood-based recommendation methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Desrosiers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender systems handbook</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="37" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On the difficulty of training recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1310" to="1318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">RepeatNet: A repeat aware neural recommendation machine for session-based recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengjie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhumin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaochun</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4806" to="4813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Factorizing personalized markov chains for next-basket recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Rendle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Freudenthaler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th international conference on World wide web</title>
		<meeting>the 19th international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="811" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Introduction to recommender systems handbook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Ricci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Rokach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bracha</forename><surname>Shapira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Recommender systems handbook</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Item-based collaborative filtering recommendation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Badrul</forename><surname>Sarwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th international conference on World Wide Web</title>
		<meeting>the 10th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="285" to="295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Adaptive matrix completion for the users and the items in tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Karypis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3223" to="3229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On the computational power of neural nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><forename type="middle">D</forename><surname>Siegelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sontag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth annual workshop on Computational learning theory</title>
		<meeting>the fifth annual workshop on Computational learning theory</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="440" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Representing and Recommending Shopping Baskets with Complementarity, Compatibility and Loyalty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengting</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Information and Knowledge Management</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1133" to="1142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Modeling Item-Specific Temporal Dynamics of Repeat Consumption for Recommender Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoping</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning ReLU networks on linearly separable data: Algorithm, optimality, and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Georgios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Giannakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="2357" to="2370" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning hierarchical representation model for next-basket recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengxian</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 38th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Sequential recommender system based on hierarchical attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haochao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzhen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuzheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanchi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guandong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the 27th International Joint Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A dynamic recurrent model for next basket recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="729" to="732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Future Data Helps Training: Modeling Future Contexts for Session-based Recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fajie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangnan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haochuan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guibing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhezhao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilin</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The Web Conference 2020</title>
		<meeting>The Web Conference 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="303" to="313" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
