<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Czech Dataset for Cross-lingual Subjectivity Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>P?ib??</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">NTIS -New Technologies for the Information Society</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Univerzitn?</orgName>
								<address>
									<addrLine>2732/8</addrLine>
									<postCode>301 00</postCode>
									<settlement>Pilsen</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Steinberger</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">NTIS -New Technologies for the Information Society</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Univerzitn?</orgName>
								<address>
									<addrLine>2732/8</addrLine>
									<postCode>301 00</postCode>
									<settlement>Pilsen</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Applied Sciences</orgName>
								<orgName type="institution">University of West Bohemia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Czech Dataset for Cross-lingual Subjectivity Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>subjectivity</term>
					<term>dataset</term>
					<term>Czech</term>
					<term>cross-lingual</term>
					<term>classification</term>
					<term>transformers</term>
					<term>benchmark</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we introduce a new Czech subjectivity dataset of 10k manually annotated subjective and objective sentences from movie reviews and descriptions. Our prime motivation is to provide a reliable dataset that can be used with the existing English dataset as a benchmark to test the ability of pre-trained multilingual models to transfer knowledge between Czech and English and vice versa. Two annotators annotated the dataset reaching 0.83 of the Cohen's ? inter-annotator agreement. To the best of our knowledge, this is the first subjectivity dataset for the Czech language. We also created an additional dataset that consists of 200k automatically labeled sentences. Both datasets are freely available for research purposes. Furthermore, we fine-tune five pre-trained BERT-like models to set a monolingual baseline for the new dataset and we achieve 93.56% of accuracy. We fine-tune models on the existing English dataset for which we obtained results that are on par with the current state-of-the-art results. Finally, we perform zero-shot cross-lingual subjectivity classification between Czech and English to verify the usability of our dataset as the cross-lingual benchmark. We compare and discuss the cross-lingual and monolingual results and the ability of multilingual models to transfer knowledge between languages.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Subjectivity classification <ref type="bibr" target="#b36">(Wiebe et al., 1999)</ref> is one of the integral parts of sentiment analysis (opinion mining). Its basic purpose is to determine if a sentence or phrase is subjective or objective <ref type="bibr" target="#b15">(Liu, 2012)</ref>. It can be further used to improve other tasks such as polarity detection or information extraction <ref type="bibr" target="#b36">(Wiebe et al., 1999;</ref><ref type="bibr" target="#b19">Pang and Lee, 2004)</ref>. Nowadays, the subjectivity classification is often used as a benchmark test <ref type="bibr" target="#b38">(Zhao et al., 2015;</ref><ref type="bibr" target="#b23">Reimers and Gurevych, 2019;</ref><ref type="bibr" target="#b33">Wang et al., 2021;</ref><ref type="bibr" target="#b2">Bragg et al., 2021)</ref> in transfer learning to test abilities and language understanding of pre-trained BERT-like language models based on the Transformer architecture <ref type="bibr" target="#b29">(Vaswani et al., 2017)</ref>. The goal of subjectivity classification is to classify a sentence or a clause of the sentence as subjective or objective. Subjective sentences express personal feelings, views, beliefs or opinions and objective sentences hold or describe some factual information <ref type="bibr" target="#b15">(Liu, 2012)</ref>. Evaluation of the pre-trained models for transfer learning is a crucial part of their development. For English, the well-known GLUE <ref type="bibr" target="#b31">(Wang et al., 2018)</ref> and Super-GLUE <ref type="bibr" target="#b32">(Wang et al., 2019)</ref> benchmarks are available. These benchmarks contain a set of diverse tasks that allow a thorough evaluation of English pre-trained models.</p><p>For multilingual models such as mBERT <ref type="bibr" target="#b6">(Devlin et al., 2019)</ref> or XLM-R <ref type="bibr" target="#b5">(Conneau et al., 2020)</ref>, the XTREME <ref type="bibr" target="#b10">(Hu et al., 2020)</ref> benchmark can be used to test their ability of cross-lingual transfer learning and knowledge transfer between languages. Unfortunately, the XTREME benchmark does not include any task for the Czech language.</p><p>Our main motivation is to partly fill this gap and contribute a bit by introducing a reliable Czech dataset that can be used for the cross-lingual evaluation. We intend to use the dataset to test the cross-lingual abilities of pre-trained multilingual models in pair with the existing English dataset <ref type="bibr" target="#b19">(Pang and Lee, 2004)</ref> as a benchmark for zero-shot cross-lingual subjectivity classification. Thus, partly test the ability of pre-trained multilingual models to transfer knowledge between Czech and English. We are aware that to properly evaluate any pre-trained model, a diverse set of tasks is needed, but we believe that even one task can be helpful in the evaluation process. To the best of our knowledge, there is no subjectivity dataset for the Czech language, therefore our secondary goal is to extend the available dataset resources for Czech.</p><p>In this paper, we present the first Czech dataset for subjectivity classification task that consists of 10k manually annotated sentences from movie reviews and movie descriptions. Secondly, we provide an additional dataset of 200k sentences labeled in a distant supervised way (automatically). The automatic labeling is based on the idea from <ref type="bibr" target="#b19">(Pang and Lee, 2004)</ref> that movie reviews contain mostly subjective sentences and the movie descriptions usually consist of objective sentences. We describe the process of building and annotating the dataset. The dataset is annotated by two annotators and the Cohen's ? <ref type="bibr" target="#b4">(Cohen, 1960)</ref> interannotator agreement between them reaches 0.83. We perform experiments with two multilingual mBERT <ref type="bibr" target="#b6">(Devlin et al., 2019)</ref> and XLM-R-Large <ref type="bibr" target="#b5">(Conneau et al., 2020)</ref> and three monolingual Transformer based models on the new Czech dataset and providing a competitive baseline of 93.56% of accuracy. Next, we conduct experiments with the same two multilingual models on the English dataset to be able to compare our cross-lingual experiments. Our results for the monolingual experiments with English are on par with the current state-of-the-art results. Finally, we evaluate the multilingual models and their ability to transfer knowledge between English and Czech on the zeroshot cross-lingual classification task. The cross-lingual experiments show that using only English data for finetuning the XLM-R-Large, the model can achieve worse results only by 2.8% on the Czech dataset compared to the model trained on Czech data. When the model is trained using only the Czech data, the result on the English dataset is roughly 4.4% worse than the current state-of-the-art results. Our main contributions are the following: 1) we introduce the first Czech subjectivity dataset that allows cross-lingual evaluation in pair with the existing English dataset. 2) We perform a series of monolingual and cross-lingual experiments. We set a competitive baseline for the new Czech dataset. We compare abilities of two multilingual models to transfer knowledge between Czech and English in the subjectivity classification task. 3) We release 1 the dataset and code freely for research purposes, including the dataset splits for easier comparison and reproducibility of our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The subjectivity classification task was a popular research topic at the beginning of the 21st century. It was studied in many papers <ref type="bibr" target="#b35">(Wiebe and Wilson, 2002;</ref><ref type="bibr" target="#b37">Wiebe et al., 2004;</ref><ref type="bibr" target="#b24">Riloff et al., 2005;</ref><ref type="bibr" target="#b7">Esuli and Sebastiani, 2006;</ref><ref type="bibr" target="#b34">Wiebe and Mihalcea, 2006;</ref><ref type="bibr" target="#b17">Mihalcea et al., 2007)</ref>. Nowadays, the subjectivity classification is often used as a benchmark for the evaluation of pretrained models intended for transfer learning. In <ref type="bibr" target="#b36">(Wiebe et al., 1999)</ref>, the authors describe the annotation process of 1k news sentences. Four annotators annotated the sentences as subjective or objective, but because some sentences can be considered borderline examples, they also assigned certainty ratings, ranging from 0, for least certain, to 3, for most certain. We use special label trash for the borderline sentences during our annotation, see Section 3.2.1. <ref type="bibr" target="#b19">Pang and Lee (2004)</ref> created English subjectivity dataset from movie reviews and movie descriptions. They automatically made the dataset using the assumption that reviews have mostly subjective sentences and descriptions usually contain objective sentences. The resulted dataset consists of 10k sentences, see <ref type="table" target="#tab_3">Table 2</ref>.</p><p>Further in this paper, we reference the dataset as the English dataset. In terms of Czech resources, the Czech subjectivity lexicon Czech SubLex 1.0 <ref type="bibr" target="#b30">(Veselovsk? and Bojar, 2013)</ref> contains a list of words with assigned sentiment polarity and part-of-speech tags. There are also pairs of existing datasets that can be used for the cross-lingual evaluation similarly to our approach. For example, the Czech sentiment dataset of movie reviews CSFD <ref type="bibr" target="#b8">(Habernal et al., 2013)</ref> can be used with the English IMDB <ref type="bibr" target="#b16">(Maas et al., 2011)</ref> sentiment reviews dataset as shown in <ref type="bibr" target="#b22">(P?ib?? and Steinberger, 2021)</ref>. Another example is the multilingual corpus <ref type="bibr" target="#b20">(Piskorski et al., 2019)</ref> for named entity recognition (NER) that contains labels in the same format for four Slavic languages, including Czech. Next, the Czech aspect-based sentiment dataset <ref type="bibr" target="#b9">(Hercig et al., 2016)</ref> can be evaluated together with the English dataset <ref type="bibr" target="#b21">(Pontiki et al., 2014)</ref> and both of them come from the same domain and contain the same set of labels. The initial work focused on cross-lingual subjectivity classification is presented in <ref type="bibr" target="#b17">(Mihalcea et al., 2007)</ref>. The authors investigated methods to automatically generate resources for subjectivity analysis for new language by using a parallel corpus and available resources in English. <ref type="bibr" target="#b0">Amini et al. (2019)</ref> performed cross-lingual subjectivity classification between English and Persian. Other work that is related to crosslingual subjectivity can be found in <ref type="bibr" target="#b25">(Saralegi et al., 2013)</ref>. In <ref type="bibr" target="#b33">(Wang et al., 2021)</ref>, the authors used the English subjectivity dataset as one of the tasks to evaluate their approach for few-shot learning based on RoBERTa model <ref type="bibr" target="#b14">(Liu et al., 2019)</ref>. <ref type="bibr" target="#b18">(Nandi et al., 2021)</ref> analyzed various models for text representation, including the original BERT model <ref type="bibr" target="#b6">(Devlin et al., 2019)</ref> on the English dataset. Similarly, in <ref type="bibr" target="#b38">(Zhao et al., 2015;</ref><ref type="bibr" target="#b1">Amplayo et al., 2018;</ref><ref type="bibr" target="#b11">Khodak et al., 2018;</ref><ref type="bibr" target="#b23">Reimers and Gurevych, 2019)</ref>, the authors also used the English dataset to evaluate the performance of their newly designed models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dataset Building</head><p>We provide two datasets of subjective and objective Czech sentences from movie reviews and movie descriptions (plot summaries), respectively. We use the mentioned idea from <ref type="bibr" target="#b19">Pang and Lee (2004)</ref>, in which the authors automatically created English dataset (Subj-EN) of 10k subjective and objective sentences. They assume that the descriptions are mostly objective and the reviews are subjective. This assumption is valid in most cases, but there can also be objective sentences in reviews and subjective sentences in descriptions. The number of these noisy samples differs in both cases, as you can see in <ref type="table" target="#tab_1">Table 1</ref>. For this reason, we decided to create a manually annotated dataset <ref type="bibr">(Subj-CS)</ref> of 10k examples that should eliminate the incorrect occurrences as much as possible. Secondly, we automatically built an additional dataset (Subj-CS-L) of 200k sentences using almost the same approach 2 as in <ref type="bibr" target="#b19">(Pang and Lee, 2004)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Cleaning and Obtaining Data</head><p>We acquired roughly 4M reviews and 735k descriptions from Czech Movie Database 3 (CSFD) during October 2021. The Czech sentiment movie review dataset <ref type="bibr" target="#b8">(Habernal et al., 2013)</ref> also consists of reviews from CSFD. We assume that in the future, our dataset can be used in combination with the sentiment dataset therefore, we decided to remove the sentiment reviews from the data downloaded by us. We were able to match and remove about 74k reviews out of a total of 91k from the sentiment dataset. The remaining 17k reviews were most likely changed or removed from the CSFD website since the authors of the sentiment dataset originally downloaded the data in 2013. Next, we split the reviews and descriptions into sentences by UDPipe 2 <ref type="bibr">(Straka, 2018) 4</ref> . We have to note that in some cases, it failed to split the sentences correctly, especially for sentences without a space after the first sentence. The reviews can contain phrases instead of grammatically correct sentences, but we do not distinguish between them. Some of the texts (mostly reviews) were written in other languages (most often Slovak and English). We filter these out 5 and we keep only Czech sentences. Finally, we filter out sentences with less than six tokens. See <ref type="figure" target="#fig_0">Figure 1</ref> for the cleaning pipeline visualization.</p><p>The entire cleaning process resulted in 884k and 19M sentences (phrases) from descriptions and reviews, respectively. We randomly selected 40k sentences from the obtained reviews and descriptions for manual annotation and 200k sentences (100k from reviews and 100k from descriptions) for the automatically created dataset. The remaining sentences are not used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Data Annotation</head><p>In this section, we describe the process of manual annotation. Two Czech native speakers performed the annotation. Even though the subjectivity classification may seem like an easy task, it showed to be rather difficult for some sentences to assign a subjectivity label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Annotation Procedure</head><p>Firstly, the task of subjectivity classification was explained to the annotators along with the meaning of the subjective and objective sentences according to the definition in <ref type="bibr" target="#b15">(Liu, 2012)</ref>. The annotators were also asked to read the papers mentioned in Section 2 to clearly understand the task. We summarize the annotation guidelines in Section 3.2.3. During the first annotation stage, each of the annotators was asked to label a common set of 100 sentences with one of three labels: subjective, objective and trash, see Section 3.2.3 for their description. We use the trash label because, despite our best data cleaning efforts, there were still undesirable texts: e.g., short sequences of words that does not make any sense (random words), only numbers and other characters, sentences in other languages, texts that were obviously incorrectly segmented and made no sense etc. After the first 100 annotated sentences, the annotators discussed the conflicts to clarify and improve the annotation guidelines. Based on the discussion, we decided to extend the annotation labels by two more unsure and question.</p><p>The questions appeared to be rather problematic. The subjectivity was not clear very often and thus, we decided to exclude them. In addition, the questions are only in a tiny part of the data, i.e., 1.73% and 2.41% for review and description sentences, respectively, see <ref type="table" target="#tab_1">Table 1</ref>. The unsure label was added because for some sentences, the annotators were not able to assign the subjectivity. For example, sentences for which a context (previous sentence) is needed to decide, sentences that describe a movie or event, but contain some clearly subjective adjective(s) and they can be perceived or interpreted both as subjective or objective depending on an individual person. Other problematic sentences are commands, wishes or parts of poems and rhymes. Here we list some of the problematic sentences that both annotators labeled with the unsure label:</p><p>(1) "V?echno ov?em tak snadn??e?en? nem?." -"Not everything has such an easy solution."</p><p>(2) "To je dobr? d?vod pro to, aby byla Japonsku vyhl??ena v?lka." -"That's a good reason to declare war on Japan."</p><p>(3) "Dnes ve?er je to v?ak d?ky napjat? atmosf??e velmi obt??n?." -"Tonight, the tense atmosphere makes it very difficult."</p><p>(4) "Drastick? horor, p?i kter?m tuhne krev v?il?ch" -"Drastic horror that makes your blood run cold"</p><p>(5) "Tak se o to postar? p??roda sama!" -"Nature will take care of it!"</p><p>We decided to add these additional labels because we wanted to assign labels only in cases where the annotators are very confident with their annotations and thus obtain more reliable annotations without controversial examples and dataset of high quality.</p><p>After the update of the annotation guideline, both of the annotators assigned labels to the same 2,034 sentences. The Cohen's ? <ref type="bibr" target="#b4">(Cohen, 1960)</ref> inter-annotator agreement for this 2k sentences reaches 0.68 for all five labels. Because we provide the dataset only with the objective and subjective labels, we exclude any sentence with at least one 6 of the trash, unsure or question labels. Thanks to this filtration, we obtain 1,668 sentences only with the subjective and objective labels. The Cohen's ? for this subset is 0.83, which represents a fairly good level of agreement. The remaining 141 conflict sentences are then resolved with the help of third person. Finally, almost 5,000 sentences were annotated by each of the two annotators resulting in a total of 11,907 annotated sentences, see <ref type="table" target="#tab_1">Table 1</ref>. We can see that the subjective and objective sentences are relatively balanced in the annotated samples and we believe that this reflects the real data distribution. Even though we obtained more than 5,000 sentences with the subjective and objective labels, we cut the annotations to have exactly 5,000 examples for each of the two labels. We decided to provide a perfectly balanced dataset since it allows easier comparison and evaluation of experiments.</p><p>In our experiments, we use only the sentences with the subjective and objective labels, i.e., 10,000 sentences. We refer to this dataset as Subj-CS.</p><p>The entire procedure of annotation can be summarized into the following steps:</p><p>1. Each annotator annotated 100 sentences as subjective, objective or trash.</p><p>2. Every conflict in the first 100 sentences was discussed separately between the annotators to clarify and improve the annotation guideline. We extended the annotation guideline by two more labels: unsure and question.</p><p>3. 2,034 sentences are annotated by each annotator (1,668 as subjective or objective with 141 conflicts). The Cohen's ? reaches 0.83 for subjective and objective sentences. The conflicts are resolved by a third person.</p><p>4. Almost 10k another sentences are annotated in total by both annotators. The annotations are cut down to contain exactly 5,000 subjective and objective sentences.</p><p>6 Each sentence has two labels -one from each annotator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Annotation Statistics</head><p>The manual annotation resulted in a total of 11,907 annotated sentences with one of five labels, see <ref type="table" target="#tab_1">Table 1</ref>. During the annotation procedure, we set the limit of at most 15 review sentences for the same movie and at most three description sentences in the 40k sentences selected for the manual annotation. However, the average number of sentences for the same movie is only 1.43 and 1.02 for review and description sentences, respectively.  As we assumed, a considerable percentage of sentences in reviews are not subjective (only 72.57% of sentences are subjective). Similarly, there is also a relatively large part of sentences in the movie descriptions that are not objective (84.22% of the sentences are objective).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Annotation Guideline</head><p>The annotators were instructed to annotate a given sentence or phrase with one of five labels. Based on the subjectivity description from <ref type="bibr" target="#b36">(Wiebe et al., 1999;</ref><ref type="bibr" target="#b19">Pang and Lee, 2004;</ref><ref type="bibr" target="#b15">Liu, 2012)</ref>, the sentence should be annotated as subjective if it expresses or evokes some personal feelings, views, beliefs or the sentence holds an opinion about entities, events or their properties (mostly movies in our case) from the non-objective point of view. For example:</p><p>"Samotn? film se mi l?bil, ale nep?ekvapil." -"I liked the movie itself, but it didn't surprise me."</p><p>The sentence should be annotated as objective if it contains some factual information about an entity, event or their properties but does not hold a personal or subjective opinion about it and it does not try to convince or impose some opinion to the reader, for example:</p><p>"Maurice?ije a pracuje v ji?n? Francii." -"Maurice lives and works in the south of France."</p><p>The disputed and controversial sentences, sentences where the annotator is not sure about its subjectivity or sentences for which context from previous text is needed to decide should be annotated with the unsure label, see Section 3.2.1 for examples. The trash label is used for sentences or phrases that do not make any sense or contain random words, characters or numbers. The question label is used for sentences that are questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Automatic Dataset</head><p>Besides the manually annotated dataset, we also built a large dataset (named Subj-CS-L) in a distant supervised way using the same approach as in <ref type="bibr" target="#b19">(Pang and Lee, 2004)</ref>. We labeled 100k review sentences as subjective and 100k movie description sentences as objective ones. All sentences have to have at least six tokens. We believe that even if the dataset contains some incorrect labels, it could be useful in combination with the manually created dataset, for example, in an unsupervised pre-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Data &amp; Models for Experiments</head><p>For the experiments, we split the Subj-CS dataset into three parts with the following ratio: 75% for training, 5% for the development evaluation and 20% for testing. For the cross-lingual experiment with the Subj-CS-L dataset from Czech to English, we use 5% as the development evaluation data and the rest is used for training. Because there is no official split for the English dataset <ref type="bibr" target="#b19">(Pang and Lee, 2004)</ref>, we use 10-fold cross-validation for the monolingual experiments to be able to compare our results with other papers. We also split the English dataset into training, development and testing parts with the same test size (see <ref type="table" target="#tab_3">Table 2</ref>) that was used in <ref type="bibr">(Wang et al., 2021) 7</ref> . For all three Czech and English datasets, we provide a script to obtain exactly the same data split to allow reproducibility and future comparison of our results.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Transformer Models</head><p>For the experiments, we use solely the pre-trained BERT-like models based on the encoder part of the original Transformer architecture <ref type="bibr" target="#b29">(Vaswani et al., 2017)</ref>. The modified language modeling task is used to pre-train all the models, see the corresponding papers for details. We employ three Czech monolingual models Czert-B <ref type="bibr" target="#b26">(Sido et al., 2021)</ref>, RobeCzech <ref type="bibr" target="#b27">(Straka et al., 2021)</ref>,</p><p>Czech Electra model <ref type="bibr" target="#b13">(Koci?n et al., 2021)</ref>, two multilingual models mBERT <ref type="bibr" target="#b6">(Devlin et al., 2019)</ref>, XLM-R <ref type="bibr" target="#b5">(Conneau et al., 2020)</ref> and the original monolingual English BERT model <ref type="bibr" target="#b6">(Devlin et al., 2019)</ref>, see <ref type="table" target="#tab_5">Table 3</ref> for their size (in a number of parameters) comparison.  Czech Electra <ref type="bibr" target="#b13">(Koci?n et al., 2021)</ref> is Czech model based on the Electra-small model <ref type="bibr" target="#b3">(Clark et al., 2020)</ref>.</p><p>Czert-B <ref type="bibr" target="#b26">(Sido et al., 2021)</ref> is Czech variant of the original BERT BASE model <ref type="bibr" target="#b6">(Devlin et al., 2019)</ref>.</p><p>RobeCzech <ref type="bibr" target="#b27">(Straka et al., 2021)</ref> is Czech version of the RoBERTa model <ref type="bibr" target="#b14">(Liu et al., 2019)</ref>.</p><p>BERT <ref type="formula">(</ref> We fine-tune all the models for the binary classification task, i.e., subjective vs. objective sentence detection. For all models based on the original BERT model, we use the hidden vector h ? R H of the classification token [CLS] that represents the entire input sequence, where H is the hidden size of the model. The vector is obtained from the pooling layer, i.e., from a fullyconnected layer of size H with a hyperbolic tangent used as the activation function. The dropout of 0.1 is applied and the result is then passed into a task-specific linear layer represented by matrix W ? R |2|?H . The output class c (subjective or objective) is computed as c = argmax (hW T ).</p><p>For the XLM-R-Large and RobeCzech models, the same 8 approach is used and in addition, an extra dropout of 0.1 is applied before the pooling layer (as in the original RoBERTa implementation). We use the Adam <ref type="bibr" target="#b12">(Kingma and Ba, 2014)</ref> optimizer with default parameters (? 1 = 0.9, ? 2 = 0.999) and the cross-entropy loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>To set baseline results for the new Czech dataset and verify its usability as a cross-lingual benchmark dataset between Czech and English, we performed a series of experiments with Transformer based models. The experiments can be categorized into two groups -monolingual and cross-lingual.</p><p>In monolingual experiments for Czech, we fine-tune the three Czech monolingual BERT-like models, i.e., Czert-B, RobeCzech and Czech Electra model and two multilingual models mBERT and XLM-R. For English, we use the same two multilingual models and the original BERT model. In cross-lingual experiments, we test the ability to transfer knowledge between Czech and English using the zero-shot cross-lingual classification. We fine-tune the multilingual models only on the dataset in one language (Czech or English) and then evaluate the fine-tuned model on the dataset in the other language.</p><p>We always fine-tune 9 on training data and measure the results on the development and testing data parts. We select the model that performs best on the development data and we report the results using average accuracy with the 95% confidence intervals (we repeat each experiment at least 12 times). We fine-tune all parameters of the model, including the added classification layers. We run the experiments for at most ten epochs with the linear learning rate decay (without learning rate warmup) with the initial learning rates ranging from 2e-7 to 2e-4. The batch size is set to 32 and the max sequence length of the input is 200 since we classify sentences and the vast majority of them fit into this length. See Appendix A.1 for the hyper-parameters details for the reported experiment results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Czech Monolingual Experiments</head><p>For Czech monolingual experiments, we use two types of training data. The training part (cs-train) of the manually labeled dataset Subj-CS and the entire automatically created dataset Subj-CS-L (marked as cs-L-train). In both cases, we evaluate models on the development (cs-dev) and testing (cs-test) parts of the Subj-CS dataset. We report the results in <ref type="table" target="#tab_7">Table 4</ref>. As we expected, the XLM-R-Large model achieves the highest average accuracy of 93.56% for both types of training data. Despite the highest achieved accuracy, there is an intersection in its confidence interval with RobeCzech model for the cs-train data (the * symbol in <ref type="table" target="#tab_7">Table 4</ref>). Thus, we can conclude that RobeCzech and XLM-R-Large perform very similarly for Czech monolingual experiments. Thanks to the XLM-R-Large size (and its relatively large hardware training requirements), one could prefer the smaller <ref type="bibr">9</ref> The composition of data used for training and evaluation depends on the corresponding experiment. In the case of English monolingual experiments for the 10-fold split, we did not use any development data.  RobeCzech model. The last observation is that all the models achieve better results with the cs-train data part. We expected XLM-R-Large to perform very well because it is the largest model and as shown in <ref type="bibr" target="#b22">(P?ib?? and Steinberger, 2021)</ref> it usually outperforms smaller monolingual models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">English Monolingual Experiments</head><p>In our English monolingual experiments, we evaluate the English dataset on our training (en-train), development (en-dev) and testing (en-test) data split. Because models from other works <ref type="bibr" target="#b38">(Zhao et al., 2015;</ref><ref type="bibr" target="#b1">Amplayo et al., 2018;</ref><ref type="bibr" target="#b11">Khodak et al., 2018;</ref><ref type="bibr" target="#b23">Reimers and Gurevych, 2019;</ref><ref type="bibr" target="#b18">Nandi et al., 2021)</ref> are evaluated on the 10-fold split, we evaluate the models also on the 10-fold split (en-10-fold) to be able to compare their and ours results.  <ref type="table">Table 5</ref>: Results for English monolingual experiments reported as average accuracy for the testing en-test and en-10-fold data parts. The model in paper marked with the ? symbol uses the same test size, but the distribution of sentences is different in each split part and they also use the standard deviation instead of the confidence interval.</p><p>As shown in <ref type="table">Table 5</ref>, the XLM-R-Large performs best among the other two transformer models without any intersection of confidence intervals between the different models. We can also see that the results for en-test and en-10-fold are very similar and their confidence intervals overlap for the same model pairs (but different training data). Based on this observation, we assume that the results for en-test and en-10-fold are comparable to each other, thus in the cross-lingual experiments, English is evaluated only on the en-test part. We compare our results with the current state-of-the-art results (rows below the dashed line in <ref type="table">Table 5</ref>). Most of the other works use the 10-fold cross-validation and our results also achieve the SotA results and are on par with them. We have to note that our 10-fold splits are not exactly the same as those in the referenced works because the authors do not provide them publicly. Using their distribution, we would probably get slightly different results. Nevertheless, we believe that we can compare our results with the other works to some extent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Cross-lingual Experiments</head><p>We perform three types of cross-lingual experiments: from English to Czech, from Czech to English and joint training and evaluation of both languages. The first two are also known as a zero-shot cross-lingual classification because the model is fine-tuned only on data from one language (source language) and evaluated on data from the second language (target language). The model has never seen the labeled data from the target language.</p><p>For the experiments from English to Czech (EN?CS), we fine-tune the multilingual models on English en-train data and we evaluate them on the en-dev and cs-test. We select the model that performs best on the en-dev (i.e., the same best model as for the English monolingual data) and we report results for the cs-test data in <ref type="table">Table 6</ref>   <ref type="table">Table 6</ref>: Accuracy results for cross-lingual experiments from English to Czech along with the results for models trained on monolingual data.</p><p>The XLM-R-Large model clearly outperforms the mBERT model by 4.5% but is worse than the same model that was trained on monolingual data roughly by 2.8%. In the case of mBERT, the results are much worse (5% difference) than the model trained only on monolingual data. For experiments from Czech to English (CS?EN), we fine-tune the models on cs-train and evaluate on cs-dev and en-test. We select the model that performs best on cs-dev.</p><p>We also train the model on the cs-L-train data, but in this case, we select the model that performs best on the en-dev data from the target language (English). We use the en-dev for selecting the best model because we found out that if we use cs-L-dev, we get much worse results (up to 20% worse) for the en-test. We are aware of this simplification of the zero-shot cross-lingual classification task, but otherwise, we would not be able to obtain a model with reasonable results. The results are stated in <ref type="table" target="#tab_11">Table 7</ref>. For both models trained on Czech data (cs-train and cs-L-train), the results are even worse in comparison to the previous experiment from English to Czech. For example, the difference between XLM-R-Large trained on cs-train and XLM-R-Large trained on English en-train data is 4.4%, whereas in the case of the previous experiment from English to Czech, it was only 2.8%. The results of the models trained on the cs-L-train are significantly worse (10% for mBERT). Finally, we fine-tune the models jointly on cs-train and en-train, i.e., on both languages at once. We average the results obtained on cs-dev and en-dev and we select the model that achieves the highest average value. We report the results for the cs-test and en-test in <ref type="table" target="#tab_12">Table 8</ref>.</p><p>We can see that the obtained results are almost identical or slightly different compared to the models trained only on monolingual data. Thus, we can conclude that the joint fine-tuning has no beneficial contribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Discussion</head><p>In this section, we summarize and mention some of our main findings and conclusions from the experiments. Even though that the Czech Electra model is significantly smaller than all the other models, it achieves very competitive results compared to the other models. Thanks to its smaller size, it is much easier and faster to be fine-tuned. The XLM-R-Large model dominates the results, but it is also several times larger than the other models, see <ref type="table" target="#tab_5">Table 3</ref>. Despite the worse results in the cross-lingual experiments, we can state that generally, the XLM-R-Large (and in some cases even mBERT) is relatively capable of transferring knowledge between Czech and English and vice versa, at least for the subjectivity classification task. The confidence intervals for results obtained in cross-lingual experiments are usually larger than the ones for the monolingual results. Thus, we consider the cross-lingual results less stable. During the cross-lingual experiments, we select the best model based on development results for the source language. We believe that this is more difficult and challenging than choosing the model according to the results on the target language. We also believe that this setting is much closer to the potential usage of the multilingual models in the industry or to solving practical real-world tasks that are often more complicated. We do not use this approach for models trained on the large data that were obtained automatically because of its poor results. Based on the cross-lingual results, we believe that for knowledge transfer between languages, a smaller but high-quality (manually annotated) dataset is better   and more important than a large automatically created dataset to obtain more reliable results for downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work, we introduce the first Czech subjectivity dataset Subj-CS that consists of 10k manually annotated subjective and objective sentences from movie reviews and descriptions. In addition, we automatically compiled a second much larger dataset of 200k sentences. Both datasets are freely available for research purposes.</p><p>We describe the process of building and annotating the dataset. The dataset was annotated by two annotators with Cohen's ? inter-annotator agreement equal to 0.83. In the paper, we provide a summary of the annotation guidelines used by the annotators.</p><p>We perform a series of monolingual experiments with five pre-trained BERT-like models to obtain the baseline results for the newly created Czech dataset and we are able to achieve 93.5%6 of accuracy with the XLM-R-Large model. We also perform monolingual experiments for the existing English subjectivity dataset with three models obtaining 97.28% of accuracy, which is on par with the current state-of-the-art results for this dataset. Finally, we conduct zero-shot cross-lingual subjectivity classification to verify the usability of our dataset as the cross-lingual benchmark for pre-trained multilingual models that allow transfer learning.</p><p>Our experiments confirm that we provide a dataset of relatively high quality and it can be used as an evaluation benchmark to test the ability of pre-trained models to transfer knowledge between Czech and English.</p><p>In future work, we want to focus on using the dataset to improve sentiment analysis (polarity detection) in Czech and English. Furthermore, we would like to include sentences labeled as unsure in the dataset, along with a detailed error analysis of the fine-tuned models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgments</head><p>This work has been partly supported by ERDF "Research and Development of Intelligent Components of Advanced Technologies for the Pilsen Metropolitan Area (InteCom)" (no.: CZ.02.1.01/0.0/0.0/17 048/0007267); and by Grant No. SGS-2022-016 Advanced methods of data processing and analysis. Computational resources were supplied by the project "e-Infrastruktura CZ" (e-INFRA CZ LM2018140 ) supported by the Ministry of Education, Youth and Sports of the Czech Republic.   95.87 ? 0.13 (2e-5 / 10) 96.03 ? 0.24 (2e-5 / 5) XLM-R-Large 97.28 ? 0.07 (2e-6 / 10) 97.34 ? 0.21 (2e-5 / 4)  <ref type="table" target="#tab_1">Table 13</ref>: Accuracy results with model hyperparameters for cross-lingual experiments from English to Czech along with the results for models trained on monolingual data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Data cleaning pipeline visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc><ref type="bibr" target="#b6">Devlin et al., 2019)</ref> is the original BERT BASE model.mBERT<ref type="bibr" target="#b6">(Devlin et al., 2019</ref>) is a cased multilingual version of the BERT BASE that was jointly trained on 104 languages.XLM-R-Large<ref type="bibr" target="#b5">(Conneau et al., 2020</ref>) is a multilingual version of the RoBERTa<ref type="bibr" target="#b14">(Liu et al., 2019</ref>) that supports 100 languages.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Annotation statistics for subjective and objec- tive</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Datasets statistics.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: A comparison of used models: number of pa-</cell></row><row><cell>rameters, vocabulary size and a number of supported</cell></row><row><cell>languages.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Results for Czech monolingual experiments reported as average accuracy for the testing cs-test data part. The * symbol denotes results containing intersection in confidence interval with the best model.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>? 0.38 88.99 ? 0.94 85.80 ? 0.89 85.53 ? 0.98 95.87 ? 0.13 XLM-R-Large 94.40 ? 0.36 92.86 ? 0.44 93.35 ? 0.22 90.98 ? 0.26 97.28 ? 0.07</figDesc><table><row><cell>Model</cell><cell>CS ? EN (cs-train) cs-dev en-test</cell><cell>CS ? EN (cs-L-train) en-dev en-test</cell><cell>Monolingual (en-train) en-test</cell></row><row><cell>mBERT</cell><cell>92.11</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Accuracy results for cross-lingual experiments from Czech to English along with the results for models trained on monolingual data.</figDesc><table><row><cell></cell><cell cols="2">Joint (cs-train + en-train)</cell><cell>Monolingual (cs-train)</cell><cell>Monolingual (en-train)</cell></row><row><cell>Model</cell><cell>cs-test</cell><cell>en-test</cell><cell>cs-test</cell><cell>en-test</cell></row><row><cell>mBERT</cell><cell cols="2">91.12 ? 0.24 95.69 ? 0.22</cell><cell>91.23 ? 0.21</cell><cell>95.87 ? 0.13</cell></row><row><cell cols="3">XLM-R-Large 93.85 ? 0.15 96.95 ? 0.12</cell><cell>93.56 ? 0.13</cell><cell>97.28 ? 0.07</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Accuracy results for models jointly trained on English and Czech data along with the results for models trained on monolingual data.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9 :</head><label>9</label><figDesc>Results with model hyper-parameters for Czech monolingual experiments reported as average accuracy for the testing cs-test data part. The * symbol denotes results containing intersection in confidence interval with the best model. ? 0.38 88.99 ? 0.94 (2e-5 / 3) 85.80 ? 0.89 85.53 ? 0.98 (2e-6 / 1) 95.87 ? 0.13 (2e-5 / 10) XLM-R-Large 94.40 ? 0.36 92.86 ? 0.44(2e-5 / 4)   93.35 ? 0.22 90.98 ? 0.26 (2e-7 / 1) 97.28 ? 0.07 (2e-6 / 10)</figDesc><table><row><cell>Model</cell><cell>CS ? EN (cs-train) cs-dev en-test</cell><cell>CS ? EN (cs-L-train) en-dev en-test</cell><cell>Monolingual (en-train) en-test</cell></row><row><cell>mBERT</cell><cell>92.11</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10 :</head><label>10</label><figDesc>Accuracy results with model hyper-parameters for cross-lingual experiments from Czech to English along with the results for models trained on monolingual data.</figDesc><table><row><cell></cell><cell cols="2">Joint (cs-train + en-train)</cell><cell>Monolingual (cs-train)</cell><cell>Monolingual (en-train)</cell></row><row><cell>Model</cell><cell>cs-test</cell><cell>en-test</cell><cell>cs-test</cell><cell>en-test</cell></row><row><cell>mBERT</cell><cell cols="2">91.12 ? 0.24 95.69 ? 0.22 (2e-5 / 3)</cell><cell>91.23 ? 0.21 (2e-5 / 3)</cell><cell>95.87 ? 0.13 (2e-5 / 10)</cell></row><row><cell cols="3">XLM-R-Large 93.85 ? 0.15 96.95 ? 0.12 (2e-6 / 10)</cell><cell>93.56 ? 0.13 (2e-5 / 4)</cell><cell>97.28 ? 0.07 (2e-6 / 10)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 11 :</head><label>11</label><figDesc>Accuracy results with hyper-parameters for models jointly trained on English and Czech data along with the results for models trained on monolingual data.</figDesc><table><row><cell>Model</cell><cell>en-test</cell><cell>en-10-fold</cell></row><row><cell>BERT</cell><cell>96.55 ? 0.16 (2e-5 / 3)</cell><cell>96.87 ? 0.25 (2e-5 / 9)</cell></row><row><cell>mBERT</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 12 :</head><label>12</label><figDesc>Results with model hyper-parameters for English monolingual experiments reported as average accuracy for the testing en-test and en-10-fold data parts. Large 97.60 ? 0.18 90.75 ? 0.32 (2e-6 / 10) 93.56 ? 0.13 (2e-5 / 4)</figDesc><table><row><cell>Model</cell><cell>en-dev</cell><cell>EN ? CS cs-test</cell><cell>Monoling. (cs-train) cs-test</cell></row><row><cell>mBERT</cell><cell cols="2">95.38 ? 0.22 86.18 ? 0.33 (2e-5 / 10)</cell><cell>91.23 ? 0.21 (2e-5 / 3)</cell></row><row><cell>XLM-R-</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The datasets and code are freely available for research purposes at https://github.com/pauli31/ czech-subjectivity-dataset</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Based on our observations in the dataset, we decided to use sentences or phrases with at least six tokens but they used sentences longer than nine tokens.3 https://www.csfd.cz4  We use the czech-pdt-ud-2.5-191206.udpipe model.5  We use the Python package langdetect available at https://pypi.org/project/langdetect/ to detect the language.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">Unfortunately, they do not provide any script or details to obtain the identical split. In other words, we do not know which sentences belong to the training part and which to the testing part.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">The first artificial token &lt;s&gt; of the input sequence is used instead of the [CLS] token.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">We also include the monolingual results for an easier comparison of the results.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Hyper-parameters</head><p>During fine-tuning, we tried a variety of hyperparameters, we use the Adam <ref type="bibr" target="#b12">(Kingma and Ba, 2014)</ref> optimizer with default parameters (? 1 = 0.9, ? 2 = 0.999) and the cross-entropy loss function. We randomly shuffle training data before each epoch. We run the experiments for at most ten epochs with the linear learning rate decay (without learning rate warm-up) with the initial learning rates ranging from 2e-7 to 2e-4. The 2e-4 learning rate was used only for the Czech Electra model, when used with other models, the models started to diverge. The batch size is always set to 32 and the max length of the input sequence is 200. In Tables 9, 12, 13, 10 and 11 we report results with the used initial learning rate and a number of epochs in parentheses. The first number in brackets is the initial learning rate and the second is the number of epochs for fine-tuning.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Crosslingual subjectivity detection for resource lean languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shakery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
		<meeting>the Tenth Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis<address><addrLine>Minneapolis, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Translations as additional contexts for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Amplayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-W</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence, IJCAI&apos;18</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence, IJCAI&apos;18</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3955" to="3961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Flex: Unifying evaluation for few-shot nlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bragg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10555</idno>
		<title level="m">Electra: Pre-training text encoders as discriminators rather than generators</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A coefficient of agreement for nominal scales. Educational and psychological measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1960" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="37" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised cross-lingual representation learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Guzm?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
	<note>Online, July. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Determining term subjectivity and term orientation for opinion mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Trento, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006-04" />
			<biblScope unit="page" from="193" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sentiment analysis in Czech social media using supervised machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pt??ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
		<meeting>the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unsupervised methods to improve aspect-based sentiment analysis in czech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hercig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brychc?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Konkol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computaci?n y Sistemas</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="365" to="375" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">XTREME: A massively multilingual multi-task benchmark for evaluating cross-lingual generalisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<editor>Hal Daum? III et al.</editor>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A la carte embedding: Cheap but effective induction of semantic feature vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="12" to="22" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koci?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>N?plava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>?tancl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kadlec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.01810</idno>
		<title level="m">Siamese bert-based model for web search relevance ranking evaluated on a new czech dataset</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Roberta: A robustly optimized bert pretraining approach</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Sentiment analysis and opinion mining. Synthesis lectures on human language technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning word vectors for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Daly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-06" />
			<biblScope unit="page" from="142" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning multilingual subjective language via crosslingual projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Banea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="976" to="983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An empirical evaluation of word embedding models for subjectivity analysis tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Maiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shekhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04)</title>
		<meeting>the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04)<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-07" />
			<biblScope unit="page" from="271" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The second cross-lingual challenge on recognition, normalization, classification, and linking of named entities across Slavic languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Piskorski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Laskova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marci?czuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pivovarova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P?ib??</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yangarber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing</title>
		<meeting>the 7th Workshop on Balto-Slavic Natural Language Processing<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08" />
			<biblScope unit="page" from="63" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">SemEval-2014 task 4: Aspect based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Galanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Manandhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
		<meeting>the 8th International Workshop on Semantic Evaluation<address><addrLine>Dublin, Ireland, August</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="27" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Are the multilingual models better? improving Czech sentiment with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P?ib??</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Recent Advances in Natural Language Processing</title>
		<meeting>the International Conference on Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<publisher>Held Online</publisher>
			<date type="published" when="2021-09" />
			<biblScope unit="page" from="1138" to="1149" />
		</imprint>
	</monogr>
	<note>RANLP 2021. INCOMA Ltd</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence embeddings using Siamese BERTnetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11" />
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Exploiting subjectivity classification to improve information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th National Conference on Artificial Intelligence</title>
		<meeting>the 20th National Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1106" to="1111" />
		</imprint>
	</monogr>
	<note>AAAI&apos;05</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cross-lingual projections vs. corpora extracted subjectivity lexicons for less-resourced languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Saralegi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>San Vicente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ugarteburu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Intelligent Text Processing and Computational Linguistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="96" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Czert -Czech BERTlike model for language representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pra??k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P?ib??</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pa?ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sej?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Konop?k</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Recent Advances in Natural Language Processing</title>
		<meeting>the International Conference on Recent Advances in Natural Language Processing</meeting>
		<imprint>
			<publisher>Held Online</publisher>
			<date type="published" when="2021-09" />
			<biblScope unit="page" from="1326" to="1338" />
		</imprint>
	</monogr>
	<note>RANLP 2021. INCOMA Ltd</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>N?plava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Strakov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Samuel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.11314</idno>
		<title level="m">Robeczech: Czech roberta, a monolingual contextualized language representation model</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">UDPipe 2.0 prototype at CoNLL 2018 UD shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-10" />
			<biblScope unit="page" from="197" to="207" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, et al.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Czech SubLex 1.0. LINDAT/CLARIAH-CZ digital library at the Institute of Formal and Applied Linguistics (?FAL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Veselovsk?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bojar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Faculty of Mathematics and Physics, Charles University</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11" />
			<biblScope unit="page" from="353" to="355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Superglue: A stickier benchmark for general-purpose language understanding systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, et al.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.14690</idno>
		<title level="m">Entailment as few-shot learner</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Word sense and subjectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-07" />
			<biblScope unit="page" from="1065" to="1072" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning to disambiguate potentially subjective expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING-02: The 6th Conference on Natural Language Learning</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Development and use of a gold-standard data set for subjectivity classifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Hara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 37th Annual Meeting of the Association for Computational Linguistics<address><addrLine>College Park, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-06" />
			<biblScope unit="page" from="246" to="253" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning subjective language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="308" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Self-adaptive hierarchical sentence model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Poupart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twenty-fourth international joint conference on artificial intelligence. Model Subj-CS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>cs-train</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Cs-L</forename><surname>Subj</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note type="report_type">cs-L-train</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
