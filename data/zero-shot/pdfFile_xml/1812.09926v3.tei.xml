<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SNAS: STOCHASTIC NEURAL ARCHITECTURE SEARCH</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirui</forename><surname>Xie</surname></persName>
							<email>xiesirui@sensetime.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
							<email>zhenghehui@sensetime.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
							<email>liuchunxiao@sensetime.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Liang</surname></persName>
							<email>linliang@ieee.org</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sensetime</surname></persName>
						</author>
						<title level="a" type="main">SNAS: STOCHASTIC NEURAL ARCHITECTURE SEARCH</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose Stochastic Neural Architecture Search (SNAS), an economical endto-end solution to Neural Architecture Search (NAS) that trains neural operation parameters and architecture distribution parameters in same round of backpropagation, while maintaining the completeness and differentiability of the NAS pipeline. In this work, NAS is reformulated as an optimization problem on parameters of a joint distribution for the search space in a cell. To leverage the gradient information in generic differentiable loss for architecture search, a novel search gradient is proposed. We prove that this search gradient optimizes the same objective as reinforcement-learning-based NAS, but assigns credits to structural decisions more efficiently. This credit assignment is further augmented with locally decomposable reward to enforce a resource-efficient constraint. In experiments on CIFAR-10, SNAS takes fewer epochs to find a cell architecture with state-of-theart accuracy than non-differentiable evolution-based and reinforcement-learningbased NAS, which is also transferable to ImageNet. It is also shown that child networks of SNAS can maintain the validation accuracy in searching, with which attention-based NAS requires parameter retraining to compete, exhibiting potentials to stride towards efficient NAS on big datasets. arXiv:1812.09926v3 [cs.</p><p>LG] 1 Apr 2020</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>The trend to seek for state-of-the-art neural network architecture automatically has been growing since <ref type="bibr" target="#b34">Zoph &amp; Le (2016)</ref>, given the enormous effort needed in scientific research. Normally, a Neural Architecture Search (NAS) pipeline comprises architecture sampling, parameter learning, architecture validation, credit assignment and search direction update.</p><p>There are basically three existing frameworks for neural architecture search. Evolution-based NAS like NEAT <ref type="bibr" target="#b26">(Stanley &amp; Miikkulainen, 2002)</ref> employs evolution algorithm to simultaneously optimize topology alongside with parameters. However, it takes enormous computational power and could not leverage the efficient gradient back-propagation in deep learning. To achieve the state-of-the-art performance as human-designed architectures, <ref type="bibr" target="#b22">Real et al. (2018)</ref> takes 3150 GPU days for the whole evolution. Reinforcement-learning-based NAS is end-to-end for gradient back-propagation, among which the most efficient one, ENAS <ref type="bibr" target="#b19">(Pham et al., 2018)</ref> learns optimal parameters and architectures together just like NEAT. However, as NAS is modeled as a Markov Decision Process, credits are assigned to structural decisions with temporal-difference (TD) learning <ref type="bibr" target="#b27">(Sutton et al., 1998)</ref>, whose efficiency and interpretability suffer from delayed rewards <ref type="bibr" target="#b0">(Arjona-Medina et al., 2018)</ref>. To get rid of the architecture sampling process, DARTS <ref type="bibr" target="#b13">(Liu et al., 2019)</ref> proposes deterministic attention on operations to analytically calculate expectation at each layer. After the convergence of the parent network, it removes operations with relatively weak attention. Due to the pervasive non-linearity in neural operations, it introduces untractable bias to the loss function. This bias causes inconsistency between the performance of derived child networks and converged parent networks, thus parameter retraining comes up as necessary. A more efficient, more interpretable and less biased framework is in desire, especially for future full-fledged NAS solutions on large datasets.</p><p>In this work, we propose a novel, efficient and highly automated framework, Stochastic Neural Architecture Search (SNAS), that trains neural operation parameters and architecture distribution parameters in same round of back propagation, while maintaining the completeness and differentiability of the NAS pipeline. One of the key motivations of SNAS is to replace the feedback Published as a conference paper at ICLR 2019 mechanism triggered by constant rewards in reinforcement-learning-based NAS with more efficient gradient feedback from generic loss. We reformulate NAS with a new stochastic modeling to bypass the MDP assumption in reinforcement learning. To combine architecture sampling with computational graph of arbitrary differentiable loss, the search space is represented with a set of one-hot random variables from a fully factorizable joint distribution, multiplied as a mask to select operations in the graph. Sampling from this search space is made differentiable by relaxing the architecture distribution with concrete distribution <ref type="bibr" target="#b16">(Maddison et al., 2016)</ref>. We name gradients w.r.t their parameters search gradient. From a global view, we prove that SNAS optimizes the same objective as reinforcement-learning-based NAS, except the training loss is used as reward. Zooming in, we provide a policy gradient equivalent of this search gradient, showing how gradients from the loss of each sample are used to assign credits to structural decisions. By interpreting this credit assignment as Taylor Decomposition <ref type="bibr" target="#b17">(Montavon et al., 2017a)</ref>, we prove SNAS's efficiency over reinforcementlearning-based NAS. Additionally, seeing that existing methods <ref type="bibr" target="#b13">(Liu et al., 2019</ref>) manually design topology in child networks to avoid complex architecture, we propose a global resource constraint to automate it, augmenting the objective with feasiblity concerns. This global constraint could be linearly decomposed for structural decisions, hence the proof of SNAS's efficiency still applies.</p><p>In our experiments, SNAS shows strong performance compared with DARTS and all other existing NAS methods in terms of test error, model complexity and searching resources. Specifically, SNAS discovers novel convolutional cells achieving 2.85?0.02% test error on CIFAR-10 with only 2.8M parameters, which is better than 3.00?0.14%-3.3M from 1st-order DARTS and 2.89%-4.6M from ENAS. It is also on par with 2.76?0.09%-3.3M from 2nd-order DARTS with fewer parameters. With a more aggressive resource constraint, SNAS discovers even smaller model achieving 3.10?0.04% test error on CIFAR-10 with 2.3M parameters. During the architecture search process, SNAS obtains a validation accuracy of 88% compared to around 70% of ENAS in fewer epochs. When validating the derived child network on CIFAR-10 without finetuning, SNAS maintains the search validation accuracy, significantly outperforming 54.66% by DARTS. These results validate our theory that SNAS is less biased than DARTS. The discovered cell achieves 27.3% top-1 error when transferred to ImageNet (mobile setting), which is comparable to 26.9% by 2nd-order DARTS. We have released our implementation at https://github.com/SNAS-Series/SNAS-Series. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>![?]</head><p>(0, 1)</p><formula xml:id="formula_0">(0, 2) (0, 3) (1, 2) (1, 3) (2, 3) (0, 1) (0, 2) (0, 3) (1, 2) (1, 3) (2, 3) % &amp; 0 % ' % ( % &amp; 0 % ' % ( )*+(-(&amp;) )</formula><p>. . . <ref type="figure">Figure 1</ref>: A conceptual visualization for a forward pass within SNAS. Sampled from p(Z), Z is a matrix whose rows Z i,j are one-hot random variable vectors indicating masks multiplied to edges (i, j) in the DAG. Columns of this matrix correspond to operations O k . In this example, there are 4 operation candidates, among which the last one is zero, i.e. removing that edge. The objective is the expectation of generic loss L of all child graphs.</p><formula xml:id="formula_1">/(-) )*+(-(') ) -(&amp;) -(') SAMPLING (a) (b)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHODOLOGY</head><p>The main initiative of SNAS is to build an efficient and economical end-to-end learning system with as little compromise of the NAS pipeline as possible. In this section, we first describe how to sample from the search space for NAS in a cell, and how it motivates a stochastic reformuation for SNAS (Section 2.1). A new optimization objective is provided and the attention-based NAS's inconsistency is discussed. Then in Section 2.2, we introduce how this discrete search space is relaxed to be continuous to let gradients back-propagate through. In Section 2.3, the search gradient of SNAS is connected to the policy gradient in reinforcement-learning-based NAS <ref type="bibr" target="#b34">(Zoph &amp; Le, 2016;</ref><ref type="bibr" target="#b19">Pham et al., 2018)</ref>, interpreting SNAS's credit assignment with contribution analysis. At last, we introduce in Section 2.4 how SNAS automates the topology search to reduce the complexity of child netowrk, as well as how it decomposes this global constraint in the context of credit assignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">SEARCH SPACE AND ARCHITECTURE SAMPLING</head><p>Searching for structure of a cell that is later stacked as building blocks for a deep architecture is an ad hoc solution to trade-off search efficiency and result optimality <ref type="bibr" target="#b35">(Zoph et al., 2017;</ref><ref type="bibr" target="#b11">Liu et al., 2017a;</ref><ref type="bibr" target="#b22">Real et al., 2018;</ref><ref type="bibr" target="#b19">Pham et al., 2018;</ref><ref type="bibr" target="#b13">Liu et al., 2019)</ref>. As shown in the left of <ref type="figure">Figure 1</ref>, the search space, i.e. a cell, is represented using a directed acyclic graph (DAG), which is called parent graph. Nodes x i in this DAG represent latent representation, whose dimensions are simply ignored to avoid abuse of notations. In convolutional networks, they are feature maps. Edges (i, j) represent information flows and possible operations O i,j to be selected between two nodes x i and x j . To make the skip operation included, nodes are enforced to be ordered, while edges only point from lower indexed nodes to higher ones. Thus we have intermediate nodes</p><formula xml:id="formula_2">x j = i&lt;j? i,j (x i ),<label>(1)</label></formula><p>where? i,j is the selected operation at edge (i, j). Analog to ENAS, SNAS search for operations and topology of this cell at the same time. Rather than using two distributions, this is done by introducing a zero operation, as in DARTS. Same as ENAS and DARTS, each cell is designed to have two inputs from the output of previous cells. The output of a cell is the concatenate of intermediate nodes.</p><p>Thanks to the fact that the volume of structural decisions, which pick? i,j for edge (i, j), is generally tractable in a cell, we represent it with a distribution p(Z). Multiplying each one-hot random variable Z i,j to each edge (i, j) in the DAG, we obtain a child graph, whose intermediate nodes are</p><formula xml:id="formula_3">x j = i&lt;j? i,j (x i ) = i&lt;j Z T i,j O i,j (x i ).<label>(2)</label></formula><p>In terms of how to parameterize and factorize p(Z), SNAS is built upon the observation that NAS is a task with fully delayed rewards in a deterministic environment. That is, the feedback signal is only ready after the whole episode is done and all state transition distributions are delta functions. Therefore, a Markov Decision Process assumption as in ENAS may not be necessary. In SNAS, we simply assume that p(Z) is fully factorizable, whose factors are parameterized with ? and learnt along with operation parameters ?. In Appendix A we connect the probability of a trajectory in the MDP of ENAS and this joint probability p(Z).</p><p>Following the setting in <ref type="bibr" target="#b34">Zoph &amp; Le (2016)</ref>, the objective of SNAS is also</p><formula xml:id="formula_4">E Z?p?(Z) [R(Z)].<label>(3)</label></formula><p>While the difference is that rather than using a constant reward from validation accuracy, we use the training/testing loss directly as reward, R(Z) = L ? (Z), such that the operation parameters and architecture parameters can be trained under one generic loss:</p><formula xml:id="formula_5">E Z?p?(Z) [R(Z)] = E Z?p?(Z) [L ? (Z)].<label>(4)</label></formula><p>The whole process of obtaining a Monte Carlo estimate of this objective is shown in <ref type="figure">Figure 1</ref>. An intuitive interpretation of this objective is to optimize the expected performance of architectures sampled with p(Z). This differentiates SNAS from attention-based NAS like DARTS, which avoids the sampling process by taking analytical expectation at each edge over all operations. In Appendix B we illustrate the inconsistency between DARTS's loss and this objective, explaining its necessity of parameter finetuning or even retraining after architecture derivation. Resembling ENAS, SNAS does not have this constraint. We introduce in next subsection how SNAS calculates gradients w.r.t ? and ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">PARAMETER LEARNING FOR OPERATIONS AND ARCHITECTURES</head><p>Though the objective (4) could be optimized with black-box gradient descent method as in <ref type="bibr" target="#b21">Ranganath et al. (2014)</ref>, it would suffer from the high variance of likelihood ratio trick <ref type="bibr" target="#b31">(Williams, 1992)</ref> and could not make use of the differentiable nature of L ? (Z). Instead, we use concrete distribution <ref type="bibr" target="#b16">(Maddison et al., 2016)</ref> here to relax the discrete architecture distribution to be continuous and differentiable with reparameterization trick:</p><formula xml:id="formula_6">Z k i,j = f ?i,j (G k i,j ) = exp((log ? k i,j + G k i,j )/?) n l=0 exp((log ? l i,j + G l i,j )/?) ,<label>(5)</label></formula><p>where Z i,j is the softened one-hot random variable for operation selection at edge (i, j), G k i,j = ? log(? log(U k i,j )) is the kth Gumbel random variable, U k i,j is a uniform random variable. ? i,j is the architecture parameter, which could depend on predecessors Z h,i if p(Z i,j ) is a conditional probability. ? is the temperature of the softmax, which is steadily annealed to be close to zero in SNAS. In <ref type="bibr" target="#b16">Maddison et al. (2016)</ref></p><formula xml:id="formula_7">, it is proved that p(lim ??0 Z k i,j = 1) = ? k i,j /( n l=0 ? l i,j ), making this relaxation unbiased once converged. The full derivation of ?E Z?p?(Z) [L ? (Z)] is given in Appendix C.</formula><p>Here with the surrogate loss L for each sample, we provide its gradient w.r.t x j , ? k i,j and ? k i,j :</p><formula xml:id="formula_8">?L ?x j = m&gt;j ?L ?x m Z T m ?O m (x j ) ?x j , ?L ?? k i,j = ?L ?x j Z k i,j ?O i,j (x i ) ?? k i,j , ?L ?? k i,j = ?L ?x j O T i,j (x i )(?(k ? k) ? Z i,j )Z k i,j 1 ?? k i,j .<label>(6)</label></formula><p>We name ?L ?? search gradient similar to the one in <ref type="bibr" target="#b30">Wierstra et al. (2008)</ref>, even though no policy gradient is involved. This renders SNAS a differentiable version of evolutionary-strategy-based NAS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">CREDIT ASSIGNMENT</head><p>With the equivalence of p(Z) in SNAS and p(? ) in ENAS from Section 2.1 and the search gradient of SNAS from Section 2.2, we discuss in this subsection what credits SNAS search gradients assign to each structural decision.</p><p>To assign credits to actions both temporally and laterally is an important topic in reinforcement learning <ref type="bibr" target="#b20">(Precup, 2000;</ref><ref type="bibr" target="#b24">Schulman et al., 2015;</ref><ref type="bibr" target="#b29">Tucker et al., 2018;</ref><ref type="bibr" target="#b32">Xu et al., 2018)</ref>. In ENAS, proximal policy optimization (PPO) <ref type="bibr" target="#b25">(Schulman et al., 2017)</ref> is used to optimize the architecture policy, which distributes credits with TD learning and generalized advantage estimator (GAE) <ref type="bibr" target="#b24">(Schulman et al., 2015)</ref>. However, as the reward of NAS task is only obtainable after the architecture is finalized and the network is tested for accuracy, it is a task with delayed rewards. As proved by <ref type="bibr" target="#b0">Arjona-Medina et al. (2018)</ref>, TD learning has bias with reward delay and corrects it exponentially slowly.</p><p>Different from ENAS, there is no MDP assumption in SNAS, but the reward function is made differentiable in terms of structural decisions. From Section 2.2 we can derive the expected search gradient for architecture parameters at edge (i, j):</p><formula xml:id="formula_9">E Z?p(Z) [ ?L ?? k i,j ] = E Z?p(Z) [? ? k i,j log p(Z i,j )[ ?L ?x j? i,j (x i )] c ],<label>(7)</label></formula><p>where [?] c emphasizes ? is constant for the gradient calculation w.r.t. ?. A full derivation is provided in Appendix D. Apparently, the search gradient is equivalent to a policy gradient for distribution at this edge whose credit is assigned as</p><formula xml:id="formula_10">R i,j = ?[ ?L ?x j? i,j (x i )] c .<label>(8)</label></formula><p>From a decision-wise perspective, this reward could be interpreted as contribution analysis of L with Taylor Decomposition <ref type="bibr" target="#b17">(Montavon et al., 2017a)</ref>, which distributes importance scores among nodes in the same effective layer. Given the presence of skip connections, nodes may be involved into multiple effective layers, credits from which would be integrated. This integrated credit of a node j is then distributed to edges (i, j) pointing to it, weighted by? i,j (x i ). Details are given in Appendix E. Thus for each structural decision, no delayed reward exists, the credits assigned to it are valid from the beginning. This proves why SNAS is more efficient than ENAS. Laterally at each edge, credits are distributed among possible operations, adjusted with random variables Z i,j . At the beginning of the training, Z i,j is continuous and operations share the credit, the training is mainly on neural operation parameters. With the temperature goes down and Z i,j becomes closer to one-hot, credits are given to the chosen operations, adjusting their probabilities to be sampled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">RESOURCE CONSTRAINT</head><p>Apart from training efficiency and validation accuracy, forwarding time of the child network is another concern in NAS in order for its feasible employment. In SNAS, this could be taken into account as a regularizer in the objective:</p><formula xml:id="formula_11">E Z?p?(Z) [L ? (Z) + ?C(Z)] = E Z?p?(Z) [L ? (Z)] + ?E Z?p?(Z) [C(Z)],<label>(9)</label></formula><p>where C(Z) is the cost of time for the child network associated with random variables Z. Rather than directly estimating the forwarding time, there are three candidates from the literature <ref type="bibr" target="#b5">(Gordon et al., 2018;</ref><ref type="bibr" target="#b15">Ma et al., 2018)</ref> that can be used to approximately represent it: 1) the parameter size ; 2) the number of float-point operations (FLOPs); and 3) the memory access cost (MAC). Details about C(Z) in SNAS could be found in Appendix F.</p><formula xml:id="formula_12">However, not like L ? (Z), C(Z) is not differentiable w.r.t. either ? or ?.</formula><p>A natural problem to ask is, whether efficient credit assignment from C(Z) could be done with similar decomposition introduced above, such that the proof of SNAS's efficiency still applies. And the answer is positive, thanks to the fact that C(Z) is linear in terms of all one-hot random variables Z i,j :</p><formula xml:id="formula_13">C(Z) = i,j C(Z i,j ) = i,j Z T i,j C(O i,j ),<label>(10)</label></formula><p>mainly because the size of feature maps at each node is not dependent on the structural decision. That is, the distribution at each edge (i, j) is optimized with local penalty, which is the conservative decomposition of the global cost, consistent with the credit assignment principle in SNAS.</p><p>In SNAS, p ? (Z) is fully factorizable, making it possible to calculate E Z?p? [C(Z)] analytically with sum-product algorithm <ref type="bibr" target="#b10">(Kschischang et al., 2001)</ref>. Unfortunately, this expectation is non-trivial to calculate, we optimize the Monte Carlo estimate of the final form from sum-product algorithm</p><formula xml:id="formula_14">E Z?p? [C(Z)] = i,j E Z \i,j ?p? [E Zi,j ?p? [Z T i,j C(O i,j )]]<label>(11)</label></formula><p>with policy gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTS</head><p>Following the pipeline in DARTS, our experiments consist of three stages. First, SNAS is applied to search for convolutional cells in a small parent network on CIFAR-10 and we choose the best cells based on their search validation accuracy. Then, a larger network is constructed by stacking the learned cells (child graphs) and is retrained on CIFAR-10 to compare the performance of SNAS with other state-of-the-art methods. Finally, we show that the cells learned on CIFAR-10 is transferable to large datasets by evaluating their performance on ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">ARCHITECTURE SEARCH ON CIFAR-10</head><p>Motivation We apply SNAS to find convolutional cells on CIFAR-10 for image classification. Unlike DARTS, which evaluates the performance of child networks during the searching stage by training their snapshots from scratch, we directly take the search validation accuracy as the performance evaluation criterion. This evaluation method is valid in SNAS since the searching is unbiased from its objective, as introduced in Section 2.1. Dataset CIFAR-10 dataset <ref type="bibr" target="#b9">(Krizhevsky &amp; Hinton, 2009</ref>) is a basic dataset for image classification, which consists of 50,000 training images and 10,000 testing images. Data transformation is achieved by the standard data pre-processing and augmentation techniques (see Appendix G.1).</p><p>Search Space Our setup follows DARTS, where convolutional cells (parent graphs) of 7 nodes are stacked for multiple times to form a network. The input nodes, i.e. the first and second nodes, of cell k are set equal to the outputs of cell k?2 and cell k?1, respectively, with 1 ? 1 convolutions inserted as necessary, and the output node is the depthwise concatenation of all the intermediate nodes.</p><p>Reduction cells are located at the 1/3 and 2/3 of the total depth of the network to reduce the spatial resolution of feature maps. Therefore the architecture distribution parameters is (? normal , ? reduce ), where ? normal is shared by all the normal cells and ? reduce is shared by all the reduction cells. Details about all operations included are shown in Appendix G.1.</p><p>Training Settings In the searching stage, we train a small network stacked by 8 cells (parent graphs) using SNAS with three levels of resource constraint for 150 epochs. This network size is determined to fit into a single GPU. Single-level optimization is employed to optimize ? and ? over the same dataset as opposed to bilevel optimization employed by DARTS. The rest of the setup follows DARTS (Appendix G.1). The search takes 32 hours 1 on a single GPU 2 .</p><p>Searching Process The normal and reduction cells learned on CIFAR-10 using SNAS with mild resource constraint are shown in <ref type="figure" target="#fig_1">Figure 2</ref>. In <ref type="figure">Figure 3</ref>, we give the validation accuracy during the search of SNAS, DARTS and ENAS with 10 Randomly Generated Seeds. Comparing with ENAS, SNAS takes fewer epochs to converge to higher validation accuracy. Though DARTS converges faster than SNAS, this accuracy is inconsistent with the child network. <ref type="table" target="#tab_0">Table 1</ref> presents their comparison of the validation accuracy at the end of search and after architecture derivation without fine-tuning. While SNAS can maintain its performance, there is a huge gap between those two in DARTS.  This gap is caused by the extra architecture derivation step in DARTS, consisting of the following two steps. (1) Remove operations with relatively weak attention. As shown in <ref type="figure">Figure 4</ref>, the entropy of the architecture distribution (softmax) at each edge, i.e. H p? , is relatively high in DARTS, indicating its uncertainty in structural decisions. Hence removing other operations from the continuous relaxation will strongly affect the output of the network. (2) Remove relatively ambiguous edges. DARTS manually selects two inputs for each intermediate nodes, thus the topology is inconsistent with that in the training stage. While SNAS employs architecture sampling and resource regularizer to automatically induce sparsity. Phenomena shown in <ref type="figure">Figure 4</ref> and <ref type="table" target="#tab_0">Table 1</ref> verify our claim that searching process in SNAS is less biased from the objective, i.e. Equation <ref type="formula" target="#formula_5">(4)</ref>, and could possibly save computation resources for parameter retraining when extended to NAS on large datasets.</p><p>Searching Results Three levels of resource constraint, mild, moderate and aggressive are examined in SNAS. Mild resource constraint lies at the margin of the appearance of zero operation to drop edges in child graphs, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>. Interestingly, every node takes only two input edges, just as in the designed scheme in ENAS and DARTS. When the constraint level is increased to moderate, the reduction cell begins to discover similar structures as normal cells, as shown in Appendix H. When a more aggressive resource constraint is added, the structure of reduction cells is further sparsified. As shown in <ref type="figure" target="#fig_4">Figure 5</ref>, more edges are dropped, leaving only two, which leads to the drop of some nodes, including the input node c k?1 , and two intermediate nodes x 2 and x 3 . Note that this child graph is a structure that ENAS and DARTS are not able to discover 4 .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">ARCHITECTURE EVALUATION ON CIFAR-10</head><p>Motivation In the searching stage, we follow the economical setup of DARTS to use only one single GPU, which constrains the parameter size of the child network. A conventional assumption in DARTS and ENAS 5 is that the final search validation accuracy has exploited the parameter size, the ceiling of which can only be raised by allowing more parameters. For a fair comparison, we follow this assumption in evaluation stage, stacking more cells (child graphs) to build a deeper network. This network is trained from scratch as in DARTS and ENAS to report the performance of the cells learned by SNAS on CIFAR-10.</p><p>Evaluation Settings A large network of 20 cells is trained from scratch for 600 epochs with batch size 96. Other hyperparameters remain the same as those for architecture search. Additional enhancements are listed in Appendix G.2. The training takes 1.5 days on a single GPU with our implementation in PyTorch.  <ref type="bibr" target="#b22">(Real et al., 2018)</ref> 3.34 ? 0.06 3.2 3150 evolution complete AmoebaNet-B + cutout <ref type="bibr" target="#b22">(Real et al., 2018)</ref> 2.55 ? 0.05 2.8 3150 evolution complete Hierarchical Evo <ref type="bibr" target="#b12">(Liu et al., 2017b)</ref> 3.75 ? 0.12 15.7 300 evolution complete PNAS <ref type="bibr" target="#b11">(Liu et al., 2017a)</ref> 3.41 ? 0.09 3.2 225 SMBO complete ENAS + cutout <ref type="bibr" target="#b19">(Pham et al., 2018)</ref> 2.89 4.6 0.5 RL complete</p><p>Random search baseline + cutout <ref type="bibr" target="#b13">(Liu et al., 2019)</ref> 3.29 ? 0.15 3.2 1 random -DARTS (1st order bi-level) + cutout <ref type="bibr" target="#b13">(Liu et al., 2019)</ref> 3.00 ? 0.14 3.3 0.4 gradient-based incomplete DARTS (2nd order bi-level) + cutout <ref type="bibr" target="#b13">(Liu et al., 2019)</ref> 2.76 ? 0.09 3.3 1 gradient-based incomplete DARTS (single-level) + cutout <ref type="bibr" target="#b13">(Liu et al., 2019)</ref> 3.56 ? 0.10 3.0 0.3 gradient-based incomplete SNAS (single-level) + mild constraint + cutout 2.98 2.9 1.5 gradient-based complete SNAS (single-level) + moderate constraint + cutout 2.85 ? 0.02 2.8 1.5 gradient-based complete SNAS (single-level) + aggressive constraint + cutout 3.10 ? 0.04 2.3 1.5 gradient-based complete</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The CIFAR-10 evaluation results are presented in <ref type="table" target="#tab_1">Table 2</ref>. The test error of SNAS is on par with the state-of-the-art RL-based and evolution-based NAS while using three orders of magnitude less computation resources. Furthermore, with slightly longer wall-clock-time, SNAS outperforms 1st-order DARTS and ENAS by discovering convolutional cells with both a smaller error rate and fewer parameters. It also achieves a comparable error rate compared to 2nd-order DARTS but with fewer parameters. With a more aggressive resource constraint, SNAS can sparsify the architecture even further to distinguish from ENAS and DARTS with only a slight drop in performance, which is still on par with 1st-order DARTS. It is interesting to note that with same single-level optimization, SNAS significantly outperforms DARTS. Bilevel optimization could be regarded as a data-driven meta-learning method to resolve the bias proved above, whose bias from the exact meta-learning objective is still unjustified due to the ignorance of separate child network derivation scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">ARCHITECTURE TRANSFERABILITY EVALUATION ON IMAGENET</head><p>Motivation Since real world applications often involve much larger datasets than CIFAR-10, transferability is a crucial criterion to evaluate the potential of the learned cells (child graphs) <ref type="bibr" target="#b35">(Zoph et al., 2017)</ref>. To show whether the cells learned on by SNAS CIFAR-10 can be generalized to larger datasets, we apply the same cells evaluated in Section 3.2 to the classification task on ImageNet.</p><p>Dataset The mobile setting is adopted where the size of the input images is 224 ? 224 and the number of multiply-add operations in the model is restricted to be less than 600M.  <ref type="bibr" target="#b35">(Zoph et al., 2017)</ref> 27.2 8.7 5.3 488 1800 RL complete NASNet-C <ref type="bibr" target="#b35">(Zoph et al., 2017)</ref> 27.5 9.0 4.9 558 1800 RL complete AmoebaNet-A <ref type="bibr" target="#b22">(Real et al., 2018)</ref> 25.5 8.0 5.1 555 3150 evolution complete AmoebaNet-B <ref type="bibr" target="#b22">(Real et al., 2018)</ref> 26.0 8.5 5.3 555 3150 evolution complete AmoebaNet-C <ref type="bibr" target="#b22">(Real et al., 2018)</ref> 24.3 7.6 6.4 570 3150 evolution complete PNAS <ref type="bibr" target="#b11">(Liu et al., 2017a)</ref> 25.8 8. Evaluation Settings We stack a network of 14 cells using the same cells designed by SNAS (mild constraint) and evaluated on CIFAR-10 (Section 3.2) and train it for 250 epochs with other hyperparameters following DARTS (see Appendix G.3). The training takes 12 days on a single GPU.</p><p>Results <ref type="table" target="#tab_2">Table 3</ref> presents the results of the evaluation on ImageNet and shows that the cell found by SNAS on CIFAR-10 can be successfully transferred to ImageNet. Notably, SNAS is able to achieve competitive test error with the state-of-the-art RL-based NAS using three orders of magnitude less computation resources. And with resource constraints added, SNAS can find smaller cell architectures that achieve competitive performance with DARTS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RELATED WORKS</head><p>Improving the efficiency of NAS is a prerequisite to extending it to more complicated vision tasks like detection, as well as larger datasets. In the complete pipeline of NAS, parameter learning is a time-consuming one that attracts attention from the literature. Ideas to design auxiliary mechanisms like performance prediction <ref type="bibr" target="#b1">(Baker et al., 2017;</ref><ref type="bibr" target="#b3">Deng et al., 2017)</ref>, iterative search <ref type="bibr" target="#b11">(Liu et al., 2017a)</ref>, hypernetwork generated weights <ref type="bibr" target="#b2">(Brock et al., 2017)</ref> successfully accelerate NAS to certain degrees. Getting rid of these auxiliary mechanisms, ENAS <ref type="bibr" target="#b19">(Pham et al., 2018)</ref> is the state-of-the-art NAS framework, proposing parameter sharing among all possible child graphs, which is followed by SNAS. In Section 2 we introduced SNAS's relation with ENAS in details. Apart from ENAS, we are also inspired by <ref type="bibr" target="#b14">Louizos et al. (2017)</ref> to use continuous distribution for structural decision at each edge and optimize it along with an l 0 complexity regularizer.</p><p>The most important motivation of SNAS is to leverage the gradient information in generic differentiable loss to update architecture distribution, which is shared by DARTS <ref type="bibr" target="#b13">(Liu et al., 2019)</ref>.</p><p>In Section 2 and Appendix B we have introduced SNAS's advantage over DARTS, a reward for maintaining the completeness of the NAS pipeline. Actually, the idea to make use of this gradient information to improve the learning efficiency of a stochastic model has been discussed in the literature of generative model <ref type="bibr" target="#b6">(Gu et al., 2015;</ref><ref type="bibr" target="#b16">Maddison et al., 2016)</ref> and reinforcement learning <ref type="bibr" target="#b23">(Schmidhuber, 1990;</ref><ref type="bibr" target="#b0">Arjona-Medina et al., 2018)</ref>. But as far as we known, we are the first one to combine the insights from these two fields to discuss possible efficiency improvement of NAS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this work, we presented SNAS, a novel and economical end-to-end neural architecture search framework. The key contribution of SNAS is that by making use of gradient information from generic differentiable loss without sacrificing the completeness of NAS pipeline, stochastic architecture search could be more efficient. This improvement is proved by comparing the credit assigned by the search gradient with reinforcement-learning-based NAS. Augmented by a complexity regu-larizer, this search gradient trades off testing error and forwarding time. Experiments showed that SNAS searches well on CIFAR-10, whose result could be transferred to ImageNet as well. As a more efficient and less-biased framework, SNAS will serve as a possible candidate for full-fledged NAS on large datasets in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A CONNECTING p(Z) IN SNAS AND p(? ) IN ENAS</head><p>In ENAS, the NAS task is defined as an MDP, where the observation o i = a 0 , a 1 ...a i?1 . Thus the transition probability p(o i |o i?1 , a i?1 ) = p(o i |a 0 , a 1 ...a i?2 , a i?1 ) = ?(a 0 , a 1 ...a i?1 ).</p><p>(12) With the policy of RNN controller denoted as ?(a i |o i ), the joint probability of a trajectory ? in this MDP is</p><formula xml:id="formula_15">p(? ) = ?(o 0 ) i ?(a i |o i ) i p(o i+1 |o i , a i ) = i ?(a i |o i ) = i ?(a i |a 0 , a 1 ...a i?1 ) = p(a),<label>(13)</label></formula><p>where a is a vector of all structural decisions, which is denoted as Z in SNAS. So we have p(? ) = p(Z).</p><p>(14) Note that if we factorize p(Z) with conditional probability to have Markovian property as in Equation 13, we have the factor p(Z i |Z 0 , Z 1 ...Z i?1 ) = ?(a i |a 0 , a 1 ...a i?1 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B DIFFERENCE BETWEEN SNAS AND DARTS</head><p>We take a search space with three intermediate nodes for example to exhibit the difference between SNAS and DARTS <ref type="bibr" target="#b13">(Liu et al., 2019)</ref>, as shown in <ref type="figure" target="#fig_5">Figure 6</ref>. This search space could be viewed as a unit search space whose property could be generalized to larger space since it contains nodes in series and in parallel.</p><p>The objective of a NAS task is</p><formula xml:id="formula_17">E Z?p?(Z) [R(Z)],<label>(16)</label></formula><p>where p ? (Z) is the distribution of architectures, which is previously solved with reinforcement learning. In both SNAS and DARTS, the reward function is made differentiable using the training/testing loss, R(Z) = L ? ((Z)), such that the architecture learning could leverage information in the gradients of this loss and conduct together with operation parameters training:</p><formula xml:id="formula_18">E Z?p?(Z) [R(Z)] = E Z?p?(Z) [L ? (Z)].</formula><p>(17) As introduced in Appendix A, SNAS solves (16) with a novel type of factorization, without relying on the MDP assumption. Though independent assumption between edges would restrict the probability distribution, there is no bias introduced.</p><p>However, to avoid the sampling process and gradient back-propagation through discrete random variables, DARTS takes analytical expectation at the input of each node over operations at incoming edges and optimizes a relaxed loss with deterministic gradients. Take the cell in <ref type="figure" target="#fig_5">Figure 6</ref> as a base case, the objective before this relaxation is</p><formula xml:id="formula_19">E Z?p?(Z) [L ? (Z T j,l O j,l (Z T i,j O i,j (x i )) + Z T j,m O j,m (Z T i,j O i,j (x i )))] =E Z?p?(Z) [L ? ( m&gt;j Z T j,m O j,m (Z T i,j O i,j (x i ))].<label>(18)</label></formula><p>DARTS relaxed this objective to</p><formula xml:id="formula_20">L ? ( m&gt;j E p? j,m [Z T j,m O j,m (E p? i,j [Z T i,j O i,j (x i )])]).<label>(19)</label></formula><p>Considering that O(x) are ReLU-Conv-BN stacks as in ENAS <ref type="bibr" target="#b19">(Pham et al., 2018)</ref>, which are nonlinear, this transformation introduces unbounded bias. Though it will not be perceivable in training, where the complete graph is used for accuracy validation, consistent this loss, the derived graph is never validated during training. Hence the training is inconsistent with the true objective maximizing the expected performance of derived architectures. After an architecture derivation introduced in DARTS, the performance falls enormously and the parameters need to be retrained. We have</p><formula xml:id="formula_21">x j = h&lt;j Z T h,j O h,j (x h ) = Z T i,j O i,j (x i ) + h&lt;i Z T h,j O h,j (x h ).<label>(20)</label></formula><p>Let ? k i,j be the parameters in O k i,j , we have</p><formula xml:id="formula_22">?x j ?? k i,j = Z T i,j ?O i,j (x i ) ?? k i,j .<label>(21)</label></formula><p>As we use concrete disctribution here to make the sampling differentiable with reparametrization trick:</p><formula xml:id="formula_23">Z k i,j = f ?i,j (G k i,j ) = exp((log ? k i,j + G k i,j )/?) n l=0 exp((log ? l i,j + G l i,j )/?) ,<label>(22)</label></formula><p>where G k i,j = ? log(? log(U k i,j )) is the kth Gumbel random variable, U k i,j is a uniform random variable, the gradient w.r.t. ? i,j is:</p><formula xml:id="formula_24">?x j ?? k i,j = O T i,j (x i ) ?f ?i,j (G i,j ) ?? k i,j .<label>(23)</label></formula><p>The partial derivative</p><formula xml:id="formula_25">?f? i,j ?? k i,j is ?f ?i,j (G i,j ) ?? k i,j = ? ?? k i,j exp((log ? k i,j + G k i,j )/?) n l=0 exp((log ? l i,j + G l i,j )/?) (?(k ? k) ? exp((log ? i,j + G i,j )/?) n l=0 exp((log ? i i,j + G l i,j )/?) ) = ?(log ? k i,j + G k i,j )/? ?? k i,j f ?i,j (G k i,j )(?(k ? k) ? f ?i,j (G i,j )) =(?(k ? k) ? f ?i,j (G i,j ))f ?i,j (G k i,j ) 1 ?? k i,j =(?(k ? k) ? Z i,j )Z k i,j 1 ?? k i,j .</formula><p>(24) Substitute it back to (23), we obtain</p><formula xml:id="formula_26">?x j ?? k i,j = O T i,j (x i )(?(k ? k) ? Z i,j )Z k i,j 1 ?? k i,j .<label>(25)</label></formula><p>We can also derive ?xm ?xj for chain rule connection:</p><formula xml:id="formula_27">?x m ?x j = Z T j,m ?O j,m (x j ) ?x j .<label>(26)</label></formula><p>Thus the gradient from the surrogate loss L to x j , ? k i,j and ? k i,j respectively are</p><formula xml:id="formula_28">?L ?x j = m&gt;j ?L ?x m Z T j,m ?O j,m (x j ) ?x j , ?L ?? k i,j = ?L ?x j Z k i,j ?O i,j (x i ) ?? k i,j , ?L ?? k i,j = ?L ?x 1 O T i,j (x i )(?(k ? k) ? Z i,j )Z k i,j 1 ?? k i,j .<label>(27)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D CREDIT ASSIGNMENT FOR EQUIVALENT POLICY GRADIENT</head><p>From Appendix C we can see that the expected search gradient for architecture parameters at each edge is:</p><formula xml:id="formula_29">E Z?p(Z) [ ?L ?? k i,j ] = E U ?U nif orm [ ?L ?x j O T i,j (x i ) ?f ?i,j (? log(? log(U i,j ))) ?? k i,j ] = 1 0 p(U i,j ) ?L ?x j O T i,j (x i ) ?f ?i,j (? log(? log(U i.j ))) ?? k i,j dU i,j = ? ?? k 1 1 0 p(U i,j )[ ?L ?x j O T i,j (x i )] c f ?i,j (? log(? log(U i,j )))dU i,j = ? ?? k i,j p(Z i,j )[ ?L ?x j O T i,j (x i )] c Z i,j dZ i,j = p(Z i,j ) ? log p(Z i,j ) ?? k i,j [ ?L ?x j O T i,j (x i )Z i,j ] c dZ i,j = E Z?p(Z) [? ? k i,j log p(Z i,j )[ ?L ?x j O T i,j (x i )Z i,j ] c ] = E Z?p(Z) [? ? k i,j log p(Z i,j )[ ?L ?x j? i,j (x i )] c ],<label>(28)</label></formula><p>where [?] c denotes ? is a constant for the gradient calculation w.r.t. ?. Note that in this derivation we stop the gradient from successor nodes, with an independence assumption enforced in backpropagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E TAYLOR DECOMPOSITION FOR CONTRIBUTION ANALYSIS</head><p>With d neurons (pixels) x i in the same layer of a deep neural network, whose output is f (x), <ref type="bibr" target="#b17">Montavon et al. (2017a)</ref> decomposes f (x) as a sum of individual credits for x i . This decomposition is obtained by the first-order Taylor expansion of the function at some root pointx for which f (x) = 0:</p><formula xml:id="formula_30">f (x) = d i=1 R i (x) + O(xx T ),<label>(29)</label></formula><p>where the individual credits</p><formula xml:id="formula_31">R i (x) = ?f ?x i | x=x (x i ?x i )<label>(30)</label></formula><p>are first-order terms and O(xx T ) is for higher-order information. When ReLU is chosen as the activation function, O(xx T ) can be omitted <ref type="bibr" target="#b18">(Montavon et al., 2017b)</ref>. Thus ones can always find a root pointx = lim ?0 x that incidentally lies on the same linear region as point x, in which case the function can be written as</p><formula xml:id="formula_32">f (x) = d i=1 R i (x) = d i=1 ?f ?x i x i .<label>(31)</label></formula><p>Noticing the similarity between <ref type="formula" target="#formula_10">(8)</ref> and <ref type="formula" target="#formula_2">(31)</ref>, we try using Taylor Decomposition to interpret the credit assignment in SNAS. Given a sample x 0 , ones can iterate all effective layers of the DAG and distribute credits from network output f among nodes x j in each layer. In <ref type="figure">Figure 1</ref> for example, DAG(Z (1) ) has 2 effective layers, while DAG(Z (2) ) has 3 effective layers. Given the presence of the skip connection, nodes may be involved into multiple layers and thus obtain integrated credits</p><formula xml:id="formula_33">?f ?x j = m&gt;j ?f ?x m ?? m (x j ) ?x j ,<label>(32)</label></formula><p>e.g. x 1 in DAG(2) integrates credits from x 2 and x 3 . According to (1), multiple edges (i, j) are pointing to j, which decompose (32) as:R</p><formula xml:id="formula_34">i,j = ?f ?x j? i,j (x i ).<label>(33)</label></formula><p>Adjusting the weight of this sample with ?L/?f and taking the optimization direction into account, we have</p><formula xml:id="formula_35">R i,j = ? ?L ?x j? i,j (x i )<label>(34)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F CANDIDATES FOR LOCAL RESOURCE CONSTRAINTS</head><p>In the case of a convolutional layer, H, W and f , k correspond to the output spatial dimensions and the filter dimensions respectively and we use I, O to denote the number of input and output channels.</p><p>Since group convolution is also adopted in this paper to reduce the computational complexity, g is the number of groups.</p><p>Thus, the parameter size and the number of float-point operations (FLOPs) of a single convolutional layer is</p><formula xml:id="formula_36">parameter size = f kIO g<label>(35)</label></formula><p>FLOPs = HW f kIO g</p><p>By assuming the computing device has enough cache to store the feature maps and the parameters, we can simplify the memory access cost (MAC) to be the sum of the memory access for the input/output feature maps and kernel weights <ref type="bibr" target="#b15">(Ma et al., 2018)</ref>.</p><formula xml:id="formula_38">MAC = HW (I + O) + f kIO g<label>(37)</label></formula><p>In SNAS, because all the operations on a single edge share the same output spatial dimensions and the input/output channels, FLOPs of a convolutional operation is directly proportional to its parameter size. And although the memory access cost for the input/output feature maps HW <ref type="table">(I +O)</ref> does not depend on the parameter size, since both are positively correlated to the number of layers used in the operation, we may say there is a positive correlation between MAC and the parameter size. Thus, when only considering the convolution operations, solely using the parameter size as the resource constraint is sufficient. However, in SNAS, we also have the pooling operation and the skip connection, which are parameter free. The equations to calculate the resource criteria of a pooling operation or a skip connection are as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FLOPs of pooling:</head><p>FLOPs = HW f kIO</p><p>FLOPs of skip connection:</p><formula xml:id="formula_40">FLOPs = 0<label>(39)</label></formula><p>MAC of pooling and skip connection:</p><formula xml:id="formula_41">MAC = HW (I + O)<label>(40)</label></formula><p>We can see that MAC is the same for pooling and skip connection since they need to access the same input/output feature maps, therefore, to distinguish between pooling and skip connection, FLOPs need to be included in the resource constraint. Similarly, to distinguish between skip connection and none (free, no operation), MAC also need to be included.</p><p>In conclusion, to construct a resource constraint which fully distinguishes the four types of operations, all three locally decomposable criteria, the parameter size, FLOPs and MAC, need to be combined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G DETAILED SETTINGS OF EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.1 ARCHITECTURE SEARCH ON CIFAR-10</head><p>Data Pre-processing and Augmentation Techniques We employ the following techniques in our experiments: centrally padding the training images to 40 ? 40 and then randomly cropping them back to 32 ? 32; randomly flipping the training images horizontally; normalizing the training and validation images by subtracting the channel mean and dividing by the channel standard deviation.</p><p>Implementation Details of Operations The operations include: 3 ? 3 and 5 ? 5 separable convolutions, 3 ? 3 and 5 ? 5 dilated separable convolutions, 3 ? 3 max pooling, 3 ? 3 average pooling, skip connection and zero operation. All operations are of stride one (excluded the ones adjacent to the input nodes in the reduction cell, which are of stride two) and the convolved feature maps are padded to preserve their spatial resolution. Convolutions are applied in the order of ReLU-Conv-BN, and the depthwise separable convolution is always applied twice <ref type="bibr" target="#b35">(Zoph et al., 2017;</ref><ref type="bibr" target="#b22">Real et al., 2018;</ref><ref type="bibr" target="#b11">Liu et al., 2017a;</ref><ref type="bibr" target="#b13">2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detailed Training Settings</head><p>We follow the training settings as in <ref type="bibr" target="#b13">Liu et al. (2019)</ref>. The neural operation parameters ? are optimized using momentum SGD, with initial learning rate ? ? = 0.025 (annealed down to zero following a cosine schedule), momentum 0.9, and weight decay 3 ? 10 ?4 . The architecture distribution parameters ? are optimized by Adam, with initial learning rate ? ? = 3 ? 10 ?4 , momentum ? = (0.5, 0.999) and weight decay 10 ?3 . The batch size employed is 64 and the initial number of channels is 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.2 ARCHITECTURE EVALUATION ON CIFAR-10</head><p>Additional Enhancement Techniques Following existing works <ref type="bibr" target="#b35">(Zoph et al., 2017;</ref><ref type="bibr" target="#b11">Liu et al., 2017a;</ref><ref type="bibr" target="#b19">Pham et al., 2018;</ref><ref type="bibr" target="#b22">Real et al., 2018;</ref><ref type="bibr" target="#b13">Liu et al., 2019)</ref>, we employ the following additional enhancements: cutout (DeVries &amp; Taylor, 2017), path dropout of probability 0.2 (same as DARTS in the code publicly released by its authors) and auxiliary towers with weight 0.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G.3 ARCHITECTURE TRANSFERABILITY EVALUATION ON CIFAR-10</head><p>Detailed Training Settings The network is trained with batch size 128, weight decay 3 ? 10 ?5 and initial SGD learning rate 0.1, which is decayed by a factor of 0.97 after each epoch. Auxiliary towers with weight 0.4 are adopted as additional enhancements. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H CELLS LEARNED BY SNAS WITH</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Cells (child graphs) SNAS (mild constraint) finds on CIFAR-10. (a) Normal cell. (b) Reduction cell.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Search progress in validation accuracy from SNAS, DARTS and ENAS. Entropy of architecture distribution in SNAS and DARTS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Cells (child graphs) SNAS (aggressive constraint) finds on CIFAR-10. (a) Normal cell. (b) Reduction cell.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>A comparison for gradients in DARTS and SNAS. (a) Deterministic gradients in DARTS; (b) Stochastic gradients in SNAS. Solid lines denote deterministic nodes, while dashed lines denote stochastic nodes. Black dotted lines denote compounded gradients, purple lines for parameter gradients in SNAS, red for search gradients. C GRADIENTS IN SNAS Figure 6(b) gives an illustration of a base three-intermediate-node unit in SNAS, where each edge has three operations (indexed by k) to choose from. In the search space of SNAS, intermediate nodes take input from all previous nodes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Cells (child graphs) SNAS (moderate constraint) finds on CIFAR-10. (a) Normal cell. (b) Reduction cell.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Search validation accuracy and child network validation accuracy of SNAS and DARTS.Results marked with * were obtained using the code publicly released by<ref type="bibr" target="#b13">Liu et al. (2019)</ref>.</figDesc><table><row><cell>Architecture</cell><cell>Search Valid. Acc (%)</cell><cell>Child Net Valid. Acc (%)</cell><cell>Search Cost (GPU days)</cell></row><row><cell>DARTS (2nd order bi-level) (Liu et al., 2019)*</cell><cell>87.67</cell><cell>54.66</cell><cell>1 3</cell></row><row><cell>SNAS (single-level) + mild constraint</cell><cell>88.54</cell><cell>90.67</cell><cell>1.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Classification errors of SNAS and state-of-the-art image classifiers on CIFAR-10.</figDesc><table><row><cell>Architecture</cell><cell>Test Error (%)</cell><cell>Params (M)</cell><cell>Search Cost (GPU days)</cell><cell>Search Method</cell><cell>NAS Pipeline Completeness</cell></row><row><cell>DenseNet-BC (Huang et al., 2017)</cell><cell>3.46</cell><cell>25.6</cell><cell>-</cell><cell>manual</cell><cell>-</cell></row><row><cell>NASNet-A + cutout (Zoph et al., 2017)</cell><cell>2.65</cell><cell>3.3</cell><cell>1800</cell><cell>RL</cell><cell>complete</cell></row><row><cell>AmoebaNet-A + cutout</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Classification errors of SNAS and state-of-the-art image classifiers on ImageNet.</figDesc><table><row><cell>Architecture</cell><cell cols="2">Test Error (%) top-1 top-5</cell><cell>Params (M)</cell><cell>+ ? (M)</cell><cell>Search Cost (GPU days)</cell><cell>Search Method</cell><cell>NAS Pipeline Completeness</cell></row><row><cell>Inception-v1 (Szegedy et al., 2015)</cell><cell>30.2</cell><cell>10.1</cell><cell>6.6</cell><cell>1448</cell><cell>-</cell><cell>manual</cell><cell>-</cell></row><row><cell>MobileNet (Howard et al., 2017)</cell><cell>29.4</cell><cell>10.5</cell><cell>4.2</cell><cell>569</cell><cell>-</cell><cell>manual</cell><cell>-</cell></row><row><cell>ShuffleNet 2? (v1) (Zhang et al.)</cell><cell>26.4</cell><cell>10.2</cell><cell>?5</cell><cell>524</cell><cell>-</cell><cell>manual</cell><cell>-</cell></row><row><cell cols="2">ShuffleNet 2? (v2) (Ma et al., 2018) 25.1</cell><cell>10.1</cell><cell>?5</cell><cell>591</cell><cell>-</cell><cell>manual</cell><cell>-</cell></row><row><cell>NASNet-A (Zoph et al., 2017)</cell><cell>26.0</cell><cell>8.4</cell><cell>5.3</cell><cell>564</cell><cell>1800</cell><cell>RL</cell><cell>complete</cell></row><row><cell>NASNet-B</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The batch size of SNAS is 64 and that of ENAS is 160. 2 All the experiments were performed using NVIDIA TITAN Xp GPUs</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Repetition for convolutional cells is not necessary since the optimization outcomes are not initializationsensetive<ref type="bibr" target="#b13">(Liu et al., 2019)</ref>.4  In the code from<ref type="bibr" target="#b13">Liu et al. (2019)</ref>, zero is omitted in child graph derivation as empirically it tends to learn the largest weight.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">As shown in the code publicly released by<ref type="bibr" target="#b19">Pham et al. (2018)</ref> </note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jose A Arjona-Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gillhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Widrich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.07857</idno>
		<title level="m">Thomas Unterthiner, and Sepp Hochreiter. Rudder: Return decomposition for delayed rewards</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Accelerating neural architecture search using performance prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otkrist</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Naik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10823</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Smash: one-shot model architecture search through hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodore</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ritchie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.05344</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Peephole: Predicting network performance before training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.03351</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<title level="m">Improved regularization of convolutional neural networks with cutout</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Morphnet: Fast &amp; simple resource-constrained structure learning of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Eban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Nachum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tien-Ju</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Muprop</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05176</idno>
		<title level="m">Unbiased backpropagation for stochastic neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Factor graphs and the sum-product algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><forename type="middle">J</forename><surname>Frank R Kschischang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H-A</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Loeliger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on information theory</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="498" to="519" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.00559</idno>
		<title level="m">Progressive neural architecture search</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Hierarchical representations for efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisantha</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.00436</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=S1eYHoC5FX" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik P</forename><surname>Kingma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.01312</idno>
		<title level="m">Learning sparse neural networks through l 0 regularization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Shufflenet v2: Practical guidelines for efficient cnn architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningning</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai-Tao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.11164</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The concrete distribution: A continuous relaxation of discrete random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Chris J Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.00712</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Explaining nonlinear classification decisions with deep taylor decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gr?goire</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Lapuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="211" to="222" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Methods for interpreting and understanding deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gr?goire</forename><surname>Montavon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Robert</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Signal Processing</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameter sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melody</forename><forename type="middle">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Eligibility traces for off-policy policy evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science Department Faculty Publication Series</title>
		<imprint>
			<biblScope unit="page">80</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Black box variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="814" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.01548</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Making the world differentiable: On using fully recurrent self-supervised neural networks for dynamic reinforcement learning and planning in non-stationary environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno>FKI-126</idno>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">90</biblScope>
		</imprint>
		<respStmt>
			<orgName>Institut f?r Informatik, Technische Universit?t M?nchen</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Highdimensional continuous control using generalized advantage estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.02438</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Evolving neural networks through augmenting topologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kenneth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risto</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="127" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The mirage of action-dependent baselines in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Bhupatiraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.10031</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Natural evolution strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE World Congress on Computational Intelligence)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3381" to="3387" />
		</imprint>
	</monogr>
	<note>Evolutionary Computation</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Reinforcement Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1992" />
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongwen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hado Van Hasselt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Silver</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.09801</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Meta-gradient reinforcement learning. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Shufflenet: An extremely efficient convolutional neural network for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.01083</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01578</idno>
		<title level="m">Neural architecture search with reinforcement learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07012</idno>
		<title level="m">Learning transferable architectures for scalable image recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
