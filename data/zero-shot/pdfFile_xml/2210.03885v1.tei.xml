<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Meta-DMoE: Adapting to Domain Shift by Meta-Distillation from Mixture-of-Experts</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Zhong</surname></persName>
							<email>tao.zhong@mail.utoronto.cayang.wang@concordia.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixiang</forename><surname>Chi</surname></persName>
							<email>zhixiang.chi@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Gu</surname></persName>
							<email>li.gu@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Concordia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhao</forename><surname>Yu</surname></persName>
							<email>yuanhao.yu@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Tang</surname></persName>
							<email>tangjin@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Meta-DMoE: Adapting to Domain Shift by Meta-Distillation from Mixture-of-Experts</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we tackle the problem of domain shift. Most existing methods perform training on multiple source domains using a single model, and the same trained model is used on all unseen target domains. Such solutions are sub-optimal as each target domain exhibits its own speciality, which is not adapted. Furthermore, expecting the single-model training to learn extensive knowledge from the multiple source domains is counterintuitive. The model is more biased toward learning only domain-invariant features and may result in negative knowledge transfer. In this work, we propose a novel framework for unsupervised test-time adaptation, which is formulated as a knowledge distillation process to address domain shift. Specifically, we incorporate Mixture-of-Experts (MoE) as teachers, where each expert is separately trained on different source domains to maximize their speciality. Given a test-time target domain, a small set of unlabeled data is sampled to query the knowledge from MoE. As the source domains are correlated to the target domains, a transformer-based aggregator then combines the domain knowledge by examining the interconnection among them. The output is treated as a supervision signal to adapt a student prediction network toward the target domain. We further employ meta-learning to enforce the aggregator to distill positive knowledge and the student network to achieve fast adaptation. Extensive experiments demonstrate that the proposed method outperforms the state-of-the-art and validates the effectiveness of each proposed component. Our code is available at https://github.com/n3il666/Meta-DMoE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>domains <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b69">70]</ref>. Adversarial learning is also applied to develop indistinguishable feature space <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b56">57]</ref>. The first limitation of UDA is the assumption of the co-existence of source and target data, which is inapplicable when the target domain is unknown in advance. Furthermore, most of the algorithms focus on unrealistic single-source-single-target adaptation as source data normally come from multiple domains. Splitting the source data into various distinct domains and exploring the unique characteristics of each domain and the dependencies among them strengthen the robustness <ref type="bibr" target="#b88">[89,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b77">78]</ref>. Domain generalization (DG) is another line of research to alleviate the domain shift. DG aims to train a model on multiple source domains without accessing any prior information of the target domain and expects it to perform well on unseen target domains. <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b52">53]</ref> aim to learn the domain-invariant feature representation. <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b74">75]</ref> exploit data augmentation strategies in data or feature space. A concurrent work proposed bidirectional learning to mitigate domain shift <ref type="bibr" target="#b13">[14]</ref>. However, deploying the generic model to all unseen target domains fails to explore domain specialty and yields sub-optimal solutions. In contrast, our method further exploits the unlabeled target data and updates the trained model to each specific unseen target domain at test time.</p><p>Test-time adaptation (TTA). TTA constructs supervision signals from unlabeled data to update the generic model before inference. Sun et al. <ref type="bibr" target="#b67">[68]</ref> use rotation prediction to update the model during inference. Chi et al. <ref type="bibr" target="#b16">[17]</ref> and Li et al. <ref type="bibr" target="#b45">[46]</ref> reconstruct the input images to achieve internal-learning to better restore the blurry images and estimate the human pose. ARM <ref type="bibr" target="#b86">[87]</ref> incorporates test-time adaptation with DG which meta-learns a model that is capable of adapting to unseen target domains before making an inference. Instead of adapting to every data sample, our method only updates once for each target domain using a fixed number of examples.</p><p>Meta-learning. The existing meta-learning methods can be categorised as model-based <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b7">8]</ref>, metric-based <ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b29">30]</ref>, and optimization-based <ref type="bibr" target="#b24">[25]</ref>. Meta-learning aims to learn the learning process by episodic learning which is based on bi-level optimization ( <ref type="bibr" target="#b12">[13]</ref> provides a comprehensive survey). One of the advantages of bi-level optimization is to improve the training with conflicting learning objectives. Utilizing such paradigm, <ref type="bibr">[16,</ref><ref type="bibr" target="#b84">85]</ref> successfully reduce the forgetting issue and improve adaptation for continual learning <ref type="bibr" target="#b48">[49]</ref>. In our method, we incorporate meta-learning with knowledge distillation by jointly learning a student model initialization and a knowledge aggregator for fast adaptation.</p><p>Mixture-of-experts. The goal of MoE <ref type="bibr" target="#b36">[37]</ref> is to decompose the whole training set into many subsets, which are independently learned by different models. It has been successfully applied in image recognition models to improve the accuracy <ref type="bibr" target="#b0">[1]</ref>. MoE is also popular in scaling up the architectures. As each expert is independently trained, sparse selection methods are developed to select a subset of the MoE during inference to increase the network capacity <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b28">29]</ref>. In contrast, our method utilizes all the experts to extract and combine the knowledge for positive knowledge transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</head><p>In this section, we describe the problem setting and discuss the adaptive model. We mainly follow the test-time unsupervised adaptation as in <ref type="bibr" target="#b86">[87]</ref>. Specifically, we define a set of N source domains</p><formula xml:id="formula_0">D S = {D S i } N i=1 and M target domains D T = {D T j } M j=1 .</formula><p>The exact definition of a domain varies and depends on the applications or data collection methods. It could be a specific dataset, user, or location. Let x ? X and y ? Y denote the input and the corresponding label, respectively. Each of the source domains contains data in the form of input-output pairs:</p><formula xml:id="formula_1">D S i = {(x z S , y z S )} Zi z=1 .</formula><p>In contrast, each of the target domains contains only unlabeled data:</p><formula xml:id="formula_2">D T j = {(x k T )} Kj k=1</formula><p>. For well-designed datasets (e.g. <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b19">20]</ref>), all the source or target domains have the same number of data samples. Such condition is not ubiquitous for real-world scenarios (i.e. Z i1 = Z i2 if i 1 = i 2 and K j1 = K j2 if j 1 = j 2 ) where data imbalance always exists <ref type="bibr" target="#b38">[39]</ref>. It further challenges the generalization with a broader range of real-world distribution shifts instead of finite synthetic ones. Generic domain shift tasks focus on the out-of-distribution setting where the source and target domains are non-overlapping (i.e. D S ? D T = ?), but the label spaces of both domains are the same (i.e. Y S = Y T ).</p><p>Conventional DG methods perform training on D S and make a minimal assumption on the testing scenarios <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b34">35]</ref>. Therefore, the same generic model is directly applied to all target domains D T , which leads to non-optimal solutions <ref type="bibr" target="#b67">[68]</ref>. In fact, for each D T j , some unlabeled data are readily available which provides certain prior knowledge for that target distribution. Adaptive Risk Minimization (ARM) <ref type="bibr" target="#b86">[87]</ref> assumes that a batch of unlabeled input data x approximate the ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Domain expert models</head><p>Aggregator <ref type="bibr">(</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Support set</head><p>Distill knowledge <ref type="table">(   Query set  Meta-update   Inner loop, adaptation</ref> Outer loop, update meta parameters <ref type="figure">Figure 1</ref>: Overview of the training of Meta-DMoE. We first sample disjoint support set x SU and query set (x Q , y Q ) from a training domain. x SU is sent to the expert models M to query their domain-specific knowledge. An aggregator A(?; ?) then combines the information and generates a supervision signal to update the f (?; ?) via knowledge distillation. The updated f (?; ? ) is evaluated using the labeled query set to update the meta-parameters. input distribution p x which provides useful information about p y|x . Based on the assumption, an unsupervised test-time adaptation <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b26">27]</ref> is proposed. The fundamental concept is to adapt the model to the specific domain using x. Overall, ARM aims to minimize the following objective L(?, ?) over all training domains:</p><formula xml:id="formula_3">D S j ?D S (x,y)?D S j L(y, f (x; ? )), where ? = h(x, ?; ?).<label>(1)</label></formula><p>y is the labels for x. f (x; ?) denotes the prediction model parameterized by ?. h(?; ?) is an adaptation function parameterized by ?. It receives the original ? of f and the unlabeled data x to adapt ? to ? .</p><p>The goal of ARM is to learn both (?, ?). To mimic the test-time adaptation (i.e., adapt before prediction), it follows the episodic learning as in meta-learning <ref type="bibr" target="#b24">[25]</ref>. Specifically, each episode processes a domain by performing unsupervised adaptation using x and h(?; ?) in the inner loop to obtain f (?; ? ). The outer loop evaluates the adapted f (?; ? ) using the true label to perform a meta-update. ARM is a general framework that can be incorporated with existing meta-learning approaches with different forms of adaptation module h(?; ?) <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b26">27]</ref>.</p><p>However, several shortcomings are observed with respect to the generalization. The episodic learning processes one domain at a time, which has clear boundaries among the domains. The overall setting is equivalent to the multi-source domain setting, which is proven to be more effective than learning from a single domain <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b87">88]</ref> as most of the domains are correlated to each other <ref type="bibr" target="#b1">[2]</ref>. However, it is counterintuitive to learn all the domain knowledge in one single model as each domain has specialized semantics or low-level features <ref type="bibr" target="#b63">[64]</ref>. Therefore, the single-model method in ARM is sub-optimal due to: 1) some domains may contain competitive information, which leads to negative knowledge transfer <ref type="bibr" target="#b65">[66]</ref>. It may tend to learn the ambiguous feature representations instead of capturing all the domain-specific information <ref type="bibr" target="#b79">[80]</ref>; 2) not all the domains are equally important <ref type="bibr" target="#b75">[76]</ref>, and the learning might be biased as data in different domains are imbalanced in real-world applications <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proposed approach</head><p>In this section, we explicitly formulate the test-time adaptation as a knowledge transfer process to distill the knowledge from MoE. The proposed method is learned via meta-learning to mimic the test-time out-of-distribution scenarios and ensure positive knowledge transfer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Meta-distillation from mixture-of-experts</head><p>Overview. <ref type="figure">Fig. 1</ref> shows the method overview. We wish to explicitly transfer useful knowledge from various source domains to achieve generalization on unseen target domains. Concretely, we define MoE as M = {M i } N i=1 to represent the domain-specific models. Each M i is separately trained using standard supervised learning on the source domain D S i to learn its discriminative features. We propose the test-time adaptation as the unsupervised knowledge distillation <ref type="bibr" target="#b33">[34]</ref> to learn the knowledge from MoE. Therefore, we treat M as the teacher and aim to distill its knowledge to a student prediction network f (?; ?) to achieve adaptation. To do so, we sample a batch of unlabeled x from a target domain, and pass it to M to query their domain-specific knowledge {M i (x)} N i=1 . That knowledge is then forwarded to a knowledge aggregator A(?; ?). The aggregator is learned to capture the interconnection among domain knowledge aggregate information from MoE. The output of A(?; ?) is treated as the supervision signal to update f (x; ?). Once the adapted ? is obtained, f (?; ? ) is used to make predictions for the rest of the data in that domain. The overall framework follows the effective few-shot learning where x is treated as unlabeled support set <ref type="bibr" target="#b73">[74,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b24">25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Training for Meta-DMoE</head><p>Require: </p><formula xml:id="formula_4">{D S i } N i=1 : data</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10:</head><p>Sample support and query set:</p><formula xml:id="formula_5">(x SU ), (x Q , y Q ) ? D S b 11: M e (x SU ; ?) = {M i e (x SU ; ?)} N i=1 , mask M i e (x SU ; ?) with 0 if b = i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12:</head><p>Perform adaptation via knowledge distillation from MoE: <ref type="bibr" target="#b12">13</ref>:</p><formula xml:id="formula_6">? e = ?e ? ?? ?e A(M e (x SU ; ?)) ? f (x SU ; ?e) 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14:</head><p>Evaluate the adapted ? e using query set and accumulate the loss: <ref type="bibr" target="#b14">15</ref>:</p><formula xml:id="formula_7">L B = L B + L CE (y Q , f (x Q ; ? e , ?c))</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>16:</head><p>end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>17:</head><p>Update ?, ?e, ?c for the current meta batch: 18:</p><formula xml:id="formula_8">(?, ?e, ?c) ? (?, ?e, ?c) ? ?? (?,?e ,?c ) L B</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>19: end while</head><p>Training Meta-DMoE. Properly training (?, ?) is critical to improve the generalization on unseen domains. In our framework, A(?, ?) acts as a mechanism that explores and mixes the knowledge from multiple source domains. Conventional knowledge distillation process requires large numbers of data samples and learning iterations <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b1">2]</ref>. The repetitive large-scale training is inapplicable in real-world applications. To mitigate the aforementioned challenges, we follow the metalearning paradigm <ref type="bibr" target="#b24">[25]</ref>. Such bilevel optimization enforces the A(?, ?) to learn beyond any specific knowledge <ref type="bibr" target="#b85">[86]</ref> and allows the student prediction network f (?; ?) to achieve fast adaptation. Specifically, We first split the data samples in each source domain D S i into disjoint support and query sets. The unlabeled support set (x SU ) is used to perform adaptation via knowledge distillation, while the labeled query set (x Q , y Q ) is used to evaluate the adapted parameters to explicitly test the generalization on unseen data.</p><p>The student prediction network f (?; ?) can be decoupled as a feature extractor ? e and classifier ? c . Unsupervised knowledge distillation can be achieved via the softened output <ref type="bibr" target="#b33">[34]</ref> or intermediate features <ref type="bibr" target="#b83">[84]</ref> from M. The former one allows the whole student network ? = (? e , ? c ) to be adaptive, while the latter one allows partial or complete ? e to adapt to x, depending on the features utilized. We follow <ref type="bibr" target="#b55">[56]</ref> to only adapt ? e in the inner loop while keeping the ? c fixed. Thus, the adaptation process is achieved by distilling the knowledge via the aggregated features:</p><formula xml:id="formula_9">DIST (x SU , M e , ?, ? e ) = ? e = ? e ? ?? ?e A(M e (x SU ); ?) ? f (x SU ; ? e ) 2 ,<label>(2)</label></formula><p>where ? denotes the adaptation learning rate, M e is the feature extractor of MoE models which extracts the features before the classifier, and ? 2 measures the L 2 distance. The goal is to obtain an updated ? e such that the extracted features of f (x SU ; ? e ) is closer to the aggregated features. The overall learning objective of Meta-DMoE is to minimize the following expected loss:</p><formula xml:id="formula_10">arg min ?e,?c,? D S j ?D S (x SU )?D S j (x Q ,y Q )?D S j L CE (y Q , f (x Q ; ? e , ? c )), where ? e = DIST (x SU , M e , ?, ? e ),<label>(3)</label></formula><p>where L CE is the cross-entropy loss. Alg. 1 demonstrates our full training procedure. To smooth the meta gradient and stabilize the training, we process a batch of episodes before each meta-update.</p><p>Since the training domains overlap for the MoE and meta-training, we simulate the test-time out-ofdistribution by excluding the corresponding expert model in each episode. To do so, we multiply the features by 0 to mask them out. M e in L11 of Alg. 1 denotes such operation. Therefore, the adaptation is enforced to use the knowledge that is aggregated from other domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Fully learned explicit knowledge aggregator</head><p>Aggregating the knowledge from distinct domains requires capturing the relation among them to ensure the relevant knowledge transfer. Prior works design hand-engineered solutions to combine the knowledge or choose data samples that are closer to the target domain for knowledge transfer <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b88">89]</ref>. A superior alternative is to replace the hand-designed pipelines with fully learned solutions <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b8">9]</ref>. Thus we follow the same trend and allow the aggregator A(?; ?) to be fully meta-learned without heavy hand-engineering.</p><p>We observe that the self-attention mechanism is quite suitable where interaction among domain knowledge can be computed. Therefore, we use a transformer encoder as the aggregator <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b72">73]</ref>. The encoder consists of multi-head self-attention and multi-layer perceptron blocks with layernorm <ref type="bibr" target="#b3">[4]</ref> applied before each block, and residual connection applied after each block. We refer the readers to the appendix for the detailed architecture and computation. We concatenate the output features from the MoE models as</p><formula xml:id="formula_11">Concat[M 1 e (x), M 2 e (x), ..., M N e (x)] ? R N ?d , where d is the feature dimension.</formula><p>The aggregator A(?; ?) processes the input tensor to obtain the aggregated feature F ? R d , which is used as a supervision signal for test-time adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">More constrained real-world settings</head><p>In this section, we investigate two critical settings for real-world applications that have drawn less attention from the prior works: limitation on computational resources and data privacy.</p><p>Constraint on computational cost. In real-world deployment environments, the computational power might be highly constrained (e.g., smartphones). It requires fast inference and compact models. However, the reduction in learning capabilities greatly hinders the generalization as some methods utilize only a single model regardless of the data complexity. On the other hand, when the number of domain data scales up, methods relying on adaptation on every data sample <ref type="bibr" target="#b86">[87]</ref> will experience inefficiency. In contrast, our method only needs to perform adaptation once for every unseen domain.</p><p>Only the final f (?; ? ) is used for inference. To investigate the impact on generalization caused by reducing the model size, we experiment with some lightweight network architectures (only f (?; ?) for us) such as MobileNet V2 <ref type="bibr" target="#b60">[61]</ref>.</p><p>Data privacy. Large-scale training data are normally collected from various venues. However, some venues may have privacy regulations enforced. Their data might not be accessible but the models that are trained using private data are available. To simulate such an environment, we split the training source domains into two splits: private domains (D S pri ) and public domains (D S pub ). We use D S pri to train MoE models and D S pub for the subsequent meta-training. Since ARM and other methods only utilize the data as input, we train them on D S pub .</p><p>We conduct experiments to show the superiority of the proposed method in these more constrained real-world settings with computation and data privacy issues. For details on the settings, please refer to the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiements</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and implementation details</head><p>Datasets and evaluation metrics. In this work, we mainly evaluate our method on the real-world domain shift scenarios. Drastic variation in deployment conditions normally exists in nature, such as a change in illumination, background, and time. It shows a huge domain gap between deployment environments and imposes challenges to the algorithm's robustness. Thus, we test our methods on the large-scale distribution shift benchmark WILDS <ref type="bibr" target="#b38">[39]</ref>, which reflects a diverse range of realworld distribution shifts. Following <ref type="bibr" target="#b86">[87]</ref>, we mainly perform experiments on five image testbeds, iWildCam <ref type="bibr" target="#b9">[10]</ref>, Camelyon17 <ref type="bibr" target="#b6">[7]</ref>,RxRx1 <ref type="bibr" target="#b68">[69]</ref> and FMoW <ref type="bibr" target="#b17">[18]</ref> and PovertyMap <ref type="bibr" target="#b82">[83]</ref>. In each benchmark dataset, a domain represents a distribution of data that is similar in some way, such as images collected from the same camera trap or satellite images taken in the same location. We follow the same evaluation metrics as in <ref type="bibr" target="#b38">[39]</ref> to compute severl metrics: accuracy, Macro F1, worst-case (WC) accuracy, Pearson correlation (r), and its worst-case counterpart. We also evaluate our method on popular benchmarks DomainNet <ref type="bibr" target="#b57">[58]</ref> and PACS <ref type="bibr" target="#b43">[44]</ref> from DomainBed <ref type="bibr" target="#b30">[31]</ref> by computing the accuracy.</p><p>Network architecture. We follow WILDS <ref type="bibr" target="#b38">[39]</ref> to use ResNet18 &amp; 50 <ref type="bibr" target="#b31">[32]</ref> or DenseNet101 <ref type="bibr" target="#b35">[36]</ref> for the expert models {M i } N i=1 and student network f (?, ; ?). Also, we use a single-layer transformer encoder block <ref type="bibr" target="#b72">[73]</ref> as the knowledge aggregator A(?; ?). To investigate the resource-constrained and privacy-sensitive scenarios, we utilize MobileNet V2 <ref type="bibr" target="#b60">[61]</ref> with a width multiplier of 0.25. As for DomainNet and PACS, we follow the setting in DomainBed to use ResNet50 for both experts and student networks.</p><p>Pre-training domain-specific models. The WILDS benchmark is highly imbalanced in data size, and some classes have empty input data se. We found that using every single domain to train an expert is unstable, and sometimes it cannot converge. Inspired by <ref type="bibr" target="#b51">[52]</ref>, we propose to cluster the training domains into N super domains and use each super-domain to train the expert models. Specifically, we set N = {10, 5, 3, 4, 3} for iWildCam, Camelyon17, RxRx1, FMoW and Poverty Map, respectively. We use ImageNet <ref type="bibr" target="#b20">[21]</ref> pre-trained model as the initialization and separately train the models using Adam optimizer <ref type="bibr" target="#b37">[38]</ref> with a learning rate of 1e ?4 and a decay of 0.96 per epoch.</p><p>Meta-training and testing. We first pre-train the aggregator and student network <ref type="bibr" target="#b14">[15]</ref>. After that, the model is further trained using Alg. 1 for 15 epochs with a fixed learning rate of 3e ?4 for ? and 3e ?5 for ?. During meta-testing, we use Line 13 of Alg. 1 to adapt before making a prediction for every testing domain. Specifically, we set the number of examples for adaptation at test time = {24, 64, 75, 64, 64} for iWildCam, Camelyon17, RxRx1, FMoW, and Poverty Map, respectively. For both meta-training and testing, we perform one gradient update for adaptation on the unseen target domain. We refer the readers to the supplementary materials for more detailed information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Main results</head><p>Comparison on WILDS. We compare the proposed method with prior approaches showing on WILDS leaderboard <ref type="bibr" target="#b38">[39]</ref>, including non-adaptive methods: CORAL <ref type="bibr" target="#b66">[67]</ref>, ERM <ref type="bibr" target="#b71">[72]</ref>, IRM <ref type="bibr" target="#b2">[3]</ref>, Group DRO <ref type="bibr" target="#b59">[60]</ref> and adaptive methods used in ARM <ref type="bibr" target="#b86">[87]</ref> (CML, BN and LL). We directly copy the available results from the leaderboard or their corresponding paper. As for the missing ones, we conduct experiments using their provided source code with default hyperparameters. <ref type="table" target="#tab_1">Table 1</ref> reports the comparison with the state-of-the-art. Our proposed method performs well across all datasets and increases both worst-case and average accuracy compared to other methods. Our proposed method achieves the best performance on 4 out of 5 benchmark datasets. ARM <ref type="bibr" target="#b86">[87]</ref> applies meta-learning approach to learn how to adapt to unseen domains with unlabeled data. However, their method is greatly bounded by using a single model to exploit knowledge from multiple source domains. Instead, our proposed method is more fitted to multi-source domain settings and meta-trains an aggregator that properly mixtures the knowledge from multiple domain-specific experts. As a result, our method outperforms ARM-CML, BN and LL by 9.5%, 9.8%, 8.1% for iWildCam, 8.5%, 4.8%, 8.5% for Camelyon17 and 14.8%, 25.0%, 22.9% for FMoW in terms of average accuracy. Furthermore, we also evaluate our method without masking the in-distribution domain in MoE models (Ours w/o mask) during meta-training (Line 10-11 of Alg. 1), where the sampled domain is overlapped with MoE. It violates the generalization to unseen target domains during testing. As most of the performance dropped, it reflects the importance of aligning the training and evaluation objectives.  Comparison on DomainNet and PACS. <ref type="table" target="#tab_2">Table 2</ref> and <ref type="table" target="#tab_3">Table 3</ref> report the results on DomainNet and PACS. In DomainNet, our method performs the best on all experimental settings and outperforms recent SOTA significantly in terms of the average accuracy (+2.7). <ref type="bibr" target="#b81">[82]</ref> has discovered that the lack of a large number of meta-training episodes leads to the meta-level overfitting/memorization problem. To our task, since PACS has 57? less number of images than DomainNet and 80? less number of domains than iWildCam, the capability of our meta-learning-based method is hampered by the less diversity of episodes. As a result, we outperform other methods in 2 out of 4 experiments but still achieve the SOTA in terms of average accuracy.</p><p>Visualization of adapted features. To evaluate the capability of adaptation via learning discriminative representations on unseen target domains, we compare the t-SNE <ref type="bibr" target="#b70">[71]</ref> feature visualization using the same test domain sampled from iWildCam and Camelyon17 datasets. ERM utilizes a single model and standard supervised training without adaptation. Therefore, we set it as the baseline. <ref type="figure" target="#fig_0">Figure 2</ref> shows the comparison, where each color denotes a class and each point represents a data sample. It is clear that our method obtains better clustered and more discriminative features. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results under constrained real-world settings</head><p>In this section, we mainly conduct experiments on iWildCam dataset under two real-world settings. Constraint on computational cost. Computational power is always limited in real-world deployment scenarios, such as edge devices. Efficiency and adaptation ability should be both considered. Thus, we replace our student model and the models in other methods with MobileNet V2. As reported in <ref type="table" target="#tab_4">Table 4</ref>, our proposed method still outperforms prior methods. Since the MoE model is only used for knowledge transfer, our method is more flexible in designing the student architecture for different scenarios. We also report multiply-Accumulate operations (MACS) for inference and time complexity on adaptation. As ARM needs to make adaptations before inference on every example, its adaptation cost scales linearly with the number of examples. Our proposed method performs better in accuracy and requires much less computational cost for adaptation, as reported in <ref type="table" target="#tab_5">Table 5</ref>.   Constraint on data privacy. On top of computational limitations, privacy-regulated scenarios are common in the real world. It introduces new challenges as the raw data is inaccessible. Our method does not need to access the raw data but the trained models, which greatly mitigates such regulation. Thus, as shown in <ref type="table" target="#tab_6">Table 6</ref>, our method does not suffer from much performance degradation compared to other methods that require access to the private raw data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Ablation studies</head><p>In this section, we conduct ablation studies on iWildCam to analyze various components of the proposed method. We also seek to answer the two key questions: 1) Does the number of experts affect the capability of capturing knowledge from multi-source domains? 2) Is metalearning superior to standard supervised learning under the knowledge distillation framework?</p><p>Number of domain-specific experts. We investigate the impact of exploiting multiple experts to store domain-specific knowledge separately. Specifically, we keep the total number of data for experts pretraining fixed and report the results using a various number of expert models. The experiments in <ref type="table" target="#tab_7">Table 7</ref> validate the benefits of using more domain-specific experts.</p><p>Training scheme. To verify the effectiveness of meta-learning, we investigate three training schemes: random initialization, pre-train, and meta-train. To pre-train the aggregator, we add a classifier layer to its aggregated output and follow the standard supervised training scheme. For fair comparisons, we use the same testing scheme, including the number of updates and images for adaptation. <ref type="table" target="#tab_8">Table 8</ref> reports the results of different training scheme combinations. We observe that the randomly initialized student model struggles to learn with only a few-shot data. And the pre-trained aggregator brings weaker adaptation guidance to the student network as the aggregator is not learned to distill. In contrast, our bi-level optimization-based training scheme enforces the aggregator to choose more correlated knowledge from multiple experts to improve the adaptation of the student model. Therefore, the meta-learned aggregator is more optimal (row 1 vs. row 2). Furthermore, our meta-distillation training process simulates the adaptation in testing scenarios, which aligns with the training objective and evaluation protocol. Hence, for both meta-trained aggregator and student models, it gains additional improvement (row 3 vs. row 4).   Aggregator and distillation methods. <ref type="table" target="#tab_9">Table 9</ref> reports the effects of various aggregators including two hand-designed operators: Max and Average pooling, and two MLP-based methods: Weighted sum (MLP-WS) and Projector (MLP-P) (details are provided in the supplement). We found that the fully learned transformer-based aggregator is crucial for mixing domain-specific features. Another important design choice in our proposed framework is in the form of knowledge: distilling the teacher model's logits, intermediate features, or both. We show evaluation results of those three forms of knowledge in <ref type="table" target="#tab_1">Table 10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>We present Meta-DMoE, a framework for adaptation towards domain shift using unlabeled examples at test time. We formulate the adaptation as a knowledge distillation process and devise a meta-learning algorithm to guide the student network to fast adapt to unseen target domains via transferring the aggregated knowledge from multiple sources domain-specific models. We demonstrate that Meta-DMoE is state-of-the-art on four benchmarks. And it is competitive under two constrained real-world settings, including limited computational budget and data privacy consideration.</p><p>Limitations. As discussed in Section 5.4, Meta-DMoE can improve the capacity to capture complex knowledge from multi-source domains by increasing the number of experts. However, to compute the aggregated knowledge from domain-specific experts, every expert model needs to have one feed-forward pass. As a result, the computational cost of adaptation scales linearly with the number of experts. Furthermore, to add or remove any domain-specific expert, both the aggregator and the student network need to be re-trained. Thus, enabling a sparse-gated Meta-DMoE to encourage efficiency and scalability could be a valuable future direction, where a gating module determines a sparse combination of domain-specific experts to be used for each target domain.</p><p>Social impact. Tackling domain shift problems can have positive social impacts as it helps to elevate the model accuracy in real-world scenarios (e.g., healthcare and self-driving cars). In healthcare, domain shift occurs when a trained model is applied to patients in different hospitals. In this case, model performance might dramatically decrease, which leads to severe consequences. Tackling domain shifts helps to ensure that models can work well on new data, which can ultimately lead to better patient care. We believe our work is a small step toward the goal of adapting to domain shift.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Additional Ablation Studies</head><p>In this section, we provide three additional ablation studies and discussions to further analyze our proposed method. These ablation studies are conducted on the iWildCam dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Aggregator Methods</head><p>In <ref type="table" target="#tab_9">Table 9</ref>, we include several hand-designed aggregation operators: max-pooling, average-pooling, and two MLP-based learnable architectures. The two MLP-based learnable architectures work as follows.</p><p>MLP weighted sum (MLP-WS) takes the output features from the MoE models as input and produces the score for each expert. Then, we weigh those output features using the scores and sum them to obtain the final output for knowledge distillation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Excluding Overlapping Expert</head><p>As discussed in Section 4.1, we simulate the test-time out-of-distribution by excluding the corresponding expert model in each episode since the training domains overlap for the MoE and meta-training. If the corresponding expert model is not excluded during meta-training, the aggregator output might be dominated by the corresponding expert output, or even collapse into a domain classification problem from the perspective of the aggregator. This might hinder the generalization on OOD domains. The experiments in <ref type="table" target="#tab_1">Table 11</ref> also validate the benefits of using such an operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Expert Architecture</head><p>In this section, we analyze the effects of using a different expert architecture. <ref type="table" target="#tab_1">Table 12</ref> validates the benefits of using the knowledge aggregator and our proposed training algorithm. Our proposed method could perform robustly across different expert architectures.  During deployment, our method uses a small number of unlabelled images to adapt the student prediction network to the target domain. Increasing the number of images used for adaptation might give a better approximation of the marginal of the target domain. Thus, the performance in the target domains is also enhanced. The experiments in <ref type="table" target="#tab_1">Table 13</ref> validate the benefits of using more images for adaptation.  In this section, we discuss a problem setting where data privacy regulation is imposed. To achieve data diversity, large-scale labeled training data are normally collected from public venues (internet or among institutes) and stored in a server where i.i.d conditions can be satisfied to train a generic model by sampling mini-batches. However, in real-world applications, due to privacy-related regulations, some datasets cannot be shared among users or distributed edges. Such data can only be processed locally. Thus, they cannot be directly used for training a generalized model in most existing approaches <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b50">51]</ref>. In this work, we consider a more realistic deployment problem with privacy constraints imposed.</p><p>We illustrate the privacy-regulated test-time adaptation setting in <ref type="figure" target="#fig_2">Fig. 3</ref>. To simulate the privacyregulated scenario, we explicitly separate the distributed training source domains into two nonoverlapping sets of domains: D S pri for private domains and D S pub for public domains. Each domain within D S pri contains private data that can only be shared and accessed within that domain. Therefore, the data within D S pri can only be accessed locally in a distributed manner during training, and cannot be seen at test time. D S pub contains domains with only public data that has fewer restrictions and can be accessed from a centralized platform. Such splitting allows the use of D S pub to simulate D T at training to learn the interaction with D S pri . It is also possible for some algorithms to mix all D S pub and store them in a server to draw a mini-batch for every training iterations <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b2">3]</ref>, but such operation is not allowed for private data.</p><p>The ultimate goal under this privacy-regulated setting is to train a recognition model on domains D S pri and D S pub with the above privacy regulations applied. The model should perform well in the target domains D T without accessing either D S pri or D S pub .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Applying Meta-DMoE to Privacy Constrained Setting</head><p>Our proposed Meta-DMoE method is a natural solution to this setting. Concretely, for each private domain D S i,pri , we train an expert model M i e using only data from D S i,pri . After obtaining the domain-specific experts {M i e }, we perform the subsequent meta-training on D S pub to simulation OOD test-time adaptation. The training algorithm is identical to Alg. 1, except we don't mask any experts' output since the training domains for the MoEs and meta-training do not overlap. In this way, we can leverage the knowledge residing in D S pri without accessing the raw data but only the trained model on each domain during centralized meta-training. We also include the details of the experiments under this setting in Appendix D.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Details on Knowledge Aggregator</head><p>In this section, we discuss the detailed architecture and computation of the knowledge aggregator. We use a naive single-layer transformer encoder <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b21">22]</ref> to implement the aggregator. The transformer encoder consists of multi-head self-attention blocks (MSA) and multi-layer perceptron blocks (MLP) with layernorm (LN) <ref type="bibr" target="#b3">[4]</ref> applied before each block, and residual connection applied after each block. Formally, given the concatenated output features from the MoE models,</p><formula xml:id="formula_12">z 0 = Concat[M 1 e (x), M 2 e (x), ..., M N e (x)] ? R N ?d ,<label>(4)</label></formula><formula xml:id="formula_13">z 0 = M SA k (LN (z 0 )) + z 0 ,<label>(5)</label></formula><formula xml:id="formula_14">z out = M LP (LN (z 0 )) + z 0 ,<label>(6)</label></formula><p>where M SA k (?) is the MSA block with k heads and a head dimension of d k (typically set to d/k),</p><formula xml:id="formula_15">[q, k, v] = zW qkv W qkv ? R d?3?d k ,<label>(7)</label></formula><formula xml:id="formula_16">SA(z) = Sof tmax( qk T ? d k )v,<label>(8)</label></formula><formula xml:id="formula_17">M SA k (z) = Concat[SA 1 (z), ..., SA k (z)]W o W o ? R k?D k ?D .<label>(9)</label></formula><p>We finally average-pool the transformer encoder output z out ? R N ?d along the first dimension to obtain the final output. In the case when the dimensions of the features outputted by the aggregator and the student are different, we apply an additional MLP layer with layernorm on z out to reduce the dimensionality as desired.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional Experimental Details</head><p>We run all the experiments using a single NVIDIA V100 GPU. The official WILDS dataset contains training, validation, and testing domains which we use as source, validation target, and test target domains. The validation set in WILDS <ref type="bibr" target="#b38">[39]</ref> contains held-out domains with labeled data that are non-overlapping with training and testing domains. To be specific, we first use the training domains to pre-train expert models and meta-train the aggregator and the student prediction model and then use the validation set to tune the hyperparameters of meta-learning. At last, we evaluate our method with the test set. We include the official train/val/test domain split in the following subsections. We run each experiment and report the average as well as the unbiased standard deviation across three random seeds unless otherwise noted. In the following subsections, we provide the hyperparameters and training details for each dataset below. For all experiments, we select the hyperparameters settings using the validation split on the default evaluation metrics from WILDS. For both meta-training and testing, we perform one gradient update for adaptation on the unseen target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Details for Privacy Constrained Evaluation</head><p>We mainly perform experiments under privacy constrained setting on two subsets of WILDS for image recognition tasks, iWildCam and FMoW. To simulate the privacy constrained scenarios, we randomly select 100 domains from iWildCam training split as D S pri to train {M i e } M i=1 and the rest as D S pub to meta-train the knowledge aggregator and student network. As for FMoW, we randomly select data from 6 years as D S pri and the rest as D S pub . The domains are merged into 10 and 3 super-domains, respectively, as discussed in Section 5.1. Since ARM and other methods only utilize the data as input, we train them on only D S pub .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 IWildCam Details</head><p>IWildCam is a multi-class species classification dataset, where the input x is an RGB photo taken by a camera trap, the label y indicates one of 182 animal species, and the domain z is the ID of the camera trap. During training and testing, the input x is resized to 448 ? 448. The train/val/test set contains 243/32/48 domains, respectively.</p><p>Evaluation. Models are evaluated on the Macro-F1 score, which is the F1 score across all classes. According to <ref type="bibr" target="#b38">[39]</ref>, Macro-F1 score might better describe the performance on this dataset as the classes are highly imbalanced. We also report the average accuracy across all test images.</p><p>Training domain-specific model. For this dataset, we train 10 expert models where each expert is trained on a super-domain formed by 24-25 domains. The expert model is trained using a ResNet-50 model pretrained on ImageNet. We train the expert models for 12 epochs with a batch size of 16. We use Adam optimizer with a learning rate of 3e-5.</p><p>Meta-training and testing. We train the knowledge aggregator using a single-layer transformer encoder with 16 heads. The transformer encoder has an input and output dimension of 2048, and the inner layer has a dimension of 4096. We use ResNet-50 <ref type="bibr" target="#b31">[32]</ref> model for producing the results in <ref type="table" target="#tab_1">Table 1</ref>. We first train the aggregator and student network with ERM until convergence for faster convergence speed during meta-training. After that, the models are meta-trained using Alg. 1 with a learning rate of 3e-4 for ?, 3e-5 for ? s , 1e-6 for ? a using Adam optimizer, and decay of 0.98 per epoch. Note that we use a different meta learning rate, ? a and ? s respectively, for the knowledge aggregator and the student network as we found it more stable during meta training. In each episode, we first uniformly sample a domain, and then use 24 images in this domain for adaptation and use 16 images to query the loss for meta-update. We train the models for 15 epochs with early stopping on validation Macro-F1. During testing, we use 24 images to adapt the student model to each domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.3 Camelyon Details</head><p>This dataset contains 450,000 lymph node scan patches extracted from 50 whole-slide images (WSIs) with 10 WSIs from each of 5 hospitals. The task is to perform binary classification to predict whether a region of tissue contains tumor tissue. Under this task specification, the input x is a 96 by 96 scan patch, the label y indicates whether the central region of a patch contains tumor tissue, and the domain z identifies the hospital. The train/val/test set contains 30/10/10 WSIs, respectively.</p><p>Evaluation. Models are evaluated on the average accuracy across all test images.</p><p>Training domain-specific model. For this dataset, we train 5 expert models where each expert is trained on a super-domain formed by 6 WSIs since there are only 3 hospitals in the training split. The expert model is trained using a DenseNet-121 model from scratch. We train the expert models for 5 epochs with a batch size of 32. We use an Adam optimizer with a learning rate of 1e-3 and an L2 regularization of 1e-2.</p><p>Meta-training and testing. We train the knowledge aggregator using a single-layer transformer encoder with 16 heads. The knowledge aggregator has an input and output dimension of 1024, and the inner layer has a dimension of 2048. We use DenseNet-121 <ref type="bibr" target="#b35">[36]</ref> model for producing the results in <ref type="table" target="#tab_1">Table 1</ref>. We first train the aggregator until convergence, and the student network is trained from ImageNet pretrained. After that, the models are meta-trained using Alg. 1 with a learning rate of 1e-3 for ?, 1e-4 for ? s , 1e-3 for ? a using Adam optimizer and a decay of 0.98 per epoch for 10 epochs. In each episode, we first uniformly sample a WSI, and then use 64 images in this WSI for adaptation and use 32 images to query the loss for meta-update. The model is trained for 10 epochs with early stopping. During testing, we use 64 images to adapt the student model to each WSI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4 RxRx1 Details</head><p>The task is to predict 1 of 1,139 genetic treatments that cells received using fluorescent microscopy images of human cells. The input x is a 3-channel fluorescent microscopy image, the label y indicates which of the treatments the cells received, and the domain z identifies the experimental batch of the image. The train/val/test set contains 33/4/14 domains, respectively.</p><p>Evaluation. Models are evaluated on the average accuracy across all test images.</p><p>Training domain-specific model. For this dataset, we train 3 expert models where each expert is trained on a super-domain formed by 11 experiments. The expert model is trained using a ResNet-50 model pretrained from ImageNet. We train the expert models for 90 epochs with a batch size of 75. We use an Adam optimizer with a learning rate of 1e-4 and an L2 regularization of 1e-5. We follow <ref type="bibr" target="#b38">[39]</ref> to linearly increase the learning rate for the first 10 epochs and then decrease it using a cosine learning rate scheduler.</p><p>Meta-training and testing. We train the knowledge aggregator using a single-layer transformer encoder with 16 heads. The knowledge aggregator has an input and output dimension of 2048, and the inner layer has a dimension of 4096. We use the ResNet-50 model to produce the results in <ref type="table" target="#tab_1">Table 1</ref>. We first train the aggregator and student network with ERM until convergence. After that, the models are meta-trained using Alg. 1 with a learning rate of 1e-4 for ?, 1e-6 for ? s , 3e-6 for ? a using Adam optimizer and following the cosine learning rate schedule for 10 epochs. In each episode, we use 75 images from the same domain for adaptation and use 48 images to query the loss for meta-update. During testing, we use 75 images to adapt the student model to each domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.5 FMoW Details</head><p>FMoW is comprised of high-definition satellite images from over 200 countries based on the functional purpose of land in the image. The task is to predict the functional purpose of the land captured in the image out of 62 categories. The input x is an RBD satellite image resized to 224 ? 224, the label y indicates which of the categories that the land belongs to, and the domain z identifies both the continent and the year that the image was taken. The train/val/test set contains 55/15/15 domains, respectively.</p><p>Evaluation. Models are evaluated by the average accuracy and worst-case (WC) accuracy based on geographical regions.</p><p>Training domain-specific model. For this dataset, we train 4 expert models where each expert is trained on a super-domain formed by all the images in 2-3 years. The expert model is trained using a DenseNet-121 model pretrained from ImageNet. We train the expert models for 20 epochs with a batch size of 64. We use an Adam optimizer with a learning rate of 1e-4 and a decay of 0.96 per epoch.</p><p>Meta-training and testing. We train the knowledge aggregator using a single-layer transformer encoder with 16 heads. The knowledge aggregator has an input and output dimension of 1024, and the inner layer has a dimension of 2048. We use the DenseNet-121 model to produce the results in <ref type="table" target="#tab_1">Table 1</ref>. We first train the aggregator and student network with ERM until convergence. After that, the models are meta-trained using Alg. 1 with a learning rate of 1e-4 for ?, 1e-5 for ? s , 1e-6 for ? a using Adam optimizer and a decay of 0.96 per epoch. In each episode, we first uniformly sample a domain from {continent ? year}, and then use 64 images from this domain for adaptation and use 48 images to query the loss for meta-update. We train the models for 30 epochs with early stopping on validation WC accuracy. During testing, we use 64 images to adapt the student model to each domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.6 Poverty Details</head><p>The task is to predict the real-valued asset wealth index using a multispectral satellite image. The input x is an 8-channel satellite image resized to 224 ? 224, the label y is a real-valued asset wealth index of the captured location, and the domain z identifies both the country that the image was taken and whether the area is urban or rural. For this dataset, we use MSE Loss for training the domain-specific experts and meta-training. The train/val/test set contains 26-28/8-10/8-10 domains, respectively. The number of domains varies slightly from the fold to the fold for Poverty.</p><p>Evaluation. Models are evaluated by the Pearson correlation (r) and worst-case (WC) r based on urban/rural sub-populations. This dataset is split into 5 folds where each fold defines a different set of Out-of-Distribution (OOD) countries. The results are aggregated over 5 folds.</p><p>Training domain-specific model. For this dataset, we train 3 expert models where each expert is trained on a super-domain formed by 4-5 countries. The expert model is trained using a ResNet-18 model from scratch. We train the expert models for 70 epochs with a batch size of 64. We use an Adam optimizer with a learning rate of 1e-3 and a decay of 0.96 per epoch.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>t-SNE visualization of adapted features at test-time. We directly utilize features adapted to the same unseen target domains from ERM and our proposed method in Camelyon17 and WildCam datasets, respectively. Our resulting features show more discriminative decision boundaries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>For</head><label></label><figDesc>the MLP projector (MLP-P), the output features from the MoE are flattened at first (N ? D ? N D ? 1) and then fed into an MLP architecture (N D ? D, D ? D) to obtain the final output (D ? 1) for knowledge distillation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Left: Standard methods require sampling mini-batched data across domains and thus cannot utilize the locally-stored private data within each private domain. Right: Privacy-related algorithms can improve the adaptation results by transferring knowledge from the private data without access to the raw data. B Details on Privacy Constrained Setting B.1 Problem Definition</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison with the state-of-the-arts on the WILDS image testbeds and out-of-distribution setting. Metric means and standard deviations are reported across replicates. Our proposed method performs well across all problems and achieves the best results on 4 out of 5 datasets.</figDesc><table><row><cell></cell><cell cols="2">iWildCam</cell><cell>Camelyon17</cell><cell>RxRx1</cell><cell cols="2">FMoW</cell><cell cols="2">PovertyMap</cell></row><row><cell>Method</cell><cell>Acc</cell><cell>Macro F1</cell><cell>Acc</cell><cell>Acc</cell><cell>WC Acc</cell><cell>Avg Acc</cell><cell>WC Pearson r</cell><cell>Pearson r</cell></row><row><cell>ERM</cell><cell>71.6 (2.5)</cell><cell>31.0 (1.3)</cell><cell>70.3 (6.4)</cell><cell>29.9 (0.4)</cell><cell>32.3 (1.25)</cell><cell>53.0 (0.55)</cell><cell>0.45 (0.06)</cell><cell>0.78 (0.04)</cell></row><row><cell>CORAL</cell><cell>73.3 (4.3)</cell><cell>32.8 (0.1)</cell><cell>59.5 (7.7)</cell><cell>28.4 (0.3)</cell><cell>31.7 (1.24)</cell><cell>50.5 (0.36)</cell><cell>0.44 (0.06)</cell><cell>0.78 (0.05)</cell></row><row><cell>Group DRO</cell><cell>72.7 (2.1)</cell><cell>23.9 (2.0)</cell><cell>68.4 (7.3)</cell><cell>23.0 (0.3)</cell><cell>30.8 (0.81)</cell><cell>52.1 (0.5)</cell><cell>0.39 (0.06)</cell><cell>0.75 (0.07)</cell></row><row><cell>IRM</cell><cell>59.8 (3.7)</cell><cell>15.1 (4.9)</cell><cell>64.2 (8.1)</cell><cell>8.2 (1.1)</cell><cell>30.0 (1.37)</cell><cell>50.8 (0.13)</cell><cell>0.43 (0.07)</cell><cell>0.77 (0.05)</cell></row><row><cell>ARM-CML</cell><cell>70.5 (0.6)</cell><cell>28.6 (0.1)</cell><cell>84.2 (1.4)</cell><cell>17.3 (1.8)</cell><cell>27.2 (0.38)</cell><cell>45.7 (0.28)</cell><cell>0.37 (0.08)</cell><cell>0.75 (0.04)</cell></row><row><cell>ARM-BN</cell><cell>70.3 (2.4)</cell><cell>23.7 (2.7)</cell><cell>87.2 (0.9)</cell><cell>31.2 (0.1)</cell><cell>24.6 (0.04)</cell><cell>42.0 (0.21)</cell><cell>0.49 (0.21)</cell><cell>0.84 (0.05)</cell></row><row><cell>ARM-LL</cell><cell>71.4 (0.6)</cell><cell>27.4 (0.8)</cell><cell>84.2 (2.6)</cell><cell>24.3 (0.3)</cell><cell>22.1 (0.46)</cell><cell>42.7 (0.71)</cell><cell>0.41 (0.04)</cell><cell>0.76 (0.04)</cell></row><row><cell>Ours (w/o mask)</cell><cell>74.1 (0.4)</cell><cell>35.1 (0.9)</cell><cell>90.8 (1.3)</cell><cell>29.6 (0.5)</cell><cell>36.8 (1.01)</cell><cell>50.6 (0.20)</cell><cell>0.52 (0.04)</cell><cell>0.80 (0.03)</cell></row><row><cell>Ours</cell><cell>77.2 (0.3)</cell><cell>34.0 (0.6)</cell><cell>91.4 (1.5)</cell><cell>29.8 (0.4)</cell><cell>35.4 (0.58)</cell><cell>52.5 (0.18)</cell><cell>0.51 (0.04)</cell><cell>0.80 (0.03)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Evaluation on DomainNet. Our method performs the best on all experimental settings and outperforms recent SOTA significantly in terms of the average accuracy.</figDesc><table><row><cell>Method</cell><cell>clip</cell><cell>info</cell><cell>paint</cell><cell>quick</cell><cell>real</cell><cell>sketch</cell><cell>avg</cell></row><row><cell>ERM [72]</cell><cell>58.1 (0.3)</cell><cell>18.8 (0.3)</cell><cell>46.7 (0.3)</cell><cell>12.2 (0.4)</cell><cell>59.6 (0.1)</cell><cell>49.8 (0.4)</cell><cell>40.9</cell></row><row><cell>IRM [3]</cell><cell>48.5 (2.8)</cell><cell>15.0 (1.5)</cell><cell>38.3 (4.3)</cell><cell>10.9 (0.5)</cell><cell>48.2 (5.2)</cell><cell>42.3 (3.1)</cell><cell>33.9</cell></row><row><cell>Group DRO [60]</cell><cell>47.2 (0.5)</cell><cell>17.5 (0.4)</cell><cell>33.8 (0.5)</cell><cell>9.3 (0.3)</cell><cell>51.6 (0.4)</cell><cell>40.1 (0.6)</cell><cell>33.3</cell></row><row><cell>Mixup [77]</cell><cell>55.7 (0.3)</cell><cell>18.5 (0.5)</cell><cell>44.3 (0.5)</cell><cell>12.5 (0.4)</cell><cell>55.8 (0.3)</cell><cell>48.2 (0.5)</cell><cell>39.2</cell></row><row><cell>MLDG [43]</cell><cell>59.1 (0.2)</cell><cell>19.1 (0.3)</cell><cell>45.8 (0.7)</cell><cell>13.4 (0.3)</cell><cell>59.6 (0.2)</cell><cell>50.2 (0.4)</cell><cell>41.2</cell></row><row><cell>CORAL [67]</cell><cell>59.2 (0.1)</cell><cell>19.7 (0.2)</cell><cell>46.6 (0.3)</cell><cell>13.4 (0.4)</cell><cell>59.8 (0.2)</cell><cell>50.1 (0.6)</cell><cell>41.5</cell></row><row><cell>DANN [26]</cell><cell>53.1 (0.2)</cell><cell>18.3 (0.1)</cell><cell>44.2 (0.7)</cell><cell>11.8 (0.1)</cell><cell>55.5 (0.4)</cell><cell>46.8 (0.6)</cell><cell>38.3</cell></row><row><cell>MTL [11]</cell><cell>57.9 (0.5)</cell><cell>18.5 (0.4)</cell><cell>46.0 (0.1)</cell><cell>12.5 (0.1)</cell><cell>59.5 (0.3)</cell><cell>49.2 (0.1)</cell><cell>40.6</cell></row><row><cell>SegNet [55]</cell><cell>57.7 (0.3)</cell><cell>19.0 (0.2)</cell><cell>45.3 (0.3)</cell><cell>12.7 (0.5)</cell><cell>58.1 (0.5)</cell><cell>48.8 (0.2)</cell><cell>40.3</cell></row><row><cell>ARM [87]</cell><cell>49.7 (0.3)</cell><cell>16.3 (0.5)</cell><cell>40.9 (1.1)</cell><cell>9.4 (0.1)</cell><cell>53.4 (0.4)</cell><cell>43.5 (0.4)</cell><cell>35.5</cell></row><row><cell>Ours</cell><cell>63.5 (0.2)</cell><cell>21.4 (0.3)</cell><cell>51.3 (0.4)</cell><cell>14.3 (0.3)</cell><cell>62.3 (1.0)</cell><cell>52.4 (0.2)</cell><cell>44.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Evaluation on PACS. Our method outperforms other methods on 2 out of 4 experiments but still achieves the SOTA in terms of the average accuracy.</figDesc><table><row><cell>Method</cell><cell>art</cell><cell>cartoon</cell><cell>photo</cell><cell>sketch</cell><cell>avg</cell></row><row><cell>ERM [72]</cell><cell>84.7 (0.4)</cell><cell>80.8 (0.6)</cell><cell>97.2 (0.3)</cell><cell>79.3 (1.0)</cell><cell>85.5</cell></row><row><cell>CORAL [67]</cell><cell>88.3 (0.2)</cell><cell>80.0 (0.5)</cell><cell>97.5 (0.3)</cell><cell>78.8 (1.3)</cell><cell>86.2</cell></row><row><cell>Group DRO [60]</cell><cell>83.5 (0.9)</cell><cell>79.1 (0.6)</cell><cell>96.7 (0.3)</cell><cell>78.3 (2.0)</cell><cell>84.4</cell></row><row><cell>IRM [3]</cell><cell>84.8 (1.3)</cell><cell>76.4 (1.1)</cell><cell>96.7 (0.6)</cell><cell>76.1 (1.0)</cell><cell>83.5</cell></row><row><cell>ARM [87]</cell><cell>86.8 (0.6)</cell><cell>76.8 (0.5)</cell><cell>97.4 (0.3)</cell><cell>79.3 (1.2)</cell><cell>85.1</cell></row><row><cell>Ours</cell><cell>86.1 (0.2)</cell><cell>82.5 (0.5)</cell><cell>96.7 (0.4)</cell><cell>82.3 (1.4)</cell><cell>86.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison of WILDS testbeds using MobileNet V2. Reducing the model size hampers the learning capability. Our method shows a better trade-off as the knowledge is distilled from MoE.</figDesc><table><row><cell></cell><cell cols="2">iWildCam</cell><cell>Camelyon17</cell><cell>RxRx1</cell><cell cols="2">FMoW</cell><cell cols="2">PovertyMap</cell></row><row><cell>Method</cell><cell>Acc</cell><cell>Macro F1</cell><cell>Acc</cell><cell>Acc</cell><cell>WC Acc</cell><cell>Avg Acc</cell><cell>WC Pearson r</cell><cell>Pearson r</cell></row><row><cell>ERM</cell><cell>56.7 (0.7)</cell><cell>17.5 (1.2)</cell><cell>69.0 (8.8)</cell><cell>14.3 (0.2)</cell><cell>15.7 (0.68)</cell><cell>40.0 (0.11)</cell><cell>0.39 (0.05)</cell><cell>0.77 (0.04)</cell></row><row><cell>CORAL</cell><cell>61.5 (1.7)</cell><cell>17.6 (0.1)</cell><cell>75.9 (6.9)</cell><cell>12.6 (0.1)</cell><cell>22.7 (0.76)</cell><cell>31.0 (0.32)</cell><cell>0.44 (0.06)</cell><cell>0.79 (0.04)</cell></row><row><cell>ARM-CML</cell><cell>58.2 (0.8)</cell><cell>15.8 (0.6)</cell><cell>74.9 (4.6)</cell><cell>14.0 (1.4)</cell><cell>21.1 (0.33)</cell><cell>30.0 (0.13)</cell><cell>0.41 (0.05)</cell><cell>0.76 (0.03)</cell></row><row><cell>ARM-BN</cell><cell>54.8 (0.6)</cell><cell>13.8 (0.2)</cell><cell>85.6 (1.6)</cell><cell>14.9 (0.1)</cell><cell>17.9 (1.82)</cell><cell>29.0 (0.69)</cell><cell>0.42 (0.05)</cell><cell>0.76 (0.03)</cell></row><row><cell>ARM-LL</cell><cell>57.5 (0.5)</cell><cell>12.6 (0.8)</cell><cell>84.8 (1.7)</cell><cell>15.0 (0.2)</cell><cell>17.1 (0.22)</cell><cell>30.3 (0.54)</cell><cell>0.39 (0.07)</cell><cell>0.76 (0.02)</cell></row><row><cell>Ours</cell><cell>59.5 (0.7)</cell><cell>19.7 (0.5)</cell><cell>87.1 (2.3)</cell><cell>15.1 (0.4)</cell><cell>26.9 (0.67)</cell><cell>37.9 (0.31)</cell><cell>0.44 (0.04)</cell><cell>0.77 (0.03)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table><row><cell cols="3">Method Acc / Macro-F1 MACS Complexity</cell></row><row><cell>ERM</cell><cell>56.7 / 17.5 7.18 ?10 7</cell><cell>N/A</cell></row><row><cell cols="2">ARM-CML 58.2 / 15.8 7.73 ?10 7</cell><cell>O(n)</cell></row><row><cell>ARM-LL</cell><cell>57.5 / 12.6 7.18 ?10 7</cell><cell>O(n)</cell></row><row><cell>Ours</cell><cell>59.5 / 19.7 7.18 ?10 7</cell><cell>O(1)</cell></row></table><note>Adaptation efficiency evaluated on iWild- Cam using MobileNet V2. Our method not only outperforms prior methods but also keeps constant time complexity in test-time adaptation.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table><row><cell cols="4">Results on privacy-related regulation set-</cell></row><row><cell cols="4">ting evaluated on iWildCam and FMoW using Mo-</cell></row><row><cell cols="4">bileNet V2. Without privacy considered in the</cell></row><row><cell cols="4">design, prior methods can only exploit public data</cell></row><row><cell cols="4">and thus achieve far worse performance.</cell></row><row><cell></cell><cell cols="2">iWildCam</cell><cell>FMoW</cell></row><row><cell cols="4">Method Acc Macro-F1 WC Acc Acc</cell></row><row><cell>ERM</cell><cell cols="2">51.2 11.2</cell><cell>22.5 35.4</cell></row><row><cell cols="3">CORAL 50.2 11.1</cell><cell>18.1 25.4</cell></row><row><cell cols="2">ARM-CML 42.7</cell><cell>7.5</cell><cell>16.8 24.1</cell></row><row><cell cols="2">ARM-BN 46.9</cell><cell>8.7</cell><cell>14.2 22.2</cell></row><row><cell cols="2">ARM-LL 46.8</cell><cell>9.3</cell><cell>13.7 22.6</cell></row><row><cell>Ours</cell><cell cols="2">54.7 14.2</cell><cell>24.4 33.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 :</head><label>7</label><figDesc>Results on the number of domain-specific experts. More experts increase the learning capacity to better explore each source domain, thus, improving generalization.</figDesc><table><row><cell># of experts</cell><cell>2</cell><cell>5</cell><cell>7</cell><cell>10</cell></row><row><cell>Accuracy</cell><cell cols="4">70.4 74.1 76.4 77.2</cell></row><row><cell>Macro-F1</cell><cell cols="4">30.6 32.3 33.7 34.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table><row><cell cols="4">Evaluation of training schemes. Using</cell></row><row><cell cols="4">both meta-learned aggregator and student model</cell></row><row><cell cols="4">improves generalization as they are learned to-</cell></row><row><cell cols="2">wards test-time adaptation.</cell><cell></cell><cell></cell></row><row><cell cols="2">Train Scheme</cell><cell></cell><cell>Metrics</cell></row><row><cell cols="2">Aggregator Student</cell><cell cols="2">Acc Macro-F1</cell></row><row><cell>Pretrain</cell><cell>Random</cell><cell>6.2</cell><cell>0.1</cell></row><row><cell>Meta</cell><cell cols="2">Random 32.7</cell><cell>0.5</cell></row><row><cell>Pretrain</cell><cell>Meta</cell><cell>74.8</cell><cell>32.9</cell></row><row><cell>Meta</cell><cell>Meta</cell><cell>77.2</cell><cell>34.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 :</head><label>9</label><figDesc>Comparison between different aggregator methods. The transformer explores interconnection, which gives the best result.</figDesc><table><row><cell cols="4">Max Ave. MLP-WS MLP-P Trans.(ours)</cell></row><row><cell>Acc. 69.2 69.7</cell><cell>70.7</cell><cell>73.7</cell><cell>77.2</cell></row><row><cell>M-F1 29.2 25.0</cell><cell>32.8</cell><cell>32.7</cell><cell>34.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 :</head><label>10</label><figDesc>Comparison between different distillation methods. Distilling only the feature extractor yields the best generalization.</figDesc><table><row><cell cols="3">Logits Logits + Feat. Feat. (Ours)</cell></row><row><cell>Accuracy 72.1</cell><cell>73.1</cell><cell>77.2</cell></row><row><cell>Marco-F1 26.4</cell><cell>26.9</cell><cell>34.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 :</head><label>11</label><figDesc>Comparison using ID test split in iWildCam. The ID test split contains images from the same domains as the training set but on different days from the training images. The model trained without masks performs better than the model trained with masks under the ID test split but has lower accuracy and a comparable Macro-F1 than the model trained with masks in the OOD test split.</figDesc><table><row><cell>MoE Mask</cell><cell cols="4">ID Acc ID Macro-F1 OOD Acc OOD Macro-F1</cell></row><row><cell>Mask all except overlap</cell><cell>75.5</cell><cell>46.8</cell><cell>--</cell><cell>--</cell></row><row><cell>Without mask</cell><cell>76.4</cell><cell>48.0</cell><cell>74.1</cell><cell>35.1</cell></row><row><cell>With mask</cell><cell>72.9</cell><cell>44.4</cell><cell>77.2</cell><cell>34.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12 :</head><label>12</label><figDesc>Comparison with different expert architectures. Our proposed method is robust to different expert architectures with different capacities.</figDesc><table><row><cell cols="4">Expert architecture Student architecture Acc Macro-F1</cell></row><row><cell>MobileNet V2</cell><cell>MobileNet V2</cell><cell>59.5</cell><cell>19.7</cell></row><row><cell>ResNet-50</cell><cell>MobileNet V2</cell><cell>58.8</cell><cell>21.0</cell></row><row><cell cols="2">A.4 Number of Images Used for Test-Time Adaptation</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 13 :</head><label>13</label><figDesc>Results on the number of images for adaptation. Adaptation using more images leads to better approximations of the marginal and improves generalization.</figDesc><table><row><cell></cell><cell cols="2"># of images for adaptation</cell><cell>2</cell><cell>4</cell><cell>8</cell><cell>16</cell><cell>24</cell></row><row><cell></cell><cell>Accuracy</cell><cell></cell><cell cols="4">76.5 76.9 77.0 77.2 77.2</cell></row><row><cell></cell><cell>Macro-F1</cell><cell></cell><cell cols="4">31.5 31.2 31.7 33.0 34.0</cell></row><row><cell>Private domains</cell><cell>Public domains</cell><cell cols="2">Private domains</cell><cell></cell><cell></cell><cell>Public domains</cell></row><row><cell>X X X</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Private data</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Public data</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Training data</cell></row><row><cell cols="2">Training data</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Model</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Training</cell></row><row><cell>New domain</cell><cell>Training</cell><cell>New domain</cell><cell></cell><cell></cell><cell></cell><cell>Data Privacy</cell></row><row><cell>Adaptation</cell><cell>Deploy Deploy</cell><cell></cell><cell>Adaptation</cell><cell></cell><cell></cell><cell>Deploy</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2 Related work Domain shift. Unsupervised Domain Adaptation (UDA) has been popular to address domain shift by transferring the knowledge from the labeled source domain to the unlabeled target domain <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b80">81]</ref>. It is achieved by learning domain-invariant features via minimizing statistical discrepancy across</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Network of experts for large-scale image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karim</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Haris</forename><surname>Baig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Torresani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised multi-source domain adaptation without access to source data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sk Miraj Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dripta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujoy</forename><surname>Raychaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samet</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit K Roy-Chowdhury</forename><surname>Oymak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<title level="m">Invariant risk minimization</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Distribution-matching embedding for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahsa</forename><surname>Baktashmotlagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrtash</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2016" />
			<publisher>Article-number</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Metareg: Towards domain generalization using meta-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swami</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">From detection of individual metastases to classification of lymph node status at the patient level: the camelyon17 challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Geessink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quirine</forename><surname>Manson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcory</forename><surname>Van Dijk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maschenka</forename><surname>Balkenhol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meyke</forename><surname>Hermsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Babak</forename><forename type="middle">Ehteshami</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byungjae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Paeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aoxiao</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Improved few-shot visual classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyman</forename><surname>Bateni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghav</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaden</forename><surname>Masrani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning to continually learn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shawn</forename><surname>Beaulieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lapo</forename><surname>Frati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Miconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kenneth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Beery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elijah</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvi</forename><surname>Gjoka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.10340</idno>
		<title level="m">The iwildcam 2020 competition dataset</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Generalizing from several related classification tasks to a new unlabeled sample. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyemin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clayton</forename><surname>Scott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning to balance specificity and invariance for in and out of domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prithvijit</forename><surname>Chattopadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Gradient-based bi-level optimization for deep learning: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.11719</idno>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Bidirectional learning for offline infinite-width model-based optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Sam Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingxue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Coates</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2209.07507</idno>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Meta-baseline: exploring simple meta-learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinbo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huijuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Metafscil: A meta-learning approach for few-shot class incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixiang</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Test-time fast adaptation for dynamic scene deblurring via meta-auxiliary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixiang</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Functional map of the world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Christie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Fendley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mukherjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Ai-gas: Ai-generating algorithms, an alternate paradigm for producing general artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10985</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Emnist: Extending mnist to handwritten letters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Afshar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tapson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Van Schaik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.03961</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unsupervised visual domain adaptation using subspace alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basura</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amaury</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Sebban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Lachine Learning</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Saxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Eslami</surname></persName>
		</author>
		<title level="m">Conditional neural processes. In International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengjie</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hard mixtures of experts for large scale weakly supervised vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Improving protonet for few-shot video object recognition: Winner of orbit challenge 2022</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixiang</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2210.00174</idno>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">In search of lost domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Benchmarking neural network robustness to common corruptions and perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Does distributionally robust supervised learning give robust classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issei</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Adaptive mixtures of local experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Nowlan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="87" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Wilds: A benchmark of in-the-wild distribution shifts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Marklund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang</forename><forename type="middle">Michael</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Balsubramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">Lanas</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irena</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Domain impression: A source data free domain adaptation method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vinod K Kurmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vinay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Namboodiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on Applications of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Gshard: Scaling giant models with conditional computation and automatic sharding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyoukjoong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning to generalize: Meta-learning for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep domain generalization via conditional invariant adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Test-time personalization with a transformer for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhuo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonglin</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitesh</forename><surname>Bharadwaj Gundavarapu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="issue">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Selfsupervised spatiotemporal representation learning by exploiting video continuity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niamul</forename><surname>Quader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixiang</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juwei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dapeng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Few-shot classincremental learning via entropy-regularized data-free replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixiang</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.11213</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Conditional adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Orbit: A real-world few-shot dataset for teachable object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Massiceti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Zintgraf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bronskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lida</forename><surname>Theodorou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">Tobias</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Cutrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cecily</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katja</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Stumpf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Domain generalization using a mixture of multiple latent domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihiko</forename><surname>Matsuura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krikamol</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Reducing domain gap via style-agnostic networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonseob</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongchan</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonjun</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donggeun</forename><surname>Yoo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.11645</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Boil: Towards representation change for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehoon</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyungjun</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Se-Young</forename><surname>Yun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Multi-adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyi</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Moment matching for multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingchao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinxun</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xide</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Fast and flexible multi-task classification using conditional neural adaptive processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Requeima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bronskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Distributionally robust neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsunori</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Meta-learning with memory-augmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Generalizing across domains via cross-gradient training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Jyothi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Outrageously large neural networks: The sparsely-gated mixture-of-experts layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azalia</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Maziarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Which tasks should be learned together in multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Standley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baochen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Test-time training with self-supervision for generalization under distribution shifts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Rxrx1: An image set for cellular morphological variation across many experimental batches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Earnshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mabey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Victors</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yosinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Deep domain confusion: Maximizing for domain invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3474</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">An overview of statistical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Generalizing to unseen domains via adversarial data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riccardo</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongseok</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vittorio</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Domain aggregation networks for multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junfeng</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Greiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Adversarial domain adaptation with domain mixup</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Deep cocktail network: Multi-source unsupervised domain adaptation with category shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Curriculum manager for source selection in multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yogesh</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Generalized source-free domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiqi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shangling</forename><surname>Herranz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Meta-learning with fewer tasks through task interpolation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.02695</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Using publicly available satellite imagery and deep learning to understand economic well-being in africa</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Driscoll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Azzari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lobell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marshall</forename><surname>Burke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">A gift from knowledge distillation: Fast optimization, network minimization and transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junho</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donggyu</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihoon</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Few-shot incremental learning with continually evolved classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghui</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Few-shot incremental learning with continually evolved classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghui</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Adaptive risk minimization: Learning to adapt to domain shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Marklund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Dhawan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Adversarial multiple source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanhang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Jos?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><forename type="middle">P</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">J</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Multi-source distilling domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sicheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaxian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runbo</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Checklist 1. For all authors</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Do the main claims made in the abstract and introduction accurately reflect the paper&apos;s contributions and scope?</title>
		<imprint/>
	</monogr>
	<note>Yes] See Section 1</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
