<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">On Evolving Attention Towards Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kekai</forename><surname>Sheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Youtu Lab</orgName>
								<address>
									<region>Tencent</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Youtu Lab</orgName>
								<address>
									<region>Tencent</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiawu</forename><surname>Zheng</surname></persName>
							<email>zhengxiawu@stu.xmu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Xiamen University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Liang</surname></persName>
							<email>liangjian92@gmail.com</email>
							<affiliation key="aff2">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Dong</surname></persName>
							<email>weiming.dong@ia.ac.cn</email>
							<affiliation key="aff3">
								<orgName type="laboratory">NLPR</orgName>
								<address>
									<region>CASIA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyue</forename><surname>Huang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Youtu Lab</orgName>
								<address>
									<region>Tencent</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
							<email>rrji@xmu.edu.cn</email>
							<affiliation key="aff1">
								<orgName type="institution">Xiamen University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Youtu Lab</orgName>
								<address>
									<region>Tencent</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">On Evolving Attention Towards Domain Adaptation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Towards better unsupervised domain adaptation (UDA), recently, researchers propose various domain-conditioned attention modules and make promising progresses. However, considering that the configuration of attention, i.e., the type and the position of attention module, affects the performance significantly, it is more generalized to optimize the attention configuration automatically to be specialized for arbitrary UDA scenario. For the first time, this paper proposes EvoADA: a novel framework to evolve the attention configuration for a given UDA task without human intervention. In particular, we propose a novel search space containing diverse attention configurations. Then, to evaluate the attention configurations and make search procedure UDA-oriented (transferability + discrimination), we apply a simple and effective evaluation strategy: 1) training the network weights on two domains with off-the-shelf domain adaptation methods; 2) evolving the attention configurations under the guide of the discriminative ability on the target domain. Experiments on various kinds of cross-domain benchmarks, i.e., Office-31, Office-Home, CUB-Paintings, and Duke-Market-1510, reveal that the proposed EvoADA consistently boosts multiple state-of-the-art domain adaptation approaches, and the optimal attention configurations help them achieve better performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Unsupervised domain adaptation (UDA) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b41">42]</ref> aims at exploiting the meaningful knowledge from a labelled source domain to facilitate learning on another unlabelled target domain. Generally, researchers focus on learning domain-general features. For better performance in the target domain, researchers propose domain-conditioned spatial or channel attention mechanisms <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b24">25]</ref> to mitigate negative transfer and enhance the insufficient domain-specific features. However, these works design the attention module by hand and may fall to a sub-optimal solution in real world application. For example, in <ref type="figure" target="#fig_0">Figure 1</ref>, we observe that on a given UDA task and a pre-defined backbone network, different configurations of the attention module focus on various visual patterns and thus may come out with different accuracies. Therefore, given one arbitrary UDA task, a more generalized manner is to automatically find the optimal attention configuration. One natural and widely-used solution is neural architecture search (NAS) <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b18">19]</ref>. The goal of NAS is to automatically seek for effective architectures <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b25">26]</ref>. Nevertheless, <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b25">26]</ref> point out that existing NAS algorithms rarely consider the topic of transfer learning and are vulnerable to large domain shift, resulting in inferior performance for UDA tasks. We speculate the reasons as follows. The first challenge is the design of search space. Existing popular search spaces (e.g., NASNet <ref type="bibr" target="#b56">[57]</ref> or DARTS <ref type="bibr" target="#b30">[31]</ref> not specialized to refine the attention module and maybe ineffective in generating optimal architectures for domain adaptation. The second challenge is how to evaluate the searched architectures, which is an open question. In a conventional NAS setting, we have labelled data on both the training and validation partitions, which are assumed to have little domain shift <ref type="bibr" target="#b36">[37]</ref>. It means that the architectures optimized on the training domain can be directly evaluated on the validation domain with ground-truth labels. But in an UDA scenario, no manual annotations are available in the target domain, and the relatively larger domain shift between the source and the target domains make it ineffective to evaluate the models only on the source domain. In this paper, for the first time, we propose a novel NAS algorithm, termed EvoADA. It automatically searches attention configurations, i.e., the type and position of attention module, for different UDA scenarios. Specifically, different from existing search spaces <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b30">31]</ref> on the basic CNN operations, we design a novel search space on diverse configurations of typical attention modules <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b15">16]</ref>. To evaluate the attention configuration effectively and make the configuration optimization UDA-oriented, we further propose a simple yet effective evaluation strategy: train the network weights on both the two domains with arbitrary UDA methods to learn transferable knowledge and then evaluate the attention configurations by our pseudo-labeling discrimination in target domain to check how the learned knowledge are discriminative on target domain. We find that the estimated qualities are strongly correlates with the final accuracy in the target domain. Eventually, we propose a new UDA-oriented NAS scheme based on a typical evolutionbased NAS algorithm. Building on extensive experiments on 4 cross-domain benchmarks, we verify that the searched attention configuration via our EvoADA benefits multiple state-of-the-art methods <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b46">47]</ref> and lead to better performance in the target domain ( <ref type="figure" target="#fig_1">Figure 2</ref>). The experiments also provide practical insights for further research.</p><p>The main contributions are summarized as follows:</p><p>? We propose a new search space with a set of effective at-tention modules to cover diverse attention configurations and reinforce representations for UDA tasks.</p><p>? We propose a simple yet effective strategy to evaluate the UDA performance of attention configurations. Empirically, the measure of pseudo-labeling in the target domain is effective to seek for optimal attention configurations.</p><p>? Experiments on four benchmarks verify that our algorithm successfully consolidates various state-of-theart methods and largely promote their performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Unsupervised Domain Adaptation (UDA) <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b6">7]</ref> aims to facilitate the learning on one unlabelled target domain with the knowledge from one labelled source domain, and has practical value in many tasks <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b9">10]</ref>. There are three typical settings: closed-set UDA, partial-set UDA (PDA), and open-set UDA (ODA). Technically, two fundamental problems lie in the core of UDA: 1) how to diminish the domain discrepancy on representation spaces of two domains; 2) how to deal with negative transfer and promote discrimination on target domains. To solve the problems, researchers propose different methods that can be divided into three mainstreams: 1) feature disentanglement methods <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b24">25]</ref>; 2) domain alignment methods <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b31">32]</ref>; and 3) discrimination-aware methods <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b26">27]</ref>. More recently, novel loss designs (e.g., <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b41">42]</ref> for universal domain adaptation; <ref type="bibr" target="#b10">[11]</ref> for a progressive method) and advanced network modules (e.g., <ref type="bibr" target="#b47">[48]</ref> for normalization module; <ref type="bibr" target="#b50">[51]</ref> for convolution module; <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref> for attention module) are proposed for better domain adaptation performance. Different from TADA <ref type="bibr" target="#b49">[50]</ref>, CADA <ref type="bibr" target="#b23">[24]</ref>, and DCAN <ref type="bibr" target="#b24">[25]</ref> that combines a handcrafted attention module with an elaborate loss design, we solely investigate the improvement brought by an automatically searched attention module, which may benefit most of the state-of-theart UDA methods in a more flexible way.</p><p>Neural Architecture Search (NAS) aims to automate architecture engineering procedure given one certain problem. There are five NAS mainstreams: random search, Bayesian-based method <ref type="bibr" target="#b13">[14]</ref>, reinforcement-learning approach, evolutionary scheme <ref type="bibr" target="#b0">[1]</ref>, and surrogate-based framework (e.g., gradient-based and predictor-based). Representative approaches include DARTS <ref type="bibr" target="#b30">[31]</ref>, P-DARTS <ref type="bibr" target="#b7">[8]</ref>, AmoebaNet <ref type="bibr" target="#b37">[38]</ref>, one-shot NAS <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b18">19]</ref>, path-level NAS <ref type="bibr" target="#b2">[3]</ref>, NASNet <ref type="bibr" target="#b56">[57]</ref>, and AdaptNAS <ref type="bibr" target="#b25">[26]</ref>. Recently, NAS technique has found its value in wide tasks, such as detection <ref type="bibr" target="#b8">[9]</ref>, segmentation <ref type="bibr" target="#b28">[29]</ref>, and person re-ID <ref type="bibr" target="#b35">[36]</ref>. Different from the existing literature, in this paper, we investigate the possibility and an effective solution to search for optimal architectures towards better domain adaptation. Concurrently, we find that Li et al. <ref type="bibr" target="#b25">[26]</ref> and Robbiano et al. <ref type="bibr" target="#b39">[40]</ref> have investigated a similar topic: the generalization abilities of architectures cross domains. The differences are two-fold: 1) we propose a novel search space for diverse attention configurations, which is different from the search space of AdaptNAS <ref type="bibr" target="#b25">[26]</ref> (akin to NASNet <ref type="bibr" target="#b56">[57]</ref>) and ABAS <ref type="bibr" target="#b39">[40]</ref> (just change the architecture of the auxiliary adversarial branch); 2) we focus on an effective NAS protocol to search for optimal attention configuration towards UDA tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminary</head><p>Unsupervised Domain Adaptation. Formally, in one UDA task, we have a labeled dataset</p><formula xml:id="formula_0">{x S i , y S i } N S i=1 of N S image-annotation pairs from source domain S and an unla- beled dataset {x T i } N T i=1 of N T images from target domain T .</formula><p>Considering that the two domains S and T are semantically related, UDA aims to facilitate the learning on T by exploiting the meaningful knowledge learned from S and try to handle the challenges of large domain shift between source domain S and target domain T .</p><p>Neural Architecture Search. Given one certain task, its goal to search optimal network architectures automatically. Without loss of generality, we formulate the search procedure in a bi-level optimization process:</p><formula xml:id="formula_1">? = arg min ??A L val (y, F (x; ?, ? * (?))), s.t., ? * (?) = arg min ? L tr (y, F (x; ?, ?)),<label>(1)</label></formula><p>where ? is the architecture parameter, A denotes the search space that contains all possible architectures, ? is the network weights, and F (; ?, ?) is the function of neural network. In Eq. (1), we optimize ? with one certain loss or evaluation function on validation partition L val under the constraint that its weight parameter ? * (?) is optimal for another loss function on training dataset L tr . Researchers propose several effective NAS algorithms <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b30">31]</ref> to seek for optimal architectures ? among A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">EvoADA</head><p>Our goal is to investigate a more generalized UDA framework from the perspective of attention mechanism: automatically optimizing the configuration of attention in backbone networks for one arbitrary UDA scenario. To this end, we propose a new UDA-oriented NAS scheme, termed EvoADA, which searches the optimal attention in the attention configuration search space by employing our search algorithm and evaluation method. The overall illustration of the proposed method is shown in <ref type="figure">Figure 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search Space for Diverse Attention Configuration. Inspired by recent domain-conditioned attention mechanisms</head><p>The initial backbone</p><p>The backbone with optimal attention configuration  <ref type="figure">Figure 3</ref>. The pipeline of the proposed evolutionary framework to seek for optimal attention configurations towards domain adaptation. Given an pre-defined backbone, we sample several possible attention configurations from our search space, and then conduct an UDA-oriented performance estimation: train the network weights on the two domains with arbitrary domain adaptation method to learn transferable knowledge and evaluate the pseudolabel discrimination on target domain. <ref type="table">Table 1</ref>. The basic element to make up various attention modules.</p><p>The element can also be easily extended with other kinds of attention operations for practical usages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention Module</head><p>Module Attention on Parameter spatial position channel Choices SE <ref type="bibr" target="#b20">[21]</ref> ? #channel GSoP <ref type="bibr" target="#b15">[16]</ref> ? ? #channel CBAM <ref type="bibr" target="#b51">[52]</ref> ? ? #channel Identity 1 Group Strategy Group <ref type="bibr" target="#b48">[49]</ref> ? #group in UDA tasks <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b50">51]</ref>, we propose a novel and effective search space that consists of diverse attention configurations, we define our search space in two aspects: the type and the position of attention module. Type. Based on the function, there are two basic types of attention: spatial type and channel type, where spatial attention aims to exploit spatial interdependence and the channel one aims to make use of channel interdependence. When it comes to the choice of its parameter, there are two extra hyper-parameters, #channel and #group, where the #channel and the #group denote the number of channels and groups of intermediate features within attention layers. To produce a diverse search space towards UDA problems, we summarize the types and parameter choices of the widely-used attention modules in <ref type="table">Table 1</ref> and make up various types of attention modules with these basic elements. On sampling one type of attention, the procedure is: i) choose among 4 kinds of basic types (SE <ref type="bibr" target="#b20">[21]</ref>, GSoP <ref type="bibr" target="#b15">[16]</ref>, and CBAM [52]) or Identity; ii) when we select the first 3 modules, we have two additional choices to make: #channel and #group. In our implementation, #channel is 4 ({256, 512, 1024, 2048}) and #group is 4 ({1, 2, 4, 8}). Thus, the number of possible attention modules is (3 ? 4 ? 4 + 1). It should be noticed that the diversity and completeness of <ref type="table">Table 1</ref> works well to produce optimal attention configurations for UDA scenarios, as validated later in Section 4.</p><p>Position. We also need to consider the position in a backbone network to introduce attention modules, since features from different intermediate layers have different transferability <ref type="bibr" target="#b53">[54]</ref>. Suppose there are L intermediate layers in the backbone network (e.g., L = 50 in ResNet-50 <ref type="bibr" target="#b19">[20]</ref>), we then have L possible position choices. Given that low-level features generally have better transferability, we choose the deeper L/2 layers to cut-off unnecessary attempts. For the shallower L/2 layers, we apply weight sharing strategy on the backbone, akin to one-shot NAS algorithms <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b18">19]</ref>. To further simplify the search space, on each intermediate layer within the backbone, we only select one attention module, instead of applying parallel block design.</p><p>Overall complexity. Put the type and the position together, we then formulate the attention configuration parameter ? as: ? = [? 1 , ? 2 , ? ? ? ? L/2 ]. ? i indicates the attention configuration on layer i of the backbone network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The overall complexity of our search space</head><formula xml:id="formula_2">A is |? i | L/2 = (3 ? 4 ? 4 + 1) 25 = 49 25 ? 1 ? 10 42 .</formula><p>UDA-oriented Evaluation Strategy. Considering that the core of the UDA task (transferability and discrimination), we train the network weights with a certain attention configuration ?(?) on the two domains to learn transferable representation and evaluate the discrimination of the models on target domain, which in our case is mainly determined by the attention configuration ?. Formally, we re-write the typical NAS formulation Eq. (1) as follows:</p><formula xml:id="formula_3">? = arg min ??A ?L P E T (F (x; ?, ? * (?))), s.t., ? * (?) = arg min ? L DA S+T (y, F (x; ?, ?)),<label>(2)</label></formula><p>where L DA S+T denotes one certain loss function for the domain adaptation task from S to T (e.g., CDAN <ref type="bibr" target="#b31">[32]</ref> or SHOT <ref type="bibr" target="#b26">[27]</ref>); L P E T is the evaluation function to measure the discrimination of models in target domain and based on the information maximization loss <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22]</ref>, we propose a pseudo-label discrimination term to measure the desirable properties of ideal representations on target domain:</p><formula xml:id="formula_4">L P E T = L ent T + L div T + L pse T ,<label>(3)</label></formula><p>where L ent T is the information entropy of each output prediction on target domain, L div T is to measure the diversity of output predictions on target domain (e.g., the negative information entropy of the average output predictions), and L pse T is the cross-entropy based on pseudo-labels? via existing self-training methods (e.g., DeepCluster <ref type="bibr" target="#b5">[6]</ref>). For the detailed implementation, please refer to the supplementary. Overall Search Algorithm. To make the architecture optimization effective, we integrate the search space and the performance evaluation with an evolutionary algorithm <ref type="bibr" target="#b0">[1]</ref> and propose our EvoADA (elaborated in Algorithm 1):</p><formula xml:id="formula_5">Algorithm 1: EvoADA Data: {x S i , y S i } N S i=1 , {x T i } N T i=1 ,</formula><p>? Sample Seed. We sample K possible attention configurations of ? as initial seeds, initialize weights of the backbone on ImageNet, randomly initialize the weights of introduced attention modules, and assign each seed with different random seed numbers (e.g., random(seed)) to reduce uncertainty in training procedure.</p><p>? Inference.With initialized seeds, we then run several training epochs in each population in a parallel way, update their network weights, and evaluate their UDA performance L P E T in the target domain.</p><p>? Crossover and Mutation. We conduct crossover to get even better performance in the next generation. On those poor ones, we perform two mutation strategies to explore for better seeds: 1) drop the seed and initialize another one randomly; 2) change ? by introducing another attention module or shifting to different layers.</p><p>? Update and Early Stop. To promote training efficiency and mitigate the discord between the estimated performance and the final UDA performance, we adopt several early-stopping criteria: i) when the accuracy in source domain is higher than tr acc (e.g., 0.95), it generally indicates the model may suffer from negative transfer; ii) when the seed finishes T evolution iterations; iii) when pseudo-label accuracy in target domain keeps being poor for over T d (e.g., 5 in our implementation) iterations.</p><p>We end up with several populations that contain optimal attention configurations. To report the final performance, we re-train the optimal architectures on the two domains from scratch with one certain domain adaptation approaches. It should be noticed that we can also apply other architecture search algorithms, such as neural networkbased reinforcement learning NAS <ref type="bibr" target="#b56">[57]</ref>. Thanks to the flexibility of evolution-based NAS scheme, the proposed EvoADA can be easily applied on arbitrary domain adaptation methods and is compatible with two typical training modes of existing UDA methods: 1) single-stage mode trains on two domains simultaneously (e.g., <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b46">47]</ref>); 2) two-stage mode trains first in the source domain and then in the target domain (e.g., <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b16">17]</ref>).</p><p>Differences from Concurrent Methods. Concurrently, Liet al. <ref type="bibr" target="#b25">[26]</ref> and Robbianoet al. <ref type="bibr" target="#b39">[40]</ref> also propose to seek for better transferable network architectures. The differences between our EvoADA and them are: 1) on the design of search space: AdaptNAS <ref type="bibr" target="#b25">[26]</ref> adopted the search space of NASNet <ref type="bibr" target="#b56">[57]</ref> that includes basic operations in CNNs (e.g., different pooling or convolution operations) and seeks for optimal structures in a cell perspective, ABAS <ref type="bibr" target="#b39">[40]</ref> only changes the structure of the auxiliary branch. In EvoADA, we design a new space to produce diverse attention configurations and apply different modules on various intermediate layers of the backbone network, which is a more generalized manner; 2) on the architecture search process: AdaptNAS adopts a gradient-based differentiable scheme <ref type="bibr" target="#b30">[31]</ref>, which might result in sub-optimal solutions; ABAS leverages the BOHB <ref type="bibr" target="#b13">[14]</ref>, a Bayesian-based hyperparameter optimization method, which is not suitable for a high-dimensional optimization problem. We adopt an Evolution based NAS framework <ref type="bibr" target="#b0">[1]</ref>, which is a more flexible and stable test-bed for the propose of implementation. Experiments in Section 4 demonstrate the effectiveness and versatility of EvoADA in various UDA scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup</head><p>Implementation details. To check the effectiveness and versatility of our NAS algorithm, we experiment on 5 scenarios: closed-set UDA, PDA, ODA, UDA in fine-grained classification (FGDA), and UDA in person re-ID. Without loss of generality, we select 3 state-of-the-art methods as baselines: SHOT <ref type="bibr" target="#b26">[27]</ref> for UDA, PDA, and ODA; PAN <ref type="bibr" target="#b46">[47]</ref> for FGDA; and MMT <ref type="bibr" target="#b16">[17]</ref> for UDA in person re-ID. For fair comparisons, i) we use the same backbone, i.e., ResNet-50 <ref type="bibr" target="#b19">[20]</ref>, which is prevailing in domain adaptation literature <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b16">17]</ref>; 2) in PDA and ODA, we follow the same data pipeline as <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b26">27]</ref>; 3) in FGDA, we use the data pipeline of PAN <ref type="bibr" target="#b46">[47]</ref>; 4) to reduce the uncertainty from random seeds, we train the searched architectures with baseline methods three times using different random seeds and report the average results. On these baselines, we adopt our EvoADA to investigate whether the searched architectures help boost classification performance on the target domain. Experimental results also verify the versatility of our method in various domain adaptation tasks.</p><p>To train the network weights ?, we use the same settings (including data augmentation, learning-rate schedule, batch-size, etc.) as the aforementioned UDA baseline methods. EvoADA run T = 100 epochs and K = 20 different seeds evolve. We implement the proposed EvoADA with pytorch platform <ref type="bibr" target="#b34">[35]</ref>. We adopt 8 NVIDIA Tesla V-100 GPUs and it takes approximately 20 hours to finish the search procedure on one UDA task on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets. We experiment on multiple benchmarks:</head><p>Benchmark I: Office-Home &amp; Office-31. Office-Home <ref type="bibr" target="#b44">[45]</ref> is one challenging medium-sized dataset. It contains 12 adaptation tasks from 4 distinct domains: Artistic (Ar), Clip Art (Cl), Product (Pr), and Real-World (Rw). Office31 <ref type="bibr" target="#b40">[41]</ref> is a popular small-scale domain adaptation benchmark with 4, 110 images and 31 classes. It consists of 6 cross-domain tasks from 3 distinct domains: Amazon (A), Webcam (W), and DSLR (D). Follow the practice, we report classification accuracy on each adaptation task.</p><p>Benchmark II: FGDA. CUB-200-2011 <ref type="bibr" target="#b45">[46]</ref> and CUB-200-Paintings <ref type="bibr" target="#b46">[47]</ref> are datasets for fine-grained UDA. CUB-200-2011 <ref type="bibr" target="#b45">[46]</ref> is a fine-grained visual categorization dataset with 12K bird images in 200 species. CUB-200-Paintings is a dataset of 3K bird paintings collected by Wang et al. <ref type="bibr" target="#b46">[47]</ref> and its class lists are identical to CUB-200-2011. We follow the same data pipeline as PAN <ref type="bibr" target="#b46">[47]</ref> and report classification accuracy on the two tasks.</p><p>Benchmark III: UDA in person Re-ID. Duke <ref type="bibr" target="#b38">[39]</ref> and Market1501 <ref type="bibr" target="#b55">[56]</ref> are two widely-used person re-ID datasets. Market-1501 <ref type="bibr" target="#b55">[56]</ref> consists of 32K labelled images of 1, 501 identities shot from 6 cameras. 13K images of 751 identities are used for training and 19.7 images of 750 identities are used for inference. Duke <ref type="bibr" target="#b38">[39]</ref> contains 16.5K photos of 702 identities for training, and photos out of additional 702 identities for testing. We follow the same pipeline on these benchmarks as Ge et al. <ref type="bibr" target="#b16">[17]</ref> and report mean average precision (mAP) to evaluate the performance.</p><p>Baselines. We compare with multiple state-of-the-art approaches: DANN <ref type="bibr" target="#b14">[15]</ref>, JAN <ref type="bibr" target="#b32">[33]</ref>, OSBP <ref type="bibr" target="#b43">[44]</ref>, CDAN <ref type="bibr" target="#b31">[32]</ref>, IBN-Net <ref type="bibr" target="#b33">[34]</ref>, MCD <ref type="bibr" target="#b42">[43]</ref>, SAN <ref type="bibr" target="#b3">[4]</ref>, TADA <ref type="bibr" target="#b49">[50]</ref>, BSP <ref type="bibr" target="#b6">[7]</ref>, SAFN <ref type="bibr" target="#b52">[53]</ref>, STA <ref type="bibr" target="#b29">[30]</ref>, CADA-A <ref type="bibr" target="#b23">[24]</ref>, ETN <ref type="bibr" target="#b4">[5]</ref>, CRST <ref type="bibr" target="#b57">[58]</ref>, BA 3 US <ref type="bibr" target="#b27">[28]</ref>, DCAN <ref type="bibr" target="#b24">[25]</ref>, MMT <ref type="bibr" target="#b16">[17]</ref>, PAN <ref type="bibr" target="#b46">[47]</ref>, SHOT <ref type="bibr" target="#b26">[27]</ref>, and ABAS <ref type="bibr" target="#b39">[40]</ref>. Among them, TADA <ref type="bibr" target="#b49">[50]</ref>, CADA-A <ref type="bibr" target="#b23">[24]</ref>, DCAN <ref type="bibr" target="#b24">[25]</ref> are the competitive approaches  of better attention module design towards domain adaptation and ABAS <ref type="bibr" target="#b39">[40]</ref> (one current work) also adopts NAS to search optimal architectures for domain adaptation, which provide a good counterpart to investigate the effect of network design in the topic of domain adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results on Office-Home &amp; Office-31</head><p>Experiments on Office-Home benchmark in <ref type="table" target="#tab_2">Table 2</ref> include 3 typical settings: closed-set UDA, PDA, and ODA 1 . As we can observe that, in term of average accuracy, the proposed NAS algorithm helps SHOT achieve better performance: +2.3% on closed-set UDA tasks, +1.9% on PDA tasks, and +3.5% on ODA tasks. We also notice that sometimes, optimal performances can be obtained when only one GSoP <ref type="bibr" target="#b15">[16]</ref> attention layer is put at Layer3 for ResNet-50. These observations encourage advanced development of the attention mechanism in domain adaptation problems.</p><p>Numerical results on Office-31 dataset are listed in <ref type="table" target="#tab_3">Table 3</ref>. Again, the proposed EvoADA generally helps SHOT promote its classification performance on target domain. These results indicate the importance of optimal attention configuration and the effectiveness of our EvoADA in typical domain adaptation scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results on FGDA and UDA in Person Re-ID</head><p>We also experiment on two additional cross-domain applications: FGDA tasks and UDA tasks of person re-ID. Results are listed in <ref type="table">Table 4</ref>. On FGDA: The performance gains from the searched attention configurations are generally large on both FGDA scenarios. In terms of average accuracy, our EvoADA helps PAN achieve 4.1% gains. Similar to the observations previously, we find that the gains can be achieved by automatically introducing 2 or 3 attention modules at proper layers of the backbone network. On UDA in Person Re-ID: For full comparisons, we experiment with different configurations of MMT <ref type="bibr" target="#b16">[17]</ref>: MMT-500 and MMT-700 means that in the MMT framework, 500 and 700 centroids are adopted when k-means clustering is used, and MMT-DBSCAN means DBSCAN clustering is adopted for pseudo-labels. As listed in <ref type="table">Table 4</ref>, the architecture searched by our EvoADA generally outperforms the other two competitive baselines, i.e., ResNet-50 <ref type="bibr" target="#b19">[20]</ref> and IBN-Net-50 <ref type="bibr" target="#b33">[34]</ref>, over different configurations of MMT method and two UDA person re-ID task scenarios. Together, we verify the effectiveness and versatility of the proposed NAS scheme in searching for optimal attention configurations for various domain adaptation scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study &amp; Insight Analysis</head><p>Comparison with Other Search Spaces. To demonstrate the effectiveness of the proposed search space in the topic of domain adaptation, we also compare with two typical search spaces in NAS methods: the search space of NAS-Net <ref type="bibr" target="#b56">[57]</ref> and that of DARTS <ref type="bibr" target="#b30">[31]</ref>. Both of them are based Evo-Norm Random ResNet-50 on basic operations in convolutional neural networks (e.g., dilated convolution, pooling, and skip connection). We randomly select 4 close-set UDA settings from Office-Home dataset and alternate our search space with the two to investigate how their performance in the context of domain adaptation. For full comparison, we also report the results from ABAS <ref type="bibr" target="#b39">[40]</ref>. As listed in <ref type="table">Table 5</ref> the proposed attentionbased search space does outperform other existing alternatives and yields the best domain adaptation results.</p><p>Comparison with Random Search. The search curves of our EvoADA and one random search algorithm are shown in <ref type="figure" target="#fig_3">Figure 4</ref>. As we can observe that our EvoADA is more effective in optimizing the attention configurations for domain adaptation settings. We find similar observations on Office-Home benchmark with two additional baseline meth- Effectiveness of Performance Estimation. To further demonstrate the rationale of our performance estimation strategy, we show the rank correlation, i.e., Spearman ?, between our estimation results and the final accuracy in the  target domain. For comparison, we also show the rank correlation between the accuracy in the source domain and that in the target domain. The results are shown in <ref type="table" target="#tab_6">Table 6</ref>. Obvious, the rank correlation between the accuracy in the source domain and that in the target domain is relatively low, due to the large domain shift between two domains. The estimation results via our evaluation strategy, on the other hand, are highly correlated with the accuracy in the target domain and are effective to guide search procedures to seek optimal architectures for domain adaptation.</p><p>Good and Bad Case Analysis. Finally, we take a closer look at the searched attention configurations. <ref type="figure" target="#fig_4">Figure 5</ref> displays the accuracies of 500 randomly sampled populations on the FGDA task of CUB-200-Painting ? CUB-200-2011. The histogram verifies the benefit from refining the attention configurations and the effectiveness of the proposed attention configuration. For better understanding the searched optimal architectures, we also visualize some at- tention configurations with good and sub-optimal UDA results ( <ref type="figure" target="#fig_4">Figure 5(b)</ref>), and the training curves of the optimal networks ( <ref type="figure" target="#fig_5">Figure 6</ref>). Experiments indicate that Layer 3 and Layer 4 seem to be optimal positions to introduce attention modules, and we achieve the gains in accuracy when only moderate amounts of parameters and #FLOPs are introduced. All these numerical results can help and encourage researchers to cast a new light on designing novel attention modules towards better domain adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we devise a novel and effective NAS algorithm for UDA problems. We propose a more generalized way to apply the attention module for domain adaptation: to automatically optimize the attention configuration for one arbitrary UDA dataset. We propose a new search space with a set of attention modules and their positions in the backbone network. To be consonant with UDA settings, we propose a UDA-oriented estimation strategy: train the weights on two domains and evaluate the attention configurations in the target domain with a self-training pseudo-label strategy. We implement the EvoADA framework based on an evolution-based NAS algorithm. Extensive experiments on multiple cross-domain benchmarks and typical adaptation scenarios verify that our scheme generally promotes popular domain adaptation methods.</p><p>For future work, we will investigate the transferability of various architectures and study the topic in other scenarios, e.g., object detection and semantic segmentation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Why Attention Configuration Matters. Intuitively, different configurations of attention work differently. Given one UDA scenario, our EvoADA finds which and where to add the attention modules and achieves better domain adaptation performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>) are arXiv:2103.13561v1 [cs.CV] 25 Mar 2021 Classification accuracy (%) on target UDA result comparisons on Office-Home datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>The comparison of EvoADA and random search on the partial UDA task Pr?Rw on Office-Home dataset. The prevailing backbone, ResNet-50, is denoted as the dashed horizontal bar.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>(a) Histogram of the accuracies for 500 random populations on the FGDA task of CUB-200-Painting to CUB-200-2011. The dashed vertical line indicates the result of ResNet-50. (b) Some seeds on the PDA task of Rw ? Ar on Office-Home. The numbers indicate their corresponding accuracies on target domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>(a) and (b): The curves of three backbone networks on UDA tasks over person re-ID benchmarks. The x-axis is training epochs and the y-axis is the accuracy (%) on target domain. (c) and (d): The differences between ResNet-50 and ours on fine-grained UDA tasks over CUB-Paintings. The x-axis indicates training iterations. The y-axis indicates the training loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>population size K Result: A list of optimal architectures and corresponding network weights for the DA task from S to T 1 Seed Initialization: sample K seeds from the search space A as G seed , initialize their weights, and assign various seed numbers for each seed;2 G best = [], t = 1; 3 while t ? T do 4 train G seed ; 5inference the performance of G seed ;</figDesc><table><row><cell>14</cell><cell>end</cell></row><row><cell>15</cell><cell>t += 1;</cell></row></table><note>6 crossover top seeds to get Gcrossover;7 mutate the bottom seeds to get Gmutate;8 record mature seeds in Gcrossover with G best ;9 pop poor seeds from Gmutate;10 Gseed = Gcrossover + Gmutate;11 if |G seed | &lt; K then12 initialize another (K ? |G seed |) seeds G rand ;13 G seed = G seed + G rand ;16 end 17 return G best ;</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Accuracy (%) on Office-Home for UDA, PDA, and ODA methods (ResNet-50). -set UDA Ar?Cl Ar?Pr Ar?Rw Cl?Ar Cl?Pr Cl?Rw Pr?Ar Pr?Cl Pr?Rw Rw?Ar Rw?Cl Rw?Pr AVG</figDesc><table><row><cell>ClosedResNet-50 [20]</cell><cell>34.9</cell><cell>50.0</cell><cell>58.0</cell><cell>37.4</cell><cell>41.9</cell><cell>46.2</cell><cell>38.5</cell><cell>31.2</cell><cell>60.4</cell><cell>53.9</cell><cell>41.2</cell><cell>59.9</cell><cell>46.1</cell></row><row><cell>DANN [15]</cell><cell>45.6</cell><cell>59.3</cell><cell>70.1</cell><cell>47.0</cell><cell>58.5</cell><cell>60.9</cell><cell>46.1</cell><cell>43.7</cell><cell>68.5</cell><cell>63.2</cell><cell>51.8</cell><cell>76.8</cell><cell>57.6</cell></row><row><cell>JAN [33]</cell><cell>45.9</cell><cell>61.2</cell><cell>68.9</cell><cell>50.4</cell><cell>59.7</cell><cell>61.0</cell><cell>45.8</cell><cell>43.4</cell><cell>70.3</cell><cell>63.9</cell><cell>52.4</cell><cell>76.8</cell><cell>58.3</cell></row><row><cell>CDAN [32]</cell><cell>50.7</cell><cell>70.6</cell><cell>76.0</cell><cell>57.6</cell><cell>70.0</cell><cell>70.0</cell><cell>57.4</cell><cell>50.9</cell><cell>77.3</cell><cell>70.9</cell><cell>56.7</cell><cell>81.6</cell><cell>65.8</cell></row><row><cell>ABAS [40]</cell><cell>51.5</cell><cell>71.7</cell><cell>75.5</cell><cell>59.8</cell><cell>69.4</cell><cell>69.5</cell><cell>59.8</cell><cell>47.1</cell><cell>77.7</cell><cell>70.6</cell><cell>55.2</cell><cell>80.2</cell><cell>65.7</cell></row><row><cell>TADA [50]</cell><cell>53.1</cell><cell>72.3</cell><cell>77.2</cell><cell>59.1</cell><cell>71.2</cell><cell>72.1</cell><cell>59.7</cell><cell>53.1</cell><cell>78.4</cell><cell>72.4</cell><cell>60.0</cell><cell>82.9</cell><cell>67.6</cell></row><row><cell>CADA-A [24]</cell><cell>56.9</cell><cell>75.4</cell><cell>80.2</cell><cell>61.7</cell><cell>74.6</cell><cell>74.9</cell><cell>62.9</cell><cell>54.4</cell><cell>80.9</cell><cell>74.3</cell><cell>61.1</cell><cell>84.4</cell><cell>70.1</cell></row><row><cell>DCAN [25]</cell><cell>54.5</cell><cell>75.7</cell><cell>81.2</cell><cell>67.4</cell><cell>74.0</cell><cell>76.3</cell><cell>67.4</cell><cell>52.7</cell><cell>80.6</cell><cell>74.1</cell><cell>59.1</cell><cell>83.5</cell><cell>70.5</cell></row><row><cell>SHOT [27]</cell><cell>56.9</cell><cell>78.1</cell><cell>81.0</cell><cell>67.9</cell><cell>78.4</cell><cell>78.1</cell><cell>67.0</cell><cell>54.6</cell><cell>81.8</cell><cell>73.4</cell><cell>58.1</cell><cell>84.5</cell><cell>71.6</cell></row><row><cell>SHOT+Ours</cell><cell>60.0</cell><cell>78.0</cell><cell>83.5</cell><cell>74.0</cell><cell>77.9</cell><cell>79.8</cell><cell>71.2</cell><cell>56.3</cell><cell>82.8</cell><cell>77.5</cell><cell>59.0</cell><cell>86.2</cell><cell>73.9</cell></row><row><cell cols="14">Partial-set UDA Ar?Cl Ar?Pr Ar?Rw Cl?Ar Cl?Pr Cl?Rw Pr?Ar Pr?Cl Pr?Rw Rw?Ar Rw?Cl Rw?Pr AVG</cell></row><row><cell>ResNet-50 [20]</cell><cell>46.3</cell><cell>67.5</cell><cell>75.9</cell><cell>59.1</cell><cell>59.9</cell><cell>62.7</cell><cell>58.2</cell><cell>41.8</cell><cell>74.9</cell><cell>67.4</cell><cell>48.2</cell><cell>74.2</cell><cell>61.3</cell></row><row><cell>DANN [15]</cell><cell>35.5</cell><cell>48.2</cell><cell>51.6</cell><cell>35.2</cell><cell>35.4</cell><cell>41.4</cell><cell>34.8</cell><cell>31.7</cell><cell>46.2</cell><cell>47.5</cell><cell>34.7</cell><cell>49.0</cell><cell>40.9</cell></row><row><cell>SAN [4]</cell><cell>44.4</cell><cell>68.7</cell><cell>74.6</cell><cell>67.5</cell><cell>65.0</cell><cell>77.8</cell><cell>59.8</cell><cell>44.7</cell><cell>80.1</cell><cell>72.2</cell><cell>50.2</cell><cell>78.7</cell><cell>65.3</cell></row><row><cell>ETN [5]</cell><cell>59.2</cell><cell>77.0</cell><cell>79.5</cell><cell>62.9</cell><cell>65.7</cell><cell>75.0</cell><cell>68.3</cell><cell>55.4</cell><cell>84.4</cell><cell>75.7</cell><cell>57.7</cell><cell>84.5</cell><cell>70.5</cell></row><row><cell>SAFN [53]</cell><cell>58.9</cell><cell>76.3</cell><cell>81.4</cell><cell>70.4</cell><cell>73.0</cell><cell>77.8</cell><cell>72.4</cell><cell>55.3</cell><cell>80.4</cell><cell>75.8</cell><cell>60.4</cell><cell>79.9</cell><cell>71.8</cell></row><row><cell>BA 3 US [28]</cell><cell>60.6</cell><cell>83.2</cell><cell>88.4</cell><cell>71.8</cell><cell>72.8</cell><cell>83.4</cell><cell>75.5</cell><cell>61.6</cell><cell>86.5</cell><cell>79.3</cell><cell>62.8</cell><cell>86.1</cell><cell>76.0</cell></row><row><cell>SHOT [27]</cell><cell>62.8</cell><cell>84.2</cell><cell>92.3</cell><cell>75.1</cell><cell>76.3</cell><cell>86.4</cell><cell>78.5</cell><cell>62.3</cell><cell>89.6</cell><cell>80.9</cell><cell>63.8</cell><cell>87.1</cell><cell>78.3</cell></row><row><cell>SHOT+Ours</cell><cell>66.5</cell><cell>84.7</cell><cell>89.8</cell><cell>80.3</cell><cell>80.9</cell><cell>86.3</cell><cell>83.3</cell><cell>64.1</cell><cell>90.1</cell><cell>85.5</cell><cell>61.4</cell><cell>89.9</cell><cell>80.2</cell></row><row><cell>Open-set UDA</cell><cell cols="13">Ar?Cl Ar?Pr Ar?Rw Cl?Ar Cl?Pr Cl?Rw Pr?Ar Pr?Cl Pr?Rw Rw?Ar Rw?Cl Rw?Pr AVG</cell></row><row><cell>ResNet-50 [20]</cell><cell>53.4</cell><cell>69.3</cell><cell>78.7</cell><cell>61.4</cell><cell>61.8</cell><cell>71.0</cell><cell>64.0</cell><cell>52.7</cell><cell>74.9</cell><cell>70.0</cell><cell>51.9</cell><cell>74.1</cell><cell>65.3</cell></row><row><cell>DANN [15]</cell><cell>54.6</cell><cell>69.5</cell><cell>80.2</cell><cell>61.9</cell><cell>63.5</cell><cell>71.7</cell><cell>63.3</cell><cell>49.7</cell><cell>74.2</cell><cell>71.3</cell><cell>51.9</cell><cell>72.9</cell><cell>65.4</cell></row><row><cell>OSBP [44]</cell><cell>56.7</cell><cell>67.5</cell><cell>80.6</cell><cell>62.5</cell><cell>65.5</cell><cell>74.7</cell><cell>64.8</cell><cell>51.5</cell><cell>71.5</cell><cell>69.3</cell><cell>49.2</cell><cell>74.0</cell><cell>65.7</cell></row><row><cell>STA [30]</cell><cell>58.1</cell><cell>71.6</cell><cell>85.0</cell><cell>63.4</cell><cell>69.3</cell><cell>75.8</cell><cell>65.2</cell><cell>53.1</cell><cell>80.8</cell><cell>74.9</cell><cell>54.4</cell><cell>81.9</cell><cell>69.5</cell></row><row><cell>ETN [5]</cell><cell>58.2</cell><cell>79.9</cell><cell>85.5</cell><cell>67.7</cell><cell>70.9</cell><cell>79.6</cell><cell>66.2</cell><cell>54.8</cell><cell>81.2</cell><cell>76.8</cell><cell>60.7</cell><cell>81.7</cell><cell>71.9</cell></row><row><cell>SHOT [27]</cell><cell>60.5</cell><cell>59.2</cell><cell>69.5</cell><cell>63.4</cell><cell>73.6</cell><cell>61.8</cell><cell>54.7</cell><cell>80.4</cell><cell>81.8</cell><cell>82.3</cell><cell>82.6</cell><cell>77.2</cell><cell>70.6</cell></row><row><cell>SHOT+Ours</cell><cell>62.1</cell><cell>60.2</cell><cell>79.2</cell><cell>69.4</cell><cell>73.6</cell><cell>63.7</cell><cell>58.1</cell><cell>82.7</cell><cell>87.0</cell><cell>87.4</cell><cell>86.5</cell><cell>79.3</cell><cell>74.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Accuracy (%) on Office-31 for UDA (ResNet-50).</figDesc><table><row><cell>Method</cell><cell>A?W D?W W?D A?D D?A W?A AVG</cell></row><row><cell cols="2">ResNet-50 [20] 68.4 96.7 99.3 68.9 62.5 60.7 76.1</cell></row><row><cell>DANN [15]</cell><cell>82.0 96.9 99.1 79.7 68.2 67.4 82.2</cell></row><row><cell>JAN [33]</cell><cell>86.0 96.7 99.7 85.1 69.2 70.7 84.6</cell></row><row><cell>MCD [43]</cell><cell>88.6 98.5 100.0 92.2 69.5 69.7 86.5</cell></row><row><cell>CRST [58]</cell><cell>89.4 98.9 100.0 88.7 72.6 70.9 86.8</cell></row><row><cell>CDAN [32]</cell><cell>94.1 98.6 100.0 92.9 71.0 69.3 87.7</cell></row><row><cell>TADA [50]</cell><cell>94.3 98.7 99.8 91.6 72.9 73.0 88.4</cell></row><row><cell>BSP [7]</cell><cell>93.3 98.2 100.0 93.0 73.6 72.6 88.5</cell></row><row><cell cols="2">CADA-A [24] 96.8 99.0 99.8 93.4 71.7 70.5 88.5</cell></row><row><cell>SHOT [27]</cell><cell>90.9 98.8 99.9 93.1 74.5 74.8 88.7</cell></row><row><cell>SHOT+Ours</cell><cell>94.0 97.9 100.0 94.2 74.6 74.9 89.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .Table 5 .</head><label>45</label><figDesc>Accuracy (%) on CUB-Paintings (ResNet-50) and mAP (%) Market-1501-Duke (ResNet-50 vs IBN-Net-50 vs ours). Comparison of the proposed search space and two existing typical ones. The Experiments are conducted on the four closedset UDA settings on Office-Home dataset.</figDesc><table><row><cell>FGDA</cell><cell></cell><cell cols="3">CUB-200-2011? CUB-200-Paintings AVG CUB-200-Paintings ?CUB-200-2011</cell></row><row><cell cols="2">ResNet-50 [20]</cell><cell>47.9</cell><cell>36.6</cell><cell>42.3</cell></row><row><cell>DANN [15]</cell><cell></cell><cell>57.5</cell><cell>43.0</cell><cell>50.3</cell></row><row><cell>JAN [33]</cell><cell></cell><cell>62.4</cell><cell>40.4</cell><cell>51.4</cell></row><row><cell>MCD [43]</cell><cell></cell><cell>63.4</cell><cell>43.6</cell><cell>53.5</cell></row><row><cell>CDAN [32]</cell><cell></cell><cell>63.2</cell><cell>45.4</cell><cell>54.3</cell></row><row><cell>BSP [7]</cell><cell></cell><cell>63.3</cell><cell>46.6</cell><cell>55.0</cell></row><row><cell>SAFN [53]</cell><cell></cell><cell>61.4</cell><cell>48.9</cell><cell>55.2</cell></row><row><cell>PAN [47]</cell><cell></cell><cell>67.4</cell><cell>50.9</cell><cell>59.2</cell></row><row><cell>PAN+Ours</cell><cell></cell><cell>70.5</cell><cell>56.0</cell><cell>63.3</cell></row><row><cell cols="2">UDA in Person ReID</cell><cell>Market1501 ?Duke</cell><cell>Duke? Market-1501</cell><cell>AVG</cell></row><row><cell cols="2">MMT-500 [17]</cell><cell>63.1</cell><cell>71.2</cell><cell>67.2</cell></row><row><cell cols="2">+ IBN-Net-50 [34]</cell><cell>65.7</cell><cell>76.5</cell><cell>71.1</cell></row><row><cell>+ Ours</cell><cell></cell><cell>69.6</cell><cell>79.9</cell><cell>74.8</cell></row><row><cell cols="2">MMT-700 [17]</cell><cell>65.1</cell><cell>69.0</cell><cell>67.1</cell></row><row><cell cols="2">+ IBN-Net-50 [34]</cell><cell>68.7</cell><cell>74.5</cell><cell>71.6</cell></row><row><cell>+ Ours</cell><cell></cell><cell>71.0</cell><cell>78.5</cell><cell>74.8</cell></row><row><cell cols="2">MMT-DBSCAN [17]</cell><cell>64.3</cell><cell>75.6</cell><cell>70.0</cell></row><row><cell cols="2">+ IBN-Net-50 [34]</cell><cell>68.8</cell><cell>80.5</cell><cell>74.7</cell></row><row><cell>+ Ours</cell><cell></cell><cell>71.4</cell><cell>84.3</cell><cell>77.9</cell></row><row><cell>Settings</cell><cell cols="4">NASNet [57] DARTS [31] ABAS [40] Ours</cell></row><row><cell>Ar ? Cl</cell><cell>57.1</cell><cell>56.8</cell><cell>51.5</cell><cell>60.0</cell></row><row><cell>Cl ? Pr</cell><cell>78.1</cell><cell>77.3</cell><cell>69.4</cell><cell>77.9</cell></row><row><cell>Pr ? Rw</cell><cell>81.3</cell><cell>80.7</cell><cell>77.7</cell><cell>82.8</cell></row><row><cell>Rw ? Ar</cell><cell>73.0</cell><cell>74.6</cell><cell>70.6</cell><cell>77.5</cell></row><row><cell>AVG</cell><cell>72.6</cell><cell>72.3</cell><cell>67.3</cell><cell>74.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>ods (random search v.s. ours): CDAN<ref type="bibr" target="#b31">[32]</ref> (66.4% v.s. 69.8%) and SHOT<ref type="bibr" target="#b26">[27]</ref> (71.9% v.s. 73.9%). Therefore, the results of random search demonstrate the necessity of an effective NAS algorithm towards domain adaptation tasks.Hyper-parameter Sensitivity. We investigate the sensitivity to 3 hyper-parameters, tr acc , T , T d . Empirically, we observe that: When t acc = 0.98, the results go worse; when t acc ? {0.9, 0.93, 0.95}, the results are similar; when t acc ? {0.8, 0.85}, the results become worse again. ii) When T ? 100, the results are slightly better but the cost also arises. iii) When T d &gt; 5, the results are relatively worse; when T d ? 5, the results are similar. Thus, our EvoADA is relatively robust to these hyper-parameters.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Comparison of the rank correlation between the estimation results via the accuracy on source domain and that via our evaluation protocol.</figDesc><table><row><cell>Criteria</cell><cell></cell><cell></cell><cell>Office-31</cell><cell>Office-Home</cell></row><row><cell cols="2">Accuracy on Source Domain</cell><cell></cell><cell>0.40</cell><cell>0.23</cell></row><row><cell cols="2">Our estimation protocol</cell><cell></cell><cell>0.68</cell><cell>0.54</cell></row><row><cell>samples</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>#</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Accuracy on of the task from CUB-200-Paintings to CUB-200-2011</cell></row><row><cell></cell><cell></cell><cell>(a) (a)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>GSoP #channel 256, #group 2</cell><cell></cell><cell>GSoP #channel 512, #group 4</cell><cell>SE #channel 256, #group 1</cell></row><row><cell>Conv 1x1 acc = 75.2% Conv 3x3 Conv 1x1 + relu</cell><cell>Conv 1x1 acc = 76.9% Conv 3x3 Conv 1x1 + relu</cell><cell>(b)</cell><cell>Conv 1x1 acc = 77.8% Conv 3x3 Conv 1x1 + relu</cell><cell>Conv 1x1 Conv 3x3 acc = 76.3% Conv 1x1 + relu</cell></row><row><cell></cell><cell>at Layer 4</cell><cell></cell><cell>at Layer 3</cell><cell>at Layer 3 &amp; 4</cell></row><row><cell>ResNet-50</cell><cell>in ResNet-50</cell><cell></cell><cell>in ResNet-50</cell><cell>in ResNet-50</cell></row><row><cell>75.2%</cell><cell>76.9%</cell><cell></cell><cell>77.8%</cell><cell>76.3%</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">To compare with other ODA methods, we report the OS values. Results of the baseline methods come from<ref type="bibr" target="#b26">[27]</ref>.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Evolutionary algorithms in theory and practice: evolution strategies, evolutionary programming, genetic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Back</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1996" />
			<publisher>Oxford university press</publisher>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Understanding and simplifying one-shot architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Path-level network transformation for efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICML</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Partial transfer learning with selective adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning to transfer examples for partial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichao</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Transferability vs. discriminability: Batch spectral penalization for adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Detnas: Backbone search for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generalized representation learning for mixture domain face antispoofing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taiping</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kekai</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shouhong</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jilin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Heuristic domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhao</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Towards discriminability and diversity: Batch nuclear-norm maximization under label insufficient situations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhao</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbao</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural architecture search: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Hendrik</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bohb: Robust and efficient hyperparameter optimization at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Falkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JMLR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Global second-order pooling convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangtao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qilong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihua</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mutual meanteaching: Pseudo label refinery for unsupervised domain adaptation on person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixiao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dapeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Discriminative clustering by regularized information maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Gomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Single path one-shot neural architecture search with uniform sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyuan</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zechun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning discrete representations via information maximizing self-augmented training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiya</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichi</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Contrastive adaptation network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Attending to discriminative certainty for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Kumar Kurmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanu</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vinay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Namboodiri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Domain conditioned adaptation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><forename type="middle">Harold</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuxia</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binhui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adapting neural architectures between domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Do we really need to access the source data? source hypothesis transfer for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dapeng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ran He, and Jiashi Feng. A balanced and uncertainty-aware approach for partial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dapeng</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Autodeeplab: Hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Separate to adapt: Open set domain adaptation via progressive separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Darts: Differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Conditional adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep transfer learning with joint adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Two at once: Enhancing learning and generalization capacities via ibn-net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Auto-reid: Searching for a part-aware convnet for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijie</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Dataset shift in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joaquin</forename><surname>Quionero-Candela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Schwaighofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil D</forename><surname>Lawrence</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Performance measures and a data set for multi-target, multi-camera tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ergys</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Solera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlo</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Adversarial branch architecture search for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Robbiano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad Rameez Ur</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Galasso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">Maria</forename><surname>Carlucci</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.06679</idno>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Universal domain adaptation through self supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniaki</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2020</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Maximum classifier discrepancy for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniaki</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kohei</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Open set domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniaki</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shohei</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshitaka</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hemanth</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shayok</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sethuraman</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pietro Perona, and Serge Belongie. The caltech-ucsd birds-200-2011 dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">California Institute of Technology</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Progressive adversarial networks for fine-grained domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Transferable normalization: Towards improving transferability of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ximei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Fully learnable group convolution for acceleration of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meina</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Transferable attention for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ximei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weirui</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">A dictionary approach to domain-invariant learning in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiuyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Joon-Young Lee, and In So Kweon. Cbam: Convolutional block attention module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyun</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongchan</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">How transferable are features in deep neural networks? In NeurIPS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hod</forename><surname>Lipson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Universal domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichao</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Scalable person re-identification: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyue</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengjin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Confidence regularized self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsong</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
