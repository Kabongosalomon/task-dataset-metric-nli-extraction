<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Integrative Few-Shot Learning for Classification and Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahyun</forename><surname>Kang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Pohang University of Science and Technology (POSTECH)</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Pohang University of Science and Technology (POSTECH)</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Integrative Few-Shot Learning for Classification and Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce the integrative task of few-shot classification and segmentation (FS-CS) that aims to both classify and segment target objects in a query image when the target classes are given with a few examples. This task combines two conventional few-shot learning problems, fewshot classification and segmentation. FS-CS generalizes them to more realistic episodes with arbitrary image pairs, where each target class may or may not be present in the query. To address the task, we propose the integrative fewshot learning (iFSL) framework for FS-CS, which trains a learner to construct class-wise foreground maps for multilabel classification and pixel-wise segmentation. We also develop an effective iFSL model, attentive squeeze network (ASNet), that leverages deep semantic correlation and global self-attention to produce reliable foreground maps. In experiments, the proposed method shows promising performance on the FS-CS task and also achieves the state of the art on standard few-shot segmentation benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Few-shot learning <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b84">84,</ref><ref type="bibr" target="#b86">86]</ref> is the learning problem where a learner experiences only a limited number of examples as supervision. In computer vision, it has been most actively studied for the tasks of image classification <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b67">68]</ref> and semantic segmentation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b60">61]</ref> among many others <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b96">96,</ref><ref type="bibr" target="#b101">101]</ref>. Few-shot classification (FS-C) aims to classify a query image into target classes when a few support examples are given for each target class. Few-shot segmentation (FS-S) is to segment out the target class regions on the query image in a similar setup. While being closely related to each other <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b94">94,</ref><ref type="bibr" target="#b102">102]</ref>, these two few-shot learning problems have so far been treated individually. Furthermore, the conventional setups for the fewshot problems, FS-C and FS-S, are limited and do not reflect realistic scenarios; FS-C <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b78">78]</ref> presumes that the query always contains one of the target classes in classification, while FS-S <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b64">65]</ref> allows the presence of multiple Bottom: FS-S learners are trained to segment a query image using a semantically-coupled support set thus often blindly highlight any salient objects regardless of support semantics. The proposed FS-CS learners are trained to predict class presence as well as corresponding masks thus correctly discriminate what to segment based on the semantic relevance between the query and the support. classes but does not handle the absence of the target classes in segmentation. These respective limitations prevent fewshot learning from generalizing to and evaluating on more realistic cases in the wild. For example, when a query image without any target class is given as in <ref type="figure" target="#fig_0">Fig. 1</ref>, FS-S learners typically segment out arbitrary salient objects in the query.</p><p>To address the aforementioned issues, we introduce the integrative task of few-shot classification and segmentation (FS-CS) that combines the two few-shot learning problems into a multi-label and background-aware prediction problem. Given a query image and a few-shot support set for target classes, FS-CS aims to identify the presence of each target class and predict its foreground mask from the query. Unlike FS-C and FS-S, it does not presume either the class exclusiveness in classification or the presence of all the tar-get classes in segmentation.</p><p>As a learning framework for FS-CS, we propose integrative few-shot learning (iFSL) that learns to construct shared foreground maps for both classification and segmentation. It naturally combines multi-label classification and pixel-wise segmentation by sharing class-wise foreground maps and also allows to learn with class tags or segmentation annotations. For effective iFSL, we design the attentive squeeze network (ASNet) that computes semantic correlation tensors between the query and the support image features and then transforms the tensor into a foreground map by strided self-attention. It generates reliable foreground maps for iFSL by leveraging multi-layer neural features <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b45">46]</ref> and global self-attention <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b77">77]</ref>. In experiments, we demonstrate the efficacy of the iFSL framework on FS-CS and compare ASNet with recent methods <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b88">[88]</ref><ref type="bibr" target="#b89">[89]</ref><ref type="bibr" target="#b90">[90]</ref>. Our method significantly improves over the other methods on FS-CS in terms of classification and segmentation accuracy and also outperforms the recent FS-S methods on the conventional FS-S. We also cross-validate the task transferability between the FS-C, FS-S, and FS-CS learners, and show the FS-CS learners effectively generalize when transferred to the FS-C and FS-S tasks.</p><p>Our contribution is summarized as follows:</p><p>? We introduce the task of integrative few-shot classification and segmentation (FS-CS), which combines few-shot classification and few-shot segmentation into an integrative task by addressing their limitations.</p><p>? We propose the integrative few-shot learning framework (iFSL), which learns to both classify and segment a query image using class-wise foreground maps.</p><p>? We design the attentive squeeze network (ASNet), which squeezes semantic correlations into a foreground map for iFSL via strided global self-attention.</p><p>? We show in extensive experiments that the framework, iFSL, and the architecture, ASNet, are both effective, achieving a significant gain on FS-S as well as FS-CS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Few-shot classification (FS-C). Recent FS-C methods typically learn neural networks that maximize positive class similarity and suppress the rest to predict the most probable class. Such a similarity function is obtained by a) metalearning embedding functions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b78">78,</ref><ref type="bibr" target="#b95">95,</ref><ref type="bibr" target="#b98">98]</ref>, b) meta-learning to optimize classifier weights <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b70">71]</ref>, or c) transfer learning <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b83">83]</ref>, all of which aim to generalize to unseen classes. This conventional formulation is applicable if a query image corresponds to no less or more than a single class among target classes. To generalize FS-C to classify images associated with either none or multiple classes, we employ the multi-label classification <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b42">43]</ref>. While the conventional FS-C methods make use of the class uniqueness property via using the categorical cross-entropy, we instead devise a learning framework that compares the binary relationship between the query and each support image individually and estimates a binary presence of the corresponding class.</p><p>Few-shot semantic segmentation (FS-S). A prevalent FS-S approach is learning to match a query feature map with a set of support feature embeddings that are obtained by collapsing spatial dimensions at the cost of spatial structures <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b80">80,</ref><ref type="bibr" target="#b91">91,</ref><ref type="bibr" target="#b92">92,</ref><ref type="bibr" target="#b97">97,</ref><ref type="bibr" target="#b100">100]</ref>. Recent methods <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b88">[88]</ref><ref type="bibr" target="#b89">[89]</ref><ref type="bibr" target="#b90">[90]</ref><ref type="bibr" target="#b99">99]</ref> focus on learning structural details by leveraging dense feature correlation tensors between the query and each support. HSNet <ref type="bibr" target="#b44">[45]</ref> learns to squeeze a dense feature correlation tensor and transform it to a segmentation mask via high-dimensional convolutions that analyze the local correlation patterns on the correlation pyramid. We inherit the idea of learning to squeeze correlations and improve it by analyzing the spatial context of the correlation with effective global self-attention <ref type="bibr" target="#b77">[77]</ref>.</p><p>Note that several methods <ref type="bibr" target="#b69">[70,</ref><ref type="bibr" target="#b79">79,</ref><ref type="bibr" target="#b93">93]</ref> adopt non-local selfattention <ref type="bibr" target="#b82">[82]</ref> of the query-key-value interaction for FS-S, but they are distinct from ours in the sense that they learn to transform image feature maps, whereas our method focuses on transforming dense correlation maps via self-attention. FS-S has been predominantly investigated as an oneway segmentation task, i.e., foreground or background segmentation, since the task is defined so that every target (support) class object appears in query images, thus being not straightforward to extend to a multi-class problem in the wild. Consequently, most work on FS-S except for a few <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b80">80]</ref> focuses on the one-way segmentation, where the work of <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b71">72]</ref> among the few presents two-way segmentation results from person-and-object images only, e.g., images containing (person, dog) or (person <ref type="table" target="#tab_3">, table)</ref>.</p><p>Comparison with other few-shot approaches. Here we contrast FS-CS with other loosely-related work for generalized few-shot learning. Few-shot open-set classification <ref type="bibr" target="#b39">[40]</ref> brings the idea of the open-set problem <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b63">64]</ref> to few-shot classification by allowing a query to have no target classes. This formulation enables background-aware classification as in FS-CS, whereas multi-label classification is not considered. The work of <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b73">74]</ref> generalizes few-shot segmentation to a multi-class task, but it is mainly studied under the umbrella of incremental learning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b57">58]</ref>. The work of <ref type="bibr" target="#b65">[66]</ref> investigates weakly-supervised few-shot segmentation using image-level vision and language supervision, while FS-CS uses visual supervision only. The aforementioned tasks generalize few-shot learning but differ from FS-CS in the sense that FS-CS integrates two related problems under more general and relaxed constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem formulation</head><p>Given a query image and a few support images for target classes, we aim to identify the presence of each class and predict its foreground mask from the query ( <ref type="figure" target="#fig_0">Fig. 1</ref>), which we call the integrative few-shot classification and segmentation (FS-CS). Specifically, let us assume a target (support) class set C s of N classes and its support set</p><formula xml:id="formula_0">S = {(x (i) s , y (i) s )|y (i) s ? C s } N K i=1</formula><p>, which contains K labeled instances for each of the N classes, i.e., N -way Kshot <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b78">78]</ref>. The label y (i) s is either a class tag (weak label) or a segmentation annotation (strong label). For a given query image x, we aim to identify the multi-hot class occurrence y C and also predict the segmentation mask Y S corresponding to the classes. We assume the class set of the query C is a subset of the target class set, i.e., C ? C s , thus it is also possible to obtain y C = ? and Y S = ?. This naturally generalizes the existing few-shot classification <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b78">78]</ref> and few-shot segmentation <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b64">65]</ref>.</p><p>Multi-label background-aware prediction. The conventional formulation of few-shot classification (FS-C) <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b78">78]</ref> assigns the query to one class among the target classes exclusively and ignores the possibility of the query belonging to none or multiple target classes. FS-CS tackle this limitation and generalizes FS-C to multi-label classification with a background class. A multi-label few-shot classification learner f C compares semantic similarities between the query and the support images and estimates class-wise occurrences:? C = f C (x, S; ?) where? C is an N -dimensional multi-hot vector each entry of which indicates the occurrence of the corresponding target class. Note that the query is classified into a background class if none of the target classes were detected. Thanks to the relaxed constraint on the query, i.e., the query not always belonging to exactly one class, FS-CS is more general than FS-C.</p><p>Integration of classification and segmentation. FS-CS integrates multi-label few-shot classification with semantic segmentation by adopting pixel-level spatial reasoning. While the conventional FS-S <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b80">80]</ref> assumes the query class set exactly matches the support class set, i.e., C = C s , FS-CS relaxes the assumption such that the query class set can be a subset of the support class set, i.e., C ? C s . In this generalized segmentation setup along with classification, an integrative FS-CS learner f estimates both classwise occurrences and their semantic segmentation maps: {? C ,? S } = f (x, S; ?). This combined and generalized formulation gives a high degree of freedom to both of the few-shot learning tasks, which has been missing in the literature; the integrative few-shot learner can predict multilabel background-aware class occurrences and segmentation maps simultaneously under a relaxed constraint on the few-shot episodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Integrative Few-Shot Learning (iFSL)</head><p>To solve the FS-CS problem, we propose an effective learning framework, integrative few-shot learning (iFSL). The iFSL framework is designed to jointly solve few-shot classification and few-shot segmentation using either a class tag or a segmentation supervision. The integrative few-shot learner f takes as input the query image x and the support set S and then produces as output the class-wise foreground maps. The set of class-wise foreground maps Y is comprised of Y (n) ? R H?W for N classes:</p><formula xml:id="formula_1">Y = f (x, S; ?) = {Y (n) } N n=1 ,<label>(1)</label></formula><p>where H ? W denotes the size of each map and ? is parameters to be meta-learned. The output at each position on the map represents the probability of the position being on a foreground region of the corresponding class.</p><p>Inference. iFSL infers both class-wise occurrences and segmentation masks on top of the set of foreground maps Y. For class-wise occurrences, a multi-hot vector? C ? R N is predicted via max pooling followed by thresholding:</p><formula xml:id="formula_2">y (n) C = 1 if max p?[H]?[W ] Y (n) (p) ? ?, 0 otherwise,<label>(2)</label></formula><p>where p denotes a 2D position, ? is a threshold, and [k] denotes a set of integers from 1 to k, i.e., [k] = {1,2,? ? ? ,k}. We find that inference with average pooling is prone to miss small objects in multi-label classification and thus choose to use max pooling. The detected class at any position on the spatial map signifies the presence of the class. For segmentation, a segmentation probability tensor Y S ? R H?W ?(N +1) is derived from the class-wise foreground maps. As the background class is not given as a separate support, we estimate the background map in the context of the given supports; we combine N class-wise background maps into an episodic background map on the fly. Specifically, we compute the episodic background map Y bg by averaging the probability maps of not being foreground and then concatenate it with the class-wise foreground maps to obtain a segmentation probability tensor Y S :</p><formula xml:id="formula_3">Y bg = 1 N N n=1 (1 ? Y (n) ),<label>(3)</label></formula><formula xml:id="formula_4">Y S = [Y||Y bg ] ? R H?W ?(N +1) .<label>(4)</label></formula><p>The final segmentation mask? S ? R H?W is obtained by computing the most probable class label for each position:</p><formula xml:id="formula_5">Y S = arg max n?[N +1] Y S .<label>(5)</label></formula><p>Learning objective. The iFSL framework allows a learner to be trained using a class tag or a segmentation annotation broadcasted element-wise addition <ref type="figure">Figure 2</ref>. Overview of ASNet. ASNet first constructs a hypercorrelation <ref type="bibr" target="#b44">[45]</ref> with image feature maps between a query (colored red) and a support (colored blue), where the 4D correlation is depicted as two 2D squares for demonstrational simplicity. ASNet then learns to transform the correlation to a foreground map by gradually squeezing the support dimension on each query dimension via global selfattention. Each input correlation, intermediate feature, and output foreground map has a channel dimension but is omitted in the illustration.</p><formula xml:id="formula_6">correlation of size ! ? ! ? " ? " ! (#) ! (#) % (#) % (#) ! (&amp;) ! (&amp;) % (&amp;) % (&amp;) ! (') % (') % (') ! (') ! ? ! ? " ? " correlation ! ? ! mask prediction !? !? ?%? ?% !? ! !? !? ?%? ?% 1?1 1?1 1?1</formula><p>using the classification loss or segmentation loss, respectively. The classification loss is formulated as the average binary cross-entropy between the spatially average-pooled class scores and its ground-truth class label:</p><formula xml:id="formula_7">L C = ? 1 N N n=1 y (n) gt log 1 HW p?[H]?[W ] Y (n) (p),<label>(6)</label></formula><p>where y gt denotes the multi-hot encoded ground-truth class.</p><p>The segmentation loss is formulated as the average cross-entropy between the class distribution at each individual position and its ground-truth segmentation annotation:</p><formula xml:id="formula_8">L S = ? 1 (N + 1) 1 HW N +1 n=1 p?[H]?[W ] Y (n) gt (p) log Y (n) S (p),<label>(7)</label></formula><p>where Y gt denotes the ground-truth segmentation mask.</p><p>These two losses share a similar goal of classification but differ in whether to classify each image or each pixel. Either of them is thus chosen according to the given level of supervision for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Model architecture</head><p>In this section, we present Attentive Squeeze Network (ASNet) of an effective iFSL model. The main building block of ASNet is the attentive squeeze layer (AS layer), which is a high-order self-attention layer that takes a correlation tensor and returns another level of correlational representation. ASNet takes as input the pyramidal crosscorrelation tensors between a query and a support image feature pyramids, i.e., a hypercorrelation <ref type="bibr" target="#b44">[45]</ref>. The pyramidal correlations are fed to pyramidal AS layers that gradually squeeze the spatial dimensions of the support image, and the pyramidal outputs are merged to a final foreground map in a bottom-up pathway <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b44">45]</ref>. <ref type="figure">Figure 2</ref> illustrates the overall process of ASNet. The N -way output maps are computed in parallel and collected to prepare the class-wise foreground maps in Eq. (1) for iFSL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Attentive Squeeze Network (ASNet)</head><p>Hypercorrelation construction. Our method first constructs N K hypercorrelations <ref type="bibr" target="#b44">[45]</ref> between a query and each N K support image and then learns to generate a foreground segmentation mask w.r.t. each support input. To prepare the input hypercorrelations, an episode, i.e., a query and a support set, is enumerated into a paired list of the query, a support image, and a support label:</p><formula xml:id="formula_9">{(x, (x (i) s , y (i) s ))} N K i=1 .</formula><p>The input image is fed to stacked convolutional layers in a CNN and its mid-to high-level output feature maps are collected to build a feature pyramid {F (l) } L l=1 , where l denotes the index of a unit layer, e.g., Bottleneck layer in ResNet50 <ref type="bibr" target="#b22">[23]</ref>. We then compute cosine similarity between each pair of feature maps from the pair of query and support feature pyramids to obtain 4D correlation tensors of size H</p><formula xml:id="formula_10">(l) q ?W (l) q ?H (l) s ?W (l)</formula><p>s , which is followed by ReLU <ref type="bibr" target="#b46">[47]</ref>:</p><formula xml:id="formula_11">C (l) (p q , p s ) = ReLU F (l) q (p q ) ? F (l) s (p s ) ||F (l) q (p q )|| ||F (l) s (p s )|| .<label>(8)</label></formula><p>These L correlation tensors are grouped by P groups of the identical spatial sizes, and then the tensors in each group are concatenated along a new channel dimension to build a hypercorrelation pyramid:</p><formula xml:id="formula_12">{C (p) |C (p) ? R H (p) q ?W (p) q ?H (p) s ?W (p) s ?C (p) in } P p=1 such that the channel size C (p)</formula><p>in corresponds to the number of concatenated tensors in the p th group. We denote the first two spatial dimensions of the correlation tensor, i.e., R Hq?Wq , as query dimensions, and the last two spatial dimensions, i.e., R Hs?Ws , as support dimensions hereafter.</p><p>Attentive squeeze layer (AS layer). The AS layer transforms a correlation tensor to another with a smaller support dimension via strided self-attention. The tensor is recast as a matrix with each element representing a support pattern. Given a correlation tensor C ? R Hq?Wq?Hs?Ws?Cin in a hypercorrelation pyramid, we start by reshaping the correlation tensor as a block matrix of size H q ? W q with each element corresponding to a correlation tensor of C(x q ) ? R Hs?Ws?Cin on the query position x q such that</p><formula xml:id="formula_13">C block = ? ? ? C((1, 1)) . . . C((1, W q )) . . . . . . . . . C((H q , 1)) . . . C((H q , W q )) ? ? ? . (9)</formula><p>We call each element a support correlation tensor. The goal of an AS layer is to analyze the global context of each support correlation tensor and extract a correlational representation with a reduced support dimension while the query dimension is preserved:</p><formula xml:id="formula_14">R Hq?Wq?Hs?Ws?Cin ? R Hq?Wq?H ? s ?W ? s ?Cout , where H ? s ? H s and W ? s ? W s .</formula><p>To learn a holistic pattern of each support correlation, we adopt the global self-attention mechanism <ref type="bibr" target="#b77">[77]</ref> for correlational feature transform. The self-attention weights are shared across all query positions and processed in parallel.</p><p>Let us denote a support correlation tensor on any query position x q by C s = C block (x q ) for notational brevity as all positions share the following computation. The selfattention computation starts by embedding a support correlation tensor C s to a target 1 , key, value triplet: T, K, V ? R H ? s ?W ? s ?Chd , using three convolutions of which strides greater than or equal to one to govern the output size. The resultant target and key correlational representations, T and K, are then used to compute an attention context. The attention context is computed as following matrix multiplication:</p><formula xml:id="formula_15">A = TK ? ? R H ? s ?W ? s ?H ? s ?W ? s .<label>(10)</label></formula><p>Next, the attention context is normalized by softmax such that the votes on key foreground positions sum to one with masking attention by the support mask annotation Y s if <ref type="bibr" target="#b0">1</ref> In this section, we adapt the term "target" to indicate the "query" embedding in the context of self-attention learning <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b77">77,</ref><ref type="bibr" target="#b81">81]</ref> to avoid homonymous confusion with the "query" image to be segmented. available to attend more on the foreground region:</p><formula xml:id="formula_16">A(p t , p k ) = exp (A(p t , p k )Y s (p k )) p ? k exp (A(p t , p ? k )Y s (p ? k )) , where Y s (p k ) = 1 if p k ? [H ? s ] ? [W ? s ] is foreground, ?? otherwise.</formula><p>(11) The masked attention context? is then used to aggregate the value embedding V:</p><formula xml:id="formula_17">C s A =?V ? R H ? s ?W ? s ?Chd .<label>(12)</label></formula><p>The attended representation is fed to an MLP layer, W o , and added to the input. In case the input and output dimensions mismatch, the input is optionally fed to a convolutional layer, W I . The addition is followed by an activation layer ?(?) consisting of a group normalization <ref type="bibr" target="#b87">[87]</ref> and a ReLU activation <ref type="bibr" target="#b46">[47]</ref>:</p><formula xml:id="formula_18">C s o = ?(W o (C s A ) + W I (C s )) ? R H ? s ?W ? s ?Cout . (13)</formula><p>The output is then fed to another MLP that concludes a unit operation of an AS layer:</p><formula xml:id="formula_19">C s? = ?(W FF (C s o ) + C s o ) ? R H ? s ?W ? s ?Cout ,<label>(14)</label></formula><p>which is embedded to the corresponding query position in the block matrix of Eq. <ref type="bibr" target="#b8">(9)</ref>. Note that the AS layer can be stacked to progressively reduce the size of support correlation tensor, H ? s ? W ? s , to a smaller size. The overall pipeline of AS layer is illustrated in the supplementary material.</p><p>Multi-layer fusion. The pyramid correlational representations are merged from the coarsest to the finest level by cascading a pair-wise operation of the following three steps: upsampling, addition, and non-linear transform. We first bilinearly upsample the bottommost correlational representation to the query spatial dimension of its adjacent earlier one and then add the two representations to obtain a mixed one C mix . The mixed representation is fed to two sequential AS layers until it becomes a point feature of size H ? s = W ? s = 1, which is fed to the subsequent pyramidal fusion. The output from the earliest fusion layer is fed to a convolutional decoder, which consists of interleaved 2D convolution and bi-linear upsampling that map the C-dimensional channel to 2 (foreground and background) and the output spatial size to the input query image size. See <ref type="figure">Fig. 2</ref> for the overall process of multi-layer fusion. Class-wise foreground map computation. The K-shot output foreground activation maps are averaged to produce a mask prediction for each class. The averaged output map is normalized by softmax over the two channels of the binary segmentation map to obtain a foreground probability prediction Y (n) ? R H?W .  <ref type="table" target="#tab_3">Table 1</ref>. Performance comparison of ASNet and others on FS-CS and Pascal-5 i <ref type="bibr" target="#b64">[65]</ref>. All methods are trained and evaluated under the iFSL framework given strong labels, i.e., class segmentation masks, except for ASNetw that is trained only with weak labels, i.e., class tags. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>In this section we report our experimental results regarding the FS-CS task, the iFSL framework, as well as the ASNet after briefly describing implementation details and evaluation benchmarks. See the supplementary material for additional results, analyses, and experimental details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Experimental setups</head><p>Experimental settings. We select ResNet50 and ResNet-101 <ref type="bibr" target="#b22">[23]</ref> pretrained on ImageNet <ref type="bibr" target="#b61">[62]</ref> as our backbone networks for a fair comparison with other methods and freeze the backbone during training as similarly as the previous work <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b74">75]</ref>. We train models using Adam <ref type="bibr" target="#b27">[28]</ref> optimizer with learning rate of 10 ?4 and 10 ?3 for the classification loss and the segmentation loss, respectively. We train all models with 1-way 1-shot training episodes and evaluate the models on arbitrary N -way K-shot episodes. For inferring class occurrences, we use a threshold ? = 0.5. All the AS layers are implemented as multi-head attention with 8 heads. The number of correlation pyramid is set to P = 3.</p><p>Dataset. For the new task of FS-CS, we construct a benchmark adopting the images and splits from the two widely-used FS-S datasets, Pascal-5 i <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b64">65]</ref> and COCO-20 i <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b47">48]</ref>, which are also suitable for multi-label classification <ref type="bibr" target="#b85">[85]</ref>. Within each fold, we construct an episode by randomly sampling a query and an N -way K-shot support set that annotates the query with N -way class labels and an (N+1)-way segmentation mask in the context of the support set. For the FS-S task, we also use Pascal-5 i and COCO-20 i following the same data splits as <ref type="bibr" target="#b64">[65]</ref> and <ref type="bibr" target="#b47">[48]</ref>, respectively.</p><p>Evaluation. Each dataset is split into four mutually disjoint 1st support (blue) 2nd support (red) query (prediction) query (ground truth) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Experimental evaluation of iFSL on FS-CS</head><p>In this subsection, we investigate the iFSL learning framework on the FS-CS task. All ablation studies are conducted using ResNet50 on Pascal-i 5 and evaluated in 1way 1-shot setup unless specified otherwise. Note that it is difficult to present a fair and direct comparison between the conventional FS-C and our few-shot classification task since FS-C is always evaluated on single-label classification benchmarks <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b78">78]</ref>, whereas our task is evaluated on multi-label benchmarks <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b36">37]</ref>, which are irreducible to a single-label one in general.  Effectiveness of iFSL on FS-CS. We validate the iFSL framework on FS-CS and also compare the performance of ASNet with those of three recent state-of-the-art methods, PANet <ref type="bibr" target="#b80">[80]</ref>, PFENet <ref type="bibr" target="#b74">[75]</ref>, and HSNet <ref type="bibr" target="#b44">[45]</ref>, which are originally proposed for the conventional FS-S task; all the models are trained by iFSL for a fair comparison. Note that we exclude the background merging step (Eqs. 3 and 4) for PANet as its own pipeline produces a multi-class output including background. <ref type="table" target="#tab_1">Tables 1 and 2</ref> validate the iFSL framework on the FS-CS task quantitatively, where our ASNet surpasses other methods on both 1-way and 2way setups in terms of few-shot classification as well as the segmentation performance. The 2-way segmentation results are also qualitatively demonstrated in <ref type="figure">Fig. 3</ref> visualizing exhaustive inclusion relations between a query class set C and a target (support) class set C s in a 2-way setup.</p><p>Weakly-supervised iFSL. The iFSL framework is versatile across the level of supervision: weak labels (class tags) or strong labels (segmentation masks). Assuming weak labels are available but strong labels are not, ASNet is trainable with the classification learning objective of iFSL (Eq. 6) and its results are presented as ASNet w in <ref type="table" target="#tab_3">Table 1</ref>. ASNet w performs on par with ASNet in terms of classification ER (82.0% vs. 84.9% on 1-way 1-shot), but performs ineffectively on the segmentation task (15.0% vs. 52.3% on 1-way 1-shot). The result implies that the class tag labels are sufficient for a model to recognize the class occurrences, but are weak to endorse model's precise spatial recognition ability.</p><p>Multi-class scalability of FS-CS. In addition, FS-CS is extensible to a multi-class problem with arbitrary numbers of classes, while FS-S is not as flexible as FS-CS in the wild. <ref type="figure" target="#fig_4">Figure 4</ref> compares the FS-CS performances of four methods by varying the N -way classes from one to five, where the other experimental setup follows the same one as in <ref type="table" target="#tab_3">Table 1</ref>. Our ASNet shows consistently better performances than other methods on FS-CS in varying number of classes. Robustness of FS-CS against task transfer. We evaluate the transferability between FS-CS, FS-C, and FS-S by training a model on one task and evaluating it on the other task. The results are compared in <ref type="figure" target="#fig_5">Fig. 5</ref> in which 'FS-S ? FS-CS' represents the result where the model trained on the FS-S task (with the guarantee of support class presence) is evaluated on the FS-CS setup. To construct training and validation splits for FS-C or FS-S, we sample episodes that satisfy the constraint of support class occurrences 2 . For training FS-C models, we use the class tag supervision only. All the other settings are fixed the same, e.g., we use ASNet with ResNet50 and Pascal-i 5 .</p><p>The results show that FS-CS learners, i.e., models trained on FS-CS, are transferable to the two conventional few-shot learning tasks and yet overcome their shortcomings. The transferability between few-shot classification tasks, i.e., FS-C and FS-CS w , is presented in <ref type="figure" target="#fig_5">Fig. 5 (a)</ref>. On this setup, the FS-CS w learner is evaluated by predicting a higher class response between the two classes, although it is trained using the multi-label classification objective. The FS-CS learner closely competes with the FS-C learner on FS-C in terms of classification accuracy. In contrast, the task transfer between segmentation tasks, FS-S and FS-CS, results in asymmetric outcomes as shown in <ref type="figure" target="#fig_5">Fig. 5 (b) and (c)</ref>. The FS-CS learner shows relatively small performance drop on FS-S, however, the FS-S learner suffers a severe performance drop on FS-CS. Qualitative examples in <ref type="figure" target="#fig_0">Fig. 1</ref> demonstrate that the FS-S learner predicts a vast number of false-positive pixels and results in poor performances. In contrast, the FS-CS learner successfully distinguishes the region of interest by analyzing the semantic relevance of the query objects between the support set. <ref type="table" target="#tab_3">Tables 3 and 4</ref> compare the results of the recent few-shot semantic segmentation methods and ASNet on the conven-  <ref type="table" target="#tab_3">Table 5</ref>. Ablation study of the AS layer on 1-way 1-shot on Pascal-5 i [65] using ResNet50 <ref type="bibr" target="#b22">[23]</ref>. tional FS-S task. All model performances in the tables are taken from corresponding papers, and the numbers of learnable parameters are either taken from papers or counted from their official sources of implementation. For a fair comparison with each other, some methods that incorporate extra unlabeled images <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b92">92]</ref> are reported as their model performances measured in the absence of the extra data. Note that ASNet in <ref type="table" target="#tab_3">Tables 3 and 4</ref> is trained and evaluated following the FS-S setup, not the proposed FS-CS one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Comparison with recent FS-S methods on FS-S</head><p>The results verify that ASNet outperforms the existing methods including the most recent ones <ref type="bibr" target="#b88">[88,</ref><ref type="bibr" target="#b90">90,</ref><ref type="bibr" target="#b92">92]</ref>. Especially, the methods that cast few-shot segmentation as the task of correlation feature transform, ASNet and HSNet <ref type="bibr" target="#b44">[45]</ref>, outperform other visual feature transform methods, indicating that learning correlations is beneficial for both FS-CS and FS-S. Note that ASNet is the most lightweight among others as ASNet processes correlation features that have smaller channel dimensions, e.g., at most 128, than visual features, e.g., at most 2048 in ResNet50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Analyses on the model architecture</head><p>We perform ablation studies on the model architecture to reveal the benefit of each component. We replace the global self-attention in the ASNet layer with the local self-attention <ref type="bibr" target="#b54">[55]</ref> to see the effect of the global selfattention <ref type="table" target="#tab_3">(Table 5a</ref>). The local self-attention variant is compatible with the global ASNet in terms of the classification exact ratio but degrades the segmentation mIoU significantly, signifying the importance of the learning the global context of feature correlations. Next, we ablate the attention masking in Eq. <ref type="bibr" target="#b10">(11)</ref>, which verifies that the attention masking prior is effective <ref type="table" target="#tab_3">(Table 5b)</ref>. Lastly, we replace the multi-layer fusion path with spatial average pooling over the support dimensions followed by element-wise addition (Table 5c), and the result indicates that it is crucial to fuse outputs from the multi-layer correlations to precisely estimate class occurrence and segmentation masks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Discussion</head><p>We have introduced the integrative task of few-shot classification and segmentation (FS-CS) that generalizes two existing few-shot learning problems. Our proposed integrative few-shot learning (iFSL) framework is shown to be effective on FS-CS, in addition, our proposed attentive squeeze network (ASNet) outperforms recent state-of-theart methods on both FS-CS and FS-S. The iFSL design allows a model to learn either with weak or strong labels, that being said, learning our method with weak labels achieves low segmentation performances. This result opens a future direction of effectively boosting the segmentation performance leveraging weak labels in the absence of strong labels for FS-CS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Detailed model architecture</head><p>The comprehensive configuration of attentive squeeze network is summarized in Table a.6, and its building block, attentive squeeze layer, is depicted in <ref type="figure">Fig. a.6</ref>. The channel sizes of the input correlation {C <ref type="bibr" target="#b0">(1)</ref> in , C <ref type="bibr" target="#b1">(2)</ref> in , C <ref type="bibr" target="#b2">(3)</ref> in } corresponds to {4, 6, 3}, {4, 23, 3}, {3, 3, 1} for ResNet50 <ref type="bibr" target="#b22">[23]</ref>, ResNet101, VGG-16 <ref type="bibr" target="#b67">[68]</ref>, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Implementation details</head><p>Our framework is implemented on PyTorch <ref type="bibr" target="#b50">[51]</ref> using the PyTorch Lightning <ref type="bibr" target="#b13">[14]</ref> framework. To reproduce the existing methods, we heavily borrow publicly available code bases. <ref type="bibr" target="#b2">3</ref> We set the officially provided hyperparameters for each method while sharing generic techniques for all the methods, e.g., excluding images of small support objects for support sets or switching the role between the query and the support during training. NVIDIA GeForce RTX 2080 Ti GPUs or NVIDIA TITAN Xp GPUs are used in all experiments, where we train models using two GPUs on Pascal-5 i [65] while using four GPUs on COCO-20 i <ref type="bibr" target="#b47">[48]</ref>. Model training is halt either when it reaches the maximum 500 th epoch or when it starts to overfit. We resize input images to 400 ? 400 without any data augmentation strategies during both training and testing time for all methods. For segmentation evaluation, we recover the two-channel output foreground map to its original image size by bilinear interpolation. Pascal-5 i and COCO-20 i is derived from Pascal Visual Object Classes 2012 <ref type="bibr" target="#b12">[13]</ref> and Microsoft Common Object in Context 2014 <ref type="bibr" target="#b36">[37]</ref>, respectively. To construct episodes from datasets, we sample support sets such that one of the query classes is included in the support set by the probability of 0.5 to balance the ratio of background episodes across arbitrary benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Further analyses</head><p>In this subsection we provide supplementary analyses on the iFSL framework and ASNet. All experimental results are obtained using ResNet50 on Pascal-5 i and evaluated with 1-way 1-shot episodes unless specified otherwise. The classification occurrence threshold ?. Equation 2 in the main paper describes the process of detecting object classes on the shared foreground map by thresholding the highest foreground probability response on each foreground map. As the foreground probability is bounded from 0 to 1, we set the threshold ? = 0.5 for simplicity. A high threshold value makes a classifier reject insufficient probabilities as class presences. <ref type="figure" target="#fig_7">Figure a.7</ref> shows the classifica-  <ref type="figure">Fig. 2</ref> in the main paper. The top of the table is the input of the model and the detailed architecture of the model below it. AS(Cin ? Cout, k, s, p) denotes an AS layer of the kernel size (k), stride (s), padding size (p) for the convolutional embedding with the input channel (Cin) and output channel (Cout). tion 0/1 exact ratios by varying the threshold, which reaches the highest classification performance around ? = 0.5 and 0.6. Fine-tuning the threshold for the best classification performance is not the focus of this work, thus we opt for the most straightforward threshold ? = 0.5 for all experiments.   iFSL with weak labels, strong labels, and both. Table a.7 compares FS-CS performances of three ASNets each of which trained with the classification loss (Eq. (6) in the main paper), the segmentation loss (Eq. <ref type="bibr" target="#b6">(7)</ref> in the main paper), or both. The loss is chosen upon the level of supervisions on support sets; classification tags (weak labels) or segmentation annotations (strong labels). We observe that neither the classification nor segmentation performances deviate significantly between L S and L C + L S ; their per-formances are not even 0.3%p different. As a segmentation annotation is a dense form of classification tags, thus the classification loss influences insignificantly when the segmentation loss is used for training. We thus choose to use the segmentation loss exclusively in the presence of segmentation annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Additional results</head><p>Here we provide several extra experimental results that are omitted in the main paper due to the lack of space. The contents include results using other backbone networks, another evaluation metric, and K shots where K &gt; 1.</p><p>iFSL on FS-CS using ResNet101. We include the FS-CS results of the iFSL framework on Pascal-5 i using ResNet101 <ref type="bibr" target="#b22">[23]</ref> in <ref type="table" target="#tab_3">Table a</ref>.8, which is missing in the main paper due to the page limit. All other experimental setups are matched with those of <ref type="table" target="#tab_3">Table 1</ref> in the main paper except for the backbone network. ASNet also shows greater performances than the previous methods on both classification and segmentation tasks with another backbone.</p><p>FS-CS classification metrics: 0/1 exact ratio and accuracy. Table a.9 presents the results of two classification evaluation metrics of FS-CS: 0/1 exact ratio <ref type="bibr" target="#b11">[12]</ref> and classification accuracy. The classification accuracy metric takes the average of correct predictions for each class for each query, while 0/1 exact ratio measures the binary correctness for all classes for each query, thus being stricter than the accuracy; the exact formulations are in Sec. 6.1. of the main paper. ASNet shows higher classification performance in both classification metrics than others.</p><p>iFSL on 5-shot FS-CS. Tables a.10 and a.11 compares four different methods on the 1-way 5-shot and 2-way 5-shot FS-CS setups, which are missing in the main paper due to the page limit. All other experimental setups are matched with those of <ref type="table" target="#tab_3">Table 1</ref> in the main paper except for the number of support samples for each class, i.e., varying K shots. ASNet also outperforms other methods on the multi-shot setups.</p><p>ASNet on FS-S using VGG-16. Table a.12 compares the recent state-of-the-art methods and ASNet on FS-S using VGG-16 <ref type="bibr" target="#b67">[68]</ref>. We train and evaluate ASNet with the FS-S problem setup to fairly compare with the recent methods. All the other experimental variables are detailed in Sec. 6.3. and <ref type="table" target="#tab_3">Table 3</ref> of the main paper. ASNet consistently shows outstanding performances using the VGG-16 backbone network as observed in experimnets using ResNets.</p><p>Qualitative results. We attach additional segmentation predictions of ASNet learned with the iFSL framework on the FS-CS task in <ref type="figure">Fig. a.9</ref>. We observe that ASNet successfully predicts segmentation maps at challenging scenarios in the wild such as a) segmenting tiny objects, b) segmenting non-salient objects, c) segmenting multiple objects, and   is trained on either FS-S or FS-CS setup and evaluated on the 2-way 1-shot FS-CS setup. The results demonstrate that ASNet FS-S is unaware of object classes and gives foreground predictions on any existing objects, whereas ASNet FS-CS effectively distinguishes the object classes based on the support classes and produces clean and adequate segmentation maps. Fold-wise results on COCO-20 i . Tables a.14 and a.15 present fold-wise performance comparison on the FS-CS and FS-S tasks, respectively. We validate that ASNet outperforms the competitors by large margins in both the FS-CS and FS-S tasks on the challenging COCO-20 i benchmark.</p><p>Numerical performances of <ref type="figure" target="#fig_4">Fig. 4</ref> in the main paper. We report the numerical performances of the <ref type="figure" target="#fig_4">Fig. 4</ref> in the main paper in <ref type="table" target="#tab_3">Table a</ref>.13 as a reference for following research.  <ref type="figure" target="#fig_4">Fig. 4</ref> in the main paper: FS-CS performances on N -way 1-shot by varying N from 1 to 5.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Top: Integrative few-shot learning framework (iFSL) for integrative few-shot classification and segmentation (FS-CS).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>U</head><label></label><figDesc>?2 bi-linear upsampling convs 2D convs. on query dims.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 . 2 - 1 N 1 Cc</head><label>3211</label><figDesc>way 1-shot segmentation results of ASNet on FS-CS.The examples cover all three cases of C = ?, C ? Cs, and C = Cs. The images are resized to square shape for visualization. class sets and cross-validated. For multi-label classification evaluation metrics, we use the 0/1 exact ratio ER = 1[y gt = y C ]<ref type="bibr" target="#b11">[12]</ref>. In the supplementary material, we also report the results in accuracy acc = For segmentation, we use mean IoU mIoU = IoU c<ref type="bibr" target="#b64">[65,</ref><ref type="bibr" target="#b80">80]</ref>, where IoU c denotes an IoU value of c th class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>N -way 1-shot FS-CS performance comparison of four methods by varying N from 1 to 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Results of task transfer. A ? B denotes a model trained on task A and evaluated on task B. FS-CSw denotes FS-CS with weak labels. (a): Exclusive 2-way 1-shot classification accuracy of FS-C or FS-CSw learners on FS-C. (b): 1-way 1-shot segmentation mIoU of FS-S or FS-CS learners on FS-CS. (c): 1-way 1-shot segmentation mIoU of FS-S or FS-CS learners on FS-S.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure a. 7 .</head><label>7</label><figDesc>Classification threshold ? and its effects.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure a. 8 .</head><label>8</label><figDesc>1st support (blue) 2nd support (red) query (prediction) query (ground truth) Visualization of background map for each support class and the merged background map Ybg for the query. High background response is illustrated in black.Visualization of Y bg .Figure a.8 visually demonstrates the background merging step of iFSL in Eq. (3) in the main paper. The background maps are taken from the 2-way 1-shot episodes. The background response of the negative class is relatively even, i.e., the majority of pixels are estimated as background, whereas the background response of the positive class highly contributes to the merged background map.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure a. 9 . 2 -</head><label>92</label><figDesc>way 1-shot FS-CS segmentation prediction maps on the COCO-20 i benchmark. d) segmenting a query given a small support object annotation. Qualitative results of ASNet FS-S . Figure a.10 visualizes typical failure cases of the ASNet FS-S model in compari-son with ASNet FS-CS ; these examples qualitatively show the severe performance drop of ASNet FS-S on FS-CS, which is quantitatively presented in Fig. 5 (b) of the main paper. Sharing the same architecture of ASNet, each model 1st support (blue) 2nd support (red) ASNetFS-S query (prediction) ASNetFS-CS query (prediction) query (ground truth) Figure a.10. 2-way 1-shot FS-CS segmentation prediction maps of ASNetFS-S and ASNetFS-CS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>20 0</head><label>20</label><figDesc>20 1 20 2 20 3 avg. 20 0 20 1 20 2 20 3 avg. 20 0 20 1 20 2 20 3 avg. 20 0 20 1 20 2 20 3 avg.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>67.7 68.8 69.4 69.0 32.8 45.8 31.0 35.1 36.2 56.2 47.5 44.6 55.4 50.9 33.3 46.0 31.2 38.4 37.2 PFENet [75] 69.8 82.4 68.1 77.9 74.6 38.3 54.7 35.1 43.8 43.0 22.5 61.7 40.3 39.5 41.0 31.1 47.3 30.8 32.2 35.3 HSNet [45] 86.6 84.8 76.9 86.3 83.7 49.1 59.7 41.0 49.0 49.7 68.0 73.2 57.0 70.9 67.3 42.4 53.7 34.0 43.9 43.5 ASNetw 86.4 86.3 70.9 84.5 82.0 10.8 20.2 13.1 16.1 15.0 71.6 72.4 46.4 68.0 64.6 11.4 20.8 12.5 15.9 15.1 ASNet 84.9 89.6 79.0 86.2 84.9 51.7 61.5 43.3 52.8 52.3 68.5 76.2 58.6 70.0 68.3 48.5 58.3 36.3 48.3 47.8</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">1-way 1-shot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">2-way 1-shot</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">classification 0/1 exact ratio (%)</cell><cell cols="5">segmentation mIoU (%)</cell><cell cols="5">classification 0/1 exact ratio (%)</cell><cell cols="4">segmentation mIoU (%)</cell><cell></cell></row><row><cell>method</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell>avg.</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell>avg.</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell>avg.</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell>avg.</cell></row><row><cell>PANet [80]</cell><cell>69.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">1-way 1-shot</cell><cell cols="2">2-way 1-shot</cell></row><row><cell>method</cell><cell>ER</cell><cell>mIoU</cell><cell>ER</cell><cell>mIoU</cell></row><row><cell>PANet [80]</cell><cell>66.7</cell><cell>25.2</cell><cell>48.5</cell><cell>23.6</cell></row><row><cell cols="2">PFENet [75] 71.4</cell><cell>31.9</cell><cell>36.5</cell><cell>22.6</cell></row><row><cell>HSNet [45]</cell><cell>77.0</cell><cell>34.3</cell><cell>62.5</cell><cell>29.5</cell></row><row><cell>ASNet</cell><cell>78.6</cell><cell>35.8</cell><cell>63.1</cell><cell>31.6</cell></row></table><note>. Performance comparison of ASNet and others on FS-CS and COCO-20 i [48].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table a .</head><label>a</label><figDesc>6. Comprehensive configuration of ASNet of which overview is illustrated in</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>86.3 70.9 84.5 82.0 10.8 20.2 13.1 16.1 15.0 71.6 72.4 46.4 68.0 64.6 11.4 20.8 12.5 15.9 15.1 ASNet (LS) 84.9 89.6 79.0 86.2 84.9 51.7 61.5 43.3 52.8 52.3 68.5 76.2 58.6 70.0 68.3 48.5 58.3 36.3 48.3 47.8 ASNet (LC + LS) 86.9 87.4 75.8 88.7 84.7 51.6 61.2 42.4 53.2 52.1 70.1 72.4 54.8 74.8 68.0 48.1 57.1 36.0 50.1 47.8 Table a.7. FS-CS results of ASNet trained with iFSL objectives. LC, LS, and LC + LS corresponds to iFSL learning objectives given classification tags, segmentation annotations, or both, respectively. 76.6 74.4 75.5 76.8 33.6 48.6 32.3 37.6 38.0 72.4 64.5 53.4 64.7 63.8 37.4 49.1 33.1 39.7 39.8 PFENet [75] 68.4 83.0 65.8 75.2 73.1 37.7 55.3 34.5 44.8 43.1 25.9 56.2 44.6 38.8 41.4 31.2 47.2 28.9 33.5 35.2 HSNet [45] 86.6 86.6 75.7 86.0 83.7 49.0 60.6 42.5 52.3 51.1 74.6 74.4 55.6 70.8 68.9 40.9 52.0 36.4 47.8 44.3 ASNet 87.2 88.1 77.2 87.2 84.9 53.5 62.0 43.9 55.1 53.6 73.1 76.8 56.7 74.7 70.3 49.5 56.3 40.0 50.0 48.9 Table a.8. FS-CS results on Pascal-5 i using ResNet101.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">1-way 1-shot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">2-way 1-shot</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="5">classification 0/1 exact ratio (%)</cell><cell cols="5">segmentation mIoU (%)</cell><cell cols="5">classification 0/1 exact ratio (%)</cell><cell></cell><cell cols="4">segmentation mIoU (%)</cell></row><row><cell>method</cell><cell></cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell>avg.</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell>avg.</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell>avg.</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell>avg.</cell></row><row><cell>ASNet (LC)</cell><cell></cell><cell cols="5">86.4 1-way 1-shot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">2-way 1-shot</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">classification 0/1 exact ratio (%)</cell><cell cols="5">segmentation mIoU (%)</cell><cell cols="6">classification 0/1 exact ratio (%)</cell><cell cols="4">segmentation mIoU (%)</cell></row><row><cell>method</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell>avg.</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell>avg.</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell cols="2">avg.</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3</cell><cell>avg.</cell></row><row><cell cols="2">PANet [80] 80.8 1st support (blue)</cell><cell cols="2">2nd support (red)</cell><cell cols="3">query (prediction)</cell><cell cols="3">query (ground truth)</cell><cell cols="3">1st support (blue)</cell><cell cols="3">2nd support (red)</cell><cell cols="3">query (prediction)</cell><cell cols="3">query (ground truth)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>PANet [80] 56.2 47.5 44.6 55.4 50.9 74.9 70.2 67.8 74.8 71.9 PFENet [75] 22.5 61.7 40.3 39.5 41.0 64.1 79.5 66.4 66.1 69.0 HSNet [45] 68.0 73.2 57.0 70.9 67.3 82.4 85.6 76.0 84.5 82.1 ASNetw 71.6 72.1 46.4 68.0 64.6 84.9 85.4 69.2 82.2 80.4 ASNet 68.5 76.2 58.6 70.0 68.3 82.9 87.5 76.7 84.0 82.8 Table a.9. FS-CS classification accuracy (%) and 0/1 exact ratio (%) on Pascal-5 i using ResNet50.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">2-way 1-shot</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">classification 0/1 exact ratio (%)</cell><cell cols="4">classification accuracy (%)</cell></row><row><cell>method</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3 avg.</cell><cell>5 0</cell><cell>5 1</cell><cell>5 2</cell><cell>5 3 avg.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table a .</head><label>a</label><figDesc>12. FS-S results on 1-way 1-shot and 1-way 5-shot setups on PASCAL-5 i using VGG-16<ref type="bibr" target="#b67">[68]</ref> and ResNet101<ref type="bibr" target="#b22">[23]</ref>.PANet  [80] 69.0 50.9 39.3 29.1 22.2 36.2 37.2 37.1 36.6 35.3 PFENet [75] 74.6 41.0 24.9 14.5 7.9 43.0 35.3 30.8 27.6 24.9 HSNet [45] 82.7 67.3 52.5 45.2 36.8 49.7 43.5 39.8 38.1 36.2 ASNet 84.9 68.3 55.8 46.8 37.3 52.3 47.8 45.4 44.5 42.4 Table a.13. Numerical results of</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">N -way 1-shot</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">classification 0/1 exact ratio (%)</cell><cell cols="4">segmentation mIoU (%)</cell><cell></cell></row><row><cell>method</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>PANet<ref type="bibr" target="#b80">[80]</ref> 64.<ref type="bibr" target="#b2">3</ref> 66.5 68.0 67.9 66.7 25.5 24.7 25.7 24.7 25.2 42.5 49.9 53.6 47.8 48.5 24.9 25.0 23.3 21.4 23.6 PFENet [75] 70.7 70.6 71.2 72.9 71.4 30.6 34.8 29.4 32.6 31.9 35.6 34.3 43.1 32.8 36.5 23.3 23.8 20.2 23.1 22.6 HSNet [45] 74.7 77.2 78.5 77.6 77.0 36.2 34.3 32.9 34.0 34.3 57.7 62.4 67.1 62.6 62.5 28.9 29.6 30.3 29.3 29.5 ASNet 76.2 78.8 79.2 80.2 78.6 35.7 36.8 35.3 35.6 35.8 59.5 61.5 68.8 62.4 63.1 29.8 33.0 33.4 30.4 31.6 Table a.14. Fold-wise FS-CS results on COCO-20 i using ResNet50. The results correspond to theTable 2in the main paper.Table a.15. Fold-wise FS-S results on 1-way 1-shot and 1-way 5-shot setups on COCO-20 i using ResNet50 (R50) and ResNet101 (R101).</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">1-way 1-shot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">1-way 5-shot</cell><cell></cell><cell></cell><cell># learn.</cell></row><row><cell></cell><cell>method</cell><cell>20 0</cell><cell>20 1</cell><cell>20 2</cell><cell>20 3</cell><cell cols="3">mIoU FBIoU 20 0</cell><cell>20 1</cell><cell>20 2</cell><cell>20 3</cell><cell cols="3">mIoU FBIoU params.</cell></row><row><cell></cell><cell>RPMM [91]</cell><cell cols="4">29.5 36.8 28.9 27.0</cell><cell>30.6</cell><cell>-</cell><cell cols="4">33.8 42.0 33.0 33.3</cell><cell>35.5</cell><cell>-</cell><cell>38.6 M</cell></row><row><cell></cell><cell>RePRI [3]</cell><cell cols="4">31.2 38.1 33.3 33.0</cell><cell>34.0</cell><cell>-</cell><cell cols="4">38.5 46.2 40.0 43.6</cell><cell>42.1</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>MMNet [88]</cell><cell cols="4">34.9 41.0 37.2 37.0</cell><cell>37.5</cell><cell>-</cell><cell cols="4">37.0 40.3 39.3 36.0</cell><cell>38.2</cell><cell>-</cell><cell>10.4 M</cell></row><row><cell>R50</cell><cell>MLC [92]</cell><cell cols="4">46.8 35.3 26.2 27.1</cell><cell>33.9</cell><cell>-</cell><cell cols="4">54.1 41.2 34.1 33.1</cell><cell>40.6</cell><cell>-</cell><cell>8.7 M</cell></row><row><cell></cell><cell>CMN [90]</cell><cell cols="4">37.9 44.8 38.7 35.6</cell><cell>39.3</cell><cell>61.7</cell><cell cols="4">42.0 50.5 41.0 38.9</cell><cell>43.1</cell><cell>63.3</cell><cell>-</cell></row><row><cell></cell><cell>HSNet [45]</cell><cell cols="4">36.3 43.1 38.7 38.7</cell><cell>39.2</cell><cell>68.2</cell><cell cols="4">43.3 51.3 48.2 45.0</cell><cell>46.9</cell><cell>70.7</cell><cell>2.6 M</cell></row><row><cell></cell><cell>ASNet</cell><cell cols="4">41.5 44.1 42.8 40.6</cell><cell>42.2</cell><cell>68.8</cell><cell cols="4">47.6 50.1 47.7 46.4</cell><cell>47.9</cell><cell>71.6</cell><cell>1.3 M</cell></row><row><cell></cell><cell>FWB [48]</cell><cell cols="4">17.0 18.0 21.0 28.9</cell><cell>21.2</cell><cell>-</cell><cell cols="4">19.1 21.5 23.9 30.1</cell><cell>23.7</cell><cell>-</cell><cell>43.0 M</cell></row><row><cell></cell><cell>DAN [79]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>24.4</cell><cell>62.3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>29.6</cell><cell>63.9</cell><cell>-</cell></row><row><cell></cell><cell>PFENet [75]</cell><cell cols="4">34.3 33.0 32.3 30.1</cell><cell>32.4</cell><cell>58.6</cell><cell cols="4">38.5 38.6 38.2 34.3</cell><cell>37.4</cell><cell>61.9</cell><cell>10.8 M</cell></row><row><cell>R101</cell><cell cols="5">SAGNN [89] 36.1 41.0 38.2 33.5</cell><cell>37.2</cell><cell>60.9</cell><cell cols="4">40.9 48.3 42.6 38.9</cell><cell>42.7</cell><cell>63.4</cell><cell>-</cell></row><row><cell></cell><cell>MLC [92]</cell><cell cols="4">50.2 37.8 27.1 30.4</cell><cell>36.4</cell><cell>-</cell><cell cols="4">57.0 46.2 37.3 37.2</cell><cell>44.4</cell><cell>-</cell><cell>27.7 M</cell></row><row><cell></cell><cell>HSNet [45]</cell><cell cols="4">37.2 44.1 42.4 41.3</cell><cell>41.2</cell><cell>69.1</cell><cell cols="4">45.9 53.0 51.8 47.1</cell><cell>49.5</cell><cell>72.4</cell><cell>2.6 M</cell></row><row><cell></cell><cell>ASNet</cell><cell cols="4">41.8 45.4 43.2 41.9</cell><cell>43.1</cell><cell>69.4</cell><cell cols="4">48.0 52.1 49.7 48.2</cell><cell>49.5</cell><cell>72.7</cell><cell>1.3 M</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We sample 2-way 1-shot episodes having a single positive class for training on FS-C or evaluating on FS-C. We collect 1-way 1-shot episodes sampled from the same class for training on FS-S or evaluating on FS-S.1-way 1-shot1-way 5-shot # learn.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">PANet [80]: https://github.com/kaixin96/PANet PFENet [75]: https : / / github . com / dvlab -research / PFENet HSNet [45]: https://github.com/juhongm999/hsnet conv( !" ? #$, k, s, p) matrix multiplication (masking &amp;) softmax matrix multiplication add &amp; norm conv( !" ? #$ , k, s, p) or identity</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">-way 5-shot 2-way 5-shot</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements.</head><p>This work was supported by Samsung Advanced Institute of Technology (SAIT) and also by Center for Applied Research in Artificial Intelligence (CARAI) grant funded by DAPA and ADD (UD190031RD).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MLP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MLP add &amp; norm</head><p>Attentive Squeeze layer</p><p>Figure a.6. Illustration of the proposed attentive squeeze layer (Sec. 5.1. in the main paper). The shape of each output tensor is denoted next to arrows. p = 1 p = 2 p = 3 </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Infinite mixture prototypes for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelsey</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanul</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning (ICML)</title>
		<meeting>International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable closedform solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Few-shot segmentation without meta-learning: A good transductive inference is all you need?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malik</forename><surname>Boudiaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hoel</forename><surname>Kervadec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Ziko Imtiaz Masud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Piantanida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Ben Ayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dolz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning multi-label scene classification. Pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Matthew R Boutell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher M</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brown</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">End-to-end incremental learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><forename type="middle">J</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicol?s</forename><surname>Mar?n-Jim?nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Guil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karteek</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alahari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<idno>2017. 1</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multi-label learning from single positive labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elijah</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><surname>Mac Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Titouan</forename><surname>Lorieul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nebojsa</forename><surname>Jojic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guneet</forename><surname>Singh Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Few-shot semantic segmentation with prototype learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanqing</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conference (BMVC)</title>
		<meeting>British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning a deep convnet for multi-label classification with partial labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibaut</forename><surname>Durand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazanin</forename><surname>Mehrasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Pytorch lightning. GitHub</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wa Falcon</surname></persName>
		</author>
		<ptr target="https://github.com/PyTorchLightning/pytorch-lightningCitedby" />
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Breaking the closed world assumption in text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geli</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">One-shot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Object classification from a single example utilizing class relevance metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning (ICML)</title>
		<meeting>International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Simpropnet: Improved similarity propagation for few-shot image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Gairola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayur</forename><surname>Hemani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayush</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Krishnamurthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Joint Conference on Artificial Intelligence (IJ-CAI)</title>
		<meeting>International Joint Conference on Artificial Intelligence (IJ-CAI)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Incremental few-shot instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><forename type="middle">Andrei</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bas</forename><surname>Boom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Poppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Query adaptive few-shot object detection with heterogeneous graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangxing</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yicheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Fu</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<biblScope unit="page" from="2021" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Cross attention network for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruibing</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Bingpeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiguang</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Local relation networks for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenda</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Attention-based multi-context guiding for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengwan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Cees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Relational embedding for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahyun</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heeseung</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhong</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML) Workshop on Deep Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Brenden M Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">General multi-label image classification with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Lanchantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicente</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjun</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Towards total scene understanding: Classification, annotation and segmentation in an automatic framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Refinenet: Multi-path refinement networks for highresolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<idno>2017. 4</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Negative margin matters: Understanding margin in few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Anti-aliasing semantic reconstruction for fewshot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Few-shot open-set recognition using metalearning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxiang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>Gang Hua, and Nuno Vasconcelos</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Songyang Zhang, and Xuming He. Part-aware prototype network for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Multi-label text classification with a mixture model trained by em</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Kachites</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI 99 workshop on text learning</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Catastrophic interference in connectionist networks: The sequential learning problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Neal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Psychology of learning and motivation</title>
		<imprint>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Hypercorrelation squeeze for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhong</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahyun</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Hyperpixel flow: Semantic correspondence with multilayer neural features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhong</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Feature weighting and boosting for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khoi</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinisa</forename><surname>Todorovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonwoo</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Fewshot image generation via cross-domain correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Utkarsh</forename><surname>Ojha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Jae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="page" from="2021" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS) Workshop Autodiff</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Low-shot learning with imprinted weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Transductive episodic-wise adaptive metric for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limeng</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yemin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaowei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Conditional networks for fewshot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Rakelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Stand-alone selfattention in vision models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwan</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">H3d-net: Few-shot high-fidelity 3d head reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Ramon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gil</forename><surname>Triginer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janna</forename><surname>Escur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Pumarola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Giro-I Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesc</forename><surname>Moreno-Noguer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<biblScope unit="page" from="2021" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR</title>
		<meeting>International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">icarl: Incremental classifier and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Sylvestre-Alvise Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><forename type="middle">H</forename><surname>Sperl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lampert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Embedding propagation: Smoother manifold for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issam</forename><surname>Pau Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Laradji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Drouin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Unet: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Oriol Vinyals, Razvan Pascanu, Simon Osindero, and Raia Hadsell. Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Andrei A Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sygnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Toward open set recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anderson</forename><surname>Scheirer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Archana</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><forename type="middle">E</forename><surname>Sapkota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Boult</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">One-shot learning for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirreza</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shray</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. British Machine Vision Conference (BMVC)</title>
		<meeting>British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
	<note>Irfan Essa, and Byron Boots</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Weakly supervised few-shot object segmentation using co-attention with visual and semantic embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mennatullah</forename><surname>Siam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naren</forename><surname>Doraiswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Boris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuai</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jagersand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Joint Conference on Artificial Intelligence (IJCAI)</title>
		<meeting>International Joint Conference on Artificial Intelligence (IJCAI)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Amp: Adaptive masked proxies for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mennatullah</forename><surname>Siam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Jagersand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Boosting few-shot semantic segmentation with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyun</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.02266</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Meta-transfer learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoyao</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Tat-Seng Chua, and Bernt Schiele</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Differentiable meta-learning model for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinzhuo</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangkai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AAAI Conference on Artificial Intelligence (AAAI)</title>
		<meeting>AAAI Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Rethinking few-shot image classification: a good embedding is all you need?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Generalized few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.05210</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Prior guided feature enrichment network for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Utku</forename><surname>Evci</surname></persName>
		</author>
		<imprint>
			<pubPlace>Kelvin Xu, Ross Goroshin, Carles Gelada, Kevin Swersky, Pierre-Antoine Manzagol</pubPlace>
		</imprint>
	</monogr>
	<note>et al.</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">A dataset of datasets for learning to learn from few examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meta-Dataset</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Learning Representations (ICLR)</title>
		<meeting>International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Few-shot semantic segmentation with democratic attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haochen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
	<note>Xianbin Cao, and Xiantong Zhen</note>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Panet: Few-shot image semantic segmentation with prototype alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Hao Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtian</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daquan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Pyramid vision transformer: A versatile backbone for dense prediction without convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng-Ping</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaitao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Frustratingly simple few-shot object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">E</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine Learning (ICML)</title>
		<meeting>International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Generalizing from a few examples: A survey on few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lionel</forename><forename type="middle">M</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ni</surname></persName>
		</author>
		<idno>2020. 1</idno>
	</analytic>
	<monogr>
		<title level="j">ACM computing surveys</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Multi-label image recognition by recurrently discovering attentional regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouxia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianshui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijia</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Towards one shot learning by imitation for humanoid robots</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiannis</forename><surname>Demiris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Learning meta-class memory for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxi</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV), 2021</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV), 2021</meeting>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Scaleaware graph neural network for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Guo-Sen Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Few-shot semantic segmentation with cyclic memory network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Guo-Sen Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhou</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Jianbin Jiao, and Ye Qixiang. Prototype mixture models for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. European Conference on Computer Vision (ECCV)</title>
		<meeting>European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Mining latent classes for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">18</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Brinet: Towards bridging the intra-class and inter-class gaps in oneshot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianghui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bairun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaige</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luping</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Describing the scene as a whole: Joint object detection, scene classification and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Few-shot learning via embedding adaptation with set-to-set functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hexiang</forename><surname>Han-Jia Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>De-Chuan Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Prototypical cross-domain selfsupervised learning for few-shot unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zangwei</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanghang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><forename type="middle">Sangiovanni</forename><surname>Vincentelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="page" from="2021" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Self-guided and cross-guided learning for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Deepemd: Few-shot image classification with differentiable earth mover&apos;s distance and structured classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Pyramid graph networks with connection attentions for region-based one-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiushuang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Canet: Class-agnostic segmentation networks with iterative refinement and attentive few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Few-shot 3d point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Na</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Collaborative learning of semisupervised segmentation and classification for medical images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanshan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
