<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LineaRE: Simple but Powerful Knowledge Graph Embedding for Link Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanhui</forename><surname>Peng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanjing University of Science and Technology</orgName>
								<address>
									<addrLine>200 Xiaolingwei Street</addrLine>
									<postCode>210094</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Zhang</surname></persName>
							<email>jzhang@njust.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Nanjing University of Science and Technology</orgName>
								<address>
									<addrLine>200 Xiaolingwei Street</addrLine>
									<postCode>210094</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LineaRE: Simple but Powerful Knowledge Graph Embedding for Link Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-knowledge graph</term>
					<term>embedding</term>
					<term>link prediction</term>
					<term>linear regression</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The task of link prediction for knowledge graphs is to predict missing relationships between entities. Knowledge graph embedding, which aims to represent entities and relations of a knowledge graph as low dimensional vectors in a continuous vector space, has achieved promising predictive performance. If an embedding model can cover different types of connectivity patterns and mapping properties of relations as many as possible, it will potentially bring more benefits for link prediction tasks. In this paper, we propose a novel embedding model, namely LineaRE, which is capable of modeling four connectivity patterns (i.e., symmetry, antisymmetry, inversion, and composition) and four mapping properties (i.e., one-to-one, one-to-many, manyto-one, and many-to-many) of relations. Specifically, we regard knowledge graph embedding as a simple linear regression task, where a relation is modeled as a linear function of two lowdimensional vector-presented entities with two weight vectors and a bias vector. Since the vectors are defined in a real number space and the scoring function of the model is linear, our model is simple and scalable to large knowledge graphs. Experimental results on multiple widely used real-world datasets show that the proposed LineaRE model significantly outperforms existing state-of-the-art models for link prediction tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The construction and applications of knowledge graphs have attracted much attention in recent years. Many knowledge graphs, such as WordNet <ref type="bibr" target="#b8">[9]</ref>, DBpedia <ref type="bibr" target="#b9">[10]</ref>, and Freebase <ref type="bibr" target="#b10">[11]</ref>, have been built and successfully applied to some AI domains, including information retrieval <ref type="bibr" target="#b11">[12]</ref>, recommender systems <ref type="bibr" target="#b12">[13]</ref>, question-answering systems <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, and natural language processing <ref type="bibr" target="#b15">[16]</ref>. A large knowledge graph stores billions of factual triplets in the form of directed graphs, where each triplet in the form of (head entity, relation, tail entity) (denoted by (h, r, t) in this paper) stands for an edge with two end nodes in the graph, indicating that there exists a specific relationship between the head and tail entities. However, knowledge graphs still suffer from incompleteness, and link prediction, which predicts relations between entities according to existing triplets, is an important way to knowledge completion <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>. On a graph with this kind of symbolic representation, algorithms that compute semantic relationships between entities usually have high computational complexity</p><p>The corresponding author of the paper is Jing Zhang. The source code is available at: https://github.com/pengyanhui/LineaRE. and lack scalability. Therefore, knowledge graph embedding is proposed to improve the calculation efficiency. By embedding entities and relations into a low-dimensional vector space, we can efficiently implement the operations such as the calculation of semantic similarity between entities, which is of considerable significance to the completion, reasoning, and applications of knowledge graphs.</p><p>Quite a few methods <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref> have been proposed for knowledge graph embedding. Given a knowledge graph, these methods first assign one or more vectors (or matrices) to each entity and relation, then define a scoring function f r (h, t) to measure the plausibility of each triplet, and finally maximize the global plausibility of all triplets. Thus, scoring functions play a critical role in the methods, which determine the capability and computational complexity of models. The capability of a model is primarily influenced by the variety of connectivity patterns and mapping properties of relations it can model. In a knowledge graph, following <ref type="bibr" target="#b7">[8]</ref>, we have four connectivity patterns of relations:</p><p>? Symmetry. A relation r is symmetric if ?x, y : r(x, y) ? r(y, x)</p><p>? Antisymmetry. A relation r is antisymmetric if ?x, y : r(x, y) ? ?r(y, x)</p><p>? Inversion. Relation r 1 is inverse to relation r 2 if ?x, y : r 1 (x, y) ? r 2 (y, x)</p><p>? Composition. Relation r 1 is composed of relation r 2 and relation r 3 if ?x, y, z : r 2 (x, y) ? r 3 (y, z) ? r 1 (x, z) Also, following <ref type="bibr" target="#b0">[1]</ref>, we have four mapping properties of relations:</p><p>? One-to-One (1-to-1). Relation r is 1-to-1 if a head can appear with at most one tail. ? One-to-Many (1-to-N). Relation r is 1-to-N if a head can appear with many tails. ? Many-to-One (N-to-1). Relation r is N-to-1 if many heads can appear with the same tail. ? Many-to-Many (N-to-N). Relation r is N-to-N if many heads can appear with many tails.</p><p>We call the latter three relations (i.e., 1-to-N, N-to-1, and Nto-N ) as the complex mapping properties. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Scoring function fr(h, h) # Parameters TransE <ref type="bibr" target="#b0">[1]</ref> h</p><formula xml:id="formula_0">+ r ? t 1/2 h, t, r ? R k TransH [2] (h ? w r hwr) + dr ? (t ? w r twr) 2 2 h, t, wr, dr ? R k TransR [3] Mrh + r ? Mrt 2 2 h, t ? R k , r ? R d , Mr ? R k?d TransD [4] (rph p + I k?d )h + r ? (rpt p + I k?d )t 2 2 h, hp, t, tp ? R d , r, rp ? R k DistMult [5] h diag(r)t h, t, r ? R k ComplEx [6] Re(h diag(r)t) h, t, r ? C k ConvE [7] &lt; ?(vec(?([r,h] * ?))W ), t &gt; h, t, r ? R k RotatE [8] h ? r ? t 1 h, t, r ? C k , |r i | = 1 LineaRE (Our model) w 1 r ? h + br ? w 2 r ? t 1 h, t, br, w 1 r , w 2 r , ? R k &lt; ? &gt; denotes the generalized dot product.</formula><p>? denotes the Hadamard product. ? denotes activation function and * denotes 2D convolution. ? denotes conjugate for complex vectors, and 2D reshaping for real vectors in ConvE model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Symmetry Antisymmetry Inversion Composition Complex mapping properties</head><formula xml:id="formula_1">TransE - - TransX a - - DistMult - - - ComplEx - RotatE</formula><p>-LineaRE (Our model) a TransX represents a wide range of TransE's <ref type="bibr" target="#b0">[1]</ref> variants, such as TransH <ref type="bibr" target="#b1">[2]</ref>, TransR <ref type="bibr" target="#b2">[3]</ref>, and TransD <ref type="bibr" target="#b3">[4]</ref>. Results with respect to connectivity patterns are taken from <ref type="bibr" target="#b7">[8]</ref>.</p><p>If an embedding method could model connectivity patterns and mapping properties as many as possible, it would potentially benefit the link prediction task. This is because methods with stronger modeling ability can preserve more structural information of knowledge graphs, so that the embeddings of entities and relations have more precise semantics. For example, in a link prediction task, a model has learned that the relation Nationality is a Composition of BornIn and LocatedIn. When triplets (Tom, BornIn, New York), (New York, Locate-dIn, United States) both hold, it can infer that triplet (Tom, Nationality, United States) holds. Another negative instance is that if a method cannot model N-to-1 mapping property, it probably treats Leonardo DiCaprio and Kate Winslet as the same entity when it reads relations (Leonardo DiCaprio, ActorIn, Titanic) and (Kate Winslet, ActorIn, Titanic).</p><p>In this paper, we proposed a novel method, namely Linear Regression Embedding (LineaRE), which interprets a relation as a linear function of entities head and tail. Specifically, our model represents each entity as a low-dimensional vector (denoted by h or t), and each relation as two weight vectors and a bias vector (denoted by w 1 r , w 2 r , and b r ), where h, t, w 1 r , w 2 r , and b r ? R k . Given a golden triplet (h, r, t), we expect the equation</p><formula xml:id="formula_2">w 1 r ? h + b r = w 2 r ? t,</formula><p>where ? denotes the Hadamard (element-wise) product <ref type="bibr" target="#b0">1</ref> . <ref type="table" target="#tab_0">Tables I &amp; II</ref> summarize the scoring functions and the modeling capabilities of some state-of-the-art knowledge graph embedding methods, respectively. <ref type="table" target="#tab_0">Table I</ref>  and RotatE are defined in complex number spaces and those of the others (including our model) are defined in real number spaces. Compared with most of the other models, the scoring function of our LineaRE is simpler. <ref type="table" target="#tab_0">Table II</ref> shows that, some of them (such as TransE and RotatE) are better at modeling connectivity patterns but do not consider complex mapping properties. In contrast, some others (TransH and DistMult) are better at modeling complex mapping properties but sacrifice some capability to model connectivity patterns. Our LineaRE has the most comprehensive modeling capability.</p><p>We summarize the main contributions of this paper as follows:</p><p>1) We propose a novel method LineaRE for knowledge graph embedding, which is simple and can cover all the above connectivity patterns and mapping properties. 2) We provide formal mathematical proofs to demonstrate the modeling capabilities of LineaRE. 3) We conduct extensive experiments to evaluate our Lin-eaRE on the task of link prediction on several benchmark datasets. The experimental results show that LineaRE has significant improvements compared with the existing state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Knowledge graph embedding models can be roughly categorized into two groups <ref type="bibr" target="#b20">[21]</ref>: translational distance models and semantic matching models. In this section, we will briefly describe some related models and the differences between our models and them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Translational Distance Models</head><p>The most classic translational distance model is TransE <ref type="bibr" target="#b0">[1]</ref>. Given a triplet (h, r, t), TransE interprets the relation as a translation r from the head entity h to the tail entity t, i.e., h + r ? t, where h, t, r ? R k . When a relation is symmetric, its vector will be represented by 0, resulting in TransE being unable to distinguish different symmetric relations. In addition, TransE has issues in dealing with 1-to-N, N-to-1, and N-to-N relations. TransH <ref type="bibr" target="#b1">[2]</ref> was proposed to address the issues of TransE in modeling complex mapping properties, which interprets a relation as a translating operation d r on a hyperplane (defined by a relation-specific normal vector w r ). For a triplet (h, r, t), the embeddings h and t are first projected to the hyperplane, and then connected by d r . TransR <ref type="bibr" target="#b2">[3]</ref> supposes that entities have multiple aspects and various relations may focus on different aspects of entities. So, entity embeddings are first projected from entity space to corresponding relation space by a relation-specific projecting matrix M r , and then connected by a translation vector r. Because of the high space and time complexity of matrix operation, TransR cannot be applied to large-scale knowledge graphs. TransD <ref type="bibr" target="#b3">[4]</ref> is an improvement of TransR, which uses entity projecting vectors (h p and t p ) and relation projecting vectors (r p ) to construct mapping matrices dynamically. However, reference <ref type="bibr" target="#b7">[8]</ref> has proved that such projection-based variants of TransE can not model inversion and composition patterns.</p><p>RotatE <ref type="bibr" target="#b7">[8]</ref> represents each entity (relation) as a complex vector, and interprets the relation as a rotation from the head entity to the tail entity on the complex plane for a triplet. RotatE can model all the above connectivity patterns, but does not consider the complex mapping properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Semantic Matching Models</head><p>Semantic matching models measure plausibility of facts by matching latent semantics of entities and relations embodied in their vector space representations <ref type="bibr" target="#b20">[21]</ref>. These models can be further divided into two categories: bilinear models and neural network-based models. a) Bilinear Models: RESCAL <ref type="bibr" target="#b21">[22]</ref> is a classic bilinear model, which represents each entity as a vector and each relation as a full rank matrix which models pairwise interactions between latent factors, and the score function is defined as f r (h, t) = h M r t. Obviously, such a method has two serious defects: prone to overfitting and can not be applied to large-scale knowledge graphs. DistMult <ref type="bibr" target="#b4">[5]</ref> simplifies RESCAL. For a triplet (h, r, t), the relation is represented as a diagonal matrix to capture pairwise interactions between the components of h and t along the same dimension, i.e., M r is restricted to a diagonal matrix. However, f r (h, t) = h diag(r)t = t diag(r)h = f r (t, h) for any h and t. As a result, DistMult can only deal with symmetric relations. ComplEx <ref type="bibr" target="#b5">[6]</ref> was proposed to address the issues of DistMult in modeling antisymmetric relations by introducing complex-valued embeddings. Unfortunately, ComplEx is still not capable of modeling the composition pattern, and the space and time complexity of the model are considerably increased. b) Neural Network Models: Some semantic matching methods using neural network architectures have also made good progress in recent years. SME <ref type="bibr" target="#b22">[23]</ref> employs two linear networks to capture the semantics of (h, r) and (t, r), respectively, and then measures the plausibility of the whole triplet by the inner product of the two network outputs. While non-linear fully connected neural networks are used in MLP <ref type="bibr" target="#b23">[24]</ref> and NTN <ref type="bibr" target="#b24">[25]</ref>. ConvE <ref type="bibr" target="#b6">[7]</ref> is a multi-layer convolutional network model. The convolution operation is capable of extracting the feature interactions between the two embeddings h and t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Difference between LineaRE and Others</head><p>From the perspective of the form of the scoring function, our proposed model LineaRE is formally similar to TransE and belongs to translational distance models. However, LineaRE is essentially different from other variants of TransE such as TransH <ref type="bibr" target="#b1">[2]</ref>, TransR <ref type="bibr" target="#b2">[3]</ref>, and TransD <ref type="bibr" target="#b3">[4]</ref> which project entities onto a plane or into a specific vector space.</p><p>We regard knowledge graph embedding as a linear regression task. Given an observed triplet (h, r, t), the entity pair (h, t) is treated as a point, and the relation r is treated as a linear mapping between h and t. In fact, we can even regard TransE as a linear regression task, in which the slope is fixed to 1, but TransH <ref type="bibr" target="#b1">[2]</ref>, TransR <ref type="bibr" target="#b2">[3]</ref>, and TransD <ref type="bibr" target="#b3">[4]</ref> can not. One may argue that LineaRE is very similar to TransR if the matrix M r is constrained as a diagonal matrix. However, the slope will be also fixed to 1 in such a simplified TransR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE PROPOSED METHOD</head><p>In this section, we will describe our proposed model Lin-eaRE in detail. First, we provide the formal definition of LineaRE and mathematically prove the powerful modeling capabilities of LineaRE with respect to the connectivity patterns and mapping properties. Then, we introduce the loss function used in our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Linear Regression Embedding</head><p>We treat knowledge graph embedding as a Linear Regression task. A knowledge graph is a directed graph G = (E, R, T ), where E is the set of entities, R is the set of relations, and T = {(h, r, t)} denotes the set of all observed triplets. Let HT r = {(h, t)|(h, r, t) ? T } denote all the entity pairs involving a specific relation r. Our main idea is that entity pairs HT r are treated as points, and the relation r is treated as a linear mapping between head entities and tail entities. For example, {(football, has part, foot), (classroom, has part, room)} is the set of triplets involving relation has part. Our objective is to make the points (football, foot) and (classroom, room) lie on the straight line defined by has part in the rectangular coordinate system.</p><p>Specifically, we represent each entity as a low-dimensional vector (h or t), and each relation as two weight vectors (w 1 r , w 2 r ) and a bias vector (b r ), where h, t, w 1 r , w 2 r , and b r ? R k . Given a golden triplet (h, r, t), we expect</p><formula xml:id="formula_3">w 1 r ? h + b r = w 2 r ? t (1) t h h br t wr 1 wr 2 + = dimension i ? ? 1 [wr ]i ? [h]i + [br]i = [wr ]i ? [t]i 2 ([h0]i, [t0]i) Fig. 1.</formula><p>Simple illustration of LineaRE. The left part is vectorized representation of entities and relations, and the right part illustrates how one dimension of the vectors is represented in a rectangular coordinate system. The point</p><formula xml:id="formula_4">([h 0 ] i , [t 0 ] i ) lies on the straight line defined by ([br] i , [w 1 r ] i , [w 2 r ] i ) if the triplet (h 0 , r, t 0 ) holds.</formula><p>where ? denotes the Hadamard (element-wise) product. <ref type="figure">Fig.  1</ref> provides a simple illustration of LineaRE. For dimension</p><formula xml:id="formula_5">i, we have [w 1 r ] i ? [h] i + [b r ] i = [w 2 r ] i ? [t] i , i.e.</formula><p>, each dimension of the relation can be represented as a straight line in a rectangular coordinate system, and the point (</p><formula xml:id="formula_6">[h] i , [t] i ) should lie on the straight line.</formula><p>The scoring function of LineaRE is:</p><formula xml:id="formula_7">f r (h, t) = w 1 r ? h + b r ? w 2 r ? t 1<label>(2)</label></formula><p>where x 1 denotes the L1-Norm of vector x. We expect a lower score for observed triplets and a higher score for negative triplets which do not hold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Modeling Capabilities of LineaRE</head><p>The connectivity patterns and mapping properties of relations are implicit in the properties of the straight lines. Formally, we have main results as follows:</p><p>Theorem 1. LineaRE can model symmetry, antisymmetry, inversion and composition patterns.</p><p>Proof. With h and t as the axes, LineaRE represents each dimension of a relation as a straight line in the rectangular coordinate system. <ref type="figure" target="#fig_0">Fig. 2</ref> illustrates the LineaRE model in a one-dimensional case.</p><p>? Symmetry (Each straight line of the relation is symmetrical with respect to h = t, shown in <ref type="figure" target="#fig_0">Fig. 2(a)</ref>).</p><formula xml:id="formula_8">w 1 r ? h + b r = w 2 r ? t w 1 r ? t + b r = w 2 r ? h ? ? ? ? ? ? w 1 r = ?w 2 r 1 or h = t 2 1 When w 1 r = ?w 2 r holds, w 1 r ? (h + t) + b r = 0, then we have (h + t) = ?, where ? is a constant vector. The slope of the straight line is ?1. 2 When h = t holds, (w 1 r ? w 2 r ) ? h + b r = 0, then we have w 1 r = w 2 r ? b r = 0, i.e.</formula><p>, the slope is 1 and the intercept is 0. To sum up, when w 1 r = ?w 2 r or w 1 r = w 2 r ? b r = 0, LineaRE can model symmetry pattern.</p><p>? Antisymmetry (There exist some straight lines not symmetrical with respect to h = t in the relation, shown in <ref type="figure" target="#fig_0">Fig. 2(b)</ref>). When w 1 r = ?w 2 r and w 1 r = w 2 r ? b r = 0, LineaRE can model symmetry pattern. In other words, ?i ? <ref type="bibr">[1, k]</ref></p><formula xml:id="formula_9">, [w 1 r ] i = ?[w 2 r ] i and [w 1 r ] i = [w 2 r ] i ? [b r ] i = 0. ? Inversion (</formula><p>The straight lines of r 1 and r 2 along the same dimension are symmetrical with respect to h = t, shown in <ref type="figure" target="#fig_0">Fig. 2(c)</ref>).</p><formula xml:id="formula_10">w 1 r1 ? h + b r1 = w 2 r1 ? t w 1 r2 ? t + b r2 = w 2 r2 ? h ? w 1 r1 ? w 1 r2 = w 2 r1 ? w 2 r2 b r1 ? w 2 r2 + b r2 ? w 1 r1 = b r1 ? w 1 r2 + b r2 ? w 2 r1 = 0</formula><p>That is, the slopes of the straight lines along the same dimension in r 1 and r 2 are mutually reciprocal, and the intercepts are symmetrical with respect to h = t. ? Composition (Composition of linear functions, shown in <ref type="figure" target="#fig_0">Fig. 2(d</ref></p><formula xml:id="formula_11">).) ? ? ? ? ? w 1 r2 ? h + b r2 = w 2 r2 ? e w 1 r3 ? e + b r3 = w 2 r3 ? t w 1 r1 ? h + b r1 = w 2 r1 ? t ? w 1 r1 = w 1 r2 ? w 1 r3 , w 2 r1 = w 2 r2 ? w 2 r3 b r1 = b r2 ? w 1 r3 + b r3 ? w 2 r2</formula><p>r 2 is a linear mapping from h to e, and r 3 is a linear mapping from e to t, then a new linear mapping from h to t (ie., r 1 ) can be obtained by combining r 2 and r 3 . Proof. 1-to-1: Obviously, LineaRE can model 1-to-1 relations. 1-to-N: Suppose that we have two observed triplets (h 0 , r, t 1 ) and (h 0 , r, t 2 ): <ref type="figure" target="#fig_8">Fig. 3(b)</ref>, the straight line is one dimension of relation r, parallel to t axis. Thus h 0 can appear with ?t ? R under relation r. However, [w 2 r ] i may actually be a value approximately equal to 0, resulting in a steep slope of the straight line 2 , as shown in <ref type="figure" target="#fig_8">Fig. 3(a)</ref>. Let ? be the maximum acceptable error, then h 0 can appear with multiple t values with low errors, where t ? [t 1 , t 2 ]. The steeper the slope is, the larger the range of t values is. Thus, multiple tail entities appearing with the same head entity can be appropriately far away from each other in such dimensions.</p><formula xml:id="formula_12">w 1 r ? h 0 + b r = w 2 r ? t 1 w 1 r ? h 0 + b r = w 2 r ? t 2 ? w 2 r ? (t 1 ? t 2 ) = 0 1 w 2 r = 0. As shown in</formula><p>2 t 1 ? t 2 = 0. For the dimensions where t 1 ? t 2 = 0, tail entities are closer        Proof. Let w 1 r = w 2 r , our LineaRE becomes TransE, ie., TransE defines a relation as straight lines with a constant slope of 1, which is a special case of LineaRE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Loss Function</head><p>A knowledge graph only contains positive triplets, and the way to construct negative triplets is to randomly replace the head or tail entity of an observed triplet with entities in E, which is called negative sampling. Many negative sampling methods have been proposed <ref type="bibr" target="#b25">[26]</ref>- <ref type="bibr" target="#b27">[28]</ref>, among which the selfadversarial negative sampling method <ref type="bibr" target="#b7">[8]</ref> dynamically adjusts the weights of negative samples according to their scores as the training goes on. We adopt this negative sampling technique. Specifically, the weights (i.e., probability distribution) of negative triplets for a golden triplet (h, r, t) are as follows:</p><formula xml:id="formula_13">p(h j , r, t j |{(h i , r, t i )}) = exp(?f r (h j , t j )) i exp(?f r (h i , t i ))<label>(3)</label></formula><p>where ? is the temperature of sampling, {(h i , r, t i )} are negative triplets for (h, r, t).</p><p>Then, we define the logistic loss function for an observed triplet and its negative samples:</p><formula xml:id="formula_14">sof tplus(x) = 1 ? log(1 + exp(?x)) (4) L = sof tplus(f r (h, t) ? ?) + n i=1 p(h i , r, t i )sof tplus(? ? f r (h i , t i )) + ? |E| e?E e 2 2<label>(5)</label></formula><p>where ? is a fixed margin, ? is a parameter that can adjust the margin between positive and negative sample scores; ? is the regularization coefficient; E is the set of entities in the knowledge graph. Adam <ref type="bibr" target="#b28">[29]</ref> is used as the optimizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section, we conduct extensive experiments to evaluate the proposed LineaRE model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>Four widely used benchmark datasets are used in our link prediction experiments: FB15k [1], WN18 <ref type="bibr" target="#b0">[1]</ref>, FB15k-237 <ref type="bibr" target="#b29">[30]</ref>, and WN18RR <ref type="bibr" target="#b6">[7]</ref>. The statistical information of these datasets is summarized in <ref type="table" target="#tab_0">Table III.</ref> ? FB15k is a subset of Freebase <ref type="bibr" target="#b10">[11]</ref>. We can see that 70.22% of test triplets (h, r, t) can be inferred via a directly linked triplet (t, r , h) in the training set, and 22.37% of test triplets can be inferred via a two-step or three-step path (h, p, t) in the training set. Thus, the key of link prediction on FB15k is to model inversion and composition patterns. ? WN18 is a subset of WordNet <ref type="bibr" target="#b8">[9]</ref>. The key of link prediction on WN18 is to model inversion and symmetry patterns.   <ref type="figure">, r , h)</ref>) in train set. #Com: test triplets (h, r, t) that can be inferred via a two-step or three-step path (h, p, t) in train set.</p><p>? WN18RR is a subset of WN18, where inverse relations are deleted. The key of link prediction on WN18RR is to model symmetry patterns.</p><p>In all these datasets, triplets involving 1-to-1 relations only account for about 1%. Thus, the methods that can model complex mapping properties will have certain advantages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Settings</head><p>Task Description: Let be the test set and E be the set of all entities in the dataset. For each test triplet (h, r, t) ? , we replace the tail entity t by each entity e i ? E in turn, forming candidate triplets {(h, r, e i )}. Some candidate triplets may exist in the datasets (training, validation, or test sets), and it is common practice to delete them (except the current test triplets). The knowledge graph embedding model is then used to calculate the plausibility of these corrupted triplets and sort them in ascending order. Eventually, the ranks of the correct entities are stored. The prediction process for the head entity is the same.</p><p>Evaluation Protocol: We report several standard evaluation metrics: the Mean of those predicted Ranks (MR), the Mean of those predicted Reciprocal Ranks (MRR), and the Hits@N (i.e., the proportion of correct entities ranked in the top N, where N = 1, 3, 10). A lower MR is better while higher MRR and Hits@N are better.</p><p>Baselines: We compare the proposed model LineaRE with seven state-of-the-art models 3 listed in <ref type="table" target="#tab_0">Table I</ref> on link prediction tasks. These models used in comparison were published in top-tier AI-related conferences, representing the highest technical level of knowledge graph embedding.</p><p>The fairness of the Comparison: For the fairness in comparison, all the models except ConvE use the same negative sampling technique (i.e., the self-adversarial negative sampling method proposed in <ref type="bibr" target="#b7">[8]</ref>), and the hyperparameters of different models are selected from the same ranges. Because ConvE is quite different from the other models in principle, to report its highest performance, we directly extract the experimental results from the original paper <ref type="bibr" target="#b6">[7]</ref>. <ref type="bibr" target="#b2">3</ref> We did not include TransR in the comparison due to its high complexity. Even a NVIDIA GeForce RTX 2080 Ti GPU with 11 GB memory can not run TransR when k = d = 100, batchsize = 512, and 128 negative samples for each observed triplet. Moreover, reference <ref type="bibr" target="#b3">[4]</ref> has demonstrated that TransD is better than TransR.</p><p>Hyperparameter Settings: The hyperparameters are selected according to the performance on the validation dataset via grid searching. We set the ranges of hyperparameters as follows: temperature of sampling ? ? {0.5, 1.0}, fixed margin ? ? {6, <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24</ref>, 30}, ? in softplus ? {0.75, 1.0, 1.25}, embedding size k ? {250, 500, 1000}, batchsize b ? {512, 1024, 2048}, and number of negative samples for each observed triplet n ? {128, 256, 512, 1024}. Optimal configurations for our LineaRE are: ?=1.0, ?=1.25, ?=15, k=1000, b=2048 and n=128 on FB15k; ?=0.5, ?=1.25, ?=6, k=500, b=1024 and n=512 on WN18; ?=0.5, ?=1.0, ?=12, k=1000, b=2048 and n=128 on FB15k-237; ?=0.5, ?=1.0, ?=12, k=1000, b=2048 and n=128 on WN18RR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Main Results</head><p>The main results on FB15k and WN18 are summarized in <ref type="table" target="#tab_0">Table IV</ref>. LineaRE significantly outperforms all those previous state-of-the-art models on almost all the metrics except that TransX performs slightly better than LineaRE on the metric MR on FB15k. <ref type="table">Table V</ref> summarizes the results on FB15k-237 and WN18RR. We can find that no previous model performs better than our LineaRE on any metric.</p><p>In general, if a model can cover the main connectivity patterns and mapping properties in a dataset, it will perform well on this dataset. For example, ComplEx and our LineaRE cover inverse pattern and complex mapping properties, they both perform well on FB15k and WN18. But there is an exception, DistMult achieves good performance on FB15k although it cannot model the antisymmetry and inversion patterns. The reason given by <ref type="bibr" target="#b7">[8]</ref> is that for most of the relations in FB15K, the types of head entities and tail entities are different. For (h, r, t), the triplet (t, r, h) is usually impossible to be valid since the entity type of t does not match the head entity type of h.</p><p>Another exception is that RotatE performs better than Com-plEx on WN18, in which the composition pattern is negligible, while the complex mapping properties are important. The reason is that triplets involving the complex relation that hpt r (or tph r ) 4 is greater than 10 account for 0.89% and 65.1% in WN18 and FB15k, respectively. Thus, the advantage of ComplEx against RotatE in dealing with complex relations is relatively small on WN18. We can find that ComplEx achieves better performance than RotatE on FB15k thanks to the capability of dealing with complex mapping properties.</p><p>Results of TransX on WN18RR: TransX appears extremely poor Hit@1 on WN18RR. The reason is that TransX makes the translation vector be 0 for symmetry relations, and f r (h, h) = h ? + 0 ? h ? 1/2 = 0, then the entity h will rank at 1 when predicting (h, r, ?), i.e., Hit@1 = 0 for almost all symmetry relations. If we remove the candidate entity h when predicting (h, r, ?) and remove the candidate entity t when predicting (?, r, t), then TransE, TransH and TransD have Hit@1 = 0.313, 0.316, 0.324, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Ablation Analysis</head><p>To evaluate the importance of connectivity patterns and complex mapping properties, in this section, we analyze the performance of these models with respect to the connectivity patterns and mapping properties in detail <ref type="table" target="#tab_0">(Refer to Table II</ref>, which summarizes the modeling capabilities of these models).</p><p>a) Symmetry (RotatE and TransE): Among these methods, the difference between RotatE and TransE is only that the former can model symmetric relations and the latter cannot. The performance of RotatE is significantly better than that of TransE, because there are many symmetric relations in all datasets except FB15k-237, especially in WN18RR.</p><p>b) Antisymmetry and Inversion (ComplEx and DistMult): Complex embeddings enable ComplEx to model two more connectivity patterns (antisymmetry and inversion) than Dist-Mult. The former performs better than the latter on all datasets, especially on WN18, in which the main relation patterns are antisymmetry and inversion. c) Composition (LineaRE and ComplEx): Complex can model not only all the connectivity patterns except composition but also the complex mapping properties, which makes it achieve very good performance on all datasets other than on FB15k-237, in which the main connectivity pattern is composition. DistMult, which cannot model composition patterns, also performs poorly on FB15k-237. The difference between our LineaRE and ComplEx is that LineaRE is capable of modeling the composition pattern. Thus, our model performs better, especially on FB15k-237. d) Complex mapping properties (LineaRE and RotatE): RotatE has a powerful modeling capability for all the above connectivity patterns, which makes it perform well on these datasets. However, RotatE is still inferior to our LineaRE because our LineaRE has the same capability of modeling all the connectivity patterns as RotatE does, and further, LineaRE can deal with complex mapping properties that RotatE cannot handle. On the relatively more complex dataset FB15k, our LineaRE archives a more prominent advantage. Recall that triplets involving a complex relation, hpt r (or tph r ) of which is greater than 10, account for 0.89% and 65.1% in datasets WN18 and FB15k, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Experimental Results on FB15k by Relation Category</head><p>Following <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, we also did some further investigation on the performance of LineaRE on different relation categories <ref type="bibr" target="#b4">5</ref> . <ref type="table" target="#tab_0">Table VI summarizes the detailed results</ref> by relation category on FB15k, which shows that our LineaRE achieves the best performance on complex relations. DistMult, ComplEx and LineaRE, which are capable of modeling complex mapping properties, perform well on 1-to-N (predicting tail), N-to-1 (predicting head), and N-to-N relations, while RotatE and TransE both perform worse.</p><p>The performance of TransH and TransD are worse than expected. We believe that these two models reduce their ability in other aspects such as modeling inversion pattern when enhancing their ability to deal with complex relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Investigation of Entity and Relation Embeddings</head><p>To verify our theoretical analysis of the modeling capabilities of LineaRE in Section III-B, we investigate some relevant entity and relation embeddings (500 dimensions on WN18 and 1000 dimensions on FB15k-237). a) Symmetry Pattern: <ref type="figure">Fig. 4(a)</ref> shows the angles between the straight lines of the relation similar to in WN18 and the h axis. Almost all of the 500 angles are equal to or close to 45?o r 135?, i.e. these straight lines are symmetrical with respect to h = t. This provides the evidence for our analysis of LineaRE in modeling the symmetry pattern in Section III-B ( <ref type="figure" target="#fig_0">Fig. 2(a)</ref>). As shown in <ref type="figure">Fig. 5</ref>, we select two representative dimensions of similar to and plot the corresponding straight lines. In <ref type="figure">Fig. 5(a)</ref>, the angle between the first straight line and h axis is 135?, and the angle between the second straight line and h axis is 45?. Moreover, the entity pairs (h, t) are closely distributed on or near the line in our LineaRE, while in TransE, the entity pairs are scattered. This indicates that our LineaRE has better modeling ability than TransE. b) Antisymmetry and Inversion Pattern: Relation hypernym and hyponym in WN18 are a pair of inverse relations. We first inverse hyponym (denoted as hyponym ?1 ), and then calculate the angles between the straight lines of the two relations along the same dimensions. <ref type="figure">Fig. 4(b)</ref> shows that most angles are equal to or close to 0?or 180?, i.e., the lines of hypernym and hyponym ?1 are parallel to each other. To further prove that hypernym and hyponym are symmetrical with respect to h = t, we select two dimensions of them and plot the corresponding straight lines, as shown in <ref type="figure">Fig. 6(a)</ref>. In addition, we can see from <ref type="figure">Fig. 6(b)</ref> that has part and part of in WN18 are also symmetrical with respect to h = t. These figures are completely consistent with <ref type="figure" target="#fig_0">Fig. 2(c)</ref> in Section III-B, which indicates that LineaRE can model the inverse pattern. c) Composition Pattern: In FB15k-237, f or 2 is a composition of f or 1 and winner 6 . We compute the angles between the composite straight lines and the lines of f or 2 along the same dimensions. <ref type="figure">Fig. 4(c)</ref> shows that the composition of f or 1 and winner is very similar to f or 2 .</p><p>d) Complex Mapping Properties: For the 1-to-N relation hyponym, hpt r = 1.02, and tph r = 3.66, <ref type="figure">Fig.  4(d)</ref> shows that there are more steep-slope straight lines than the gentle-slope ones in hyponym. The relation member of domain topic (denoted as topic) in WN18 is a 1-to-N relation, and (06090869, topic) has 69 tails in the training set, and 3 tails in the test set. <ref type="figure">Fig. 7</ref> shows two straight lines of topic and the distribution of these (06090869, t) points. The first straight line is very steep, which allows the 72 tail entities corresponding to the head entity 06090869 to be different from each other. And the second straight line is relatively flat, which makes the 72 tail entities close to each other. Thus, these tail entities are different from each other in dimensions like <ref type="figure">Fig. 7(a)</ref>, and the same in dimensions like <ref type="figure">Fig. 7(b)</ref>. This is completely consistent with our analysis in Section III-B, which proves that LineaRE can model complex mapping properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Inferring Relation Patterns on Dataset Countries</head><p>Following <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, we also evaluate our proposed LineaRE on the Countries dataset <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>, which is meticulously designed for testing the capabilities of knowledge graph embedding methods when modeling composition pattern. It contains 2 relations (neighborOf , locatedIn) and 272 entities (244 countries, 5 regions, and 23 subregions). Reference <ref type="bibr" target="#b31">[32]</ref> sets three tasks with increasing difficulty: 1) Task S1 requires inferring a simple composition pattern: locatedIn(c, s) ? locatedIn(s, r) ? locatedIn(c, r) where c denotes a country, s denotes a subregion, r denotes a region.</p><p>2) Task S2 is more difficult than task S1, the correct triplets can be predicted from: neighborOf (c 1 , c 2 ) ? locatedIn(c 2 , r) ? locatedIn(c 1 , r) 3) Task S3 is the most difficult task, the correct triplets can be predicted from: neighborOf (c 1 , c 2 ) ? locatedIn(c 2 , s) ? locatedIn(s, r) ? locatedIn(c 1 , r) In <ref type="table" target="#tab_0">Table VII</ref>, we report the results with respect to the AUC-PR metric (area under the precision-recall curve). Due to the ability of modeling both the composition pattern and complex mapping properties, LineaRE achieves the best performance, especially on the most difficult task S3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this paper, we proposed a novel knowledge graph embedding method LineaRE for link prediction, which models four connectivity patterns and four mapping properties of relations in the manner of linear regression. We provided formal mathematical proofs to demonstrate the modeling capabilities of LineaRE. Extensive experimental results on the task of link prediction showed that the proposed LineaRE model significantly outperforms existing state-of-the-art models on several widely used benchmark datasets. A deep investigation into the entity and relation embeddings further verifies our    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Theorem 2 .</head><label>2</label><figDesc>LineaRE can model 1-to-1, 1-to-N, N-to-1 and N-to-N relations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 2 .</head><label>2</label><figDesc>Illustrations of LineaRE modeling connectivity patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 3 .</head><label>3</label><figDesc>Illustrations of LineaRE modeling complex mapping properties. to each other. Slopes are not necessarily to be steep in such dimensions. N-to-1: Similarly, LineaRE can model N-to-1 relations. N-to-N: N-to-N relations contain both straight lines with steep slopes and straight lines with gentle slopes. Corollary 1. The TransE model is a special case of LineaRE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>?</head><label></label><figDesc>FB15k-237 is a subset of FB15k, where inverse relations are deleted. The key of link prediction on FB15k-237 is to model composition patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 4 .Fig. 5 .</head><label>45</label><figDesc>Histograms of angles corresponding to some relation embeddings. (a) Angles between each straight line of similar to and the h axis; (b) Angles between the straight lines of hypernym and those of hyponym ?1 along the same dimension; (c) Angles between the straight lines of f or 2 and the composition of f or 1 and winner; (d) Angles between the straight lines of hyponym and the h axis; denotes the composition operation. Visualization of the straight lines of similar to and the entity pairs having the relation of similar to.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>Visualization of the straight lines of inverse relations. Visualization of the straight lines of relation topic and 72 entity pairs (06090869, t i ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I THE</head><label>I</label><figDesc>SCORE FUNCTIONS fr(h, t) OF SEVERAL KNOWLEDGE GRAPH EMBEDDING MODELS.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II THE</head><label>II</label><figDesc>MODELING CAPABILITIES OF MODELS.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III STATISTICAL</head><label>III</label><figDesc>INFORMATION OF THE DATASETS USED IN EXPERIMENTS.</figDesc><table><row><cell>Datasets</cell><cell>#E</cell><cell>#R</cell><cell>#Train</cell><cell>#Valid</cell><cell>#Total</cell><cell>#Sym</cell><cell>#Inv</cell><cell cols="4">#Test (%) #Com #Others #1-to-1 #1-to-N</cell><cell cols="2">#N-to-1 #N-to-N</cell></row><row><cell>FB15k</cell><cell>14,951</cell><cell>1,345</cell><cell>483,142</cell><cell>50,000</cell><cell>59,071</cell><cell>7.34</cell><cell>70.22</cell><cell>22.37</cell><cell>0.06</cell><cell>1.63</cell><cell>9.56</cell><cell>15.80</cell><cell>73.02</cell></row><row><cell>WN18</cell><cell>40,943</cell><cell>18</cell><cell>141,442</cell><cell>5,000</cell><cell>5,000</cell><cell>21.74</cell><cell>72.22</cell><cell>3.0</cell><cell>3.04</cell><cell>0.84</cell><cell>36.94</cell><cell>39.62</cell><cell>22.60</cell></row><row><cell>FB15k-237</cell><cell>14,541</cell><cell>237</cell><cell>272,115</cell><cell>17,535</cell><cell>20,466</cell><cell>0</cell><cell>0</cell><cell>90.40</cell><cell>9.60</cell><cell>0.94</cell><cell>6.32</cell><cell>22.03</cell><cell>70.72</cell></row><row><cell>WN18RR</cell><cell>40,943</cell><cell>11</cell><cell>86,835</cell><cell>3,034</cell><cell>3,134</cell><cell>34.65</cell><cell>0.29</cell><cell>8.33</cell><cell>56.73</cell><cell>1.34</cell><cell>15.16</cell><cell>47.45</cell><cell>36.06</cell></row><row><cell cols="9">#Sym (#Inv): test triplets (h, r, t) that can be inferred via a directly linked triplet (t, r, h) ((t</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV LINK</head><label>IV</label><figDesc>PREDICTION RESULTS ON FB15K AND WN18.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">FB15k</cell><cell></cell><cell></cell><cell></cell><cell>WN18</cell><cell></cell><cell></cell></row><row><cell></cell><cell>MR</cell><cell cols="2">MRR Hits@1</cell><cell>Hits@3</cell><cell>Hits@10</cell><cell cols="2">MR MRR</cell><cell cols="2">Hits@1 Hits@3</cell><cell>Hits@10</cell></row><row><cell>TransE [1]</cell><cell>34</cell><cell>.737</cell><cell>.650</cell><cell>.799</cell><cell>.874</cell><cell>145</cell><cell>.821</cell><cell>.713</cell><cell>.930</cell><cell>.955</cell></row><row><cell>TransH [2]</cell><cell>32</cell><cell>.748</cell><cell>.661</cell><cell>.813</cell><cell>.884</cell><cell>452</cell><cell>.823</cell><cell>.721</cell><cell>.929</cell><cell>.954</cell></row><row><cell>TransD [4]</cell><cell>33</cell><cell>.750</cell><cell>.664</cell><cell>.817</cell><cell>.886</cell><cell>261</cell><cell>.822</cell><cell>.722</cell><cell>.926</cell><cell>.956</cell></row><row><cell>DistMult [5]</cell><cell>59</cell><cell>.789</cell><cell>.730</cell><cell>.830</cell><cell>.887</cell><cell>496</cell><cell>.810</cell><cell>.694</cell><cell>.922</cell><cell>.949</cell></row><row><cell>ComplEx [6]</cell><cell>63</cell><cell>.809</cell><cell>.757</cell><cell>.846</cell><cell>.894</cell><cell>531</cell><cell>.948</cell><cell>.945</cell><cell>.949</cell><cell>.953</cell></row><row><cell>ConvE [7]</cell><cell>64</cell><cell>.745</cell><cell>.670</cell><cell>.801</cell><cell>.873</cell><cell>504</cell><cell>.942</cell><cell>.935</cell><cell>.947</cell><cell>.955</cell></row><row><cell>RotatE [8]</cell><cell>40</cell><cell>.797</cell><cell>.746</cell><cell>.830</cell><cell>.884</cell><cell>309</cell><cell>.949</cell><cell>.944</cell><cell>.952</cell><cell>.959</cell></row><row><cell>LineaRE</cell><cell>36</cell><cell>.843</cell><cell>.805</cell><cell>.867</cell><cell>.906</cell><cell>170</cell><cell>.952</cell><cell>.947</cell><cell>.955</cell><cell>.961</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>TABLE V</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="7">LINK PREDICTION RESULTS ON FB15K-237 AND WN18RR.</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">FB15k-237</cell><cell></cell><cell></cell><cell></cell><cell cols="2">WN18RR</cell><cell></cell></row><row><cell></cell><cell>MR</cell><cell cols="2">MRR Hits@1</cell><cell cols="2">Hits@3 Hits@10</cell><cell>MR</cell><cell cols="2">MRR Hits@1</cell><cell cols="2">Hits@3 Hits@10</cell></row><row><cell>TransE [1]</cell><cell>172</cell><cell>.334</cell><cell>.238</cell><cell>.371</cell><cell>.523</cell><cell>1730</cell><cell>.242</cell><cell>.042</cell><cell>.406</cell><cell>.541</cell></row><row><cell>TransH [2]</cell><cell>168</cell><cell>.339</cell><cell>.243</cell><cell>.375</cell><cell>.531</cell><cell>4345</cell><cell>.233</cell><cell>.044</cell><cell>.395</cell><cell>.524</cell></row><row><cell>TransD [4]</cell><cell>172</cell><cell>.330</cell><cell>.235</cell><cell>.365</cell><cell>.518</cell><cell>2701</cell><cell>.247</cell><cell>.062</cell><cell>.401</cell><cell>.537</cell></row><row><cell>DistMult [5]</cell><cell>301</cell><cell>.311</cell><cell>.225</cell><cell>.341</cell><cell>.485</cell><cell>4675</cell><cell>.439</cell><cell>.407</cell><cell>.450</cell><cell>.502</cell></row><row><cell>ComplEx [6]</cell><cell>376</cell><cell>.313</cell><cell>.227</cell><cell>.342</cell><cell>.486</cell><cell>4824</cell><cell>.466</cell><cell>.438</cell><cell>.479</cell><cell>.526</cell></row><row><cell>ConvE [7]</cell><cell>246</cell><cell>.316</cell><cell>.239</cell><cell>.350</cell><cell>.491</cell><cell>5277</cell><cell>.46</cell><cell>.39</cell><cell>.43</cell><cell>.48</cell></row><row><cell>RotatE [8]</cell><cell>177</cell><cell>.338</cell><cell>.241</cell><cell>.375</cell><cell>.533</cell><cell>3340</cell><cell>.476</cell><cell>.428</cell><cell>.492</cell><cell>.571</cell></row><row><cell>LineaRE</cell><cell>155</cell><cell>.357</cell><cell>.264</cell><cell>.391</cell><cell>.545</cell><cell>1644</cell><cell>.495</cell><cell>.453</cell><cell>.509</cell><cell>.578</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI THE</head><label>VI</label><figDesc>DETAILED LINK PREDICTION RESULTS BY RELATION CATEGORY ON FB15K.</figDesc><table><row><cell>Rel. Cat</cell><cell>1-to-1</cell><cell cols="2">1-to-N N-to-1</cell><cell>N-to-N</cell><cell cols="2">1-to-1 1-to-N</cell><cell>N-to-1</cell><cell>N-to-N</cell></row><row><cell>Task</cell><cell cols="4">Predicting Head (Hits@10)</cell><cell cols="4">Predicting Tail (Hits@10)</cell></row><row><cell>TransE [1]</cell><cell>.916</cell><cell>.975</cell><cell>.626</cell><cell>.881</cell><cell>.899</cell><cell>.704</cell><cell>.968</cell><cell>.909</cell></row><row><cell>TransH [2]</cell><cell>.892</cell><cell>.969</cell><cell>.628</cell><cell>.895</cell><cell>.866</cell><cell>.716</cell><cell>.965</cell><cell>.921</cell></row><row><cell>TransD [2]</cell><cell>.903</cell><cell>.971</cell><cell>.639</cell><cell>.895</cell><cell>.880</cell><cell>.741</cell><cell>.964</cell><cell>.921</cell></row><row><cell>DistMult [5]</cell><cell>.925</cell><cell>.965</cell><cell>.657</cell><cell>.890</cell><cell>.923</cell><cell>.821</cell><cell>.949</cell><cell>.917</cell></row><row><cell>ComplEx [6]</cell><cell>.928</cell><cell>.962</cell><cell>.673</cell><cell>.897</cell><cell>.934</cell><cell>.831</cell><cell>.950</cell><cell>.923</cell></row><row><cell>RotatE [8]</cell><cell>.922</cell><cell>.967</cell><cell>.602</cell><cell>.893</cell><cell>.923</cell><cell>.713</cell><cell>.961</cell><cell>.922</cell></row><row><cell>LineaRE</cell><cell>.930</cell><cell>.973</cell><cell>.723</cell><cell>.906</cell><cell>.923</cell><cell>.854</cell><cell>.965</cell><cell>.933</cell></row><row><cell>Task</cell><cell cols="4">Predicting Head (MRR)</cell><cell></cell><cell cols="3">Predicting Tail (MRR)</cell></row><row><cell>TransE [1]</cell><cell>.740</cell><cell>.929</cell><cell>.498</cell><cell>.730</cell><cell>.739</cell><cell>.594</cell><cell>.906</cell><cell>.752</cell></row><row><cell>TransH [2]</cell><cell>.664</cell><cell>.905</cell><cell>.495</cell><cell>.750</cell><cell>.658</cell><cell>.586</cell><cell>.891</cell><cell>.774</cell></row><row><cell>TransD [2]</cell><cell>.669</cell><cell>.910</cell><cell>.499</cell><cell>.752</cell><cell>.664</cell><cell>.601</cell><cell>.894</cell><cell>.775</cell></row><row><cell>DistMult [5]</cell><cell>.813</cell><cell>.922</cell><cell>.526</cell><cell>.793</cell><cell>.805</cell><cell>.683</cell><cell>.886</cell><cell>.817</cell></row><row><cell>ComplEx [6]</cell><cell>.820</cell><cell>.928</cell><cell>.557</cell><cell>.819</cell><cell>.815</cell><cell>.717</cell><cell>.890</cell><cell>.838</cell></row><row><cell>RotatE [8]</cell><cell>.878</cell><cell>.934</cell><cell>.465</cell><cell>.787</cell><cell>.872</cell><cell>.611</cell><cell>.909</cell><cell>.832</cell></row><row><cell>LineaRE</cell><cell>.865</cell><cell>.943</cell><cell>.623</cell><cell>.845</cell><cell>.860</cell><cell>.772</cell><cell>.920</cell><cell>.867</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE VII RESULTS</head><label>VII</label><figDesc>ON THE COUNTRIES DATASET Results of TransE, ComplEx and RotatE are taken from [8].theoretical analysis of its modeling capabilities. Moreover, results on the Countries dataset showed that our LineaRE has a powerful reasoning ability.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.08</cell><cell></cell><cell></cell></row><row><cell>0.04</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.04</cell><cell></cell><cell></cell></row><row><cell>0.00</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.00</cell><cell></cell><cell></cell></row><row><cell>?0.04</cell><cell></cell><cell></cell><cell>hypernym hyponym</cell><cell></cell><cell></cell><cell></cell><cell>hypernym hyponym</cell></row><row><cell></cell><cell></cell><cell></cell><cell>train test</cell><cell>?0.04</cell><cell></cell><cell></cell><cell>train test</cell></row><row><cell></cell><cell>?0.04</cell><cell>0.00</cell><cell>0.04</cell><cell>?0.04</cell><cell>0.00</cell><cell>0.04</cell><cell>0.08</cell></row><row><cell></cell><cell></cell><cell cols="4">(a) hypernym&amp; hyponym</cell><cell></cell></row><row><cell></cell><cell>has_part</cell><cell></cell><cell></cell><cell>0.08</cell><cell></cell><cell>has_part</cell></row><row><cell></cell><cell>part_of</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>part_of</cell></row><row><cell>0.04</cell><cell>train</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>train</cell></row><row><cell></cell><cell>test</cell><cell></cell><cell></cell><cell>0.04</cell><cell></cell><cell>test</cell></row><row><cell>0.00</cell><cell></cell><cell></cell><cell></cell><cell>0.00</cell><cell></cell><cell></cell></row><row><cell>?0.04</cell><cell></cell><cell></cell><cell></cell><cell>?0.04</cell><cell></cell><cell></cell></row><row><cell cols="2">?0.08 ?0.04 ?0.08</cell><cell>0.00</cell><cell>0.04</cell><cell cols="2">?0.04</cell><cell>0.00</cell><cell>0.04</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(b) has part&amp; part of</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Countries(AUC-PR)</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>S1</cell><cell>S2</cell><cell></cell><cell>S3</cell></row><row><cell></cell><cell>TransE</cell><cell cols="2">1.00 ? 0.00</cell><cell>1.00 ? 0.00</cell><cell cols="3">0.96 ? 0.00</cell></row><row><cell></cell><cell cols="3">ComplEx 1.00 ? 0.00</cell><cell>0.98 ? 0.00</cell><cell cols="3">0.88 ? 0.01</cell></row><row><cell></cell><cell>RotatE</cell><cell cols="2">1.00 ? 0.00</cell><cell>1.00 ? 0.00</cell><cell cols="3">0.95 ? 0.00</cell></row><row><cell></cell><cell>LineaRE</cell><cell cols="2">1.00 ? 0.00</cell><cell>1.00 ? 0.00</cell><cell cols="3">0.99 ? 0.01</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">If the slope of a line is positive (negative), the larger (smaller) the slope, the steeper it is. We use the term gentle slope as the opposite of the steep slope in this study.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">For relation r, tphr denotes the average number of tails per head, and hptr denotes the average number of head per tail.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Following<ref type="bibr" target="#b1">[2]</ref>, for each relation r, we compute tphr and hptr. If hptr &lt; 1.5 and tphr &lt; 1.5, r is treated as one-to-one; if hptr ? 1.5 and tphr ? 1.5, r is treated as a many-to-many; if hptr &lt; 1.5 and tphr ? 1.5, r is treated as one-to-many. If hptr ? 1.5 and tphr &lt; 1.5, r is treated as many-to-one.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">Here, f or 1 represents relation /award/award nominee/award nominations./award/award nomination/nominated for, winner represents relation/award/ award category/winners./award/award honor/award winner, and f or 2 represents /award/award category/nominees./award/award nomination/nominated for.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding by translating on hyperplanes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 28th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning entity and relation embeddings for knowledge graph completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 29th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding via dynamic mapping matrix</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="687" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Embedding entities and relations for learning and inference in knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6575</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Complex embeddings for simple link prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Trouillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bouchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2071" to="2080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional 2d knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dettmers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Minervini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd AAAI Conference on Artificial Intelligence</title>
		<meeting>the 32nd AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rotate: Knowledge graph embedding by relational rotation in complex space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th International Conference on Learning Representations. Open-Review.net</title>
		<meeting>the 7th International Conference on Learning Representations. Open-Review.net</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dbpedia-a large-scale, multilingual knowledge base extracted from wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kontokostas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Morsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Van Kleef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="195" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 ACM SIGMOD International Conference on Management of Data</title>
		<meeting>the 2008 ACM SIGMOD International Conference on Management of Data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Explicit semantic ranking for academic search via knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</title>
		<meeting>the 26th International Conference on World Wide Web. International World Wide Web Conferences Steering Committee</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1271" to="1279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Collaborative knowledge base embedding for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="353" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An end-to-end model for question answering over knowledge base with cross-attention combining global knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="221" to="231" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding based question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th ACM International Conference on Web Search and Data Mining</title>
		<meeting>the 12th ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="105" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Leveraging knowledge bases in lstms for improving machine reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09091</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bootstrapping entity alignment with knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4396" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Triple trustworthiness measurement for knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2865" to="2871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Modeling relation paths for representation learning of knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="705" to="714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Simple embedding for link prediction in knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4284" to="4295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Knowledge graph embedding: A survey of approaches and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2724" to="2743" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A three-way model for collective learning on multi-relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-P</forename><surname>Kriegel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning</title>
		<meeting>the 28th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="809" to="816" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A semantic matching energy function for learning with multi-relational data application to word-sense disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="233" to="259" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Knowledge vault: A web-scale approach to probabilistic knowledge fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Strohmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="601" to="610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reasoning with neural tensor networks for knowledge base completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="926" to="934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Kbgan: Adversarial learning for knowledge graph embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04071</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nscaching: simple and efficient negative sampling for knowledge graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th IEEE International Conference on Data Engineering</title>
		<meeting>the 35th IEEE International Conference on Data Engineering</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="614" to="625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Incorporating gan for negative sampling in knowledge representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd AAAI Conference on Artificial Intelligence</title>
		<meeting>the 32nd AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Observed versus latent features for knowledge base and text inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality</title>
		<meeting>the 3rd Workshop on Continuous Vector Space Models and their Compositionality</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On approximate reasoning capabilities of low-rank vector spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bouchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Trouillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Syposium on Knowledge Representation and Reasoning (KRR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Holographic embeddings of knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Rosasco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 30th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
