<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IFCNet: A Benchmark Dataset for IFC Entity Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Emunds</surname></persName>
							<email>emunds@e3d.rwth-aachen.de</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Energy Efficiency and Sustainable Building E3D</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Pauen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Energy Efficiency and Sustainable Building E3D</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronika</forename><surname>Richter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Energy Efficiency and Sustainable Building E3D</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?r?me</forename><surname>Frisch</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Energy Efficiency and Sustainable Building E3D</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Van Treeck</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Energy Efficiency and Sustainable Building E3D</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">IFCNet: A Benchmark Dataset for IFC Entity Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Enhancing interoperability and information exchange between domain-specific software products for BIM is an important aspect in the Architecture, Engineering, Construction and Operations industry. Recent research started investigating methods from the areas of machine and deep learning for semantic enrichment of BIM models. However, training and evaluation of these machine learning algorithms requires sufficiently large and comprehensive datasets. This work presents IFCNet, a dataset of single-entity IFC files spanning a broad range of IFC classes containing both geometric and semantic information. Using only the geometric information of objects, the experiments show that three different deep learning models are able to achieve good classification performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Enhancing interoperability between domain-specific information modeling processes and, thus, software products for Building Information Modeling (BIM) is an important aspect to improve the lifecycle support of buildings and to facilitate the collaboration of the different disciplines across Architecture, Engineering, Construction and Operations (AECO). The Industry Foundation Classes (IFC) provide an open data exchange format for sharing information between these stakeholders.</p><p>However, since the IFC standard has to cover a broad spectrum of concepts, it contains a large number of entities and is highly complex. Past studies have shown that IFC-based exchanges of models are prone to an information loss due to reduction, simplification or interpretation when sharing data between multiple specialized software products <ref type="bibr" target="#b1">(Bazjanac &amp; Kiviniemi, 2007)</ref>. One major issue is a potential mismapping between native BIM elements and IFC entities, which can arise through e.g. manual error during model creation or the reliance on default templates <ref type="bibr" target="#b2">(Belsky, et al., 2016)</ref>. Furthermore, CAD software products interpret specifications differently when processing in-and output data.</p><p>When sharing BIM models with other teams, semantic integrity is a prerequisite for a seamless workflow and effective collaboration. Many specialized applications rely on accurate semantic information to perform their tasks, e.g. energy efficiency modelling <ref type="bibr" target="#b19">(Schlueter &amp; Thesseling, 2009;</ref><ref type="bibr" target="#b10">Ham &amp; Golparvar-Fard, 2015)</ref> or code compliance checking <ref type="bibr" target="#b8">(Eastman, et al., 2009)</ref>. Inconsistent object classification has been identified to be a common interoperability issue between different BIM authoring software suites <ref type="bibr" target="#b2">(Belsky et al., 2016;</ref><ref type="bibr" target="#b13">Lai &amp; Deng, 2018)</ref>.</p><p>Researchers have started approaching this issue with methods from the area of machine and deep learning <ref type="bibr" target="#b3">(Bloch &amp; Sacks, 2018)</ref>. These algorithms typically need labelled datasets to learn from. However, comprehensive and rich datasets in the domain of BIM and IFC are scarce, which makes the development and verification of such models difficult. In this work, the authors introduce a benchmark dataset of single-entity IFC files covering a broad range of IFC classes. This dataset, named IFCNet 1 , should contribute to the standardization of performance evaluations of future work in this domain. To evaluate the usefulness of IFCNet, three deep learning methods are trained to classify the entities and their performance is reviewed.</p><p>The key contributions of this research paper can be summarized as follows:</p><p>? A benchmark dataset for IFC entity classification, named IFCNet, is released.</p><p>? The application of recent advances in the area of geometric deep learning to the classification of IFC elements is shown using three different approaches. ? An evaluation of these deep learning methods is conducted to demonstrate the opportunities and challenges posed by IFCNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Existing approaches for the classification of BIM and IFC elements can be categorized into rule-based and machine-learning-based methods. <ref type="bibr" target="#b21">Thomson and Boehm (2015)</ref> use RANSAC to identify dominant planes and reconstruct IFC geometry from 3D point clouds, followed by an optional step of geometric reasoning. Others have used region growing <ref type="bibr" target="#b6">(Dimitrov &amp; Golparvar-Fard, 2015)</ref> or surface normal approaches <ref type="bibr" target="#b0">(Barnea &amp; Filin, 2013)</ref>. <ref type="bibr" target="#b18">Sacks et al. (2017)</ref> derived rules for object classification using object features and spatial relationships between object pairs. <ref type="bibr" target="#b15">Ma et al. (2017)</ref> devise a semantic enrichment process by establishing a knowledge base that associates objects via their geometric and spatial features.</p><p>While these methods proof to work well on specific cases, <ref type="bibr" target="#b3">Bloch &amp; Sacks (2018)</ref> argue that rule-based workflows are not applicable to all problems. In recent work, researchers started exploring algorithms from the areas of machine and deep learning. <ref type="bibr" target="#b12">Koo et al. (2020)</ref> apply PointNet <ref type="bibr" target="#b17">(Qi, et al., 2017</ref>) and a Multi-view Convolutional Neural Network (MVCNN) <ref type="bibr" target="#b20">(Su, et al., 2015)</ref> to classify elements of road infrastructure. <ref type="bibr" target="#b11">Kim et al. (2019)</ref> use images of objects to train a 2D CNN to recognize furniture elements. <ref type="bibr" target="#b14">Leonhardt et al. (2020)</ref> also employ PointNet for classification of IFC objects and for semantic segmentation of rooms.</p><p>Many of these works assemble their own datasets, but do not release them publicly. On one hand, this is inefficient, since these datasets cannot be used by the research community and thus work is done repeatedly. On the other hand, it makes comparisons between different methods impossible. IFCNet's goal is to serve as a benchmark to be used by other researchers to develop, train, and test their methods and algorithms on and offer a common ground for comparing them. To assemble IFCNet, around 1000 IFC models were collected from real-world projects, student works and online sources, such as the open IFC model repository of the university of Auckland <ref type="bibr" target="#b7">(Dimyadi, et al., 2010)</ref>. The models were created with different authoring software products, most notably Autodesk Revit and ArchiCAD. Afterwards, the models were decomposed into individual entities by extracting all objects into separate files. For the first version of IFCNet, the focus has been put on the subtypes of IfcDistributionElement, IfcBuildingElement and IfcFurnishingElement. Additionally, the attached IfcPropertySets have been extracted as well. The extraction results in roughly 1.2M entities from 82 different IFC classes. The data contain several different representation types, including Brep, AdvancedBrep, MappedRepresentation, SweptSolid, Tesselation and CSG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The IFCNet Dataset</head><p>The resulting IFC files are deduplicated to eliminate objects with identical geometry. To be able to perform this deduplication in linear time, the vertices of every object are normalized to the unit sphere and used as the key in a hash map. Objects with identical sets of vertices are then mapped onto the same key and can thus be eliminated. This, of course, assumes that the vertices match exactly, meaning that the vertices of two different objects which are in fact duplicates need to be in the same order. However, this was found to be true for the majority of objects, judging by the fact that this na?ve way of deduplicating geometries reduces the aforementioned 1.2M to around 290k entities. Since objects are only deduplicated within their respective class, this process can easily be parallelized.</p><p>In the next step, the entities are reviewed manually and misclassifications are corrected. To support this process, a web-based tool was developed, which allows users to review an entity's geometric representation and attached metadata before confirming or changing its class and enables quick switching between the different IFC classes and their objects. Furthermore, the tool supports exploring the already labelled data to document the current progress of the dataset. The labelling process has been carried out and supervised by domain experts to ensure the quality of the dataset. A view of this tool is shown in <ref type="figure" target="#fig_1">Figure 2</ref>, displaying an IfcValve. The full IFCNet dataset currently consists of 19,613 confirmed objects distributed over 65 classes, most of which are highly imbalanced with respect to the number of objects they contain. Therefore, a subset of 20 classes is selected for the experiments in Section 4. The first version of this sub-dataset, called IFCNetCore, contains a total of 7,930 objects ( <ref type="figure" target="#fig_0">Figure 1)</ref>. <ref type="table" target="#tab_0">Table 1</ref> shows the number of objects per class before and after deduplication of the full dataset, as well as the training and test split for IFCNetCore.</p><p>Some classes, like IfcWall, have little intra-class variance, while others have very large intraclass variance. IfcFurniture for example contains vastly different types of furniture, from chairs and tables to wardrobes. An additional challenge is posed by a small inter-class variance between certain classes like IfcWall and IfcPlate, both of which are rectangular shapes with varying thickness and little to no details with respect to their geometry. To better reflect the reality of people working with IFC, models and elements of different Level of Information Need (LOIN) have been included, which also covers objects that have a placeholder appearance (e.g. generic-looking cubes) and are thus likely to only be classifiable through their metadata.</p><p>Most IFC objects have additional metadata in the form of IfcProperties, which are grouped together via IfcPropertySets. The simplest and most frequently used kind of properties are userdefined key-value pairs, which often come in different languages. For instance, German, English, Dutch and French have been observed throughout the labelling process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>The following experiments apply three neural network approaches to the IFCNetCore dataset. These architectures were chosen because they are among the current state-of-the-art and cover a broad range of intuitive representations for 3D data, i.e. 2D projections, point clouds and triangulated meshes. However, all of these methods only consider the objects' geometric information. Investigating ways to combine geometric and semantic information during training is beyond the scope of this paper. The code for the neural network models is based on the PyTorch implementations of the original publications.</p><p>All experiments follow the same training protocol: The IFCNetCore dataset is split into a training and a test set. Afterwards, the data is transformed into the format expected by the different architectures. To determine the best set of hyperparameters, 30% of the training data is split off into a validation set. The models are then trained on the remaining 70% of the training data and evaluated on the validation set after each epoch. The balanced accuracy metric is used to decide for the best performing configuration of hyperparameters. Finally, the models are trained once more on the whole training set with fixed hyperparameters. Evaluation on the test set only occurs once at the end of this procedure. The code used to conduct these experiments will be released along with this work 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">MVCNN</head><p>The Multi-View Convolutional Neural Network (MVCNN) combines information from multiple views of a 3D shape to learn a shape descriptor <ref type="bibr" target="#b20">(Su, et al., 2015)</ref>. Since MVCNN uses rendered 2D views of an object from several perspectives, it has two advantages over the other methods presented here. First, neural networks for image classification have received much more attention in Deep Learning research over the last years. Neural network building blocks like 2D convolutions have been specifically designed to work well on image data. Second, MVCNN benefits from the existence of other large-scale image datasets like ImageNet <ref type="bibr" target="#b5">(Deng, et al., 2009)</ref>. CNN architectures are commonly pre-trained on these massive datasets and can later be fine-tuned on much smaller datasets while still performing well.</p><p>To prepare the IFCNetCore dataset to be consumed by MVCNN, 12 views are rendered for each object by a camera rotating around the object's up-axis in 30? increments <ref type="figure">(Figure 3</ref>). Similar to <ref type="bibr" target="#b20">Su et al. (2015)</ref>, the Phong reflection model <ref type="bibr" target="#b16">(Phong, 1975)</ref> is used to generate the rendered views. <ref type="figure" target="#fig_2">Figure 4</ref> shows the results of the evaluation on the test set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">DGCNN</head><p>The Dynamic Graph Convolutional Neural Network (DGCNN) <ref type="bibr" target="#b22">(Wang, et al., 2019)</ref> is inspired by PointNet <ref type="bibr" target="#b17">(Qi, et al., 2017)</ref>, but operates on neighborhoods of points by using convolution operations. This allows DGCNN to exploit local geometric structures.</p><p>During pre-processing, 2048 points are sampled uniformly at random from each object in IFCNetCore. The point clouds are normalized to the unit sphere before they are fed through the model. The results of the evaluation on the test set are shown in <ref type="figure" target="#fig_3">Figure 5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MeshNet</head><p>In contrast to the previous two methods, MeshNet <ref type="bibr" target="#b9">(Feng, et al., 2018)</ref> uses the geometric information of the mesh directly to learn a classifier. It solves the complexity and irregularity problem of mesh data by regarding the faces as the unit and using per-face processes and a symmetry function. Moreover, it splits faces into spatial and structural features by using a spatial and structural descriptor and a mesh convolution block. Before training, the meshes are simplified to a maximum of 2048 faces using MeshLab's <ref type="bibr" target="#b4">(Cignoni, et al., 2008)</ref> implementation of Quadric Edge Collapse Decimation. Afterwards, the meshes are converted into lists of faces containing information about their center, corners and normal as well as their immediate neighboring faces. The results on the test set are shown in <ref type="figure" target="#fig_4">Figure 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparison</head><p>A comparison of precision-recall curves for selected classes can be seen in <ref type="figure" target="#fig_5">Figure 7</ref>. Not surprisingly, classes for which there are very few objects like IfcOutlet show a worse performance. However, MVCNN still achieves better results than DGCNN and MeshNet.   <ref type="table" target="#tab_1">Table 2</ref> shows the balanced accuracy and F1 score for the three models. MVCNN achieves the best overall results. The confusion matrices show that each of the three models has its own strengths and weaknesses, but that they also make similar mistakes. For instance, plates, slabs and walls are among the most confused classes. Another example of commonly confused classes are duct segments and pipe segments. However, all three models show a reasonable performance and proof that they are able to learn from the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Limitations</head><p>Notably, the absolute sizes of objects are lost due to normalization of the data before training. Incorporating this information into the classification process is likely to improve results for objects that might look similar, but differ greatly in size. Moreover, some objects, especially those with few geometric details, might be very hard to classify when taken out of the context of the full BIM model or without regarding their semantic information. However, most current neural network architectures are trained end-to-end from raw data and were not designed to consume such explicit features.</p><p>With such a large quantity of objects, it is difficult to ensure uniqueness. The deduplication process is able to eliminate objects with identical geometry. However, there are many objects that look alike to a human observer, but are not identical on the mesh level. Such cases include permutations of a mesh's vertices or non-uniform scaling along axes. To conduct an exhaustive search and also detect objects that are almost identical is not feasible. Further research will have to investigate more efficient methods to eliminate near-duplicate objects.</p><p>Many objects use a mix of languages in their metadata. Sometimes the value of a key-value pair might be missing if a field in the authoring software was left unset. Moreover, it is common to encounter abbreviations and acronyms, which require a certain amount of domain knowledge to make use of. In some cases, properties might also be inaccurate or simply wrong. These issues make it difficult to incorporate the semantic properties into the classification process without thorough pre-processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>The first version of IFCNetCore offers a common benchmark for model training and evaluation. Expanding IFCNet with more objects, classes, and semantic information is an ongoing effort to create a large-scale dataset for the BIM and IFC domain. Since the labelling process requires specific domain knowledge, creating this dataset is even more resource intensive than other datasets used in machine and deep learning. The goal for IFCNet is to become a useful resource for other researchers working on semantic enrichment of BIM models.</p><p>The results of the experiments conducted on IFCNetCore show a good classification performance, despite only using the geometric information of objects. Further research could investigate models that can take the properties and semantic information into account to improve on these results. Moreover, in the domain of 2D images, models used for segmentation or detection are commonly pre-trained on large-scale image datasets. How to effectively use such transfer learning approaches for 3D data is an area of active research. One could imagine that, with sufficient size of IFCNet, it should be possible to use the dataset for similar pretraining purposes.</p><p>The classification process presented in this work can be integrated into the BIM workflow similarly to the SEEBIM method of <ref type="bibr" target="#b2">Belsky et al. (2016)</ref>. Upon import of an IFC file into a BIM tool, the trained network is used to infer the classes of the individual elements of the model. Afterwards, the author is prompted with a screen showing the potential misclassifications and can then decide to accept or reject the propositions of the network.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Example objects for each of the 20 classes of IFCNetCore.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>View of the tool used during the labelling process. The menu on the left allows switching between IFC classes. The menu on the right displays the current object's properties. The central canvas shows objects of the selected class in 3D.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4</head><label>4</label><figDesc>2 https://github.com/cemunds/ifcnet-models Figure 3: Example of a set of 12 views to be consumed by the MVCNN Left: Confusion matrix of the MVCNN model. Right: Precision-recall curves for selected IFC classes with corresponding values for Area Under the Curve (AUC).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5</head><label>5</label><figDesc>Left: Confusion matrix of the DGCNN model. Right: Precision-recall curves for selected IFC entities with corresponding values for Area Under the Curve (AUC).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6</head><label>6</label><figDesc>Left: Confusion matrix of the MeshNet model. Right: Precision-recall curves for selected IFC entities with corresponding values for Area Under the Curve (AUC).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Comparison of precision-recall curves for selected classes. The top-left plot shows the microaveraged precision-recall curve over all classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Number of objects per class in IFCNet and IFCNetCore. A class in IFCNetCore can have more objects than there were after deduplication, since e.g. IfcBuildingElementProxy objects could have moved into that class during the labelling process. Note that not all of the objects listed under after deduplication have been reviewed and confirmed, yet.</figDesc><table><row><cell>Class</cell><cell>Before deduplication</cell><cell>After deduplication</cell><cell>Training set</cell><cell>Test set</cell></row><row><cell>IfcAirTerminal</cell><cell>6,227</cell><cell>496</cell><cell>333</cell><cell>142</cell></row><row><cell>IfcBeam</cell><cell>128,027</cell><cell>17,957</cell><cell>198</cell><cell>84</cell></row><row><cell>IfcCableCarrierFitting</cell><cell>2,913</cell><cell>511</cell><cell>361</cell><cell>155</cell></row><row><cell>IfcCableCarrierSegment</cell><cell>4,135</cell><cell>2,820</cell><cell>370</cell><cell>159</cell></row><row><cell>IfcDoor</cell><cell>11,569</cell><cell>1,833</cell><cell>216</cell><cell>93</cell></row><row><cell>IfcDuctFitting</cell><cell>29,409</cell><cell>7,590</cell><cell>455</cell><cell>195</cell></row><row><cell>IfcDuctSegment</cell><cell>28,783</cell><cell>22,129</cell><cell>372</cell><cell>159</cell></row><row><cell>IfcFurniture</cell><cell>7,943</cell><cell>218</cell><cell>157</cell><cell>67</cell></row><row><cell>IfcLamp</cell><cell>0</cell><cell>0</cell><cell>65</cell><cell>27</cell></row><row><cell>IfcOutlet</cell><cell>1,559</cell><cell>34</cell><cell>41</cell><cell>18</cell></row><row><cell>IfcPipeFitting</cell><cell>117,979</cell><cell>5,510</cell><cell>454</cell><cell>194</cell></row><row><cell>IfcPipeSegment</cell><cell>170,308</cell><cell>86,979</cell><cell>454</cell><cell>195</cell></row><row><cell>IfcPlate</cell><cell>20,472</cell><cell>3,436</cell><cell>366</cell><cell>157</cell></row><row><cell>IfcRailing</cell><cell>3,112</cell><cell>967</cell><cell>295</cell><cell>127</cell></row><row><cell>IfcSanitaryTerminal</cell><cell>289</cell><cell>32</cell><cell>316</cell><cell>136</cell></row><row><cell>IfcSlab</cell><cell>8,787</cell><cell>4,018</cell><cell>355</cell><cell>152</cell></row><row><cell>IfcSpaceHeater</cell><cell>392</cell><cell>51</cell><cell>89</cell><cell>38</cell></row><row><cell>IfcStair</cell><cell>807</cell><cell>80</cell><cell>36</cell><cell>16</cell></row><row><cell>IfcValve</cell><cell>15,335</cell><cell>362</cell><cell>242</cell><cell>104</cell></row><row><cell>IfcWall</cell><cell>21,336</cell><cell>8,348</cell><cell>376</cell><cell>161</cell></row><row><cell>Total</cell><cell></cell><cell></cell><cell>5551</cell><cell>2379</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results of the evaluation on the test set for the three models.</figDesc><table><row><cell>Model</cell><cell>Balanced Accuracy</cell><cell>F1 score</cell></row><row><cell>MVCNN</cell><cell>85.54%</cell><cell>86.93%</cell></row><row><cell>DGCNN</cell><cell>79.11%</cell><cell>82.15%</cell></row><row><cell>MeshNet</cell><cell>83.32%</cell><cell>85.72%</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://ifcnet.e3d.rwth-aachen.de</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The research within the project EnergyTWIN leading to these results has received funding from the German Ministry for Industry and Energy under grant agreement no. 03EN1026A. The authors would like to thank the Geodetic Institute and Chair for Computing in Civil Engineering &amp; Geo Information Systems at RWTH Aachen, aedifion GmbH, DiConneX GmbH, TEMA Technologie Marketing AG, Internet Marketing Services GmbH and Aachener Grundverm?gen Kapitalverwaltungsgesellschaft mbH for their contribution to the project.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Segmentation of terrestrial laser scanning data using geometry and image information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barnea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Filin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="33" to="48" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reduction, simplification, translation and interpretation in the exchange of model data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bazjanac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kiviniemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th W78 Conference Maribor</title>
		<meeting>the 24th W78 Conference Maribor</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="163" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic Enrichment for Building Information Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sacks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Brilakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer-Aided Civil and Infrastructure Engineering</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comparing machine learning and rule-based inferencing for semantic enrichment of BIM models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sacks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation in Construction</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="256" to="272" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">MeshLab: an Open-Source Mesh Processing Tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cignoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics Italian Chapter Conference. s.l.:The Eurographics Association</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Segmentation of building point cloud models including detailed architectural/structural features and MEP systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dimitrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Golparvar-Fard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation in Construction</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="32" to="45" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Open IFC Model Repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dimyadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dimalen</surname></persName>
		</author>
		<ptr target="http://openifcmodel.cs.auckland.ac.nz/" />
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>Accessed 17th December 2020</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Automatic rule-based checking of building designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Eastman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automation in Construction</title>
		<imprint>
			<biblScope unit="page" from="1011" to="1033" />
			<date type="published" when="2009-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">MeshNet: Mesh Neural Network for 3D Shape Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Three-Dimensional Thermography-Based Method for Cost-Benefit Analysis of Energy Efficiency Building Envelope Retrofits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Golparvar-Fard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computing in Civil Engineering</title>
		<imprint>
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Recognizing and Classifying Unknown Object in BIM Using 2D CNN. Computer-Aided Architectural Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-K</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A geometric deep learning approach for checking element-to-entity mappings in infrastructure building information models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Koo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational Design and Engineering</title>
		<imprint>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Interoperability analysis of IFC-based data exchange between heterogeneous BIM software</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Civil Engineering and Management</title>
		<imprint>
			<biblScope unit="page" from="537" to="555" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Implementierung von KI-basierten Referenzprozessen f?r die computergest?tzte Objekterkennung im Geb?ude</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Leonhardt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-09" />
			<publisher>BauSIM</publisher>
			<biblScope unit="page" from="599" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Building Model Object Classification for Semantic Enrichment Using Geometric Features and Pairwise Spatial Relationships</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sacks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Kattel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lean and Computing in Construction Congress -Joint Conference on Computing in Construction</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Illumination for Computer Generated Pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Phong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="page" from="311" to="317" />
			<date type="published" when="1975-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<title level="m">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation. Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Semantic Enrichment for Building Information Modeling: Procedure for Compiling Inference Rules and Operators for Complex Geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sacks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computing in Civil Engineering</title>
		<imprint>
			<date type="published" when="2017-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Building information model based energy/exergy performance assessment in early design stages. Automation in Construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schlueter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Thesseling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009-03" />
			<biblScope unit="page" from="153" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multi-view Convolutional Neural Networks for 3D Shape Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Automatic Geometry Generation from Point Clouds for BIM. Remote Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Boehm</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="11753" to="11775" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dynamic Graph CNN for Learning on Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
