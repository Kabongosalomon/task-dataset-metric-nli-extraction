<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Human Trajectory Prediction via Neural Social Physics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangbei</forename><surname>Yue</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Leeds</orgName>
								<address>
									<settlement>Leeds</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dinesh Manocha</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Maryland at College Park</orgName>
								<address>
									<settlement>College Park</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Leeds</orgName>
								<address>
									<settlement>Leeds</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">E Ac</forename><surname>Wang@leeds</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uk</surname></persName>
						</author>
						<title level="a" type="main">Human Trajectory Prediction via Neural Social Physics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Human Trajectory Prediction; Neural Differential Equa- tions</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Trajectory prediction has been widely pursued in many fields, and many model-based and model-free methods have been explored. The former include rule-based, geometric or optimization-based models, and the latter are mainly comprised of deep learning approaches. In this paper, we propose a new method combining both methodologies based on a new Neural Differential Equation model. Our new model (Neural Social Physics or NSP) is a deep neural network within which we use an explicit physics model with learnable parameters. The explicit physics model serves as a strong inductive bias in modeling pedestrian behaviors, while the rest of the network provides a strong data-fitting capability in terms of system parameter estimation and dynamics stochasticity modeling. We compare NSP with 15 recent deep learning methods on 6 datasets and improve the state-of-the-art performance by 5.56%-70%. Besides, we show that NSP has better generalizability in predicting plausible trajectories in drastically different scenarios where the density is 2-5 times as high as the testing data. Finally, we show that the physics model in NSP can provide plausible explanations for pedestrian behaviors, as opposed to black-box deep learning. Code is available: https://github.com/realcrane/Human-Trajectory-Prediction-via-Neural-Social-Physics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Understanding human trajectories is key to many research areas such as physics, computer science and social sciences. Being able to learn behaviors with noninvasive sensors is important to analyzing the natural behaviors of humans. This problem has been widely studied in computer graphics, computer vision and machine learning <ref type="bibr" target="#b4">[5]</ref>. Existing approaches generally fall into model-based and model-free methods. Early model-based methods tended to be empirical or rule-based methods derived via the first-principles approach: summarizing observations into rules and deterministic systems based on fundamental assumptions on human motion. In such a perspective, social interactions can be modelled as forces in a particle system <ref type="bibr" target="#b19">[20]</ref> or an optimization problem <ref type="bibr" target="#b7">[8]</ref>, and individuals can be influenced by affective states <ref type="bibr" target="#b35">[36]</ref>. Later, data-driven modelbased methods were introduced, in which the model behavior is still dominated by the assumptions on the dynamics, e.g. a linear dynamical system <ref type="bibr" target="#b18">[19]</ref>, but retains sufficient flexibility so that the model can be adjusted to fit observations. More recently, model-free methods based on deep learning have also been explored, and these demonstrate surprising trajectory prediction capability <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr">49,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr">38,</ref><ref type="bibr">50,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">56,</ref><ref type="bibr" target="#b60">77,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b54">71]</ref>.</p><p>Empirical or rule-based methods possess good explainability because they are formed as explicit geometric optimization or ordinary/partial differentiable equations where specific terms correspond to certain behaviors. Therefore, they have been used for not only prediction but also analysis and simulation <ref type="bibr" target="#b42">[59]</ref>. However, they are less effective in data fitting with respect to noise and are therefore unable to predict accurately, even when the model is calibrated on data <ref type="bibr" target="#b53">[70]</ref>. Data-driven model-based methods (e.g., statistical machine learning) improve the ability of data fitting but are restricted by the specific statistical models employed which have limited capacities to learn from large amounts of data <ref type="bibr" target="#b18">[19]</ref>. Finally, deep learning approaches excel at data fitting. They can learn from large datasets, but lack explainability and therefore have been mainly used for prediction rather than analysis and simulation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr">38,</ref><ref type="bibr" target="#b60">77]</ref>.</p><p>We explore a model that can explain pedestrian behaviors and retain good data-fitting capabilities by combining model-based and model-free approaches. Inspired by recent research in neural differential equations <ref type="bibr" target="#b12">[13,</ref><ref type="bibr">44,</ref><ref type="bibr" target="#b58">75,</ref><ref type="bibr" target="#b61">78,</ref><ref type="bibr" target="#b24">25]</ref>, we propose a new crowd neural differentiable equation model consisting of two parts. The first is a deterministic model formulated using a differentiable equation. Although this equation can be arbitrary, we use a dynamical system inspired by the social force model <ref type="bibr" target="#b19">[20]</ref>. In contrast to the social force model and its variants, the key parameters of our deterministic model are learnable through data instead of being hand-picked and fixed. The second part of our model captures complex uncertainty in the motion dynamics and observations via a Variational Autoencoder. Overall, the whole model is a deep neural network with an embedded explicit model; we call this model Neural Social Physics (NSP).</p><p>We demonstrate that our NSP model outperforms the state-of-the-art methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr">49,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr">38,</ref><ref type="bibr">50,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">56,</ref><ref type="bibr" target="#b60">77,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b54">71]</ref> in standard trajectory prediction tasks across various benchmark datasets <ref type="bibr">[46,</ref><ref type="bibr">43,</ref><ref type="bibr" target="#b27">28]</ref> and metrics. In addition, we show that NSP can generalize to unseen scenarios with higher densities and still predict plausible motions with less collision between people, as opposed to pure black-box deep learning approaches. Finally, from the explicit model in NSP, we demonstrate that our method can provide plausible explanations for motions. Formally, <ref type="bibr" target="#b0">(1)</ref> we propose a new neural differentiable equation model for trajectory prediction and analysis. <ref type="bibr" target="#b1">(2)</ref> we propose a new mechanism to combine explicit and deterministic models with deep neural networks for crowd modeling. <ref type="bibr" target="#b2">(3)</ref> We demonstrate the advantages of the NSP model in several aspects: prediction accuracy, generalization and explaining behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Trajectory Analysis and Prediction</head><p>Statistical machine learning has been used for trajectory analysis in computer vision <ref type="bibr">[42,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b50">67,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b48">65,</ref><ref type="bibr" target="#b10">11]</ref>. They aim to learn individual motion dynamics <ref type="bibr" target="#b59">[76]</ref>, structured latent patterns in data <ref type="bibr" target="#b48">[65,</ref><ref type="bibr" target="#b47">64]</ref>, anomalies <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b10">11]</ref>, etc. These methods provide a certain level of explainability, but are limited in model capacity for learning from large amounts of data. Compared with these methods, our model leverages the ability of deep neural networks to handle high-dimensional and large data. More recently, deep learning has been exploited for trajectory prediction <ref type="bibr" target="#b37">[54]</ref>. Recurrent neural networks (RNNs) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b43">60]</ref> have been explored first due to their ability to learn from temporal data. Subsequently, other deep learning techniques and neural network architectures are introduced into trajectory prediction, such as Generative Adversarial Network (GAN) <ref type="bibr" target="#b17">[18]</ref>, conditional variational autoencoder (CVAE) <ref type="bibr" target="#b21">[22,</ref><ref type="bibr">38,</ref><ref type="bibr" target="#b60">77]</ref> and Convolutional Neural Network (CNN) <ref type="bibr">[39]</ref>. In order to capture the spatial features of trajectories and the interactions between pedestrians accurately, graph neural networks (GNNs) have also been used to reason and predict future trajectories <ref type="bibr">[39,</ref><ref type="bibr">53]</ref>. Compared with existing deep learning methods, our method achieves better prediction accuracy. Further, our method has an explicit model which can explain pedestrian motions and lead to better generalizability. Very recently, attempts have been made in combining physics with deep learning for trajectory prediction <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b20">21]</ref>. But their methods are tied to specific physics models and are deterministic, while NSP is a general framework that aims to accommodate arbitrary physics models and is designed to be intrinsically stochastic to capture motion randomness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pedestrian and Crowd Simulation</head><p>Crowd simulation aims to generate trajectories given the initial position and destination of each agent <ref type="bibr" target="#b42">[59]</ref>, which essentially aims to predict individual motions. Empirical modelling and data-driven methods have been the two foundations in simulation <ref type="bibr">[40,</ref><ref type="bibr" target="#b34">35]</ref>. Early research is dominated by empirical modelling or rulebased methods, where crowd motions are abstracted into mathematical equations and deterministic systems, such as flows [40], particle systems <ref type="bibr" target="#b19">[20]</ref>, and velocity and geometric optimization <ref type="bibr" target="#b7">[8,</ref><ref type="bibr">52]</ref>. Meanwhile, data-driven methods using statistical machine learning have also been employed, e.g., using first-person vision to guide steering behaviors <ref type="bibr" target="#b34">[35]</ref> or using trajectories to extract features to describe motions <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b51">68]</ref>. While the key parameters in these approaches are either fixed or learned from small datasets, our NSP model is more general. It can take existing deterministic systems as a component and provides better data-fitting capacity via deep neural networks. Compared with afore-mentioned model-based methods, our NSP can be regarded as using deep learning for model calibration. our model possesses the ability to learn from large amount of data, which is difficult for traditional parameter estimation methods based on optimization or sampling <ref type="bibr" target="#b45">[62]</ref>. Meanwhile, the formulation of our NSP is more general, flexible and data-driven than traditional model-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Deep Learning and Differential Equations</head><p>Solving differentiable equations (DE) with the assistance of deep learning has recently spiked strong interests <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b58">75,</ref><ref type="bibr" target="#b61">78,</ref><ref type="bibr" target="#b23">24]</ref>. Based on the involvement depth of deep learning, the research can be categorized into deep learning assisted DE, differentiable physics, neural differential equations and physics-informed neural networks (PINNs). Deep learning assisted DE involves accelerating various steps during the DE solve, such as Finite Element mesh generation <ref type="bibr" target="#b57">[74,</ref><ref type="bibr" target="#b56">73]</ref>. The deeper involvement of neural networks is shown in differentiable physics and neural differential equations, where the former aims to make the whole simulation process differentiable <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b52">69]</ref>, and the latter focuses on the part of the equations being parameterized by neural networks <ref type="bibr">[51]</ref>. PINNs aim to bypass the DE solve and use NN for prediction <ref type="bibr">[45,</ref><ref type="bibr" target="#b9">10]</ref>. Highly inspired by the research above, we propose a new neural differential equations model in a new application domain for human trajectory prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Neural Social Physics (NSP)</head><p>At any time t, the position p t i of the ith pedestrian can be observed in a crowd. Then a trajectory can be represented as a function of time q(t), where we have discrete observations in time up to T , {q 0 , q 1 , ? ? ? , q T }. An observation or state of a person at time t is represented by q t = [p t ,? t ] T where p,? ? R 2 are the position and velocity. For most datasets, p is given and? can be estimated via finite difference. Given an observation q t n of the nth person, we consider her neighborhood set ? t n containing other nearby pedestrians {q t j : j ? ? t n }. The neighborhood is also a function of time ?(t). Then, in NSP the dynamics of a person (agent) in a crowd can be formulated as:</p><formula xml:id="formula_0">dq dt (t) = f ?,? (t, q(t), ?(t), q T , E) + ? ? (t, q t:t?M )<label>(1)</label></formula><p>where ? and ? are learnable parameters, E represents the environment. ? contains interpretable parameters explained later and ? contains uninterpretable parameters (e.g. neural network weights). The agent dynamics are governed by f which depends on time t, its current state q(t), its time-varying neighborhood ?(t) and the environment E. Similar to existing work, we assume there is dynamics stochasticity in NSP. But unlike them which assume simple forms (e.g. white noise) <ref type="bibr" target="#b18">[19]</ref>, we model time-varying stochasticity in a more general form: as a function of time, the current state and the brief history of the agent, ? ? (t, q t:t?M ). Then we have the following equation in NSP:</p><formula xml:id="formula_1">q T = q 0 + T t=0 f ?,? (t, q(t), ?(t), q T , E) + ? ? (t, q t:t?M )dt<label>(2)</label></formula><p>given the initial and final condition q(0) = q 0 and q(T ) = q T .</p><p>Physics models have been widely used to model crowd dynamics <ref type="bibr">[40,</ref><ref type="bibr" target="#b19">20]</ref>. To leverage their interpretability, we model the dynamics as a physical system in NSP. Assuming the second-order differentiability of p(t), NSP expands q(t) via Taylor's series for a first-order approximation:</p><formula xml:id="formula_2">q(t + ?t) ? q(t) +q(t)?t = p(t) p(t) + ?t ?(t) + ?(t, q t:t?M ) p(t)<label>(3)</label></formula><p>where ?t is the time step. The stochasticity ?(t, q t:t?M ) is assumed to only influence?. Equation 3 is general and any dynamical system with second-order differentiability can be employed here. Below, we realize NSP by combining a type of physics models-social force models (SFM) <ref type="bibr" target="#b19">[20]</ref> and neural networks. We refer to our model NSP-SFM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">NSP-SFM</head><p>We design the NSP-SFM by assuming each person acts as a particle in a particle system and each particle is governed by Newton's second law of motion.p(t) is designed to be dependent on three forces: goal attraction F goal , inter-agent repulsion F col and environment repulsion F env .</p><formula xml:id="formula_3">p(t) = F goal (t, q T , q t ) + F col (t, q t , ? t ) + F env (t, q t , E)<label>(4)</label></formula><p>where E is the environment and explained later. However, unlike <ref type="bibr" target="#b19">[20]</ref>, the three forces are partially realized by neural networks, turning Equation 1 into a neural differential equation. The overall model is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Note that, in Equation 1, we assume p T is given, although it is not available during prediction. Therefore, we employ a Goal Sampling Network (GSN) to sample p T . During testing, we either first sample a p T for prediction or require the user to input p T . The GSN is similar to a part of Y-net <ref type="bibr" target="#b36">[37]</ref> and pre-trained, and detailed in the supplementary materials. Given the current state and the goal, we compute F goal using the Goal-Network N N ?1 in Eq. 5 ( <ref type="figure" target="#fig_1">Fig. 2</ref> Left), F col using the Collision-Network N N ?2 in   Eq. 6 ( <ref type="figure" target="#fig_1">Fig. 2</ref> Right) and F env using Eq. 7 directly. The Goal-Network encodes q t then feeds it into a Long Short Term Memory (LSTM) network to capture dynamics. After a linear transformation, the LSTM output is concatenated with the embedded p T . Finally, ? is computed by an MLP (multi-layer perceptron). In Collision-Network, the architecture is similar. Every agent q t j in the neighborhood ? t n is encoded and concatenated with the encoded agent q t n . Then k nj is computed. ? and k nj are interpretable key parameters of F goal and F col . The corresponding parameter in F env is k env . Finally, we show our network for ? for stochasticity modeling in <ref type="figure" target="#fig_2">Figure 3</ref>.</p><p>Goal attraction. Pedestrians are always drawn to destinations, which can be abstracted into a goal attraction force. At time t, a pedestrian has a desired walking direction e t determined by the goal p T and the current position p t :</p><formula xml:id="formula_4">e t = p T ?p t ?p T ?p t ? .</formula><p>If there are no other forces, she will change her current velocity to the desired velocity v t des = v t 0 e t where v t 0 and e t are the magnitude and direction respectively. Instead of using a fixed v 0 as in <ref type="bibr" target="#b19">[20]</ref>, we update v t 0 at every t to mimic the change of the desired speed as the pedestrian approaches the destination:</p><formula xml:id="formula_5">v t 0 = ?p T ?p t ? (T ?t)?t . Therefore, the desired velocity is defined as v t des = v t 0 e t = p T ?p t (T ?t)?t .</formula><p>The goal attraction force F goal represents the tendency of a pedestrian changing her current velocity? t to the desired velocity v t des within time ? : where ? is learned through a neural network (NN) parameterized by ? 1 .</p><formula xml:id="formula_6">F goal = 1 ? (v t des ?? t ) where ? = N N ?1 (q t , p T )<label>(5)</label></formula><p>Inter-agent Repulsion. Pedestrians often steer to avoid potential collisions and maintain personal space when other people are in the immediate neighborhood ( <ref type="figure" target="#fig_3">Fig. 4 a)</ref>. Given an agent j in ? t n of agent n and her state q t j , agent j repels agent n based on r nj = p t n ? p t j :</p><formula xml:id="formula_7">F nj col = ?? rnj U nj (?r nj ?) , where U nj (?r nj ?) = r col k nj e ??rnj ?/r col<label>(6)</label></formula><p>where we employ a repulsive potential field U nj (?r nj ?) modeled by a monotonic decreasing function of ?r nj ?. Then the repulsive force caused by agent j ? ? t n to agent n is the gradient of U nj . Previously, simple functions such as symmetric elliptic fields were employed for U nj <ref type="bibr" target="#b19">[20]</ref>. Here, we model U nj as a time-varying field parameterized by k nj which is learned via a neural network. Instead of directly learning k nj , we set k nj = a * sigmoid(N N ?2 (q t n , q t j,j?? t n )) + b. a and b are hyperparameters to ensure that the learned k nj value is valid. If we have m agents at time t in ? t n , the net repulsive force on agent n is: F n col = m j=0 F nj col . Environment Repulsion. Besides collisions with others, people also avoid nearby obstacles. We model the repulsion from the environment as:</p><formula xml:id="formula_8">F env = k env ?p t n ? p obs ? ( p t n ? p obs ?p t n ? p obs ? )<label>(7)</label></formula><p>where p obs is the position of the obstacle and k env is a learnable parameter. NSP-SFM learns k env directly via back-propagation and stochastic gradient descent.</p><p>Since the environment is big, we assume the agent mainly focuses on her view field ( <ref type="figure" target="#fig_3">Fig. 4 b)</ref> within which the environment ( <ref type="figure" target="#fig_3">Fig. 4</ref> c) repels the pedestrian. We calculate p obs as the center of the pixels that are classified as obstacles in the view field of an agent. k env is shared among all obstacles. So far, we have introduced all the interpretable parameters ? = {?, k nj , k env } in Equation 1.</p><p>Dynamics Stochasticity ?(t, q t:t?M ). Trajectory prediction needs to explicitly model the motion randomness caused by intrinsic motion stochasticity and observational noises <ref type="bibr" target="#b46">[63,</ref><ref type="bibr" target="#b47">64]</ref>. We employ a more general setting by assuming the noise distribution can have arbitrary shapes and is also time varying, unlike previous formulations such as white noise <ref type="bibr" target="#b18">[19]</ref> which is too restrictive. Generally, learning such functions requires large amounts of data, as it is unconstrained. To constrain the learning, we further assume the noise is Normally distributed in a latent space, rather than in the data space.</p><p>Given a predictionp t+1 without dynamics stochasticity and its corresponding observation p t+1 , there is an error ? t+1 =p t+1 ? p t+1 . To model the arbitrary and time-varying shape of the distribution of ? t+1 , we assume it depends on the brief history p t:t?M which implicitly considers the environment and other people. Then the conditional likelihood of ? t+1 is:</p><formula xml:id="formula_9">P (? t+1 |p t:t?M ) = P (? t+1 |p t:t?M , z)P (z)dz, where z is a latent variable.</formula><p>Assuming a mapping Q(z|? t+1 , p t:t?M ) and z being Normally distributed, minimizing the KL divergence between Q, i.e., the variational posterior, and P (z|? t+1 , p t:t?M ) leads to a conditional Variational Autoencoder (CVAE) <ref type="bibr" target="#b38">[55]</ref>.</p><p>Our overall loss function is defined as L = l traj + l cvae where:</p><formula xml:id="formula_10">l traj = 1 N (T ? M ) N n=1 T t=M +1 ?p t n ?p t n ? 2 2 l cvae = 1 N (T ? M ) N n=1 T t=M +1 {?? t n ?? t n ? 2 2 + ?D KL (Q(z|? t n , p t:t?M )||P (z|? t n , p t:t?M ))} (8)</formula><p>N is the total number of samples, M is the length of the history, and T is the total length of the trajectory. l traj minimizes the difference between the predicted position and the ground-truth, while l cvae learns the distribution of randomness ?. During training, in each iteration, we assume the first M + 1 frames of the trajectory are given and run the forward pass iteratively to predict the rest of the trajectory, then back-propagate to compute the gradient to update all parameters. During the forward pass, we use a semi-implicit scheme for stability: p t+1 =? t + ?tp t and p t+1 = p t + ?t? t+1 . We employ a progressive training scheme for the sub-nets. We first train Goal-Network with l traj only, then fix Goal-Network and add Collision-Network and F env for training using l traj . Finally, we fix Goal-Network, Collision-Network and F env , add ? for training under l cvae . We find this progressive training significantly improves the convergence speed. This is because we first train the deterministic part with the main forces added gradually, which converges quickly. Then the stochasticity part is trained separately to capture complex randomness. Please see the supplementary material for implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">NSP vs. Deep Neural Networks</head><p>One big difference between NSP and existing deep learning is the deterministic system embedded in NSP. Instead of learning any function mapping the input to the output (as black box deep learning does), the deterministic system acts as a strong inductive bias and constrains the functional space within which the target mapping should lie. This is because a PDE family can be seen as a flow connecting the input and the output space <ref type="bibr" target="#b1">[2]</ref>, and the learning is essentially a process of finding the most fitting PDE within this flow. In addition to better data-fitting capability, this strong inductive bias also comes with two other advantages. First, the learned model can help explain motions because the PDE we employ is a physics system where the learnable parameters have physical meanings. Second, after learning, the PDE can be used to predict motions in drastically differ-and the ground truth. Following prior works, in the presence of multiple possible future predictions, the minimal error is reported. We compare our NSP-SFM with an extensive list of baselines, including published papers and unpublished technical reports: Social GAN (S-GAN) <ref type="bibr" target="#b17">[18]</ref>, Sophie [49], Conditional Flow VAE (CF-VAE) <ref type="bibr" target="#b8">[9]</ref>, Conditional Generative Neural System (CGNS) <ref type="bibr" target="#b28">[29]</ref>, NEXT <ref type="bibr" target="#b32">[33]</ref>, P2TIRL <ref type="bibr" target="#b13">[14]</ref>, SimAug <ref type="bibr" target="#b30">[31]</ref>, PECNet [38], Traj++ [50], Multiverse <ref type="bibr" target="#b31">[32]</ref>, Y-Net <ref type="bibr" target="#b36">[37]</ref>, SIT <ref type="bibr" target="#b39">[56]</ref>, S-CSR <ref type="bibr" target="#b60">[77]</ref>, Social-DualCVAE <ref type="bibr" target="#b15">[16]</ref> and CSCNet <ref type="bibr" target="#b54">[71]</ref>. We divide the baselines into two groups due to their setting differences. All baseline methods except S-CSR report the minimal error out of 20 sampled trajectories. S-CSR achieved better results by predicting 20 possible states in each step, and it is the only method adopting such sampling to our best knowledge. We refer to the former as standard-sampling and the latter as ultra-sampling. We compare NSP-SFM with S-CSR and other baseline methods under their respective settings. Standard-sampling results are shown in <ref type="table" target="#tab_0">Table 1</ref>. On SDD, NSP-SFM outperforms the best baseline Y-Net by 16.94% and 10.46% in ADE and FDE, respectively. In ETH/UCY, the improvement on average is 5.56% and 11.11% in ADE and FDE, with the maximal ADE improvement 12.5% in UNIV and the maximal FDE improvement 27.27% in ETH. We also compare NSP-SFM with S-CSR in <ref type="table" target="#tab_1">Table 2</ref>. NSP-SFM outperforms S-CSR on ETH/UCY by 70% and 62.5% on average in ADE and FDE. In SDD, the improvement is 35.74% and 0.3% ( <ref type="table" target="#tab_1">Table 2</ref>). S-CSR is stochastic and learns per-step distributions, which enables it to draw 20 samples for every step during prediction. Therefore, the min error of S-CSR is much smaller than the other baselines. Similarly, NSP-SFM also learns a per-step distribution (the ? function) despite its main behavior being dictated by a deterministic system. Under the same ultra-sampling setting, NSP-SFM outperforms S-CSR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Generalization to Unseen Scenarios</head><p>We evaluate NSP-SFM on significantly different scenarios after training. We increase the scene density as it is a major factor in pedestrian dynamics <ref type="bibr">[41]</ref>. This is through randomly sampling initial and goal positions and let NSP-SFM predict the trajectories. Since there is no ground truth, to evaluate the prediction plausibility, we employ collision rate because it is widely adopted <ref type="bibr" target="#b33">[34]</ref> and parsimonious: regardless of the specific behaviors of agents, they do not penetrate each other in the real world. The collision rate is computed based on the percentage of trajectories colliding with one another. We treat each agent as a disc with radius r = 0.2 m in ECY/UCY and r = 15 pixels in SDD. Once the distance between two agents falls below 2r, we count the two trajectories as in collision. Due to the tracking error and the distorted images, the ground truth r is hard to obtain. We need to estimate r. If it is too large, the collision rate will be high in all cases; otherwise the collision rate will be too low, e.g., r = 0 will give 0% collision rate all the time. Therefore, we did a search and found that the above values are reasonable as they keep the collision rate of the ground-truth data approximately zero. We show two experiments. The first is the collision rate on the testing data, and the second is scenarios with higher densities. While the first is mainly to compare the plausibility of the prediction, the second is to test the model generalizability. For comparison, we choose two state-of-the-art baseline methods: Y-net and S-CSR. Y-net is published which achieves the best performance, while S-CSR is unpublished but claims to achieve better performance. <ref type="table" target="#tab_2">Table 3</ref> shows the comparison of the collision rate. NSP-SFM outperforms the baseline methods in generating trajectories with fewer collisions. Y-net and S-CSR also perform well on the testing data because their predictions are close to the ground-truth. Nevertheless, they are still worse than NSP-SFM. Next, we test drastically different scenarios. We use ZARA2 and coupa0 (a sub-dataset from SDD) as the environment and randomly sample the initial positions and goals for 32 and 50 agents respectively. Because the highest number of people that simultaneously appear in the scene is 14 in ZARA2 and 11 in coupa0, we effectively increase the density by 2-5 times. For NSP-SFM, the initial and goal positions are sufficient. For Y-net and S-CSR which require 8 frames (3.2 Seconds) as input, we use NSP-SFM to simulate the first 8 frames of each agent, then feed them into both baselines. <ref type="table">Table 4</ref> shows the results of three experi-  ments. Since the density is significantly higher than the data, both Y-net and S-CSR cause much higher collision rate. While NSP-SFM's collision rate also occasionally increases (i.e. SDD) compared with <ref type="table" target="#tab_2">Table 3</ref>, it is far more plausible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Interpretability of Prediction</head><p>Unlike black-box deep learning methods, NSP-SFM has an embedded explainable model. While predicting a trajectory, NSP can also provide plausible explanations of the motion, by estimating the 'forces' exerted on a specific person. This potentially enables NSP-SFM to be used in applications beyond prediction, e.g. behavior analysis <ref type="bibr" target="#b55">[72]</ref>. <ref type="figure" target="#fig_4">Figure 5</ref> Left shows that a person, instead of directly walking towards the goal, steered upwards (the green trajectory in the orange  <ref type="table">Table 4</ref>. Collision rates of the generalization experiments on ZARA2 (Z) and coupa0 (C). NSP-SFM shows strong generalizability in unseen high density scenarios.  area). This could be explained by the strong repulsive force (the light blue arrow) which is generated by the potential collisions with the agents in front of this person, in line with existing studies <ref type="bibr">[41]</ref>. Similar explanations can be made in <ref type="figure" target="#fig_4">Figure 5</ref> Middle, where all three forces are present. F env (the black arrow) is the most prominent, as expected, as the person is very close to the car. The repulsive force (light blue arrow) also plays a role due to the person in front of the agent (the blue dot in the orange area). <ref type="figure" target="#fig_4">Figure 5</ref> Right shows an example where motion randomness is captured by NSP. In this example, there was no other pedestrian and the person was not close to any obstacle. However, the trajectory still significantly deviates from a straight line, which cannot be fully explained by e.g. the principle of minimal energy expenditure <ref type="bibr" target="#b44">[61]</ref>. The deviation could be caused by unobserved factors, e.g. the agent changing her goal or being distracted by something on the side. These factors do not only affect the trajectory but also the dynamics, e.g. sudden changes of velocity. These unobserved random factors are implicitly captured by the CVAE in NSP-SFM. More results are in the supplementary material.</p><formula xml:id="formula_11">Methods Z(1) Z(2) Z(3) Z(avg) C(1) C(2) C(3) C(avg) Y-</formula><p>We emphasize that NSP-SFM merely provides plausible explanations and by no means the only possible explanations. Although explaining behaviors based on physics models has been widely used, there can be alternative explanations <ref type="bibr" target="#b49">[66]</ref>. Visualizing the forces is merely one possible way. Theoretically, it is also possible to visualize deep neural networks, e.g. layer activation. However, it is unclear how or which layer to visualize to explain the motion. Overall, NSP-SFM is more explainable than black-box deep learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablation Study</head><p>To further investigate the roles of different components, we conduct an ablation study on SDD with three settings: F goal (w/o) with goal attraction only, i.e. omitting other components such as F col , F env and dynamics stochasticity; NSP-SFM (w/o) without dynamics stochasticity; and NSP-SFM (w) the full model. The results are shown in <ref type="table" target="#tab_4">Table 5</ref>. Interestingly, F goal (w/o) can already achieve good results. This is understandable as it is trained first in our progressive training scheme and catches most of the dynamics. NSP-SFM (w/o) further improves the performance. The improvement seems to be small but we find the other repulsive forces are crucial for trajectories with irregular geometries such as avoiding obstacles. Further NSP-SFM (w) significantly improves the results because it enables NSP to learn the dynamics stochasticity via a per-step distribution. We show one example in <ref type="figure" target="#fig_5">Figure 6</ref> in all settings. More ablation experiments can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions, Limitations, and Future Work</head><p>In this paper, we have proposed a new Neural Differential Equation model for trajectory prediction. Through exhaustive evaluation and comparison, our model, Neural Social Physics, has proven to be more accurate in trajectory prediction, generalize well in significantly different scenarios and can provide possible explanations for motions. The major limitation of NSP lies in the physics model, which overly simplifies people into 2D particles. In real-world scenarios, people are much more complex, and their motions can be influenced by other factors such as their affective states or interact with dense scenarios <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. It would be useful to extend our NSP framework by incorporating these ideas and handle complex systems such as fluids/fields/agent-based modeling can be adopted to replace the components in Equation 3. In the future, we would like to extend the current framework to model high-density crowds, where continuum models or reciprocal velocity obstacles need to be used. We would also like to incorporate learning-based collision detection techniques into this framework <ref type="bibr" target="#b40">[57,</ref><ref type="bibr" target="#b41">58]</ref>. A Additional Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Generalization to Unseen Scenarios</head><p>We use the collision rate to evaluate prediction plausibility. We first elaborate on the definition of the collision rate and then show more experimental results. Provided there are N agents in a scene, we consider their collision rates during a period of time such as 4.8 seconds which is widely used to evaluate trajectory predictions <ref type="bibr">[38,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b60">77]</ref>. We count one collision if the minimum distance between two agents is smaller than 2r at any time, where r is the radius of a disc representing an agent. The maximum possible number of collisions is N (N ? 1)/2. The final collision rate is defined as:</p><formula xml:id="formula_12">R col = M N (N ? 1)/2 (9)</formula><p>where M is the number of collisions. We show more results on the scene, coupa0, with different numbers of agents. We chose coupa0 because it is a large space and can accommodate many people. The highest number of people simultaneously in the environment in the original data is merely 11. Therefore, this is a good scene to show how different methods can generalize to higher densities when learning from low density data. In each experiment, the agents are randomly initialized with different initial positions, initial velocities and goals near the boundary of the scene, which is sufficient  for our method to simulate. Therefore, we use NSP to predict trajectories of 30 seconds (t = 0 to 29) at FPS = 10 for all agents. We sample three intervals out of every trajectory, from t = 0 to 8, t = 4 to 12 and t = 8 to 16, where the density in the central area reaches the highest during t=8 to 16. For each interval (8 seconds long), we subsample at FPS = 2.5 to get 20 frames, where the first 8 frames are used as input for Y-net <ref type="bibr" target="#b36">[37]</ref> and S-CSR <ref type="bibr" target="#b60">[77]</ref>. The remaining 12 frames and the predictions (12 frames) of Y-net and S-CSR are used to calculate the collision rate. Before prediction, all methods are trained on the training dataset of SDD under the same setting explained in the main paper.</p><p>The results are shown in <ref type="table" target="#tab_5">Table 6</ref>. We tested 50, 74, 100, 150 and 200 agents on the aforementioned three methods including ours. We can see that our method is always the best in the collision rate under different settings. Although its collision rate increases with the growth of the number of agents, our method is still the best compared with the baselines and our predictions are more plausible. In addition, we also plot the relation between the collision rate (and the number of collisions) and the agent number ranging from 50 to 200 in <ref type="figure" target="#fig_7">Figure 7</ref>. Y-net is worse than S-CSR and NSP. In addition, although the trend of NSP and S-CSR are similar, the number of collisions of S-CSR increases faster than NSP. Finally, some visualization results can be found in <ref type="figure" target="#fig_8">Figure 8</ref>. Here, every green disc has a radius of 7.5 pixels. When two green discs intersect, they collide with each other. <ref type="figure" target="#fig_8">Figure 8</ref> demonstrates that our method (NSP) has better performance in avoiding collisions than Y-net and S-CSR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Interpretability of Prediction</head><p>More examples of interpretability are shown in <ref type="figure">Figure 9</ref>. In <ref type="figure">Figure 9</ref> (1)-(2), we show the influence of different three forces, F goal , F col and F env , on the whole trajectory of an agent. In <ref type="figure">Figure 9</ref> (3)-(4), we choose two consecutive moments of one agent for analysis. In <ref type="figure">Figure 9</ref> (1), instead of directly aiming for the goal, the agent suddenly turns (at the intersection between red and green dots) due to the incoming agents (the three blue dots under the green dots). The result is a result of major influence from F goal and F col . Similarly, the agent in <ref type="figure">Figure 9</ref> (2) did not need to avoid other agents but still did not directly walk towards the goal, because of F env from the grass. In <ref type="figure">Figure 9</ref> (3)-(4), we show the detailed analysis of forces at two consecutive time steps of the same agent, where F env is from the lawn which is a 'weakly repulsive area'. More examples where randomness is captured by our model are shown in <ref type="figure" target="#fig_0">Figure 10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Ablation Experiments</head><p>We conduct more ablation experiments to further validate our design decisions and explore the effect of components of our model. The ablation studies on the network architectures focuses on the Goal-Network and the Collision-Network.</p><p>The main variants are with/without LSTM to show the importance of the temporal modeling for learning ? and k nj , and replacing the MLPs with simple two-layer MLPs. <ref type="table" target="#tab_6">Table 7</ref> shows the results on SDD. We can see that the tem- <ref type="figure">Fig. 9</ref>. Examples of interpretability. Red dots are observed, green dots are our prediction. Bule dots in <ref type="formula" target="#formula_0">(1)</ref>, <ref type="formula" target="#formula_2">(3)</ref> and <ref type="formula" target="#formula_3">(4)</ref> are other pedestrians at time step 7, 16 and 17 respectively. We show the influence of all forces, F goal , F col and Fenv, on the whole trajecroty in <ref type="formula" target="#formula_0">(1)</ref> and <ref type="formula" target="#formula_1">(2)</ref>. We display detailed analysis of three forces at two consecutive time steps of the same agent, where F goal , F col and Fenv are shown as yellow, light blue and black arrows respectively. poral modeling and the original MLPs make our model achieve the best performance. To understand the role of each component in our model, we take social force model (SFM) as the baseline and incrementally add components from our model. The results are shown in <ref type="table">Table 8</ref>. We tried our best to manually find good parameter values: ? = 0.5, k nj =25/50 and k env =65. We adopted the same way with our model to sample destinations for SFM. Then we only learn ? and k nj . At last, the result of the full model without CVAE is given. The performance is better when more components are added.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Details of the Neural Social Physics Model</head><p>In this section, we elaborate the details of the Goal Sampling Network (GSN) and the conditional Variational Autoencoder (CVAE) in our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Goal Sampling Network</head><p>The main components of the GSN are two U-nets [47] as illustrated in <ref type="figure" target="#fig_0">Figure 11</ref>. We first feed the scene image I to a U-net, U seg , to get its corresponding en-  <ref type="bibr" target="#b36">[37]</ref>. NSP can use manually annotated or automatically segmented environment maps to calculate F env , but using segmentation maps from the GSN is more efficient. Then the past trajectories {p t } M t=0 are converted into M+1 trajectory heatmaps by:</p><formula xml:id="formula_13">Hm(t, i, j) = 2 ?(i, j) ? p t ? max (x,y)?I ?(x, y) ? p t ?<label>(10)</label></formula><p>where (i, j) is the pixel coordinate on the heatmap and (x, y) is the pixel coordinate on the scene image I. Then, we concatenate these trajectory heatmaps and the segmentation map to get the input with dimension of H * W * (K c +M +1) for the network U goal . U goal will output a non-parametric probability distribution map,D goal , with dimensions H * W . Every pixel inD goal has a corresponding probability value between 0 and 1, and their sum is equal to 1. Details of these two U-nets can be found in <ref type="bibr" target="#b36">[37]</ref>. We train the GSN by minimizing the Kullback-Leibler divergence between predictedD goal and its ground truth D goal . We assume that D goal is a discrete gaussian distribution with a mean at the position of the ground-truth goal and a hyper-parameter variance ? goal . During testing, instead of picking the position with highest probability, we adopt the test-time sampling trick introduced by <ref type="bibr" target="#b36">[37]</ref> to sample goals for better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Conditional Variational Autoencoder</head><p>We model the dynamics stochasticity for each agent individually by using a CVAE as illustrated in <ref type="figure" target="#fig_0">Figure 12</ref>. Red connections are only used in the training <ref type="figure" target="#fig_0">Fig. 11</ref>. Model Architecture of Goal Sampling Network. The detailed network architecture of two U-nets, Useg and U goal , can be found in <ref type="bibr" target="#b36">[37]</ref>. phase. Given an agent p t and his/her destination, a deterministic predictionp t+1 without dynamics stochasticity is first calculated from F goal , F col and F env and a semi-implicit scheme. During training time, we use the corresponding ground truth p t+1 to calculate the error ? t+1 = p t+1 ?p t+1 , and feed ? t+1 into an encoder E bias to get the feature f bias . The brief history (p t?7 , . . . , p t?1 , p t ) is encoded as f past by using an encoder E past . We concatenate f bias with f past and encode it using a latent encoder to yield the parameters (?, ?) of the gaussian distribution of the latent variable Z. We sample Z, concatenate it with f past for history information, and decode using the decoder D latent to acquire our guess for stochasticity? t+1 . Finally, the estimated stochasticity will be added to the deterministic predictionp t+1 to get our final predictionp t+1 . During testing time, the ground truth p t+1 is unavailable. Therefore, we sample the latent variable Z from a gaussian distribution N (0, ? latent I) where ? latent is a hyperparameter. We concatenate the sampled Z and f past to decode directly using the learned decoder D latent to get the estimate of stochasticity? t+1 . We can produce final predictionp t+1 using the same way as the training phase. Encoders E bias , E past , E latent and the decoder D latent are all multi-layer perceptrons (MLP) with dimensions indicated in the square brackets in <ref type="figure" target="#fig_0">Figure 12</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Implementation Details</head><p>We use ADAM as the optimizer to train the Goal-Network, Collision-Network and F env with a learning rate between 3 ? 10 ?5 and 3 ? 10 ?4 , and to train the CVAE with a learning rate between 3 ? 10 ?6 and 3 ? 10 ?5 . When we train the CVAE of our model, the training data is scaled by 0.005 to balance reconstruction error and KL-divergence in l cvae . The hyper-parameter ? in l cvae is set to 1.</p><p>Concrete structures of all sub-network are shown in <ref type="figure" target="#fig_0">Figure 12</ref>.</p><p>For the Goal-Network, instead of learning parameter ? directly, we set ? = a * sigmoind(N N ?1 (q t , p T )) + b where a and b are hyper-parameters. We list all hyper-parameters of our model in <ref type="table" target="#tab_7">Table 9</ref>. We segment scene images into two  classes and three classes on ETH/UCY and SDD, respectively. The two classes on ETH/UCY are 'walkable area' and 'unwalkable area'. Three classes on SDD include 'walkable area', 'unwalkable area' and 'weakly repulsive area' that some people tend to avoid such as lawns. The calculation of F env on ETH/UCY has been introduced in our main paper. On SDD, we calculate the position of the obstacle p obs and the position of the weak obstacle p w?obs (i.e. in the weakly repulsive area) by averaging pixels that are classified as 'unwalkable area' and 'weak repulsive area' respectively. Then, the F env consists of two repulsive forces from p obs and p w?obs as shown in <ref type="bibr">Equation 11</ref>, where the parameter k env is shared and an additional hyper-parameter ? weak is introduced for p w?obs :</p><formula xml:id="formula_14">F env = k env ?p t n ? p obs ? ( p t n ? p obs ?p t n ? p obs ? ) + ? weak k env ?p t n ? p w?obs ? ( p t n ? p w?obs ?p t n ? p w?obs ? )<label>(11)</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Overview of NSP-SFM. F goal , F col and Fenv are estimated in every time step by Goal-Network, Collision-Network and Eq. 7 before solving Eq. 4. The output is used to update the position and velocity which are then combined with the estimated noise from ? for the final prediction</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Left: Goal-Network and Right: Collision-Network. The numbers in square brackets show both the number and dimension of the layers in each component.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>The architecture of the CVAE, wherep t+1 is the intermediate prediction out of our force model and ? t+1 = p t+1 ?p t+1 . Encoder E bias , Epast, E latent and decoder D latent are all MLP networks with dimensions indicated in the square brackets. More Details of the network can be found in the supplementary material</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>(a) The neighborhood ?(t) of a person is a sector within a circle (centered at this person with radius r col ) spanned by an angle ? from the current velocity vector (green arrow). (b) Each person has a view field (orange box) within which the environment repels a pedestrian. The view field is a square with dimension renv based on the current velocity vector (green arrow). The current velocity is along the diagonal of the orange box. (c) The environment is segmented into walkable (red) and unwalkable (blue) areas. Within the view field of the pedestrian in (b), the yellow pixels are the environment pixels that repel the pedestrian. ?, r col and renv are hyperparameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Red dots are observed, green dots are our prediction and black dots are the ground-truth. Blue dots are pedestrians. F goal , F col and Fenv are shown as yellow, light blue and black arrows for a person. The orange areas are the view field for avoiding collisions with other people (left) and the environment (middle). They provide plausible explanations of individual behaviors such as steering. Left and middle show the major influence of different forces. Right shows motion randomness captured by our model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Red, green and cyan dots are observations, prediction and ground-truth respectively. From left to right: ground truth, F goal (w/o), NSP-SFM(w/o) and NSP-SFM(w).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>38. Mangalam, K., Girase, H., Agarwal, S., Lee, K.H., Adeli, E., Malik, J., Gaidon, A.: It is not the journey but the destination: Endpoint conditioned trajectory prediction. In: European Conference on Computer Vision. pp. 759-776. Springer (2020) 39. Mohamed, A., Qian, K., Elhoseiny, M., Claudel, C.: Social-stgcnn: A social spatiotemporal graph convolutional neural network for human trajectory prediction. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 14424-14432 (2020) 40. Narain, R., Golas, A., Curtis, S., Lin, M.C.: Aggregate dynamics for dense crowd simulation. In: ACM SIGGRAPH Asia 2009 papers, pp. 1-8 (2009) 41. Narang, S., Best, A., Curtis, S., Manocha, D.: Generating pedestrian trajectories consistent with the fundamental diagram based on physiological and psychological factors. PLoS one 10(4), e0117856 (2015) 42. Oliver, N.M., Rosario, B., Pentland, A.P.: A bayesian computer vision system for modeling human interactions. IEEE transactions on pattern analysis and machine intelligence 22(8), 831-843 (2000) 43. Pellegrini, S., Ess, A., Gool, L.V.: Improving data association by joint modeling of pedestrian trajectories and groupings. In: European conference on computer vision. pp. 452-465. Springer (2010) 44. Rackauckas, C., Ma, Y., Martensen, J., Warner, C., Zubov, K., Supekar, R., Skinner, D., Ramadhan, A., Edelman, A.: Universal differential equations for scientific machine learning. arXiv preprint arXiv:2001.04385 (2020) 45. Raissi, M., Perdikaris, P., Karniadakis, G.E.: Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. Journal of Computational physics 378, 686-707 (2019) 46. Robicquet, A., Sadeghian, A., Alahi, A., Savarese, S.: Learning social etiquette: Human trajectory understanding in crowded scenes. In: European conference on computer vision. pp. 549-565. Springer (2016) 47. Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks for biomedical image segmentation. In: International Conference on Medical image computing and computer-assisted intervention. pp. 234-241. Springer (2015) 48. Sadeghian, A., Kosaraju, V., Gupta, A., Savarese, S., Alahi, A.: Trajnet: Towards a benchmark for human trajectory prediction. arXiv preprint (2018) 49. Sadeghian, A., Kosaraju, V., Sadeghian, A., Hirose, N., Rezatofighi, H., Savarese, S.: Sophie: An attentive gan for predicting paths compliant to social and physical constraints. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 1349-1358 (2019) 50. Salzmann, T., Ivanovic, B., Chakravarty, P., Pavone, M.: Trajectron++: Dynamically-feasible trajectory forecasting with heterogeneous data. In: European Conference on Computer Vision. pp. 683-700. Springer (2020) 51. Shen, S., Yang, Y., Shao, T., Wang, H., Jiang, C., Lan, L., Zhou, K.: High-order differentiable autoencoder for nonlinear model reduction. ACM Trans. Graph. 40(4) (jul 2021) 52. Shen, Y., Henry, J., Wang, H., Ho, E.S.L., Komura, T., Shum, H.P.H.: Data-Driven Crowd Motion Control With Multi-Touch Gestures. Computer Graphics Forum (2018). https://doi.org/10.1111/cgf.13333 53. Shi, L., Wang, L., Long, C., Zhou, S., Zhou, M., Niu, Z., Hua, G.: Sgcn: Sparse graph convolution network for pedestrian trajectory prediction. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 8994-9003 (2021)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 7 .</head><label>7</label><figDesc>The collision rate and the number of collisions against the number of agents are shown in (a) and (b) respectively. Both of horizontal axes represent the number of agents from 50 to 200. The vertical axes in (a) and (b) represent the collision rate and the number of collisions respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>The visualization results of generalization to 74, 100, 150 and 200 agents on coupa0 are shown in (a), (b), (c) and (d) respectively. For each experimental setting, visualization results of NSP, Y-net and S-CSR are at the same frame. We amplify the area of red ellipse to boxes with yellow borders for better visualization performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 10 .</head><label>10</label><figDesc>Motion randomness is captured by our model. Red dots are observed, green dots are our prediction and black dots are the ground-truth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 12 .</head><label>12</label><figDesc>The architecture of the CVAE, wherep t+1 is the intermediate prediction out of our force model and ? t+1 = p t+1 ?p t+1 . Encoder E bias , Epast, E latent and decoder D latent are all MLP networks with dimensions indicated in the square brackets. Red connections are only used in the training phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Results on ETH/UCY and SDD based standard-sampling. NSP-SFM outperforms all baseline methods in both ADE and FDE. 20 samples are used in prediction and the minimal error is reported. M = 7 in all experiments. The unit is meters on ETH/UCY and pixels on SDD.</figDesc><table><row><cell>Methods</cell><cell cols="2">Metrics ETH</cell><cell cols="5">Hotel UNIV ZARA1 ZARA2 AVG</cell><cell>SDD</cell></row><row><cell>S-GAN [18]</cell><cell>ADE FDE</cell><cell>0.81 1.52</cell><cell>0.72 1.61</cell><cell>0.60 1.26</cell><cell>0.34 0.69</cell><cell>0.42 0.84</cell><cell>0.58 1.18</cell><cell>27.23 41.44</cell></row><row><cell>Sophie [49]</cell><cell>ADE FDE</cell><cell>0.70 1.43</cell><cell>0.76 1.67</cell><cell>0.54 1.24</cell><cell>0.30 0.63</cell><cell>0.38 0.78</cell><cell>0.54 1.15</cell><cell>16.27 29.38</cell></row><row><cell>CF-VAE [9]</cell><cell>ADE FDE</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>12.60 22.30</cell></row><row><cell>CGNS [29]</cell><cell>ADE FDE</cell><cell>0.62 1.40</cell><cell>0.70 0.93</cell><cell>0.48 1.22</cell><cell>0.32 0.59</cell><cell>0.35 0.71</cell><cell>0.49 0.97</cell><cell>15.6 28.2</cell></row><row><cell>NEXT [33]</cell><cell>ADE FDE</cell><cell>0.73 1.65</cell><cell>0.30 0.59</cell><cell>0.60 1.27</cell><cell>0.38 0.81</cell><cell>0.31 0.68</cell><cell>0.46 1.00</cell><cell>N/A N/A</cell></row><row><cell>P2TIRL [14]</cell><cell>ADE FDE</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>12.58 22.07</cell></row><row><cell>SimAug [31]</cell><cell>ADE FDE</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>10.27 19.71</cell></row><row><cell>PECNet [38]</cell><cell>ADE FDE</cell><cell>0.54 0.87</cell><cell>0.18 0.24</cell><cell>0.35 0.60</cell><cell>0.22 0.39</cell><cell>0.17 0.30</cell><cell>0.29 0.48</cell><cell>9.96 15.88</cell></row><row><cell>Traj++ [50]</cell><cell>ADE FDE</cell><cell>0.39 0.83</cell><cell>0.12 0.21</cell><cell>0.20 0.44</cell><cell>0.15 0.33</cell><cell>0.11 0.25</cell><cell>0.19 0.41</cell><cell>N/A N/A</cell></row><row><cell>Multiverse [32]</cell><cell>ADE FDE</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>N/A N/A</cell><cell>14.78 27.09</cell></row><row><cell>Y-net [37]</cell><cell>ADE FDE</cell><cell>0.28 0.33</cell><cell>0.10 0.14</cell><cell>0.24 0.41</cell><cell>0.17 0.27</cell><cell>0.13 0.22</cell><cell>0.18 0.27</cell><cell>7.85 11.85</cell></row><row><cell>SIT [56]</cell><cell>ADE FDE</cell><cell>0.38 0.88</cell><cell>0.11 0.21</cell><cell>0.20 0.46</cell><cell>0.16 0.37</cell><cell>0.12 0.27</cell><cell>0.19 0.44</cell><cell>N/A N/A</cell></row><row><cell>Social</cell><cell>ADE</cell><cell>0.66</cell><cell>0.34</cell><cell>0.39</cell><cell>0.27</cell><cell>0.24</cell><cell>0.38</cell><cell>N/A</cell></row><row><cell cols="2">DualCVAE [16] FDE</cell><cell>1.18</cell><cell>0.61</cell><cell>0.74</cell><cell>0.48</cell><cell>0.42</cell><cell>0.69</cell><cell>N/A</cell></row><row><cell>CSCNet [71]</cell><cell>ADE FDE</cell><cell>0.51 1.05</cell><cell>0.22 0.42</cell><cell>0.36 0.81</cell><cell>0.31 0.68</cell><cell>0.47 1.02</cell><cell>0.37 0.79</cell><cell>14.63 26.91</cell></row><row><cell>NSP-SFM</cell><cell>ADE</cell><cell>0.25</cell><cell>0.09</cell><cell>0.21</cell><cell>0.16</cell><cell>0.12</cell><cell>0.17</cell><cell>6.52</cell></row><row><cell>(Ours)</cell><cell>FDE</cell><cell>0.24</cell><cell>0.13</cell><cell>0.38</cell><cell>0.27</cell><cell>0.20</cell><cell>0.24</cell><cell>10.61</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Results on ETH/UCY (left) and SDD (right) based on ultra-sampling. 20 samples per step are used for prediction and the overall minimal error is reported. NSP-SFM outperforms S-CSR on both datasets in ADE and FDE.</figDesc><table><row><cell>Methods</cell><cell cols="2">Metrics ETH</cell><cell cols="5">Hotel UNIV ZARA1 ZARA2 Avg</cell><cell>SDD</cell></row><row><cell>S-CSR [77]</cell><cell>ADE FDE</cell><cell>0.19 0.35</cell><cell>0.06 0.07</cell><cell>0.13 0.21</cell><cell>0.06 0.07</cell><cell>0.06 0.08</cell><cell>0.10 0.16</cell><cell>2.77 3.45</cell></row><row><cell>NSP-SFM</cell><cell>ADE FDE</cell><cell>0.07 0.09</cell><cell>0.03 0.07</cell><cell>0.03 0.04</cell><cell>0.02 0.04</cell><cell>0.02 0.04</cell><cell>0.03 0.06</cell><cell>1.78 3.44</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Collision rate on testing data in ETH/UCY and SDD. NSP-SFM universally outperforms all baseline methods.</figDesc><table><row><cell cols="2">Methods ETH</cell><cell cols="2">Hotel UNIV</cell><cell>ZARA1</cell><cell>ZARA2</cell><cell>Avg</cell><cell>SDD</cell></row><row><cell>Y-net</cell><cell>0</cell><cell>0</cell><cell>1.51%</cell><cell>0.82%</cell><cell>1.31%</cell><cell>0.73%</cell><cell>0.47%</cell></row><row><cell>S-CSR</cell><cell>0</cell><cell>0</cell><cell>1.82%</cell><cell>0.41%</cell><cell>1.31%</cell><cell>0.71%</cell><cell>0.42%</cell></row><row><cell cols="2">NSP-SFM 0</cell><cell>0</cell><cell>1.48%</cell><cell>0</cell><cell>0.66%</cell><cell>0.43%</cell><cell>0.42%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Ablation study on SDD. (w/o) means without CVAE and (w) means with CVAE. F goal is goal attraction only and NSP-SFM is all three forces.</figDesc><table><row><cell>SDD</cell><cell>F goal (w/o)</cell><cell cols="2">NSP-SFM(w/o) NSP-SFM(w)</cell></row><row><cell>ADE</cell><cell>6.57</cell><cell>6.52</cell><cell>1.78</cell></row><row><cell>FDE</cell><cell>10.68</cell><cell>10.61</cell><cell>3.44</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>Collision rates of the generalization experiments on Coupa0.</figDesc><table><row><cell>Results of Y-net,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 .</head><label>7</label><figDesc>Ablation experiments on network architecture. Goal-Network and the Collision-Network possess the same architecture under each experimental setup. vironment pixel-wise segmentation with dimension of H * W * K c . H and W are the height and width of I, and K c is the number of classes for segmentation. The segmantation maps are byproducts of the GSN from</figDesc><table><row><cell>ADE</cell><cell cols="3">Two layers MLP Full MLP</cell></row><row><cell cols="2">w/o LSTM 6.83</cell><cell>6.61</cell><cell></cell></row><row><cell cols="2">with LSTM 6.66</cell><cell>6.52</cell><cell></cell></row><row><cell cols="4">Table 8. Ablation experiments on SDD. Different components from our model are</cell></row><row><cell>added incrementally</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">knj=25 hand-tuned learned ? and knj NSP</cell></row><row><cell>ADE</cell><cell>8.32</cell><cell>6.53</cell><cell>6.52</cell></row><row><cell>FDE</cell><cell>10.97</cell><cell>10.61</cell><cell>10.61</cell></row><row><cell cols="4">knj=50 hand-tuned learned ? and knj NSP</cell></row><row><cell>ADE</cell><cell>7.54</cell><cell>6.53</cell><cell>6.52</cell></row><row><cell>FDE</cell><cell>10.81</cell><cell>10.61</cell><cell>10.61</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9 .</head><label>9</label><figDesc>Hyper-parameters for all six datasets.</figDesc><table><row><cell cols="2">Hyper-Para ETH</cell><cell>Hotel</cell><cell>UNIV</cell><cell cols="3">ZARA1 ZARA2 SDD</cell></row><row><cell>a(? )</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>b(? )</cell><cell>0.1</cell><cell>0.1</cell><cell>2.2</cell><cell>1.6</cell><cell>1.4</cell><cell>0.4</cell></row><row><cell>a(knj)</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>100</cell></row><row><cell>b(knj)</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>?</cell><cell>?/3</cell><cell>?/3</cell><cell>?/3</cell><cell>?/3</cell><cell>?/3</cell><cell>?/3</cell></row><row><cell>r col</cell><cell>75</cell><cell>75</cell><cell>75</cell><cell>75</cell><cell>75</cell><cell>100</cell></row><row><cell>renv</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>75</cell><cell>75</cell><cell>50</cell></row><row><cell>? goal</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>4</cell><cell>4</cell></row><row><cell>? latent</cell><cell>1.3</cell><cell>1.3</cell><cell>1.3</cell><cell>1.3</cell><cell>1.3</cell><cell>1.3</cell></row><row><cell>? weak</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>0.2</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">ent scenes (e.g., with higher densities) and generate more plausible trajectories (e.g., fewer collisions). This is difficult for existing deep learning as it requires to extrapolate significantly to unseen interactions between pedestrians.4 Experiments4.1 DatasetsWe employ six widely used datasets in human trajectory prediction tasks: the Stanford Drone Dataset [46], ETH Hotel, ETH University [43], UCY University, Zara1, and Zara2 datasets<ref type="bibr" target="#b27">[28]</ref>. Stanford Drone Dataset (SDD): SDD contains videos of a university campus with six classes of agents with rich interactions. SDD includes about 185,000 interactions between different agents and approximately 40,000 interactions between the agent and the environment. ETH/UCY Datasets: The datasets consist of human trajectories across five scenes recording the world coordinates of pedestrians. Following previous research<ref type="bibr" target="#b36">[37,</ref>38], we adopt the standard leave-one-out evaluation protocol, where the model is trained on four sub-datasets and evaluated one. Since our goal sampling network and F env need to work in the pixel space, we project the world coordinates in ETH/UCY into the pixel space using the homography matrices provided in Y-net<ref type="bibr" target="#b36">[37]</ref>. When computing the prediction error, we project the predictions in the pixel space back into the world space. Finally, for SDD and ETH/UCY, we follow previous work<ref type="bibr" target="#b36">[37,</ref>48]  to segment trajectories into 20-frame samples and split the dataset for training/testing. Given the first 8 (M = 7) frames, we train NSP to predict the remaining 12 frames for each trajectory.4.2 Trajectory PredictionAverage Displacement Error (ADE) and Final Displacement Error (FDE) are employed as previous research<ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref>38,<ref type="bibr" target="#b36">37]</ref>. ADE is calculated as the l 2 error between a predicted trajectory and the ground truth, averaged over the entire trajectory. FDE is calculated as the l 2 error between the predicted final point</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements This project has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement No</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social lstm: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="961" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A pde model for computing the optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>?lvarez Le?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Esclar?n Monreal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lef?bure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>S?nchez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antonucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P R</forename><surname>Papini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Palopoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fontanelli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.08429</idno>
		<title level="m">Generating reliable and efficient predictions of human motion: A promising encounter between physics and neural networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Context-aware trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bartoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lisanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ballan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Del Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">24th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1941" to="1946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Recent trends in crowd analysis: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bendali-Braham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Forestier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Idoumghar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning with Applications</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">100023</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Realtime multilevel crowd tracking using reciprocal velocity obstacles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd International Conference on Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4164" to="4169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Aggressive, tense or shy? identifying personality traits from crowd videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Randhavane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI. pp</title>
		<imprint>
			<biblScope unit="page" from="112" to="118" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Reciprocal velocity obstacles for real-time multi-agent navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Den Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Conditional flow variational autoencoders for structured sequence prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hanselmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>Straehle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th Workshop on Bayesian Deep Learning. bayesiandeeplearning. org</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Physics-informed neural networks (pinns) for fluid mechanics: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Mechanica Sinica</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Social network model for crowd anomaly detection and localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chaker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Al Aghbari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">N</forename><surname>Junejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="266" to="281" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A data-driven framework for visual crowd analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Charalambous</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Karamouzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chrysanthou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="41" to="50" />
			<date type="published" when="2014" />
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Neural ordinary differential equations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rubanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bettencourt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00735</idno>
		<title level="m">Trajectory forecasts in unknown environments conditioned on grid-based plans</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Modelling pedestrian trajectory patterns with gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sommerlade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1229" to="1234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Social-dualcvae: Multimodal trajectory forecasting based on social interactions pattern aware and dual conditional variational auto-encoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.03954</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fine-grained differentiable physics: a yarn-level model for fabrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Informative scene decomposition for crowd analysis, comparison and simulation guidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transaction on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">39</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Social force model for pedestrian dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">4282</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>Johora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hartmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Reinhardt</surname></persName>
		</author>
		<title level="m">Sfmgnet: A physics-based neural network to predict pedestrian trajectories. arXiv</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2375" to="2384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Crowd space: a predictive crowd analysis technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Karamouzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sohre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Guy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Physics-informed machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Karniadakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">G</forename><surname>Kevrekidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perdikaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Rev Phys</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="422" to="440" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kidger</surname></persName>
		</author>
		<title level="m">On neural differential equations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Interactive crowd content generation and analysis using trajectory-level behavior learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Symposium on Multimedia (ISM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="21" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kreiss</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.12081</idno>
		<title level="m">Deep social force</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Crowds by example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chrysanthou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer graphics forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="655" to="664" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Conditional generative neural system for probabilistic trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tomizuka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6150" to="6156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Differentiable cloth simulation for inverse problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Simaug: Learning robust representations from 3d simulation for pedestrian trajectory prediction in unseen cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hauptmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.02022</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The garden of forking paths: Towards multi-future trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10508" to="10518" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Peeking into the future: Predicting future person activities and locations in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5725" to="5734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Social nce: Contrastive learning of socially-aware motion representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15118" to="15129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Character navigation in dynamic environments based on optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chaumette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pettr?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="181" to="192" />
			<date type="published" when="2019" />
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Agent-based human behavior modeling for crowd simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y H</forename><surname>Low</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Animation and Virtual Worlds</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">From goals, waypoints &amp; paths to long term human trajectory forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15233" to="15242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A review of deep learning-based methods for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">I</forename><surname>Sighencea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Stanciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>C?leanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page">7543</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Pedestrian trajectory prediction via spatial interaction transformer network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE Intelligent Vehicles Symposium Workshops (IV Workshops)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="154" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Lcollision: Fast generation of collision-free human poses using learned non-penetration constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="3913" to="3921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">N-penetrate: Active learning of neural collision handler for complex 3d mesh deformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Shiratori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2022" />
			<biblScope unit="page" from="21037" to="21049" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Algorithms for Microscopic Crowd Simulation: Advancements in the 2010s</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Van Toll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pettr?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Social attention: Modeling attention in human crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vemula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muelling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE international Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4601" to="4607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Energy-based pedestrian navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Virtanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th ITS World Congr</title>
		<meeting>20th ITS World Congr</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">A learning based approach for social force model parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IEEE</publisher>
			<biblScope unit="page" from="4058" to="4064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Path patterns: Analyzing and comparing real and simulated crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ond?ej</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>O&amp;apos;sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="49" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Trending paths: A new semantic-level metric for comparing simulated and real crowd data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ond?ej</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>O&amp;apos;sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics PP</title>
		<imprint>
			<biblScope unit="issue">99</biblScope>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Globally continuous and non-markovian crowd activity analysis from videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>O&amp;apos;sullivan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="527" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Understanding social-force model in psychological principles of collective behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.05146</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Trajectory analysis and semantic region modeling using nonparametric hierarchical bayesian models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E L</forename><surname>Grimson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="287" to="312" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Simulating crowd evacuation in a social force model with iterative extended state observer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of advanced transportation</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Fast and featurecomplete differentiable physics for articulated rigid bodies with contact</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Werling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Omens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Exarchos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Liu</surname></persName>
		</author>
		<idno>abs/2103.16021</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Parameter estimation and comparative evaluation of crowd simulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wolinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Manocha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pettr?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="312" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Cscnet: Contextual semantic consistency network for trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="page">108552</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Application of social force model to pedestrian behavior analysis at signalized crosswalk. Transportation research part C: emerging technologies 40</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iryo-Asano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="143" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">MeshingNet3D: Efficient generation of adapted tetrahedral meshes for computational mechanics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Jimack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Engineering Software</title>
		<imprint>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="issue">158</biblScope>
			<date type="published" when="2021-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Meshingnet: A new mesh generation method based on deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Jimack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Science -ICCS 2020</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="186" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">D</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chakraborty</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.12077</idno>
		<title level="m">Symplectic ode-net: Learning hamiltonian dynamics with control</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Random field topic model for semantic region analysis in crowded scenes from tracklets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3441" to="3448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Sliding sequential cvae with time variant socially-aware rethinking for trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.15016</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Neuralpde: Automating physics-informed neural networks (pinns) with error approximations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zubov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Calisto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Pagliarino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Azeglio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Luj?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sulzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bharambe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vinchhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Upadhyay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rackauckas</surname></persName>
		</author>
		<idno>abs/2107.09443</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
