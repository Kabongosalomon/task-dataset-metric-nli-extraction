<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Danish Fungi 2020 -Not Just Another Image Recognition Dataset Milan?ulc, Ji?? Matas CTU in Prague</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luk??</forename><surname>Picek</surname></persName>
							<email>picekl@kky.zcu.cz</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Jeppesen</surname></persName>
							<email>tsjeppesen@gbif.org</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gbif</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Heilmann-Clausen</surname></persName>
							<email>jheilmann-clausen@snm.ku.dk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Laess?e</surname></persName>
							<email>thomasl@bio.ku.dk</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Fr?slev</surname></persName>
							<email>tobiasgf@sund.ku.dk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of West Bohemia</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Danish Fungi 2020 -Not Just Another Image Recognition Dataset Milan?ulc, Ji?? Matas CTU in Prague</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce a novel fine-grained dataset and benchmark, the Danish Fungi 2020 (DF20). The dataset, constructed from observations submitted to the Atlas of Danish Fungi, is unique in its taxonomy-accurate class labels, small number of errors, highly unbalanced long-tailed class distribution, rich observation metadata, and well-defined class hierarchy. DF20 has zero overlap with ImageNet, allowing unbiased comparison of models fine-tuned from publicly available ImageNet checkpoints. The proposed evaluation protocol enables testing the ability to improve classification using metadata -e.g. precise geographic location, habitat, and substrate, facilitates classifier calibration testing, and finally allows to study the impact of the device settings on the classification performance. Experiments using Convolutional Neural Networks (CNN) and the recent Vision Transformers (ViT) show that DF20 presents a challenging task. Interestingly, ViT achieves results superior to CNN baselines with 80.45% accuracy and 0.743 macro F1 score, reducing the CNN error by 9% and 12% respectively. A simple procedure for including metadata into the decision process improves the classification accuracy by more than 2.95 percentage points, reducing the error rate by 15%. The source code for all methods and experiments is available at https://sites.google.com/ view/danish-fungi-dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Publicly available datasets and benchmarks accelerate machine learning research and allow for quantitative comparison of novel methods. In the area of deep learning and computer vision, the rapid progress over the past decade was, to a great extent, facilitated by the publication of largescale image datasets. In the case of image recognition, the formation of the ImageNet <ref type="bibr" target="#b6">[7]</ref> database and its usage in the <ref type="bibr">Figure 1</ref>. Selected images from the DF20 dataset from different Habitats (Rows) that grow on a variety of Substrates (Columns). ILSVRC 1 challenge <ref type="bibr" target="#b36">[36]</ref>, together with PASCAL VOC <ref type="bibr" target="#b9">[10]</ref> among others, helped start the CNN revolution. The same holds for the problem of fine-grained visual categorization (FGVC), where datasets and challenges like Plant-CLEF <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b21">22]</ref>, iNaturalist <ref type="bibr" target="#b46">[46]</ref>, CUB <ref type="bibr" target="#b48">[48]</ref>, and Oxford Flowers <ref type="bibr" target="#b32">[33]</ref>, have helped to develop and evaluate novel approaches to fine-grained domain adaptation <ref type="bibr" target="#b11">[12]</ref>, domain specific transfer learning <ref type="bibr" target="#b16">[17]</ref>, image retrieval <ref type="bibr" target="#b34">[34,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b53">53]</ref>, unsupervised visual representation, few-shot learning <ref type="bibr" target="#b49">[49]</ref>, transfer learning <ref type="bibr" target="#b16">[17]</ref>, prior-shift <ref type="bibr" target="#b39">[39]</ref> and many others.</p><p>While the datasets have been extremely useful for the image recognition community, there are issues that limit their relevance to real-world applications. We mention several such problems. Uniform class distribution, common in research datasets, are rare in practice. Often, class prior distributions are the same in the training and test splits. This is a standard machine learning assumption that, nevertheless, is not valid if the collection of training data differs from the deployment of the trained system, which is not rare. A non-negligible percentage of noisy-labels restricts quality assessment <ref type="bibr" target="#b2">[3]</ref>, and, despite CNN's surprising robustness to label noise <ref type="bibr" target="#b23">[24]</ref>, may influence the perceived relative merit of learning algorithms. Some commonly used datasets <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b32">33]</ref> are saturated in accuracy or close to the point, leaving limited space for improvement in future research <ref type="bibr" target="#b2">[3]</ref>. Extremely large dataset sizes might discourage researchers that do not have access to massive computational resources as experiments have become time and hardware demanding. With these observations in mind, we introduce the DF20 dataset with a number of unique characteristics. Its class labels are exceptionally accurate, annotated by domain experts -Mycologists with specialization on specific Families/Genera. Moreover, we are preparing private test with labels acquired by DNA sequencing. The minimal error levels allow highly accurate performance evaluation. With its zero overlap with ImageNet, it allows an unbiased comparison of models fine-tuned from publicly available ImageNet checkpoints.</p><p>The class frequencies in DF20 follow the natural species distribution, which is long-tailed. The frequencies change significantly within the calendar year, making the data suitable for testing the response of the classifier to differing long tailed distributions and changing class priors. The con- tinuous data flow of collection over a long period provides a ground for modelling and exploiting the temporal phenomena on different scales, e.g., month, season, year. The visual data is accompanied with metadata for more than 99% of the image observations. The rich metadata includes information related to the environment, place, time and full taxonomy labels and enables testing the ability to improve classification accuracy using different metadata types -time, precise location, habitat, and substrate type, to perform hierarchical classification, evaluate finegrained classification on different levels of granularity (taxonomic ranks), to test classifier calibration, and to model intra-metadata and metadata-visual appearance relationships. Moreover, EXIF metadata is available for many observations, which is useful, e.g., for studying the impact of the device settings on classification performance.</p><p>The DF20 Benchmark. To allow evaluation at any time, we have prepared a web-based public automatic benchmark 2 for different scenarios, including visual-based, metadata focused or classifier-calibration related research. Besides the full benchmark, we introduce DF20 -mini, a small subset with roughly 1/10 of the data and species, for fast, low-energy friendly prototyping. DF20 -mini includes six well-known genera of fungi forming fruit-bodies of the toadstool type, and offers, surprisingly, an even more challenging problem then the full benchmark, while having a compact size.</p><p>We prepared a baseline performance evaluation, including the quantitative and qualitative analysis of the results for a number of well-known CNN and recent ViT architectures <ref type="bibr" target="#b7">[8]</ref>. The recent ViT achieves excellent results in fine-grained classification outperforming the state-of-theart CNN classifiers. We show that ViT performs way better on the FGVC domain, where attention to detail is needed, than in a common object recognition. We show that both the DF20 and DF20 -Mini benchmarks are far from saturated as the best performing model -ViT-Large/16-384 -achieved 80.45% and 75.85% accuracy on DF20 and DF20 -Mini, respectively. We propose a simple method for processing the habitat, substrate and time (month) metadata, showing that -even with the simple approach -utilizing the metadata increases the classification performance significantly. To support and accelerate future research on the DF20 we open source the code through the public GitHub.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>This section overviews existing fine-grained image datasets, which, unlike datasets with visually distinct object classes <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b25">26]</ref>, are characterized by small inter-class differences and huge intra-class similarity. Currently, there exists a number of FGVC dataset with a focus on plants <ref type="bibr">[</ref>  20, 22, 27, 33], animals <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b48">48]</ref>, cars <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b42">42]</ref> or airplanes <ref type="bibr" target="#b31">[32]</ref>. The dataset statistics are compared in <ref type="table">Table 1</ref>.</p><p>Most of the datasets are artificially constructed to have a flat class distribution. Many datasets use web scraped data that may contain out-of-domain images and wrong labels. Fungi species have been covered by image classification datasets. In the FGVCx 2018 Fungi classification challenge 3 , a dataset sampled from the same source as DF20 was used. The challenge dataset was smaller, scrambled the species names, did not include taxonomic labels and did not contain any metadata. The latest edition of iNaturalist dataset includes 90,048 images of 384 fungi species from 240 genera. DF20 is more fine-grained in the Fungi kingdom, and it is thus more challenging, with more than 1,500 fungi species. Many of these visually similar but from different genera or families ( <ref type="figure" target="#fig_0">Figure 2</ref>). Labels. As species-level labels are essential for usage in real-world applications, the tedious labelling procedure often rely on domain experts. With just a small number of experts and their limited time, the labelling process is frequently delegated to crowd-sourced annotation platforms such as the Amazon Mechanical Turk <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b48">48]</ref>. The main drawback of this approach is related to poor domain knowledge of the annotators that results in a high number of noisy labels [45] -4.4% in CUB 200-2011 and approximately 4.0% for fine-grained classes in ImageNet. To address this issue, more recent datasets use citizen-science platforms and their users -citizen scientists 4 -to label data with high-quality annotations <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b46">46]</ref>.</p><p>ImageNet Overlap. Strict separation of training and test data is a core machine learning principle and it is standard in the field of image recognition. Nevertheless, some 3 https://github.com/visipedia/fgvcx_fungi_comp 4 Domain specific nonprofessional enthusiasts -experts. datasets containt ImageNet images in their test set, and thus fine-tuning from ImageNet weights contradicts the separation principle. This is commonly overlooked and may lead to biased (inflated) test set accuracies. For instance, a number of publications with high impact used ImageNet weights and performed the fine-tuning and testing with the CUB 200-2011 <ref type="bibr" target="#b48">[48]</ref> dataset that overlaps with the Im-ageNet <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b51">51,</ref><ref type="bibr" target="#b52">52,</ref><ref type="bibr" target="#b54">54,</ref><ref type="bibr" target="#b55">55,</ref><ref type="bibr" target="#b56">56]</ref> in 43 out of 5,794 images (0.75%).</p><p>Metadata. Besides images and class labels, image classification datasets often provide additional metadata, such as higher taxon labels <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b46">46]</ref>, label hierarchy <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b31">32]</ref>, object parts and attribute annotations <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b48">48]</ref>, masks <ref type="bibr" target="#b48">[48]</ref>, GPS location <ref type="bibr" target="#b21">[22]</ref>, and time of observation <ref type="bibr" target="#b21">[22]</ref>. The existence of such metadata enables the usage of these datasets in machine learning research beyond image classification. For example <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b30">31]</ref> use location context, and <ref type="bibr" target="#b14">[15]</ref> use taxonomy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Atlas of Danish Fungi</head><p>The Atlas of Danish Fungi (Svampeatlas) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b18">19]</ref> is supported by more than 3,300 volunteers who have contributed more than 950,000 content-checked observations of fungi, many with expert-validated class labels, submitted mostly since 2009.</p><p>The project has resulted in a vastly improved knowledge of fungi in Denmark <ref type="bibr" target="#b18">[19]</ref>. More than 180 species belonging to Basidiomycota 5 have been added to the list of known Danish species, and several species that were considered extinct have been re-discovered. Simultaneously, several search and assistance functions have been developed that </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Annotation Process</head><p>The Atlas of Danish Fungi uses an interactive labelling procedure for all submitted observations. When a user submits a fungal sighting (record) at species level, a "reliability score" (1-100) is calculated based on following factors:</p><p>? Species rarity, i.e. its relative frequency in the Atlas.</p><p>? The geographical distribution of the species.</p><p>? Phenology of the species, its seasonality.</p><p>? User's historical species-level proposal precision.</p><p>? As above, within the proposal's higher taxon rank. Subsequently, other users may agree with the proposed species identity, increasing the identification score following the same principles, or proposing alternative identification for non-committal suggestions. Once the submission reaches a score of 80, the label (identification) is internally approved. Simultaneously, a small group of taxonomic experts (validators) monitor most of the observation on their own. These have the power to approve or reject species identifications regardless of the score in the interactive validation. Since 2019, the Atlas of Danish Fungi observation identification has been streamlined thanks to an image recognition system <ref type="bibr" target="#b40">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Dataset Description</head><p>The Danish Fungi 2020 (DF20) dataset contains image observations from the Atlas of Danish Fungi belonging to species with more than 30 images. The data are observations collected before the end of 2020 6 , originating from 30 countries, and including samples from all seasons. It consists of 295,938 images belonging to 1,604 species mainly from the Fungi kingdom with a few visually similar species (See <ref type="figure" target="#fig_1">Figure 3)</ref>  and Chromista kingdoms (0.06% classes / 0.03% images) kingdoms, covering 566 genera and 190 families. The most frequent species -Trametes versicolor -is represented by 1,913 images and the least present with 31.</p><p>Additionally, we hand-picked a subset of 36,393 images belonging to 182 species from 6 genera with a similar visual appearance. This compact dataset, DF20 -Mini, introduces a challenging fine-grained recognition task, while allowing to decrease the necessary training times and hardware requirements. As species in the same genus are most likely to be confused, we chose six commonly known genera of fungi forming fruit-bodies of the toadstool type with a large number of species: (Russula, Boletus, Amanita, Clitocybe, Agaricus and Mycena) for the construction of the DF20 -Mini. The most frequent species in the DF20 -Mini dataset -Mycena galericulata -has 1,221 images, the rarest have 31 samples. For a quantitative summary of the data selection, see <ref type="table" target="#tab_2">Table 2</ref>.</p><p>The DF20 and DF20 -Mini datasets were randomly split -with respect to the class distribution -into the provided training and (public) test sets, where the training set contains 90% of images of each species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Metadata</head><p>Unlike most computer vision datasets, DF20 and DF20 -Mini include rich metadata acquired by citizen-scientists in the field while recording the observations. We see a promising research direction in combining visual data with metadata like timestamp, location at multiple scales, substrate, habitat, full taxonomy labels and camera device settings. For a detailed list see <ref type="table" target="#tab_5">Table 4</ref>.</p><p>Substrate. Substrates on which fungi live and fruit are an important source of information that helps differentiate similarly looking species. Each species or genus has its preferable substrate, and it is rare to find it on other substrates. For example, Trametes occurs only on wood and Russula on soil. As such metadata is crucial for the final categorization capability, we provide one of 32 substrate types for more than 99% of images. We differentiate wood of living trees, dead wood, soil, bark, stone, fruits, mosses and others.</p><p>Location. Fungi are highly location dependent with different species distributions across continents, states, regions or even districts. To support studies on better understanding where Fungi species lives, we include multi-level location information. Starting from latitude and longitude values and their uncertainty, we further extracted information about the country, region, district, and locality with 9003 unique values.</p><p>Time-Stamp. Time of observation is essential for fungi classification in the wild as fruitbodies' presence depends on seasonality or even (but rarely) the time in a day. Considering the existence of such dependency, integrating information about time into the classification should also improve fungal recognition. In <ref type="figure" target="#fig_2">Figure 4</ref> we show the probability of three genera being observed in different months of the calendar year. Brief inspection shows that there is almost zero probability to spot a Boletus in January but still a small chance to find a Mycena. In contrast to Boletus, Exidia occurs mostly during the cold months.</p><p>EXIF data. Since the camera device and its settings affect the resulting image, the image classification models may be biased towards certain (e.g. more common) device attributes. To allow a deeper study of such phenomena, we include the EXIF data for approximately 84% of images, where the EXIF information was available in the Atlas of Danish Fungi. The included attributes, the number of unique values in the dataset and the proportion of images with the attributes present are summarized in <ref type="table">Table 3</ref>. Habitat. While substrate denotes the spots, the habitat indicates the more overall environment where fungi grow and hence is vital for fungal recognition. It is well known that some species occur in deciduous forests rather than in conifer forests or plantations, while others grow in farmland. For a deeper understanding of such relation, we include the information about the habitat for approximately 99.5% of observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attribute Description</head><p>EventDate Date of observation.</p><p>EXIF Camera device attributes extracted from the image, e.g., metering mode, color space, device type, exposure time, and shutter speed.</p><p>Habitat The environment where the specimen was observed.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>To establish a baseline performance on the DF20 and DF20 -Mini datasets, we performed multiple experiments. First, we train a wide variety of well known CNN architectures such as ResNets <ref type="bibr" target="#b17">[18]</ref>, Efficient-Nets <ref type="bibr" target="#b43">[43]</ref>, MobileNet <ref type="bibr" target="#b37">[37]</ref>, Inception networks <ref type="bibr" target="#b41">[41]</ref> and SE-ResNeXt-101-32x4d that extends the ResNet-101 by cardinality <ref type="bibr" target="#b50">[50]</ref> and Squeeze and Excite blocks <ref type="bibr" target="#b20">[21]</ref>. Second, the EfficientNet-B0, EfficientNet-B3, and SE-ResNeXt-101-32x4d are compared with Vision Transformer architectures ViT-Large/16 and ViT-Base/16 <ref type="bibr" target="#b7">[8]</ref>. Finally, the impact of different metadata and their combinations on both the CNN and the ViT final prediction performance is evaluated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Setup</head><p>In this section, we describe the full training and evaluation procedure, including the training strategy and image augmentations.</p><p>Training Strategy. All architectures were initialized from publicly available ImageNet-1k pre-trained checkpoints and further fine-tuned with the same strategy for 100 epochs with the PyTorch framework <ref type="bibr" target="#b35">[35]</ref> within the 21.05 NGC deep learning framework Docker container. All neural networks were optimized by Stochastic Gradient Descent with momentum set to 0.9. The start Learning Rate (LR) was set to 0.01 and was further decreased with a specific adaptive learning rate schedule strategy -if the validation loss is not reduced from one epoch to another, reduce LR by 10%. To have the same effective mini-batch size of 64 for all architectures, we accumulated gradients from smaller mini-batches accordingly, where needed.</p><p>Augmentations. For training, we utilized several augmentation techniques from the Albumentations library <ref type="bibr" target="#b4">[5]</ref>. More specifically, we used: random horizontal flip with 50% probability, random vertical flip with 50% probability, random resized crop with a scale of 0.8 -1.0, random brightness / contrast adjustments with 20% probability, and mean and std. dev. normalization. All images were resized to the required network input size: For the CNN performance experiment, inputs of size 299?299 were used. In the case of the CNN vs ViT experiment, we used two different resolutions, 224?224 and 384?384, to match the input resolutions of the pre-trained models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Test-time.</head><p>While testing, we avoided any additional techniques such as ensembles, centre-cropping, prior weighting, etc. Only the resize and normalization operations were used to pre-process the data. The impact of testtime augmentation methods on the final performance can be studied in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Metadata Use</head><p>We propose a simple method for the use of metadata to improve the categorization performance -similar to spatiotemporal prior used in <ref type="bibr" target="#b1">[2]</ref>. For a given type of metadata (D) and image (I), we adopt the following assumption for the likelihood of an image observation:</p><formula xml:id="formula_0">P (I|S) = P (I|S, D),<label>(1)</label></formula><p>i.e. that the visual appearance of a species does not depend on the metadata. This does not mean that the posterior probability of a species given an image is independent of metadata D.</p><p>A few lines of algebraic manipulation prove that under assumption Eq. (1), the class posterior given the image I and metadata D is easily obtained:</p><formula xml:id="formula_1">P (S|I, D) = P (S|I) P (S|D) P (S) P (I) P (I|D) ? P (S|I) p(S|D) p(S) ,<label>(2)</label></formula><p>where P (S) is the class prior in the training set. The discrete conditional probability P (S|D) is estimated as the relative frequency of species S with metadata D in the training set. While we know this assumption is not always true in practice, since metadata like substrate or time in fact do impact the image background as well as the appearance of the specimen, this is the only possible approach not requiring modelling the dependence of visual appearance and the metadata. The model trained without metadata has no information about visual appearance changes of a species as a function of D. Moreover, this assumption is applicable for situations where the classifier has to be treated as a black box without the possibility to retrain the model. Even this simplistic model based on an unrealistic assumption reduces error rates, see <ref type="table">Table 7</ref>.</p><p>With multiple metadata at once, e.g. month and habitat, we combine the posteriors assuming statistical independence:</p><formula xml:id="formula_2">P (S|D1, D2) ? P (S|D1)P (S|D2) P (S) .<label>(3)</label></formula><p>This is a simple, baseline assumption, which again may not always be valid for related meta-data. Direct estimation of P (S|D 1 , D 2 ), e.g. as relative frequencies, is another possibility. The D20 benchmark has thus the potential to be a fertile ground for evaluation of intra-metadata, as well as visual-metadata, dependencies. The approach of Eq. (2) needs a probabilistic classifier to serve as an estimator of P (S|I). In our experiments, we use the outputs of the softmax layer. Note that for CNNs, the estimates of max P (S|I) are typically overconfident, and the quality of the estimator can be improved by a process is called calibration in the literature <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b44">44]</ref>. The proposed benchmark may be used, in the context of exploiting metadata, to evaluate and compare classifier calibration techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Metrics</head><p>Besides commonly used metrics, Top1 and Top3 accuracy, we measured the macro-averaged F 1 score, F m 1 , which is not biased by class frequencies and is more suitable for the long-tailed class distributions observed in the nature. Interestingly, even though the performance across the whole taxonomy in nature-related FGVC datasets is highly demanded, most existing datasets are only using accuracy as the score measure. Considering that the datasets are highly imbalanced with long-tail distribution, learning procedure may ignore the least present species. Additionaly, usage of F m 1 allows to easily assign a cost value to both types of error (fp and fn) for each label and to measure more taskrelevant performance. For example, in fungi recognition, mistaking a poisonous mushroom for the edible one is a more significant problem than the opposite.</p><p>The F m 1 is defined as the mean of class-wise F 1 scores:</p><formula xml:id="formula_3">F m 1 = 1 N N S=1 F1 S ,<label>(4)</label></formula><p>where N represents the number of classes and S is the species index. Than the F 1 score for each class is calculated as a harmonic mean of the class precision P S and recall R S :  In multi-class classification, the True Positive (tp) represents the number of correct Top1 predictions, False Positive (fp) how many times was a specific class predicted instead of the (tp), and False Negative (fn) how many images of class S have been misclassified.</p><formula xml:id="formula_4">F1 S = 2 ? PS ? RS PS + RS ,<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Results</head><p>In this section, we compare the performance of the well known CNN based models and ViT models in terms of Top1 and Top3 accuracy, and the newly included F m 1 metric. Additionally, we discuss the impact of the metadata on the classification performance and differences in performance between CNNs and ViTs.</p><p>Convolutional Neural Networks. Comparing well known CNN architectures on DF20 and DF20 -Mini, we can see a similar behaviour as on other datasets <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr" target="#b48">48]</ref>. The best performing model on both datasets was SE-ResNeXt-101 with 0.620 F m 1 score on DF20 -Mini and 0.693 F m 1 score on DF20. A more detailed comparison of the achieved scores (Top1, Top3, and F m 1 ) for each model are summarized in <ref type="table" target="#tab_7">Table 5</ref>.</p><p>Vision Transformers. The recently introduced ViT [8] showed excellent performance in object classification compared to state-of-the-art convolutional networks. Apart from the CNNs, the ViT is not using convolutions but interprets an image as a sequence of patches and process it by a standard Transformer encoder as used in natural language processing <ref type="bibr" target="#b47">[47]</ref>. To evaluate its performance for transferlearning in the FGVC domain, we compare two ViT architectures -ViT-Base/16 and ViT-Large/16 -against the well performing CNN models -EfficientNet-B0, EfficientNet-B3 and SE-ResNeXt-101. As ImageNet pre-trained ViT models were available just for input sizes of 224?224  and 384?384, we trained all networks on these resolutions while following the training setup fully described in subsection 5.1. Differently from the performance validation of Dosovitskiy et al. <ref type="bibr" target="#b7">[8]</ref> on ImageNet, in our evaluation on DF20, ViTs ourperform state-of-the-art CNNs by a large margin. The best performing ViT model achieved an impressive 0.743 F m 1 score while outperforming the SE-ResNeXt-101 by a significant margin of 0.035 in F m 1 , and 1.73% of Top1 accuracy on the images with 384?384 input size. In the case of the 224?224, we see a smaller margin of 1.62% in Top1 accuracy and 0.018 in the F m 1 score. Wider performance comparison is shown in <ref type="table">Table 6</ref>.</p><p>Importance of the metadata. Inspired by the common practice in mycology, we set up an experiment to show the importance of metadata for Fungus species identification. Using the approach described in Section 5.2, we improved performance in all measured metrics by a significant margin. We measured the performance improvement with all metadata types and their combinations. Overall, habitat was most efficient in improving the performance. With the combination of habitat, substrate and month, we improved the ViT-Large/16 model's performance on DF20 by 2.95%, 1.92% and 0.053 in Top1, Top3 and F m 1 , respectively, and the performance of the ViT-Base/16 model by 3.81%, 2.84% and 0.070 in Top1, Top3 and F m 1 Detailed evaluation of the performance gain using different observation metadata and their combinations is shown in <ref type="table">Table 7</ref>.</p><p>DF20 vs DF20 -Mini. The performance evaluation with selected CNN and ViT architectures showed that even with a smaller number of classes and one-tenth of the data, DF20 -Mini as a compact subset of DF20 offers an even more challenging problem for state-of-the-art architectures while being less time and hardware demanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper introduced a novel fine-grained dataset and classification benchmark, the Danish Fungi 2020, and its subset, Danish Fungi 2020 -Mini. The dataset was constructed from data submitted to the Atlas of Danish Fungi and labeled by mycologists. It includes 295,938 photographs of 1,604 species -mainly from the Fungi kingdom -together with full taxonomic labels, rich metadata, compact size and severe difficulty, and the same training and test set species distribution.</p><p>The quantitative and qualitative analysis of CNNs and ViTs shows superior performance of the ViT in fine-grained classification. We present the baselines for processing the habitat, substrate and time (month) metadata. We show that --even with the simple method from Section 5.2 -utilizing the metadata increases the classification performance significantly. We provide the code and trained model checkpoints to all our baselines. A publicly available web benchmark allows -through CSV submision file -for an on-line comparison of state-of-the-art results for both image-only and image + metadata submissions. With the precise annotation and rich metadata, we would like to encourage further research in other areas of computer vision and machine learning, beyond fine-grained visual categorization. The benchmark may help research in classifier calibration, loss functions, validation metrics, taxonomy / hierarchical learning, device dependency or time series based species prediction. For example, the standard loss function focusing on recognition accuracy ignores the practically important cost of predicting a species with high toxicity.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Examples of intra-and inter-class similarities and differences for selected species of three taxonomically distinct fungi families. The similarity holds on the species and the family level. Left: Russulaceae, center: Boletaceae, right: Amanitaceae.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Visually similar image pairs from the Fungi and Protozoa, and from the Fungi and Chromista kingdoms, respectively. present features relating to the individual species, making it much easier to include an understanding of endangered species in nature management and decision-making. Expert-validated Svampeatlas records are published in the Global Biodiversity Information Facility (GBIF), weekly, since 2017. As of end of July 2021, GBIF included 438,872 such images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Monthly distribution of observations in the DF20 dataset for genera Mycena, Boletus, and Exidia. The differences imply that the class prior distribution varies significantly over time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>Box plot of the dependence of classification performance (F1) on the number of training samples of a class. Tested on DF20 with input resolution of 224 ? 224.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>from Protozoa (1.7% classes / 1.1% images) Numbers of images, species, genera and families in the Atlas of Danish Fungi and their subsets DF20 and DF20 -Mini.</figDesc><table><row><cell></cell><cell cols="4">Images Species Genera Families</cell></row><row><cell cols="2">Svampeatlas (GBIF) 438,872</cell><cell>6,347</cell><cell>1,519</cell><cell>398</cell></row><row><cell>DF20</cell><cell>295,938</cell><cell>1,604</cell><cell>566</cell><cell>190</cell></row><row><cell>DF20 -Mini</cell><cell>36,393</cell><cell>182</cell><cell>6</cell><cell>6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Substrate The natural substance on which the specimen lives. A total of 32 values such as Bark, Soil, Stone, etc. Species 1th taxon rank. 1,578 unique values present. Genus 2nd taxon rank. 566 unique values present. Family 3rd taxon rank. 190 unique values present. Order 4th taxon rank. 66 unique values present. Class 5th taxon rank. 23 unique values present. Phylum 6th taxon rank. 5 unique values present. Kingdom 7th taxon rank. 3 unique values present.</figDesc><table><row><cell>Scientific Lowest taxonomic rank including specific Epithets.</cell></row><row><cell>1,604 unique values present.</cell></row><row><cell>CountryCode ISO 3166-1 alpha-2 code (DK, AT, etc.) of the obser-</cell></row><row><cell>vation. The dataset covers 30 countries.</cell></row><row><cell>Locality More precise location information. Mostly smaller</cell></row><row><cell>than a district, e.g. part of a city or a specific forest.</cell></row><row><cell>9003 values present.</cell></row><row><cell>Level1Gid ID of a Country region related to the specimen obser-</cell></row><row><cell>vation, 115 regions are listed.</cell></row><row><cell>Level2Gid ID of a district region related to the specimen obser-</cell></row><row><cell>vation, 317 districts are listed.</cell></row><row><cell>Latitude A decimal GPS coordinate.</cell></row><row><cell>Longitude A decimal GPS coordinate.</cell></row></table><note>Selected from 32 values such as Mixed woodland, De- ciduous woodland etc.GPSUncert GPS coordinates uncertainty in meters.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Description of the provided metadata (observation attributes). For almost all images, a detailed information about taxonomy, location, time, habitat and substrate type is included.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table><row><cell>Classification performance of selected CNN architectures</cell></row><row><cell>on DF20 and DF20 -Mini. All networks share the settings de-</cell></row><row><cell>scribed in Section 5.1 and were trained on 299?299 images. The</cell></row><row><cell>top results -F m 1 , see Eq. (4), equal to 0.620 / 0.693 and Top1 to</cell></row><row><cell>72.23% / 77.13% -are far from saturated. The datasets are chal-</cell></row><row><cell>lenging for the state-of-the-art CNN classifiers.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 .Table 7 .</head><label>67</label><figDesc>Classification results of selected CNN and ViT architectures on DF20 and DF20 -Mini datasets. ViT achieves results superior to CNN baselines with 80.45% accuracy and 0.743 F m 1 , reducing the CNN error by 9% and 12% respectively. +1.50 +1.00 +0.027 +1.94 +1.50 +0.040 ? ? +0.95 +0.62 +0.014 +1.23 +0.95 +0.020 ? ? +1.13 +0.69 +0.020 +1.39 +1.17 +0.025 ? +1.93 +1.27 +0.032 +2.47 +1.98 +0.042 ? +2.48 +1.66 +0.044 +3.23 +2.47 +0.062 ? +2.31 +1.48 +0.040 +3.11 +2.30 +0.057 +2.95 +1.92 +0.053 +3.81 +2.84 +0.070 ViT-Large/16 -384 ? 384 ViT-Base/16 -224 ? 224 Performance gains based on 3 observation metadata and their combination. DF20. H -Habitat, S -Substrate, M -Month.</figDesc><table><row><cell>H M S Top1</cell><cell>Top3</cell><cell>F m 1</cell><cell>Top1</cell><cell>Top3</cell><cell>F m 1</cell></row><row><cell cols="2">? ? ? 80.45 91.68</cell><cell>0.743</cell><cell cols="2">73.51 87.55</cell><cell>0.655</cell></row><row><cell>? ?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The ImageNet Large Scale Visual Recognition Challenge. 1 arXiv:2103.10107v4 [cs.CV] 20 Aug 2021</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">www.aicrowd.com/challenges/danish-fungi-2020</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">a group of fungi that produces their sexual spores (basidiospores) on a club-shaped spore-producing structure (basidium).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">Including 3 preserved specimens collected in 1874, 1882, and 1887, recently photographed.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Image classification with orchard metadata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suchet</forename><surname>Bargoti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Underwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5164" to="5170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Birdsnap: Large-scale fine-grained visual categorization of birds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiongxin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seung</forename><surname>Woo Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><forename type="middle">L</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Xiaohua Zhai, and A?ron van den Oord</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>H?naff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kolesnikov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07159</idno>
	</analytic>
	<monogr>
		<title level="m">Are we done with imagenet? arXiv preprint</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Bird species categorization using pose normalized deep convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grant</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2952</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Albumentations: Fast and flexible image augmentations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Buslaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">I</forename><surname>Iglovikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Khvedchenya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Parinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Druzhinin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandr</forename><forename type="middle">A</forename><surname>Kalinin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2020" to="2026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<ptr target="https://svampe.databasen.org" />
	</analytic>
	<monogr>
		<title level="j">Danish Mycological Society</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<title level="m">Sylvain Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Improving plankton image classification using context metadata</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><forename type="middle">A</forename><surname>Jeffrey S Ellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Graff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ohman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Limnology and Oceanography: Methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="439" to="461" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Jens Henrik Petersen, Ulrik S?chting, Thomas Stjernegaard Jeppesen, and Jan Vesterholt. Danish mycological society, fungal records database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Tobias Guldberg Fr?slev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Heilmann-Clausen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laess?e</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fine-grained recognition in the wild: A multi-task domain adaptation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timnit</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1349" to="1358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Plant identification in an open-world (lifeclef 2016)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>Go?au</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CLEF working notes 2016</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Plant identification based on noisy web data: the amazing performance of deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Goeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Taxonomy-regularized semantic deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonjoon</forename><surname>Goo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juyong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunhee</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung</forename><forename type="middle">Ju</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="86" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno>PMLR, 2017. 7</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="1321" to="1330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">How citizen science boosted primary knowledge on fungal biodiversity in denmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Heilmann-Clausen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><forename type="middle">Henrik</forename><surname>Bruun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rasmus</forename><surname>Ejrnaes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><forename type="middle">Guldberg</forename><surname>Fr?slev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Laess?e</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><forename type="middle">H</forename><surname>Petersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological Conservation</title>
		<imprint>
			<biblScope unit="volume">237</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="366" to="372" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Vegfru: A domain-specific dataset for fine-grained visual categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saihui</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushan</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017-10" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Lifeclef 2015: multimedia life species identification challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>Go?au</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Concetto</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Willem-Pier</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Planqu?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Palazzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bob</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Novel dataset for fine-grained image categorization : Stanford dogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nityananda</forename><surname>Jayadevaprakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bangpeng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The unreasonable effectiveness of noisy data for fine-grained recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Howard</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Duerig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="301" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei Fei</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<title level="m">Convolutional deep belief networks on cifar-10</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Leafsnap: A computer vision system for automatic plant species identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neeraj</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arijit</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">John</forename><surname>Kress</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ida</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><forename type="middle">V B</forename><surname>Soares</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 12th European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2012-10" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Hoiem</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2935" to="2947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Bilinear cnn models for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aruni</forename><surname>Roychowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1449" to="1457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dog breed classification using part localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiongxin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Belhumeur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="172" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Presenceonly geographical priors for fine-grained image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><surname>Mac Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elijah</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Fine-grained visual classification of aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Automated flower classification over a large number of classes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria-Elena</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<title level="m">Sixth Indian Conference on Computer Vision, Graphics &amp; Image Processing</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Improved deep metric learning with multiclass n-pair loss objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Neural Information Processing Systems</title>
		<meeting>the 30th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1857" to="1865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Improving cnn classifiers by estimating test-time priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08235v2</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fungi recognition: A practical use case</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Sulc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Picek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Jeppesen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Heilmann-Clausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-First AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A large and diverse dataset for improved vehicle make and model recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faezeh</forename><surname>Tafazzoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hichem</forename><surname>Frigui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keishin</forename><surname>Nishiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11946</idno>
		<title level="m">Rethinking model scaling for convolutional neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Evaluating model calibration in classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juozas</forename><surname>Vaicenavicius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Widmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fredrik</forename><surname>Lindsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Roll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Sch?n</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3459" to="3467" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Panos Ipeirotis, Pietro Perona, and Serge Belongie. Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained dataset collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Grant Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Farrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessie</forename><surname>Haber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The inaturalist species classification and detection dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><forename type="middle">Mac</forename><surname>Grant Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="8769" to="8778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Few-shot learning with localization in realistic settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davis</forename><surname>Wertheimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6558" to="6567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Attngan: Finegrained text to image generation with attentional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengchuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuyuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1316" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A gift from knowledge distillation: Fast optimization, network minimization and transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junho</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donggyu</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihoon</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4133" to="4141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Classification is a strong baseline for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao-Yu</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British machine vision conference</title>
		<meeting>the British machine vision conference</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanshi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><forename type="middle">Nian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<title level="m">terpretable convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8827" to="8836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Picking deep filter responses for finegrained image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wengang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1134" to="1142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Unlabeled samples generated by gan improve the person re-identification baseline in vitro</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhedong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3754" to="3762" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
