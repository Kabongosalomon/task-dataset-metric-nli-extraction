<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Generic Neural Architecture Search via Regression</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Hao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Li</surname></persName>
							<email>panli@purdue.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University at Buffalo</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
							<email>jinjun@buffalo.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deming</forename><surname>Chen</surname></persName>
							<email>dchen@illinois.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Illinois at Urbana-Champaign 1</orgName>
								<orgName type="institution" key="instit2">Georgia Institute of Technology 2</orgName>
								<orgName type="institution" key="instit3">Purdue University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Generic Neural Architecture Search via Regression</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>further improving the performance of GenNAS. We also thoroughly evaluate Gen-NAS&apos;s generality and end-to-end NAS performance on all search spaces, which outperforms almost all existing works with significant speedup. For example, on NASBench-201, GenNAS can find near-optimal architectures within 0.3 GPU hour. Our code has been made available at: https://github.com/leeyeehoo/GenNAS</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T19:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most existing neural architecture search (NAS) algorithms are dedicated to and evaluated by the downstream tasks, e.g., image classification in computer vision. However, extensive experiments have shown that, prominent neural architectures, such as ResNet in computer vision and LSTM in natural language processing, are generally good at extracting patterns from the input data and perform well on different downstream tasks. In this paper, we attempt to answer two fundamental questions related to NAS. (1) Is it necessary to use the performance of specific downstream tasks to evaluate and search for good neural architectures? (2) Can we perform NAS effectively and efficiently while being agnostic to the downstream tasks? To answer these questions, we propose a novel and generic NAS framework, termed Generic NAS (GenNAS). GenNAS does not use task-specific labels but instead adopts regression on a set of manually designed synthetic signal bases for architecture evaluation. Such a self-supervised regression task can effectively evaluate the intrinsic power of an architecture to capture and transform the input signal patterns, and allow more sufficient usage of training samples. Extensive experiments across 13 CNN search spaces and one NLP space demonstrate the remarkable efficiency of GenNAS using regression, in terms of both evaluating the neural architectures (quantified by the ranking correlation Spearman's ? between the approximated performances and the downstream task performances) and the convergence speed for training (within a few seconds). For example, on NAS-Bench-101, GenNAS achieves 0.85 ? while the existing efficient methods only achieve 0.38. We then propose an automatic task search to optimize the combination of synthetic signals using limited downstream-task-specific labels, further improving the performance of GenNAS. We also thoroughly evaluate Gen-NAS's generality and end-to-end NAS performance on all search spaces, which outperforms almost all existing works with significant speedup. For example, on NASBench-201, GenNAS can find near-optimal architectures within 0.3 GPU hour. Our code has been made available at:</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Most existing neural architecture search (NAS) approaches aim to find top-performing architectures on a specific downstream task, such as image classification <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>, semantic segmentation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>, neural machine translation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref> or more complex tasks like hardware-software codesign <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref>. They either directly search on the target task using the target dataset (e.g., classification on CIFAR-10 <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b16">17]</ref> ), or search on a proxy dataset and then transfer to the target one (e.g. CIFAR-10 to ImageNet) <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b2">3]</ref>. However, extensive experiments show that prominent neural architectures are generally good at extracting patterns from the input data and perform well to different downstream tasks. For example, ResNet <ref type="bibr" target="#b18">[19]</ref> being a prevailing architecture in computer vision, shows outstanding performance across various datasets and tasks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>, because of its For regression, all samples equally contribute to the regression accuracy. Therefore, regression is better at leveraging all training samples than classification to achieve faster convergence.</p><p>advantageous architecture, the residual blocks. This observation motivates us to ask the first question: Is there a generic way to search for and evaluate neural architectures without using the specific knowledge of downstream tasks?</p><p>Meanwhile, we observe that most existing NAS approaches directly use the final classification performance as the metric for architecture evaluation and search, which has several major issues. First, the classification accuracy is dominated by the samples along the classification boundary, while other samples have clearer classification outcomes compared to the boundary ones (as illustrated in <ref type="figure" target="#fig_0">Fig. 1a</ref>). Such phenomena can be observed in the limited number of effective support vectors in SVM <ref type="bibr" target="#b22">[23]</ref>, which also applies to neural networks because of the theory of neural tangent kernel <ref type="bibr" target="#b23">[24]</ref>. Therefore, discriminating performance of classifiers needs many more samples than necessary (the indeed effective ones), causing a big waste. Second, a classifier tends to discard a lot of valuable information, such as finer-grained features and spatial information, by transforming input representations into categorical labels. This observation motivates us to ask the second question: Is there a more effective way that can make more sufficient use of input samples and better capture valuable information?</p><p>To answer the two fundamental questions for NAS, in this work, we propose a Generic Neural Architecture Search method, termed GenNAS. GenNAS adopts a regression-based proxy task using downstream-task-agnostic synthetic signals for network training and evaluation. It can efficiently (with near-zero training cost) and accurately approximate the neural architecture performance.</p><p>Insights. First, as opposed to classification, regression can efficiently make fully use of all the input samples, which equally contribute to the regression accuracy ( <ref type="figure" target="#fig_0">Fig. 1b)</ref>. Second, regression on properly-designed synthetic signals is essentially evaluating the intrinsic representation power of neural architectures, which is to capture and distinguish fundamental data patterns that are agnostic to downstream tasks. Third, such representation power is heavily reflected in the intermediate data of a network (as we will show in the experiments), which are regrettably discarded by classification.</p><p>Approach. First, we propose a regression proxy task as the supervising task to train, evaluate, and search for neural architectures <ref type="figure" target="#fig_2">(Fig. 2)</ref>. Then, the searched architectures will be used for the target downstream tasks. To the best of our knowledge, we are the first to propose self-supervised regression proxy task instead of classification for NAS. Second, we propose to use unlabeled synthetic data (e.g., sine and random signals) as the groundtruth <ref type="figure" target="#fig_4">(Fig. 3)</ref> to measure neural architectures' intrinsic capability of capturing fundamental data patterns. Third, to further boost NAS performance, we propose a weakly-supervised automatic proxy task search with only a handful of groundtruth architecture performance (e.g. 20 architectures), to determine the best proxy task, i.e., the combination of synthetic signal bases, targeting a specific downstream task, search space, and/or dataset ( <ref type="figure" target="#fig_6">Fig. 4)</ref>.</p><p>GenNAS Evaluation. The efficiency and effectiveness of NAS are dominated by neural architecture evaluation, which directs the search algorithm towards top-performing network architectures. To quantify how accurate the evaluation is, one widely used indicator is the network performance Ranking</p><p>Correlation <ref type="bibr" target="#b24">[25]</ref> between the prediction and groundtruth ranking, defined as Spearman's Rho (?) or Kendall's Tau (? ). The ideal ranking correlation is 1 when the approximated and groundtruth rankings are exactly the same; achieving large ? or ? can significantly improve NAS quality <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28]</ref>. Therefore, in the experiments (Sec. 4), we evaluate GenNAS using the ranking correlation factors it achieves, and then show its end-to-end NAS performance in finding the best architectures. Extensive experiments are done on 13 CNN search spaces and one NLP space <ref type="bibr" target="#b28">[29]</ref>. Trained by the regression proxy task using only a single batch of unlabeled data within a few seconds, GenNAS significantly outperforms all existing NAS approaches on almost all the search spaces and datasets. For example, GenNAS achieves 0.87 ? on NASBench-101 <ref type="bibr" target="#b29">[30]</ref>, while Zero-Cost NAS <ref type="bibr" target="#b30">[31]</ref>, an efficient proxy NAS approach, only achieves 0.38. On end-to-end NAS, GenNAS generally outperforms others with large speedup. This implies that the insights behind GenNAS are plausible and that our proposed regression-based task-agnostic approach is generalizable across tasks, search spaces, and datasets.</p><p>Contributions. We summarize our contributions as follows:</p><p>? To the best of our knowledge, GenNAS is the first NAS approach using regression as the self-supervised proxy task instead of classification for neural architecture evaluation and search. It is agnostic to the specific downstream tasks and can significantly improve training and evaluation efficiency by fully utilizing only a handful of unlabeled data. ? GenNAS uses synthetic signal bases as the groundtruth to measure the intrinsic capability of networks that captures fundamental signal patterns. Using such unlabeled synthetic data in regression, GenNAS can find the generic task-agnostic top-performing networks and can apply to any new search spaces with zero effort. ? An automated proxy task search to further improve GenNAS performance.</p><p>? Thorough experiments show that GenNAS outperforms existing NAS approaches by large margins in terms of ranking correlation with near-zero training cost, across 13 CNN and one NLP space without proxy task search. GenNAS also achieves state-of-the-art performance for end-to-end NAS with orders of magnitude of speedup over conventional methods. ? With proxy task search being optional, GenNAS is fine-tuning-free, highly efficient, and can be easily implemented on a single customer-level GPU.</p><p>2 Related Work NAS Evaluation. Network architecture evaluation is critical in guiding the search algorithms of NAS by identifying the top-performing architectures, which is also a challenging task with intensive research interests. Early NAS works evaluated the networks by training from scratch with tremendous computation and time cost <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b0">1]</ref>. To expedite, weight-sharing among the subnets sampled from a supernet is widely adopted <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>. However, due to the poor correlation between the weight-sharing and the final performance ranking, weight-sharing NAS can easily fail even in simple search spaces <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>. Yu et al. <ref type="bibr" target="#b35">[36]</ref> further pointed out that without accurate evaluation, NAS runs in a near-random fashion. Recently, zero-cost NAS methods <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref> have been proposed, which score the networks using their initial parameters with only one forward and backward propagation. Despite the significant speed up, they fail to identify top-performing architectures in large search spaces such as NASBench-101. To detach the time-consuming network evaluation from NAS, several benchmarks are developed with fully-trained neural networks within the NAS search spaces <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b40">41]</ref>, so that researchers can assess the search algorithms alone in the playground.</p><p>NAS Transferability. To improve search efficiency, proxy tasks are widely used, on which the architectures are searched and then transferred to target datasets and tasks. For example, the CIFAR-10 classification dataset seems to be a good proxy for ImageNet <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b2">3]</ref>. Kornblith et al. <ref type="bibr" target="#b41">[42]</ref> studied the transferability of 16 classification networks on 12 image classification datasets. NASBench-201 <ref type="bibr" target="#b34">[35]</ref> evaluated the ranking correlations across three popular datasets with 15625 architectures. Liu et al. <ref type="bibr" target="#b42">[43]</ref> studied the architecture transferability across supervised and unsupervised tasks. Nevertheless, training on a downsized proxy dataset is still inefficient (e.g. a few epochs of full-blown training <ref type="bibr" target="#b42">[43]</ref>). In contrast, GenNAS significantly improves the efficiency by using a single batch of data while maintaining extremely good generalizability across different search spaces and datasets.</p><p>Self-supervised Learning. Self-supervised learning is a form of unsupervised learning, that the neural architectures are trained with automatically generated labels to gain a good degree of com-  On RNNs, we construct a many-to-many regression task, where the input and output tensors have the same size.</p><p>prehension or understanding <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b42">43]</ref>. Liu et al. <ref type="bibr" target="#b42">[43]</ref> recently proposed three unlabeled classification proxy tasks, including rotation prediction, colorization, and solving jigsaw puzzles, for neural network evaluation. Though promising, this approach did not explain why such manually designed proxy tasks are beneficial and still used classification for training with the entire dataset. In contrast, GenNAS uses regression with only a single batch of synthetic data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed GenNAS</head><p>In Section 3.1, we introduce the main concepts of task-agnostic GenNAS: 1) the proposed regression proxy task for both CNN architectures and recurrent neural network (RNN) architectures; 2) the synthetic signal bases used for representing the fundamental data patterns as the proxy task. In Section 3.2, we introduce the automated proxy task search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">GenNAS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Regression Architectures</head><p>Training using unlabeled regression is the key that GenNAS being agnostic to downstream tasks. Based on the insights discussed in Section 1, the principle of designing the regression architecture is to fully utilize the abundant intermediate information rather than the final classifier.</p><p>Regression on CNNs. Empirical studies show that CNNs learn fine-grained high-frequency spatial details in the early layers and produce semantic features in the late layers <ref type="bibr" target="#b47">[48]</ref>. Following this principle, as shown in <ref type="figure" target="#fig_2">Fig. 2a</ref>, we construct a Fully Convolutional Network (FCN) <ref type="bibr" target="#b48">[49]</ref> by removing the final classifier of a CNN, and then extract the FCN's intermediate feature maps from multiple stages. We denote the number of stages as N . Inputs. The inputs to the FCN are unlabeled real images, shaped as a tensor I ? R b?3?h?w , where b is the batch size, and h and w are the input image size. Outputs. From each stage i (1 ? i ? N ) of the FCN, we first extract a feature map tensor, denoted by F i ? R b?ci?hi?wi , and reshape it asF i ? R b?c i ?h ?w through a convolutional layer</p><formula xml:id="formula_0">M i byF i = M i (F i ) (with downsampling if w i &gt; w or h i &gt; h )</formula><p>. The outputs are the tensorsF i , which encapsulate the captured signal patterns from different stages. Groundtruth. We construct a synthetic signal tensor for each stage as the groundtruth, which serves as part of the proxy task. A synthetic tensor is a combination of multiple synthetic signal bases (more details in Section 3.1.2), denoted by F * i . We compareF i with F * i for training and evaluating the neural architectures. During training, we use MSE loss defined as L =</p><formula xml:id="formula_1">N i=1 E[(F * i ?F i ) 2 ]</formula><p>; during validation, we adjust each stage's output importance as L = N i=1</p><formula xml:id="formula_2">1 2 N ?i E[(F * i ?F i ) 2 ]</formula><p>since the feature map tensors of later stages are more related to the downstream task's performance. The detailed configurations of N , h , w , and c i are provided in the experiments. Regression on RNNs. The proposed regression proxy task can be similarly applied to NLP tasks using RNNs. Most existing NLP models use a sequence of word-classifiers as the final outputs,  whose evaluations are thus based on the word classification accuracy <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b51">52]</ref>. Following the same principle for CNNs, we design a many-to-many regression task for RNNs as shown in <ref type="figure" target="#fig_2">Fig. 2b</ref>. Instead of using the final word-classifier's output, we extract the output tensor of the intermediate layer before it. Inputs. For a general RNN model, the input is a random tensor I ? R l?b?d , where l is the sequence length, b is the batch size, and d is the length of input/output word vectors. Given a sequence of length l, the input to the RNN each time is one slice of the tensor I, denoted by</p><formula xml:id="formula_3">I (i) ? R b?d , 1 ? i ? l. Outputs. The output isF ? R l?b?d , where a slice ofF isF (i) ? R b?d .</formula><p>Groundtruth. Similar to the CNN case, we generate a synthetic signal tensor F * as the proxy task groundtruth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Synthetic Signal Bases</head><p>The proxy task for regression aims to capture the task-agnostic intrinsic learning capability of the neural architectures, i.e., representing various fundamental data patterns. For example, good CNNs must be able to learn different frequency signals to capture image features <ref type="bibr" target="#b52">[53]</ref>. Here, we design four types of synthetic signal basis: (1) 1-D frequency basis (Sin1D); (2) 2-D frequency basis (Sin2D); (3) Spatial basis (Dot and GDot); (4) Resized input signal (Resize). Sin1D and Sin2D represent frequency information, Dot and GDot represent spatial information, and Resize reflects the CNN's scale-invariant capability. The combinations of these signal bases, especially with different sine frequencies, can represent a wide range of complicated real-world signals <ref type="bibr" target="#b53">[54]</ref>. If a network architecture is good at learning such signal basis and their simple combinations, it is more likely to be able to capture real-world signals from different downstream tasks. <ref type="figure" target="#fig_4">Fig.3a</ref> depicts examples of synthetic signal bases, where each base is a 2D signal feature map. Sin1D is generated by sin(2?f x+?) or sin(2?f y +?), and Sin2D is generated by sin(2?f x x+2?f y y +?), where x and y are pixel indices. Dot is generated according to biased Rademacher distribution <ref type="bibr" target="#b54">[55]</ref> by randomly setting k% pixels to ?1 on zeroed feature maps. GDot is generated by applying a Gaussian filter with ? = 1 on Dot and normalizing between ?1. The synthetic signal tensor F * (the proxy task groundtruth) is constructed by stacking the 2D signal feature maps along the channel dimension (CNNs) or the batch dimension (for RNNs). <ref type="figure" target="#fig_4">Fig.3b</ref> shows examples of stacked synthetic tensor F * for CNN architectures. Within one batch of input images, we consider two settings: global and local. The global setting means that the synthetic tensor is the same for all the inputs within the batch, as the Sin2D Global in <ref type="figure" target="#fig_4">Fig. 3b</ref>, aiming to test the network's ability to capture invariant features from different inputs; the local setting uses different synthetic signal tensors for different inputs, as the Dot Local in <ref type="figure" target="#fig_4">Fig.3b</ref>, aiming to test the network's ability to distinguish between images. For CNNs, the real images are only used by resize, and both global and local settings are used. For RNNs, we only use synthetic signals and the local setting, because resizing natural language or time series, the typical input of RNNs, does not make as much sense as resizing images for CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Proxy Task Search</head><p>While the synthetic signals can express generic features, the importance of these features for different tasks, NAS search spaces, and datasets may be different. Therefore, we further propose a weaklysupervised proxy task search, to automatically find the best synthetic signal tensor, i.e., the best combination of synthetic signal bases. We define the proxy task search space as the parameters when generating the synthetic signal tensors. As illustrated in <ref type="figure" target="#fig_6">Fig. 4</ref>, first, we randomly sample a small subset (e.g., 20) of the neural architectures in the NAS search space and obtain their groundtruth ranking on the target task (e.g., image classification). We then train these networks using different proxy tasks and calculate the performance ranking correlation ? of the proxy and the target task. We use the regularized tournament selection evolutionary algorithm [1] to search for the task that results in the largest ?, where ? is the fitness function. Ranking on Proxy task  Proxy Task Search Space. We consider the following parameters as the proxy task search space. <ref type="formula">(1)</ref> Noise. We add noise to the input data following the distribution of parameterized Gaussian or uniform distribution. <ref type="formula">(2)</ref> The number of channels for each synthetic signal tensor (c i in F * i ? R b?ci?h ?w ) can be adjusted. <ref type="formula">(3)</ref> Signal parameters, such as the frequency f and phase ? in Sin, can be adjusted. (4) Feature combination. Each synthetic signal tensor uses either local or global, and tensors can be selected and summed up. Detailed parameters can be found in the supplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ranking on</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We perform the following evaluations for GenNAS. First, to show the true power of regression, we use manually designed proxy tasks without task search and apply the same proxy task on all datasets and search spaces. We demonstrate that the GenNAS generally excels in all different cases with zero task-specific cost, thanks to unlabeled self-supervised regression proxy task. Specifically, in Section 4.1, we analyze the effectiveness of the synthetic signal bases and manually construct two sets of synthetic tensors as the baseline proxy tasks; in Section 4.2, we extensively evaluate the proposed regression approach in 13 CNN search spaces and one NLP search space. Second, in Section 4.3, we evaluate the proxy task search and demonstrate the remarkable generalizability by applying one searched task to all NAS search spaces with no change. Third, in Section 4.4, we evaluate GenNAS on end-to-end NAS tasks, which outperforms existing works with significant speedup. Experiment Setup. We consider 13 CNN NAS search spaces including NASBench-101 <ref type="bibr" target="#b29">[30]</ref>, NASBench-201 <ref type="bibr" target="#b34">[35]</ref>, Network Design Spaces (NDS) <ref type="bibr" target="#b55">[56]</ref>, and one NLP search space, NASBench-NLP <ref type="bibr" target="#b28">[29]</ref>. All the training is conducted using only one batch of data with batch size 16 for 100 iterations. Details of NAS search spaces and experiment settings are in the supplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Effectiveness of Synthetic Signals</head><p>The synthetic signal analysis is performed on NASBench-101 using CIFAR-10 dataset. From the whole NAS search space, 500 network architectures are randomly sampled with a known performance ranking provided by NASBench-101. We train the 500 networks using different synthetic signal tensors and calculate their ranking correlations with respect to the groundtruth ranking. Using the CNN architecture discussed in Section 3.1.1, we consider three stages, S 1 to S 3 for N = 3; the number of channels is 64 for each stage. For Sin1D and Sin2D, we set three ranges for frequency f : low (L) f ? (0, 0.125) , medium (M) f ? (0.125, 0.375), and high (H) f ? (0.375, 0.5). Within each frequency range, 10 signals are generated using uniformly sampled frequencies. For Dot and GDot, we randomly set 50% and 100% pixels to ?1 on the zeroized feature maps.</p><p>The results of ranking correlations are shown in <ref type="table" target="#tab_1">Table 1</ref>. The three stages are evaluated independently and then used together. Among the three stages, Sin1D and Sin2D within medium and high frequency work better in S 1 and S 2 , while the high frequency Dot and resize work better in S 3 . The low frequency signals, such as GDot, Sin1D-L, Sin2D-L, and the extreme case zero tensors, result in low ranking correlations; we attribute to their poor distinguishing ability. We also observe that the best task in S 3 (0.81) achieves higher ? than S 1 (0.64) and S 2 (0.79), which is consistent with the intuition that the features learned in deeper stages have more impact to the final network performance. When all three stages are used, where each stage uses its top-3 signal bases, the ranking correlation can achieve 0.85, higher than the individual stages. This supports our assumption in Section 3.1.1 that utilizing more intermediate information of a network is beneficial. From this analysis, we choose two top-performing proxy tasks in the following evaluations to demonstrate the effectiveness of regression: GenNAS-single -the best proxy task with a single signal tensor Dot%100 used only in S 3 , and GenNAS-combo -the combination of the three top-performing tasks in three stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Effectiveness and Efficiency of Regression without Proxy Task Search</head><p>To quantify how well the proposed regression can approximate the neural architecture performance with only one batch of data within seconds, we use the ranking correlation, Spearman's ?, as the metric <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b33">34]</ref>. We use the two manually designed proxy tasks (GenNAS-single and GenNAS-combo) without proxy task search to demonstrate that GenNAS is generic and can be directly applied to any new search spaces with zero task-specific search efforts. The evaluation is extensively conducted on 13 CNN search spaces and 1 NLP search space, and the results are summarized in <ref type="table" target="#tab_2">Table 2</ref>.</p><p>On NASBench-101, GenNAS is compared with zero-cost NAS <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b36">37]</ref> and the latest classification based approaches <ref type="bibr" target="#b42">[43]</ref>. Specifically, NASWOT <ref type="bibr" target="#b36">[37]</ref> is a zero-training approach that predicts a network's trained accuracy from its initial state by examining the overlap of activations between datapoints. Abdelfattah et al. <ref type="bibr" target="#b30">[31]</ref> proposed proxies such as synflow to evaluate the networks, where the synflow computes the summation of all the weights multiplied by their gradients and has the best reported performance in the paper. Liu et al. <ref type="bibr" target="#b42">[43]</ref> used three unsupervised classification training proxies, namely rotation prediction (rot), colorization (col), and solving jigsaw puzzles (jig), and one supervised classification proxy (cls).  <ref type="figure">Figure 5</ref>: The effectiveness of regression-based proxy task. GenNAS significantly outperforms all the existing NAS evaluation approaches regarding ranking correlation, with near-zero training cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GenNAS</head><p>We report their results after 10 epochs (@ep10) for each proxy. The results show that GenNASsingle and GenNAS-combo achieve 0.81 and 0.85 ? on CIFAR-10, and achive 0.73 on Im-ageNet, respectively, much higher than NAS-WOT and synflow. It is also comparable and even higher comparing with the classification proxies, cls@ep5 and cls@ep10. Notably, the classification proxies need to train for 10 epochs using all training data, while GenNAS requires only a few seconds, more than 40? faster. On NASBench-201, we further compare with vote <ref type="bibr" target="#b30">[31]</ref> and EcoNAS <ref type="bibr" target="#b25">[26]</ref>. EcoNAS is a recently proposed reduced-training proxy NAS approach. Vote <ref type="bibr" target="#b30">[31]</ref> adopts the majority vote between three zero-training proxies including synflow, jacob_cov, and snip. Clearly, GenNAScombo outperforms all these methods regarding ranking correlation, and is also 60? faster than EcoNAS and 40? faster than cls@ep10. On Neural Design Spaces, we evaluate GenNAS on both CIFAR-10 and ImageNet datasets. Comparing with NASWOT and synflow, GenNAS-single and GenNAS-combo achieve higher ? in almost all cases. Also, synflow performs poorly on most of the NDS search spaces especially on ImageNet dataset, while GenNAS achieves even higher ?. Extending to NLP search space, NASBench-NLP, GenNAS-single and GenNAS-combo achieve 0.73 and 0.74 ?, respectively, surpassing the best zero-proxy method (0.56). Comparing with the ppl@ep3, the architectures trained on PTB <ref type="bibr" target="#b56">[57]</ref> dataset after three epochs, GenNAS is 192? faster in prediction.  Effectiveness of Proxy Task Search. While the unsearched proxy tasks can already significantly outperform all existing approaches (shown in Section 4.2), we demonstrate that the proxy task search described in Section 3.2 can further improve the ranking correlation. We adopt the regularized evolutionary algorithm <ref type="bibr" target="#b0">[1]</ref>. The population size is 50; the tournament sample size is 10; the search runs 400 iterations. We randomly select 20 architectures with groundtruth for calculating the ?. More settings can be found in the supplemental material. <ref type="figure">Fig. 6</ref> shows the search results averaged from 10 runs with different seeds. It shows that the regularized evolutionary algorithm is more effective comparing with random search, where the correlations of 20 architectures are 0.86 ? 0.02 and 0.82 ? 0.01, respectively.</p><p>In the following experiments, we evaluate three searched proxy tasks, denoted by GenNAS search-N, -D, and -R, meaning that the task is searched on NASBench-101, NDS DARTS search space, and GenNAS with Searched/Transferred Proxy Task. The performance of GenNAS-search-N, -D, and -R proxy tasks is shown in <ref type="table" target="#tab_2">Table 2</ref>. First, in most cases, proxy task search improves the ranking correlation. For example, in NDS, using the proxy task searched on DARTS space (search-D) outperforms other GenNAS settings on DARTS-like spaces, while using proxy task search-R on ResNet-like spaces outperforms others as well. In NASBench-NLP, the proxy task search can push the ranking correlation to 0.81, surpassing the ppl@ep3 (0.79). Such results demonstrate the effectiveness of our proposed proxy task search. Second, the searched proxy task shows great transferability: the proxy task searched on NASBench-101 (search-N) generally works well for other search spaces, i.e., NASBench-201, NDS, and NASBench-NLP. This further emphasizes that the fundamental principles for top-performing neural architectures are similar across different tasks and datasets. <ref type="figure">Fig. 5</ref> visualizes the performance of GenNAS comparing with others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">GenNAS for End-to-End NAS</head><p>Finally, we evaluate GenNAS on the end-to-end NAS tasks, aiming to find the best neural architectures within the search space. <ref type="table" target="#tab_3">Table 3</ref> summarizes the comparisons with the state-of-the-art NAS approaches, including previously used NASWOT, synflow, cls@ep10, and additionally Halfway <ref type="bibr" target="#b29">[30]</ref>, RSPS <ref type="bibr" target="#b27">[28]</ref>, DARTS-V1 <ref type="bibr" target="#b2">[3]</ref>, DARTS-V2, GDAS <ref type="bibr" target="#b57">[58]</ref>, SETN <ref type="bibr" target="#b58">[59]</ref>, and ENAS <ref type="bibr" target="#b59">[60]</ref>. Halfway is the NASBench-101-released result using half of the total epochs for network training. In all the searches during NAS, we do not use any tricks such as warmup selection <ref type="bibr" target="#b30">[31]</ref> or groundtruth query to compensate the low rank correlations. We fairly use a simple yet effective regularized evolutionary algorithm <ref type="bibr" target="#b0">[1]</ref> and adopt the proposed regression loss as the fitness function. The population size is 50 and the tournament sample size is 10 with 400 iterations. On NASBench-101, GenNAS finds better architectures than NASWOT and Halfway while being up to 200? faster. On NASBench-201, GenNAS finds better architectures than the state-of-the-art GDAS within 0.3 GPU hours, being 30? faster. Note that GenNAS uses the proxy task searched on NASBench-101 and transferred to NASBench-201, demonstrating remarkable transferability. On Neural Design Spaces, GenNAS finds better architectures than the cls@ep10 using labeled classification while being 40? faster. On NASBench-NLP, GenNAS finds architectures that achieve 0.246 (the lower the better) average final regret score r, outperforming the ppl@ep3 (0.268) with 192? speed up. The regret score r at the moment t is r(t) = L(t) ? L , where L(t) is the testing log perplexity of the best found architecture On DARTS search space, we also perform the end-to-end search on ImageNet-1k <ref type="bibr" target="#b60">[61]</ref> dataset. We fix the depth (layer) of the networks to be 14 and adjust the width (channel) so that the # of FLOPs is between 500M to 600M. We evaluate two strategies: one without task search using GenNAS-combo (see <ref type="table" target="#tab_1">Table 1</ref>), and the other GenNAS-D14 with proxy task search on DARTS search space with depth 14 and initial channel 16. The training settings follow TENAS <ref type="bibr" target="#b61">[62]</ref>. The results are shown in <ref type="table" target="#tab_4">Table 4</ref>. We achieve top-1/5 test error of 25.1/7.8 using GenNAS-combo and top-1/5 test error of 24.3/7.2 using GenNAS-D14, which are on par with existing NAS architectures. GenNAS-combo is much faster than existing works, while GenNAS-D14 pays extra search time cost. Our next step is to investigate the searched tasks and demonstrate the generalization and transferrability of those searched tasks to further reduce the extra search time cost.</p><p>These end-to-end NAS experiments strongly suggest that GenNAS is generically efficient and effective across different search spaces and datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we proposed GenNAS, a self-supervised regression-based approach for neural architecture training, evaluation, and search. GenNAS successfully answered the two questions at the beginning. (1) GenNAS is a generic task-agnostic method, using synthetic signals to capture neural networks' fundamental learning capability without specific downstream task knowledge. (2) GenNAS is an extremely effective and efficient method using regression, fully utilizing all the training samples and better capturing valued information. We show the true power of self-supervised regression via manually designed proxy tasks that do not need to search. With proxy search, GenNAS can deliver even better results. Extensive experiments confirmed that GenNAS is able to deliver state-of-the-art performance with near-zero search time, in terms of both ranking correlation and the end-to-end NAS tasks with great generalizability.  <ref type="bibr" target="#b59">[60]</ref>, NASNet <ref type="bibr" target="#b17">[18]</ref>, PNAS <ref type="bibr" target="#b62">[63]</ref>, ResNet <ref type="bibr" target="#b18">[19]</ref>, ResNeXt <ref type="bibr" target="#b67">[68]</ref>, etc. A search space with "-f" suffix stands for a search space that has fixed number of layers and channels. The ResNeXt-A and ResNeXt-B have different channel-number and group-convolution settings. NASBench-NLP 5 <ref type="bibr" target="#b28">[29]</ref> is an NLP neural architecture search space, including 14k recurrent cells trained on the Penn Treebank (PTB) <ref type="bibr" target="#b56">[57]</ref> dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Experiment Setup</head><p>For CNN architecture training, the learning rate is 1e?1 and the weight decay is 1e?5. Each architecture is trained for 100 iterations on a single batch of data using SGD optimizer <ref type="bibr" target="#b68">[69]</ref>. All the convolutional architectures use the same setting. The size of the input images is h = w = 32 and the size of output feature maps is h = w = 8. For RNN training, the learning rate is 1e?3, the weight decay is 1.2e?6, the batch size b is 16, and the sequence length l is 8. Each architecture is trained for 100 iterations on a single batch of data using the Adam optimizer <ref type="bibr" target="#b69">[70]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.1 Regularized Evolutionary Algorithm</head><p>Regularized Evolutionary Algorithm <ref type="bibr" target="#b0">[1]</ref> (RE) combines the tournament selection <ref type="bibr" target="#b70">[71]</ref> with the aging mechanism which remove the oldest individuals from the population each round. We show a general form of RE in Alg. 1. Aging evolution aims to explore the search space more extensively, instead of focusing on the good models too early. Works <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b71">72]</ref> also suggest that the RE is suitable for neural architecture search. Since we aim to develop a general NAS evaluator (as the fitness function in RE), we conduct fair comparisons between GenNAS and other methods without fine-tuning or any tricks (e.g., warming-up). Hence, we constantly use the setting P = 50, S = 10, T _iter = 400 for all the search experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 Proxy Task Search</head><p>The configuration of a task is shown in <ref type="figure">Fig. 7</ref>. We introduce the detailed settings of different signal bases. (1) Noise is chosen from standard Gaussian distribution (N (0, 1)) or uniform distribution (U <ref type="figure" target="#fig_0">(?1, 1)</ref>). The generated noise maps are directly multiplied by the level which can be selected from 0 to 1 with a step of 0.1. (2) Sin1D generates 2D synthetic feature maps using different frequencies choosing from the range, which contains 10 frequencies sampled from [a, b], where a and b are sampled from 0 to 0.5 with the constraint 0 &lt; a &lt; b &lt; 0.5. (3) Sin2D uses the similar setting as Sin1D, where both the f x and f y for a 2D feature map are sampled from the range.</p><p>(4) C i can be selected from {16, 32, 48, 64, 96}. Other settings are already described in Section 3.1.2. During the mutation, each minimum mutatable block (including signal definitions and the number of channels) has 0.2 probability to be regenerated as shown in <ref type="figure">Fig. 7</ref>. For RNN settings, we search for both the input and output synthetic signal tensors. The dimension d is chosen from {16, 32, 48, 64, 96}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1: Regularized Evolutionary Algorithm in General</head><p>Initialize an empty population queue, Q_pop // The maximum population is P Initialize an empty set, history // Will contain all visited individuals for i = 1, 2, ? ? ? , P do new_individual ? RandomInit() new_individual.f itness ? Eval(new_individual) Enqueue(Q_pop, new_individual)// Add individual to the right of Q_pop Add new_individual to history end // Evolve for T _iter for i = 1, 2, ? ? ? , T _iter do Initialize an empty set, sample_set for i = 1, 2, ? ? ? , S do Add an individual to sample_set from Q_pop without replacement.  <ref type="figure">Figure 7</ref>: The configuration of a task in JSON style and the illustration of task mutation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.3 End-to-end NAS</head><p>In the end-to-end NAS, GenNAS is incorporated in the RE as the fitness function to explore the search space. For NASBench-101, the mutation rate for each vertice is 1/|v| where |v| = 7. More details of the search space NASBench-101 can be found in the original paper <ref type="bibr" target="#b29">[30]</ref>. For NASBench-201, the mutation rate for each edge is 1/|e| where |e| = 6. More details of the search space NASBench-101 can be found in the original paper <ref type="bibr" target="#b34">[35]</ref>. For NDS ResNet series, the sub search space consists of 25000 sampled architectures from the whole search space. We apply mutation in RE by randomly sampling 200 architectures from the sub search space and choosing the most similar architecture as the child. For NASBench-NLP, we follow the work <ref type="bibr" target="#b28">[29]</ref> by using the graph2vec <ref type="bibr" target="#b72">[73]</ref> features find the most similar architecture as the child.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Additional Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.1 Regression vs. Classification Using Same Training Samples</head><p>We study effectiveness of regression using 10 tasks searched on NASBench-101, varying the batch size from 1 to 1024. The ranking correlation achieved by GenNAS using regression is plotted in <ref type="figure" target="#fig_11">Fig. 8a</ref>. We also plot the classification task performances with single-batch data in <ref type="figure" target="#fig_11">Fig. 8b</ref>. Apparently, using the same amount of data, the ranking correlation achieved by classification (? around 0.85) is much worse than regression (? around 0.3).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.2 Batch Sizes and Iterations</head><p>We show the effect of batch size by using 10 tasks searched on NASBench-101. We use batch sizes varied from 1 to 1024 and plot the ranking results in <ref type="figure" target="#fig_11">Fig. 8a</ref>. We find that 16 as the batch size is adequate for a good ranking performance. Also, we observe a small degradation when batch size increases and then becomes stable as the batch size keeps increasing. Hence, We plot the ranked architecture distribution with a searched task using 1, 16, 1024 as batch size respectively on <ref type="figure" target="#fig_11">Fig. 8c, 8d</ref>, 8e. We observe that when only using a single image, the poor-performance architectures can also achieve similar regression losses as the good architectures. It suggests that the task is too easy to distinguish the differences among architectures. Also, 1024 as batch size leads to the higher regression losses of best architectures. It suggests that a very challenging task is also hard for good architectures to learn and may lead to slight ranking performance degradation. In addition, we plot the ranking performance using different numbers of iterations in <ref type="figure" target="#fig_11">Fig. 8f</ref>. It shows that 100 iterations is necessary for the convergence of ranking performance. Random Seeds. We rerun the 3 searched tasks on their target search spaces (NASBench-101, DARTS, ResNet) for 10 runs with different random seeds. The results are shown in <ref type="table" target="#tab_6">Table 5</ref>. GenNAS demonstrates its robustness across different random seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.3 Sensitivity Studies of Random Seeds and Initialization</head><p>Initialization. We perform an experiment to evaluate the effects of different initialization for 10 searched tasks on NASBench-101. For the weights, we use the default PyTorch initialization, Kaiming initialization <ref type="bibr" target="#b73">[74]</ref>, and Xavier initialization <ref type="bibr" target="#b74">[75]</ref>. For the bias, we use the default PyTorch initialization and zeroized initialization. The results are shown in <ref type="table" target="#tab_7">Table 6</ref>. We observe that for some specific tasks (e.g., task 7), Kaiming initialization may lead to lower ranking correlation. Also, zeroized bias initialization slightly increases the ranking correlation. However, overall, GenNAS shows stable performance across different initialization methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.4 Kendall Tau and Retrieving Rates</head><p>For the sample experiments on NASBench-101/201/NLP and NDS, we report the performance of our methods compared to other efficient NAS approaches' in <ref type="table" target="#tab_8">Table 7</ref> by Kendall ? <ref type="bibr" target="#b75">[76]</ref>. We define the retrieving rate@topK as #{Pred@TopK?GT@TopK} #{GT@TopK} , where # is the operator of cardinality, GT@TopK and Pred@TopK are the set of architectures that are ranked in the top-K of groundtruths and predictions respectively. We report the retrieving rate@Top10% for all the search spaces in <ref type="table" target="#tab_9">Table 8</ref>. Moreover, we report the retrieving rate@Top5%-Top50% for GenNAS-COMBO and GenNAS-N on NASBench-101 with other 1000 random sampled architectures in <ref type="table" target="#tab_10">Table 9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.5 End-to-end NAS Architectures</head><p>Here we visualize all the ImageNet DARTS cell architectures: searched by GenNAS-combo, searched by GenNAS-D14 in <ref type="figure">Fig 9 and</ref>        </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3.6 GPU Performance</head><p>We use the PyTorch 1.5.0 <ref type="bibr" target="#b76">[77]</ref>, on a desktop with I7-7700K CPU, 16 GB RAM and a GTX 1080 Ti GPU (11GB GDDR5X memory) to evaluate the GPU performance of GenNAS. The results are shown in <ref type="table" target="#tab_1">Table 10</ref>. <ref type="table" target="#tab_1">Table 10</ref>: Evaluations of GenNAS' GPU performance. We test GenNAS with 6 different batch sizes from 16 to 96. "A/B" denotes: A (second) as the average one-iteration run time for the search space, and B (GB or gigabyte) as the GPU memory usage. "OOM" means some large models may lead to the out-of-memory issue for the target GPU.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>For classification, only samples near the decision boundary determine the classification accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Regression architectures on CNNs and RNNs. (a) On CNNs, we remove the final classifier and extract multiple stages of intermediate feature map for training. (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a) Examples of signal bases (b) Examples of synthetic signal tensors</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>(a) Examples of synthetic signal bases (2D feature maps). (b) Examples of the synthetic signal tensors by stacking 2D feature maps along the channel dimension for CNN architectures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 :</head><label>4</label><figDesc>Proxy task search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5 Figure 6 :</head><label>56</label><figDesc>visualizes the comparisons between GenNAS and existing NAS approaches on NASBench-101, CIFAR-10. Clearly, regression-based GenNAS (single, combo) significantly outperforms the existing NAS with near-zero training cost, showing remarkable effectiveness and high efficiency. 4.3 Effectiveness of Proxy Task Search and Transferability Proxy task search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>// The individual stays in Q_pop end parent ? the individual with best fitness in sample_set child ? Mutate(parent) child.f itness ? Eval(child) Enqueue( Q_pop, child ) Add child to history Dequeue( Q_pop)// Remove the oldest individual from the left of Q_pop end return the individual with best fitness in history {'noise': {'type':'uniform','noise_level': 0.7}, 'c1': 64, 'c2': 32, 'c3': 96, 'features': {'1': {'sin1D': {'level': 1.3, 'range': [...], 'local': True}, 'sin2D': None, 'dot': {'level': 2.4, 'partial': 0.6, 'local': False}, 'gdot': None, 'resize': {'level': 1': 0.3, 'range': [...], 'local': False} Yes No None</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>(a) Regression (GenNAS) ranking correlation averaged from 10 searched tasks using different batch sizes.(b) Classification task's ranking correlation using the same setting as (a). (c) Classification accuracy vs. GenNS regression loss with batch size 1. (d) Classification accuracy vs. GenNS regression loss with batch size 16. (e) Classification accuracy vs. GenNS regression loss with batch size 1024. (f) 10 searched tasks' ranking correlation on NASBench-101 using different numbers of iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 8 :</head><label>8</label><figDesc>(a) Regression (GenNAS) ranking correlation averaged from 10 searched tasks on NASBench-101 in terms of Spearman's ? with batch size in {1, 16, 32, ..., 256, 512, 1024}. (b) Classification task's ranking correlation using the same amount of data in (a). (c) Classification accuracy using a searched task on NASBench-101 with batch size as 1 on CIFAR-10. The y-axis is the groundtruth (CIFAR-10 accuracy) and the x-axis is the GenNAS regression loss. (d) Similar to (c), batch size as 16. (e) Similar to (c), batch size as 1024. (f) 10 searched tasks ranking performance (in terms of Spearman's ?) on NASBench-101 using different iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Fig 10 respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 9 :Figure 10 :</head><label>910</label><figDesc>Cell architectures (normal and reduce) searched by GenNAS-combo Cell architectures (normal and reduce) searched by GenNAS-D14</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Ranking correlation (Spearman's ?) analysis of different synthetic signals on NASBench-101.</figDesc><table><row><cell>Stage</cell><cell></cell><cell>Sin1D</cell><cell></cell><cell></cell><cell>Sin2D</cell><cell></cell><cell></cell><cell>Dot</cell><cell></cell><cell>GDot</cell><cell>Resize</cell><cell>Zero</cell></row><row><cell></cell><cell>L</cell><cell>M</cell><cell>H</cell><cell>L</cell><cell>M</cell><cell>H</cell><cell>50%</cell><cell>100%</cell><cell>50%</cell><cell>100%</cell><cell></cell><cell></cell></row><row><cell>S1</cell><cell>0.13</cell><cell>0.43</cell><cell>0.64</cell><cell>0.14</cell><cell>0.53</cell><cell>0.63</cell><cell>0.55</cell><cell>0.62</cell><cell>0.18</cell><cell>0.16</cell><cell>0.56</cell><cell>0.17</cell></row><row><cell>S2</cell><cell>0.03</cell><cell>0.52</cell><cell>0.79</cell><cell>0.05</cell><cell>0.73</cell><cell>0.72</cell><cell>0.64</cell><cell>0.69</cell><cell>0.03</cell><cell>0.02</cell><cell>0.73</cell><cell>0.18</cell></row><row><cell>S3</cell><cell>0.08</cell><cell>0.77</cell><cell>0.80</cell><cell>0.23</cell><cell>0.78</cell><cell>0.72</cell><cell>0.76</cell><cell>0.81</cell><cell>0.16</cell><cell>0.17</cell><cell>0.80</cell><cell>0.22</cell></row><row><cell cols="3">GenNAS-combo:: 0.85</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>GenNAS ranking correlation evaluation using the correlation Spearman's ?. GenNAS-single and GenNAS-combo use a single or a combination of synthetic signals that are manually designed without proxy task search. GenNAS search-N, -D, -R mean the proxy task is searched on NASBench-101, NDS DARTS design space, and NDS ResNet design space, respectively. The top-1/2/3 results of GenNAS and efficient NAS baselines are highlighted by ? / ? / ? respectively for each task. The values with superscripts are obtained after task search ( s ) or transferred ( t ) from a previous searched task. Methods like jig@ep10 which is 40x slower compared to the GenNAS in prediction are not considered as efficient ones.</figDesc><table><row><cell cols="2">NASBench-101</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell cols="7">NASWOT synflow jig@ep10 rot@ep10 col@ep10 cls@ep10</cell><cell></cell><cell>GenNAS</cell></row><row><cell></cell><cell>[37]</cell><cell>[31]</cell><cell></cell><cell></cell><cell cols="2">&gt; 40? slower</cell><cell></cell><cell cols="3">single combo search-N</cell></row><row><cell>CIFAR-10</cell><cell>0.34</cell><cell>0.38</cell><cell cols="2">0.69</cell><cell>0.85</cell><cell>0.71</cell><cell>0.81</cell><cell cols="3">0.81  ? 0.85  ? 0.87  ?s</cell></row><row><cell>ImgNet</cell><cell>0.21</cell><cell>0.09</cell><cell cols="2">0.72</cell><cell>0.82</cell><cell>0.67</cell><cell>0.79</cell><cell cols="3">0.65  ? 0.73  ? 0.71  ?t</cell></row><row><cell cols="2">NASBench-201</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell cols="4">NASWOT synflow jacob_cov snip</cell><cell>cls@ep10</cell><cell>vote</cell><cell cols="2">EcoNAS</cell><cell cols="2">GenNAS</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">&gt; 40? slower</cell><cell cols="4">&gt; 60? slower single combo search-N</cell></row><row><cell>CIFAR-10</cell><cell>0.79  ?</cell><cell>0.72</cell><cell>0.76</cell><cell>0.57</cell><cell>0.75</cell><cell>0.81</cell><cell>0.81</cell><cell cols="3">0.77 0.87  ? 0.90  ?t</cell></row><row><cell>CIFAR-100</cell><cell>0.81</cell><cell>0.76</cell><cell>0.70</cell><cell>0.61</cell><cell>0.75</cell><cell>0.83  ?</cell><cell>0.75</cell><cell cols="3">0.69 0.82  ? 0.84  ?t</cell></row><row><cell>ImgNet16</cell><cell>0.78</cell><cell>0.73</cell><cell>0.73</cell><cell>0.59</cell><cell>0.68</cell><cell>0.81  ?</cell><cell>0.77</cell><cell cols="3">0.70 0.81  ? 0.87  ?t</cell></row><row><cell cols="2">Neural Design Spaces</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell cols="4">NAS-Space NASWOT synflow</cell><cell>cls@ep10</cell><cell></cell><cell></cell><cell>GenNAS</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">&gt; 40? slower single combo search-N search-D search-R</cell></row><row><cell>CIFAR-10</cell><cell>DARTS</cell><cell>0.65</cell><cell></cell><cell>0.41</cell><cell>0.63</cell><cell>0.43</cell><cell>0.68</cell><cell>0.71  ?t</cell><cell>0.86  ?s</cell><cell>0.82  ?t</cell></row><row><cell></cell><cell>DARTS-f</cell><cell>0.31</cell><cell></cell><cell>0.09</cell><cell>0.82</cell><cell cols="2">0.51 0.59  ?</cell><cell>0.53  ?t</cell><cell>0.58  ?t</cell><cell>0.52 t</cell></row><row><cell></cell><cell>Amoeba</cell><cell>0.33</cell><cell></cell><cell>0.06</cell><cell>0.67</cell><cell>0.52</cell><cell>0.64</cell><cell>0.68  ?t</cell><cell>0.78  ?t</cell><cell>0.72  ?t</cell></row><row><cell></cell><cell>ENAS</cell><cell>0.55</cell><cell></cell><cell>0.19</cell><cell>0.66</cell><cell cols="2">0.56 0.70  ?</cell><cell>0.67 t</cell><cell>0.82  ?t</cell><cell>0.78  ?t</cell></row><row><cell></cell><cell>ENAS-f</cell><cell>0.43</cell><cell></cell><cell>0.26</cell><cell>0.86</cell><cell>0.65</cell><cell>0.65</cell><cell>0.67  ?t</cell><cell>0.73  ?t</cell><cell>0.67  ?t</cell></row><row><cell></cell><cell>NASNet</cell><cell>0.40</cell><cell></cell><cell>0.00</cell><cell>0.64</cell><cell cols="2">0.56 0.66  ?</cell><cell>0.65 t</cell><cell>0.77  ?t</cell><cell>0.71  ?t</cell></row><row><cell></cell><cell>PNAS</cell><cell>0.51</cell><cell></cell><cell>0.26</cell><cell>0.50</cell><cell>0.32</cell><cell>0.58</cell><cell>0.59  ?t</cell><cell>0.76  ?t</cell><cell>0.71  ?t</cell></row><row><cell></cell><cell>PNAS-f</cell><cell>0.10</cell><cell></cell><cell>0.32</cell><cell>0.85</cell><cell cols="2">0.45 0.48  ?</cell><cell>0.56  ?t</cell><cell>0.55  ?t</cell><cell>0.47 t</cell></row><row><cell></cell><cell>ResNet</cell><cell>0.26</cell><cell></cell><cell>0.22</cell><cell>0.65</cell><cell>0.34</cell><cell>0.52</cell><cell>0.55  ?t</cell><cell>0.54  ?t</cell><cell>0.83  ?s</cell></row><row><cell></cell><cell>ResNeXt-A</cell><cell>0.65  ?</cell><cell></cell><cell>0.48</cell><cell>0.86</cell><cell>0.57</cell><cell>0.61</cell><cell>0.80  ?t</cell><cell>0.63 t</cell><cell>0.84  ?t</cell></row><row><cell></cell><cell>ResNeXt-B</cell><cell>0.60  ?</cell><cell></cell><cell>0.60  ?</cell><cell>0.66</cell><cell>0.26</cell><cell>0.30</cell><cell>0.53 t</cell><cell>0.55 t</cell><cell>0.71  ?t</cell></row><row><cell>ImageNet</cell><cell>DARTS</cell><cell>0.66</cell><cell></cell><cell>0.21</cell><cell>-</cell><cell cols="2">0.61 0.75  ?</cell><cell>0.70  ?t</cell><cell>0.84  ?t</cell><cell>0.55 t</cell></row><row><cell></cell><cell>DARTS-f</cell><cell>0.20</cell><cell></cell><cell>0.37</cell><cell>-</cell><cell cols="2">0.68 ? 0.69  ?</cell><cell>0.67 t</cell><cell>0.69  ?t</cell><cell>0.59 t</cell></row><row><cell></cell><cell>Amoeba</cell><cell>0.42</cell><cell></cell><cell>0.25</cell><cell>-</cell><cell cols="2">0.63 0.72  ?</cell><cell>0.73  ?t</cell><cell>0.80  ?t</cell><cell>0.67 t</cell></row><row><cell></cell><cell>ENAS</cell><cell>0.69  ?</cell><cell></cell><cell>0.17</cell><cell>-</cell><cell cols="2">0.59 0.70  ?</cell><cell>0.58 t</cell><cell>0.81  ?t</cell><cell>0.65 t</cell></row><row><cell></cell><cell>NASNet</cell><cell>0.51</cell><cell></cell><cell>0.01</cell><cell>-</cell><cell cols="2">0.52 0.59  ?</cell><cell>0.52 t</cell><cell>0.70  ?t</cell><cell>0.61  ?t</cell></row><row><cell></cell><cell>PNAS</cell><cell>0.60  ?</cell><cell></cell><cell>0.14</cell><cell>-</cell><cell>0.28</cell><cell>0.39</cell><cell>0.45  ?t</cell><cell>0.62  ?t</cell><cell>0.40 t</cell></row><row><cell></cell><cell>ResNeXt-A</cell><cell>0.72</cell><cell></cell><cell>0.42</cell><cell>-</cell><cell cols="2">0.80  ? 0.84  ?</cell><cell>0.75 t</cell><cell>0.62 t</cell><cell>0.87  ?t</cell></row><row><cell></cell><cell>ResNeXt-B</cell><cell>0.63</cell><cell></cell><cell>0.31</cell><cell>-</cell><cell cols="2">0.71  ? 0.79  ?</cell><cell>0.51 t</cell><cell>0.60 t</cell><cell>0.64  ?t</cell></row><row><cell cols="2">NASBench-NLP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Dataset grad_norm snip grasp synflow jacob_cov</cell><cell cols="2">ppl@ep3</cell><cell></cell><cell>GenNAS</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">&gt; 192? slower single combo search</cell></row><row><cell>PTB</cell><cell>0.21</cell><cell cols="2">0.19 0.16</cell><cell>0.34</cell><cell>0.56  ?</cell><cell></cell><cell>0.79</cell><cell cols="3">0.73 0.74  ? 0.81  ?s</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>GenNAS end-to-end NAS results comparing with the state-of-the-art NAS approaches, showing test accuracy (%) on different NAS-spaces and datasets. denotes a method that is replicated with the same regularized evolutionary algorithm in Section 4.4 for fair comparison. On NASBench-201, the GPU hours do not include task search since GenNAS-N is transferred from NASBench-101. The values with superscripts are obtained after task search ( s ) or transferred ( t ) from a previous searched task.</figDesc><table><row><cell cols="2">NASBench-101(CIFAR-10)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Optimal</cell><cell>NASWOT</cell><cell>synflow</cell><cell>Halfway</cell><cell>GenNAS-N</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>94.32</cell><cell cols="4">93.30?0.002 91.31?0.02 93.28?0.002 93.92?0.004 s</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">NASBench-201</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell>Optimal</cell><cell>RSPS</cell><cell>DARTS-V2</cell><cell>GDAS</cell><cell>SETN</cell><cell>ENAS</cell><cell>NASWOT</cell><cell>GenNAS-N</cell></row><row><cell>CIFAR-10</cell><cell>94.37</cell><cell cols="2">84.07?3.61 54.30?0.00</cell><cell>93.61?0.09</cell><cell cols="4">87.64?0.00 53.89?0.58 92.96?0.80 94.18?0.10 t</cell></row><row><cell>CIFAR-100</cell><cell>73.49</cell><cell cols="2">58.33?4.34 15.61?0.00</cell><cell>70.61?0.26</cell><cell cols="4">56.87?7.77 15.61?0.00 70.03?1.16 72.56?0.74 t</cell></row><row><cell>ImgNet16</cell><cell>47.31</cell><cell cols="2">26.28?3.09 16.32?0.00</cell><cell>41.71?0.98</cell><cell cols="4">32.52?0.21 14.84?2.10 44.43?2.07 45.59?0.54 t</cell></row><row><cell>GPU hours</cell><cell></cell><cell>2.2</cell><cell>9.9</cell><cell>8.8</cell><cell>9.5</cell><cell>3.9</cell><cell>0.1</cell><cell>0.3</cell></row><row><cell cols="3">Neural Design Spaces (CIFAR-10)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>NAS-Space</cell><cell>Optimal</cell><cell>NASWOT</cell><cell>synflow</cell><cell>cls@ep10</cell><cell cols="3">GenNAS-N GenNAS-R GenNAS-D</cell><cell></cell></row><row><cell>ResNet</cell><cell>95.30</cell><cell cols="2">92.81?0.10 93.52?0.31</cell><cell cols="4">94.51?0.20 94.48?0.24 t 94.63?0.23 t 94.77?0.13 s</cell><cell></cell></row><row><cell>ResNeXt-A</cell><cell>94.99</cell><cell cols="2">93.39?0.67 94.05?0.48</cell><cell cols="4">94.24? 0.22 94.25?0.21 t 94.12?0.20 t 94.37?0.14 t</cell><cell></cell></row><row><cell>ResNeXt-B</cell><cell>95.12</cell><cell cols="2">93.56?0.33 93.65?0.64</cell><cell cols="2">94.33?0.26 94.29?0.24</cell><cell></cell><cell></cell><cell></cell></row></table><note>t 94.26?0.35 t 94.23?0.32t NDS ResNet search space, respectively. We study the performance and transferability of the searched tasks on all NAS search spaces. Proxy task search is done on a single GPU GTX 1080Ti. On NASBench-101 (GenNAS-N), ResNeXt (GenNAS-R), and DARTS (GenNAS-D), the search time is 5.75, 4, and 12.25 GPU hours, respectively. Once the proxy tasks is searched, it can be used to evaluate any architectures in the target search space and can be transferred to other search spaces.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparisons with state-of-the-art NAS methods on ImageNet under the mobile setting. * is the time for proxy task search.</figDesc><table><row><cell>Method</cell><cell cols="2">Test Err. (%) top-1 top-5</cell><cell>Params (M)</cell><cell>FLOPS(M) (M)</cell><cell>Search Cost (GPU days)</cell><cell>Searched Method</cell><cell>Searched dataset</cell></row><row><cell>NASNet-A [18]</cell><cell>26.0</cell><cell>8.4</cell><cell>5.3</cell><cell>564</cell><cell>2000</cell><cell>RL</cell><cell>CIFAR-10</cell></row><row><cell>AmoebaNet-C [1]</cell><cell>24.3</cell><cell>7.6</cell><cell>6.4</cell><cell>570</cell><cell>3150</cell><cell>evolution</cell><cell>CIFAR-10</cell></row><row><cell>PNAS [63]</cell><cell>25.8</cell><cell>8.1</cell><cell>5.1</cell><cell>588</cell><cell>225</cell><cell>SMBO</cell><cell>CIFAR-10</cell></row><row><cell>DARTS(2nd order) [3]</cell><cell>26.7</cell><cell>8.7</cell><cell>4.7</cell><cell>574</cell><cell>4.0</cell><cell>gradient-based</cell><cell>CIFAR-10</cell></row><row><cell>SNAS [64]</cell><cell>27.3</cell><cell>9.2</cell><cell>4.3</cell><cell>522</cell><cell>1.5</cell><cell>gradient-based</cell><cell>CIFAR-10</cell></row><row><cell>GDAS [58]</cell><cell>26.0</cell><cell>8.5</cell><cell>5.3</cell><cell>581</cell><cell>0.21</cell><cell>gradient-based</cell><cell>CIFAR-10</cell></row><row><cell>P-DARTS [65]</cell><cell>24.4</cell><cell>7.4</cell><cell>4.9</cell><cell>557</cell><cell>0.3</cell><cell>gradient-based</cell><cell>CIFAR-10</cell></row><row><cell>P-DARTS</cell><cell>24.7</cell><cell>7.5</cell><cell>5.1</cell><cell>577</cell><cell>0.3</cell><cell>gradient-based</cell><cell>CIFAR-100</cell></row><row><cell>PC-DARTS [32]</cell><cell>25.1</cell><cell>7.8</cell><cell>5.3</cell><cell>586</cell><cell>0.1</cell><cell>gradient-based</cell><cell>CIFAR-10</cell></row><row><cell>TE-NAS [62]</cell><cell>26.2</cell><cell>8.3</cell><cell>6.3</cell><cell>-</cell><cell>0.05</cell><cell>training-free</cell><cell>CIFAR-10</cell></row><row><cell>PC-DARTS</cell><cell>24.2</cell><cell>7.3</cell><cell>5.3</cell><cell>597</cell><cell>3.8</cell><cell>gradient-based</cell><cell>ImageNet</cell></row><row><cell>ProxylessNAS [4]</cell><cell>24.9</cell><cell>7.5</cell><cell>7.1</cell><cell>465</cell><cell>8.3</cell><cell>gradient-based</cell><cell>ImageNet</cell></row><row><cell>UNNAS-jig [43]</cell><cell>24.1</cell><cell>-</cell><cell>5.2</cell><cell>567</cell><cell>2</cell><cell>gradient-based</cell><cell>ImageNet</cell></row><row><cell>TE-NAS</cell><cell>24.5</cell><cell>7.5</cell><cell>5.4</cell><cell>599</cell><cell>0.17</cell><cell>training-free</cell><cell>ImageNet</cell></row><row><cell>GenNAS-combo</cell><cell>25.1</cell><cell>7.8</cell><cell>4.8</cell><cell>559</cell><cell>0.04</cell><cell>evolution+few-shot</cell><cell>CIFAR-10</cell></row><row><cell>GenNAS-D14</cell><cell>24.3</cell><cell>7.2</cell><cell>5.3</cell><cell>599</cell><cell>0.7  *  +0.04</cell><cell>evolution+few-shot</cell><cell>CIFAR-10</cell></row></table><note>according to the prediction by the moment, and L = 4.36 is the lowest testing log perplexity in the whole dataset achieved by LSTM [50] architecture.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, highperformance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch?-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 8024-8035. Curran Associates, Inc., 2019.</figDesc><table><row><cell>A Appendix</cell></row><row><cell>A.1 NAS Search Spaces</cell></row><row><cell>NASBench-101 1 introduces a large and expressive search space with 423k unique convolutional</cell></row><row><cell>neural architectures and training statistics on CIFAR-10. NASBench-201 2 contains the training</cell></row><row><cell>statistics of 15,625 architectures across three different datasets, including CIFAR-10, CIFAR-100,</cell></row><row><cell>and Tiny-ImageNet-16. Network Design Spaces (NDS) dataset 3 [56] with PYCLS [67] codebase 4</cell></row><row><cell>provides trained neural networks from 11 search spaces including DARTS [3], AmoebaNet [1],</cell></row><row><cell>ENAS</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Ranking correlation (Spearman's ?) analysis of different 10 seeds across three different search spaces with the searched tasks on them respectively. For the NASBench-101, the 500 architecture samples<ref type="bibr" target="#b42">[43]</ref> are constantly used for evaluation. For DARTS and ResNet search spaces, 1000 samples are randomly sampled with different seeds from the evaluated architecture sets provided by NDS<ref type="bibr" target="#b55">[56]</ref>.</figDesc><table><row><cell>Search Space</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>Average</cell></row><row><cell>NASBench-101</cell><cell>0.880</cell><cell>0.850</cell><cell>0.875</cell><cell>0.869</cell><cell>0.872</cell><cell>0.874</cell><cell>0.877</cell><cell>0.863</cell><cell>0.872</cell><cell>0.872</cell><cell>0.870?0.008</cell></row><row><cell>DARTS</cell><cell>0.809</cell><cell>0.899</cell><cell>0.861</cell><cell>0.831</cell><cell>0.841</cell><cell>0.836</cell><cell>0.851</cell><cell>0.841</cell><cell>0.885</cell><cell>0.861</cell><cell>0.850?0.025</cell></row><row><cell>ResNet</cell><cell>0.860</cell><cell>0.853</cell><cell>0.841</cell><cell>0.810</cell><cell>0.865</cell><cell>0.877</cell><cell>0.874</cell><cell>0.804</cell><cell>0.808</cell><cell>0.803</cell><cell>0.840?0.029</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Ranking correlation (Spearman's ?) analysis of 10 searched tasks on NASBench-101 with different initialization methods.</figDesc><table><row><cell>Weight init</cell><cell>Bias init</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>Average</cell></row><row><cell>Default</cell><cell>Default</cell><cell>0.835</cell><cell>0.860</cell><cell>0.860</cell><cell>0.878</cell><cell>0.835</cell><cell>0.810</cell><cell>0.859</cell><cell>0.832</cell><cell>0.816</cell><cell>0.828</cell><cell>0.841?0.021</cell></row><row><cell>Kaiming</cell><cell>Default</cell><cell>0.844</cell><cell>0.854</cell><cell>0.857</cell><cell>0.856</cell><cell>0.832</cell><cell>0.818</cell><cell>0.854</cell><cell>0.746</cell><cell>0.829</cell><cell>0.811</cell><cell>0.830?0.032</cell></row><row><cell>Xavier</cell><cell>Default</cell><cell>0.856</cell><cell>0.881</cell><cell>0.863</cell><cell>0.874</cell><cell>0.849</cell><cell>0.825</cell><cell>0.865</cell><cell>0.830</cell><cell>0.838</cell><cell>0.851</cell><cell>0.853?0.018</cell></row><row><cell>Default</cell><cell>Zero</cell><cell>0.867</cell><cell>0.882</cell><cell>0.854</cell><cell>0.880</cell><cell>0.848</cell><cell>0.847</cell><cell>0.874</cell><cell>0.808</cell><cell>0.848</cell><cell>0.850</cell><cell>0.856?0.021</cell></row><row><cell>Kaiming</cell><cell>Zero</cell><cell>0.845</cell><cell>0.842</cell><cell>0.856</cell><cell>0.861</cell><cell>0.828</cell><cell>0.821</cell><cell>0.846</cell><cell>0.770</cell><cell>0.823</cell><cell>0.823</cell><cell>0.831?0.025</cell></row><row><cell>Xavier</cell><cell>Zero</cell><cell>0.859</cell><cell>0.876</cell><cell>0.869</cell><cell>0.879</cell><cell>0.839</cell><cell>0.842</cell><cell>0.861</cell><cell>0.828</cell><cell>0.846</cell><cell>0.843</cell><cell>0.854?0.016</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>GenNAS' ranking correlation evaluation comparing with other efficient NAS approaches using the Kendall ? .</figDesc><table><row><cell></cell><cell cols="3">NASBench-101</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Dataset</cell><cell cols="3">NASWOT synflow</cell><cell cols="2">GenNAS</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>[37]</cell><cell cols="5">[31] single combo search-N</cell></row><row><cell></cell><cell cols="2">CIFAR-10</cell><cell>0.27</cell><cell>0.24</cell><cell>0.59</cell><cell>0.66</cell><cell>0.7</cell><cell></cell></row><row><cell></cell><cell cols="2">ImgNet</cell><cell>0.36</cell><cell>0.14</cell><cell>0.47</cell><cell>0.54</cell><cell>0.53</cell><cell></cell></row><row><cell cols="2">NASBench-201</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell cols="6">NASWOT synflow jacob_cov snip EcoNAS</cell><cell cols="2">GenNAS</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[26]</cell><cell cols="3">single combo search-N</cell></row><row><cell cols="2">CIFAR-10</cell><cell>0.6</cell><cell>0.52</cell><cell>0.59</cell><cell>0.41</cell><cell>0.62</cell><cell>0.57</cell><cell>0.67</cell><cell>0.71</cell></row><row><cell cols="2">CIFAR-100</cell><cell>0.63</cell><cell>0.57</cell><cell>0.53</cell><cell>0.46</cell><cell>0.57</cell><cell>0.52</cell><cell>0.63</cell><cell>0.65</cell></row><row><cell>ImgNet16</cell><cell></cell><cell>0.6</cell><cell>0.54</cell><cell>0.56</cell><cell>0.44</cell><cell>0.57</cell><cell>0.53</cell><cell>0.61</cell><cell>0.67</cell></row><row><cell cols="3">Neural Design Spaces</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell cols="4">NAS-Space NASWOT synflow</cell><cell></cell><cell></cell><cell>GenNAS</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">single combo search-N search-D search-R</cell></row><row><cell>CIFAR-10</cell><cell cols="2">DARTS</cell><cell>0.48</cell><cell>0.3</cell><cell>0.3</cell><cell>0.45</cell><cell>0.52</cell><cell>0.68</cell><cell>0.63</cell></row><row><cell></cell><cell cols="2">DARTS-f</cell><cell>0.21</cell><cell>0.09</cell><cell>0.36</cell><cell>0.43</cell><cell>0.37</cell><cell>0.42</cell><cell>0.36</cell></row><row><cell></cell><cell cols="2">Amoeba</cell><cell>0.21</cell><cell>0.06</cell><cell>0.36</cell><cell>0.47</cell><cell>0.5</cell><cell>0.59</cell><cell>0.53</cell></row><row><cell></cell><cell cols="2">ENAS</cell><cell>0.39</cell><cell>0.13</cell><cell>0.39</cell><cell>0.49</cell><cell>0.48</cell><cell>0.63</cell><cell>0.59</cell></row><row><cell></cell><cell cols="2">ENAS-f</cell><cell>0.31</cell><cell>0.2</cell><cell>0.46</cell><cell>0.55</cell><cell>0.49</cell><cell>0.53</cell><cell>0.48</cell></row><row><cell></cell><cell cols="2">NASNet</cell><cell>0.3</cell><cell>0.02</cell><cell>0.4</cell><cell>0.5</cell><cell>0.47</cell><cell>0.58</cell><cell>0.52</cell></row><row><cell></cell><cell cols="2">PNAS</cell><cell>0.36</cell><cell>0.17</cell><cell>0.22</cell><cell>0.37</cell><cell>0.42</cell><cell>0.57</cell><cell>0.52</cell></row><row><cell></cell><cell cols="2">PNAS-f</cell><cell>0.09</cell><cell>0.18</cell><cell>0.31</cell><cell>0.38</cell><cell>0.39</cell><cell>0.38</cell><cell>0.33</cell></row><row><cell></cell><cell cols="2">ResNet</cell><cell>0.19</cell><cell>0.14</cell><cell>0.23</cell><cell>0.38</cell><cell>0.38</cell><cell>0.38</cell><cell>0.64</cell></row><row><cell cols="3">ResNeXt-A</cell><cell>0.46</cell><cell>0.32</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.45</cell><cell>0.65</cell></row><row><cell></cell><cell cols="2">ResNeXt-B</cell><cell>0.4</cell><cell>0.43</cell><cell>0.17</cell><cell>0.3</cell><cell>0.37</cell><cell>0.38</cell><cell>0.52</cell></row><row><cell>ImageNet</cell><cell cols="2">DARTS</cell><cell>0.49</cell><cell>0.14</cell><cell>0.43</cell><cell>0.52</cell><cell>0.52</cell><cell>0.66</cell><cell>0.48</cell></row><row><cell></cell><cell cols="2">DARTS-f</cell><cell>0.13</cell><cell>0.25</cell><cell>0.49</cell><cell>0.57</cell><cell>0.48</cell><cell>0.51</cell><cell>0.42</cell></row><row><cell></cell><cell cols="2">Amoeba</cell><cell>0.33</cell><cell>0.17</cell><cell>0.46</cell><cell>0.53</cell><cell>0.55</cell><cell>0.62</cell><cell>0.5</cell></row><row><cell></cell><cell cols="2">ENAS</cell><cell>0.51</cell><cell>0.12</cell><cell>0.4</cell><cell>0.47</cell><cell>0.4</cell><cell>0.63</cell><cell>0.48</cell></row><row><cell></cell><cell cols="2">NASNet</cell><cell>0.39</cell><cell>0.01</cell><cell>0.36</cell><cell>0.42</cell><cell>0.37</cell><cell>0.5</cell><cell>0.43</cell></row><row><cell></cell><cell cols="2">PNAS</cell><cell>0.45</cell><cell>0.11</cell><cell>0.19</cell><cell>0.27</cell><cell>0.31</cell><cell>0.45</cell><cell>0.3</cell></row><row><cell cols="3">ResNeXt-A</cell><cell>0.52</cell><cell>0.28</cell><cell>0.61</cell><cell>0.7</cell><cell>0.56</cell><cell>0.44</cell><cell>0.69</cell></row><row><cell></cell><cell cols="2">ResNeXt-B</cell><cell>0.45</cell><cell>0.21</cell><cell>0.53</cell><cell>0.65</cell><cell>0.39</cell><cell>0.43</cell><cell>0.67</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">NASBench-NLP</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Dataset</cell><cell cols="2">GenNAS</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">single combo search</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>PTB</cell><cell>0.43</cell><cell>0.55</cell><cell>0.63</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>GenNAS' retrieving rate@top10% comparing with other efficient NAS approaches. For the NASBench-101 we use the set of 500 architectures that sampled by Liu, et al.<ref type="bibr" target="#b42">[43]</ref> for obtaining the ImageNet groundtruth.</figDesc><table><row><cell></cell><cell cols="3">NASBench-101</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">Dataset</cell><cell cols="4">number NASWOT synflow</cell><cell></cell><cell cols="3">GenNAS</cell></row><row><cell></cell><cell></cell><cell></cell><cell>of samples</cell><cell>[37]</cell><cell cols="6">[31] single combo search-N</cell></row><row><cell></cell><cell cols="2">CIFAR-10</cell><cell>500</cell><cell>32%</cell><cell cols="2">28%</cell><cell cols="2">58%</cell><cell>64%</cell><cell>68%</cell></row><row><cell></cell><cell cols="2">ImgNet</cell><cell>500</cell><cell>36%</cell><cell cols="2">14%</cell><cell cols="2">52%</cell><cell>54%</cell><cell>64%</cell></row><row><cell cols="2">NASBench-201</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell cols="9">number NASWOT synflow jacob_cov snip EcoNAS</cell><cell>GenNAS</cell></row><row><cell></cell><cell cols="2">of samples</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">[26]</cell><cell>single combo search-N</cell></row><row><cell>CIFAR-10</cell><cell>1000</cell><cell></cell><cell>43%</cell><cell>48%</cell><cell>27%</cell><cell cols="2">27%</cell><cell cols="2">52%</cell><cell>43%</cell><cell>36%</cell><cell>53%</cell></row><row><cell>CIFAR-100</cell><cell>1000</cell><cell></cell><cell>48%</cell><cell>47%</cell><cell>23%</cell><cell cols="2">36%</cell><cell cols="2">47%</cell><cell>46%</cell><cell>46%</cell><cell>58%</cell></row><row><cell>ImgNet16</cell><cell>1000</cell><cell></cell><cell>49%</cell><cell>43%</cell><cell>33%</cell><cell cols="2">32%</cell><cell cols="2">41%</cell><cell>48%</cell><cell>40%</cell><cell>51%</cell></row><row><cell cols="2">Neural Design Spaces</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell cols="5">number NAS-Space NASWOT synflow</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>GenNAS</cell></row><row><cell cols="2">of samples</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">single combo search-N search-D search-R</cell></row><row><cell>CIFAR-10</cell><cell>1000</cell><cell cols="2">DARTS</cell><cell>29%</cell><cell>10%</cell><cell cols="2">16%</cell><cell cols="2">43%</cell><cell>45%</cell><cell>59%</cell><cell>49%</cell></row><row><cell></cell><cell>1000</cell><cell cols="2">DARTS-f</cell><cell>1%</cell><cell>5%</cell><cell cols="4">22% 33%</cell><cell>18%</cell><cell>22%</cell><cell>23%</cell></row><row><cell></cell><cell>1000</cell><cell cols="2">Amoeba</cell><cell>20%</cell><cell>4%</cell><cell cols="2">20%</cell><cell cols="2">39%</cell><cell>45%</cell><cell>50%</cell><cell>40%</cell></row><row><cell></cell><cell>1000</cell><cell cols="2">ENAS</cell><cell>31%</cell><cell>6%</cell><cell cols="2">25%</cell><cell cols="2">48%</cell><cell>41%</cell><cell>57%</cell><cell>48%</cell></row><row><cell></cell><cell>1000</cell><cell cols="2">ENAS-f</cell><cell>28%</cell><cell>2%</cell><cell cols="4">34% 45%</cell><cell>42%</cell><cell>38%</cell><cell>37%</cell></row><row><cell></cell><cell>1000</cell><cell cols="2">NASNet</cell><cell>33%</cell><cell>7%</cell><cell cols="2">27%</cell><cell cols="2">38%</cell><cell>46%</cell><cell>52%</cell><cell>43%</cell></row><row><cell></cell><cell>1000</cell><cell cols="2">PNAS</cell><cell>24%</cell><cell>9%</cell><cell cols="2">21%</cell><cell cols="2">39%</cell><cell>46%</cell><cell>44%</cell><cell>37%</cell></row><row><cell></cell><cell>1000</cell><cell cols="2">PNAS-f</cell><cell>6%</cell><cell>4%</cell><cell cols="2">21%</cell><cell cols="2">27%</cell><cell>31%</cell><cell>25%</cell><cell>22%</cell></row><row><cell></cell><cell>1000</cell><cell cols="2">ResNet</cell><cell>7%</cell><cell>4%</cell><cell cols="2">38%</cell><cell cols="2">44%</cell><cell>38%</cell><cell>54%</cell><cell>64%</cell></row><row><cell></cell><cell>1000</cell><cell cols="2">ResNeXt-A</cell><cell>28%</cell><cell>25%</cell><cell cols="4">25% 61%</cell><cell>53%</cell><cell>52%</cell><cell>58%</cell></row><row><cell></cell><cell>1000</cell><cell cols="2">ResNeXt-B</cell><cell>21%</cell><cell>30%</cell><cell cols="2">10%</cell><cell cols="2">13%</cell><cell>36%</cell><cell>40%</cell><cell>71%</cell></row><row><cell>ImageNet</cell><cell>121</cell><cell cols="2">DARTS</cell><cell>17%</cell><cell>0%</cell><cell cols="2">50%</cell><cell cols="2">58%</cell><cell>55%</cell><cell>58%</cell><cell>18%</cell></row><row><cell></cell><cell>499</cell><cell cols="2">DARTS-f</cell><cell>8%</cell><cell>4%</cell><cell cols="2">33%</cell><cell cols="2">27%</cell><cell>35%</cell><cell>39%</cell><cell>24%</cell></row><row><cell></cell><cell>124</cell><cell cols="2">Amoeba</cell><cell>33%</cell><cell>0%</cell><cell cols="2">50%</cell><cell cols="2">42%</cell><cell>58%</cell><cell>58%</cell><cell>41%</cell></row><row><cell></cell><cell>117</cell><cell cols="2">ENAS</cell><cell>36%</cell><cell>9%</cell><cell cols="2">18%</cell><cell cols="2">18%</cell><cell>45%</cell><cell>55%</cell><cell>45%</cell></row><row><cell></cell><cell>122</cell><cell cols="2">NASNet</cell><cell>33%</cell><cell>0%</cell><cell cols="4">42% 50%</cell><cell>42%</cell><cell>33%</cell><cell>33%</cell></row><row><cell></cell><cell>119</cell><cell cols="2">PNAS</cell><cell>10%</cell><cell>9%</cell><cell cols="2">45%</cell><cell cols="2">36%</cell><cell>45%</cell><cell>55%</cell><cell>9%</cell></row><row><cell></cell><cell>130</cell><cell cols="2">ResNeXt-A</cell><cell>31%</cell><cell>8%</cell><cell cols="2">67%</cell><cell cols="2">67%</cell><cell>50%</cell><cell>33%</cell><cell>75%</cell></row><row><cell></cell><cell>164</cell><cell cols="2">ResNeXt-B</cell><cell>38%</cell><cell>13%</cell><cell cols="2">38%</cell><cell cols="2">50%</cell><cell>33%</cell><cell>38%</cell><cell>64%</cell></row><row><cell cols="3">NASBench-NLP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Dataset number</cell><cell cols="6">grad norm snip grasp fisher synflow</cell><cell></cell><cell>GenNAS</cell></row><row><cell></cell><cell cols="2">of samples</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">single combo search</cell></row><row><cell>PTB</cell><cell cols="2">1000</cell><cell cols="2">10% 10% 4%</cell><cell>-</cell><cell>22%</cell><cell></cell><cell>38%</cell><cell cols="2">38%</cell><cell>47%</cell><cell>63%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Retrieving rate@top5%-top50% of GenNAS-combo/N on 1000 randomly sampled architectures on NASBench-101.</figDesc><table><row><cell>Method</cell><cell cols="6">@top5% @top10% @top20% @top30% @top40% @top50%</cell></row><row><cell>GenNAS-combo</cell><cell>0.6</cell><cell>0.6</cell><cell>0.73</cell><cell>0.74</cell><cell>0.79</cell><cell>0.82</cell></row><row><cell>GenNAS-N</cell><cell>0.56</cell><cell>0.58</cell><cell>0.66</cell><cell>0.76</cell><cell>0.80</cell><cell>0.85</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/google-research/nasbench 2 https://github.com/D-X-Y/NAS-Bench-201 3 https://github.com/facebookresearch/nds 4 https://github.com/facebookresearch/pycls 5 https://github.com/fmsnew/nas-bench-nlp-release</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgement</head><p>We thank IBM-Illinois Center for Cognitive Computing Systems Research (C3SR) for supporting this research. We thank all reviewers and the area chair for valuable discussions and feedback. This work utilizes resources <ref type="bibr" target="#b65">[66]</ref> supported by the National Science Foundation's Major Research Instrumentation program, grant #1725729, as well as the University of Illinois at Urbana-Champaign. P.L. is also partly supported by the 2021 JP Morgan Faculty Award and the National Science Foundation award HDR-2117997.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the aaai conference on artificial intelligence</title>
		<meeting>the aaai conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4780" to="4789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01578</idno>
		<title level="m">Neural architecture search with reinforcement learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.09055</idno>
		<title level="m">Darts: Differentiable architecture search</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.00332</idno>
		<title level="m">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.13700</idno>
		<title level="m">Vision transformer architecture search</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Auto-deeplab: Hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="82" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast neural architecture search of compact semantic segmentation models via auxiliary cells</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Nekrasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9126" to="9135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Squeezenas: Fast neural architecture search for faster semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Forrest</forename><surname>Landola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sammy</forename><surname>Sidhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Bossnas: Exploring hybrid cnn-transformers with block-wisely self-supervised neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changlin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangrun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiefeng</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12424</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Hat: Hardware-aware transformers for efficient natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanrui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14187</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The evolved transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5877" to="5886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep neural network model and fpga accelerator co-design: Opportunities and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deming</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IEEE International Conference on Solid-State and Integrated Circuit Technology (ICSICT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="4" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Fpga/dnn co-design: An efficient design methodology for 1ot intelligence on the edge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sitao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Rupnow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Mei</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deming</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 56th ACM/IEEE Design Automation Conference (DAC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Skynet: a hardware-efficient method for object detection and tracking on embedded systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoming</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Rupnow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.09709</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.10319</idno>
		<title level="m">Mcunet: Tiny deep learning on iot devices</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Mcunetv2: Memory-efficient patch-based inference for tiny deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Ming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.15352</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Large-scale evolution of image classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherry</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><forename type="middle">Leon</forename><surname>Suematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kurakin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2902" to="2911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8697" to="8710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Resnetcrowd: A residual deep learning architecture for crowd counting, violent behaviour detection and crowd density level classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Marsden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel E O&amp;apos;</forename><surname>Connor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Transfusion: Understanding transfer learning for medical imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.07208</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Support vector machines. IEEE Intelligent Systems and their applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marti</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Susan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgar</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Osuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scholkopf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="18" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Jacot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franck</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cl?ment</forename><surname>Hongler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.07572</idno>
		<title level="m">Neural tangent kernel: Convergence and generalization in neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Applied nonparametric statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Econas: Finding proxies for economical neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongzhan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuesen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11396" to="11404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Fairnas: Rethinking evaluation fairness of weight sharing neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruijun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.01845</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Random search and reproducibility for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameet</forename><surname>Talwalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="367" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Klyuchnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Trofimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Artemova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Salnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeny</forename><surname>Burnaev</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07116</idno>
		<title level="m">Nas-bench-nlp: neural architecture search benchmark for natural language processing</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Nas-bench-101: Towards reproducible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7105" to="7114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Zero-cost proxies for lightweight nas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Mohamed S Abdelfattah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas D</forename><surname>Dudziak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lane</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.08134</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Pc-darts: Partial channel connections for memory-efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.05737</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Edd: Efficient differentiable dnn architecture and implementation co-search for embedded ai solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Mei</forename><surname>Hwu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deming</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 57th ACM/IEEE Design Automation Conference (DAC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Understanding and robustifying differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arber</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yassine</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.09656</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Nas-bench-201: Extending the scope of reproducible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.00326</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Evaluating the search phase of neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaicheng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Sciuto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudiu</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.08142</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Mellor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot J</forename><surname>Crowley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.04647</idno>
		<title level="m">Neural architecture search without training</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Fear: A simple lightweight method to rank architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debadeepta</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shital</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastien</forename><surname>Bubeck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.04010</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Flash: Fast neural architecture search with hardware optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guihong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sumit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Umit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Ogras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Embedded Computing Systems (TECS)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5s</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Nas-bench-301 and the case for surrogate benchmarks for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Siems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Zimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arber</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jovita</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margret</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.09777</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Prioritized architecture sampling with monto-carlo tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shan</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10968" to="10977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Do better imagenet models transfer better?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2661" to="2671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Are labels necessary for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="798" to="813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Self-supervised visual feature learning with deep neural networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longlong</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingli</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Discriminative unsupervised feature learning with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations using videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2794" to="2802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">High-frequency component helps explain the generalization of convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xindi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyi</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8684" to="8694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Recurrent neural network based language model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom??</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Karafi?t</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luk??</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan?ernock?</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eleventh annual conference of the international speech communication association</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Qin John</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyang</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.06523</idno>
		<title level="m">Frequency principle: Fourier analysis sheds light on deep neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Fourier series. Courier Corporation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Georgi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tolstov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The distribution of rademacher sums</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Montgomery-Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the American Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="517" to="522" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">On network design spaces for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilija</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wan-Yen</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1882" to="1890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Building a large annotated corpus of english: The penn treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><forename type="middle">Ann</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Searching for a robust neural architecture in four gpu hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1761" to="1770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">One-shot neural architecture search via self-evaluated template network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3681" to="3690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameters sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melody</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4095" to="4104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Imagenet: A largescale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.11535</idno>
		<title level="m">Neural architecture search on imagenet in four gpu hours: A theoretically inspired perspective</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Progressive neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="19" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.09926</idno>
		<title level="m">Snas: stochastic neural architecture search</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1294" to="1303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Hal: Computer system for scalable deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Kindratenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Maloney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sayed Hadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gropp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Practice and Experience in Advanced Research Computing</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Designing network design spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilija</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><forename type="middle">Prateek</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">A comparative analysis of selection schemes used in genetic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalyanmoy</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations of genetic algorithms</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1991" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="69" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Renas: Reinforced evolutionary neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiming</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisen</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4787" to="4796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annamalai</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahinthan</forename><surname>Chandramohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajasekar</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shantanu</forename><surname>Jaiswal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.05005</idno>
		<title level="m">Learning distributed representations of graphs</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth international conference on artificial intelligence and statistics</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
	<note>JMLR Workshop and Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A new measure of rank correlation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Maurice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1/2</biblScope>
			<biblScope unit="page" from="81" to="93" />
			<date type="published" when="1938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">16</biblScope>
			<pubPlace>Martin Raison, Alykhan Tejani, Sasank Chilamkurthy</pubPlace>
		</imprint>
	</monogr>
	<note>Search Space B-size</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>B-Size</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>B-Size</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">48</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>B-Size</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">64</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>B-Size</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">80</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>B-Size</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">96</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
