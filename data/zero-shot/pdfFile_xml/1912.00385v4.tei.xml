<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Group Loss for Deep Metric Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Elezi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ca&apos; Foscari</orgName>
								<orgName type="institution">University of Venice</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastiano</forename><surname>Vascon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ca&apos; Foscari</orgName>
								<orgName type="institution">University of Venice</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Torcinovich</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ca&apos; Foscari</orgName>
								<orgName type="institution">University of Venice</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Pelillo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Ca&apos; Foscari</orgName>
								<orgName type="institution">University of Venice</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taix?</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Technical University of Munich</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The Group Loss for Deep Metric Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Deep Metric Learning</term>
					<term>Image Retrieval</term>
					<term>Image Clustering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep metric learning has yielded impressive results in tasks such as clustering and image retrieval by leveraging neural networks to obtain highly discriminative feature embeddings, which can be used to group samples into different classes. Much research has been devoted to the design of smart loss functions or data mining strategies for training such networks. Most methods consider only pairs or triplets of samples within a mini-batch to compute the loss function, which is commonly based on the distance between embeddings. We propose Group Loss, a loss function based on a differentiable label-propagation method that enforces embedding similarity across all samples of a group while promoting, at the same time, low-density regions amongst data points belonging to different groups. Guided by the smoothness assumption that "similar objects should belong to the same group", the proposed loss trains the neural network for a classification task, enforcing a consistent labelling amongst samples within a class. We show state-of-the-art results on clustering and image retrieval on several datasets, and show the potential of our method when combined with other techniques such as ensembles. To facilitate further research, we make available the code and the models at https://github.com/dvl-tum/group_loss.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Measuring object similarity is at the core of many important machine learning problems like clustering and object retrieval. For visual tasks, this means learning a distance function over images. With the rise of deep neural networks, the focus has rather shifted towards learning a feature embedding that is easily separable using a simple distance function, such as the Euclidean distance. In essence, objects of the same class (similar) should be close by in the learned manifold, while objects of a different class (dissimilar) should be far away.</p><p>Historically, the best performing approaches get deep feature embeddings from the so-called siamese networks <ref type="bibr" target="#b3">[4]</ref>, which are typically trained using the contrastive loss <ref type="bibr" target="#b3">[4]</ref> or the triplet loss <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b52">53]</ref>. A clear drawback of these losses is that they only consider pairs or triplets of data points, missing key information about the relationships between all members of the mini-batch. On a mini-batch of size n, despite that the number of pairwise relations between samples is O(n 2 ), contrastive loss uses only O(n/2) pairwise relations, while triplet loss uses O(2n/3) relations. Additionally, these methods consider only the relations between objects of the same class (positives) and objects of other classes (negatives), without making any distinction that negatives belong to different classes. This leads to not taking into consideration the global structure of the embedding space, and consequently results in lower clustering and retrieval performance. To compensate for that, researchers rely on other tricks to train neural networks for deep metric learning: intelligent sampling <ref type="bibr" target="#b24">[25]</ref>, multi-task learning <ref type="bibr" target="#b58">[59]</ref> or hard-negative mining <ref type="bibr" target="#b39">[40]</ref>. Recently, researchers have been increasingly working towards exploiting in a principled way the global structure of the embedding space <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b49">50]</ref>, typically by designing ranking loss functions instead of following the classic triplet formulations.</p><p>In a similar spirit, we propose Group Loss, a novel loss function for deep metric learning that considers the similarity between all samples in a mini-batch. To create the mini-batch, we sample from a fixed number of classes, with samples coming from a class forming a group. Thus, each mini-batch consists of several randomly chosen groups, and each group has a fixed number of samples. An iterative, fully-differentiable label propagation algorithm is then used to build feature embeddings which are similar for samples belonging to the same group, and dissimilar otherwise.</p><p>At the core of our method lies an iterative process called replicator dynamics <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b8">9]</ref>, that refines the local information, given by the softmax layer of a neural network, with the global information of the mini-batch given by the similarity between embeddings. The driving rationale is that the more similar two samples are, the more they affect each other in choosing their final label and tend to be grouped together in the same group, while dissimilar samples do not affect each other on their choices. Neural networks optimized with the Group Loss learn to provide similar features for samples belonging to the same class, making clustering and image retrieval easier.</p><p>Our contribution in this work is four-fold:</p><p>-We propose a novel loss function to train neural networks for deep metric embedding that takes into account the local information of the samples, as well as their similarity.</p><p>-We propose a differentiable label-propagation iterative model to embed the similarity computation within backpropagation, allowing end-to-end training with our new loss function.</p><p>-We perform a comprehensive robustness analysis showing the stability of our module with respect to the choice of hyperparameters.</p><p>-We show state-of-the-art qualitative and quantitative results in several standard clustering and retrieval datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Classical metric learning losses. The first attempt at using a neural network for feature embedding was done in the seminal work of Siamese Networks <ref type="bibr" target="#b3">[4]</ref>. A cost function called contrastive loss was designed in such a way as to minimize the distance between pairs of images belonging to the same cluster, and maximize the distance between pairs of images coming from different clusters. In <ref type="bibr" target="#b5">[6]</ref>, researchers used the principle to successfully address the problem of face verification. Another line of research on convex approaches for metric learning led to the triplet loss <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b52">53]</ref>, which was later combined with the expressive power of neural networks <ref type="bibr" target="#b39">[40]</ref>. The main difference from the original Siamese network is that the loss is computed using triplets (an anchor, a positive and a negative data point). The loss is defined to make the distance between features of the anchor and the positive sample smaller than the distance between the anchor and the negative sample. The approach was so successful in the field of face recognition and clustering, that soon many works followed. The majority of works on the Siamese architecture consist of finding better cost functions, resulting in better performances on clustering and retrieval. In <ref type="bibr" target="#b41">[42]</ref>, the authors generalized the concept of triplet by allowing a joint comparison among N ? 1 negative examples instead of just one. <ref type="bibr" target="#b43">[44]</ref> designed an algorithm for taking advantage of the mini-batches during the training process by lifting the vector of pairwise distances within the batch to the matrix of pairwise distances, thus enabling the algorithm to learn feature embedding by optimizing a novel structured pre-diction objective on the lifted problem. The work was later extended in <ref type="bibr" target="#b42">[43]</ref>, proposing a new metric learning scheme based on structured prediction that is designed to optimize a clustering quality metric, i.e., the normalized mutual information <ref type="bibr" target="#b25">[26]</ref>. Better results were achieved on <ref type="bibr" target="#b47">[48]</ref>, where the authors proposed a novel angular loss, which takes angle relationship into account. A very different problem formulation was given by <ref type="bibr" target="#b21">[22]</ref>, where the authors used a spectral clustering-inspired approach to achieve deep embedding. A recent work presents several extensions of the triplet loss that reduce the bias in triplet selection by adaptively correcting the distribution shift on the selected triplets <ref type="bibr" target="#b55">[56]</ref>.</p><p>Sampling and ensemble methods. Knowing that the number of possible triplets is extremely large even for moderately-sized datasets, and having found that the majority of triplets are not informative <ref type="bibr" target="#b39">[40]</ref>, researchers also investigated sampling. In the original triplet loss paper <ref type="bibr" target="#b39">[40]</ref>, it was found that using semi-hard negative mining, the network can be trained to a good performance, but the training is computationally inefficient. The work of <ref type="bibr" target="#b24">[25]</ref> found out that while the majority of research is focused on designing new loss functions, selecting training examples plays an equally important role. The authors proposed a distance-weighted sampling procedure, which selects more informative and stable examples than traditional approaches, achieving excellent results in the process. A similar work was that of <ref type="bibr" target="#b9">[10]</ref> where the authors proposed a hierarchical version of triplet loss that learns the sampling all-together with the feature embedding. The majority of recent works has been focused on complementary research directions such as intelligent sampling <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b53">54]</ref> or ensemble methods <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b56">57]</ref>. As we will show in the experimental section, these can be combined with our novel loss.</p><p>Other related problems. In order to have a focused and concise paper, we mostly discuss methods which tackle image ranking/clustering in standard datasets. Nevertheless, we acknowledge related research on specific applications such as person re-identification or landmark recognition, where researchers are also gravitating towards considering the global structure of the mini-batch. In <ref type="bibr" target="#b11">[12]</ref> the authors propose a new hashing method for learning binary embeddings of data by optimizing Average Precision metric. In <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b12">13]</ref> authors study novel metric learning functions for local descriptor matching on landmark datasets. <ref type="bibr" target="#b4">[5]</ref> designs a novel ranking loss function for the purpose of few-shot learning. Similar works that focus on the global structure have shown impressive results in the field of person re-identification <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b0">1]</ref>.</p><p>Classification-based losses. The authors of <ref type="bibr" target="#b27">[28]</ref> proposed to optimize the triplet loss on a different space of triplets than the original samples, consisting of an anchor data point and similar and dissimilar learned proxy data points. These proxies approximate the original data points so that a triplet loss over the proxies is a tight upper bound of the original loss. The final formulation of the loss is shown to be similar to that of softmax cross-entropy loss, challenging the long-hold belief that classification losses are not suitable for the task of metric learning. Recently, the work of <ref type="bibr" target="#b57">[58]</ref> showed that a carefully tuned normalized softmax cross-entropy loss function combined with a balanced sampling strategy can achieve competitive results. A similar line of research is that of <ref type="bibr" target="#b60">[61]</ref>, where the authors use a combination of normalized-scale layers and Gram-Schmidt optimization to achieve efficient usage of the softmax cross-entropy loss for metric learning. The work of <ref type="bibr" target="#b34">[35]</ref> goes a step further by taking into consideration the similarity between classes. Furthermore, the authors use multiple centers for class, allowing them to reach state-of-the-art results, at a cost of significantly increasing the number of parameters of the model. In contrast, we propose a novel loss that achieves state-of-the-art results without increasing the number of parameters of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Group Loss</head><p>Most loss functions used for deep metric learning <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b24">25]</ref> do not use a classification loss function, e.g., cross-entropy, but rather a loss function based on embedding distances. The rationale behind it, is that what matters for a classification network is that the output is correct, which does not necessarily mean that the embeddings of samples belonging to the same class are similar. Since each sample is classified independently, it is entirely possible that two images of the same class have two distant embeddings that both allow for a correct classification. We argue that a classification loss can still be used for deep metric learning if the decisions do not happen independently for each sample, but rather jointly for a whole group, i.e., the set of images of the same class in a mini-batch. In this way, the method pushes for images belonging to the same class to have similar embeddings. Towards this end, we propose Group Loss, an iterative procedure that uses the global information of the mini-batch to refine the local information provided by the softmax layer of a neural network. This iterative procedure categorizes samples into different groups, and enforces consistent labelling among the samples of a group. While softmax cross-entropy loss judges each sample in isolation, the Group Loss allows us to judge the overall class separation for all samples. In section 3.3, we show the differences between the softmax cross-entropy loss and Group Loss, and highlight the mathematical properties of our new loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of Group Loss</head><p>Given a mini-batch B consisting of n images, consider the problem of assigning a class label ? ? ? = {1, . . . , m} to each image in B. In the remainder of the manuscript, X = (x i? ) represents a n ? m (non-negative) matrix of imagelabel soft assignments. In other words, each row of X represents a probability distribution over the label set ? ( ? x i? = 1 for all i = 1 . . . n).</p><p>Our model consists of the following steps (see also <ref type="figure" target="#fig_1">Fig. 1</ref> and Algorithm 1):</p><p>1 Initialization: Initialize X, the image-label assignment using the softmax outputs of the neural network. Compute the n ? n pairwise similarity matrix W using the neural network embedding.</p><p>2 Refinement: Iteratively, refine X considering the similarities between all the mini-batch images, as encoded in W , as well as their labeling preferences. 3 Loss computation: Compute the cross-entropy loss of the refined probabilities and update the weights of the neural network using backpropagation.</p><p>We now provide a more detailed description of the three steps of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Initialization</head><p>Image-label assignment matrix. The initial assignment matrix denoted X(0), comes from the softmax output of the neural network. We can replace some of the initial assignments in matrix X with one-hot labelings of those samples. We call these randomly chosen samples anchors, as their assignments do not change during the iterative refine process and consequently do not directly affect the loss function. However, by using their correct label instead of the predicted label (coming from the softmax output of the NN), they guide the remaining samples towards their correct label. Similarity matrix. A measure of similarity is computed among all pairs of embeddings (computed via a CNN) in B to generate a similarity matrix W ? R n?n . In this work, we compute the similarity measure using the Pearson's correlation coefficient <ref type="bibr" target="#b32">[33]</ref>:</p><formula xml:id="formula_0">?(i, j) = Cov[?(I i ), ?(I j )] Var[?(I i )]Var[?(I j )]<label>(1)</label></formula><p>for i = j, and set ?(i, i) to 0. The choice of this measure over other options such as cosine layer, Gaussian kernels, or learned similarities, is motivated by the observation that the correlation coefficient uses data standardization, thus providing invariance to scaling and translation -unlike the cosine similarity, which is invariant to scaling only -and it does not require additional hyperparameters, unlike Gaussian kernels <ref type="bibr" target="#b7">[8]</ref>. The fact that a measure of the linear relationship among features provides a good similarity measure can be explained by the fact that the computed features are actually a highly non-linear function of the inputs. Thus, the linear correlation among the embeddings actually captures a non-linear relationship among the original images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Refinement</head><p>In this core step of the proposed algorithm, the initial assignment matrix X(0) is refined in an iterative manner, taking into account the similarity information provided by matrix W . X is updated in accordance with the smoothness assumption, which prescribes that similar objects should share the same label. To this end, let us define the support matrix ? = (? i? ) ? R n?m as </p><formula xml:id="formula_1">? = W X (2)</formula><formula xml:id="formula_2">whose (i, ?)-component ? i? = n j=1 w ij x j?<label>(3)</label></formula><p>represents the support that the current mini-batch gives to the hypothesis that the i-th image in B belongs to class ?. Intuitively, in obedience to the smoothness principle, ? i? is expected to be high if images similar to i are likely to belong to class ?. Given the initial assignment matrix X(0), our algorithm refines it using the following update rule:</p><formula xml:id="formula_3">x i? (t + 1) = x i? (t)? i? (t) m ?=1 x i? (t)? i? (t)<label>(4)</label></formula><p>where the denominator represents a normalization factor which guarantees that the rows of the updated matrix sum up to one. This is known as multi-population replicator dynamics in evolutionary game theory <ref type="bibr" target="#b51">[52]</ref> and is equivalent to nonlinear relaxation labeling processes <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b33">34]</ref>. In matrix notation, the update rule (4) can be written as:</p><formula xml:id="formula_4">X(t + 1) = Q ?1 (t) [X(t) ?(t)]<label>(5)</label></formula><p>where</p><formula xml:id="formula_5">Q(t) = diag([X(t) ?(t)] 1)<label>(6)</label></formula><p>and 1 is the all-one m-dimensional vector. ?(t) = W X(t) as defined in <ref type="formula">(2)</ref>, and denotes the Hadamard (element-wise) matrix product. In other words, the diagonal elements of Q(t) represent the normalization factors in <ref type="bibr" target="#b3">(4)</ref>, which can also be interpreted as the average support that object i obtains from the current mini-batch at iteration t. Intuitively, the motivation behind our update rule is that at each step of the refinement process, for each image i, a label ? will increase its probability x i? if and only if its support ? i? is higher than the average support among all the competing label hypothesis Q ii .</p><p>Thanks to the Baum-Eagon inequality <ref type="bibr" target="#b33">[34]</ref>, it is easy to show that the dynamical system defined by (4) has very nice convergence properties. In particular, it strictly increases at each step the following functional:</p><formula xml:id="formula_6">F (X) = n i=1 n j=1 m ?=1 w ij x i? x j?<label>(7)</label></formula><p>which represents a measure of "consistency" of the assignment matrix X, in accordance to the smoothness assumption (F rewards assignments where highly similar objects are likely to be assigned the same label). In other words:</p><formula xml:id="formula_7">F (X(t + 1)) ? F (X(t))<label>(8)</label></formula><p>with equality if and only if X(t) is a stationary point. Hence, our update rule <ref type="formula" target="#formula_3">(4)</ref> is, in fact, an algorithm for maximizing the functional F over the space of rowstochastic matrices. Note, that this contrasts with classical gradient methods, for which an increase in the objective function is guaranteed only when infinitesimal steps are taken, and determining the optimal step size entails computing higherorder derivatives. Here, instead, the step size is implicit and yet, at each step, the value of the functional increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Loss computation</head><p>Once the labeling assignments converge (or in practice, a maximum number of iterations is reached), we apply the cross-entropy loss to quantify the classification error and backpropagate the gradients. Recall, the refinement procedure is optimized via replicator dynamics, as shown in the previous section. By studying Equation <ref type="formula" target="#formula_4">(5)</ref>, it is straightforward to see that it is composed of fully differentiable operations (matrix-vector and scalar products), and so it can be easily integrated within backpropagation. Although the refining procedure has no parameters to be learned, its gradients can be backpropagated to the previous layers of the neural network, producing, in turn, better embeddings for similarity computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Summary of the Group Loss</head><p>In this section, we proposed the Group Loss function for deep metric learning. During training, the Group Loss works by grouping together similar samples  <ref type="bibr" target="#b6">7</ref> Compute the cross-entropy J(X(T ), y) <ref type="bibr" target="#b7">8</ref> Compute the derivatives ?J/?? via backpropagation, and update the weights ? based on both the similarity between the samples in the mini-batch and the local information of the samples. The similarity between samples is computed by the correlation between the embeddings obtained from a CNN, while the local information is computed with a softmax layer on the same CNN embeddings. Using an iterative procedure, we combine both sources of information and effectively bring together embeddings of samples that belong to the same class.</p><formula xml:id="formula_8">Q(t) = diag([X(t) ?(t)] 1) 6 X(t + 1) = Q ?1 (t) [X(t) ?(t)]</formula><p>During inference, we simply forward pass the images through the neural network to compute their embeddings, which are directly used for image retrieval within a nearest neighbor search scheme. The iterative procedure is not used during inference, thus making the feature extraction as fast as that of any other competing method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we compare the Group Loss with state-of-the-art deep metric learning models on both image retrieval and clustering tasks. Our method achieves state-of-the-art results in three public benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Implementation details</head><p>We use the PyTorch <ref type="bibr" target="#b31">[32]</ref> library for the implementation of the Group Loss. We choose GoogleNet <ref type="bibr" target="#b44">[45]</ref> with batch-normalization <ref type="bibr" target="#b15">[16]</ref> as the backbone feature extraction network. We pretrain the network on ILSVRC 2012-CLS dataset <ref type="bibr" target="#b37">[38]</ref>. For pre-processing, in order to get a fair comparison, we follow the implementation details of <ref type="bibr" target="#b42">[43]</ref>. The inputs are resized to 256?256 pixels, and then randomly cropped to 227 ? 227. Like other methods except for <ref type="bibr" target="#b41">[42]</ref>, we use only a center crop during testing time. We train all networks in the classification task for 10 epochs. We then train the network in the Group Loss task for 60 epochs using Adam optimizer <ref type="bibr" target="#b19">[20]</ref>. After 30 epochs, we lower the learning rate by multiplying it by 0.1. We find the hyperparameters using random search <ref type="bibr" target="#b1">[2]</ref>. We use small mini-batches of size 30 ? 100. As sampling strategy, on each mini-batch, we first randomly sample a fixed number of classes, and then for each of the chosen classes, we sample a fixed number of samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Benchmark datasets</head><p>We perform experiments on 3 publicly available datasets, evaluating our algorithm on both clustering and retrieval metrics. For training and testing, we follow the conventional splitting procedure <ref type="bibr" target="#b43">[44]</ref>.</p><p>CUB-200-2011 <ref type="bibr" target="#b46">[47]</ref> is a dataset containing 200 species of birds with 11, 788 images, where the first 100 species (5, 864 images) are used for training and the remaining 100 species (5, 924 images) are used for testing.</p><p>Cars 196 <ref type="bibr" target="#b20">[21]</ref> dataset is composed of 16, 185 images belonging to 196 classes. We use the first 98 classes (8, 054 images) for training and the other 98 classes (8, 131 images) for testing.</p><p>Stanford Online Products dataset <ref type="bibr" target="#b43">[44]</ref>, contains 22, 634 classes with 120, 053 product images in total, where 11, 318 classes (59, 551 images) are used for training and the remaining 11, 316 classes (60, 502 images) are used for testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation metrics</head><p>Based on the experimental protocol detailed above, we evaluate retrieval performance and clustering quality on data from unseen classes of the 3 aforementioned datasets. For the retrieval task, we calculate the percentage of the testing examples whose K nearest neighbors contain at least one example of the same class. This quantity is also known as Recall@K <ref type="bibr" target="#b16">[17]</ref> and is the most used metric for image retrieval evaluation.</p><p>Similar to all other approaches, we perform clustering using K-means algorithm <ref type="bibr" target="#b23">[24]</ref> on the embedded features. Like in other works, we evaluate the clustering quality using the Normalized Mutual Information measure (NMI) <ref type="bibr" target="#b25">[26]</ref>. The choice of NMI measure is motivated by the fact that it is invariant to label permutation, a desirable property for cluster evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>We now show the results of our model and comparison to state-of-the-art methods. Our main comparison is with other loss functions, e.g., triplet loss. To compare with perpendicular research on intelligent sampling strategies or ensembles, and show the power of the Group Loss, we propose a simple ensemble version of our method. Our ensemble network is built by training l independent neural networks with the same hyperparameter configuration. During inference, their embeddings are concatenated. Note, that this type of ensemble is much simpler than the works of <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b38">39]</ref>, and is given only to show that, when optimized for performance, our method can be extended to ensembles giving higher clustering and retrieval performance than other methods in the literature. Finally, in the interest of space, we only present results for Inception network <ref type="bibr" target="#b44">[45]</ref>,  as this is the most popular backbone for the metric learning task, which enables fair comparison among methods. In supplementary material, we present results for other backbones, and include a discussion about the methods that work by increasing the number of parameters (capacity of the network) <ref type="bibr" target="#b34">[35]</ref>, or use more expressive network architectures.</p><p>Quantitative results Loss comparison. In <ref type="table" target="#tab_2">Table 1</ref> we present the results of our method and compare them with the results of other approaches. On the CUB-200-2011 dataset, we outperform the other approaches by a large margin, with the second-best model (Classification <ref type="bibr" target="#b57">[58]</ref>) having circa 6 percentage points(pp) lower absolute accuracy in Recall@1 metric. On the NMI metric, our method achieves a score of 69.0 which is 2.8pp higher than the second-best method. Similarly, on Cars 196, our method achieves best results on Recall@1, with Classification <ref type="bibr" target="#b57">[58]</ref> coming second with a 4pp lower score. On Stanford Online Products, our method reaches the best results on the Recall@1 metric, around 2pp higher than Classification <ref type="bibr" target="#b57">[58]</ref> and Proxy-NCA <ref type="bibr" target="#b27">[28]</ref>. On the same dataset, when evaluated on the NMI score, our loss outperforms any other method, be those methods that exploit advanced sampling, or ensemble methods. Loss with ensembles. In     In <ref type="figure" target="#fig_2">Fig. 3</ref> we present qualitative results on the retrieval task in all three datasets. In all cases, the query image is given on the left, with the four nearest neighbors given on the right. Green boxes indicate the cases where the retrieved image is of the same class as the query image, and red boxes indicate a different class. As we can see, our model is able to perform well even in cases where the images suffer from occlusion and rotation. On the Cars 196 dataset, we see a successful retrieval even when the query image is taken indoors and the retrieved image outdoors, and vice-versa. The first example of Cars 196 dataset is of particular interest. Despite that the query image contains 2 cars, its four nearest neighbors have the same class as the query image, showing the robustness of the algorithm to uncommon input image configurations. We provide the results of t-SNE <ref type="bibr" target="#b22">[23]</ref> projection in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Robustness analysis</head><p>Number of anchors. In <ref type="figure" target="#fig_3">Fig. 4</ref>, we show the effect of the number of anchors with respect to the number of samples per class. We do the analysis on CUB-200-2011 dataset and give a similar analysis for CARS dataset in the supplementary material. The results reported are the percentage point differences in terms of  Recall@1 with respect to the best performing set of parameters (see Recall@1 = 64.3 in Tab. 1). The number of anchors ranges from 0 to 4, while the number of samples per class varies from 5 to 10. It is worth noting that our best setting considers 1 or 2 anchors over 9 samples. Moreover, even when we do not use any anchor, the difference in Recall@1 is no more than 2pp. Number of classes per mini-batch. In <ref type="figure" target="#fig_4">Fig. 5</ref>, we present the change in Recall@1 on the CUB-200-2011 dataset if we increase the number of classes we sample at each iteration. The best results are reached when the number of classes is not too large. This is a welcome property, as we are able to train on small mini-batches, known to achieve better generalization performance <ref type="bibr" target="#b17">[18]</ref>.</p><p>Convergence rate. In <ref type="figure" target="#fig_5">Fig. 6</ref>, we present the convergence rate of the model on the Cars 196 dataset. Within the first 30 epochs, our model achieves stateof-the-art results, making our model significantly faster than other approaches. The other models except Proxy-NCA <ref type="bibr" target="#b27">[28]</ref>, need hundreds of epochs to converge.</p><p>Implicit regularization and less overfitting. In <ref type="figure" target="#fig_6">Figures 7 and 8</ref>, we compare the results of training vs. testing on Cars 196 <ref type="bibr" target="#b20">[21]</ref> and Stanford Online Products <ref type="bibr" target="#b43">[44]</ref> datasets. We see that the difference between Recall@1 at train and test time is small, especially on Stanford Online Products dataset. On Cars 196 the best results we get for the training set are circa 93% in the Recall@1 measure, only 7.5 percentage points (pp) better than what we reach in the testing set. From the works we compared the results with, the only one which reports the results on the training set is <ref type="bibr" target="#b21">[22]</ref>. They reported results of over 90% in all three datasets (for the training sets), much above the test set accuracy which lies at 73.1% on Cars 196 and 67.6% on Stanford Online Products dataset. <ref type="bibr" target="#b45">[46]</ref> also provides results, but it uses a different network.  We further implement the P-NCA <ref type="bibr" target="#b27">[28]</ref> loss function and perform a similar experiment, in order to be able to compare training and test accuracies directly with our method. In <ref type="figure" target="#fig_6">Figure 7</ref>, we show the training and testing curves of P-NCA on the Cars 196 <ref type="bibr" target="#b20">[21]</ref> dataset. We see that while in the training set, P-NCA reaches results of 3pp higher than our method, in the testing set, our method outperforms P-NCA by around 10pp. Unfortunately, we were unable to reproduce the results of the paper <ref type="bibr" target="#b27">[28]</ref> on Stanford Online Products dataset. Furthermore, even when we turn off L2-regularization, the generalization performance of our method does not drop at all. Our intuition is that by taking into account the structure of the entire manifold of the dataset, our method introduces a form of regularization. We can clearly see a smaller gap between training and test results when compared to competing methods, indicating less overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>In this work, we propose the Group Loss, a novel loss function for metric learning. By considering the content of a mini-batch, it promotes embedding similarity across all samples of the same class, while enforcing dissimilarity for elements of different classes. This is achieved with a differentiable layer that is used to train a convolutional network in an end-to-end fashion. Our model outperforms state-of-the-art methods on several datasets, and shows fast convergence. In our work, we did not consider any advanced sampling strategy. Instead, we randomly sample objects from a few classes at each iteration. Sampling has shown to have a very important role in feature embedding <ref type="bibr" target="#b24">[25]</ref>. As future work, we will explore sampling techniques which can be suitable for our module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Robustness Analysis of CARS 196 Dataset</head><p>In the main work, we showed the robustness analysis on the CUB-200-2011 <ref type="bibr" target="#b46">[47]</ref> dataset (see <ref type="figure" target="#fig_3">Figure 4</ref> in the main paper). Here, we report the same analysis for the Cars 196 <ref type="bibr" target="#b20">[21]</ref> dataset. This leads us to the same conclusions as shown in the main paper.</p><p>We do a grid search over the total number of elements per class versus the number of anchors, as we did for the experiment in the main paper. We increase the number of elements per class from 5 to 10, and in each case, we vary the number of anchors from 0 to 4. We show the results in <ref type="figure" target="#fig_8">Fig. 9</ref>. Note, the results decrease mainly when we do not have any labeled sample, i.e., when we use zero anchors. The method shows the same robustness as on the CUB-200-2011 <ref type="bibr" target="#b46">[47]</ref> dataset, with the best result being only 2.1 percentage points better at the Recall@1 metric than the worst result. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B More Implementation Details</head><p>We first pre-train all networks in the classification task for 10 epochs. We then train our networks on all three datasets <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b43">44]</ref> for 60 epochs. During training, we use a simple learning rate scheduling in which we divide the learning rate by 10 after the first 30 epochs.</p><p>We find all hyperparameters using random search <ref type="bibr" target="#b1">[2]</ref>. For the weight decay (L2regularization) parameter, we search over the interval [0.1, 10 ?16 ], while for learning rate we search over the interval [0.1, 10 ?5 ], choosing 0.0002 as the learning rate for all networks and all datasets. During inference we normalize the features using the L2-norm.</p><p>We achieve the best results with a regularization parameter set to 10 ?6 for CUB-200-2011, 10 ?7 for Cars 196 dataset, and 10 ?12 for Stanford Online Products dataset.</p><p>This further strengthens our intuition that the method is implicitly regularized and it does not require strong regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Temperature Scaling</head><p>We mentioned in the main paper that as input to the Group Loss (step 3 of the algorithm) we initialize the matrix of priors X(0) from the softmax layer of the neural network. Following the works of <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b57">58]</ref>, we apply a sharpening function to reduce the entropy of the softmax distribution. We use the common approach of adjusting the temperature of this categorical distribution, known as temperature scaling. Intuitively, this procedure calibrates our network and in turn, provides more informative prior to the dynamical system. Additionally, this calibration allows the dynamical system to be more effective in adjusting the predictions, i.e, it is easier to change the probability of a class if its initial value is 0.6 rather than 0.95. The function is implemented using the following equation:</p><formula xml:id="formula_9">T sof tmax (zi) = e z i /T i e z i /T ,<label>(9)</label></formula><p>which can be efficiently implemented by simply dividing the prediction logits by a constant T .</p><p>Recent works in supervised learning <ref type="bibr" target="#b10">[11]</ref> and semi-supervised learning <ref type="bibr" target="#b2">[3]</ref> have found that temperature calibration improves the accuracy for the image classification task. We arrive at similar conclusions for the task of metric learning, obtaining 2.5pp better Recall@1 scores on CUB-200-2011 <ref type="bibr" target="#b46">[47]</ref> and 2pp better scores on Cars 196 <ref type="bibr" target="#b20">[21]</ref>. Note, the methods of Table 1 (main paper) that use a classification loss, use also temperature scaling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Other Backbones</head><p>In the main paper, we perform all experiments using a GoogleNet backbone with batch normalization. This choice is motivated by the fact that most methods use this backbone, making comparisons fair. In this section, we explore the performance of our method for other backbone architectures, to show the generality of our proposed loss formulation. We choose to train a few networks from Densenet family <ref type="bibr" target="#b14">[15]</ref>. Densenets are a modern CNN architecture which show similar classification accuracy to GoogleNet in most tasks (so they are a similarly strong classification baseline 3 ). Furthermore, by training multiple networks of the same family, we can study the effect of the capacity of the network, i.e., how much can we gain from using a larger network? Finally, we are interested in studying if the choice of hyperparameters can be transferred from one backbone to another.</p><p>We present the results of our method using Densenet backbones in Tab. 3. We use the same hyperparameters as the ones used for the GoogleNet experiments, reaching state-of-the-art results on both CARS 196 <ref type="bibr" target="#b20">[21]</ref> and Stanford Online Products <ref type="bibr" target="#b43">[44]</ref>    <ref type="bibr" target="#b34">[35]</ref> datasets, even compared to ensemble and sampling methods. The results in Stanford Online Products <ref type="bibr" target="#b43">[44]</ref> are particularly impressive considering that this is the first time any method in the literature has broken the 80 point barrier in Recall@1 metric. We also reach state-of-the-art results on the CUB-200-2011 <ref type="bibr" target="#b46">[47]</ref> dataset when we consider only methods that do not use ensembles (with the Group Loss ensemble reaching the highest results in this dataset). We observe a clear trend when increasing the number of parameters (weights), with the best results on both CARS 196 <ref type="bibr" target="#b20">[21]</ref> and Stanford Online Products <ref type="bibr" target="#b43">[44]</ref> datasets being achieved by the largest network, Densenet161 (whom has a lower number of convolutional layers than Densenet169 and Densenet201, but it has a higher number of weights/parameters). Finally, we study the effects of hyperparameter optimization. Despite that the networks reached state-of-the-art results even without any hyperparameter tuning, we expect a minimum amount of hyperparameters tuning to help. To this end, we used random search <ref type="bibr" target="#b1">[2]</ref> to optimize the hyperparameters of our best network on the CARS 196 <ref type="bibr" target="#b20">[21]</ref> dataset. We reach a 90.7 score (2pp higher score than the network with default hyperparameters) in Recall@1, and 77.6 score (3pp higher score than the network with default hyperparameters) in NMI metric, showing that individual hyperparameter optimization can boost the performance. The score of 90.7 in Recall@1 is not only by far the highest score ever achieved, but also the first time any method has broken the 90 point barrier in Recall@1 metric when evaluated on the CARS 196 <ref type="bibr" target="#b20">[21]</ref> dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Comparisons with SoftTriple Loss [35]</head><p>A recent paper (SoftTriple loss <ref type="bibr" target="#b34">[35]</ref>, ICCV 2019) explores another type of classification loss for the problem of metric learning. The main difference between our method and <ref type="bibr" target="#b34">[35]</ref> is that our method checks the similarity between samples, and then refines the predicted probabilities (via a dynamical system) based on that information. <ref type="bibr" target="#b34">[35]</ref> instead deals with the intra-class variability, but does not explicitly take into account the similarity between the samples in the mini-batch. They propose to add a new layer with 10 units per class.</p><p>We compare the results of <ref type="bibr" target="#b34">[35]</ref> with our method in Tab. 3. SoftTriple loss <ref type="bibr" target="#b34">[35]</ref> reaches a higher result than our method in all three datasets in Recall@1 metric, and higher results than the Group Loss on the CUB-200-2011 and Stanford Online Products datasets in NMI metric. However, this comes at a cost of significantly increasing the number of parameters. On the Stanford Online Products dataset in particular, the number of parameters of <ref type="bibr" target="#b34">[35]</ref> is 68.7 million. In comparison, we (and the other methods we compare the results with in the main paper) use only 16.6 million parameters. In effect, their increase in performance comes at the cost of using a neural network which is 4 times larger as ours, making results not directly comparable. Furthermore, using multiple centres is crucial for the performance of <ref type="bibr" target="#b34">[35]</ref>. <ref type="figure" target="#fig_3">Fig. 4</ref> of the work <ref type="bibr" target="#b34">[35]</ref> shows that when they use only 1 centre per class, the performance drops by 3pp, effectively making <ref type="bibr" target="#b34">[35]</ref> perform worse than the Group Loss by 2pp.</p><p>We further used the official code implementation to train their network using only one center on the CARS 196 <ref type="bibr" target="#b20">[21]</ref> dataset, reaching 83.1 score in Recall@1, and 70.1 score in NMI metric, with each score being 0.6pp lower than the score of The Group Loss. Essentially, when using the same backbone, SoftTriple loss <ref type="bibr" target="#b34">[35]</ref> reaches lower results than our method.</p><p>As we have shown in the previous section, increasing the number of parameters improves the performances of the network, but it is not a property of the loss function. In fact, a similarly sized network to theirs (Densenet 169) consistently outperforms SoftTriple loss, as can be seen in Tab. 3. For this reason, we keep this comparison in the supplementary material, while we leave for the main paper the comparisons with more than 20 methods that use the same backbone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Alternative Loss Formulation</head><p>In the main paper, we formulated the loss as an iterative dynamical system, followed by the cross-entropy loss function. In this way, we encourage the network to predict the same label for samples coming from the same class. One might argue that this is not necessarily the best loss for metric learning, in the end, we are interested in bringing similar samples closer together in the embedding space, without the need of having them classified correctly. Even though several works have shown that a classification loss can be used for metric learning <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b34">35]</ref>, we test whether this is also the best formulation for our loss function.</p><p>We therefore experiment with a different loss function which encourages the network to produce similar label distributions (soft labels) for the samples coming from the same class. We first define Kullback-Leibler divergence for two distributions P and Q as:</p><formula xml:id="formula_10">DKL(P ||Q) = x?X P (x)log P (x) Q(x) .<label>(10)</label></formula><p>We then minimize the divergence between the predicted probability (after the iterative procedure) of samples coming from the same class. Unfortunately, this loss formulation results in lower performances on both CUB-200-2011 <ref type="bibr" target="#b46">[47]</ref> (3pp) and Cars 196 <ref type="bibr" target="#b20">[21]</ref> (1.5pp). Thus, we report the experiments in the main paper only with the original loss formulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Dealing with Negative Similarities</head><p>Equation (4) in the main paper assumes that the matrix of similarity is non-negative. However, for similarity computation, we use a correlation metric (see Equation <ref type="bibr" target="#b0">(1)</ref> in the main paper) which produces values in the range [?1, 1]. In similar situations, different authors propose different methods to deal with the negative outputs. The most common approach is to shift the matrix of similarity towards the positive regime by subtracting the biggest negative value from every entry in the matrix <ref type="bibr" target="#b8">[9]</ref>. Nonetheless, this shift has a side effect: If a sample of class k1 has very low similarities to the elements of a large group of samples of class k2, these similarity values (which after being shifted are all positive) will be summed up. If the cardinality of class k2 is very large, then summing up all these small values lead to a large value, and consequently affect the solution of the algorithm. What we want instead, is to ignore these negative similarities, hence we propose clamping. More concretely, we use a ReLU activation function over the output of Equation <ref type="formula" target="#formula_0">(1)</ref>.</p><p>We compare the results of shifting vs clamping. On the CARS 196 dataset, we do not see a significant difference between the two approaches. However, on the CUBS-200-2011 dataset, the Recall@1 metric is 51 with shifting, much below the 64.3 obtained when using clamping. We investigate the matrix of similarities for the two datasets, and we see that the number of entries with negative values for the CUBS-200-2011 dataset is higher than for the CARS 196 dataset. This explains the difference in behavior, and also verifies our hypothesis that clamping is a better strategy to use within Group Loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Dealing with Relative Labels</head><p>The proposed method assumes that the dataset consists of classes with (absolute) labels and set of samples in each class. This is the case for the datasets used in metric learning <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b43">44]</ref>) technique evaluations. However, deep metric learning can be applied to more general problems where the absolute class label is not available but only relative label is available. For example, the data might be given as pairs that are similar or dissimilar. Similarly, the data may be given as triplets consisting of anchor (A), positive (P) and negative (N) images, such that A is semantically closer to P than N. For example, in <ref type="bibr" target="#b48">[49]</ref> a triplet network has been used to learn good visual representation where only relative labels are used as self-supervision (two tracked patches from the same video form a "similar" pair and the patch in the first frame and a patch sampled from another random video forms a "dissimilar" pair). Similarly, in <ref type="bibr" target="#b26">[27]</ref>, relative labels are used as self-supervision for learning good spatio-temporal representation.</p><p>Our method, similar to other classification-based losses <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b34">35]</ref> for deep metric learning, or triple loss improvements like Hierarchical Triplet Loss <ref type="bibr" target="#b9">[10]</ref> assumes the presence of absolute labels. Unlike traditional losses <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b39">40]</ref>, in cases where only relative labels are present, all the mentioned methods do not work. However, in the presence of both relative and absolute labels, then in our method, we could use relative labels to initialize the matrix of similarities, potentially further improving the performance of networks trained with The Group Loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I Dealing with a Large Number of Classes</head><p>In all classification based methods, the number of outputs in the last layer linearly increases with the number of classes in the dataset. This can become a problem for learning on a dataset with large number of classes (say N &gt; 1000000) where metric learning methods like pairwise/triplet losses/methods can still work. In our method, the similarity matrix is square on the number of samples per mini-batch, so its dimensions are the same regardless if there are 5 or 5 million classes. However, the matrix of probabilities is linear in the number of classes. If the number of classes grows, computing the softmax probabilities and the iterative process becomes indeed computationally expensive. An alternative (which we have tried, reaching similar results to those presented in the paper) is to sparsify the matrix. Considering that in any mini-batch, we use only a small number of classes (&lt; 10), all the entries not belonging to these classes may be safely set to 0 (followed by a normalization of the probability matrix). This would allow both saving storage (e.g. using sparse tensors in PyTorch) and an efficient tensor-tensor multiplication. It also needs to be said, that in retrieval, the number of classes is typically not very large, and many other methods <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b9">10]</ref> face the same problem. However, in related fields (for example, face recognition), there could be millions of classes (identities), in which case we can use the proposed solution. <ref type="figure" target="#fig_1">Fig. 10</ref> visualizes the t-distributed stochastic neighbor embedding (t-SNE) <ref type="bibr" target="#b22">[23]</ref> of the embedding vectors obtained by our method on the CUB-200-2011 <ref type="bibr" target="#b46">[47]</ref> dataset. The plot is best viewed on a high-resolution monitor when zoomed in. We highlight several representative groups by enlarging the corresponding regions in the corners. Despite the large pose and appearance variation, our method efficiently generates a compact feature mapping that preserves semantic similarity. <ref type="figure" target="#fig_1">Fig. 10</ref>: t-SNE <ref type="bibr" target="#b22">[23]</ref> visualization of our embedding on the CUB-200-2011 <ref type="bibr" target="#b46">[47]</ref> dataset, with some clusters highlighted. Best viewed on a monitor when zoomed in.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J t-SNE on CUB-200-2011 Dataset</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>A toy example of the refinement procedure, where the goal is to classify sample C based on the similarity with samples A and B. (1) The Affinity matrix used to update the soft assignments. (2) The initial labeling of the matrix. (3-4) The process iteratively refines the soft assignment of the unlabeled sample C. (5) At the end of the process, sample C gets the same label of A, (A, C) being more similar than (B, C).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1 :</head><label>1</label><figDesc>The Group Loss Input: input : Set of pre-processed images in the mini-batch B, set of labels y, neural network ? with learnable parameters ?, similarity function ?, number of iterations T 1 Compute feature embeddings ?(B, ?) via the forward pass 2 Compute the similarity matrix W = [?(i, j)]ij 3 Initialize the matrix of priors X(0) from the softmax layer 4 for t = 0, . . . , T-1 do5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Retrieval results on a set of images from the CUB-200-2011 (left), Cars 196 (middle), and Stanford Online Products (right) datasets using our Group Loss model. The left column contains query images. The results are ranked by distance. The green square indicates that the retrieved image is from the same class as the query image, while the red box indicates that the retrieved image is from a different class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>The effect of the number of anchors and the number of samples per class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>The effect of the number of classes per mini-batch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 :</head><label>6</label><figDesc>Recall@1 as a function of training epochs on Cars196 dataset. Figure adapted from [28].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 :</head><label>7</label><figDesc>Training vs testing Recall@1 curves on Cars 196 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 :</head><label>8</label><figDesc>Training vs testing Recall@1 curves on Stanford Online Products dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 :</head><label>9</label><figDesc>The effect of the number of anchors and the number of samples per class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>we present the results of our ensemble, and compare them with the results of other ensemble and sampling approaches. Our ensemble method (using 5 neural networks) is the highest performing model in CUB-200-2011, outperforming the second-best method (Divide and Conquer<ref type="bibr" target="#b38">[39]</ref>) by 1pp in Recall@1 and by 0.4pp in NMI. In Cars 196 our method outperforms the second best method (ABE 8<ref type="bibr" target="#b18">[19]</ref>) by 2.8pp in Recall@1. The second best method in NMI metric is the ensemble version of RLL<ref type="bibr" target="#b49">[50]</ref> which gets outperformed by 2.4pp from the Group Loss. In Stanford Online Products, our ensemble reaches the third-highest result on the Recall@1 metric (after RLL<ref type="bibr" target="#b49">[50]</ref> and GPW<ref type="bibr" target="#b50">[51]</ref>) while increasing the gap with the other methods in NMI metric.</figDesc><table><row><cell>Qualitative results</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Retrieval and Clustering performance on CUB-200-2011, CARS 196 and Stanford Online Products datasets. Bold indicates best results.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Retrieval and Clustering performance of our ensemble compared with other ensemble and sampling methods. Bold indicates best results.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>The results of Group Loss in Densenet backbones and comparisons with SoftTriple loss</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The classification accuracy of different backbones can be found in the following link: https://pytorch.org/docs/stable/torchvision/models.html. BN-Inception's top 1/top 5 error is 7.8%/25.2%, very similar to those of Densenet121 (7.8%/25.4%).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This research was partially funded by the Humboldt Foundation through the Sofja Kovalevskaja Award. We thank Michele Fenzi, Maxim Maximov and Guillem Braso Andilla for useful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep constrained dominant sets for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Alemu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pelillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision, ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9854" to="9863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems, NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5050" to="5060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Signature verification using a&quot; siamese&quot; time delay neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>S?ckinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems, NIPS</title>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="737" to="744" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep metric learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>? Akir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1861" to="1870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep embedding learning with discriminative sampling policy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Transductive label augmentation for improved deep network learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Elezi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torcinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vascon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pelillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition, ICPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1432" to="1437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Graph transduction as a noncooperative game</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Erdem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pelillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="700" to="723" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep metric learning with hierarchical triplet loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference in Computer Vision, ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="272" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<editor>Precup, D., Teh, Y.W.</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hashing as tie-aware learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bargal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Sclaroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4023" to="4032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Local descriptors optimized for average precision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="596" to="605" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2261" to="2269" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning, ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Product quantization for nearest neighbor search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="128" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">On largebatch training for deep learning: Generalization gap and sharp minima</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mudigere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Smelyanskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T P</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations, ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Attention-based ensemble for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="760" to="777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations ICLR</title>
		<meeting>the 3rd International Conference on Learning Representations ICLR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">3d object representations for finegrained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International IEEE Workshop on 3D Representation and Recognition</title>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep spectral clustering learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning, ICML</title>
		<meeting>the 34th International Conference on Machine Learning, ICML</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1985" to="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Visualizing non-metric similarities in multiple maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="33" to="55" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Fifth Berkeley Symp. on Math. Statist. and Prob</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sampling matters in deep embedding learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kr?henb?hl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision, ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2859" to="2867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Normalized mutual information to evaluate overlapping community finding algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Mcdaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Hurley</surname></persName>
		</author>
		<idno>abs/1110.2515</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Shuffle and learn: Unsupervised learning using temporal order verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">No fuss distance metric learning using proxies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision, ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="360" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">BIER -boosting independent embeddings robustly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Waltner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Possegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision, ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5199" to="5208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep metric learning with BIER: boosting independent embeddings robustly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Waltner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Possegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="276" to="290" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Relational knowledge distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<title level="m">Automatic differentiation in pytorch. NIPS Workshops</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Notes on regression and inheritance in the case of two parents. Proceedings of the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pearson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Royal Society of London</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="240" to="242" />
			<date type="published" when="1895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The dynamics of nonlinear relaxation labeling processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pelillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Imaging and Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="309" to="323" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Softtriple loss: Deep metric learning without triplet sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tacoma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision, ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6449" to="6457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning with average precision: Training image retrieval with a listwise loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Almaz?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>De Souza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision, ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5106" to="5115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Scene labeling by relaxation operations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Zucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Syst. Man Cybern</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="420" to="433" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Divide and conquer the embedding space for metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanakoyeu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tschernezki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>B?chler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning a distance metric from relative comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems, NIPS</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Improved deep metric learning with multi-class n-pair loss objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems, NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1849" to="1857" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep metric learning via facility location</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2206" to="2214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4004" to="4012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Generalization in metric learning: Should the embedding layer be embedding layer?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on Applications of Computer Vision, WACV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="589" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Deep metric learning with angular loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision, ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2612" to="2620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations using videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision, ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2794" to="2802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Ranked list loss for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5207" to="5216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Multi-similarity loss with general pair weighting for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Evolutionary Game Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weibull</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="207" to="244" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep asymmetric metric learning via rich relationship mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Vision and Pattern Recognition</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Deep randomized ensembles for metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Souvenir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference Computer Vision, ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="751" to="762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Correcting the triplet selection bias for triplet loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference in Computer Vision, ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="71" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Hard-aware deeply cascaded embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision, CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="814" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Classification is a strong baseline for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference BMVC</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">91</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Embedding label structures for fine-grained feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1114" to="1123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Regularface: Deep face recognition via exclusive regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1136" to="1144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Towards optimal fine grained retrieval via decorrelated centralized loss with normalize-scale layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Artificial Intelligence, AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9291" to="9298" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
