<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">3D Human Pose Estimation Using M?bius Graph Convolutional Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niloofar</forename><surname>Azizi</surname></persName>
							<email>azizi@icg.tugraz.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Possegger</surname></persName>
							<email>possegger@icg.tugraz.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Rodol?</surname></persName>
							<email>rodola@di.uniroma1.it</email>
							<affiliation key="aff1">
								<orgName type="institution">Sapienza University of Rome</orgName>
								<address>
									<settlement>Rome</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
							<email>bischof@icg.tugraz.at</email>
							<affiliation key="aff0">
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">3D Human Pose Estimation Using M?bius Graph Convolutional Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>3D human pose estimation is fundamental to understanding human behavior. Recently, promising results have been achieved by graph convolutional networks (GCNs), which achieve state-of-the-art performance and provide rather light-weight architectures. However, a major limitation of GCNs is their inability to encode all the transformations between joints explicitly. To address this issue, we propose a novel spectral GCN using the M?bius transformation (M?bius-GCN). In particular, this allows us to directly and explicitly encode the transformation between joints, resulting in a significantly more compact representation. Compared to even the lightest architectures so far, our novel approach requires 90-98% fewer parameters, i.e. our lightest M?biusGCN uses only 0.042M trainable parameters. Besides the drastic parameter reduction, explicitly encoding the transformation of joints also enables us to achieve state-of-the-art results. We evaluate our approach on the two challenging pose estimation benchmarks, Hu-man3.6M and MPI-INF-3DHP, demonstrating both state-of-the-art results and the generalization capabilities of M?biusGCN.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Estimating 3D human pose helps to analyze human motion and behavior, thus enabling high-level computer vision tasks such as action recognition <ref type="bibr" target="#b29">[30]</ref>, sports analysis <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b63">64]</ref>, augmented and virtual reality <ref type="bibr" target="#b14">[15]</ref>. Although human pose estimation approaches already achieve impressive results in 2D, this is not sufficient for many analysis tasks, because several 3D poses can project to exactly the same 2D pose. Thus, knowledge of the third dimension can significantly improve the results on the high-level tasks.</p><p>Estimating 3D human joint positions, however, is challenging. On the one hand, there are only very few labeled datasets because 3D annotations are expensive. On the other hand, there are self-occlusions, complex joint inter-dependencies, small and barely visible joints, changes in appearance like clothing and lighting, and the many degrees of freedom of the human body.</p><p>To solve 3D human pose estimation, some methods utilize multi-views <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b69">70]</ref>, synthetic datasets <ref type="bibr" target="#b45">[46]</ref>, or motion <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b54">55]</ref>. For improved generalization, however, we follow the most common line of work and estimate 3D poses given only the 2D estimate of a single RGB image as input, similar to <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b44">45]</ref>. First, we compute 2D pose joints given RGB images using an off-the-shelf architecture. Second, we approximate the 3D pose of the human body using the estimated 2D joints.</p><p>With the advent of deep learning methods, the accuracy of 3D human pose estimation has significantly improved, e.g. <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b44">45]</ref>. Initially, these improvements were driven by CNNs (Convolutional Neural Networks). However, these assume that the input data is stationary, hierarchical, has a grid-like structure, and shares local features across the data domain. The convolution operator in the CNN assumes that the nodes have fixed neighbor positions and a fixed number of neighbor nodes. Therefore, CNNs are not applicable to graph-structured data. The input to 3D pose estimation from 2D joint positions, however, is graph-structured data. Thus, to handle this irregular nature of the data, GCNs (Graph Convolutional Networks) have been proposed <ref type="bibr" target="#b3">[4]</ref>.</p><p>GCNs are able to achieve state-of-the-art performance for 2D-to-3D human pose estimation with comparably few parameters, e.g. <ref type="bibr" target="#b70">[71]</ref>. Nevertheless, to the best of our knowledge, none of the previous GCN approaches explicitly models the inter-segmental angles between joints. Learning the inter-segmental angle distribution explicitly along with the translation distribution, however, leads to encoding better feature representations. Thus, we present a novel spectral GCN architecture, M?biusGCN, to accurately learn the transformation between joints and to predict 3D human poses given 2D joint positions from a single RGB image. To this end, we leverage the M?bius transformation on the eigenvalue matrix of the graph Laplacian. Previous GCNs applied for estimating the 3D pose of the human body are defined in the real domain, e.g. <ref type="bibr" target="#b70">[71]</ref>. Our M?bius-GCN operates in the complex domain, which allows us to encode all the transformations (i.e. inter-segmental angles and translation) between nodes simultaneously ( <ref type="figure" target="#fig_0">Figure 1</ref>).</p><p>An enriched feature representation achieved by encoding the transformation distribution between joints using a M?bius transformation provides us with a compact model. A light DNN architecture makes the network independent of expensive hardware setup, enabling the use of mobile phones and embedded devices at inference time. This can be achieved by our compact M?biusGCN architecture.</p><p>Due to a large number of weights that need to be estimated, fully-supervised stateof-the-art approaches need an enormous amount of annotated data, where data annota-tion is both time-consuming and requires expensive setup. Our M?biusGCN, on the contrary, requires only a tiny fraction of the model parameters, which allows us to achieve competitive results with significantly fewer annotated data.</p><p>We summarize our main contributions as follows:</p><p>-We introduce a novel spectral GCN architecture leveraging the M?bius transformation to explicitly encode the pose, in terms of inter-segmental angles and translations between joints. -We achieve state-of-the-art 3D human pose estimation results, despite requiring only a fraction of the model parameters (i.e. 2-9% of even the currently lightest approaches). -Our light-weight architecture and the explicit encoding of transformations lead to state-of-the-art performance compared to other semi-supervised methods, by training only on a reduced dataset given estimated 2D human joint positions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Human 3D Pose Estimation. The classical approaches addressing the 3D human pose estimation task are usually based on hand-engineered features and leverage prior assumptions, e.g. using motion models <ref type="bibr" target="#b56">[57]</ref> or other common heuristics <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b47">48]</ref>. Despite good results, their major downside is the lack of generality. Current state-of-the-art approaches in computer vision, including 3D human pose estimation, are typically based on DNNs (Deep Neural Networks), e.g. <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b51">52]</ref>. To use these architectures, it is assumed that the statistical properties of the input data have locality, stationarity, and multi-scalability <ref type="bibr" target="#b15">[16]</ref>, which reduces the number of parameters.</p><p>Although DNNs achieve state-of-the-art in spaces governed by Euclidean geometry, a lot of the real-world problems are of a non-Euclidean nature. For these problem classes, GCNs have been introduced. There are two types of GCNs: spectral GCN and spatial GCN. Spectral GCNs rely on the Graph Fourier Transform, which analyzes the graph signals in the vector space of the graph Laplacian matrix. The second category, spatial GCN, is based on feature transformations and neighborhood aggregation on the graph. Well-known spatial GCN approaches include Message Passing Neural Networks <ref type="bibr" target="#b11">[12]</ref> and GraphSAGE <ref type="bibr" target="#b13">[14]</ref>.</p><p>For 3D human pose estimation, GCNs achieve competitive results with comparably few parameters. Pose estimation with GCNs has been addressed, e.g. in <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b70">71]</ref>. Xu and Takano <ref type="bibr" target="#b65">[66]</ref> proposed Graph Stacked Hourglass Networks (GraphSH), in which graph-structured features are processed across different scales of human skeletal representations. Liu et al. <ref type="bibr" target="#b26">[27]</ref> investigated different combinations of feature transformations and neighborhood aggregation of spatial features. They also showed the benefits of using separate weights to incorporate a node's self-information. Zhao et al. <ref type="bibr" target="#b70">[71]</ref> proposed semantic GCN (SemGCN), which currently represents the lightest architecture (0.43M). The key idea is to learn the adjacency matrix, which lets the architecture encode the graph's semantic relationships between nodes. In contrast to SemGCN, we can further reduce the number of parameters by an order of magnitude (0.042M) by explicitly encoding the transformation between joints. The key ingredient to this significant reduction is the M?bius transformation.</p><p>M?bius Transformation. The M?bius transformation has been used in neural networks as an activation function <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b38">39]</ref>, in hyperbolic neural networks <ref type="bibr" target="#b10">[11]</ref>, for data augmentation <ref type="bibr" target="#b72">[73]</ref>, and for knowledge graph embedding <ref type="bibr" target="#b36">[37]</ref>. Our work is the first to introduce M?bius transformations for spectral graph convolutional networks. To utilize the M?bius transformation, we have to design our neural network in the complex domain. The use of complex numbers (analysis in polar coordinates) to harness phase information along with the signal amplitude is well established in signal processing <ref type="bibr" target="#b31">[32]</ref>. By applying the M?bius transformation, we let the architecture encode the transformations (i.e. inter-segmental angle and translation) between joints explicitly, which leads to a very compact architecture.</p><p>Handling Rotations. Learning the rotation between joints in skeletons has been investigated previously for 3D human pose estimation <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b74">75]</ref>. Learning the rotation using Euler angles or quaternions, however, has obvious issues like discontinuities <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b76">77]</ref>. Continuous functions are easier to learn in neural networks <ref type="bibr" target="#b76">[77]</ref>. Zhou et al. <ref type="bibr" target="#b76">[77]</ref> tackle the discontinuity by lifting the problem to 5 and 6 dimensions. Another direction of research focuses on designing DNNs for inverse kinematics with the restricted assumption of putting joint angles in a specific range to avoid discontinuities. However, learning the full range of rotations is necessary for many real-world problems <ref type="bibr" target="#b76">[77]</ref>. Our M?biusGCN is continuous by definition and thus, allows us to elegantly encode rotations.</p><p>Data Reduction. A major benefit of light architectures is that they require smaller datasets to train. Semi-supervised methods require a small subset of annotated data and a large set of unannotated data for training the network. These methods are actively investigated in different domains, considering the difficulty of providing annotated datasets. Several semi-supervised approaches for 3D human pose estimation benefit from applying more constraints over the possible space solutions by utilizing multiview approaches using RGB images from different cameras <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b68">69]</ref>. These methods need expensive laboratory setups to collect synchronized multi-view data.</p><p>Pavllo et al. <ref type="bibr" target="#b44">[45]</ref> phrase the loss over the back-projected estimated 3D human pose to 2D human pose space conditioned on time. Tung et al. <ref type="bibr" target="#b60">[61]</ref> use generative adversarial networks to reduce the required annotated data for training the architecture. Iqbal et al. <ref type="bibr" target="#b18">[19]</ref> relax the constraints using weak supervision; they introduce an end-to-end architecture that estimates 2D pose and depth independently, and uses a consistency loss to estimate the pose in 3D.</p><p>Our compact M?biusGCN achieves competitive state-of-the-art results with only scarce training samples. M?biusGCN does not require any multi-view setup or temporal information. Further, it does not rely on large unlabeled datasets. It just requires a small annotated dataset to train. In contrast, the previous semi-supervised methods require complicated architectures and a considerable amount of unlabeled data during the training phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Spectral Graph Convolutional Network</head><p>Stacked Hourglass </p><formula xml:id="formula_0">M?biusGCN M?biusGCN M?biusGCN M?biusGCN M?biusGCN M?biusGCN M?biusGCN 2D input U ? U T x g ? ReLU ? 2? + Bias SVD ofL</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Graph Definitions</head><p>Let G(V, E) represent a graph consisting of a finite set of N vertices, V = {? 1 , . . . , ? N }, and a set of</p><formula xml:id="formula_1">M edges E = {e 1 , . . . , e M }, with e j = (? i , ? k ) where ? i , ? k ? V .</formula><p>The graph's adjacency matrix A N ?N contains 1 in case two vertices are connected and 0 otherwise.</p><formula xml:id="formula_2">D N ?N is a diagonal matrix where D ii is the degree of vertex ? i . A graph is directed if (? i , ? k ) ? = (? k , ? i )</formula><p>, otherwise it is an undirected graph. For an undirected graph, the adjacency matrix is symmetric. The non-normalized graph Laplacian matrix is defined as L = D ? A, and can be normalized toL = I ? D ? 1 2 AD ? 1 2 , where I is the identity matrix.L is real, symmetric, and positive semi-definite. Therefore, it has N ordered, real, and non-negative eigenvalues {? i : i = 1, . . . , N } and corresponding orthonormal eigenvectors {u i : i = 1, . . . , N }.</p><p>A signal x defined on the nodes of the graph is a vector</p><formula xml:id="formula_3">x ? R N , where its i-th component represents the function value at the i-th vertex in V . Similarly, X ? R N ?d is called a d-dimensional graph signal on G [56].</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Graph Fourier Transform</head><p>Graph signals x ? R N admit a graph Fourier expansion</p><formula xml:id="formula_4">x = N i=1 ?u i , x?u i , where u i , i = 1, .</formula><p>. . , N are the eigenvectors of the graph Laplacian <ref type="bibr" target="#b55">[56]</ref>. Eigenvalues and eigenvectors of the graph Laplacian matrix are analogous to frequencies and sinusoidal basis functions in the classical Fourier series expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Spectral Graph Convolutional Network</head><p>Spectral GCNs <ref type="bibr" target="#b4">[5]</ref> build upon the graph Fourier transform. Let x be the graph signal and y be the graph filter on graph G. The graph convolution * G can be defined as</p><formula xml:id="formula_5">x * G y = U(U ? x ? U ? y)<label>(1)</label></formula><p>where the matrix U contains the eigenvectors of the normalized graph Laplacian and ? is the Hadamard product. This can also be written as</p><formula xml:id="formula_6">x * G g ? = Ug ? (?)U ? x,<label>(2)</label></formula><p>where g ? (?) is a diagonal matrix with the parameter ? ? R N as a vector of Fourier coefficients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Spectral Graph Filter</head><p>Based on the corresponding definition of g ? in Eq. <ref type="formula" target="#formula_6">(2)</ref>, spectral GCNs can be classified into spectral graph filters with smooth functions and spectral graph filters with rational functions.</p><p>Spectral Graph Filter with Smooth Functions. Henaff et al. <ref type="bibr" target="#b15">[16]</ref> proposed defining g ? (?) to be a smooth function (smoothness in the frequency domain corresponds to the spatial decay), to address the localization problem.</p><p>Defferrard et al. <ref type="bibr" target="#b8">[9]</ref> proposed defining the function g ? in such a way to be directly applicable over the Laplacian matrix to address the computationally costly Laplacian matrix decomposition and multiplication with the eigenvector matrix in Eq. <ref type="bibr" target="#b1">(2)</ref>.</p><p>Kipf and Welling <ref type="bibr" target="#b20">[21]</ref> defined g ? (L) to be the Chebychev polynomial by assuming all the eigenvalues in the range of [?1, 1]. Computing the polynomials of the Chebychev polynomial, however, is computationally expensive. Also, considering polynomials with higher orders causes overfitting. Therefore, Kipf and Welling <ref type="bibr" target="#b20">[21]</ref> approximated the Chebychev polynomial with its first two orders.</p><p>Spectral Graph Filter with Rational Functions. Fractional spectral GCNs, unlike polynomial spectral GCNs, can model sharp changes in the frequency response <ref type="bibr" target="#b2">[3]</ref>. Levie et al. <ref type="bibr" target="#b22">[23]</ref> put the eigenvalues of the Laplacian matrix on the unit circle by applying the Cayley transform on the Laplacian matrix with a learned parameter, named spectral coefficient, that lets the network focus on the most useful frequencies.</p><p>Our proposed M?biusGCN is also a fractional GCN which applies the M?bius transformation on the eigenvalue matrix of the normalized Laplacian matrix to encode the transformations between joints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">M?biusGCN</head><p>A major drawback of previous spectral GCNs is that they do not encode the transformation distribution between nodes explicitly. We address this by applying the M?bius transformation function over the eigenvalue matrix of the decomposed Laplacian matrix. This simultaneous encoding of the rotation and translation distribution in the complex domain leads to better feature representations and fewer parameters in the network.</p><p>The input to our first block of M?biusGCN are the joint positions in 2D Euclidean space, given as J = {J i ? R 2 |i = 1, . . . , ?}, which can be computed directly from the image. Our goal is then to predict the corresponding 3D Euclidean joint position?</p><formula xml:id="formula_7">Y = {? i ? R 3 |i = 1, . . . , ?}.</formula><p>We leverage the structure of the input data, which can be represented by a connected, undirected and unweighted graph. The input graphs are fixed and share the same topological structure, which means the graph structure does not change, and each training and test example differs only in having different features at the vertices. In contrast to pose estimation, tasks like protein-protein interaction <ref type="bibr" target="#b61">[62]</ref> are not suitable for our M?biusGCN, because there the topological structure of the input data can change across samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">M?bius Transformation</head><p>The general form of a M?bius transformation <ref type="bibr" target="#b31">[32]</ref> is given by f </p><formula xml:id="formula_8">f (z) = f 4 ? f 3 ? f 2 ? f 1 (z) = az + b cz + d ,</formula><p>where ? denotes the composition of two functions f and g as</p><formula xml:id="formula_9">f ? g(z) = f (g(z)).</formula><p>The M?bius transformation is analytic everywhere except at the pole z = ? d c . Since a M?bius transformation remains unchanged by scaling with a coefficient <ref type="bibr" target="#b31">[32]</ref>, we normalize it to yield the determinant 1. We observed that in our gradient-based optimization setup, the M?bius transformation in each node converges into the fixed points. In particular, the M?bius transformation can have two fixed points (loxodromic), one fixed point (parabolic or circular), or no fixed point. The fixed points can be computed by solving az+b cz+d = z, which gives</p><formula xml:id="formula_10">? 1,2 = a ? d + (a ? d) 2 ? 4bc 2c .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">M?biusGCN</head><p>To predict the 3D human pose, we explicitly encode the local transformations between joints, where each joint corresponds to a node in the graph. To do so, we define g ? (?) in Eq.</p><p>(2) to be the M?bius transformation applied to the Laplacian eigenvalues, resulting in the following fractional spectral graph convolutional network</p><formula xml:id="formula_11">x * G g ? (?) = U M?bius(?) U ? x = N ?1 i=0 M?bius i (? i )u i u ? i x ,<label>(3)</label></formula><p>where</p><formula xml:id="formula_12">M?bius i (? i ) = a i ? i + b i c i ? i + d i ,<label>(4)</label></formula><formula xml:id="formula_13">with a i , b i , c i , d i , ? i ? C.</formula><p>Applying the M?bius transformation over the Laplacian matrix places the signal in the complex domain. To return back to the real domain, we sum it up with its conjugate</p><formula xml:id="formula_14">Z = 2?{w U M?bius(?) U ? x},<label>(5)</label></formula><p>where w is the shared complex-valued learnable weight to encode different transformation features. This causes the number of learned parameters to be reduced by a factor equal to the number of joints (nodes of the graph). The inter-segmental angles between joints are encoded by learning the rotation functions between neighboring nodes. We can easily generalize this definition to the graph signal matrix X ? C N ?d with d input channels (i.e. a d-dimensional feature vector for every node) and W ? C d?F feature maps. This defines a M?biusGCN block</p><formula xml:id="formula_15">Z = ?(2?{U M?bius(?)U ? XW} + b),<label>(6)</label></formula><p>where Z ? R N ?F is the convolved signal matrix, ? is a nonlinearity (e.g. ReLU <ref type="bibr" target="#b35">[36]</ref>), and b is a bias term.</p><p>To encode enriched and generalized joint transformation feature representations, we make the architecture deep by stacking several blocks of M?biusGCN. Stacking these blocks yields our complete architecture for 3D pose estimation, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>To apply the M?bius transformation over the matrix of eigenvalues of the Laplacian matrix, we encode the weights of the M?bius transformation for each eigenvalue in four diagonal matrices A, B, C, D and compute</p><formula xml:id="formula_16">U M?bius(?)U ? = U(A? + B)(C? + D) ?1 U ? .<label>(7)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Why M?biusGCN is a Light Architecture</head><p>As a direct consequence of applying the M?bius transformation for the graph filters in polar coordinates, the filters in each block can encode the inter-segmental angle features between joints in addition to the translation features explicitly. By applying the M?bius transformation, the graph filter scales and rotates the eigenvectors of the Laplacian matrix in the graph Fourier transform simultaneously. This leads to learning better feature representations and thus, yields a more compact architecture. For a better understanding, consider the following analogy with the classical Fourier transform: While it can be hard to construct an arbitrary signal by a linear combination of basis functions with real coefficients (i.e., the signal is built just by changing the amplitudes of the basis functions), it is significantly easier to build a signal by using complex coefficients, which change both the phase and amplitude.</p><p>In previous spectral GCNs, specifically <ref type="bibr" target="#b20">[21]</ref>, the Chebychev polynomials are only able to scale the eigenvectors of the Laplacian matrix, in turn requiring both more parameters and additional nonlinearities to encode the rotation distribution between joints implicitly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Discontinuity</head><p>Our model encodes the transformation between joints in the complex domain by learning the parameters of the normalized M?bius transformation. In the definition of the M?bius transformation, if ad ? bc ? = 0, then the M?bius transformation is an injective function and thus, continuous by the definition of continuity for neural networks given by <ref type="bibr" target="#b76">[77]</ref>. M?biusGCN does not suffer from discontinuities in representing intersegmental angles, in contrast to Euler angles or quaternions. Additionally, this leads to significantly fewer parameters in our architecture.  <ref type="bibr" target="#b17">[18]</ref> under Protocol #1. Best in bold, second-best underlined. In the upper part, all methods use stacked hourglass (HG) 2D estimates <ref type="bibr" target="#b37">[38]</ref> as inputs, except for <ref type="bibr" target="#b65">[66]</ref> (which uses CPN <ref type="bibr" target="#b6">[7]</ref>, indicated by * ). In the lower part, all methods use the 2D ground truth (GT) as input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and Evaluation Protocols</head><p>We use the publicly available motion capture dataset Human3.6M <ref type="bibr" target="#b17">[18]</ref>. It contains 3.6 million images produced by 11 actors performing 15 actions. Four different calibrated RGB cameras are used to capture the subjects during training and test time. Same as previous works, e.g. <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b70">71]</ref>, we use five subjects (S1, S5, S6, S7, S8) for training and two subjects (S9 and S11) for testing. Each sample from the different camera views is considered independently. We also use MPI-INF-3DHP dataset <ref type="bibr" target="#b33">[34]</ref> to test the generalizability of our model. MPI-INF-3DHP contains 6 subjects for testing in three different scenarios: studio with a green screen (GS), studio without green screen (noGS), and outdoor scene (Outdoor). Note that for experiments on MPI-INF-3DHP we also only trained on Human3.6M. Following <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b70">71]</ref>, we use the MPJPE protocol, referred to as Protocol #1. MPJPE is the mean per joint position error in millimeters between predicted joint positions and ground truth joint positions after aligning the pre-defined root joints (i.e. the pelvis joint). Note that some works (e.g. <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b44">45]</ref>) use the P-MPJPE metric, which reports the error after a rigid transformation to align the predictions with the ground truth joints. We explicitly select the standard MPJPE metric as it is more challenging and also allows for a fair comparison to previous related works. For the MPI-INF-3DHP test set, similar to previous works <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b65">66]</ref>, we use the percentage of correct 3D keypoints (3D PCK) within a 150 mm radius <ref type="bibr" target="#b33">[34]</ref> as evaluation metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Implementation Details</head><p>2D Pose Estimation. The inputs to our architecture are the 2D joint positions estimated from the RGB images for all four cameras independently. Our method is independent of the off-the-shelf architecture used for estimating 2D joint positions. Similar to previous works <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b70">71]</ref>, we use the stacked hourglass architecture <ref type="bibr" target="#b37">[38]</ref> to estimate the 2D joint positions. The hourglass architecture is an autoencoder architecture that stacks the encoder-decoder with skip connections multiple times. Following <ref type="bibr" target="#b70">[71]</ref>, the stacked hourglass network is first pre-trained on the MPII <ref type="bibr" target="#b0">[1]</ref> dataset and then fine-tuned on the Human3.6M <ref type="bibr" target="#b17">[18]</ref> dataset. As described in <ref type="bibr" target="#b44">[45]</ref>, the input joints are scaled to image coordinates and normalized to [?1, 1].</p><p>3D Pose Estimation. The ground truth 3D joint positions in the Human3.6M dataset are given in world coordinates. Following previous works <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b70">71]</ref>, we transform the joint positions to the camera space given the camera calibration parameters. Similar to previous works <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b70">71]</ref>, to make the architecture trainable, we chose a predefined joint (the pelvis joint) as the center of the coordinate system. We do not use any augmentations throughout all our experiments.</p><p>We trained our architecture using Adam <ref type="bibr" target="#b19">[20]</ref> with an initial learning rate of 0.001 and used mini-batches of size 64. The learning rate is dropped with a decay rate of 0.5 when the loss on the validation set saturates. The architecture contains seven M?bius-GCN blocks, where each block, except the first and the last block with the input and the output channels 2 and 3 respectively, contains either 64 channels (leading to 0.04M parameters) or 128 channels (leading to 0.16M parameters). We initialized the weights using the Xavier method <ref type="bibr" target="#b12">[13]</ref>. During the test phase, the scale of the outputs is calibrated by forcing the sum of the length of all 3D bones to be equal to a canonical skeleton <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b75">76]</ref>. To help the architecture differentiate between different 3D poses with the same 2D pose, similar to Poier et al. <ref type="bibr" target="#b46">[47]</ref>, we provide the center of mass of the subject to the architecture as an additional input. Same as <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b70">71]</ref>, we predict 16 joints (i.e. without the 'Neck/Nose' joint).</p><p>Also, as in previous works <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b70">71]</ref>, our network predicts the normalized locations of 3D joints. We did all our experiments on an NVIDIA GeForce RTX 2080 GPU using the PyTorch framework <ref type="bibr" target="#b40">[41]</ref>. For the loss function, same as previous works e.g. <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b44">45]</ref>, we use the mean squared error (MSE) between the 3D ground truth joint locations Y and our predictions?, i.e.</p><formula xml:id="formula_17">L(Y,?) = ? i=1 (Y i ?? i ) 2 .<label>(8)</label></formula><p>Complex-valued M?biusGCN. In complex-valued neural networks, the data and the weights are represented in the complex domain. A complex function is holomorphic (complex-differentiable) if not only their partial derivatives exist but also satisfy the Cauchy-Riemann equations. Complex neural networks have different applications, e.g. Wolter and Yao <ref type="bibr" target="#b64">[65]</ref> proposed a complex-valued recurrent neural network which helps solving the exploding/vanishing gradients problem in RNNs. Complex-valued neural networks are easier to optimize than real-valued neural networks and have richer representational capacity <ref type="bibr" target="#b59">[60]</ref>. Considering the Liouville theorem <ref type="bibr" target="#b31">[32]</ref>, designing a fully complex differentiable (holomorphic) neural network is hard as only constant functions are both holomorph and bounded. Nevertheless, it was shown that in practice full complex differentiability of complex neural networks is not necessary <ref type="bibr" target="#b59">[60]</ref>.</p><p>In complex-valued neural networks, the complex convolution operator is defined as</p><formula xml:id="formula_18">W * h = (A * x ? B * y) + i(B * x + A * y),</formula><p>where W = A + iB and h = x + iy. A and B are real matrices and x and y are real vectors. We also apply the same operators on our graph signals and graph filters. The PyTorch framework <ref type="bibr" target="#b40">[41]</ref> utilizes Wirtinger calculus <ref type="bibr" target="#b21">[22]</ref> for backpropagation, which optimizes the real and imaginary partial derivatives independently. </p><formula xml:id="formula_19">(a) (b) (c) (d) (e) (f) (g) (h) (i)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Fully-supervised M?biusGCN</head><p>In the following, we compare the results of M?biusGCN in a fully-supervised setup with the previous state-of-the-art for 3D human pose estimation on the Human3.6M and MPI-INF-3DHP datasets. For this, we use a) estimated 2D poses using the stacked hourglass architecture (HG) <ref type="bibr" target="#b37">[38]</ref> as input and b) the 2D ground truth (GT).</p><p>Comparisons on Human3.6M. <ref type="table" target="#tab_0">Table 1</ref> shows the comparison of our M?biusGCN to the state-of-the-art methods under Protocol #1 on Human3.6M dataset.</p><p>By setting the number of channels to 128 in each block of the M?biusGCN (0.16M parameters), given estimated 2D joint positions (HG), we achieve an average MPJPE of 52.1mm over all actions and test subjects. Using the ground truth (GT) 2D joint positions as input, we achieve an MPJPE of 36.2mm. These results are on par with the state-of-the-art, i.e. GraphSH <ref type="bibr" target="#b65">[66]</ref>, which achieves 51.9mm and 35.8mm, respectively. Note, however, that M?biusGCN drastically reduces the number of training parameters by up to 96% (0.16M vs. 3.7M).</p><p>Reducing the number of channels to 64, we still achieve impressive results considering the lightness of our architecture (i.e. only 0.042M parameters). Compared to GraphSH <ref type="bibr" target="#b65">[66]</ref>, we reduce the number of parameters by 98.9% (0.042M vs 3.7M) and still achieve notable results, i.e. MPJPE of 40.0mm vs. 35.8mm (using 2D GT inputs) and 54.2mm vs. 51.9mm (using the 2D HG inputs). Note that GraphSH <ref type="bibr" target="#b65">[66]</ref> is the only approach which uses a better 2D pose estimator as input (CPN <ref type="bibr" target="#b6">[7]</ref> instead of HG <ref type="bibr" target="#b37">[38]</ref>). Nevertheless, our M?biusGCN (with 0.16M parameters) achieves competitive results. Furthermore, M?biusGCN outperforms the previously lightest architecture SemGCN <ref type="bibr" target="#b70">[71]</ref>, i.e. 40.0mm vs 43.8mm (using 2D GT inputs) and 54.2mm vs 60.8mm (using 2D HG input), although we require only 9.7% of their number of parameters (0.042M vs. 0.43M). <ref type="figure" target="#fig_3">Figure 3</ref> shows qualitative results of our M?biusGCN with 0.16M parameters on unseen subjects of the Human3.6M dataset given the 2D ground truth (GT) as input.   <ref type="bibr" target="#b33">[34]</ref>. Best in bold, second-best underlined.</p><p>Comparisons on MPI-INF-3DHP. The quantitative results on MPI-INF-3DHP <ref type="bibr" target="#b33">[34]</ref> are shown in <ref type="table" target="#tab_2">Table 2</ref>. Although we train M?biusGCN only on the Human3.6M <ref type="bibr" target="#b17">[18]</ref> dataset and our architecture is lightweight, the results indicate our strong generalization capabilities to unseen datasets, especially for the most challenging outdoor scenario. <ref type="figure" target="#fig_4">Figure 4</ref> shows some qualitative results on unseen self-occlusion examples from the test set of MPI-INF-3DHP dataset with M?biusGCN trained only on Human3.6M.</p><p>Though M?biusGCN for 3D human pose estimation has comparably fewer parameters, it is computationally expensive, i.e. O(n 3 ), both in the forward and backward pass due to the decomposition of the Laplacian matrix. In practice, however, this is not a concern for human pose estimation because of the small human pose graphs, i.e. ? 20 nodes. More specifically, a single forward pass takes on average only 0.001 s.   Comparison to Previous GCNs.  <ref type="bibr" target="#b65">[66]</ref>, which requires 0.44M parameters.</p><p>We also compare our proposed spectral GCN with the vanilla spectral GCN, i.e. Chebychev-GCN <ref type="bibr" target="#b20">[21]</ref>. Each block of Chebychev-GCN is the real-valued spectral GCN from <ref type="bibr" target="#b20">[21]</ref>. We use 7 blocks, similar to our M?biusGCN, with 128 channels each. Our complex-valued M?biusGCN with only 0.04M clearly outperforms the Chebychev-GCN <ref type="bibr" target="#b20">[21]</ref>   <ref type="table">Table 4</ref>: Semi-supervised quantitative comparison on Human3.6M <ref type="bibr" target="#b17">[18]</ref> under Protocol #1. Temp, MV, GT, and HG stand for temporal, multi-view, ground-truth, and stacked hourglass as 2D pose input respectively. Best in bold, second-best underlined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">M?biusGCN with Reduced Dataset</head><p>A major practical limitation with training neural network architectures is to acquire sufficiently large and accurately labeled datasets. Semi-supervised methods try to address this by combining fewer labeled samples with large amounts of unlabeled data. Another benefit of M?biusGCN is that we require fewer training samples. Having a better feature representation in M?biusGCN leads to a light architecture and therefore, requires less training samples.</p><p>To demonstrate this, we train M?biusGCN with a limited number of samples. In particular, we use only one subject to train M?biusGCN and do not need any unlabeled data. <ref type="table">Table 4</ref> compares the M?biusGCN to the semi-supervised approaches <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b49">50]</ref>, which were trained using both labeled and unlabeled data. As can be seen, M?biusGCN performs favorably: we achieve an MPJPE of 82.3mm (given 2D HG inputs) and an MPJPE of 62.3mm (using the 2D GT input). In contrast to previous works, we neither utilize other subjects as weak supervision nor need large unlabeled datasets during training.</p><p>As shown in <ref type="table">Table 4</ref>, M?biusGCN also outperforms methods which rely on multiview cues <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b49">50]</ref> or leverage temporal information <ref type="bibr" target="#b25">[26]</ref>. Additionally, we achieve better results to <ref type="bibr" target="#b18">[19]</ref>, even though, in contrast to this approach, we do not incorporate multiview information or require extensive amounts of unlabeled data during training. <ref type="table">Table 5</ref> analyzes the effect of increasing the number of training samples. As can be seen, our M?biusGCN only needs to train on three subjects to perform on par with SemGCN <ref type="bibr" target="#b70">[71]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Subject # Parameters MPJPE Ours S1 0.16M 62.3 Ours S1 S5 0.16M 47.9 Ours S1 S5 S6 0.16M 43.1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SemGCN [71]</head><p>All subjects 0.43M 43.8 <ref type="table">Table 5</ref>: Evaluating the effects of using fewer training subjects on Human3.6M <ref type="bibr" target="#b17">[18]</ref> under Protocol #1 (given 2D GT inputs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Discussion</head><p>We proposed a novel rational spectral GCN (M?biusGCN) to predict 3D human pose estimation by encoding the transformation between joints of the human body, given the human body joint positions in 2D. Our proposed method achieves state-of-the-art result accuracy while preserving the compactness of the model with lower number of parameters than the most compact model existing in the literature (lower number of parameters by an order of magnitude). We verified the generalizability of our model on the MPI-INF-3DHP dataset, where we achieve state-of-the-art results on the most challenging in-the-wild (outdoor) scenario. Our proposed simple and light-weight architecture requires less data for training. This allows us to outperform the previous lightest architecture by just training our model with three subjects on the Human3.6M dataset. We also showed promising results of our architecture in comparison to previous state-of-the-art semi-supervised architectures despite not using any temporal or multi-view information or large unlabeled datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Our M?biusGCN accurately learns the transformation (particularly the rotation) between joints by leveraging the M?bius transformation given estimated 2D joint positions from a single RGB image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>The complete pipeline of the proposed M?biusGCN architecture; The output of the off-the-shelf stacked hourglass architecture<ref type="bibr" target="#b37">[38]</ref>, i.e. estimated 2D joints of the human body, is the input to the M?biusGCN architecture. The M?biusGCN architecture locally encodes the transformation between the joints of the human body. SVD is the singular value decomposition of the normalized Laplacian matrix. Function g ? is the M?bius transformation applied on the eigenvalues of the eigenvalue matrix independently. x is the graph signal and ? are the learnable parameters, both in the complex domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(z) = az+b cz+d where a, b, c, d, z ? C satisfy ad ? bc ? = 0. The M?bius transformation can be expressed as the composition of simple transformations. Specifically, if c ? = 0, then: f 1 (z) = z + d/c defines translation by d/c, f 2 (z) = 1/z defines inversion and reflection with respect to the real axis, f 3 (z) = bc?ad c 2 z defines homothety and rotation, f 4 (z) = z + a/c defines the translation by a/c. These functions can be composed to form the M?bius transformation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Qualitative results of M?biusGCN on Human3.6M<ref type="bibr" target="#b17">[18]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Qualitative self-occlusion results of M?biusGCN on MPI-INF-3DHP [34] (trained only on Human3.6m).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Hossain and Little [17] 16.9M 48.4 50.7 57.2 55.2 63.1 72.6 53.0 51.7 66.1 80.9 59.0 57.3 62.4 46.7M 45.2 49.9 47.5 50.9 54.9 66.1 48.5 46.3 59.7 71.5 51.4 48.6 53.9 39.16M 31.2 46.9 32.5 31.7 41.4 44.9 33.9 30.9 49.2 55.7 35.9 36.1 37.5 29.</figDesc><table><row><cell>5 52.4</cell><cell>62.9</cell></row></table><note>Protocol #1 # Param. Dir. Disc. Eat Greet Phone Photo Pose Purch. Sit SitD. Smoke Wait WalkD. Walk WalkT. Average Martinez et al. [33] 4.2M 51.8 56.2 58.1 59.0 69.5 78.4 55.2 58.1 74.0 94.6 62.3 59.1 65.1 49.Quantitative comparisons w.r.t. MPJPE (in mm) on Human3.6M</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Results on the MPI-INF-3DHP test set</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Supervised quantitative comparison between GCN architectures on Human3.6M<ref type="bibr" target="#b17">[18]</ref> under Protocol #1. Best in bold, second-best underlined. All methods use 2D ground truth as input.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>shows our performance in comparison to previous GCN architectures. Besides significantly reducing the number of required parameters, applying the M?bius transformation also allows us to leverage better feature representations. Thus, M?biusGCN can outperform all other light-weight GCN architectures. It even achieves better results (36.2mm vs. 39.2mm) than the light-weight version of the state-of-the-art GraphSH</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>with 0.08M parameters (40.0mm vs. 110.6mm). This highlights the representational power of our M?biusGCN in contrast to vanilla spectral GCNs.</figDesc><table><row><cell>Method</cell><cell cols="3">Temp MV Input MPJPE</cell></row><row><cell cols="2">Rhodin et al. [50] ?</cell><cell cols="2">RGB 131.7</cell></row><row><cell>Pavlakos et al. [44]</cell><cell></cell><cell cols="2">RGB 110.7</cell></row><row><cell>Chen et al. [6]</cell><cell>?</cell><cell cols="2">HG 91.9</cell></row><row><cell>Li et al. [26]</cell><cell></cell><cell cols="2">? RGB 88.8</cell></row><row><cell>Ours (0.16M)</cell><cell>?</cell><cell cols="2">? HG 82.3</cell></row><row><cell>Iqbal et al. [19]</cell><cell>?</cell><cell>GT</cell><cell>62.8</cell></row><row><cell>Ours (0.16M)</cell><cell>?</cell><cell>? GT</cell><cell>62.3</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">2D Human Pose Estimation: New Benchmark and State of the Art Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Estimating anthropometry and pose from a single uncalibrated image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Barr?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kakadiaris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="269" to="284" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Graph Neural Networks with Convolutional Arma Filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Filippo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniele</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Grattarola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cesare</forename><surname>Livi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Alippi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>Early access article</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Geometric Deep Learning: Going Beyond Euclidean Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="42" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Spectral Networks and Locally Connected Networks on Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Weaklysupervised Discovery of Geometry-aware Representation for 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwan-Yee</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Cascaded Pyramid Network for Multi-Person Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Optimizing Network Structure for 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Ci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?l</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning Pose Grammar to Encode Human Body Configuration for 3D Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlu</forename><surname>Hao-Shu Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In AAAI</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hyperbolic Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Octavian</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Becigneul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS</title>
		<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Neural Message Passing for Quantum Chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Understanding the Difficulty of Training Deep Feedforward Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Inductive Representation Learning on Large Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Viton: An Image-based Virtual Try-on Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruichi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.05163</idno>
		<title level="m">Deep Convolutional Networks on Graph-structured Data</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exploiting Temporal Information for 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imtiaz</forename><surname>Mir Rayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hu-man3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Weakly-Supervised 3D Human Pose Learning via Multi-view Images in the Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umar</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavlo</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020. 4</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semi-supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Kreutz-Delgado</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0906.4835</idno>
		<title level="m">The Complex Gradient Operator and the CR-calculus</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cayleynets: Graph Nonvolutional Neural Networks with Complex Rational Spectral Filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Levie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Signal Process</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="97" to="109" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Generating Multiple Hypotheses for 3D Human Pose Estimation with Mixture Density Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Lifting Transformer for 3D Human Pose Estimation in Video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runwei</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pichao</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14304</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On Boosting Single-frame 3D Human Pose Estimation via Monocular Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peilin</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A Comprehensive Study of Weight Sharing in Graph Networks for 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenkun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongqi</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiming</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A Fully Convolutional Network for 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multi-task Neural Network with Physical Constraint for Real-time Multi-person 3D Pose Estimation from Monocular Camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingli</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songlin</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Ikenaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimed. Tools. Appl</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="27223" to="27244" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">2D/3D Pose Estimation and Action Recognition Using Multitask Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Diogo C Luvizon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hedi</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tabia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Context Modeling in 3D Human Pose Estimation: A Unified Perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Ci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Complex-valued Nonlinear Adaptive Filters: Noncircularity, Widely Linear and Neural Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Danilo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa Su Lee</forename><surname>Mandic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A Simple Yet Effective Baseline for 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julieta</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayat</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Monocular 3D Human Pose Estimation In The Wild Using Improved CNN Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3DV, 2017. 9</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Multiview-consistent Semi-supervised Learning for 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Gundavarapu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jain</surname></persName>
		</author>
		<idno>CVPR, 2020. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Rectified Linear Units Improve Restricted Boltzmann Machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Can Aykul, and Jens Lehmann. 5* Knowledge Graph Embeddings with Projective Transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mojtaba</forename><surname>Nayyeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sahar</forename><surname>Vahdati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Stacked Hourglass Networks for Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Complex-valued Neural Network with M?bius Activation Function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Necati</forename><surname>?zdemir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beyza</forename><surname>Biskender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nihal Y?lmaz</forename><surname>?zg?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun Nonlinear</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="4698" to="4703" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">View Independent Human Body Pose Estimation from a Single Perspective Image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasu</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-Performance Deep Learning Library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Coarse-to-fine Volumetric Prediction for Single-image 3D Human Pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konstantinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Ordinal Depth Supervision for 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Texturepose: Supervising Human Mesh Estimation with Texture Consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">3D Human Pose Estimation in Video with Temporal Convolutions and Semi-supervised Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Pavllo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Jointly Optimize Data Augmentation and Network Training: Adversarial Data Augmentation in Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rogerio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning Pose Specific Representations by Predicting Different Views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Poier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Schinagl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Reconstructing 3D Human Pose from 2D Image Landmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Ramakrishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Soccer on Your Tabletop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Rematas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Unsupervised Geometryaware Representation for 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning Monocular 3D Human Pose Estimation from Multi-view Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rg</forename><surname>Sp?rri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isinsu</forename><surname>Katircioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">MeTRAbs: Metric-Scale Truncation-Robust Heatmaps for Absolute 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Istv?n</forename><surname>S?r?ndi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timm</forename><surname>Linder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><forename type="middle">O</forename><surname>Arras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Biom. Behav. Identity Sci</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="30" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Learning 3D Object Orientation from Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashutosh</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Driemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Monocular 3D Human Pose Estimation by Generation and Ordinal Ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><forename type="middle">Teja</forename><surname>Varigonda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashast</forename><surname>Bindal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Temporally Consistent 3D Human Pose Estimation Using Dual 360deg Cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Shere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hansung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Hilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The Emerging Field of Signal Processing on Graphs: Extending High-dimensional Data Analysis to Networks and Other Irregular Domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David I Shuman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sunil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Frossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Ortega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Process. Mag</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="83" to="98" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">3D Human Motion Analysis in Monocular Video Techniques and Challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AVSS</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Compositional Human Pose Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxiang</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning to Fuse 2D and 3D Image Cues for Monocular Body Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bugra Tekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Marquez-Neila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiheb</forename><surname>Trabelsi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olexa</forename><surname>Bilaniuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Serdyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><forename type="middle">Felipe</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soroush</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Negar</forename><surname>Rostamzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">J</forename><surname>Pal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Deep Complex Networks. In ICLR</title>
		<imprint>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Adversarial Inverse Graphics Networks: Learning 2D-to-3D Lifting and Imageto-image Translation from Unpaired Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Yu Fish</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">W</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Seto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katerina</forename><surname>Fragkiadaki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Graph Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">CanonPose: Self-supervised Monocular 3D Human Pose Estimation in the Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petrissa</forename><surname>Zell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Deep Human Pose Estimation and Analysis for Personalized Athletic Training Assistance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houwen</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Coach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM-MM</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Complex Gated Recurrent Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Wolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Graph Stacked Hourglass Networks for 3D Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wataru</forename><surname>Takano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2021. 3, 9</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Spatial Temporal Graph Convolutional Networks for Skeleton-based Action Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">3D Human Pose Estimation in the Wild by Adversarial Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Monet: Multiview Semisupervised Keypoint Detection via Epipolar Divergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasamin</forename><surname>Jafarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><forename type="middle">Soo</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Ada-Fuse: Adaptive Multiview Fusion for Accurate Human Pose Estimation in the Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weichao</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhu</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="703" to="718" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Semantic Graph Convolutional Networks for 3D Human Pose Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubbasir</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Hemlets pose: Learning part-centric heatmap triplets for accurate 3D human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianjuan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangbo</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Data Augmentation with M?bius Transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharon</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiequan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torbj?rn</forename><surname>Lundh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
		<idno>2021. 4</idno>
	</analytic>
	<monogr>
		<title level="j">Mach. learn.: sci. technol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">25016</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Monocap: Monocular Human Motion Capture using a cnn Coupled with a Geometric Prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyridon</forename><surname>Leonardos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konstantinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="901" to="914" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Deep Kinematic Pose Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Towards 3D Human Pose Estimation in the Wild: a Weakly-supervised Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">On the Continuity of Rotation Representations in Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Connelly</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
