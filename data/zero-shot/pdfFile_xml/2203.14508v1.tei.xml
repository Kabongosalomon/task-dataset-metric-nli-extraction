<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Stratified Transformer for 3D Point Cloud Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI Informatics</orgName>
								<address>
									<addrLine>5 MIT</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhui</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI Informatics</orgName>
								<address>
									<addrLine>5 MIT</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI Informatics</orgName>
								<address>
									<addrLine>5 MIT</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI Informatics</orgName>
								<address>
									<addrLine>5 MIT</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI Informatics</orgName>
								<address>
									<addrLine>5 MIT</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI Informatics</orgName>
								<address>
									<addrLine>5 MIT</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI Informatics</orgName>
								<address>
									<addrLine>5 MIT</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><forename type="middle">Jiaya</forename><surname>Jia</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI Informatics</orgName>
								<address>
									<addrLine>5 MIT</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hku</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI Informatics</orgName>
								<address>
									<addrLine>5 MIT</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smartmore</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">MPI Informatics</orgName>
								<address>
									<addrLine>5 MIT</addrLine>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Stratified Transformer for 3D Point Cloud Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>3D point cloud segmentation has made tremendous progress in recent years. Most current methods focus on aggregating local features, but fail to directly model longrange dependencies. In this paper, we propose Stratified Transformer that is able to capture long-range contexts and demonstrates strong generalization ability and high performance. Specifically, we first put forward a novel key sampling strategy. For each query point, we sample nearby points densely and distant points sparsely as its keys in a stratified way, which enables the model to enlarge the effective receptive field and enjoy long-range contexts at a low computational cost. Also, to combat the challenges posed by irregular point arrangements, we propose first-layer point embedding to aggregate local information, which facilitates convergence and boosts performance. Besides, we adopt contextual relative position encoding to adaptively capture position information. Finally, a memory-efficient implementation is introduced to overcome the issue of varying point numbers in each window. Extensive experiments demonstrate the effectiveness and superiority of our method on S3DIS, ScanNetv2 and ShapeNetPart datasets. Code is available at https:// github.com/ dvlab-research/ Stratified-Transformer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Nowadays 3D point clouds can be conveniently collected. They have demonstrated great potential in various applications, such as autonomous driving, robotics and augmented reality. Unlike regular pixels in 2D images, 3D points are arranged irregularly, hampering direct adoption of well-studied 2D networks to process 3D data. Therefore, it is imperative to explore advanced methods that are tailored for 3D point cloud data.</p><p>Abundant methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b61">62]</ref>   <ref type="figure">Figure 1</ref>. Visualization of Effective Receptive Field (ERF) <ref type="bibr" target="#b28">[29]</ref>, given the feature of interest (shown with green star) in the output layer. Red region corresponds to high contribution. Left: Input point cloud and the ground truth. Middle: The ERF and prediction of the model without stratified strategy and by only attending to its own window. Right: The ERF and prediction of the model with direct long-range dependency, using the stratified strategy. More illustrations are shown in the supplementary file.</p><p>performance. Most of them focus on aggregating local features, but fail to explicitly model long-range dependencies, which has been demonstrated to be crucial in capturing contexts from a long distance <ref type="bibr" target="#b48">[49]</ref>. Along another line of research, Transformer <ref type="bibr" target="#b43">[44]</ref> can naturally harvest long-range information via the self-attention mechanism. However, only limited attempts <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b61">62]</ref> have been made to apply Transformer to 3D point clouds. Point Transformer <ref type="bibr" target="#b61">[62]</ref> proposes "vector self-attention" and "subtraction relation" to aggregate local features, but it is still difficult to directly capture long-range contexts. Voxel Transformer <ref type="bibr" target="#b30">[31]</ref> is tailored for object detection and performs self-attention over the voxels, but it loses accurate position due to voxelization. Differently, we develop an efficient segmentation network to capture long-range contexts using the standard multi-head self-attention <ref type="bibr" target="#b43">[44]</ref>, while keeping position information intact. To this end, we propose a simple and powerful framework, namely, Stratified Transformer.</p><p>Specifically, we first partition the 3D space into nonoverlapping cubic windows, inspired by Swin Transformer <ref type="bibr" target="#b25">[26]</ref>. However, in Swin Transformer, different windows work independently, and each query token only chooses the tokens within its window as keys, thus attend-ing to a limited local region. Instead, we propose a stratified strategy for sampling keys. Rather than only selecting nearby points in the same window as keys, we also sparsely sample distant points. In this way, for each query point, both denser nearby points and sparser distant points are sampled to form the keys all together, achieving a significantly enlarged effective receptive field while incurring negligible extra computations. For instance, we visualize the Effective Receptive Field (ERF) <ref type="bibr" target="#b28">[29]</ref> in <ref type="figure">Fig. 1</ref> to show the importance of modeling long-range contexts. In the middle of the figure, due to incapability to model the direct long-range dependency, the desk merely attends to the local region, leading to false predictions. Contrarily, with our proposed stratified strategy, the desk is able to aggregate contexts from distant objects, such as the bed or curtain, which helps to correct the prediction.</p><p>Moreover, it is notable that irregular point arrangements pose significant challenges in designing 3D Transformer. In 2D images, patch-wise tokens can be easily formed with spatially regular pixels. But 3D points are completely different. In our framework, each point is deemed as a token and we perform point embedding for each point to aggregate local information in the first layer, which is beneficial for faster convergence and stronger performance. Furthermore, we adopt effective relative position encoding to capture richer position information. It can generate the positional bias dynamically with contexts, through the interaction with the semantic features. Also, considering that 3D point numbers in different windows vary a lot and cause unnecessary memory occupation for windows with a small number of points, we introduce a memory-efficient implementation to significantly reduce memory consumption.</p><p>In total, our contribution is threefold:</p><p>? We propose Stratified Transformer to additionally sample distant points as keys but in a sparser way, enlarging the effective receptive field and building direct long-range dependency while incurring negligible extra computations.</p><p>? To handle irregular point arrangements, we design first-layer point embedding and effective contextual position encoding, along with a memory-efficient implementation, to build a strong Transformer tailored for 3D point cloud segmentation.</p><p>? Experiments show our model achieves state-of-theart results on widely adopted large-scale segmentation datasets, i.e., S3DIS <ref type="bibr" target="#b0">[1]</ref>, ScanNetv2 <ref type="bibr" target="#b9">[10]</ref> and ShapeNetPart <ref type="bibr" target="#b4">[5]</ref>. Extensive ablation studies verify the benefit of each component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Vision Transformer. Recently, vision Transformer <ref type="bibr" target="#b43">[44]</ref> becomes popular in 2D image understanding <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b62">63]</ref>. ViT <ref type="bibr" target="#b12">[13]</ref> treats each patch as a token, and directly uses a Transformer encoder to extract features for image classification. Further, PVT <ref type="bibr" target="#b47">[48]</ref> proposes a hierarchical structure to obtain a pyramid of features for semantic segmentation and also presents Spatial Reduction Attention to save memory. Alternatively, Swin Transformer <ref type="bibr" target="#b25">[26]</ref> uses a window-based attention, and proposes a shifted window operation in the successive Transformer block. Methods of <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b56">57]</ref> further propose different designs to incorporate long-range and global dependencies. Transformer is already popular in 2D, but remains under-explored on point clouds. Inspired by Swin Transformer, we adopt hierarchical structure and shifted window operation for 3D point cloud. On top of that, we propose a stratified strategy for sampling keys to harvest long-range contexts, and put forward several essential designs to combat the challenges posed by irregular point arrangements.</p><p>Point Cloud Segmentation. Approaches for point cloud segmentation can be grouped into two categories, i.e., voxel-based and the point-based methods. The voxel-based solutions <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref> first divide the 3D space into regular voxels, and then apply sparse convolutions upon them. They yield decent performance, but suffer from inaccurate position information due to voxelization. Point-based methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b32">[33]</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b53">[54]</ref><ref type="bibr" target="#b54">[55]</ref><ref type="bibr" target="#b55">[56]</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b61">62]</ref> directly adopt the point features and positions as inputs, thus keeping the position information intact. Following this line of research, different ways for feature aggregation are designed to learn high-level semantic features. PointNet and its variants <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref> use max pooling to aggregate features. PointConv <ref type="bibr" target="#b51">[52]</ref> and KPConv <ref type="bibr" target="#b40">[41]</ref> try to use an MLP or discrete kernel points to mimic a continuous convolution kernel. Point Transformer <ref type="bibr" target="#b61">[62]</ref> uses the "vector self-attention" operator to aggregate local features and the "subtraction relation" to generate the attention weights, but it suffers from lack of long-range contexts and insufficient robustness upon various perturbations in testing. Our work is pointed-based and closely related point transformer yet with a fundamental difference: ours overcomes the limited effective receptive field issue and makes the best of Transformer for modeling long-range contextual dependencies instead of merely local aggregation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Our Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overview</head><p>The overview of our model is illustrated in <ref type="figure" target="#fig_0">Fig. 2</ref>. Our framework is point-based, and we use both xyz coordinates and rgb colors as input. The encoder-decoder structure is adopted where the encoder is composed of multiple stages connected by downsample layers. At the beginning of the encoder, the first-layer point embedding module is used for local aggregation. Then, there are several Transformer blocks at each stage. As for the decoder, the encoder features are upsampled to become denser layer by layer in the way similar to U-Net <ref type="bibr" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Transformer Block</head><p>The Transformer block is composed of a standard multihead self-attention module and a feed-forward network (FFN). With tens of thousands of points as inputs, directly applying global self-attention incurs unacceptable O(N 2 ) memory consumption, where N is the input point number.</p><p>Vanilla Version. To this end, we employ window-based self-attention. The 3D space is firstly partitioned into nonoverlapping cubic windows, where the points are scattered in different windows. Instead of attending to all the points as in global self-attention, each query point only needs to consider neighbors in the same window. Multi-head selfattention is performed in each window independently. Since different windows may contain varying numbers of points, we denote k t as the number of points within the t-th window. Formally, given that N h is the number of heads, N d is the dimension of each head and N c = N h ? N d is the feature dimension, for the input points in the t-th window x ? R kt?(N h ?N d ) , the multi-head self-attention in the t-th window is formulated as</p><formula xml:id="formula_0">q = Linear q (x), k = Linear k (x), v = Linear v (x), attn i,j,h = q i,h ? k j,h , attn i,.,h = sof tmax(attn i,.,h ),<label>(1)</label></formula><formula xml:id="formula_1">y i,h = kt j=1? ttn i,j,h ? v j,h , z = Linear(y),</formula><p>where q, k, v ? R kt?N h ?N d are obtained from x by three linear layers, and ? means dot product between vectors q i,h The green star denotes the given query point. and k j,h . attn ? R kt?kt?N h is the attention map, and y ? R kt?N h ?N d is the aggregated feature, which is further projected to the output feature? ? R kt?(N h ?N d ) . Note that the above equations only show the calculation in a single window, and different windows work in the same way independently. In this way, the memory complexity is</p><formula xml:id="formula_2">dramatically reduced to O( N k ? k 2 ) = O(N ? k),</formula><p>where k is the average number of points scattered in each window.</p><p>To facilitate cross-window communication, we also shift the window by half of the window size between two successive Transformer blocks, similar to <ref type="bibr" target="#b25">[26]</ref>. The illustration of shifted window is given in the supplementary file. Stratified Key-sampling Strategy. Since every query point only attends to the local points in its own window, the vanilla version Transformer block suffers from limited effective receptive field even with shifted window, as shown in <ref type="figure">Fig. 1</ref>. Therefore, it fails to capture long-range contextual dependencies over distant objects, causing false predictions.</p><p>A simple solution is to enlarge the size of cubic window. However, the memory would grow as the window size increases. To effectively aggregate long-range contexts at a low cost of memory, we propose a stratified strategy  for sampling keys. As shown in <ref type="figure" target="#fig_1">Fig. 3</ref>, we partition the space into non-overlapping cubic windows with the window size s win . For each query point q i (shown with green star), we find the points K dense i in its window, same as the vanilla version. Additionally, we downsample the input points through farthest point sampling (fps) at the scale of s, and find the points K sparse i with a larger window size s large win . In the end, both dense and sparse keys form the final keys, i.e., K i = K dense i ? K sparse i . Note that duplicated key points are only counted once.</p><p>The complete structure of Stratified Transformer block is shown in <ref type="figure" target="#fig_0">Fig. 2 (b)</ref>. Following common practice, we use LayerNorm <ref type="bibr" target="#b2">[3]</ref> before each self-attention module or feedforward network. To further complement the information interaction across windows, the original window is shifted by <ref type="bibr" target="#b0">1</ref> 2 s win while the large window is shifted by 1 2 s large win in the successive Transformer block. This further boosts the performance as listed in <ref type="table">Table 7</ref>.</p><p>Thanks to the stratified strategy for key sampling, the effective receptive field is enlarged remarkably and the query feature is able to effectively aggregate long-range contexts. Compared to the vanilla version, we merely incur the extra computations on the sparse distant keys, which only takes up about 10% of the final keys K i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">First-layer Point Embedding</head><p>In the first layer, we build a point embedding module. An intuitive choice is to use a linear layer or MLP to project the input features to a high dimension. However, we empirically observe relatively slow convergence and poor performance by using a linear layer in the first layer, as shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. We note that the point feature from a linear layer or MLP merely comprises the raw information of its own xyz position and the rgb color, but it lacks local geometric and contextual information. As a result, in the first Transformer block, the attention map could not capture high-level relevance between the queries and keys that only contain raw xyz and rgb information. This negatively affects representation power and generalization ability of the model.</p><p>We contrarily propose to aggregate the features of local neighbors for each point in the Point Embedding module.</p><p>We try a variety of methods for local aggregation, such as max pooling and average pooling, and find KPConv performs the best, as shown in <ref type="table">Table 5</ref>. Surprisingly, this minor modification to the architecture brings about considerable improvement as suggested in Exp.I and II as well as Exp.V and VI of <ref type="table">Table 4</ref>. It proves the importance of initial local aggregation in the Transformer-based networks. Note that a single KPConv incurs negligible extra computations (merely 2% FLOPs) compared to the whole network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Contextual Relative Position Encoding</head><p>Compared to 2D spatially regular pixels, 3D points are in a more complicated continuous space, posing challenges to exploit the xyz position. <ref type="bibr" target="#b31">[32]</ref> claims that position encoding is unnecessary for 3D Transformer-based networks because the xyz coordinates have already been used as the input features. However, although the input of the Transformer block has already contained the xyz position, fine-grained position information may be lost in high-level features when going deeper through the network. To make better use of the position information, we adopt a context-based adaptive relative position encoding scheme inspired by <ref type="bibr" target="#b50">[51]</ref>.</p><p>Particularly, for the point features x ? R kt?(N h ?N d ) in the t-th window, we denote the xyz coordinates as p ? R kt?3 . So, the relative xyz coordinates r ? R kt?kt?3 between the queries and keys are formulated as</p><formula xml:id="formula_3">r i,j,m = p i,m ? p j,m , 1 ? i, j ? kt, m ? {1, 2, 3}.<label>(2)</label></formula><p>To map relative coordinates to the corresponding position encoding, we maintain three learnable look-up tables t x , t y , t z ? R L?(N h ?N d ) corresponding to x, y and z axis, respectively. As the relative coordinates are continuous floating-point numbers, we uniformly quantize the range of r i,j,m , i.e., (?s win , s win ) into L discrete parts and map the relative coordinates r i,j,m to the indices of the tables as</p><formula xml:id="formula_4">idx i,j,m = ? r i,j,m + s win squant ?,<label>(3)</label></formula><p>where s win is the window size and s quant = 2?swin L is the quantization size, and ??? denotes floor rounding.</p><p>We look up the tables to retrieve corresponding embedding with the index and sum them up to obtain the position encoding of</p><formula xml:id="formula_5">e i,j = tx[idx i,j,1 ] + ty[idx i,j,2 ] + tz[idx i,j,3 ],<label>(4)</label></formula><p>where t[idx] ? R N h ?N d means the idx-th entry of the table t, and e ? R kt?kt?N h ?N d is the position encoding. Practically, the tables for query, key and value are not shared. So we differentiate among them by adding a superscript, where t q x denotes the x-axis table for the query. Similarly, the position encoding corresponding to query, key and value is denoted by e q , e k and e v , respectively.</p><p>Then the position encoding performs dot product with the query and key feature to obtain the positional bias Compared to the MLP-based position encoding, where the relative xyz coordinates r ? R kt?kt?3 are directly projected to the positional bias pe bias ? R kt?kt?N h via an MLP, cRPE adaptively generates the positional bias through the dot product with queries and keys, thus providing semantic information. The positional bias of the MLP-based and cRPE are visualized in <ref type="figure">Fig. 5</ref>. It reveals the fact that the positional bias generated by the MLP-based model is similar among the keys. So it makes little difference to the attention weights. But for cRPE, the positional bias varies a lot for different keys. Besides, Exp. III and IV and Exp. V and VIII of <ref type="table">Table 4</ref> also show the superiority of cRPE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Downsample and Upsample Layers</head><p>The Downsample Layer is shown in <ref type="figure">Fig. 6 (a)</ref>. First, the xyz coordinates p s go through the Sampling &amp; Grouping module, where we first sample centroid points p s+1 by fathest point sampling (fps) <ref type="bibr" target="#b34">[35]</ref> and then use kNN to query the original points to get the grouping index idx group ? R Ns+1?k . The number of centroid points is <ref type="bibr">1 4</ref> of the original points, i.e., N s+1 = ? 1 4 N s ?. Meanwhile, the point fea-  For the upsample layer, as shown in <ref type="figure">Fig. 6 (b)</ref>, the decoder features x ? s are firstly projected by a Pre-LN linear layer. We perform interpolation <ref type="bibr" target="#b34">[35]</ref> between current xyz coordinates p s and the previous ones p s?1 . The encoder point features in the previous stage x s?1 go through a Pre-LN linear layer. Finally, we sum them up to yield the next decoder features x ? s?1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Memory-efficient Implementation</head><p>In 2D Swin Transformer, it is easy to implement the window-based attention because the number of tokens is fixed in each window. Nevertheless, due to the irregular point arrangements in 3D, the number of the tokens in each window varies a lot. A simple solution is to pad the tokens in each window to the maximum token number k max with dummy tokens, and then apply a masked self-attention. But this solution wastes much memory and computations.</p><p>Instead, we first pre-compute all pairs of query and key that need to perform dot product. As shown in <ref type="figure" target="#fig_6">Fig. 7 (a)</ref>, we use two indices of index q , index k ? R M , to index the q and k of shape (N, N h , N d ), respectively, where N denotes the total number of input points. Then, we perform dot product between the entries indexed by index q and index k , yielding the attention map attn of the shape (M, N h ). Afterwards, as shown in <ref type="figure" target="#fig_6">Fig. 7 (b)</ref>, we perform the scatter softmax directly on attn with the query index index q , where the softmax function is applied on the entries in attn with the same index in index q . Further, as shown in <ref type="figure" target="#fig_6">Fig. 7 (c)</ref>, we use index k to index the values v and multiply them with the attention map attn. We finally sum up the entries with the same index in index q and save the results into the output features y. Note that each of the steps is implemented by a single CUDA kernel. So the intermediate variables inside each step hardly occupy memory. In this way, we reach the memory complexity of O(M ?N h ), much less than that used in vanilla implementation. More detailed memory complexity analysis and discussion of po-sition encoding implementation are given in the supplementary file. Our implementation saves 57% memory compared to the vanilla one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experimental Setting</head><p>Network Architecture. The main architecture is shown in <ref type="figure" target="#fig_0">Fig. 2</ref>. Both the xyz coordinates and rgb colors are used as inputs. We set the initial feature dimension and number of heads to 48 and 3 respectively, and they will double in each downsample layer. As for S3DIS, four stages are constructed with the block depths <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b1">2]</ref>. In contrast, for ScanNetv2, we note that the point number is larger. So we add an extra downsample layer on top of the first-layer point embedding module. Then, the later four stages with block depths <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b2">3]</ref> are added. So a total of five stages are constructed for ScanNetv2.</p><p>Implementation Detail. For S3DIS, following previous work <ref type="bibr" target="#b61">[62]</ref>, we train for 76, 500 iterations with 4 RTX 2080Ti GPUs. The batch size is set to 8. Following common practice, the raw input points are firstly grid sampled with the grid size set to 0.04m. During training, the maximum input points number is set to 80, 000, and all extra ones are discarded if points number reaches this number. The window size is set to 0.16m initially, and it doubles after each downsample layer. The downsample scale for the stratified sampling strategy is set to 8. Unless otherwise specified, we use z-axis rotation, scale, jitter and drop color as data augmentation.</p><p>For ScanNetv2, we train for 600 epochs with weight decay and batch size set to 0.1 and 8 respectively, and the grid size for grid sampling is set to 0.02m. At most 120, 000 points of a point cloud are fed into the network during training. The initial window size is set to 0.1m. And the downsample scale for the stratified sampling is set to 4. Except random jitter, the data augmentation is the same as that on S3DIS. The implementation details for ShapeNetPart and the datasets descriptions are given in the supplementary file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results</head><p>We make comparisons with recent state-of-the-art semantic segmentation methods. <ref type="table" target="#tab_1">Tables 1 and 2</ref> show the results on S3DIS and ScanNetv2 datasets. Our method achieves state-of-the-art performance on both challenging datasets. On S3DIS, ours outperforms others significantly, even higher than Point Transformer [62] by 1.6% mIoU. On ScanNetv2, the validation mIoU of our method surpasses others including voxel-based methods, with a gap of 2.1% mIoU. On the test set, ours achieves slightly higher results than MinkowskiNet <ref type="bibr" target="#b6">[7]</ref>. The potential reason may be the points in ScanNetv2 are relatively sparse. So the loss of accurate position in voxelization is negligible for voxelbased methods. But on S3DIS where points are denser, our method outperforms MinkowskiNet with a huge gap, i.e., 6.6% mIoU. Also, ours outperforms MinkowskiNet by 2.1% mIoU on the validation set and is much more robust than MinkowskiNet when encountering various perturbations in testing, as shown in <ref type="table" target="#tab_8">Table 9</ref>. Notably, it is the first time for the point-based methods to achieve higher performance compared with voxel-based methods on ScanNetv2. Also, in <ref type="table">Table 3</ref>, to show the generalization ability, we also make comparison on ShapeNetPart <ref type="bibr" target="#b4">[5]</ref> for the task of part segmentation. Our method outperforms previous ones and achieves new state of the art in terms of both category mIoU and instance mIoU. Although the instance mIoU of ours is comparable to Point Transformer, ours outperforms  Point Transformer by a large margin in category mIoU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Ablation Study</head><p>We conduct extensive ablation studies to verify the effectiveness of each component in our method, and show results in <ref type="table">Table 4</ref>. To make our conclusions more convincing, we make evaluations on both S3DIS and ScanNetv2 datasets. From Exp.I to V, we add one component each time. Also, from Exp.VI to VIII, we make double verification by removing each component from the final model, i.e., Exp.V.</p><p>Stratified Transformer. In <ref type="table">Table 4</ref>, comparing Exp.IV and V, we notice that with the stratified strategy, the model improves with 1.9% mIoU on S3DIS and 1.2% mIoU on ScanNetv2. Combining the visualizations in <ref type="figure">Fig. 1</ref>, we note that the stratified strategy is able to enlarge the effective receptive field and boost the performance. Besides, we also show the effect when setting different downsample scales, i.e., 4, 8 and 16, in the supplementary file.</p><p>First-layer Point Embedding. We compare Exp.I with II, and find the model improves by a large margin with firstlayer point embedding. Also, we compare Exp.VI and V,  where the model gets 2.0% mIoU gain on S3DIS and 4.0% mIoU gain on ScanNetv2 with the equipment of first-layer point embedding. This minor modification in the architecture brings considerable benefit. To further explore the role of local aggregation in firstlayer point embedding, we compare different ways of local aggregation with linear projection in <ref type="table">Table 5</ref>. Obviously, all listed local aggregation methods are better than linear projection for the first-layer point embedding.</p><p>Contextual Relative Position Encoding. From Exp.III to IV, the performance increases by 2.9% mIoU on S3DIS and 1.9% mIoU on ScanNetv2 after using cRPE. Moreover, when also using the stratified Transformer, the model still improves with 4.0% mIoU gain on S3DIS and 2.3% gain on ScanNetv2 equipped with cRPE, through the comparison between Exp.VIII and V.</p><p>Further, we testify the contribution of applying cRPE on each of the query, key or value features. <ref type="table">Table 6</ref> shows that applying cRPE in either feature can make improvement. When applying cRPE on query, key and value simultaneously, the model achieves the best performance.</p><p>In addition, we compare our approach with the MLPbased method as mentioned in Sec. 3.4. As shown in Table 6, we find the MLP-based method (the first column) actually makes no difference with the model without any position encoding (the second column). Combining the visualization in <ref type="figure">Fig. 5</ref>, we conclude that the relative position information purely based on xyz coordinates is not helpful, since input point features to the network have already incorporated the xyz coordinates. In contrast, cRPE is based on both xyz coordinates and contextual features.</p><p>Shifted Window. Shifted window is adopted to complement information interaction across windows. In <ref type="table">Table 7</ref>, we compare the models w/ and w/o shifted window for both our vanilla version and Stratified Transformer on S3DIS. Evidently, shifted window is effective in our framework.  <ref type="table">Table 8</ref>. Ablation study on data augmentation evaluated on S3DIS.</p><p>Moreover, even without shifted window, Stratified Transformer still yields higher performance, i.e., 70.1% mIoU, compared to the vanilla version. Also, shifting on both original and large windows is beneficial.</p><p>Data Augmentation. Data augmentation plays an important role in training Transformer-based network. It is also the case in our framework as shown in Exp.V and VII as well as Exp.II and III. We also investigate the contribution of each augmentation in <ref type="table">Table 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Robustness Study</head><p>To show the anti-interference ability of our model, we measure the robustness by applying a variety of perturbations in testing. Following <ref type="bibr" target="#b53">[54]</ref>, we make evaluations in aspects of permutation, rotation, shift, scale and jitter. As shown in <ref type="table" target="#tab_8">Table 9</ref>, our method is extremely robust to various perturbations, while previous methods fluctuate drastically under these scenarios. It is notable that ours performs even better (+0.63% mIoU) with 90 ? z-axis rotation.</p><p>Although Point Transformer also employs the selfattention mechanism, it yields limited robustness. A potential reason may be Point Transformer uses special operator  designs such as "vector self-attention" and "subtraction relation", rather than standard multi-head self-attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Visual Comparison</head><p>In <ref type="figure">Fig. 8</ref>, we visually compare Point Transformer, the baseline model and ours. It clearly shows the superiority of our method. Due to the awareness of long-range contexts, our method is able to recognize the objects highlighted with yellow box, while others fail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We propose Stratified Transformer and achieve state-ofthe-art results. The stratified strategy significantly enlarges the effective receptive field. Also, first-layer point embedding and an effective contextual relative position encoding are put forward. Our work answers two questions. First, it is possible to build direct long-range dependencies at low computational costs and yield higher performance. Second, standard Transformer can be applied to 3D point cloud with strong generalization ability and powerful performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>LinearFigure 2 .</head><label>2</label><figDesc>(a) Framework Overview. (b) Structure of Stratified Transformer Block. Hierarchical structure is employed to obtain multilevel features. Input point clouds firstly go through the Point Embedding module to aggregate local structure information. After several downsample layers and transformer blocks, the features are upsampled for segmentation. SSA: Stratified Self-attention. Shifted SSA: SSA with shifted window. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Illustration of the stratified strategy for keys sampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>mIoU: w/ point embedding Val mIoU: w/o point embedding</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Plot of training loss (solid line) and validation mIoU (dotted line) in the training process. The models w/ (blue curve) and w/o (orange curve) first-layer point embedding are compared.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>Visualization of the positional bias of each key at the first head of the last transformer block given the query point (shown with green star). The color map is shown on the right. Structural illustration of (a) Downsample Layer and (b) Upsample Layer.pos bias ? R kt?kt?N h , which is then added to the attention map. Also, we add the value feature with its corresponding position encoding, followed by the weighted sum aggregation. Finally, the original equations Eq. (1) are updated to the contextual Relative Position Encoding (cRPE) version of pos bias cRP E i,j,h = q i,h ? e q i,j,h + k j,h ? e k i,j,h , attn cRP E i,j,h = q i,h ? k j,h + pos bias cRP E i,j,h , ,h ? (v j,h + e v i,j,h ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Memory-efficient implementation includes three steps: (a) dot product; (b) scatter softmax; (c) weighted sum. It is best viewed in color and by zoom-in. tures x s are fed into a Pre-LN [53] linear projection layer. Further, we exploit max pooling to aggregate the projected features using the grouping index, yielding the output features x s+1 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>have explored 3D point cloud segmentation and obtained decent</figDesc><table><row><cell cols="2">Input / Ground Truth</cell><cell cols="2">w/o stratified</cell><cell></cell><cell cols="2">w/ stratified</cell></row><row><cell>bed</cell><cell>chair</cell><cell>curtain</cell><cell>desk</cell><cell>floor</cell><cell>table</cell><cell>wall</cell></row><row><cell>Equal Contribution</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>? Corresponding Author</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Results on ScanNetv2 for semantic segmentation. More results and analysis are included in the supplementary file.</figDesc><table><row><cell>Method</cell><cell>Input</cell><cell>OA</cell><cell cols="2">mAcc mIoU</cell></row><row><cell>PointNet [34]</cell><cell>point</cell><cell>-</cell><cell>49.0</cell><cell>41.1</cell></row><row><cell>SegCloud [40]</cell><cell>point</cell><cell>-</cell><cell>57.4</cell><cell>48.9</cell></row><row><cell>TangentConv [39]</cell><cell>point</cell><cell>-</cell><cell>62.2</cell><cell>52.6</cell></row><row><cell>PointCNN [22]</cell><cell cols="2">point 85.9</cell><cell>63.9</cell><cell>57.3</cell></row><row><cell>PointWeb [61]</cell><cell cols="2">point 87.0</cell><cell>66.6</cell><cell>60.3</cell></row><row><cell>HPEIN [19]</cell><cell cols="2">point 87.2</cell><cell>68.3</cell><cell>61.9</cell></row><row><cell>GACNet [45]</cell><cell cols="2">point 87.8</cell><cell>-</cell><cell>62.9</cell></row><row><cell>PAT [58]</cell><cell>point</cell><cell>-</cell><cell>70.8</cell><cell>60.1</cell></row><row><cell>ParamConv [46]</cell><cell>point</cell><cell>-</cell><cell>67.0</cell><cell>58.3</cell></row><row><cell>SPGraph [20]</cell><cell cols="2">point 86.4</cell><cell>66.5</cell><cell>58.0</cell></row><row><cell>SegGCN [21]</cell><cell cols="2">point 88.2</cell><cell>70.4</cell><cell>63.6</cell></row><row><cell>MinkowskiNet [7]</cell><cell>voxel</cell><cell>-</cell><cell>71.7</cell><cell>65.4</cell></row><row><cell>PAConv [54]</cell><cell>point</cell><cell>-</cell><cell>-</cell><cell>66.6</cell></row><row><cell>KPConv [41]</cell><cell>point</cell><cell>-</cell><cell>72.8</cell><cell>67.1</cell></row><row><cell cols="3">PointTransformer [62] point 90.8</cell><cell>76.5</cell><cell>70.4</cell></row><row><cell>Ours</cell><cell cols="2">point 91.5</cell><cell>78.1</cell><cell>72.0</cell></row><row><cell cols="5">Table 1. Results on S3DIS Area5 for semantic segmentation.</cell></row><row><cell>Method</cell><cell cols="4">Input Val mIoU Test mIoU</cell></row><row><cell>PointNet++ [35]</cell><cell>point</cell><cell>53.5</cell><cell></cell><cell>55.7</cell></row><row><cell>3DMV [11]</cell><cell>point</cell><cell>-</cell><cell></cell><cell>48.4</cell></row><row><cell>PanopticFusion [33]</cell><cell>point</cell><cell>-</cell><cell></cell><cell>52.9</cell></row><row><cell>PointCNN [22]</cell><cell>point</cell><cell>-</cell><cell></cell><cell>45.8</cell></row><row><cell>PointConv [52]</cell><cell>point</cell><cell>61.0</cell><cell></cell><cell>66.6</cell></row><row><cell>JointPointBased [6]</cell><cell>point</cell><cell>69.2</cell><cell></cell><cell>63.4</cell></row><row><cell>PointASNL [56]</cell><cell>point</cell><cell>63.5</cell><cell></cell><cell>66.6</cell></row><row><cell>SegGCN [21]</cell><cell>point</cell><cell>-</cell><cell></cell><cell>58.9</cell></row><row><cell>RandLA-Net [17]</cell><cell>point</cell><cell>-</cell><cell></cell><cell>64.5</cell></row><row><cell>KPConv [41]</cell><cell>point</cell><cell>69.2</cell><cell></cell><cell>68.6</cell></row><row><cell>JSENet [18]</cell><cell>point</cell><cell>-</cell><cell></cell><cell>69.9</cell></row><row><cell>FusionNet [59]</cell><cell>point</cell><cell>-</cell><cell></cell><cell>68.8</cell></row><row><cell cols="2">PointTransformer [62] point</cell><cell>70.6</cell><cell></cell><cell>-</cell></row><row><cell>SparseConvNet [15]</cell><cell>voxel</cell><cell>69.3</cell><cell></cell><cell>72.5</cell></row><row><cell>MinkowskiNet [7]</cell><cell>voxel</cell><cell>72.2</cell><cell></cell><cell>73.6</cell></row><row><cell>Ours</cell><cell>point</cell><cell>74.3</cell><cell></cell><cell>73.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .Table 4 .</head><label>34</label><figDesc>Results on ShapeNetPart for part segmentation. Ablation study. PointEmb: First-layer Point Embedding.</figDesc><table><row><cell cols="3">ID PointEmb Aug cRPE Stratified S3DIS ScanNet</cell></row><row><cell>I</cell><cell>56.8</cell><cell>56.8</cell></row><row><cell>II</cell><cell>61.3</cell><cell>69.6</cell></row><row><cell>III</cell><cell>67.2</cell><cell>70.6</cell></row><row><cell>IV</cell><cell>70.1</cell><cell>72.5</cell></row><row><cell>V</cell><cell>72.0</cell><cell>73.7</cell></row><row><cell>VI</cell><cell>70.0</cell><cell>69.7</cell></row><row><cell>VII</cell><cell>66.1</cell><cell>72.3</cell></row><row><cell>VIII</cell><cell>68.0</cell><cell>71.4</cell></row></table><note>Aug: Data Augmentation. cRPE: contextual Relative Position En- coding. Stratified: Stratified Transformer Block. Metric: mIoU.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .Table 6 .</head><label>56</label><figDesc>Comparison among different ways of first-layer point embedding on S3DIS. PointTrans block: Point Transformer block. Ablation study on cRPE. We evaluate on the S3DIS dataset. Query, Key and Value: applying the cRPE on the corresponding features to get positional bias. MLP: MLP-based relative position encoding.</figDesc><table><row><cell>Query</cell></row><row><cell>Key</cell></row><row><cell>Value</cell></row><row><cell>MLP</cell></row><row><cell>mIoU 68.0 68.0 70.2 70.5 70.8 70.8 71.0 70.8 72.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Method None Perm. 90 ? 180 ? 270 ? +0.2 ?0.2 ?0.8 ?1.2 jitter PointNet++ 59.75 59.71 58.15 57.18 58.19 22.33 29.85 56.24 59.74 59.05 Minkowski 64.68 64.56 63.45 63.83 63.36 64.59 64.96 59.60 61.93 58.96 PAConv 65.63 65.64 61.66 63.48 61.80 55.81 57.42 64.20 63.94 65.12 PointTrans 70.36 70.45 65.94 67.78 65.72 70.44 70.43 65.73 66.15 59.67 Ours 71.96 72.02 72.59 72.37 71.86 71.99 71.93 70.42 71.21 72.02</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 .</head><label>9</label><figDesc>Robustness study on S3DIS. We apply the perturbations of permutation (Perm.), z-axis rotation (90 ? , 180 ? , 270 ? ), shifting (?0.2), scaling (?0.8, ?1.2) and jitter in testing. PointTrans: Point Transformer<ref type="bibr" target="#b61">[62]</ref>.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The work is supported in part by Hong Kong Research Grant Council -Early Career Scheme (Grant No. 27209621), HKU Startup Fund, HKU Seed Fund for Basic Research, and SmartMore donation fund.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ioannis Brilakis, Martin Fischer, and Silvio Savarese. 3d semantic parsing of large-scale indoor spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Point convolutional neural networks by extension operators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matan</forename><surname>Atzmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haggai</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaron</forename><surname>Lipman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOG</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Layer normalization. Stat</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">End-toend object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pat</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zimo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03012</idno>
		<title level="m">An information-rich 3d model repository</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A unified point-based framework for 3d segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung-Yueh</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueh-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Winston H</forename><surname>Hsu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">4d spatio-temporal convnets: Minkowski convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Icm-3d: Instantiated category modeling for 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Twins: Revisiting the design of spatial attention in vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxia</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.13840</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Scannet: Richly-annotated 3d reconstructions of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Joint 3d-multiview prediction for 3d semantic scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Cswin transformer: A general vision transformer backbone with cross-shaped windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.00652</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dilated point convolutions: On the receptive field size of point convolutions on 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theodora</forename><surname>Kontogianni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">and Laurens van der Maaten. 3d semantic segmentation with submanifold sparse convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Engelcke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.01307</idno>
		<title level="m">Submanifold sparse convolutional networks</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Randla-net: Efficient semantic segmentation of large-scale point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhai</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Trigoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Markham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Jsenet: Joint semantic segmentation and edge detection network for 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingmin</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuyang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbo</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiew-Lan</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hierarchical point-edge interaction network for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Large-scale point cloud semantic segmentation with superpoint graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Landrieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Simonovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Seggcn: Efficient 3d point cloud segmentation with fuzzy spherical kernel</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveed</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajmal</forename><surname>Mian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pointcnn: Convolution on x-transformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingchao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhan</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Point2sequence: Learning the shape representation of 3d point clouds with an attention-based sequence to sequence network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizhong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Shen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zwicker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Densepoint: Learning densely contextual representation for efficient point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Shiming Xiang, and Chunhong Pan</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note>ICCV</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Shiming Xiang, and Chunhong Pan. Relation-shape convolutional neural network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV, 2021. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pointvoxel cnn for efficient 3d deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haotian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Group-free 3d object detection via transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Understanding the effective receptive field in deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interpolated convolutional networks for 3d point cloud understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiageng</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Voxel transformer for 3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiageng</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujing</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minzhe</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyue</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An endto-end transformer model for 3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Girdhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Panopticfusion: Online volumetric semantic mapping at the level of stuff and things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaku</forename><surname>Narita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Seno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoya</forename><surname>Ishikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohsuke</forename><surname>Kaji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Point-net++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Splatnet: Sparse lattice networks for point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.05790</idno>
		<title level="m">Visual parser: Representing part-whole hierarchies with transformers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Tangent convolutions for dense prediction in 3d</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Tatarchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesik</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian-Yi</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Segcloud: Semantic segmentation of 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lyne</forename><surname>Tchapmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3DV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Kpconv: Flexible and deformable convolution for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Emmanuel</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatriz</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Training data-efficient image transformers &amp; distillation through attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Jegou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.17239</idno>
		<title level="m">Alexandre Sablayrolles, Gabriel Synnaeve, and Herv? J?gou. Going deeper with image transformers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Graph attention convolution for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaolin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenman</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Shan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep parametric continuous convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Suo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chiu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Pokrovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng-Ping</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaitao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.13797</idno>
		<title level="m">Pvtv2: Improved baselines with pyramid vision transformer</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Pyramid vision transformer: A versatile backbone for dense prediction without convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng-Ping</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaitao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Abhinav Gupta, and Kaiming He. Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sanjay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOG</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Rethinking and improving relative position encoding for vision transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houwen</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Chao</surname></persName>
		</author>
		<idno>ICCV, 2021. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Pointconv: Deep convolutional networks on 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fuxin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">On layer normalization in the transformer architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruibin</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuxin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huishuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieyan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Paconv: Position adaptive convolution with dynamic kernel assembling on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mutian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runyu</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Spidercnn: Deep learning on point sets with parameterized convolutional filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingye</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Pointasnl: Robust point clouds processing using nonlocal neural networks with adaptive sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoda</forename><surname>Xu Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Focal selfattention for local-global interactions in vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengchuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Modeling point clouds with self-attention and gumbel subset sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiancheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengdie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Deep fusionnet for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feihu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Exploring self-attention for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Pointweb: Enhancing local neighborhood features for point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Point transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deformable detr: Deformable transformers for end-to-end object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xizhou</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
