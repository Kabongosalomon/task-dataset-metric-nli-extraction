<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HateBERT: Retraining BERT for Abusive Language Detection in English</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
							<email>?t.caselli@rug.nl?jelena.mitrovic|michael.granitzer@uni-passau.de</email>
							<affiliation key="aff0">
								<orgName type="department">?University of Passau Groningen The Netherlands</orgName>
								<orgName type="institution" key="instit1">University of Groningen</orgName>
								<orgName type="institution" key="instit2">University of Turin</orgName>
								<address>
									<settlement>Turin Italy, Passau</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerio</forename><surname>Basile</surname></persName>
							<email>valerio.basile@unito.it</email>
							<affiliation key="aff0">
								<orgName type="department">?University of Passau Groningen The Netherlands</orgName>
								<orgName type="institution" key="instit1">University of Groningen</orgName>
								<orgName type="institution" key="instit2">University of Turin</orgName>
								<address>
									<settlement>Turin Italy, Passau</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jelena</forename><surname>Mitrovi?</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">?University of Passau Groningen The Netherlands</orgName>
								<orgName type="institution" key="instit1">University of Groningen</orgName>
								<orgName type="institution" key="instit2">University of Turin</orgName>
								<address>
									<settlement>Turin Italy, Passau</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">?University of Passau Groningen The Netherlands</orgName>
								<orgName type="institution" key="instit1">University of Groningen</orgName>
								<orgName type="institution" key="instit2">University of Turin</orgName>
								<address>
									<settlement>Turin Italy, Passau</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">HateBERT: Retraining BERT for Abusive Language Detection in English</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we introduce HateBERT, a re-trained BERT model for abusive language detection in English. The model was trained on RAL-E, a large-scale dataset of Reddit comments in English from communities banned for being offensive, abusive, or hateful that we have collected and made available to the public. We present the results of a detailed comparison between a general pre-trained language model and the abuse-inclined version obtained by retraining with posts from the banned communities on three English datasets for offensive, abusive language and hate speech detection tasks. In all datasets, HateBERT outperforms the corresponding general BERT model. We also discuss a battery of experiments comparing the portability of the generic pre-trained language model and its corresponding abusive language-inclined counterpart across the datasets, indicating that portability is affected by compatibility of the annotated phenomena.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The popularity of social media and micro-blogging platforms is still having undisclosed effects in our life as a result of an increased connectivity among people. The potential benefits are overshadowed by numerous expressions of abusive language phenomena. This contribution focuses on finding solutions to overcome that problem.</p><p>The development of systems for the automatic identification of abusive language phenomena has followed a common trend in NLP: feature-based linear classifiers <ref type="bibr" target="#b30">(Waseem and Hovy, 2016;</ref><ref type="bibr" target="#b25">Ribeiro et al., 2018;</ref><ref type="bibr" target="#b11">Ibrohim and Budi, 2019)</ref>, neural network architectures (e.g., CNN or Bi-LSTM) <ref type="bibr" target="#b14">(Kshirsagar et al., 2018;</ref><ref type="bibr" target="#b20">Mishra et al., 2018;</ref><ref type="bibr" target="#b21">Mitrovi? et al., 2019;</ref><ref type="bibr" target="#b28">Sigurbergsson and Derczynski, 2020)</ref>, and, finally, fine-tuning pre-trained language models, e.g., BERT, RoBERTa, a.o., <ref type="bibr" target="#b16">(Liu et al., 2019;</ref><ref type="bibr" target="#b29">Swamy et al., 2019)</ref>. Results vary both across datasets and architectures, with linear classifiers qualifying as very competitive, if not better, when compared to neural networks. On the other hand, systems based on pre-trained language models have reached new state-of-the-art results. One issue with these pre-trained models is that the training language variety makes them well suited for general-purpose language understanding tasks, and it highlights their limits with more domain-specific language varieties. To address this, there is a growing interest in generating domain-specific BERT-like pre-trained language models, such as AlBERTo <ref type="bibr" target="#b24">(Polignano et al., 2019)</ref> or TweetEval <ref type="bibr" target="#b0">(Barbieri et al., 2020)</ref> for Twitter, BioBERT for the biomedical domain in English <ref type="bibr" target="#b15">(Lee et al., 2019)</ref>, FinBERT for the financial domain in English <ref type="bibr" target="#b32">(Yang et al., 2020)</ref>, and LEGAL-BERT for the legal domain in English <ref type="bibr">(Chalkidis et al., 2020)</ref>. We introduce HateBERT, a pre-trained BERT model for abusive language phenomena in social media in English.</p><p>Abusive language phenomena fall along a wide spectrum including, a.o., microaggression, stereotyping, offense, abuse, hate speech, threats, and doxxing <ref type="bibr" target="#b12">(Jurgens et al., 2019)</ref>. Current approaches have focus on a limited range, namely offensive language, abusive language, and hate speech. The connections among these phenomena have only superficially been accounted for, resulting in a fragmented picture, with a variety of definitions, and (in)compatible annotations <ref type="bibr" target="#b31">(Waseem et al., 2017)</ref>. <ref type="bibr" target="#b23">Poletto et al. (2020)</ref> introduce a graphical visualisation <ref type="figure" target="#fig_0">(Figure 1</ref>) of the connections among abusive language phenomena according to the definitions in previous work <ref type="bibr" target="#b30">(Waseem and Hovy, 2016;</ref><ref type="bibr" target="#b7">Fortuna and Nunes, 2018;</ref><ref type="bibr" target="#b17">Malmasi and Zampieri, 2018;</ref><ref type="bibr" target="#b33">Zampieri et al., 2019)</ref>.</p><p>When it comes to offensive language, abusive language, and hate speech, the distinguishing factor is their level of specificity. This makes offensive language the most generic form of abusive language phenomena and hate speech the most specific, with abusive language being somewhere in the middle. Such differences are a major issue for the study of portability of models. Previous work <ref type="bibr">(Karan an? Snajder, 2018;</ref><ref type="bibr" target="#b2">Benk, 2019;</ref><ref type="bibr" target="#b22">Pamungkas and Patti, 2019;</ref><ref type="bibr" target="#b26">Rizoiu et al., 2019)</ref> has addressed this task by conflating portability with generalizability, forcing datasets with different phenomena into homogenous annotations by collapsing labels into (binary) macro-categories. In our portability experiments, we show that the behavior of HateBERT can be explained by accounting for these difference in specificity across the abusive language phenomena.</p><p>Our key contributions are: (i.) additional evidence that further pre-training is a viable strategy to obtain domain-specific or language variety-oriented models in a fast and cheap way; (ii.) the release of HateBERT, a pre-trained BERT for abusive language phenomena, intended to boost research in this area; (iii.) the release of a large-scale dataset of social media posts in English from communities banned for being offensive, abusive, or hateful.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">HateBERT: Re-training BERT with Abusive Online Communities</head><p>While transformer-based pre-trained language models, such as BERT, achieve good performance on numerous NLP tasks, when applied to less standard language varieties, such as social media data, results may fluctuate a lot. For instance, by comparing different fine-tuned BERT models on the OffensEval 2019 dataset <ref type="bibr" target="#b33">(Zampieri et al., 2019)</ref>, it appears that the key factor in boosting the performance is the quality of the pre-processing step <ref type="bibr" target="#b16">(Liu et al., 2019;</ref><ref type="bibr" target="#b29">Swamy et al., 2019)</ref>, rather than other aspects such as learning rate or training time.</p><p>Further pre-training of a BERT-like model is becoming more and more popular as a competitive, effective, and fast solution to adapt pre-trained language models to new language varieties or domains <ref type="bibr" target="#b0">(Barbieri et al., 2020;</ref><ref type="bibr" target="#b15">Lee et al., 2019;</ref><ref type="bibr" target="#b32">Yang et al., 2020;</ref><ref type="bibr">Chalkidis et al., 2020)</ref>, especially in cases where raw data are not scarce to generate a BERT-like model from scratch <ref type="bibr" target="#b9">(Gururangan et al., 2020)</ref>. This is the case of abusive language phenomena. However, for these phenomena an additional predicament with respect to previous work is that the options for suitable and representative collections of data are very limited. Directly scraping messages containing profanities would not be the best option as lots of potentially useful data may be missed. <ref type="bibr" target="#b8">Graumas et al. (2019)</ref> have used tweets about controversial topics to generate offensive-loaded embeddings, but their approach presents some limits. On the other hand, <ref type="bibr" target="#b19">Merenda et al. (2018)</ref> have shown the effectiveness of using messages from potentially abusive-oriented on-line communities to generate so-called hate embeddings. We follow this latter approach by using messages from banned communities in Reddit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RAL-E: the Reddit Abusive Language English dataset</head><p>Reddit is a popular social media outlet where users share and discuss content. The website is organized into user-created and user-moderated communities known as subreddits, being de facto on-line communities. In 2015, Reddit strengthened its content policies and banned several subreddits <ref type="bibr" target="#b5">(Chandrasekharan et al., 2017)</ref>. We retrieved a large list of banned communities in English from different sources including official posts by the Reddit administrators and Wikipedia pages. <ref type="bibr">1</ref> We then selected only communities that were banned for being deemed to host or promote offensive, abusive, and/or hateful content (e.g., expressing harassment, bullying, inciting/promoting violence, inciting/promoting hate). We collected the posts from these communities by crawling a publicly available collection of Reddit Comments from December 2005 to March 2017. 2 For each post, we kept only the text and the name of the community. The resulting collection comprises 1,492,740 messages from a period between January 2012 and June 2015, for a total of 43,820,621 tokens. The list of selected communities with the number of retrieved messages per community is reported in <ref type="table">Table A</ref>.1 in Appendix A.</p><p>Creating HateBERT From the RAL-E dataset, we used 1,478,348 messages (for a total of 43,379,350 tokens) to re-train the English BERT base-uncased model 3 by applying the Masked Language Model (MLM) objective. The remaining 14,932 messages (441,271 tokens) have been used as test set. We retrained for 100 epochs (almost 2 million steps) in batches of 64 samples, including up to 512 sentencepiece tokens. We used Adam with learning rate 5e-5. We trained using the huggingface code 4 on one Nvidia V100 GPU. The result is a shifted BERT model, HateBERT base-uncased, along two dimensions: (i.) language variety (i.e. social media); and (ii.) polarity (i.e., offense-, abuse-, and hate-oriented model).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>To verify the validity of HateBERT as being more suitable than a general one, i.e. BERT, for detecting offensive and abusive language phenomena, we run a set of experiments on three English datasets.</p><p>OffensEval 2019 <ref type="bibr" target="#b33">(Zampieri et al., 2019)</ref> This dataset was distributed in the context of the SemEval 2019: Task 6 evaluation exercise. 5 The dataset contains 14,100 tweets annotated for offensive language. According to the task definition, a message is labelled as offensive if "it contains any form of nonacceptable language (profanity) or a targeted offense, which can be veiled or direct." <ref type="bibr">(Zampieri et al., 2019, pg. 76</ref> AbusEval <ref type="bibr">(Caselli et al., 2020)</ref> This dataset has been obtained by adding a layer of abusive language annotation to OffensEval 2019. Abusive language is defined as a specific case of offensive language, namely "hurtful language that a speaker uses to insult or offend another individual or a group of individuals based on their personal qualities, appearance, social status, opinions, statements, or actions." <ref type="bibr">(Caselli et al., 2020, pg. 6197</ref>). The main difference with respect to offensive language is the exclusion of isolated profanities or untargeted messages from the positive class. The size of the dataset is the same as OffensEval 2019, i.e., 14,100 tweets, as well as that of the training and test splits (13,240 and 860 messages, respectively). The differences concern the distribution of the positive class which results in 2,749 in training and 178 in test.</p><p>HatEval  This dataset was distributed for the SemEval 2019: Task 5 evaluation exercise. <ref type="bibr">6</ref> The English portion of the dataset contains 13,000 tweets annotated for hate speech against migrants and women. The authors define hate speech as "any communication that disparages a person or a group on the basis of some characteristic such as race, color, ethnicity, gender, sexual orientation, nationality, religion, or other characteristics." <ref type="bibr">(Basile et al., 2019, pg. 54)</ref>. Only hateful messages targeting migrants and women belong to the positive class, leaving any other message (including offensive or abusive against other targets) to the negative class. The training set is composed of 10,000 messages and the test contains 3,000. Both training and test contain an equal amount of messages with respect to the targets, i.e., 5,000 each in training and 1,500 each in test. This does not hold for the distribution of the positive class, where 4,165 messages are present in the training and 1,252 in the test set.</p><p>All datasets are imbalanced between positive and negative classes and they target phenomena that vary along the specificity dimension. This allows us to evaluate both the robusteness and the portability of HateBERT.</p><p>We applied the same pre-processing steps and hyperparameters when fine-tuning both the generic BERT and HateBERT. Pre-processing steps and hyperparameters <ref type="table">(Table A.</ref>2) are more closely detailed in the Appendix B. <ref type="table" target="#tab_1">Table 1</ref> illustrates the results on each dataset (in-dataset evaluation), while <ref type="table" target="#tab_2">Table 2</ref> reports on the portability experiments (cross-dataset evaluation). The same evaluation metric from the original tasks, or paper, is applied, that is macro-averaged F1 of the positive and negative classes.  The in-domain results confirm the validity of the re-training approach to generate better models for detection of abusive language phenomena. On every dataset, HateBERT largely outperforms the corresponding general BERT model. A detailed analysis of the results per class show that the improvements, in all datasets, affect both the positive and the negative classes, suggesting that HateBERT is more robust. Interestingly, the use of data from a different social media platform does not harm the fine-tuning stage of the retrained model, opening up possibilities of cross-fertilisation studies across social media platforms. HateBERT beats the state-of-the-art results only in one case, namely for AbusEval, achieving competitive results on OffensEval and HatEval. <ref type="bibr">7</ref> The portability experiments were run using the best model for each of the in-dataset experiments. Besides a general drop in performance when compared to the corresponding in-dataset scores, our results show that HateBERT ensures better portability than a generic BERT model, especially when going from generic abusive language phenomena (i.e., offensive language) towards more specific one (i.e., abusive language or hate speech). This behaviour was expected and provides empirical evidence to the differences across the annotated phenomena. We also claim that HateBERT consistently obtains better representations of the targeted phenomena. This is evident when looking at the differences in False Positives and False Negatives for the positive class, measured by means of Precision and Recall, respectively. As illustrated in <ref type="table" target="#tab_4">Table 3</ref>, HateBERT always obtains a higher Precision score than BERT when fine-tuned on a generic  abusive phenomenon and applied to more specific ones, at a very low cost for Recall. The unexpected higher Precision of HateBERT fine-tuned on AbusEval and tested on OffensEval 2019 (i.e., from specific to generic) is due to the datasets sharing same data distribution. Indeed, the results of the same model against HatEval support our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Directions</head><p>This contribution introduces HateBERT base uncased, 8 a pre-trained language model for abusive language phenomena in English. We confirm that further pre-training is an effective and cheap strategy to port pre-trained language models to other language varieties. The in-dataset evaluation shows that HateBERT consistently outperforms a generic BERT across different abusive language phenomena, such as offensive language (OffensEval 2019), abusive language (AbusEval), and hate speech (HatEval). The cross-dataset experiments show that HateBERT obtains robust representations of each abusive language phenomenon against which it has been fine-tuned. In particular, the cross-dataset experiments have provided (i.) further empirical evidence on the relationship among three abusive language phenomena along the dimension of specificity; (ii.) empirical support to the validity of the annotated data; (iii.) a principled explanation for the different performances of HateBERT and BERT.</p><p>Future work will focus on two directions: (i.) investigating to what extent the embedding representations of HateBERT are actually different from a general BERT pre-trained model, and (ii.) testing the generalizability of HateBERT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethical Statement</head><p>In this paper, the authors introduce HateBERT, a pre-trained language model for the study of abusive language phenomena in social media in English. HateBERT is unique because (i.) it is based on further pre-training of an existing pre-trained language model (i.e., BERT base-uncased) rather than training it from scratch, thus reducing the environmental impact of its creation; 9 (ii.) it uses a large collection of messages from communities that have been deemed to violate the content policy of a social media platform, namely Reddit, because of expressing harassment, bullying, incitement of violence, hate, offense, and abuse. The judgment on policy violation has been made by the community administrators and moderators. We consider this dataset for further pre-training more ecologically representative of the expressions of different abusive language phenomena in English than the use of manually annotated datasets.</p><p>The collection of banned subreddits has been retrieved from a publicly available collection of Reddit, obtained through the Reddit API. From this collection, we generated the RAL-E dataset. RAL-E will be publicly released (it is accessible also at review phase in the Supplementary Materials). While its availability may have an important impact in boosting research on abusive language phenomena, especially by making natural interactions in online communities available, we are also aware of the risks of privacy violations for owners of the messages. This is one of the reasons why at this stage, we only make available in RAL-E the content of the message without metadata such as the screen name of the author and the community where the message was posted.</p><p>There are numerous benefits from using such models to monitor the spread of abusive language phenomena in social media. Among them, we mention the following: (i.) reducing exposure to harmful content in social media; (ii.) contributing to the creation of healthier online interactions; and (iii.) promoting positive contagious behaviors and interactions <ref type="bibr" target="#b18">(Matias, 2019)</ref>. Unfortunately, work in this area is not free from potentially negative impacts. The most direct is a risk of promoting misrepresentation.</p><p>HateBERT is an intrinsically biased pre-trained language model. The fine-tuned models that can be obtained are not overgenerating the positive classes, but they suffer from the biases in the manually annotated data, especially for the offensive language detection task <ref type="bibr" target="#b27">(Sap et al., 2019;</ref><ref type="bibr" target="#b6">Davidson et al., 2019)</ref>. Furthermore, we think that such tools must always be used under the supervision of humans. Current datasets are completely lacking the actual context of occurrence of a messsage and the associated meaning nuances that may accompany it, labelling the positive classes only on the basis of superficial linguistic cues. The deployment of models based on HateBERT "in the wild" without human supervision requires additional research and suitable datasets for training.</p><p>We see benefits in the use of HateBERT in research on abusive language phenomena as well as in the availability of RAL-E. Researchers are encouraged to be aware of the intrinsic biased nature of HateBERT and of its impacts in real-world scenarios.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Abusive language phenomena and their relationships (source<ref type="bibr" target="#b23">Poletto et al. (2020)</ref>).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>). The dataset is split into training and test, with 13,240 messages in training and 860 in test. The positive class (i.e. messages labeled as offensive) are 4,400 in training and 240 in test. No development data is provided.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>BERT vs. HateBERT: in-dataset. Best scores in bold. For BERT and HateBERT we report the average from 5 runs and its standard deviations. Best corresponds to the best systems in the original shared tasks.Caselli et al. (2020)  is the most recent result for AbusEval.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Model</cell><cell cols="3">Macro F1 Pos. class -F1</cell></row><row><cell>OffensEval 2019</cell><cell cols="2">BERT HateBERT Best</cell><cell cols="2">.803?.006 .809?.008 .829</cell><cell>.715?.009 .723?.012 .599</cell></row><row><cell></cell><cell cols="2">BERT</cell><cell cols="2">.727?.008</cell><cell>.552?.012</cell></row><row><cell>AbusEval</cell><cell cols="2">HateBERT</cell><cell cols="2">.765?.006</cell><cell>.623?.010</cell></row><row><cell></cell><cell cols="4">Caselli et al. (2020) .716?.034</cell><cell>.531</cell></row><row><cell></cell><cell cols="2">BERT</cell><cell cols="2">.480?.008</cell><cell>.633?.002</cell></row><row><cell>HatEval</cell><cell cols="2">HateBERT</cell><cell cols="2">.516?.007</cell><cell>.645?.001</cell></row><row><cell></cell><cell cols="2">Best</cell><cell></cell><cell>.651</cell><cell>-</cell></row><row><cell>Train</cell><cell></cell><cell>Model</cell><cell>OffensEval 2019</cell><cell cols="2">AbusEval HatEval</cell></row><row><cell cols="2">OffensEval</cell><cell>BERT</cell><cell>-</cell><cell>.726</cell><cell>.545</cell></row><row><cell>2019</cell><cell></cell><cell>HateBERT</cell><cell>.-</cell><cell>.750</cell><cell>.547</cell></row><row><cell>AbusEval</cell><cell></cell><cell>BERT HateBERT</cell><cell>.710 .713</cell><cell>--</cell><cell>.611 .624</cell></row><row><cell>HatEval</cell><cell></cell><cell>BERT HateBERT</cell><cell>.572 .543</cell><cell>.590 .555</cell><cell>--</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>BERT vs. HateBERT: Portability. Columns show the dataset used for testing. Best scores per training/test combination are underlined.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>BERT vs. HateBERT: Portability -Precision and Recall for the positive class. Rows show the dataset used to train the model and columns the dataset used for testing. Best scores are underlined.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://en.wikipedia.org/wiki/Controversial_Reddit_communities</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_ available_reddit_comment/ 3 We used the pre-trained model available via the huggingface Transformers libraryhttps://github.com/ huggingface/transformers 4 https://github.com/huggingface/transformers/tree/master/src/transformers 5 https://competitions.codalab.org/competitions/20011 6 https://competitions.codalab.org/competitions/19935</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">We did not manage to replicate the results by<ref type="bibr" target="#b16">Liu et al. (2019)</ref>, who qualified as the best system at OffensEval 2019.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">HateBERT, the fine-tuned model, and the RAL-E dataset are available at https://osf.io/tbd58/?view_only= cb79b3228d4248ddb875eb1803525ad8</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">The Nvidia V100 GPU we used is shared and it has a maximum number of continuous reserved time of 72 hours. In total, it took 18 days to complete the 2 million retraining steps.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The project on which this report is based was funded by the German Federal Ministry of Education and Research (BMBF) under the funding code 01-S20049. The author is responsible for the content of this publication.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pre-processing before re-training ? all users' mentions have been substituted with a placeholder (@USER);</p><p>? all URLs have been substituted with a with a placeholder (URL);</p><p>? emojis have been replaced with text (e.g. ? :pleading face:) using Python emoji package;</p><p>? hashtag symbol has been removed from hasthtags (e.g. #kadiricinadalet ? kadiricinadalet);</p><p>? extra blank spaces have been replaced with a single space;</p><p>? extra blank new lines have been removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B</head><p>Pre-processing before fine-tuning For each dataset, we have adopted minimal pre-processing steps. In particular:</p><p>? all users' mentions have been substituted with a placeholder (@USER);</p><p>? all URLs have been substituted with a with a placeholder (URL);</p><p>? emojis have been replaced with text (e.g.</p><p>? :pleading face:) using Python emoji package;</p><p>? hashtag symbol has been removed from hashtags (e.g. #kadiricinadalet ? kadiricinadalet);</p><p>? extra blank spaces have been replaced with a single space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hyperparameters Value</head><p>Learning </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">TweetEval: Unified benchmark and comparative evaluation for tweet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Espinosa Anke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="1644" to="1650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristina</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabetta</forename><surname>Fersini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debora</forename><surname>Nozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viviana</forename><surname>Patti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco Manuel Rangel</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="page" from="54" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Data Augmentation in Deep Learning for Hate Speech Detection in Lower Resource Settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michaela</forename><surname>Benk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
		<respStmt>
			<orgName>Universit?t Z?rich</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">2020. I feel offended, don&apos;t be abusive! implicit/explicit messages in offensive and abusive language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jelena</forename><surname>Mitrovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inga</forename><surname>Kartoziya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 12th Language Resources and Evaluation Conference</title>
		<meeting>The 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<biblScope unit="page" from="6193" to="6202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">LEGAL-BERT: The muppets straight out of law school</title>
	</analytic>
	<monogr>
		<title level="m">Manos Fergadiotis, Prodromos Malakasiotis, Nikolaos Aletras, and Ion Androutsopoulos. 2020</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="2898" to="2904" />
		</imprint>
	</monogr>
	<note>Findings of the Association for Computational Linguistics: EMNLP 2020</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">You can&apos;t stay here: The efficacy of reddit&apos;s 2015 ban examined through hate speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eshwar</forename><surname>Chandrasekharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umashanthi</forename><surname>Pavalanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Glynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Gilbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Racial bias in hate speech and abusive language detection datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debasmita</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingmar</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Abusive Language Online</title>
		<meeting>the Third Workshop on Abusive Language Online<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08" />
			<biblScope unit="page" from="25" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A survey on automatic detection of hate speech in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paula</forename><surname>Fortuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?rgio</forename><surname>Nunes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Twitter-based Polarised Embeddings for Abusive Language Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Graumas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Don&apos;t stop pretraining: Adapt language models to domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><surname>Suchin Gururangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swabha</forename><surname>Marasovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doug</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th</title>
		<meeting>the 58th</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="8342" to="8360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-label Hate Speech and Abusive Language Detection in Indonesian Twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><surname>Okky Ibrohim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Indra</forename><surname>Budi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Abusive Language Online</title>
		<meeting>the Third Workshop on Abusive Language Online</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="46" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A just and comprehensive strategy for using NLP to address online abuse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Libby</forename><surname>Hemphill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eshwar</forename><surname>Chandrasekharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07" />
			<biblScope unit="page" from="3658" to="3666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cross-domain detection of abusive language online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mladen</forename><surname>Karan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan?najder</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</title>
		<meeting>the 2nd Workshop on Abusive Language Online (ALW2)<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10" />
			<biblScope unit="page" from="132" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Predictive embeddings for hate speech detection on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Kshirsagar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyrus</forename><surname>Cukuvac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathy</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Mcgregor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</title>
		<meeting>the 2nd Workshop on Abusive Language Online (ALW2)<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10" />
			<biblScope unit="page" from="26" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">BioBERT: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonjin</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunkyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chan</forename><surname>Ho So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">NULI at SemEval-2019 task 6: Transfer learning for offensive language detection using bidirectional transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="page" from="87" to="91" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Challenges in discriminating profanity from hate speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental &amp; Theoretical Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="202" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Preventing harassment and increasing group participation through social norms in 2,190 online science discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matias</forename><surname>J Nathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="9785" to="9789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Source-driven Representations for Hate Speech Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flavio</forename><surname>Merenda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudia</forename><surname>Zaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tommaso</forename><surname>Caselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malvina</forename><surname>Nissim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th Italian Conference on Computational Linguistics</title>
		<meeting>the 5th Italian Conference on Computational Linguistics<address><addrLine>Turin, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural character-based composition models for abuse detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushkar</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Yannakoudakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekaterina</forename><surname>Shutova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Abusive Language Online (ALW2)</title>
		<meeting>the 2nd Workshop on Abusive Language Online (ALW2)<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">nlpUP at SemEval-2019 task 6: A deep neural language model for offensive language detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jelena</forename><surname>Mitrovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Birkeneder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="page" from="722" to="726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cross-domain and cross-lingual abusive language detection: A hybrid approach with deep learning and a multilingual lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wahyu</forename><surname>Endang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viviana</forename><surname>Pamungkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Resources and Benchmark Corpora for Hate Speech Detection: a Systematic Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Poletto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerio</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuela</forename><surname>Sanguinetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristina</forename><surname>Bosco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viviana</forename><surname>Patti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hate speech detection through alberto italian language understanding model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Polignano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierpaolo</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>De Gemmis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giovanni</forename><surname>Semeraro</surname></persName>
		</author>
		<ptr target="CEURWorkshopProceed-ings.CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Natural Language for Artificial Intelligence co-located with the 18th International Conference of the Italian Association for Artificial Intelligence (AIIA 2019)</title>
		<editor>Mehwish Alam, Valerio Basile, Felice Dell&apos;Orletta, Malvina Nissim, and Nicole Novielli</editor>
		<meeting>the 3rd Workshop on Natural Language for Artificial Intelligence co-located with the 18th International Conference of the Italian Association for Artificial Intelligence (AIIA 2019)<address><addrLine>Rende, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11-19" />
			<biblScope unit="volume">2521</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Characterizing and detecting hateful users on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">H</forename><surname>Manoel Horta Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><forename type="middle">A</forename><surname>Calais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Virg?lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wagner</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meira</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twelfth International AAAI Conference on Web and Social Media</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Transfer learning for hate speech detection in social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marian-Andrei</forename><surname>Rizoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriela</forename><surname>Ferraro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanna</forename><surname>Suominen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.03829</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The risk of racial bias in hate speech detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dallas</forename><surname>Card</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saadia</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07" />
			<biblScope unit="page" from="1668" to="1678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Offensive Language and Hate Speech Detection for Danish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Gudbjartur Ingi Sigurbergsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Derczynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>ELRA</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Studying generalisability across abusive language detection datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><forename type="middle">Durairaj</forename><surname>Swamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anupam</forename><surname>Jamatia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bj?rn</forename><surname>Gamb?ck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 23rd Conference on Computational Natural Language Learning (CoNLL)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11" />
			<biblScope unit="page" from="940" to="950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Hateful symbols or hateful people? predictive features for hate speech detection on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL Student Research Workshop</title>
		<meeting>the NAACL Student Research Workshop<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-06" />
			<biblScope unit="page" from="88" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Understanding abuse: A typology of abusive language detection subtasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeerak</forename><surname>Waseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dana</forename><surname>Warmsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ingmar</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Abusive Language Online</title>
		<meeting>the First Workshop on Abusive Language Online</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="78" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Finbert: A pretrained language model for financial communications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">Christopher</forename><surname>Siy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">Y</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">SemEval-2019 task 6: Identifying and categorizing offensive language in social media (OffensEval)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcos</forename><surname>Zampieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shervin</forename><surname>Malmasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noura</forename><surname>Farra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ritesh</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
