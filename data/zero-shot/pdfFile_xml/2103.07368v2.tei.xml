<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Information Maximization Clustering via Multi-View Self-Labelling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Foivos</forename><surname>Ntelemis</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE</roleName><forename type="first">Yaochu</forename><surname>Jin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spencer</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
						</author>
						<title level="a" type="main">Information Maximization Clustering via Multi-View Self-Labelling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Deep neural models</term>
					<term>mutual information max- imization</term>
					<term>unsupervised learning</term>
					<term>self-supervised learning</term>
					<term>clus- tering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Image clustering is a particularly challenging computer vision task, which aims to generate annotations without human supervision. Recent advances focus on the use of self-supervised learning strategies in image clustering, by first learning valuable semantics and then clustering the image representations. These multiple-phase algorithms, however, involve several hyper-parameters and transformation functions, and are computationally intensive. By extending the self-supervised approach, this work proposes a novel single-phase clustering method that simultaneously learns meaningful representations and assigns the corresponding annotations. This is achieved by integrating a discrete representation into the self-supervised paradigm through a classifier net. Specifically, the proposed clustering objective employs mutual information, and maximizes the dependency between the integrated discrete representation and a discrete probability distribution. The discrete probability distribution is derived through the self-supervised process by comparing the learnt latent representation with a set of trainable prototypes. To enhance the learning performance of the classifier, we jointly apply the mutual information across multi-crop views. Our empirical results show that the proposed framework outperforms state-of-the-art techniques with an average clustering accuracy of 89.1%, 49.0%, 83.1% and 27.9%, respectively, on the baseline datasets of CIFAR-10, CIFAR-100/20, STL10 and Tiny-ImageNet/200. Finally, the proposed method also demonstrates attractive robustness to parameter settings, and to a large number of classes, making it ready to be applicable to other datasets. The implementation of our method is available online.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Modern technologies such as Internet of Things and cloud computing have resulted in the collection and storage of a huge amount of data such as images and videos. With the help of such huge amount of data, deep supervised learning <ref type="bibr" target="#b23">[23]</ref>, <ref type="bibr" target="#b45">[45]</ref> has achieved great success, provided that these data are labelled. Unfortunately, labelling such huge datasets is extremely laborious, and in many cases intractable. As a result, many image datasets are not fully utilized due to the lack of labels. In addition to the huge volumes, image data are usually characterized by a high dimensionality and multi-modal structure. Thus, the performance of traditional clustering approaches <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b24">[24]</ref>, <ref type="bibr" target="#b51">[51]</ref>, <ref type="bibr" target="#b57">[56]</ref> seriously deteriorates on such data <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b44">[44]</ref>. By contrast, deep unsupervised methods have demonstrated superiority and scalability in handling vision data <ref type="bibr" target="#b34">[34]</ref>, including representation learning <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b21">[21]</ref> and clustering <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b29">[29]</ref>, <ref type="bibr" target="#b42">[42]</ref>, <ref type="bibr" target="#b47">[47]</ref>.</p><p>Representation learning techniques are gaining popularity, since they can generate discriminative features by considering spatial properties, object shapes and photometric information without the requiring of human annotations. Recent studies <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b21">[21]</ref>, <ref type="bibr" target="#b46">[46]</ref> have dramatically enhanced the learning capacity and thus minimized the performance gap between supervised and unsupervised learning tasks. This is achieved by proposing self-training objectives for representation learning, also called self-supervised methods. In particular, contrastive learning strategies have widely been applied in selfsupervised methods <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b17">[17]</ref>, <ref type="bibr" target="#b46">[46]</ref>. They aim to increase the concordance of positive (similar) features of augmented views and decrease the discordance in negative (dissimilar) instances. Alternatively, feature comparisons are replaced in grouping techniques <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b56">[55]</ref> by identifying sub-classes and assigning pseudo-labels to the relevant representations based on their similarities. These pseudo-labelling annotations are either derived through traditional clustering methods <ref type="bibr" target="#b3">[4]</ref> (i.e., extracted features using a convolutional encoder are annotated through K-means clustering) or through an optimal transport plan <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b56">[55]</ref> that can ensure consistency and balance population.</p><p>Despite the remarkable success of grouping based selfsupervised tasks, the pseudo-labels they generate have so far been evaluated for learning discriminative features only. Additionally, the deep clustering methods have not yet fully exploited the recently developed self-supervised algorithms. Some existing approaches <ref type="bibr" target="#b27">[27]</ref>, <ref type="bibr" target="#b29">[29]</ref> implement a convolutional framework that introduces mutual information (MI) in the clustering objective during training. The application of MI has demonstrated to be beneficial; however, the performance of these methods degrades in tackling more challenging datasets. Most recently, self-supervised mechanisms were introduced to further improve clustering results on challenging datasets <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b48">[48]</ref>, by firstly learning valuable properties of the training instances and then performing the clustering. Although the performance is enhanced, they often require multiple training phases whose clustering performance relies on the previous training phase and the effectiveness of each individual stage. Furthermore, many individual training phases require an additional set of augmentation operations and/or different objective arXiv:2103.07368v2 [cs.CV] 18 Oct 2021 functions. As a result, the final clustering accuracy heavily relies on an increasing number of hyper-parameters. Finally, multiple training phases often increase the computational complexity.</p><p>This study aims to address the issues of multiple-phase clustering methods by extending the functionality of Swapping Assignments between multiple Views (SwAV) <ref type="bibr" target="#b4">[5]</ref>, a recently proposed grouping based self-supervised learning strategy that performs discriminative feature learning. Therefore, we propose an online single-phase clustering framework by integrating a deep classifier net into the SwAV framework to simultaneously learn the representations and assign the desired annotations. Specifically, the proposed clustering method exploits the semantic structure obtained through a discrete probabilistic distribution that is derived by comparing the latent representations with a set of trainable prototypes. This is accomplished by maximizing the mutual dependency between the discrete representation of the integrated classifier and the discrete probabilistic distribution derived by the prototypes. To further enhance the clustering performance, we adopt the multi-crop strategy as presented in <ref type="bibr" target="#b4">[5]</ref> and optimize the mutual information across multi-crop views. We call the proposed framework Information Maximization Clustering by Swapping Assignments between multiple Views (IMC-SwAV). Our empirical studies show that the proposed framework is highly competitive and outperforms a wide range of state-of-the-art methods. Additionally, it shows robustness to the number of prototypes and the number of clusters. Finally, we demonstrate that other grouping-based self-supervised learning methods such as SeLa <ref type="bibr" target="#b56">[55]</ref> can also be adopted, although the proposed single-phase clustering method is based on an extended SwAV.</p><p>We highlight our contributions as follows:</p><p>1) A single-phase training framework is proposed by extending a feature learning strategy to simultaneously generated features and assign labels. This way, the proposed algorithm avoids extra hyper-parameters, and does not require additional transformation functions, nor extra training phases. 2) A modified clustering objective based on mutual information that maximizes the dependency between an over-clustering discrete probabilistic distribution and the classifier's discrete representation. A multi-crop view strategy is adopted in optimizing the classifier to further enhance the classifier's performance. 3) We demonstrate that our clustering strategy is not limited to a specific self-supervised learning strategy and can in principle be extended to any other grouping based self-supervised learning strategies within a single-phase training framework.</p><p>The rest of the paper is organized as follows. In Section II, related work on clustering and representation learning are briefly reviewed. The proposed method, including the overall representation learning framework and a modified objective function for joint training on the basis of mutual information maximization is presented in Section III. Comparative experiments and ablation studies, along with the parameter settings and performance metrics, are described in Section IV. A summary of the proposed algorithm and future work are provided in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Embedding strategies have emerged as an effective means to eliminate the necessity of the desired annotations in terms of disentangled feature learning. Previous approaches employ traditional frameworks, such as autoencoders <ref type="bibr" target="#b26">[26]</ref>, <ref type="bibr" target="#b49">[49]</ref> and deep belief networks <ref type="bibr" target="#b25">[25]</ref>. Generative models including variational autoencoders <ref type="bibr" target="#b31">[31]</ref> and generative adversarial networks <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b41">[41]</ref> also became popular. This type of frameworks rely on two separate models, one generating training instances from a latent space, and the other mapping the training samples into a latent domain.</p><p>Self-supervised learning, on the other hand, obtains visual representations using a single unit model. A range of training objectives have been proposed in literature: 1) each training sample is treated as a unique class <ref type="bibr" target="#b12">[13]</ref>; 2) an image instance is partitioned in several patches and the encoder either attempts to solve the jigsaw puzzle <ref type="bibr" target="#b37">[37]</ref>, or 3) predicts the code of next image's patch <ref type="bibr" target="#b46">[46]</ref>. Contrastive learning addresses feature extraction by comparing positive pairs (augmented views of similar instances). Many implementations <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b21">[21]</ref>, <ref type="bibr" target="#b46">[46]</ref>, <ref type="bibr" target="#b59">[58]</ref> adopt variations of noise contrastive estimation (NCE) <ref type="bibr" target="#b17">[17]</ref> loss function, that achieves a good representation by comparing positive pairs versus a large number of negative instances. To deal with the large negative sampling, momentum contrast (MoCo) <ref type="bibr" target="#b21">[21]</ref> has been suggested that compares representations between a momentum and a simple encoder, or in <ref type="bibr" target="#b59">[58]</ref> through a memory bank for storing past representations. As another option, the grouping based strategies <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b56">[55]</ref> assign the representations to a numerous surrogate sub-classes. A method presented in <ref type="bibr" target="#b3">[4]</ref> employs a traditional K-means to cluster representations, whose performance, however, depends on network initialization, and an additional computational time is required for computing the centroids in each iteration. Some recently proposed algorithms <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b56">[55]</ref> take advantage of the efficient optimal transport plan, and introduce a self-labelling mechanism as target distribution which is computed via the Shinkhorn-Knopp <ref type="bibr" target="#b11">[12]</ref> algorithm. Nevertheless, these methods aim to extract features without producing cluster annotations.</p><p>Image clustering techniques group the corresponding representation basis to the defined priorities. Two main strategies are considered from different perspectives. A first group of studies <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b29">[29]</ref>, <ref type="bibr" target="#b55">[54]</ref>, <ref type="bibr" target="#b58">[57]</ref> apply a defined clustering loss function to identify patterns within the training samples. A method called deep adaptive clustering (DAC) <ref type="bibr" target="#b7">[8]</ref> implements a convolutional net, and measures the cosine similarities of the generated features. The model is gradually trained to assign the most similar features to the same group index. Ji et al. propose invariant information clustering (IIC) <ref type="bibr" target="#b29">[29]</ref> which includes the MI as a training objective to maximize the dependency between the categorical outputs of numerous augmented views. A similar algorithm is reported in <ref type="bibr" target="#b27">[27]</ref>, which suggests a variation of MI as the training objective for learning discrete representations regularized through virtual adversarial training. Nevertheless, the performance of the aforementioned single-phase training methods deteriorate on more challenging datasets. A second group of most recent methods is based on multiple sequential training phases. State-of-the-art performance has reported in <ref type="bibr" target="#b48">[48]</ref>, where the model is initialized in the first phase by applying a contrastive learning objective. In the second phase, the k nearest features of each instance are measured and considered to belong to the same group, then the model is trained accordingly. Due to the mismatch prediction of the k nearest features, the method implements a third round of training, where the model learns from the most confident predictions. Likewise, a two-stage clustering is incorporated in <ref type="bibr" target="#b19">[19]</ref>, where the encoder parameters are firstly initialized through a self-supervised strategy. This pre-training phase significantly improves the performance by a large margin of the later clustering objective in the second stage. However, having multiple training stages will no doubt increase the computation time and introduce dependency on previous phases. In addition, each training phase usually involves its specific hyper-parameters, transformation functions, optimizers as well as objective functions. By contrast, our proposed strategy is based on a single-phase training method, nevertheless, it demonstrates competitive performance comparable to the most recent multiple-phases strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE PROPOSED METHOD</head><p>Assume there is an unlabelled set of images denoted as X = {x i } n i=1 , which holds a relation with a finite set of classes Y = {y i ? N, 0 &lt; y i ? k}, where k is a given hyper-parameter equal to the number of classes. The goal of this work is to instantiate a convolutional model and map the described relation as f ? : X ? Y , and ? indicates the model's parameters. <ref type="figure" target="#fig_1">Figure 1</ref> presents the overall framework of the proposed IMC-SwAV, consisting of three main components: 1) a ConvNet encoder (E ? ) that projects the training instances onto a latent space (Z); 2) the trainable prototype vectors C that are compared with the projected features to derive the computed distribution; and 3) an introduced classifier (A ? ), which maps the generated features to the corresponding discrete representation.</p><p>In the following, we begin with a brief description of a representation learning strategy based on an online self-labelling assignment method and its application to the optimization of an encoder model. We then present a joint training objective, which is a modified form of mutual information, with the aim to maximise the mutual dependency of the computed distribution obtained by the prototypes and the classifier's predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Unsupervised Representation Learning</head><p>The encoder model adopted in this work E ? : X ? Z, where ? denotes the encoder's trainable parameters, aims to learn the important semantic information of the given set of data without supervision, while ignoring less valuable semantics such as background or noise. Hence, motivated by the recent state-of-the-art achievement of SwAV <ref type="bibr" target="#b4">[5]</ref>, we employ the SwAV contrastive learning strategy to impose the consistency between representations (Z) obtained from augmented views of the same instances by comparing them to a set of prototype vectors C. These prototypes are evaluated only for uniformly mapping the obtained representations by exchanging their predicted probabilistic distributions, respectively. This is achieved by minimizing the swapped self-labelling training objective <ref type="bibr" target="#b4">[5]</ref>:</p><formula xml:id="formula_0">L swap ?,C (z (1) , z (2) ) = (z (1) , q (2) ) + (z (2) , q (1) ) where (z (j) , q (l) ) = ? 1 m m i=1 q (j) i log(u (l) i )<label>(1)</label></formula><p>where z</p><formula xml:id="formula_1">(t) i = E ? (T (x i )</formula><p>) denotes a latent representation derived by the encoder (E ? ) of the i-th training instance, respectively, T ? {f 1 , f 2 , .., f n } is a collection of stochastic transformation functions applied on the original instance beforehand to obtain a transformed view x</p><formula xml:id="formula_2">(t) i = T (x i ),</formula><p>where t is the augmented view index. For example, representations obtained by two alternative views of the same instance (x i ) are indicated as z are the computed probabilistic distributions, respectively, also called "codes", determined by comparing the corresponding representations with the trainable prototype vectors C as follows:</p><formula xml:id="formula_3">u (t) i = exp( 1 ? sim(z (t) i , c j )) k j=1 exp( 1 ? sim(z (t) i , c j ))<label>(2)</label></formula><p>where ? is a temperature parameter that controls the smoothness of the probabilistic Softmax output, and k indicates the number of prototypes. Lastly, we define sim(z i , c j ) = z T i c j / z i c j as the cosine similarity distance of both 2 normalized vectors, and c j represents the j-th prototype vector.</p><p>To minimize the cross-entropy terms of the swapped training objective (Equation 1), the computation of the exchanged pair distributions (q (t) i ) for each augmented view is required. The self-labelling target distributions (q (t) i ) prevent the assignment of trivial solutions, and enforce a uniform mapping to the prototypes. Ultimately, we accommodate the online computation as introduced in [5] to derive the required distribution. Given a collection of feature vectors Z = [z 1 , z 2 , ..., z m ], with m being the size of the training mini-batch, and the prototype vectors C = [c 1 , c 2 , ..., c k ], we aim to define a target distribution Q = [q 1 , q 2 , ..., q m ] to maximize the correlation between the generated feature vectors and the trainable prototypes by satisfying the aforementioned conditions as:</p><formula xml:id="formula_4">max Q?Q Tr(Q T C T Z) + H(Q) (3) Q = {Q ? R k ?m + |Q1 M = 1 K 1 K , Q T 1 K = 1 M 1 M } (4)</formula><p>where is a scaling parameter that regularizes the entropy term H(Q) by controlling the mapping of the distribution. In practice, the required target distribution can be efficiently optimized by iteratively employing the Sinkhorn-Knopp <ref type="bibr" target="#b11">[12]</ref> algorithm. Hence, the constraints of a uniform mapping and homogeneity are encouraged within the training mini-batch. The reader is referred to <ref type="bibr" target="#b4">[5]</ref> and <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b40">[40]</ref>, respectively, for a more detailed description of the SwAV and Sinkhorn-Knopp algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Joint Cluster Representations</head><p>Thus far, the described encoder generates features without producing the desired annotation or discrete properties to the given k classes. Instead, the training set is mapped in domain</p><formula xml:id="formula_5">U = {U ? R m?k + | k j=1 u i,j = 1}.</formula><p>Our goal is to define a parametric classifier that assigns the generated representations into a given number of classes k such as A ? : Z ? Y , where ? are parameters of classifier A. To this end, the encoder is optimized by assigning pairs of the same instances to their corresponding prototypes, while ensuring different instances, that are distinct for each prototype. We evaluate this argumentation by computing two distributions of a mini-batch denoted as U <ref type="bibr" target="#b0">(1)</ref> and U (2) using a pre-trained encoder. Each distribution includes the same 32 instances from the training set, where each instance is alternated with the application of the transformation functions T (). We measure the pairwise similarity of the two probabilistic distributions by applying the Jensen-Shannon divergence (JSD) <ref type="bibr" target="#b13">[14]</ref>, a symmetric bounded distance measurement for evaluating two probability distributions. As presented in <ref type="figure" target="#fig_3">Fig. 2</ref>, the diagonal positions express the lower divergences with the mean value ? 0.06 as these transformed views are from the same original instances. On the other hand, the larger divergences are observed in the instances of different indices (off diagonals) with the mean value ? 0.63. Note that the upper bound of JSD is log(2) ? 0.69 and zero the lower bound.</p><p>Complementary to the above observation, we assume that the transformed views of an instance produce similar distribution in domain U . We can also assume that the probabilistic output (U ) in Eq. 2 and the corresponding classifier's outputs Y = A ? (Z) holds a relationship since both are obtained from representations Z, hence defining a training objective that maximizes the mutual dependency between these two distributions with respect to parameters ?. Then classifier A ? will map semantically similar instances in domain U to the same cluster in domain Y . Note that the distributions of Y and U are a product of the Softmax output; hence, both belong to the probability simplex. Inspired by <ref type="bibr" target="#b29">[29]</ref>, we propose a measurement describing the amount of dependency between the two probabilistic outputs, which is the direct application of mutual information (MI) <ref type="bibr" target="#b10">[11]</ref>:</p><formula xml:id="formula_6">I(U ; Y ) = ?H(Y |U ) + H(Y ) = (u,y) p(u, y)log p(u, y) p(u) ? y p(y)log(p(y))<label>(5)</label></formula><p>The MI expression is the relative entropy for measuring the divergence of the joint probability p(u, y) and the product of two marginals. We modify Equation 5 to define our clustering objective function with respect to parameters ? of the classifier. In this work, we employ a deep net as the classifier A ? on top of the embedding layer (Z) to jointly perform the training. We invert the corresponding expression into a minimization loss function, and optimizing the model using the stochastic gradient descent:</p><formula xml:id="formula_7">L cluster ? (Y, U ) = 1 V 2 V i V j [H(P Y j |P U i ) ? ?H(P Y j )] = 1 V 2 V i V j ? ? Y j ,U i P Y j U i log P U i P Y j U i + ? Y P Y j log(P Y j ) .<label>(6)</label></formula><p>where</p><formula xml:id="formula_8">P Y j U i = { 1 m Y j U i ? R k?k + |Y j ? R m?k + , U i ? R m?k + }, U i denotes the computed codes, Y j the classifier's prediction, P U i = { 1 m m l=1 u i l,k ? R k + } and P Y j = { 1 m m l=1 y j l,k ? R k + } the two marginal terms.</formula><p>Here, m indicates the number of elements in the mini-batch and indices i and j denote the corresponding transformed views of the mini-batch, as illustrated in <ref type="figure" target="#fig_1">Fig. 1</ref>, where V indicates the total number of transformed views obtained from instances in the mini-batch. The scalar ? denotes an introduced weight parameter of the entropy term H(P Y j ), that encourages the classifier to uniformly assign the predicted class indices and thus prevent degeneracy. The conditional entropy term is minimized by increasing the classifier's prediction confidence. In Listing 1, we provide the pseudo-code of the clustering objective function as described in Eq. 6, which returns a quantitative measurement of the dependency between the classifier's predictions (Y j ) and the distribution (U i ). The pseudo-code is written in Python and includes commands extended in the Pytorch library <ref type="bibr" target="#b39">[39]</ref>. The final training objective with respect to all parameters of the overall framework {?, ?, C} ? ? is defined as follows:</p><formula xml:id="formula_9">L ? = L swap ?,C + L cluster ? .<label>(7)</label></formula><p>def mi(y, u, b=4): p_yu = torch.matmul(y.T, u) # k x k' p_yu /= p_yu.sum() # normalize to sum 1 p_u = p_yu.sum(0).view(1, -1) # marginal p_u p_y = p_yu.sum <ref type="bibr" target="#b0">(1)</ref>.view(-1, 1) # marginal p_y h_uy = (p_yu * (torch.log(p_u) -torch.log(p_yu))).sum() # conditional entropy hy = b * (p_yu * torch.log(p_y)).sum() # weighted marginal entropy return h_uy + hy Listing 1: Pseudo-code written in Python presents the clustering objective based on Pytorch library <ref type="bibr" target="#b39">[39]</ref>.</p><formula xml:id="formula_10">Algorithm 1 Framework method Function Framework(B): B t = T (B) apply transformation functions Z t = E ? (B t ) generate the representations U t = exp( 1 ? sim(z t i ,cj )) k j=1 exp( 1 ? sim(z t i ,cj )) compute the distribution Y t = A ? (Z t ) classifier's output Q t = derived by U t through Shinkhorn-Knopp [12] return U t , Q t , Y t End Function Algorithm 2</formula><p>The proposed joint training algorithm.</p><formula xml:id="formula_11">Data: X = {x i } n i=1 Initialize : {?, ?, C} ? ? while Convergence condition not satisfied do ? Sample minibatch B = {x 1 , ..., x m } First Views ? U (1) , Q (1) , Y (1) = Framework(B) Second Views ? U (2) , Q (2) , Y (2) = Framework(B) Swap loss L swap ?,C = 1 m m i=1 ?q (2) i log(u (1) i ) ? q (1) i log(u (2) i ) Clustering loss L cluster ? (U, Y ) = 1 2 2 2 i=1 2 j=1 H(Y j |U i ) ? ?H(U i )</formula><p>? Jointly update the framework's parameters to minimize the combined training objective L ? :</p><formula xml:id="formula_12">L ? = L swap ?,C + L cluster ? end</formula><p>The internal computation of the IMC-SwAV is presented in Algorithm 1 and the full training process, including all steps for the two transformed views, are given in Algorithm 2.</p><p>In the following, we briefly discuss the reason for using mutual information in the objective function. Recall that the convergence of the SwAV <ref type="bibr" target="#b4">[5]</ref> framework is achieved by gradually dividing the full dataset into k partitions, where k is the number of defined prototypes, which is usually large. Thus, on average n/k instances are assigned to each partition. By maximizing the dependency between the distribution U = {U ? R m?k + | k j=1 u i,j = 1} and the classifier's prediction Y , the classifier converges by identifying partitions that hold similar semantics in U and grouping them to the same cluster in Y . The marginal entropy in Equation 6 regularizes the classifier to ensure that each cluster is approximately assigned n/k elements. On the other hand, the classifier increases its confidence on its predictions by minimizing the conditional entropy. Despite its simplicity, the experimental results presented in Section IV indicate that the proposed clustering objective can effectively leverage the derived distribution U to achieve high performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Multi-Crop Strategy</head><p>In this work, we adopt the same multi-crop views training strategy as introduced in <ref type="bibr" target="#b4">[5]</ref> for a full exploitation of the proposed framework. Each training instance is transformed into a set of augmented views. The first two main transformed views are cropped in a negligible lower resolution of the original image, we later called this transformation as high resolution views. The additional mini-cropped views cover only a small part of the image with their resolution to be approximately the half of the original image size to reduce the convolutional operations and thus the time complexity. We named this transformation as low resolution views. During the training, Q target distributions are computed only for the high resolution views, and used across all augmented views. We extend this process also to the proposed clustering objective (Eq. 6). Here, we compute pairwise the MI quantity based on all views; hence, if a mini-batch is transformed into two high and two low resolution views, so V = 4, resulting in 16 combinations in total. It is found that the multi-crop strategy, as demonstrated in our empirical studies, effectively enhances the model's prediction capability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL STUDIES</head><p>We evaluate the proposed clustering method, IMC-SwAV, on four challenging colour image datasets: 1) CIFAR-10, which contains 10 equally populated classes; 2) CIFAR-100 containing 100 classes with all elements being uniform distributed. These 100 classes are also grouped into 20 superclasses with each super class consisting of five classes. For convenience, we refer to the 20 super-classes as CIFAR-100/20; 3) STL10, which contains labels only for the 13000 images and the remaining unlabeled images are from various classes. The encoder is trained across the labeled and unlabeled instances, where the classifier is trained and evaluated only for the labeled instances; and 4) Tiny-ImageNet/200, which is a subset of ImageNet containing 200 classes downsampled to a lower resolution. <ref type="table" target="#tab_0">Table I</ref> presents the details of each set, including the number of training and validation elements, the number of clusters, the image resolution, and the multi-crop ranges during the training. By "2x28+4x18", we mean two high resolution views of crop size 28, and four low resolution views of crop size 18.</p><p>The proposed algorithm is compared with a range of stateof-the-art visual clustering approaches in terms of unsupervised learning metrics. We further demonstrate the effectiveness of the proposed single-phase method on datasets with up to 200 classes. Ablation studies are also performed to evaluate the effects of different hyper-parameters to examine the role of the most important components of the proposed algorithm and the sensitivity to the key parameters. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Metrics for Unsupervised Learning</head><p>Three quantitative metrics for supervised learning are adopted to measure the performance of IMC-SwAV: 1) Accuracy (ACC); 2) Normalized mutual information (NMI) <ref type="bibr" target="#b50">[50]</ref>; and 3) Adjusted rand index (ARI). The ACC reports the accuracy by finding the best mapping between the predicted labels and the ground truth labels. The mapping matrix is found using the Hungarian algorithm <ref type="bibr" target="#b35">[35]</ref>. NMI measures the mutual information between the two distributions (the model's prediction and the ground truth), which is scaled between zero and one. ARI measures the similarity between the two particular distributions by comparing all possible pairs and measuring those assigned in the same cluster and those in different ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experimental Settings</head><p>1) Architecture Implementation: For fair comparisons, we adopt the same settings across all datasets as those given in <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[9]</ref>. Specifically, the proposed framework implements an encoder based on ResNet18 <ref type="bibr" target="#b22">[22]</ref> architecture. The classifier employs a multilayer perceptron net containing two hidden layers on top of the embedding layer. Similar to <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b8">[9]</ref>, we use a projection head to reduce the dimension of the embedding layer prior to the comparison with the prototypes. For the overall framework, the Adam optimizer <ref type="bibr" target="#b32">[32]</ref> is adopted for training. The learning rate is set to 5 ? 10 ?4 with a warmup schedule in the first 500 training iterations. We use a decay learning rate of 0.4 in epochs [150, 300, 400] and a total of 500 epochs is run. The mini-batch size is set to 256 across all datasets except Tiny-ImageNet/200, for which the batch size was set 512 due to the large number of classes in this dataset. A 2 weight decay regularizer is used with a rate of 1 ? 10 ?5 . We apply an additional two-sided regularizer, in a similar form to that reported in <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b15">[16]</ref>, to the logit outputs of the classifier's representation. Specifically, we penalize any absolute value higher than five prior to the Softmax activation function, hence preventing the classifier from making predictions with a high confidence level in the early stage of the training phase as:</p><formula xml:id="formula_13">L cluster ? (U, Y ) + ? ? 1 m m i k j max(|x i,j |?5, 0)<label>(8)</label></formula><p>where x is the logit outputs of the classifier, ? is a weight parameter set to 1 ? 10 ?2 across all experiments, m is the batch size, and k is the number of clusters. 2) Hyper-Parameters Selection: The settings below are applied across all experiments. The temperature scalar ? in Softmax smoothness is set to 0.1 as recommended in <ref type="bibr" target="#b4">[5]</ref>. Similarly, to prevent degeneracy, we set the hyperparameter of the weighted entropy of Sinkhorn-Knopp to 0.05 and optimize it for three iterations. The implemented prototype vectors are set to k = 1000 (except in the ablation studies). In the clustering objective, we set the weight factor of the marginal entropy ? = 4 for all experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Transformation Functions:</head><p>In this work, we follow the same transformation/augmentation scheme as presented in <ref type="bibr" target="#b8">[9]</ref> across all experiments. Each instance is horizontally flipped at a probability of 0.5. All images are modified with color jittering at a rate: brightness 0.4, contrast 0.4, saturation 0.4, and hue 0.2. Color jitter is applied at a probability of 0.8. A probability of 0.25 is also used for a gray-scale instance transformation. The re-sizing rates are set to the range between 0.2 and 1.0, between 0.08 and 0.4, respectively, for the two main views (of high resolution) and four smaller views (of low resolution). The aspect ratio in both cases is set to (3/4, 4/3). The corresponding crop sizes are given in <ref type="table" target="#tab_0">Table I</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Comparative Results</head><p>Table II presents the results over 15 independent runs. To demonstrate the stability of the proposed IMC-SwAV, in each run the model's parameters are randomly initialized. The same process is followed across all datasets. We present the mean, standard deviation (STD), and the best result. In contrast to the previous clustering studies in which all instances are used for training and validation, we use a similar validation process as that in <ref type="bibr" target="#b47">[47]</ref>, where the validation results are derived from the validation data that has not been seen by the model. During the training, all components of the framework are jointly trained with training instances only. We list the results obtained by a broad range of state-of-the-art unsupervised learning algorithms for comparison. It should be stressed that the ground truth is used only for computing the relevant metrics. To further demonstrate the effectiveness of our approach, we freeze the encoder parameters and train a single layer net on top of the embedding layer in a supervised manner. We present these supervised learning result to further demonstrate the capability of the proposed unsupervised clustering approach. Finally, we compare the clustering results of K-means by using the same features extracted by the SwAV method. We also report the best results of "SwAV + K-means" over 20 initializations of K-means' centroids. <ref type="table" target="#tab_0">Table II</ref>, the average performance of IMC-SwAV outperforms all state-of-the-art methods on CIFAR-10, CIFAR-100/20, and Tiny-ImageNet and produces competitive results on STL10, while the best results of our method are the best among all algorithms under comparison. Note that only the best results of all algorithms under comparison are reported in <ref type="table" target="#tab_0">Table II</ref>. IMC-SwAV performs clustering based on the online mode in the swap training strategy without the requirement of a pre-trained model or the implementation of multi-phase strategies, thus providing an additional advantage in terms of simplicity and training time. We observe a large margin between the clustering performance of IMC-SwAV and SwAV + K-means. Since both methods are trained on the same features, this performance improvement can be attributed to the defined clustering objective and the jointly training proposed in this work. Furthermore, the increased number of parameters of the classifier has a low computational impact during the training, with the training time on a Nvidia Quadro RTX6000 GPU being increased by 1.08x only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>As presented in</head><p>In the following, we further demonstrate our model performance by evaluating the individual classes and instances.  1) Individual class performance: To examine the performance of individual class accuracies on CIFAR-10, a confusion matrix with the predictions made by IMC-SwAV on the unseen validation set is presented in <ref type="figure" target="#fig_4">Fig. 3</ref>. Note that in contrast to the previous methods, none of the implemented components are trained on the validation set. Each class consists of 1000 instances. In the figure, x-axis and yaxis indicates the model's predictions and the ground truth, respectively. From these results, it can be seen that IMC-SwAV shows a high accuracy on the majority of the classes. Mismatch inaccurate predictions are mainly observed between classes 'Cat' and 'Deer'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2) Visual interpretation:</head><p>We visualize the predictions made by IMC-SwAV on STL10 dataset in <ref type="figure" target="#fig_5">Fig. 4</ref>. The predictions are visualized via Grad-Cam <ref type="bibr" target="#b43">[43]</ref>. IMC-SwAV is able to find specific visual elements to achieve the successful predictions such as airplane wings or horse's body shape. On the other hand, from the visual heatmap layers of the negative predictions, we see that the model fails to recognize specific object  3) Influence of sample size: We vary the number of the training instances per class by an increasing interval of 500 per experiment within the range of [1000, 5000], where 5000 is the maximum number of samples in each CIFAR-10 class (recall that CIFAR-10's classes are equally spread with each class containing 5000 element). The model is trained on the selected subset only, and the performance of validation set is illustrated in <ref type="figure" target="#fig_6">Fig. 5</ref>. As expected, the model's precision is gradually decreasing when fewer training samples are considered. Notably, IMC-SwAV's performance remains stable when the sample size is larger than 2500.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Effectiveness to a large number of clusters:</head><p>To further validate our method on a dataset with a large number of clusters, we conduct an experiment on the 100 sub-class of CIFAR-100 to evaluate the clustering performance of IMC-SwAV. The features extracted by IMC-SwAV are directly compared with those obtained by the K-means algorithm. The metrics of Top-1 and Top-5 accuracy, as well as the rest unsupervised metrics are listed in <ref type="table" target="#tab_0">Table III</ref>. These results demonstrate that IMC-SwAV performs well on this highly demanding clustering task. The proposed algorithm achieves a large margin of 15% on Top-1 ACC and 19% on Top-5 ACC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Ablation Studies</head><p>In this subsection, we experiment with a variety of hyperparameters to evaluate the effectiveness of the proposed IMC-SwAV. All parameters remain unchanged, as per the main settings, except for those to be studied.    <ref type="figure" target="#fig_7">Figure 6</ref> shows the results from five independent runs of the unsupervised learning task. From these results, we conclude that IMC-SwAV shows robustness over different numbers of prototypes with the lowest mean value above 86.5%. We also note that for k larger than 300, all three performance metrics become less sensitive to k . Additionally, we note that our choice to set k to 1000 prototypes in the main settings is not the optimum in terms of all metrics on CIFAR-10. However, in unsupervised learning, the ground truth is unknown and hence it is more realistic to compare the performance without using the optimal parameter setting.</p><p>2) Experiment with different encoder architectures: In this subsection, we examine the performance of the proposed IMC-SwAV by varying the encoder's architecture by using different types of the ResNet <ref type="bibr" target="#b22">[22]</ref> models. Specifically, we compare the performance of the proposed method when ResNet34 (21.3M parameters) and ResNet50 (23.5M parameters), respectively, is adopted to replace ResNet18 (11.1M parameters) used in the main experiments. All models are evaluated over five independent runs (the results of ResNet18 are averaged over 15 runs as in the main experiment) and the average and best recorded performances are reported for each model. The   <ref type="table" target="#tab_4">Table V.</ref> reported metrics are on the unseen test subset, and all frameworks are optimised with training subset only. The results are listed in <ref type="table" target="#tab_0">Table IV</ref>. As expected, larger models achieve slightly better performance in terms of all metrics. Note also that the discrepancies between different metrics of each model are minor, with the highest differences being observed difference on CIFAR-10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3) Multiple Crops:</head><p>We demonstrate the impact of the multiple crops strategy on the clustering performance on CIFAR-10. We change the number of low resolution cropped views with all other settings unchanged. First, a basic setting with two main views of the original image dimensions is evaluated. Then, we add two, four, and six additional low resolution views, respectively. The size of the two main views is decreased to 28x28 to reduce the computation time. The resizing ratio remains unchanged: [0.2, 1.0] for the two main views, and [0.08, 0.4] for the low resolution views. We report the mean and STD of the metrics over five independent experiments. Additionally, the accuracy of a single layer net, which is trained independently on generated features through a supervised mode, is also included. <ref type="table" target="#tab_4">Table V</ref> presents the results of the multiple crop experiments. From results, we notice that the additional low resolution views increase the performance in terms of all metrics, for both the unsupervised and supervised models. The last column presents the ratio of training time based on a basic training strategy of 2x32. The training accuracy over the iterations are presented in <ref type="figure" target="#fig_9">Fig. 7</ref> for each experiment. We note that the mini-crop strategy of "2x28+4x18" already reaches satisfactory results (87.7 ACC) within 250 iterations, in comparison to the full experiment of a simple setup. Recall, the two-crop strategy holds an advantage by using the original resolution of 2x32 instead of 2x28.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Combinations of crop sizes:</head><p>To further examine the impact of multi-crop's strategy, we vary the resolution of crop sizes of main views (high) and smaller views (low) within the intervals of <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b32">32]</ref> and <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b22">22]</ref>, respectively. All experiments are performed on CIFAR-10 based on the main setting. We also preserve the same crop ratios and the number of views (two main views and four smaller views). Since, the resizing ratio of the smaller view is set to 0.4, the difference between high and low resolutions does not exceed the absolute difference of the maximum 14 pixels and minimum four pixels, to keep proportional to the crop size of main view. <ref type="figure" target="#fig_10">Figure  8</ref> presents our findings in terms of ACC. The performance of IMC-SwAV slightly degrades in a very low resolution in combination with "2x20+4x12", probably because the model fails to capture sufficient semantic details. On the other hand, all combinations above the crop sizes of (high view) ? 26 and (low view) ? 18 exhibit a satisfactory accuracy above 86%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Other representation learning strategies:</head><p>In this section, we aim to demonstrate that our clustering strategy is not restricted to the SwAV <ref type="bibr" target="#b4">[5]</ref> framework and is also applicable to other self-supervised learning strategies. Here, we evaluate our single-phase clustering method that adopts SeLa <ref type="bibr" target="#b56">[55]</ref>, another grouping based self-supervised learning method, to replace SwAV. Similar to IMC-SwAV, the components of the encoder and the classifier are jointly trained in a singlephase mode. We compare the performance of the variant of our clustering method using Sela (called IMC-SeLa) with the K-means algorithm, and a supervised classifier net trained on same extracted features. The parameters of the encoder model are optimized with the self-supervised loss function of the adopted strategy only without using any additional loss functions or pre-trained models. Similar to the main experiments, the framework is optimized on training subset and the performance evaluation is made on the validation subset. Each method is performed for five independent runs and the best result is reported. For a fair comparison, the architecture is similar to the main experiment with the encoder being based on a ResNet18 network.</p><p>The comparative results are listed in <ref type="table" target="#tab_0">Table VI</ref>, from which a performance degradation of all methods under comparison can be observed, implying that the extracted features are less separable. This can be easily validated by examining the results of the supervised linear classifier net (Supervised in the Tables) trained on the extracted features (for SwAV <ref type="bibr" target="#b4">[5]</ref> in <ref type="table" target="#tab_0">Table II</ref> and for SeLa <ref type="bibr" target="#b56">[55]</ref> in <ref type="table" target="#tab_0">Table VI</ref>). This can also be confirmed by the K-means clustering approach on the same features extracted by the two self-supervised techniques. These results indicate that the final performance of the proposed framework also depends on the performance of the self-supervised learning algorithm it adopts. Nevertheless, IMC-SeLa still outperforms "SeLA + K-means" at a large margin on CIFAR-10, CIFAR-100/20 and Tiny-ImageNet/200.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>This study presents a single-phase framework for image clustering, called IMC-SwAV. We introduce a modified mutual information to jointly train the framework by maximizing the dependency of a self-labelling assignment strategy and an implemented classifier. IMC-SwAV achieves highly competitive performance on challenging datasets compared to the state-ofthe-art. In addition to the encouraging clustering performance, we demonstrate the robustness of the proposed method to the parameter settings and the possibility to adopt a different selfsupervised learning technique. Although the proposed model achieves significant capabilities in clustering, the multi-crop training strategy adopted in the framework slightly increases the time complexity. Additionally, we observe a dependency of its performance on the grouping based self-supervised learning method. Our future work will aim to remove the requirement of using the multicrop views without deteriorating the performance of the overall framework. Moreover, we will examine the effectiveness of other grouping based self-supervised learning algorithms in the proposed single-phase training framework to make it available for a wider range of applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>This project is funded by an EPSRC industrial CASE award (number 17000013) and Department for Business, Energy and Industrial Strategy through the National Measurement System (122416). (Corresponding author: Yaochu Jin) F. Ntelemis and Y. Jin are with the Department of Computer Science, University of Surrey, Guildford, GU2 7XH, United Kingdom. (Email: {f.ntelemis; yaochu.jin}@surrey.ac.uk) S. A. Thomas is with the National Physical Laboratory, Teddington, TW11 0LW, United Kingdom. (Email: spencer.thomas@npl.co.uk)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>A diagram presents the framework's structure and a training instance x i , transformed twice through T (). Here E ? denotes the encoder model, and the comparable prototypes as C. A ? indicates the introduced classification model implemented on top of the embedding output (diagram is designed via PlotNeuralNet<ref type="bibr" target="#b28">[28]</ref>).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>self-labelling target distributions of the two transformed views of the i-th training instance, and u</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2 :</head><label>2</label><figDesc>A scatter illustration of JSD pairwise distances between two probabilistic distributions U<ref type="bibr" target="#b0">(1)</ref> and U (2) generated by a pre-trained encoder of the same 32 image instances, where different transformations applied in each instance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 :</head><label>3</label><figDesc>The above confusion matrix showing the predictions and ground truth made by the proposed model on CIFAR-10 validation set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 :</head><label>4</label><figDesc>This illustration is an interpretation of visual activation heatmap of accurate (positive -green frame) and inaccurate (negative -red frame) prediction made by our model on STL10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>Performance of IMC-SwAV made on CIFAR-10 for a limited number of training elements. x-axis presents the number of training samples (by thousand) per class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 :</head><label>6</label><figDesc>These diagrams plot the performance metrics on CIFAR-10 over different numbers of prototypes. From top to low: ACC, NMI and ARI. All figures report the number of prototypes in x-axis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>ACC NMI ARI ACC NMI ARI IMC-SwAV-18 (Avg) 89.1 81.1 79.0 49.0 50.3 33.7 83.1 72.9 68.5 IMC-SwAV-18 (Best) 89.7 81.8 80.0 51.9 52.7 36.1 85.3 74.7 71.6 IMC-SwAV-34 (Avg) 89.5 81.7 79.9 50.2 51.2 34.6 84.5 74.8 70.9 IMC-SwAV-34 (Best) 90.2 82.4 80.9 52.1 53.2 36.3 86.0 76.7 73.3 IMC-SwAV-50 (Avg) 91.0 83.8 82.6 51.2 52.6 35.6 86.3 77.3 73.8 IMC-SwAV-50 (Best) 91.4 84.1 82.9 52.7 54.0 37.0 87.1 77.9 75.0 1) Prototypes: We examine the performance of IMC-SwAV by varying the number of prototypes, k , in the range of [100, 2000] while keeping all other parameters unchanged.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 7 :</head><label>7</label><figDesc>Illustration presents the accuracy per epoch of each multi-crop implementation of</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 8 :</head><label>8</label><figDesc>Presentation with various combinations of high and low crop sizes. x-axis represent different low resolution crop sizes and high resolution are associated with different colours and symbols.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Descriptions of the Datasets</figDesc><table><row><cell>Name</cell><cell>Train. No.</cell><cell>Val. No.</cell><cell>Classes (k)</cell><cell>Res.</cell><cell>Multi-crops</cell></row><row><cell>CIFAR-10</cell><cell>50000</cell><cell>10000</cell><cell>10</cell><cell>32x32</cell><cell>2x28+ 4x18</cell></row><row><cell>CIFAR-100 CIFAR-100/20</cell><cell>50000</cell><cell>10000</cell><cell>100 20</cell><cell>32x32</cell><cell>2x28+ 4x18</cell></row><row><cell>STL10</cell><cell>105000</cell><cell>8000</cell><cell>10</cell><cell>96x96</cell><cell>2x76+ 4x52</cell></row><row><cell cols="2">Tiny-ImageNet 100000</cell><cell>10000</cell><cell>200</cell><cell>64x64</cell><cell>2x56+ 4x36</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Comparative results on the three benchmarks. The top three methods in terms of the best results highlighted. Note that our method is evaluated for 15 independent runs across all datasets, and the average and best results are reported.Avg?) 89.1?0.5 81.1?0.7 79.0?1.0 49.0?1.8 50.3?1.2 33.7?1.3 83.1?1.0 72.9?0.9 68.5?1.4 27.9?0.3 48.5?2.0 14.3?2.1</figDesc><table><row><cell>Method/Dataset</cell><cell>ACC</cell><cell>CIFAR-10 NMI</cell><cell>ARI</cell><cell>ACC</cell><cell>CIFAR-100/20 NMI</cell><cell>ARI</cell><cell>ACC</cell><cell>STL10 NMI</cell><cell>ARI</cell><cell cols="3">Tiny-ImageNet/200 ACC NMI ARI</cell></row><row><cell>K-means</cell><cell>22.9</cell><cell>8.7</cell><cell>4.9</cell><cell>13.0</cell><cell>8.4</cell><cell>2.8</cell><cell>19.2</cell><cell>12.5</cell><cell>6.1</cell><cell>2.5</cell><cell>6.5</cell><cell>0.5</cell></row><row><cell>AE [2]</cell><cell>31.4</cell><cell>23.9</cell><cell>16.9</cell><cell>16.5</cell><cell>10.0</cell><cell>4.8</cell><cell>30.3</cell><cell>25.0</cell><cell>16.1</cell><cell>4.1</cell><cell>13.1</cell><cell>0.7</cell></row><row><cell>VAE [33]</cell><cell>29.1</cell><cell>24.5</cell><cell>16.7</cell><cell>15.2</cell><cell>10.8</cell><cell>4.0</cell><cell>28.2</cell><cell>20.0</cell><cell>14.6</cell><cell>3.6</cell><cell>11.3</cell><cell>0.6</cell></row><row><cell>DCGAN [41]</cell><cell>31.5</cell><cell>26.5</cell><cell>17.6</cell><cell>15.1</cell><cell>12.0</cell><cell>4.5</cell><cell>29.8</cell><cell>21.0</cell><cell>13.9</cell><cell>4.1</cell><cell>13.5</cell><cell>0.7</cell></row><row><cell>DEC [53]</cell><cell>30.1</cell><cell>25.7</cell><cell>16.1</cell><cell>18.5</cell><cell>13.6</cell><cell>5.0</cell><cell>35.9</cell><cell>27.6</cell><cell>18.6</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>JULE [54]</cell><cell>27.2</cell><cell>19.2</cell><cell>13.8</cell><cell>13.7</cell><cell>10.3</cell><cell>3.3</cell><cell>27.7</cell><cell>18.2</cell><cell>16.4</cell><cell>3.3</cell><cell>10.2</cell><cell>0.6</cell></row><row><cell>ADC [20]</cell><cell>32.5</cell><cell>-</cell><cell>-</cell><cell>16.0</cell><cell>-</cell><cell>-</cell><cell>53.0</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DAC [7]</cell><cell>52.2</cell><cell>39.6</cell><cell>30.6</cell><cell>23.8</cell><cell>18.5</cell><cell>8.8</cell><cell>47.0</cell><cell>36.6</cell><cell>25.7</cell><cell>6.6</cell><cell>19.0</cell><cell>1.7</cell></row><row><cell>IMSAT-DCGAN [38]</cell><cell>70.0</cell><cell>-</cell><cell>-</cell><cell>32.4</cell><cell>-</cell><cell>-</cell><cell>58.7</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DDC [6]</cell><cell>52.4</cell><cell>42.4</cell><cell>32.9</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>48.9</cell><cell>37.1</cell><cell>26.7</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DCCM [52]</cell><cell>62.3</cell><cell>49.6</cell><cell>40.8</cell><cell>32.7</cell><cell>28.5</cell><cell>17.3</cell><cell>48.2</cell><cell>37.6</cell><cell>26.2</cell><cell>10.8</cell><cell>22.4</cell><cell>3.8</cell></row><row><cell>IIC [29]</cell><cell>61.7</cell><cell>51.1</cell><cell>41.1</cell><cell>25.7</cell><cell>22.5</cell><cell>11.7</cell><cell>59.6</cell><cell>49.6</cell><cell>39.7</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DCCS [57]</cell><cell>65.6</cell><cell>56.9</cell><cell>46.9</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>53.6</cell><cell>49.0</cell><cell>36.2</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PICA [30]</cell><cell>69.6</cell><cell>59.1</cell><cell>51.2</cell><cell>33.7</cell><cell>31.0</cell><cell>17.1</cell><cell>71.3</cell><cell>61.1</cell><cell>53.1</cell><cell>9.8</cell><cell>27.7</cell><cell>4.0</cell></row><row><cell>DRC [59]</cell><cell>72.7</cell><cell>62.1</cell><cell>54.7</cell><cell>36.7</cell><cell>35.6</cell><cell>20.8</cell><cell>74.7</cell><cell>64.4</cell><cell>56.9</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>EmbedUL [18]</cell><cell>81.0</cell><cell>-</cell><cell>-</cell><cell>35.3</cell><cell>-</cell><cell>-</cell><cell>66.5</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>CC [36]</cell><cell>79.0</cell><cell>70.5</cell><cell>63.7</cell><cell>42.9</cell><cell>43.1</cell><cell>26.6</cell><cell>85.0</cell><cell>76.4</cell><cell>72.6</cell><cell>14.0</cell><cell>34.0</cell><cell>7.1</cell></row><row><cell>SCAN [48] (Best)</cell><cell>88.3</cell><cell>79.7</cell><cell>77.2</cell><cell>50.7</cell><cell>48.6</cell><cell>33.3</cell><cell>80.9</cell><cell>69.8</cell><cell>64.6</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Supervised</cell><cell>92.8</cell><cell>-</cell><cell>-</cell><cell>76.1</cell><cell>-</cell><cell>-</cell><cell>89.2</cell><cell>-</cell><cell>-</cell><cell>45.4</cell><cell>-</cell><cell>-</cell></row><row><cell>SwAV [5] + K-means</cell><cell>78.4</cell><cell>67.5</cell><cell>61.3</cell><cell>40.1</cell><cell>47.0</cell><cell>10.6</cell><cell>74.9</cell><cell>70.5</cell><cell>54.0</cell><cell>18.2</cell><cell>46.8</cell><cell>5.2</cell></row><row><cell>IMC-SwAV (IMC-SwAV (Best)</cell><cell>89.7</cell><cell>81.8</cell><cell>80.0</cell><cell>51.9</cell><cell>52.7</cell><cell>36.1</cell><cell>85.3</cell><cell>74.7</cell><cell>71.6</cell><cell>28.2</cell><cell>52.6</cell><cell>14.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>CIFAR100 -Evaluation on 100 Classes</figDesc><table><row><cell></cell><cell cols="2">Top-1 ACC Top-5 ACC</cell><cell>NMI</cell><cell>ARI</cell></row><row><cell>IMC-SwAV</cell><cell>45.1</cell><cell>67.5</cell><cell>60.8</cell><cell>30.7</cell></row><row><cell>SwAV + K-means</cell><cell>30.2</cell><cell>48.6</cell><cell>56.25</cell><cell>12.3</cell></row><row><cell>elements.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV :</head><label>IV</label><figDesc>IMC-SwAV with different ResNet architectures indicated by the method suffix</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V :</head><label>V</label><figDesc>Effectiveness of Multiple Crops Strategies</figDesc><table><row><cell>Crops</cell><cell>ACC</cell><cell>NMI</cell><cell>ARI</cell><cell>Sup.</cell><cell>Train Time</cell></row><row><cell>2x32</cell><cell cols="3">78.7?1.0 66.2?1.1 61.2?1.3</cell><cell>86.1</cell><cell>1x</cell></row><row><cell>2x28+2x18</cell><cell cols="3">87.2?1.1 78.6?1.4 75.8?2.0</cell><cell>92.1</cell><cell>1.1x</cell></row><row><cell>2x28+4x18</cell><cell cols="3">89.1?0.5 81.1?0.7 79.0?1.0</cell><cell>92.8</cell><cell>1.7x</cell></row><row><cell>2x28+6x18</cell><cell cols="3">89.4?0.6 81.2?0.9 79.0?1.8</cell><cell>93.2</cell><cell>2.4x</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE VI :</head><label>VI</label><figDesc>Clustering strategy adopted to SeLA training CIFAR-10 CIFAR-100/20 Tiny-ImgNet200 ACC NMI ARI ACC NMI ARI ACC NMI ARI IMC-SeLa 74.5 65.2 59.1 39.4 40.7 25.1 19.1 45.2 7.9 SeLA [55] + Kmeans 64.0 56.4 47.3 34.7 34.3 18.0 17.1 43.2 6.7</figDesc><table><row><cell>Method/</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Supervised</cell><cell>87.1 -</cell><cell>-66.6 -</cell><cell>-</cell><cell>34.2 -</cell><cell>-</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Buchwalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 19</title>
		<editor>B. Sch?lkopf, J. C. Platt, and T. Hoffman</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fcm: The fuzzy c-means clustering algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">C</forename><surname>Bezdek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Ehrlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Full</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Geosciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="191" to="203" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9912" to="9924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiwen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.01681</idno>
		<title level="m">Shiming Xiang, and Chunhong Pan. Deep Discriminative Clustering Analysis. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2019-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Shiming Xiang, and Chunhong Pan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<meeting><address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017-10-22" />
			<biblScope unit="page" from="5880" to="5888" />
		</imprint>
	</monogr>
	<note>Deep adaptive image clustering</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep adaptive image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5880" to="5888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<editor>Hal Daum? III and Aarti Singh</editor>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mean shift analysis and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dorin</forename><surname>Comaniciu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Meer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Computer Vision</title>
		<meeting>the International Conference on Computer Vision<address><addrLine>Kerkyra, Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="1197" to="1203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joy</forename><forename type="middle">A</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>Wiley-Interscience</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sinkhorn distances: Lightspeed computation of optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="2292" to="2300" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with exemplar convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">A</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1734" to="1747" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Jensen-shannon divergence and hilbert space embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fuglede</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Topsoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium onInformation Theory</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Neural Information Processing Systems</title>
		<meeting>the 27th International Conference on Neural Information Processing Systems<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Bootstrap your own latent -a new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Valko</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="21271" to="21284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<editor>Yee Whye Teh and Mike Titterington</editor>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics<address><addrLine>Sardinia, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-05" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="13" to="15" />
		</imprint>
		<respStmt>
			<orgName>Chia Laguna Resort</orgName>
		</respStmt>
	</monogr>
	<note>Workshop and Conference Proceedings</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mitigating embedding and class assignment mismatch in unsupervised image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungkyu</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sundong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meeyoung</forename><surname>Cha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020 -16th European Conference</title>
		<editor>Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm</editor>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">12369</biblScope>
			<biblScope unit="page" from="768" to="784" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XXIV</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mitigating embedding and class assignment mismatch in unsupervised image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungkyu</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sundong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meeyoung</forename><surname>Cha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Associative deep clustering: Training a classification network with no labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>H?usser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Plapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elie</forename><surname>Aljalbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition -40th German Conference</title>
		<editor>Thomas Brox, Andr?s Bruhn, and Mario Fritz</editor>
		<meeting><address><addrLine>Stuttgart, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-10-09" />
			<biblScope unit="volume">11269</biblScope>
			<biblScope unit="page" from="18" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bayesian hierarchical clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><forename type="middle">A</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML &apos;05</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee-Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R R</forename><surname>G E Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning discrete representations via information maximizing self-augmented training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiya</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eiichi</forename><surname>Matsumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1558" to="1567" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<idno>v1.0.0</idno>
		<title level="m">Haris Iqbal. Harisiqbal88/plotneuralnet</title>
		<imprint>
			<date type="published" when="2018-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep semantic clustering by partition confidence maximisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabo</forename><surname>Shaogang Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Variational autoencoders and nonlinear ICA: A unifying framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilyes</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><forename type="middle">Pio</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 23rd International Conference on Artificial Intelligence and Statistics</title>
		<editor>Silvia Chiappa and Roberto Calandra</editor>
		<meeting><address><addrLine>Online [Palermo, Sicily, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-08-28" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="2207" to="2217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations</title>
		<meeting><address><addrLine>Banff, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04-14" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistics Quarterly</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="83" to="97" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zitao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dezhong</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<title level="m">Contrastive clustering. Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2021-05" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="8547" to="8555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2016</title>
		<editor>Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Image clustering using an augmented generative adversarial network and information maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Foivos</forename><surname>Ntelemis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaochu</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spencer</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d?lch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Computational optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Peyr?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">4th International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05-02" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Deep density-based image clustering. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhou</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ni</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zenglin</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">197</biblScope>
			<biblScope unit="page">105841</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Grad-cam: Visual explanations from deep networks via gradientbased localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">The Challenges of Clustering High Dimensional Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Steinbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levent</forename><surname>Ert?z</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vipin</forename><surname>Kumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="273" to="309" />
			<pubPlace>Berlin Heidelberg; Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation Learning with Contrastive Predictive Coding. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2018-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Scan: Learning to classify images without labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Wouter Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020</title>
		<editor>Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="268" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Scan: Learning to classify images without labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Wouter Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on Machine Learning, ICML &apos;08</title>
		<meeting>the 25th International Conference on Machine Learning, ICML &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Information theoretic measures for clusterings comparison: is a correction for chance necessary?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Nguyen Xuan Vinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Epps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML &apos;09: Proceedings of the 26th Annual International Conference on Machine Learning</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1073" to="1080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A mcmc approach to hierarchical mixture modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deep comprehensive correlation mining for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyu</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<editor>Maria Florina Balcan and Kilian Q</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<meeting>The 33rd International Conference on Machine Learning<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="20" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5147" to="5156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Self-labelling via simultaneous clustering and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rupprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Graph degree linkage: Agglomerative clustering on a directed graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2012</title>
		<editor>Andrew Fitzgibbon, Svetlana Lazebnik, Pietro Perona, Yoichi Sato, and Cordelia Schmid</editor>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="428" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Deep image clustering with category-style representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yefeng</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Temporal action detection with structured segment networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="74" to="95" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huasong</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongming</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian-Sheng</forename><surname>Hua</surname></persName>
		</author>
		<title level="m">Deep robust clustering by contrastive learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
