<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AASIST: AUDIO ANTI-SPOOFING USING INTEGRATED SPECTRO-TEMPORAL GRAPH ATTENTION NETWORKS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jee-Weon</forename><surname>Jung</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Naver Corporation</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hee-Soo</forename><surname>Heo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Naver Corporation</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hemlata</forename><surname>Tak</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">EURECOM</orgName>
								<address>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hye-Jin</forename><surname>Shim</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Seoul</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joon</forename><forename type="middle">Son</forename><surname>Chung</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Naver Corporation</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bong-Jin</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Naver Corporation</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ha-Jin</forename><surname>Yu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Seoul</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Evans</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">EURECOM</orgName>
								<address>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AASIST: AUDIO ANTI-SPOOFING USING INTEGRATED SPECTRO-TEMPORAL GRAPH ATTENTION NETWORKS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-audio spoofing detection</term>
					<term>anti-spoofing</term>
					<term>graph attention networks</term>
					<term>end-to-end</term>
					<term>heterogeneous</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Artefacts that differentiate spoofed from bona-fide utterances can reside in spectral or temporal domains. Their reliable detection usually depends upon computationally demanding ensemble systems where each subsystem is tuned to some specific artefacts. We seek to develop an efficient, single system that can detect a broad range of different spoofing attacks without score-level ensembles. We propose a novel heterogeneous stacking graph attention layer which models artefacts spanning heterogeneous temporal and spectral domains with a heterogeneous attention mechanism and a stack node. With a new max graph operation that involves a competitive mechanism and an extended readout scheme, our approach, named AA-SIST, outperforms the current state-of-the-art by 20% relative. Even a lightweight variant, AASIST-L, with only 85K parameters, outperforms all competing systems.</p><p>Index Termsaudio spoofing detection, anti-spoofing, graph attention networks, end-to-end, heterogeneous</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The audio anti-spoofing (i.e., spoofing detection) task can bridge a speaker verification into a real world application by determining whether an input speech utterance is genuine (bona-fide) or spoofed, thus, improving the credibility. Practical spoofing detection systems are required to detect spoofed utterances generated using a wide range of different techniques. The ASVspoof community has led research in the field with a series of challenges accompanied by public datasets <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. Two major scenarios are being studied, namely logical access (LA) and physical access. The focus in this paper is LA, which considers spoofing attacks mounted with voice conversion and text-to-speech algorithms.</p><p>Recent studies show that discriminative information (i.e., spoofing artefact) can reside in both spectral and temporal domains <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>. Artefacts tend to be dependent upon the nature of the attack and the specific algorithm used. Adaptive mechanisms, which have the flexibility to concentrate on the domain in which the artefacts lie, are therefore crucial to reliable detection. In our recent works <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, we proposed end-to-end systems leveraging a RawNet2-alike encoder <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> and graph attention networks <ref type="bibr" target="#b13">[14]</ref>. We modeled both spectral and temporal information concurrently using two parallel graphs and then applied element-wise multiplication on two graphs. While we achieved state-of-the-art performance in [11], we Code and models are available at: https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>believe that there is still room for further improvement because two graphs are heterogeneous, integrating them using a heterogeneityaware technique would be beneficial.</p><p>We propose four extensions to our previous work, RawGAT-ST <ref type="bibr" target="#b10">[11]</ref> where the first three compose the proposed model named AASIST and the last builds a smaller version of the AASIST. First, we propose an extended variant of the graph attention layer, referred to as a "heterogeneous stacking graph attention layer" (HS-GAL). It facilitates the concurrent modeling of heterogeneous (spectral and temporal) graph representations. HS-GAL includes a modified attention mechanism considering heterogeneity and an additional stack node, each inspired from <ref type="bibr" target="#b14">[15]</ref> and <ref type="bibr" target="#b15">[16]</ref> respectively. HS-GAL can directly model two arbitrary graphs where the two graphs can have different numbers of nodes and different dimensionalities. Second, we propose a mechanism referred to as "max graph operation" (MGO) that mimics the max feature map <ref type="bibr" target="#b16">[17]</ref>. MGO involves two branches where each branch includes two HS-GALs and graph pooling layers, followed by an element-wise maximum operation. The underlying objective here is to enable different branches to learn different groups of artefacts. The elements that include artefacts would survive the maximum operation. Third, we present a new readout scheme that utilizes the stack node. Finally, given the application of anti-spoofing solutions in aasisting speaker verification systems <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> and given the associated requirement for practical, lightweight models, we further propose a lightweight variant of AA-SIST which comprises only 85K parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PRELIMINARIES</head><p>In this section, we summarise the components that are common to the RawGAT-ST <ref type="bibr" target="#b10">[11]</ref> and new AASIST models. We describe: i) the RawNet2-based encoder used for extracting high-level feature maps from raw input waveforms; ii) the graph module which includes graph attention and graph pooling layers. The two components correspond to "encoder" and "graph module" in <ref type="figure" target="#fig_0">Figure 1</ref>, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">RawNet2-based encoder</head><p>A growing number of researchers are adopting models that operate directly upon raw waveform inputs. The work described in this paper utilizes a variant of the RawNet2 model introduced in <ref type="bibr" target="#b11">[12]</ref> for the task of speaker verification and applied subsequently for antispoofing <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b12">13]</ref>. It extracts high-level representations F , F ? R C?S?T directly from raw waveform inputs where C, S and T are the number of channels, spectral (frequency) bins, and the temporal sequence length respectively. Overall framework of the proposed AASIST. Identical to <ref type="bibr" target="#b10">[11]</ref>: encoder extracts F and two graph modules each model spectral and temporal domains. Proposed: then, the proposed max graph operation technique adopts two branches that model heterogeneous graphs in parallel, followed by an element-wise maximum. Each branch includes two proposed HS-GAL layers and two graph pooling layers (graph pooling layers and one HS-GAL layer is omitted in the illustration). Finally, the maximum and average of nodes, and the stack node are concatenated followed by an output layer.</p><p>Different to the original RawNet2 model, we interpret the output of the sinc-convolution layer as a 2-dimensional image with a single channel (akin to a spectrogram) rather than a 1-dimensional sequence with multiple filters by treating the output of each filter as a spectral bin. A series of six residual blocks with pre-activation <ref type="bibr" target="#b19">[20]</ref> is used to extract the high-level representation. Each residual block comprises a batch normalization layer <ref type="bibr" target="#b20">[21]</ref>, a 2-dimensional convolution layer, SeLU activation <ref type="bibr" target="#b21">[22]</ref>, and a max pooling layer. Further information can be found in <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Graph module</head><p>Graph attention network. Recent advances in graph neural networks have brought performance breakthroughs in a number of tasks <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b22">23]</ref> where a graph is defined by a set of nodes and a set of edges connecting different node pairs. Using high-dimensional vector as a node, graph neural networks can be used to model the non-Euclidean data manifold between different nodes. In particular, we have shown that the graph attention network <ref type="bibr" target="#b13">[14]</ref> can be applied to both speaker verification <ref type="bibr" target="#b22">[23]</ref> and spoofing detection <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>.</p><p>The graph attention layer used in our work is a variant of the original architecture <ref type="bibr" target="#b13">[14]</ref>. In our work, graphs are fully-connected in the sense of there being edges between each and every node pair. This is because the relevance of each node pair to the task at hand cannot be predetermined. Instead, the self-attention mechanism in a graph attention layer derives data-driven attention weights, assigned to each edge, to reflect the relevance of each node pair. Before deriving attention weights, an element-wise multiplication is utilized to make edges symmetric. The reader is referred to <ref type="bibr" target="#b10">[11]</ref> (Section 3) for further details.</p><p>Graph pooling. Various graph pooling layers have been proposed to effectively scale down the graph <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25]</ref>. This has the aim of reducing complexity and improving discrimination. We apply a simple attentive graph pooling layer to the output of each graph attention layer. Except for the omission of projection vector normalization, our implementation is identical to that in <ref type="bibr" target="#b24">[25]</ref>.</p><p>Let G, G ? R N ?D be the output graph of a graph attention layer where N is the number of nodes and D refers to the dimensionality of each node. Note that the order of nodes is meaningless; the relationships between them are defined via the attention weights assigned to each edge. Attention weights are derived via G ? P where ? is the dot product and P, P ? R D is a projection vector that returns a scalar attention weight for each node. After the multiplication of a sigmoid non-linearity with the corresponding k nodes, the nodes with the top-k values are retained while the rest are discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">AASIST</head><p>AASIST builds upon the foundation of our previous work, RawGAT-ST, whereby two heterogeneous graphs, one spectral and the other temporal, are combined at the model-level. However, instead of using trivial element-wise operations and fully-connected layers, the new approach relies upon a more elegant approach using the proposed HS-GAL. Also, AASIST includes the proposed MGO and readout techniques. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the overall framework of the AASIST including proposed HS-GAL, MGO, and readout techniques. Highlevel representation F is extracted by feeding raw waveforms into the RawNet2-based encoder (Section 2.1). Two graph modules first model the spectral and the temporal domain in parallel, deriving Gs and Gt (Section 2.2). The results are combined into Gst (Section 3.1) and processed using MGO (Section 3.3) that includes four HS-GAL layers (Section 3.2) and four graph pooling layers. Readout operations are then performed, followed by an output layer with two nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Graph combination</head><p>We first compose a heterogeneous graph using two different graphs that each model spectral and temporal domains (Gst in <ref type="figure" target="#fig_0">Figure 1</ref>). Let Gs, Gs ? R Ns?Ds and Gt, Gt ? R N t ?D t be spectral and temporal graphs respectively, each derived according to:  <ref type="bibr" target="#b10">[11]</ref> (baseline, state-of-the-art) and the proposed AASIST are reported. We reproduced RawGAT-ST using three different random seeds where the performance of the best seed shows similar performance compared to that of the original paper (in <ref type="table" target="#tab_2">Table 2</ref>). All reported performances are the average using three repeated experiments with different random seeds, in which values inside brackets are the performance of the best performing seed. The best performance for each column is marked in boldface.</p><formula xml:id="formula_0">Gs = graph module(maxt(abs(F ))), (1) Gt = graph module(maxs(abs(F ))),<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">HS-GAL</head><p>The new contribution is based upon a heterogeneous stacking graph attention layer (HS-GAL -dotted box in <ref type="figure" target="#fig_0">Figure 1</ref>). It comprises two components, namely heterogeneous attention and a stack node. Our approach to heterogeneous attention is inspired by the approach to the modeling of heterogeneous data described in <ref type="bibr" target="#b14">[15]</ref>. The input to the HS-GAL is first projected into another latent space to give each of the two graphs with node dimensionalities Dt and Ds a common dimensionality Dst. Two fully-connected layers are utilized for this purpose, each projecting one of the constituent sub-graphs to a dimensionality of Dst.</p><p>Heterogeneous attention. Whereas the homogeneous graphs use a single projection vector to derive attention weights, we use three different projection vectors to calculate attention weights for the heterogeneous graph. They are illustrated inside Gst of <ref type="figure" target="#fig_0">Figure 1</ref> and are used to determine attention weights for edges connecting: (i) nodes in Gs to nodes in Gs (edges between orange nodes); (ii) nodes in Gs to Gt and Gt to Gs (dotted edges); (iii) Gt to Gt (edges between blue nodes). The projection vector in the case of (ii) above applies to edges in both directions; the graph attention layer applies elementwise multiplication between two nodes, making attention weights symmetrical, rather than concatenating two nodes as in <ref type="bibr" target="#b13">[14]</ref>.</p><p>Stack node. We also introduce a new, additional node referred to as the "stack" node. The role of the stack node is to accumulate heterogeneous information, namely information or the relationship between spectral and temporal domains. The stack node is connected to the full set of nodes (stemming from Gs and Gt). The use of uni-directional edges from all other nodes to the stack node helps to preserve information in both Gs and Gt. It does not transmit information to other nodes. Also, when using more than one HS-GAL layer sequentially, the stack node of the previous layer can be passed on to the next layer. The behaviour of the stack node is similar to that of classification tokens <ref type="bibr" target="#b15">[16]</ref>, except that connections to other nodes are uni-directional.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Max graph operation and readout</head><p>The new "max graph operation" (MGO), highlighted with a large grey box in <ref type="figure" target="#fig_0">Figure 1</ref>, is inspired by a number of works in the antispoofing literature which showed the benefit of element-wise maximum operations <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b25">26]</ref>. MGO aims to mimic the procedure of detecting various artefacts evoked by spoofing in parallel and combining them. It utilizes two parallel branches where element-wise maximum is applied to two branches' outputs. Specifically, each branch involves two HS-GAL sequentially where a graph pooling layer is adopted after each HS-GAL. Thus, MGO comprises four HS-GAL and four graph pooling layers in total. The two HS-GAL in each branch share the stack node by passing the stack node of preceding HS-GAL to the following HS-GAL. Element-wise maximum is also applied to two branches' stack nodes.</p><p>The modified readout scheme is illustrated in the right-most grey box of <ref type="figure" target="#fig_0">Figure 1</ref>. First, we apply node-wise maximum and average. The last hidden layer is then formed from the concatenation of two nodes derived using average and maximum along with the stack node.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Lightweight variant of AASIST</head><p>We additionally explore a lightweight variant, namely AASIST-L. Leaving the architecture identical, we tune the number of parameters to compose a model with 85K parameters using the populationbased training algorithm <ref type="bibr" target="#b26">[27]</ref>. This results in a 332KB model where after techniques such as half-precision training, the size would be halved. Through experiments, we demonstrate that AASIST-L still outperforms all models except AASIST, shown in <ref type="table" target="#tab_2">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EXPERIMENTS AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset and metrics</head><p>All experiments were performed using the ASVspoof 2019 logical access (LA) dataset <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b38">39]</ref>. It comprises three subsets: train, development, and evaluation. The train and the development sets contain attacks created from six spoofing attack algorithms (A01-A06), whereas the evaluation set contains attacks created from thirteen algorithms (A7-A19). Readers are referred to <ref type="bibr" target="#b38">[39]</ref> for full details.</p><p>We use two metrics: the default minimum tandem detection cost function (min t-DCF) <ref type="bibr" target="#b17">[18]</ref> and the equal error rate (EER). The min t-DCF shows the impact of spoofing and the spoofing detection system upon the performance of an automatic speaker verification system whereas the EER reflects purely standalone spoofing detection performance.</p><p>Wang et al. <ref type="bibr" target="#b32">[33]</ref> showed that the performance of spoofing detection systems can vary significantly with different random seeds. We observed the same phenomenon; when trained with different random seeds, the EER of the baseline RawGAT-ST <ref type="bibr" target="#b10">[11]</ref> system was found to vary between 1.19% and 2.06%. Thus, the results are slightly different from the reported ones in <ref type="bibr" target="#b10">[11]</ref>. All results reported in this paper are average results in addition to the best result from three runs with different random seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation details</head><p>AASIST was implemented using PyTorch, a deep learning toolkit in Python. Inputs in the form of raw waveforms of 64, 600 samples (? 4 seconds) are fed to the RawNet2-based encoder. The first layer of the encoder, sinc-convolution <ref type="bibr" target="#b39">[40]</ref>, has 70 filters. The RawNet2based encoder consists of six residual blocks. The first two have 32 filters while the remaining four have 64 filters. The first two graph attention layers have 64 filters. Graph pooling layers remove 50% and 30% of spectral and temporal nodes, respectively. All subsequent graph attention layers have 32 filters and are followed by  <ref type="table">Table 3</ref>. Ablation experiments intended to demonstrate the effectiveness of each detailed techniques for modelling two heterogeneous graphs (spectral and temporal). Performance reported in "average(best)" after three repeated experiments.</p><p>graph pooling which further reduces the number of nodes by 50%.</p><p>We used Adam optimizer <ref type="bibr" target="#b40">[41]</ref> with a learning rate of 10 ?4 and cosine annealing learning rate decay. The AASIST-L system was tuned with a population-based training algorithm over 7 generations and with 30 experiments for each generation <ref type="bibr" target="#b26">[27]</ref>. <ref type="table" target="#tab_0">Table 1</ref> describes the EERs for each individual attacks, pooled min t-DCF, and pooled EER. For pooled performances, we also report the best performance inside brackets. It shows a performance comparison for the proposed AASIST model and the state-of-the-art baseline RawGAT-ST <ref type="bibr" target="#b10">[11]</ref> model. ASSIST performs similarly or better than the baseline for 9 of the 13 conditions. For the remaining 4 conditions for which the baseline performs better, the differences are modest. For conditions where AASIST performs better, improvements can be substantial, e.g. for the A15 condition where AASIST outperforms the baseline by over 35% relative (1.03% vs 0.65%). Pooled min t-DCF and EER results are shown in the two right-most columns of <ref type="table" target="#tab_0">Table 1</ref>. AASIST outperforms the RawGAT-ST baseline in terms of both the pooled min t-DCF and the pooled EER. For AA-SIST, the min t-DCF drops by over 20% relative (0.0443 vs 0.0347).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results</head><p>With the best performing seed, AASIST demonstrates an EER of 0.83% and a min t-DCF of 0.0275, beyond that of any reported single systems in the literature.</p><p>Comparison with state-of-the-art systems. AASIST-L: lightweight variant. <ref type="table" target="#tab_2">Table 2</ref> also shows a comparison in terms of complexity for the smaller AASIST-L model and other models for which the number of parameters is openly available. In using only 85K parameters, AASIST-L is substantially less complex than all other systems. The min t-DCF and EER achieved by the AASIST-L model are better than those of all other systems except for the full AASIST model. If appropriately modified using techniques such as half-precision inference and parameter pruning, we believe that it would be small enough to be used in embedded systems.</p><p>Ablations. <ref type="table">Table 3</ref> shows results for ablation experiments for which one of the components in the AASIST model is removed. Results show that all three techniques are beneficial; without any one of them, results are worse than the full AASIST model. Applying heterogeneous attention had the most impact in terms of performance. MGO, a similar concept with the max feature map <ref type="bibr" target="#b16">[17]</ref> was also effective, showing consistent impact of max operation in spoofing detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>We propose AASIST, a new end-to-end spoofing detection system based upon graph neural networks. New contributions are threefold: (i) a heterogeneous stacking graph attention layer (HS-GAL) used to model spectral and temporal sub-graphs consisted of a heterogeneous attention mechanism and a stack node to accumulate heterogeneous information; (ii) a max graph operation (MGO) that involves a competitive selection of artefacts; (iii) a modified readout scheme. AASIST improves upon the performance of state-of-the-art baseline by over 20% relative in terms of min t-DCF. Even the lightweight version, AASIST-L, with 85K parameters, outperforms all competing systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overall framework of the proposed AASIST. Identical to [11]: encoder extracts F and two graph modules each model spectral and temporal domains. Proposed: then, the proposed max graph operation technique adopts two branches that model heterogeneous graphs in parallel, followed by an element-wise maximum. Each branch includes two proposed HS-GAL layers and two graph pooling layers (graph pooling layers and one HS-GAL layer is omitted in the illustration). Finally, the maximum and average of nodes, and the stack node are concatenated followed by an output layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>where graph module refers to the combination of graph attention and graph pooling layers and where F ? R C?S?T is the encoder output feature map. We then formulate a combined graph Gst which has Ns + Nt nodes by adding edges between every node in Gt and every node in Gs and vice versa (dotted arrows under Gst). The new edges in the combined graph Gst allow deriving attention weights between pairs of heterogeneous nodes that each spans temporal and spectral domains. Despite the combination, Gst remains a heterogeneous graph in that nodes in each of the constituent graphs lie in different latent spaces; Ns and Ds are normally different to Nt and Dt.RawGAT-ST 1.19 0.33 0.03 1.54 0.41 1.54 0.14 0.14 1.03 0.67 1.44 3.22 0.62 0.0443(0.0333) 1.39(1.19) AASIST 0.80 0.44 0.00 1.06 0.31 0.91 0.1 0.14 0.65 0.72 1.52 3.40 0.62 0.0347(0.0275) 1.13(0.83) Breakdown EER (%) performance of all 13 attacks that exist in the ASVspoof 2019 LA evaluation set, pooled min t-DCF (P1), and pooled EER (%, P2). RawGAT-ST</figDesc><table><row><cell>System</cell><cell>A07 A08 A09 A10 A11 A12 A13 A14 A15 A16 A17 A18 A19</cell><cell>P1</cell><cell>P2 (%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>presents a comparison of the proposed AASIST model to the performance of a number of recently proposed competing systems [9-11, 28-38] for the same ASVspoof 2019 LA dataset. The set of systems covers a broad range of different front-end representations and model architectures. Five of the top six systems operate upon raw waveform inputs while the top three systems are based upon graph attention networks. The proposed AASIST system is the best performing of all.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Asvspoof 2015: the first automatic speaker verification spoofing and countermeasures challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kinnunen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The asvspoof 2017 challenge: Assessing the limits of replay spoofing attack detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kinnunen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sahidullah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Delgado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Asvspoof 2019: Future horizons in spoofed and fake audio detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Todisco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vestman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Asvspoof 2021: accelerating progress in spoofed and deepfake speech detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yamagishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Todisco</surname></persName>
		</author>
		<idno>arXiv 2109.00537</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Significance of subband features for synthetic speech detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Investigation of sub-band discriminative information between spoofed and genuine speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sriskandaraja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sethu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ambikairajah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Replay attack detection with complementary high-resolution information using end-toend dnn for the asvspoof 2019 challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An explainability study of the constant Q cepstral coefficient spoofing countermeasure for automatic speaker verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Patino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nautsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Odyssey</title>
		<meeting>Odyssey</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Spoofing Attack Detection using the Non-linear Fusion of Sub-band Classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Patino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nautsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Graph attention networks for anti-spoofing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Patino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">End-to-end spectro-temporal graph attention networks for speaker verification anti-spoofing and speech deepfake detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Patino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASVspoof workshop</title>
		<meeting>ASVspoof workshop</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Improved RawNet with Feature Map Scaling for Text-Independent Speaker Verification Using Raw Waveforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">End-to-end anti-spoofing with rawnet2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Patino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Todisco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Heterogeneous graph attention network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bert: Pretraining of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><forename type="middle">C</forename><surname>Kenton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A light cnn for deep face representation with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">t-dcf: a detection cost function for the tandem assessment of spoofing countermeasures and automatic speaker verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kinnunen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Delgado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Odyssey</title>
		<meeting>Odyssey</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Integrated replay spoofing-aware text-independent speaker verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">18</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Self-normalizing neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc NeuralIPS</title>
		<meeting>NeuralIPS</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Graph attention networks for speaker verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Self-attention graph pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Graph u-nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLM</title>
		<meeting>ICLM</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Audio replay attack detection with deep learning frameworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lavrentyeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Novoselov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Malykh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Population based training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dalibard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<idno>arXiv 1711.09846</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The effect of silence and dual-band fusion in anti-spoofing system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Towards end-to-end synthetic speech detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beng Jin Teoh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Raw differentiable architecture search for speech deepfake and spoofing detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Patino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Todisco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASVspoof workshop</title>
		<meeting>ASVspoof workshop</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Channel-wise gated res2net: Towards robust detection of synthetic speech attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generalization of audio deepfake detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Nagarsheth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Odyssey</title>
		<meeting>Odyssey</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A Comparative Study on Recent Neural Spoofing Countermeasures for Synthetic Speech Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yamagishi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A capsule network based approach for detection of audio spoofing attacks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc.ICASSP</title>
		<meeting>.ICASSP</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">One-class learning towards synthetic voice spoofing detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Replay and synthetic speech detection with res2net architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Improved lightcnn with attention modules for asv spoofing detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE ICME</title>
		<meeting>IEEE ICME</meeting>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Partially-Connected Differentiable Architecture Search for Deepfake and Spoofing Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Panariello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Patino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Asvspoof 2019: A large-scale public database of synthesized, converted and replayed speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yamagishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Todisco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Speaker recognition from raw waveform with sincnet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ravanelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE SLT</title>
		<meeting>IEEE SLT</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
