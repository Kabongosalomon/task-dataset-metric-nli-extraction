<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AN EFFICIENT DEEP CONVOLUTIONAL LAPLACIAN PYRAMID ARCHITECTURE FOR CS RECONSTRUCTION AT LOW SAMPLING RATIOS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxue</forename><surname>Cui</surname></persName>
							<email>wenxuecui@stu.hit.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heyao</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwei</forename><surname>Gao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Wechat Business Group</orgName>
								<address>
									<settlement>Shenzhen</settlement>
									<region>Tencent</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengping</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debin</forename><surname>Zhao</surname></persName>
							<email>dbzhao@hit.edu.cnvitogao@tencent.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Harbin Institute of Technology</orgName>
								<address>
									<settlement>Harbin</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">AN EFFICIENT DEEP CONVOLUTIONAL LAPLACIAN PYRAMID ARCHITECTURE FOR CS RECONSTRUCTION AT LOW SAMPLING RATIOS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Compressed sensing</term>
					<term>deep networks</term>
					<term>im- age compression</term>
					<term>laplacian pyramid</term>
					<term>residual learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The compressed sensing (CS) has been successfully applied to image compression in the past few years as most image signals are sparse in a certain domain. Several CS reconstruction models have been proposed and obtained superior performance. However, these methods suffer from blocking artifacts or ringing effects at low sampling ratios in most cases. To address this problem, we propose a deep convolutional Laplacian Pyramid Compressed Sensing Network (LapC-SNet) for CS, which consists of a sampling sub-network and a reconstruction sub-network. In the sampling sub-network, we utilize a convolutional layer to mimic the sampling operator. In contrast to the fixed sampling matrices used in traditional CS methods, the filters used in our convolutional layer are jointly optimized with the reconstruction sub-network. In the reconstruction sub-network, two branches are designed to reconstruct multi-scale residual images and muti-scale target images progressively using a Laplacian pyramid architecture. The proposed LapCSNet not only integrates multi-scale information to achieve better performance but also reduces computational cost dramatically. Experimental results on benchmark datasets demonstrate that the proposed method is capable of reconstructing more details and sharper edges against the state-of-the-arts methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The compressed sensing theory <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b2">2]</ref> shows that if a signal is sparse in a certain domain ?, it can be accurately recovered from a small number of random linear measurements less than that of Nyquist sampling theorem. Mathematically, the measurements are obtained by the following linear transformation</p><formula xml:id="formula_0">y = ?x + e<label>(1)</label></formula><p>where x ? R N is the signal, y ? R M is known as the measurement vector, ? ? R M ?N is the measurement matrix and e denotes noise. If M N , reconstructing x from y is generally ill-posed, which is one of the most challenging issues in compressed sensing.</p><p>To design an efficient CS reconstruction algorithm, many methods have been proposed, which can be generally divided into two categories: traditional optimization-based methods and recent DNN-based methods.</p><p>In the optimization-based reconstruction methods, given the linear projections y, the original image x can be reconstructed by solving the following convex optimization problem <ref type="bibr" target="#b1">[1,</ref><ref type="bibr" target="#b2">2]</ref>:</p><formula xml:id="formula_1">x = argmin x 1 2 ? x ? y 2 2 + ? ? x 1<label>(2)</label></formula><p>To solve this convex problem, many algorithms have been proposed <ref type="bibr" target="#b4">[4]</ref><ref type="bibr" target="#b5">[5]</ref><ref type="bibr" target="#b6">[6]</ref>. However, these algorithms suffer from uncertain reconstruction qualities and high computation cost, which inevitably limit their applications in practice.</p><p>Recently, some DNN-based algorithms have been proposed for image CS reconstruction. In <ref type="bibr" target="#b7">[7]</ref>, Mousavi et al. propose to utilize a stacked denoising autoencoder (SDA) to reconstruct original images from their measurements. A series of convolutional layers are adopted in <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b8">8,</ref><ref type="bibr" target="#b9">9]</ref> for image reconstruction. Despite their impressive results, massive block artifacts and ringing effects are delivered at low sampling ratios.</p><p>To overcome the shortcomings of the aforementioned methods, we propose a Laplacian Pyramid based deep architecture for CS reconstruction. Our network contains two sub-networks: sampling sub-network and reconstruction subnetwork. In the sampling sub-network, a convolutional layer with the kernel size of B?B (B is the size of current block) is utilized to mimic the sampling process. In the reconstruction sub-network, we use two branches to reconstruct multi-scale residual features and multi-scale target images progressively through Laplacian pyramid architectures. Besides, the second branch integrates multi-scale information from the first branch to preserve finer textures. The sampling sub-network and reconstruction sub-network are optimized jointly with the robust Charbonnier loss <ref type="bibr" target="#b10">[10]</ref>.  <ref type="bibr" target="#b3">[3]</ref> for initial reconstruction. The gray and blue boxes denote convolutional layers and transposed convolutional layers respectively and the four tuples in the bracket indicate the dimensions of parameters for adjacent convolutional layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">PROPOSED METHOD</head><p>In this section, we describe the methodology of the proposed LapCSNet including the sampling sub-network and the reconstruction sub-network as well as the loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Sampling Sub-network</head><p>In traditional block-based compressed sensing (BCS), each row of the sampling matrix ? can be considered as a filter. Therefore, the sampling process can be mimicked using a convolutional layer <ref type="bibr" target="#b3">[3,</ref><ref type="bibr" target="#b9">9]</ref>. In our model, we use a convolutional layer with B ? B filters and set stride as B for nonoverlapping blocks. Specifically, given an image with size w ? h, there are a total of L = w B ? h B non-overlapping blocks with size B ? B (B = 32). The dimensions of measurements for each block is n B = M N B 2 , Therefore, the dimensions of measurements for the current image is L ? n B . Traditional sampling matrices are fixed for various reconstruction algorithms. The proposed DNN-based sampling matrices are learned jointly with the reconstruction sub-network from large amounts of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Reconstruction Sub-network</head><p>For the CS reconstruction, several DNN-based models have been proposed <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b9">9]</ref>. These methods are implemented for each block, which ignore the relationship between blocks and therefore results in serious blocking artifacts in most cases. To solve this problem, we adopt a "reshape+concat" layer <ref type="bibr" target="#b3">[3]</ref> to concatenate all blocks to obtain initial reconstruction, which is then refined to obtain superior reconstruction.</p><p>Initial reconstruction Given the compressed measurements, the initial reconstruction blockx (j,S) can be obtained</p><formula xml:id="formula_2">byx (j,S) =? (B,S) y j<label>(3)</label></formula><p>where y j is the measurement of the current j th block and S is the scale factor for current block.</p><formula xml:id="formula_3">? (B,S) is a ( B S ) 2 ? n B matrix.</formula><p>In the aforementioned methods without scaling (S = 1), is difficult to be accurate calculated. By introducing the pyramid structure, a small block is first reconstructed in our method. Let Q = {2 i |i = 1, 2, . . . , } and S = {s|s ? Q and 1 2 s &gt; M N }. The optimal scale factor S is obtained as</p><formula xml:id="formula_4">S * = M ax(S)<label>(4)</label></formula><p>where M ax(?) is used to return the maximal element of a set. Therefore, S &gt; 1 in our model. The convolution output of an image block in the sampling sub-network is a n B ? 1 vector, so the size of the convolution filter in the initial reconstruction layer is 1 ? 1 ? n B . We use 1 ? 1 stride convolution to reconstruct each block. Since a smaller version of the target block is reconstructed, ( B S ) 2 convolution filters of size 1 ? 1 ? n B are used. However, the reconstructed outputs of each block is still a vector. To obtain the initial reconstructed image, a "re-shape+concat" layer is adopted. This layer first reshapes each  computational complexity due to the unenlightened superposition of convolutional layers. Our further reconstruction network takes the output of initial reconstruction as input and progressively predicts residual images at a total of log 2 S levels where S is the scale factor from Eq. 4. Moreover, our reconstruction model has two branches: residual feature extraction <ref type="bibr" target="#b11">[11]</ref> and feature integration.</p><formula xml:id="formula_5">( B S ) 2 reconstructed vector into a B S ? B S block,</formula><p>(1) Multi-scale residual feature extraction: There is a one-to-one correspondence between reconstruction levels and residual blocks (shown in <ref type="figure" target="#fig_0">Fig. 1</ref>). In level l, the corresponding residual block consists of d convolutional layers and one transposed convolutional layer <ref type="bibr" target="#b12">[12]</ref> to upsample the extracted features by a scale of 2. The output of each transposed convolutional layer is connected to two different layers: (i) a convolutional layer for reconstructing a residual image for level l; (ii) a convolutional layer for extracting features in next level l + 1. Note that the residual feature at lower levels are shared with higher levels and thus can increase the non-linearity of the network to reconstruct the target image. Moreover, the hierarchical architecture is used for the CS feature extraction, which can preserve more details.</p><p>(2) Multi-scale feature integration: In level l, the input image is up-sampled by a scale of 2 using a transposed convolutional layer <ref type="bibr" target="#b12">[12]</ref>. The upsampled image is then combined with the predicted residual images from the residual feature extraction branch. Then, the output in this level l is fed into the next reconstruction module of level l+1. This integration architecture fuses the the multi-scale residual branch and corresponding reconstruction branch efficiently. In addition, most of convolution operation are executed on the smaller version of the target image, which indicates our model is more efficient than the existing models with the same depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Loss function</head><p>Let x be the input image, ? S is the parameter of the sampling sub-network and ? R the parameter of reconstruction sub-network. Two mapping function f S and f R are desired to produce accurate measurements and reconstructed image? = f (x; ? S , ? R ). We denote the residual image in level l by r l , the up-scaled image by x l and the corresponding target image by? l . The desired output images in level l is modeled by? l = x l + r l . We use the bicubic downsampling method to resize the ground truth image y to y l at each level. We propose to use the robust Charbonnier penalty function for each level. The overall loss function is defined as:</p><formula xml:id="formula_6">(?, y; ? S , ? R ) = 1 N N i=1 L l=1 ?(? l (i) ? y (i) l ) (5) where? (i) l = x (i) l + r (i) l and ?(x) = ? x 2 + ? 2 .</formula><p>N is the number of training samples, and L is the number of levels in our pyramid. ? is empirically set to 1e ? 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">EXPERIMENTAL RESULTS AND ANALYSIS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Implementation and training details</head><p>In the reconstruction sub-network, each convolutional layer consists of 64 kernels with size of 3 ? 3. We initialize the convolutional filters using the same method <ref type="bibr" target="#b15">[15]</ref>. The size of the transposed convolutional filter is 4?4. A ReLU layer with a negative slope of 0.2 is subsequent for all convolutional and transposed convolutional layers. We pad zero values around the boundaries before applying convolution to keep the size of all feature maps the same as the input of each level.</p><p>We use the training set (200 images) and testing set (200 images) of the BSDS500 database <ref type="bibr" target="#b16">[16]</ref> for training, and the validation set (100 images) of BSDS500 for validation. We set the patch size as 128 ? 128, and batch size as 64. We augment the training data in three ways: (i) Randomly scale between [0.75, 1.2]. (ii) Rotate the images by 90 ? , 180 ? , and 270 ? . (iii) Flip the images horizontally or vertically with a probability of 0.5. We train our model with the Matlab toolbox MatConvNet <ref type="bibr" target="#b17">[17]</ref> on a Titan X GPU. The momentum parameter is set as 0.9 and weight decay as 1e ? 4. The learning rate is initialized to 1e ? 6 for all layers and decreased by a factor of 2 for every 50 epochs. We train our model for 200 epochs and each epoch iterates 1000 times. <ref type="table">Table 1</ref>. Quantitative evaluation of state-of-the-arts CS reconstruction algorithms: Average PSNR\SSIM\time\network Layers for sampling ratios 0.01, 0.02, 0.1 on dataset Set5. Red text indicates the best and blue the second best performance </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Comparison with the state-of-the-arts</head><p>We compare our algorithm with seven representative methods, i.e., total variation (TV) method <ref type="bibr" target="#b5">[5]</ref>, multi-hypothesis (MH) method <ref type="bibr" target="#b13">[13]</ref>, collaborative sparsity (Cos) method <ref type="bibr" target="#b14">[14]</ref>, group sparse representation (GSR) method <ref type="bibr" target="#b6">[6]</ref>, ReconNet <ref type="bibr" target="#b8">[8]</ref>, BCSNet <ref type="bibr" target="#b9">[9]</ref> and CSNet <ref type="bibr" target="#b3">[3]</ref>. In these algorithms, the first four belong to traditional optimization-based methods, while the last three are recent network-based methods. The PSNR and SSIM reconstruction performances at three different sampling ratios: 0.01, 0.02 and 0.1 for the datasets Set5 and Set14 are summarized in <ref type="table">Table 1</ref> and <ref type="table" target="#tab_1">Table 2</ref>, respectively. The "LapCSNet-2" denotes d = 2 and "LapCSNet-4" d = 4. It can be seen from the tables that about 0.2-0.5dB PSNR improvement is obtained on both test datasets Set5 and Set14 when the sampling ratio is very low. Obviously, the proposed method outperform the existing algorithms in low-ratio by a large margin, which fully demonstrates the effectiveness of our model. Moreover, for the ratio=0.01, our model is about 4 times deeper than CSNet, while the running time is just about 3 times longer than that of the CSNet, which demonstrate the Laplacian pyramid is a high-efficiency design for CS reconstruction. The visual comparisons in the case of ra-tio=0.01 and ratio=0.02 in <ref type="figure" target="#fig_1">Fig. 2 and Fig. 3</ref> show that the proposed LapCSNet is able to reconstruct more details and sharper edges without obvious blocking artifacts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CONCLUSION</head><p>In this work, we propose a deep convolutional network (LapCSNet) within a Laplacian pyramid framework for fast and accurate CS reconstruction. Our model consists of two sub-networks namely sampling sub-network and reconstruction sub-network. In the sampling sub-network, the sampling filters are learned jointly with the reconstruction sub-network.</p><p>In the reconstruction sub-network, we divide our model into two branches to extract the residual features and integrate target images using laplacian pyramid architectures, respectively. In other words, the reconstruction sub-network progressively predicts high-frequency residuals and integrate multi-scale information in a coarse-to-fine manner. The sampling sub-network and reconstruction sub-network are optimized jointly using a robust Charbonnier loss function. Experimental results show that the proposed LapCSNet is capable of reconstructing more details and sharper edges against several state-of-the-arts algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>(a) is the overview of the proposed LapCSNet and (b) shows the detailed structure in each level. The red box indicates convolutional layer for sampling operator. The sequence of squares indicate measurements. The purple box represents the "reshape+concat" layer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Visual quality comparison of image CS recovery on image Monarch from Set14 in the case of sampling ratio = 0.02</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>then concatenates all the blocks to get the reconstructed image. From Eq. (4), we can get that when M N &gt; 0.25, we can not obtain the smaller version of the target image. In this case, we only use this model for CS reconstruction at low sampling ratios.Further reconstruction CSNet<ref type="bibr" target="#b3">[3]</ref> has only 5 layers for CS reconstruction, which results in poor performance at low sampling ratios. Deep networks and elaborated architectures are essential for accurate reconstruction while increasingFig. 2. Visual quality comparison of image CS recovery on image Pepper from Set14 in the case of sampling ratio = 0.01</figDesc><table><row><cell>Original\PSNR\SSIM</cell><cell>HM\12.59\0.1586</cell><cell>Cos\19.13\0.5987</cell><cell>GSR\21.01\0.6083</cell><cell>ReconNet\19.96\0.5726</cell><cell>BCSNet\23.46\0.6508</cell><cell>CSNet\25.73\0.7209</cell><cell>Ours\26.68\0.7588</cell></row><row><cell>Original\PSNR\SSIM</cell><cell>HM\18.85\0.6909</cell><cell>Cos\17.66\0.6546</cell><cell>GSR\20.74\0.6832</cell><cell>ReconNet\20.00\0.6706</cell><cell>BCSNet\22.57\0.7531</cell><cell>CSNet\24.90\0.8098</cell><cell>Ours\25.57\0.8351</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Quantitative evaluation of state-of-the-arts CS reconstruction algorithms: Average PSNR\SSIM\time\ network Layers for sampling ratios 0.01, 0.02, 0.1 on dataset Set14. Red text indicates the best and blue the second best performance</figDesc><table><row><cell>Alg.</cell><cell>sampling ratio 0.01</cell><cell>sampling ratio 0.02</cell><cell>sampling ratio 0.1</cell><cell>Avg.</cell></row><row><cell>TV [5]</cell><cell>15.17\0.3691\58.43\-</cell><cell>17.20\0.4069\47.36\-</cell><cell>17.96\0.5381\17.21\-</cell><cell>16.78\0.4380\41.00\-</cell></row><row><cell>MH [13]</cell><cell>12.26\0.1319\95.48\-</cell><cell>19.20\0.4923\89.37\-</cell><cell>26.38\0.7282\70.19\-</cell><cell>19.28\0.4508\85.01\-</cell></row><row><cell>Cos [14]</cell><cell cols="4">16.73\0.3533\23563.48\-18.35\0.4074\23042.53\-27.20\0.7433\16596.02\-20.76\0.5013\21067.32\-</cell></row><row><cell>GSR [6]</cell><cell>19.41\0.4583\1654.39\-</cell><cell>20.89\0.4900\1486.10\-</cell><cell>27.50\0.7705\948.03\-</cell><cell>22.60\0.5729\1362.86\-</cell></row><row><cell>ReconNet [8]</cell><cell>18.09\0.3907\1.04\7</cell><cell>19.46\0.4507\1.12\7</cell><cell>22.91\0.5974\1.23\7</cell><cell>20.15\0.4796\1.13\7</cell></row><row><cell>BCSNet [9]</cell><cell>20.94\0.4910\0.05\3</cell><cell>22.00\0.5557\0.04\3</cell><cell>27.33\0.8732\0.05\3</cell><cell>23.42\0.6400\0.05\3</cell></row><row><cell>CSNet [3]</cell><cell>22.78\0.5574\0.13\6</cell><cell>24.33\0.6185\0.12\6</cell><cell>28.91\0.8119\0.14\5</cell><cell>25.34\0.6626\0.13\6</cell></row><row><cell>LapCSNet-2</cell><cell>23.03\0.5688\0.25\17</cell><cell>24.55\0.6324\0.19\12</cell><cell>28.94\0.8124\0.13\7</cell><cell>25.51\0.6712\0.19\12</cell></row><row><cell>LapCSNet-4</cell><cell>23.16\0.5818\0.39\23</cell><cell>24.76\0.6454\0.25\16</cell><cell>29.00\0.8147\0.17\9</cell><cell>25.64\0.6806\0.24\16</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">ACKNOWLEDGEMENTS</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Csnet</surname></persName>
		</author>
		<idno>3] 24.04\0.6374\0.03\6 25.87\0.7069\0.02\6 32.30\0.9015\0.04\6 27.40\0.7486\0.03\6</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Emmanuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Cand?s</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terence</forename><surname>Romberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="489" to="509" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Compressed sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Donoho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1289" to="1306" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep networks for compressed image sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wuzhen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengping</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debin</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia and Expo (ICME)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="877" to="882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Atomic decomposition by basis pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">L</forename><surname>Scott Shaobing Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael A</forename><surname>Donoho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saunders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM review</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="129" to="159" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An efficient augmented lagrangian method with applications to total variation minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengbo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wotao</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Optimization and Applications</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Group-based sparse representation for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A deep learning approach to structured signal recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ankit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">G</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baraniuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Allerton Conference on Communication, Control, and Computing (Allerton)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1336" to="1343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Reconnet: Non-iterative reconstruction of images from compressively sensed random measurements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuldeep</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suhas</forename><surname>Lohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Kerviche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Ashok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recongnition (CVPR)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="449" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A deep learning approach to blockbased compressed sensing of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Boublil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zibulevsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01519</idno>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Lucas/kanade meets horn/schunck: Combining local and global optic flow methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andr?s</forename><surname>Bruhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Weickert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Schn?rr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Springer International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="231" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A guide to convolution arithmetic for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Visin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.07285</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Compressed-sensing recovery of images and video using multihypothesis predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">W</forename><surname>Tramel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">E</forename><surname>Fowler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference Record of the Forty Fifth Asilomar Conference on Signals, Systems and Computers (ASILOMAR)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1193" to="1198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Compressed sensing recovery via collaborative sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqin</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Data Compression Conference (DCC)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="287" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Contour detection and hierarchical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="898" to="916" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Matconvnet: Convolutional neural networks for matlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Lenc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Multimedia</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="689" to="692" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
