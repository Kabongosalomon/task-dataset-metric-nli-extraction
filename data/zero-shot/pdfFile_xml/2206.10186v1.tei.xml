<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Improving Localization for Semi-Supervised Object Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo</forename><surname>Rossi</surname></persName>
							<email>leonardo.rossi@unipr.itimplab.ce.unipr.it</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IMP Lab -D.I.A</orgName>
								<orgName type="institution">University of Parma</orgName>
								<address>
									<settlement>Parma</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Prati</surname></persName>
							<email>andrea.prati@unipr.itimplab.ce.unipr.it</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IMP Lab -D.I.A</orgName>
								<orgName type="institution">University of Parma</orgName>
								<address>
									<settlement>Parma</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:lang="en">Improving Localization for Semi-Supervised Object Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="title">[0000?0002?9316?595X] , Akbar Karimi [0000?0002?5132?2435] , and</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Object Detection ? Multi-Task Learning ? Teacher-Student Technique ? Semi-Supervised Learning ? Semi-Supervised Object Detec- tion</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Nowadays, Semi-Supervised Object Detection (SSOD) is a hot topic, since, while it is rather easy to collect images for creating a new dataset, labeling them is still an expensive and time-consuming task. One of the successful methods to take advantage of raw images on a Semi-Supervised Learning (SSL) setting is the Mean Teacher technique <ref type="bibr" target="#b16">[17]</ref>, where the operations of pseudo-labeling by the Teacher and the Knowledge Transfer from the Student to the Teacher take place simultaneously. However, the pseudo-labeling by thresholding is not the best solution since the confidence value is not strictly related to the prediction uncertainty, not permitting to safely filter predictions. In this paper, we introduce an additional classification task for bounding box localization to improve the filtering of the predicted bounding boxes and obtain higher quality on Student training. Furthermore, we empirically prove that bounding box regression on the unsupervised part can equally contribute to the training as much as category classification. Our experiments show that our IL-net (Improving Localization net) increases SSOD performance by 1.14% AP on COCO dataset in limited-annotation regime. The code is available at https://github. com/IMPLabUniPr/unbiased-teacher/tree/ilnet.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Supervised learning usually requires a large amount of annotated training data which can be expensive and time-consuming to produce. Semi-Supervised Learning (SSL), on the other hand, addresses this issue by taking advantage of large unlabeled data accompanied by a small labeled dataset. Usually, in an SSL setting, we have two models that act as Teacher and Student. The latter is trained in a supervised way, drawing the needed ground truths from the dataset, if exist, and from the Teacher's predictions, otherwise.</p><p>This approach can be beneficial in many machine learning tasks including object detection, whose final result is a list of bounding boxes (bboxes) and the corresponding classes. In this task, the network is devoted to finding the position of the localized objects in an image, as well as identifying which class they belong to. Hereinafter, we will refer to this specific application as Semi-Supervised Object Detection (SSOD). In <ref type="bibr" target="#b9">[10]</ref>, authors have collected many interesting ideas applied to SSOD. Among them, the one that seems more promising is the Mean Teacher <ref type="bibr" target="#b16">[17]</ref>, which uses the Exponential Moving Average (EMA) as a knowledge transfer technique from the Student to the Teacher. In particular, while the Teacher produces pseudo-labels on unlabeled and weakly augmented images to obtain more reliable labels, the Student is trained using the pseudo-labels as ground-truth on the same images, but strongly augmented to differentiate the training. In weak augmentation, only a random horizontal flip is applied, while in strong augmentation, other transformations such as randomly adding color jittering, grayscale, Gaussian blur, and cutout patches are also used.</p><p>Although they obtain good performances with this pseudo-labeling technique, the Student model is still influenced by the Teacher's erroneous predictions. The quality of these predictions is difficult to control by applying only a simple confidence thresholding. For this reason, there is a need for an additional way to strengthen the region proposals and reduce the number of erroneous predictions by the Teacher. In the proposed architecture, we introduce a new task used for the classification of the bboxes, with the aim of distinguishing good quality ones from the others. This new score exploits the information complementary to the class score already used in these networks, allowing a different level of filtering. In addition, we show how to take advantage of the regression tasks on the unsupervised learning part. Usually, they are excluded in the unsupervised training phase. The justification is that the classification score is not able to filter the potentially incorrect bboxes <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref>. A well-known problem during training is the Objective Imbalance <ref type="bibr" target="#b11">[12]</ref>, which is characterized by the difficulty in balancing the different loss contributions. In our hypothesis, this is the case for the unsupervised training part. In order to obtain a positive effect from regression losses, an adequate balance of the contribution of these two losses (regression and category classification) is a possible solution to the above-mentioned problem. In this way, we prevent the regression losses on unsupervised dataset from dominating the training, a phenomenon that greatly amplifies the error introduced by inaccurate Teacher predictions.</p><p>The main contributions of this paper are the following:</p><p>a new bounding box IoU (Intersection over Union) classification task to filter out errors on pseudo-labels produced by the Teacher;</p><p>the introduction of a regression task on the unlabeled dataset which can help the network to learn better;</p><p>an exhaustive ablation study on all the components of the architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Semi-Supervised Learning for Object Detection. In <ref type="bibr" target="#b13">[14]</ref>, the authors proposed the ?-Model which is an ensemble of the predictions of the model at different epochs under multiple regularizations and input augmentation conditions. The predictions for the unlabeled images are merged together to form a better predictor. In <ref type="bibr" target="#b3">[4]</ref>, the authors proposed Consistency-based Semi-supervised Learning for Object Detection (CSD), which uses consistency constraints as a self-training task to obtain a better training of the network. In <ref type="bibr" target="#b14">[15]</ref>, an SSL framework with Self-Training (via pseudo label) and the Augmentation driven Consistency regularization (STAC) is introduced, exploiting weak data augmentation for model training and strong data augmentation for pseudo-labeling. Several works <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref> proposed to use the Mean Teacher model, applying EMA to the weights instead of the predictions, facilitating knowledge transfer from Student to the Teacher model at each iteration. For one-stage object detection models, authors of <ref type="bibr" target="#b10">[11]</ref> use an Expectation-Maximization approach, generating pseudo-labels in the expectation step and training the model on them in the maximization step, optimizing for classification in each iteration and for localization in each epoch. In <ref type="bibr" target="#b18">[19]</ref>, the authors propose a Soft Teacher mechanism where the classification loss of each unlabeled box is weighted by the Teacher classification score, also using a box jittering approach to select the most reliable pseudo-bboxes. In <ref type="bibr" target="#b5">[6]</ref>, authors utilize SelectiveNet to properly filter pseudobboxes trained after the Teacher. In <ref type="bibr" target="#b19">[20]</ref>, the authors propose two models, one of which generates a proposal list of bounding boxes and the second one refines these proposals, using the average class probability and the weighted average of the bounding box coordinates. Bounding Box Intersection over Union (BBox IoU). In <ref type="bibr" target="#b2">[3]</ref>, the authors added a new branch on top of the Fast R-CNN model to estimate standard deviation of each bounding box and use it at Non-maximum Suppression (NMS) level to give more weight to the less uncertain ones. In <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b20">21]</ref>, the authors added a new branch on top of the Faster R-CNN to regress bounding box IoU and to multiply this value with the classification score to compute final score of the suppression criterion of the NMS. In the same direction, Fitness NMS was proposed in <ref type="bibr" target="#b17">[18]</ref> to correct the detection score for better selecting bounding boxes which maximize their estimated IoU with the ground-truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Teacher-Student Learning Architecture</head><p>In SSOD, we have two datasets. The first set D s = {x s i , y s i } Ns i=1 , typically smaller, contains N s images x s with the corresponding labels y s , and the second set</p><formula xml:id="formula_0">D u = {x u i } Nu i=1 contains N u images x u without labels.</formula><p>Similarly to <ref type="bibr" target="#b9">[10]</ref>, our architecture is composed of two identical models where one behaves as Teacher and the other as the Student. At each iteration of the semi-supervised training, the Student is trained with one batch of images coming from D s (supervised training) and one from D u (unsupervised training), using the pseudo-labels generated by the Teacher as ground-truth and filtered by a threshold. Then, the Student transfers the learned knowledge to the Teacher using the EMA applied to the weights.</p><p>In our model, the total loss L for the Student is composed of two terms, which come from the the supervised L sup and unsupervised L unsup training:</p><formula xml:id="formula_1">L = L sup + L unsup L sup = i L cls + L reg + L IoU L unsup = i ?L cls + ?L reg + ?L IoU L cls = L rpn cls (x s i , y s i ) + L roi cls (x s i , y s i ) L reg = L rpn reg (x s i , y s i ) + L roi reg (x s i , y s i )<label>(1)</label></formula><p>where L cls contains the sum of Region Proposal Network (RPN) and Region of Interest (RoI) classification losses, while L reg contains the sum of RPN and RoI regression losses. The L IoU loss will be defined in Subsection 3.2. ?, ? and ? represent how much weight each component of the unsupervised training has.</p><p>The new terms introduced in this paper, w.r.t. the ones defined in <ref type="bibr" target="#b9">[10]</ref>, are shown in bold in the above equations and will be described in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Bounding Box Regression on Unsupervised Training</head><p>The training consists of two phases, the burn up stage and Teacher-Student Mutual Learning stage. In the first stage, the Student is trained only on the labeled dataset, following the standard supervised training procedure. Then, for the second stage, at each iteration, the Student is trained on two batches at the same time, one coming from the labeled dataset and the other coming from the unlabeled dataset. For the latter, the baseline <ref type="bibr" target="#b9">[10]</ref> trains only the RPN and RoI head classifier and disregards regression. The authors justify this choice noticing that the classification confidence thresholds are not able to filter the incorrect bounding box regression. Our hypothesis is that training also on pseudo bounding box regression could help the Student as long as the task is correctly weighted with respect to the others. Category classification and regression tasks are learned in parallel. Given that the classification performance improves during the training, we can also expect the bounding box regression to behave the same way. In other words, while the training proceeds, the average quality of the pseudo-labels increases and so does the classification confidence value. During the Student training, although pseudo bounding boxes are filtered with a threshold on classification confidence score, we still have bounding boxes of any IoU quality. This problem is related to the uncertainty on prediction. <ref type="figure" target="#fig_1">Figure 1a</ref> visualizes the IoU distribution quality with respect to the ground-truth of the Teacher filtered predictions. We can notice that the number of pseudo bounding boxes with IoU less than the threshold (0.6 in our experiments) remains almost constant during the entire training, unlike the others which slowly  increase. In <ref type="figure" target="#fig_1">Figure 1b</ref>, we show only the filtered pseudo bounding boxes that the Teacher has wrongly classified and split by their IoU. In <ref type="figure" target="#fig_1">Figure 1c</ref>, the same data are shown using a different graph. We can notice that the number of wrongly classified pseudo-bboxes decreases exponentially with the increase of the quality, and this trend remains the same during the training. The bounding boxes with low quality (IoU &lt; 0.6) represent 45% of the total pseudo-bboxes and more than 90% of classification errors. This means that the low-quality IoU bboxes contain almost all the classification errors. By looking at <ref type="figure" target="#fig_1">Figure 1d</ref>, we can see that the unsupervised regression loss (from RPN and RoI heads) represents between 20% and 30% of the total loss. Conversely, the unsupervised classification loss (from RPN and RoI heads) accounts only for 15% (at most) of the total loss. This means that an error in pseudo-labels has almost three times (see blue line in <ref type="figure" target="#fig_1">Figure 1d</ref>) more weight on regression branch than on classification branch. To avoid the amplification of the errors, an appropriate value for ? is chosen, by under-weighting the regression contribution and making it comparable with the classification one. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bounding Box IoU Classification Task</head><p>As noted by <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b20">21]</ref>, adding a new task related to the IoU prediction could help the network to train better. Our model learns to predict the bounding box quality, using this value to further filter pseudo-labels in conjunction with the classification score. Differently from them, we train the model to make a binary classification instead of a regression since it is sufficient (and easier to learn) for the purpose of filtering. <ref type="figure" target="#fig_2">Fig. 2</ref> illustrates the architecture of a two-stage object detection model such as Faster R-CNN <ref type="bibr" target="#b12">[13]</ref> with our additional branch highlighted in red. For each positive bounding box (i.e., the ones recognized as foreground), it concatenates the output of the shared layers (x sh i , with the size of 1024), all the classification scores (s i , with the size of the number of classes plus the background) and all bounding box regression deltas (d i , with the size of 4). All these features are passed to the IoU cls branch (also called f (?) in the following), which outputs a vector with the same size as s i (i.e., one for each class). This will return the i th IoU classification, called IoU score q IoU , corresponding to the predicted bbox. The f (?) branch consists of two fully-connected layers with an ELU <ref type="bibr" target="#b0">[1]</ref> activation function between them and a sigmoid activation function at the end.</p><p>The loss L IoU i for the new branch of IoU classification, conditioned on the class, is defined as:</p><formula xml:id="formula_2">q IoU i = f (concat(x sh i , s i , d i )) L IoU i = F L(q IoU i , t i )<label>(2)</label></formula><p>where the FL function is the Focal Loss <ref type="bibr" target="#b7">[8]</ref> with its own ? value equal to 1.  <ref type="table">Table 1</ref>: Performance varying the weight loss ? on unsupervised regression losses.</p><formula xml:id="formula_3">IoU i = max IoU b t i , g ?b i ? B|IoU (b i , g) u t i = 1 IoU i &gt; ? 0 otherwise (3)</formula><p>where B is the list of proposals coming from the RPN, b i are the i th predicted bounding boxes, g is the ground-truth bounding box, u is the minimum IoU threshold to consider the bounding b i as positive example (typically set to 0.5) and ? (set to 0.75) is the minimum IoU threshold to be classified as high-quality.</p><p>In the evaluation phase, the Teacher's filtering of the predicted bounding boxes with low confidence is preceded by the IoU classification filtering, which uses a new IoU inference threshold ? (set to 0.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Dataset. We perform our tests on the MS COCO 2017 dataset <ref type="bibr" target="#b8">[9]</ref>. The training dataset consists of more than 117,000 images and 80 different classes of objects, where 10% of the labeled images are used. Evaluation Metrics. All the tests are done on COCO minival 2017 validation dataset, which contains 5000 images. We report mean Average Precision (mAP) and AP 50 and AP 75 with 0.5 and 0.75 minimum IoU thresholds, and AP s , AP m and AP l for small, medium and large objects, respectively. Implementation details. All the values are obtained running the training with the same hardware and hyper-parameters. When available, the original code released by the authors is used. Our code is developed on top of the Unbiased Teacher <ref type="bibr" target="#b9">[10]</ref> source code. We perform the training on a single machine with 6 Tesla P100 GPUs with 12GB of memory. The train lasts 180,000 iterations with a batch size of 2 images per GPU for the supervised part and 2 images for the unsupervised part, with ? set to 4. We use the Stochastic Gradient Descent (SGD) optimization algorithm with a learning rate of 0.0075, a weight decay of 0.0001, and a momentum of 0.9. The learning rate decays at iteration 179990 and 179995. We use the Faster R-CNN with FPN <ref type="bibr" target="#b6">[7]</ref> and the ResNet 50 <ref type="bibr" target="#b1">[2]</ref> backbone for the teacher and student models, initialized by pre-trained on ImageNet, and the same augmentation of Unbiased Teacher <ref type="bibr" target="#b9">[10]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Ablation study</head><p>Unsupervised regression loss. In this experiment, we empirically show that we can also use regression losses on RPN and RoI head for the unsupervised part. We test different weights for the constant ? in the loss formula (see eq. 1). In <ref type="figure" target="#fig_4">Figure 3a</ref> and <ref type="table">Table 1</ref>, we can see that greatly amplifying the contribution can be deleterious, becoming counterproductive in the case of ? equal to 4.</p><p>Bounding box IoU branch loss type. Our proposal involves a new IoU classification task, trained with a binary cross-entropy function. In this experiment, we test how performance changes in case our new branch learns a regression task instead of a classification, using a smooth L1 loss. In this case, the ground-truth is represented by the real IoU value between the bbox and the ground-truth. In <ref type="figure" target="#fig_4">Figure 3b</ref>, we can see that classification branch is a bit more stable and reaches a slightly higher performance.</p><p>With and without filtering bboxes. The bbox IoU branch learns to recognize high quality bounding boxes and, as the default behavior, also to pre-filter Teacher's pseudo-bboxes depending on our new threshold score. In <ref type="figure" target="#fig_4">Figure 3c</ref> and in   <ref type="table">Table 3</ref>: Performance using BBox IoU classification branch with inference threshold ? fixed to 0.5 and varying training threshold ?.</p><p>increase of the general performance (+0.48% mAP). Then, another small improvement is given by the filtering phase, increasing the performance by +0.1% mAP.</p><p>Bounding box training threshold ?. In this experiment, we test the bbox IoU classification branch, setting inference threshold ? to 0.5 and varying the training threshold ?. From <ref type="table">Table 3</ref>, it is clear that the choice of a correct threshold greatly influences the performance. On the one hand, if the threshold is too low, it does not help the network to learn more descriptive feature maps. On the other hand, if it is too high, the risk to wrongly filter out the bounding boxes will increase. As we can see in <ref type="figure" target="#fig_4">Fig. 3d</ref>, with the increase of IoU threshold ?, the number of teacher pseudo-bboxes filtered during the training increases exponentially. This is likely due to an imbalance in training, where the higher the threshold, the fewer   high-quality examples are available. The best value is in the middle between the threshold u (0.5) and the IoU maximum value 1.0. Bounding box inference filter threshold ?. In this experiment, we test our bbox IoU branch, setting the training threshold ? to 0.75 (best value previously found) and varying the inference threshold ?. In <ref type="table" target="#tab_4">Table 4</ref>, we see that the best value for this threshold is in the middle as expected because the branch is trained to reply 1 if the bbox is good enough and 0 otherwise.</p><p>IL-net: Improving Localization net. Finally, we test the full architecture IL-net, composed of the unsupervised regression losses and the new IoU classification branch. Since, using both of them, the contribution of the new branch is absorbed by the loss of unsupervised regression (see rows 2 and 5 in <ref type="table" target="#tab_5">Table 5</ref>), we performed an ablation study reducing the values in input to the new branch (see eq. 2). This analysis has allowed us to highlight that by removing the contribution of the deltas, we can increase the general performance. This behavior could be explained by the fact that the deltas are optimized from both losses (L reg usup and L IoU ), causing the conflict as a result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper, we proposed two new architectural enhancements with respect to the network proposed in <ref type="bibr" target="#b9">[10]</ref>: a new bounding box IoU classification task to filter out errors on pseudo-labels produced by the Teacher and the introduction of the unsupervised regression losses. For the former, we introduced a lightweight branch to predict the bounding box IoU quality. For the latter, we demonstrated how to successfully integrate it in the training, balancing the training tasks.</p><p>Our new model called IL-net, which contains both, increases the general SSOD performance by a 1.14% AP on COCO dataset in a limited annotation regime.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) count pseudo bboxes (b) count class errors (c) count class errors per IoU (d) Unsupervised L cls and Lreg</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>The pseudo bounding boxes generated during training: (1a) IoU distribution of pseudo-bboxes, (1b) distribution of pseudo-bboxes when the predicted class is wrong. (1c) number of pseudo-bboxes per IoU collected every 5000 iterations. (1d) Unsupervised classification and regression losses comparison during the training. Better seen in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>Faster R-CNN architecture with our branch in red.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a) Unsup regression loss weights.(b) Classification vs Regression.(c) Filtering with bbox IoU score. (d) Count filtered pseudo-bboxes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 :</head><label>3</label><figDesc>Ablation studies: (3a) weights for unsupervised regression loss on RPN and RoI. (3b) classification vs regression loss on bbox IoU branch. (3c) filtering bbox on inference with bbox IoU classification score. (3d) count bboxes filtered by inference threshold ? during training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>5 and t i represents the binary target label. For the i th bounding box, the branch output q IoU i ? [0, 1] is a single value which predicts if it is a high-or low-quality bounding box. The target t i and its IoU are defined as follows: .5 31.775 51.450 34.190 16.952 34.384 41.549 1 1.0 31.947 51.530 34.270 16.949 34.900 41.306 2 2.0 31.754 51.078 34.143 16.691 35.008 41.670 3 4.0 30.445 49.387 32.727 15.044 33.200 40.209</figDesc><table><row><cell># ?</cell><cell>AP</cell><cell>AP50 AP75</cell><cell>APs</cell><cell>APm</cell><cell>AP l</cell></row><row><cell>0 0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>(rows #2 and #3), we see that our new branch contributes to the # Method AP AP50 AP75 APs APm AP l 1 UT 31.027 50.757 33.056 17.014 33.684 40.322 2 Ours (with filter) 31.604 51.181 33.962 16.816 34.283 40.809 3 Ours (w/out filter) 31.509 51.118 33.564 16.848 34.684 40.582</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Performance comparison with original Unbiased Teacher (UT) model: (2) Training with BBox IoU branch with and (3) w/out pseudo-labels filtering.</figDesc><table><row><cell># ?</cell><cell>AP</cell><cell>AP50 AP75</cell><cell>APs</cell><cell>APm</cell><cell>AP l</cell></row><row><cell cols="6">1 0.5 31.199 51.009 33.047 16.187 34.000 40.180</cell></row><row><cell cols="6">2 0.6 31.128 50.785 33.268 17.102 33.805 39.932</cell></row><row><cell cols="6">3 0.7 31.461 51.319 33.637 16.714 34.217 40.100</cell></row><row><cell cols="6">4 0.75 31.604 51.181 33.962 16.816 34.283 40.809</cell></row><row><cell cols="6">5 0.8 31.336 50.601 33.707 16.327 34.180 40.476</cell></row><row><cell cols="6">6 0.9 27.125 43.515 28.800 12.815 29.486 36.034</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>31.404 51.205 33.792 16.273 34.542 40.851 1 0.4 31.630 51.185 34.044 17.387 34.494 40.784 2 0.5 31.604 51.181 33.962 16.816 34.283 40.809 3 0.6 31.158 50.227 33.418 16.203 33.687 40.323 4 0.7 30.649 49.216 33.138 16.532 33.409 39.542</figDesc><table><row><cell># ?</cell><cell>AP</cell><cell>AP50 AP75</cell><cell>APs</cell><cell>APm</cell><cell>AP l</cell></row><row><cell>0 0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Performance using BBox IoU classification branch with training threshold ? fixed to 0.75 and varying inference threshold ?.</figDesc><table><row><cell># L unsup reg</cell><cell>x sh scores deltas AP</cell><cell>AP50 AP75</cell><cell>APs</cell><cell>APm</cell><cell>AP l</cell></row><row><cell>1</cell><cell cols="5">31.027 50.757 33.056 17.014 33.684 40.322</cell></row><row><cell>2</cell><cell cols="5">31.947 51.530 34.270 16.949 34.900 41.306</cell></row><row><cell>3</cell><cell cols="5">31.754 51.189 34.032 16.850 34.657 41.320</cell></row><row><cell>4</cell><cell cols="5">32.166 51.772 34.765 16.647 34.999 41.870</cell></row><row><cell>5</cell><cell cols="5">31.923 51.464 34.070 16.202 35.197 41.368</cell></row><row><cell>6</cell><cell cols="5">31.630 51.185 34.044 17.387 34.494 40.784</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Study on unsupervised regression losses and IoU classification loss.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research benefits from the HPC (High Performance Computing) facility of the University of Parma, Italy.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Fast and accurate deep network learning by exponential linear units (elus)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Clevert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.07289</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bounding box regression with uncertainty for accurate object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Consistency-based semi-supervised learning for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Acquisition of localization confidence for accurate object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improving object detection with selective self-supervised self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Unbiased teacher for semi-supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vajda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.09480</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>3, 4</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semi-supervised object detection with unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">V</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rigaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Burie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VISIGRAPP (5: VISAPP)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Imbalance problems in object detection: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Oksuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Cam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kalkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Akbas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Samuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Timo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A simple semi-supervised learning framework for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04757</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Humble teachers teach better students for semi-supervised object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Improving object localization with fitness nms and bounded iou loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tychsen-Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Petersson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">End-to-end semi-supervised object detection with soft teacher</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09018</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Instant-teaching: An end-to-end semi-supervised object detection framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Iou-uniform r-cnn: Breaking through the limitations of rpn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
