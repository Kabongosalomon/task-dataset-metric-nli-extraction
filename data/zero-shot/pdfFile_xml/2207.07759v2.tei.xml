<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ESFPNet: efficient deep learning architecture for real-time lesion segmentation in autofluorescence bronchoscopic video</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering and Computer Science</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danish</forename><surname>Ahmad</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Medicine</orgName>
								<orgName type="institution">Penn State University</orgName>
								<address>
									<settlement>University Park and Hershey</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Toth</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Medicine</orgName>
								<orgName type="institution">Penn State University</orgName>
								<address>
									<settlement>University Park and Hershey</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Bascom</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">College of Medicine</orgName>
								<orgName type="institution">Penn State University</orgName>
								<address>
									<settlement>University Park and Hershey</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">E</forename><surname>Higgins</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering and Computer Science</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ESFPNet: efficient deep learning architecture for real-time lesion segmentation in autofluorescence bronchoscopic video</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>bronchoscopy</term>
					<term>lung cancer</term>
					<term>lesion detection and segmentation</term>
					<term>airway wall analysis</term>
					<term>autofluorescence imaging</term>
					<term>transformer</term>
					<term>feature pyramid</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With lung cancer being the most fatal cancer worldwide, it is important to detect the disease early. A potentially effective way of detecting early cancer lesions developing along the airway walls (epithelium) is bronchoscopy. To this end, developments in bronchoscopy offer three promising noninvasive modalities for imaging bronchial lesions: white-light bronchoscopy (WLB), autofluorescence bronchoscopy (AFB), and narrow-band imaging (NBI). While these modalities give complementary views of the airway epithelium, the physician must manually inspect each video stream produced by a given modality to locate the suspect cancer lesions. Unfortunately, no effort has been made to rectify this situation by providing efficient quantitative and visual tools for analyzing these video streams. This makes the lesion search process extremely time-consuming and error-prone, thereby making it impractical to utilize these rich data sources effectively. We propose a framework for synchronizing multiple bronchoscopic videos to enable interactive multimodal analysis of bronchial lesions. Our methods first register the video streams to a reference 3D chest computed-tomography (CT) scan to produce multimodal linkages to the airway tree. Our methods then temporally correlate the videos to one another to enable synchronous visualization of the resulting multimodal data set. Pictorial and quantitative results illustrate the potential of the methods on our collected AFB dataset. Furthermore, our model achieves state-of-the-art (SOTA) performance in both learning and generalization assessment on public datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Lung cancer is the most common cause of cancer death worldwide. <ref type="bibr" target="#b0">1</ref> An important goal toward improving lung cancer survival is to detect the disease at an early stage, thereby giving an opportunity for the most effective treatment options. Lung cancer begins when lesions develop in the bronchial epithelium of the lung mucosa. These bronchial lesions can eventually evolve into squamous cell lung cancer and also help predict the potential development of other lung cancers. Hence, methods for early detection of bronchial lesions are essential to help improve lung cancer patient care. A noninvasive way for physicians to search for such lesions is to use bronchoscopy for imaging the airway epithelium during a routine airway exam. <ref type="bibr" target="#b1">2</ref> Among the current advanced videobronchosopic techniques, autofluorescence bronchoscopy exhibits high sensitivity to suspicious bronchial lesions and effectively distinguishes developing bronchial lesions from the normal epithelium. Unfortunately, the current standard entails manual inspection of an incoming AFB video stream, which is extremely tedious and error prone. While some research has considered computer-based lesion analysis methods for AFB video frames, these works all have at least one of the following limitations: 1. Need complicated image preprocessing before reaching lesion decisions. 2. Don't provide accurate, instantaneous segmentation of abnormal lesion regions, as an aid toward locating potential lesions. 3. Can't process an input AFB video stream in real-time, thereby making the methods unsuitable for making lesion decisions during a live bronchoscopic airway exam.</p><p>We propose a DL architecture that enables real-time detection and segmentation of bronchial lesions in an AFB video frame, without the need for image enhancement. Our architecture draws on pretrained Mix Transformer encoders as the backbone and a decoder structure that incorporates a stage-wise feature pyramid to guarantee accurate lesion segmentation. <ref type="figure" target="#fig_0">Figure 1</ref> depicts our architecture, which utilizes the Mix Transformer (MiT) encoder as the backbone and uses an efficient stage-wise feature pyramid (ESFP) decoder to generate segmentation outputs. We introduce each component in the following subsections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Backbone:</head><p>The Mix Transformer encoder (MiT) is a module that takes advantage of the idea of the vision Transformer (ViT) network and uses four overlapped path merging modules and self-attention prediction in four stages. <ref type="bibr" target="#b2">3</ref> These stages not only furnish high-resolution coarse features, but also provide low-resolution fine-grained features. In addition, the high-and low-resolution features are commonly used to boost the performance of semantic segmentation. Benefiting from the widely used concept of transfer learning for applications drawing on small datasets to alleviate the challenge of data hunger, the MiT encoders are pretrained on the ImageNet database. <ref type="bibr" target="#b3">4</ref> This facilitates good performance over small task-specific datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Efficient Stage-wise Feature Pyramid (ESFP):</head><p>Previous state-of-the-art networks (such as U-net) rely on aggregating multi-level features from the encoder. In general, the high-level features contribute more to segmentation performance, while the low-level features provide less. The existing Segformer model, however, simply concatenates these multi-level features to predict segmentation results and lacks the ability to selectively use local information. <ref type="bibr" target="#b2">3</ref> As a result, this makes it easy for the network to compute useless local features, which can mislead final segmentations. To address this issue, SSFormer proposes an aggregating feature pyramid architecture that first utilizes two layers of convolution to preprocess feature outputs from each MiT stage and then fuses any two features in reverse order until final prediction. <ref type="bibr" target="#b4">5</ref> Nevertheless, our experiments indicate that SSFormer is not efficient for real-time segmentation. Inspired by a lightweight channel-wise feature pyramid network (CfpNet) that fuses every pair of features and concatenates multi-level fused elements for the final prediction, we propose a novel and efficient stage-wise feature pyramid (ESFP) to exploit multi-stage features more effectively. <ref type="bibr" target="#b5">6</ref> ESFP starts with linear predictions of each stage output and then linearly fuses these preprocessed features from global to local. These fused features are concatenated and work cooperatively for the final segmentation .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">VALIDATION EXPERIMENTS:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Implementation details</head><p>We implement our model in Pytorch and accelerate training via NVIDIA GPUs. Since the difference of MiT encoders' scales and the GPU memory required to train, we train MiT-B0 based network on an NVIDIA RTX 3090 and others (MiT-B1?5) on an NVIDIA TESLA A100 GPU. Before the training, we resize the inputs to 352 ? 352 pixels and normalize them for segmentation. We also employ random flipping, rotation, and brightness changing as data augmentation operations on the inputs. Our loss function combines the weighted intersection over union (IoU) loss and the weighted binary cross-entropy (BCE) loss:</p><formula xml:id="formula_0">L = L w IoU + L w BCE .</formula><p>We use the default AdamW optimizer with the learning rate 1e ?4 and train our models 200 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dataset</head><p>We first tested our architecture using our AFB dataset consisting of 720 ? 720 video frames. As an additional validation to measure our network's general applicability, we also used five public datasets (Kvasir, 7 CVC-ClinicDB, <ref type="bibr" target="#b7">8</ref> CVC-T, 9 CVC-ColonDB 10 and ETIS-LaribPolypDB 11 ) to demonstrate our network performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">AFB dataset</head><p>See <ref type="table">Table 1</ref>. We collected 150 AFB frames depicting bronchial lesions, where we drew frames from 10 patient cases. These cases were collected under informed consent at our University hospital under an IRB approved protocol. The lesion frames were selected to ensure variations in the locations and sizes of lesions, with all frames labeled by an expert. We split the dataset into train, test, and validation sets using a 60%, 20%, 20% split, respectively. Images from 8 cases were utilized for training. Case 171 data were used to validate and choose the network hyper-parameters, while case 184 data were used to test and evaluate segmentation performance. See <ref type="figure" target="#fig_1">Figure 2</ref>.  <ref type="table">Table 1</ref>. AFB dataset details. All data collected under informed consent at our University hospital under IRB protocol 21405. "Case" = patient case number, "lesion frames" = number of lesion frames selected from the case, "total lesion frames" = the total number of selected lesion frames as given in column 2, and "split ratio" = percent of total lesion-frame dataset applied to the particular operation. Finally, the "lesion size ratio" values assume that lesions occur inside the frame's circular portion corresponding to AFB video; i.e., 100% = 352?352?? pixels. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Polyp segmentation datasets</head><p>A good model usually contains both strong learning ability and robust generalization capability. Moreover, a model is trained on a dataset, and learning ability indicates the predicting accuracy of the model on the same dataset, while generalization capability refers to the forecasting performances of this model on the other unseen datasets. To exemplify the advantages of our model in these aspects, we set up 3 experiments. Each setup is reported in detail below:</p><p>? Learning ability experiment: Following the experimental scheme of MSRF-Net, <ref type="bibr" target="#b11">12</ref> we train, validate, and test ESFPNet on the Kavsir and CVC-ClinicDB benchmark datasets, respectively. We randomly split each dataset into 80% training dataset, 10% validation dataset, and 10% test dataset. The model is saved when it reaches the optimized dice coefficient on the validation dataset and later used to generate predictions from the test dataset.</p><p>? Generalization capability experiment: We use the same dataset splitting as recommended in the experimental scheme of ParaNet, <ref type="bibr" target="#b12">13</ref> where 1450 (90%) video frames from the Kvasir and CVC-ClinicDB benchmark datasets are used for training. All images from CVC-ColonDB and ETIS-LaribPolypDB are used for testing. The best performance of each dataset is kept and used to depict the model's forecasting performance on an unseen dataset.</p><p>? Power balance experiment: We use the same training dataset in the generalization capability experiment. The remaining frames from the Kvasir and CVC-ClinicDB datasets and all pictures from CVC-ColonDB, CVC-T, and ETIS-LaribPolypDB are used for testing. The model is saved when it reaches convergence and utilized to analyze the segmentation performances of 5 testing datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Baseline and measurement metrics</head><p>We compare our ESFPNet with other medical segmentation models, including state-of-art models: Unet++, 14 Deeplabv3+, 15 SFA, <ref type="bibr" target="#b15">16</ref> CaraNet, 17 MSRF-Net, <ref type="bibr" target="#b11">12</ref> and SSFormer. <ref type="bibr" target="#b4">5</ref> To evaluate our results, we use mean dice, mean IoU, structural measurement S ? , 18 enhanced alignment metric E max ? , <ref type="bibr" target="#b18">19</ref> and the average mean absolute error (MAE). Moreover, S ? is used to measure the structural similarity between predictions and ground truth, while the recently released E max ? is utilized to assess the pixel-level and global-level similarity. The MAE is the measurement of pixel accuracy. All these metrics are calculated by the ParaNet provided tool. <ref type="bibr" target="#b12">13</ref> To compare with other models, we only use mean dice and mean IoU as the unifying measures in the learning ability and the power balance experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RESULTS</head><p>Based on the different MiT encoder scales, we propose ESFPNet-T (tiny model), ESFPNet-S (standard model), and ESFPNet-L (large model) based on the MiT-B0, -B2, and -B4, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Result analysis on AFB dataset</head><p>We compare our segmentation results with the SSFormer 5 and the CARANet 17 by training these networks under the same settings. Moreover, We compare the attributes of the various networks by noting the number of parameters they entail and the number of floating-point operations (FLOPs) they require when used. We evaluate the segmentation performance of the various networks by using the mean Dice and IoU values. <ref type="figure" target="#fig_2">Figure  3</ref> shows examples lesion segmentation results for our models and the CARANet, SSFormer-S, and SSFormer-L, while <ref type="table" target="#tab_2">Table 2</ref> gives quantitative results. The ESFPNet-S uses the same backbone as the SSFormer-S and performs better in terms of the mean Dice and IoU values, while also requiring fewer FLOPs for computation. This same result arises for the comparison between ESFPNet-L and the SSFormer-L. In conclusion, ESFPNet-S performs best in the comparison of the AFB dataset.</p><p>Besides, we load our ESFPNet-S into C++ and use an NVIDIA RTX 3090 to test the processing speed of the end-to-end segmentation procedure. The end-to-end segmentation procedure contains reading frames from the AFB video, image normalization and resizing, ESFPNet prediction on the lesion, and displaying the lesion segmentation views on the original frames. The average frame rate of processing 1000 images is 27 frames per second (FPS), which enables real-time processing.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Quantitative comparison on Polyp dataset</head><p>Table3 demonstrates our ESFPNet-L achieves SOTA performances on CVC-ClinicDB benchmark dataset. In other words, our ESFPNet has a strong learning ability. Table4 shows the comparison of variations of ESFPNet and table5 refers to the quantitative comparison of power balance with other models. These results indicate that model has the best generalization capability on CVC-ColonDB and ETIS-LaribPolyDB, while maintaining a fair learning ability.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>Bronchial lesions can be treated as biomarkers that signal lung cancer. These lesions, which can be detected by autofluorescence bronchoscopy, are useful for detecting lung cancer at the early stage. We have proposed ESFPNet for bronchial lesion segmentation and have applied it to an AFB lung cancer patient dataset. Our preliminary results demonstrate good segmentation performance and the potential to be used during live bronchoscopic airway exams. To the best of our knowledge, this is the first work for automatic real-time segmentation of bronchial lesions in AFB video. Moreover, our proposed efficient stage-wise feature pyramid (ESFP) on Mixtransformer (MiT) encoder with the SOTA performances on public datasets presents a strong capability for medical image segmentation. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Block diagram of our DL architecture, which contains a pretrained MiT encoder and an ESFP decoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>AFB lesion samples in the training dataset (first row) and validation dataset (second row) that varies in the view and the size of lesion area. Each frame pair gives the original frame and ground truth segmentation.The size of the lesion object is increased from left to right on each row. Remarkably, the first and second column of the first row indicates the same lesion but show a different appearance of the lesion object from a different position, as well as the first two columns of the second row.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Segmentation results from the different models in the autofluorescence bronchoscopy (AFB) frames.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Analysis performance for several DL architectures. "Parameters" = number of architecture parameters in millions (M), GFLOPs = gigaflops (flops = floating-point operations). The GFLOPs count assumes input dimensions = (1,3,352,352).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Quantitative comparison on learning ability</figDesc><table><row><cell>Dataset</cell><cell cols="2">CVC-ClinicDB</cell><cell cols="2">Kvasir</cell></row><row><cell>Methods</cell><cell cols="4">mDice mIoU mDice mIoU</cell></row><row><cell>U-net++</cell><cell>0.915</cell><cell>0.865</cell><cell>0.863</cell><cell>0.818</cell></row><row><cell cols="2">Deeplabv3+ 0.888</cell><cell>0.871</cell><cell>0.897</cell><cell>0.858</cell></row><row><cell>MSRF-Net</cell><cell>0.942</cell><cell>0.904</cell><cell>0.922</cell><cell>0.891</cell></row><row><cell>SSFormer-L</cell><cell>0.945</cell><cell cols="3">0.899 0.936 0.891</cell></row><row><cell cols="4">ESFPNet-L 0.950 0.909 0.925</cell><cell>0.875</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Generalization capability test</figDesc><table><row><cell>datasets</cell><cell>methods</cell><cell>mDice mIoU</cell><cell>S ?</cell><cell>E max ?</cell><cell>MAE</cell></row><row><cell>ETIS-LaribPolypDB</cell><cell cols="5">ESFPNet-T 0.745 ESFPNet-S 0.781 ESFPNet-L 0.815 0.734 0.883 0.927 0.011 0.657 0.845 0.876 0.018 0.693 0.860 0.885 0.017</cell></row><row><cell>CVC-ColonDB</cell><cell cols="5">ESFPNet-T 0.769 ESFPNet-S 0.771 ESFPNet-L 0.811 0.727 0.864 0.909 0.031 0.679 0.836 0.882 0.036 0.682 0.860 0.885 0.016</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Quantitative comparison on power balance experiment</figDesc><table><row><cell>methods</cell><cell cols="10">Kvasir mDice mIoU mDice mIoU mDice mIoU mDice mIoU mDice CVC-ClinicDB CVC-T CVC-ColonDB ETIS-LaribPolypDB mIoU</cell></row><row><cell>Unet++</cell><cell>0.818</cell><cell>0.746</cell><cell>0.823</cell><cell>0.750</cell><cell>0.710</cell><cell>0.627</cell><cell>0.512</cell><cell>0.444</cell><cell>0.398</cell><cell>0.335</cell></row><row><cell>SFA</cell><cell>0.723</cell><cell>0.611</cell><cell>0.700</cell><cell>0.607</cell><cell>0.297</cell><cell>0.217</cell><cell>0.469</cell><cell>0.347</cell><cell>0.467</cell><cell>0.329</cell></row><row><cell>CaraNet</cell><cell cols="7">0.918 0.865 0.936 0.887 0.903 0.838 0.773</cell><cell>0.689</cell><cell>0.747</cell><cell>0.672</cell></row><row><cell cols="2">SSFormer-L 0.917</cell><cell>0.864</cell><cell>0.906</cell><cell>0.855</cell><cell>0.895</cell><cell>0.827</cell><cell cols="3">0.802 0.721 0.796</cell><cell>0.720</cell></row><row><cell cols="2">ESFPNet-L 0.913</cell><cell>0.860</cell><cell>0.924</cell><cell>0.878</cell><cell>0.895</cell><cell cols="4">0.827 0.803 0.719 0.801</cell><cell>0.772</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Global cancer statistics 2018: Globocan estimates of incidence and mortality worldwide for 36 cancers in 185 countries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ferlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Soerjomataram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jemal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CA: Cancer J. Clin</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="394" to="424" />
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Early lung cancer detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Inage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yoshino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasufuku</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin. Chest Med</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="45" to="55" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Segformer: Simple and efficient design for semantic segmentation with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="12077" to="12090" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Stepwise feature fusion: Local guides global</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.03635</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Cfpnet: Channel-wise feature pyramid for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loew</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.12212</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Kvasir-seg: A segmented polyp dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimedia Modeling</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Wm-dova maps for accurate polyp highlighting in colonoscopy: Validation vs. saliency maps from physicians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fern?ndez-Esparrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vilari?o</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Med. Imaging Graph</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="2015-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A benchmark for endoluminal scene segmentation of colonoscopy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>V?zquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fern?ndez-Esparrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Drozdzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of healthcare engineering</title>
		<imprint>
			<biblScope unit="page">2017</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automated polyp detection in colonoscopy videos using shape and context information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Gurudu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="630" to="644" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Toward embedded detection of polyps in wce images for early diagnosis of colorectal cancer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Histace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Romain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Granado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer assisted radiology and surgery</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="283" to="293" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Msrf-net: A multi-scale residual fusion network for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2252" to="2263" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Pranet: Parallel reverse attention network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="263" to="273" />
		</imprint>
	</monogr>
	<note>International conference on medical image computing and computer-assisted intervention</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Unet++: A nested u-net architecture for medical image segmentation,&quot; in [Deep learning in medical image analysis and multimodal learning for clinical decision support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M R</forename><surname>Siddiquee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="3" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
	<note>in [Proceedings of the European conference on computer vision (ECCV)</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Selective feature aggregation network with area-boundary constraints for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<biblScope unit="page" from="302" to="310" />
			<date type="published" when="2019" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Caranet: Context axial reverse attention network for segmentation of small medical objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loew</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07368</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Structure-measure: A new way to evaluate foreground maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4548" to="4557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Enhanced-alignment measure for binary foreground map evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Borji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10421</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
