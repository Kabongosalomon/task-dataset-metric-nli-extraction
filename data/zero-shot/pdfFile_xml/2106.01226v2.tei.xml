<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Zeng</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory of Machine Perception (MOE)</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we study the semi-supervised semantic segmentation problem via exploring both labeled data and extra unlabeled data. We propose a novel consistency regularization approach, called cross pseudo supervision (CPS). Our approach imposes the consistency on two segmentation networks perturbed with different initialization for the same input image. The pseudo one-hot label map, output from one perturbed segmentation network, is used to supervise the other segmentation network with the standard cross-entropy loss, and vice versa. The CPS consistency has two roles: encourage high similarity between the predictions of two perturbed networks for the same input image, and expand training data by using the unlabeled data with pseudo labels. Experiment results show that our approach achieves the state-of-the-art semi-supervised segmentation performance on Cityscapes and PASCAL VOC 2012. Code</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image semantic segmentation is a fundamental recognition task in computer vision. The semantic segmentation training data requires pixel-level manual labeling, which is much more expensive compared to the other vision tasks, such as image classification and object detection. This makes semi-supervised segmentation an important problem to learn segmentation models by using the labeled data as well as the additional unlabeled data.</p><p>Consistency regularization is widely studied in semisupervised semantic segmentation. It enforces the consistency of the predictions with various perturbations, e.g., input perturbation by augmenting input images <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19]</ref>, feature perturbation <ref type="bibr" target="#b26">[27]</ref>, and network perturbation <ref type="bibr" target="#b17">[18]</ref>. Self-training is also studied for semi-supervised segmentation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b24">25]</ref>. It incorporates pseudo segmentation maps on the unlabeled images obtained from the segmentation model trained on the labeled images to expand the training data, and retrains the segmentation model.</p><p>We present a novel and simple consistency regularization approach with network perturbation, called cross pseudo supervision. The proposed approach feeds the labeled and unlabeled images into two segmentation networks that share the same structure and are initialized differently. The outputs of the two networks on the labeled data are supervised separately by the corresponding ground-truth segmentation map. Our main point lies in the cross pseudo supervision that enforces the consistency between the two segmentation networks. Each segmentation network for an input image estimates a segmentation result, called pseudo segmentation map. The pseudo segmentation map is used as an additional signal to supervise the other segmentation network.</p><p>The benefits from the cross pseudo supervision scheme lie in two-fold. On the one hand, like previous consistency regularization, the proposed approach encourages that the predictions across differently initialized networks for the same input image are consistent and that the prediction decision boundary lies in low-density regions. On the other hand, during the later optimization stage the pseudo segmentation becomes stable and more accurate than the result from normal supervised training only on the labeled data. The pseudo labeled data behaves like expanding the training data, thus improving the segmentation network training quality.</p><p>Experimental results with various settings on two benchmarks, Cityscapes and PASCAL VOC 2012, show that the proposed cross pseudo supervision approach is superior to existing consistency schemes for semi-supervised segmentation. Our approach achieves the state-of-the-art semisupervised segmentation performance on both benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Semantic segmentation. Modern deep learning methods for semantic segmentation are mostly based on fullyconvolutional network (FCN) <ref type="bibr" target="#b22">[23]</ref>. The subsequent developments studies the models from three main aspects: resolution, context, and edge. The works on resolution enlargement include mediating the spatial loss caused in the classification network, e.g., using the encoder-decoder scheme <ref type="bibr" target="#b4">[5]</ref> or dilated convolutions <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b3">4]</ref>, and maintaining high resolution, such as HRNet <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b29">30]</ref>.</p><p>The works on exploiting contexts include spatial context, e.g., PSPNet <ref type="bibr" target="#b40">[41]</ref> and ASPP <ref type="bibr" target="#b3">[4]</ref>, object context <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b36">37]</ref>, and application of self-attention <ref type="bibr" target="#b32">[33]</ref>. Improving the segmentation quality on the edge areas include Gated-SCNN <ref type="bibr" target="#b30">[31]</ref>, PointRend <ref type="bibr" target="#b19">[20]</ref>, and SegFix <ref type="bibr" target="#b38">[39]</ref>. In this paper, we focus on how to use the unlabeled data, conduct experiments mainly using DeepLabv3+ and also report the results on HRNet.</p><p>Semi-supervised semantic segmentation. Manual pixellevel annotations for semantic segmentation is very timeconsuming and costly. It is valuable to explore the available unlabeled images to help learn segmentation models. Consistency regularization is widely studied for semisupervised segmentation. It enforces the consistency of the predictions/intermediate features with various perturbations. Input perturbation methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b18">19]</ref> augment the input images randomly and impose the consistency constraint between the predictions of augmented images, so that the decision function lies in the low-density region.</p><p>Feature perturbation presents a feature perturbation scheme by using multiple decoders and enforces the consistency between the outputs of the decoders <ref type="bibr" target="#b26">[27]</ref>. The approach GCT <ref type="bibr" target="#b16">[17]</ref> further performs network perturbation by using two segmentation networks with the same structure but initialized differently and enforces the consistency between the predictions of the perturbed networks. Our approach differs from GCT and enforces the consistency by using the pseudo segmentation maps with an additional benefit like expanding the training data.</p><p>Other than enforcing the consistency between various perturbations for one image, the GAN-based approach <ref type="bibr" target="#b24">[25]</ref> enforce the consistency between the statistical features of the ground-truth segmentation maps for labeled data and the predicted segmentation maps on unlabeled data. The statistical features are extracted from a discriminator network that is learned to distinguish ground-truth segmentation and predicted segmentation.</p><p>Self-training, a.k.a., self-learning, self-labeling, or decision-directed learning, is initially developed for using unlabeled data in classification <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b21">22]</ref>. Recently it is applied for semi-supervised segmentation <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b23">24]</ref>. It incorporates pseudo segmentation maps on unlabeled data obtained from the segmentation model previously trained on labeled data for retraining the segmentation model. The process can be iterated several times. Various schemes are introduced on how to decide the pseudo segmentation maps. For example, the GANbased methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29]</ref>, use the discriminator learned for distinguishing the predictions and the ground-truth segmentation to select high-confident segmentation predictions on unlabeled images as pseudo segmentation.</p><p>PseudoSeg <ref type="bibr" target="#b44">[44]</ref>, concurrent to our work, also explores pseudo segmentation for semi-supervised segmentation. There are at least two differences from our approach. Pseu-doSeg follows the FixMatch scheme <ref type="bibr" target="#b27">[28]</ref> via using the pseudo segmentation of a weakly-augmented image to su-pervise the segmentation of a strongly-augmented image based on a single segmentation network. Our approach adopts two same and independently-initialized segmentation networks with the same input image, and uses the pseudo segmentation maps of each network to supervise the other network. On the other hand, our approach performs back propagation on both the two segmentation networks, while PseudoSeg only performs back propagation for the strongly-augmented image.</p><p>Semi-supervised classification. Semi-supervised classification was widely studied in the first decade of this century <ref type="bibr" target="#b2">[3]</ref>. Most solutions are based on the assumptions, such as smoothness, consistency, low-density, or clustered. Intuitively, neighboring data have a high probability of belonging to the same class, or the decision boundary should lie in low-density regions.</p><p>Deep learning methods impose the consistency over perturbed inputs or augmented images encouraging the model to produce the similar output/distributions for the perturbed inputs, such as temporal ensembling <ref type="bibr" target="#b20">[21]</ref> and its extension mean teacher <ref type="bibr" target="#b31">[32]</ref>. Dual student <ref type="bibr" target="#b17">[18]</ref> makes modifications by jointly learning two classification networks that initialized differently with complex consistency on the predictions and different image augmentations.</p><p>Other development includes estimating labels for unlabeled data, e.g., MixMatch <ref type="bibr" target="#b1">[2]</ref> combining the estimations on multiple augmentations, FixMatch <ref type="bibr" target="#b27">[28]</ref> using pseudo labels on weak augmentation to supervise the labeling on strong augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head><p>Given a set D l of N labeled images, and a set D u of M unlabeled images, the semi-supervised semantic segmentation task aims to learn a segmentation network by exploring both the labeled and unlabeled images.</p><p>Cross pseudo supervision. The proposed approach consists of two parallel segmentation networks:</p><formula xml:id="formula_0">P 1 = f (X; ? 1 ),<label>(1)</label></formula><formula xml:id="formula_1">P 2 = f (X; ? 2 ).<label>(2)</label></formula><p>The two networks have the same structure and their weights, i.e., ? 1 and ? 2 , are initialized differently. The inputs X are with the same augmentation, and P 1 (P 2 ) is the segmentation confidence map, which is the network output after softmax normalization. The proposed approach is logically illustrated as below 1 :</p><formula xml:id="formula_2">X ? X ? f (? 1 ) ? P 1 ? Y 1 f (? 2 ) ? P 2 ? Y 2 .<label>(3)</label></formula><p>Here Y 1 (Y 2 ) is the predicted one-hot label map, called pseudo segmentation map. At each position i, the label vec- <ref type="figure">Figure 1</ref>: Illustrating the architectures for (a) our approach cross pseudo supervision, (b) cross confidence consistency (e.g., a component of GCT <ref type="bibr" target="#b16">[17]</ref>), (c) mean teacher (used in CutMix-Seg <ref type="bibr" target="#b10">[11]</ref>), and (d) PseudoSeg <ref type="bibr" target="#b44">[44]</ref> structure (similar to FixMatch <ref type="bibr" target="#b27">[28]</ref>). '?' means forward operation and ' ' means loss supervision. '//' on '?' means stop-gradient. More details are illustrated in the approach section.</p><formula xml:id="formula_3">(a) f (? 2 ) P 1 P 2 X f (? 1 ) Y 1 Y 2 (b) f (? 2 ) P 1 P 2 X f (? 1 ) (c) f (?) P 1 P 2 X f (?) X 1 X 2 (d) f (?) P s P w X f (?) X s X w Y w</formula><p>tor y 1i (y 2i ) is a one-hot vector computed from the corresponding confidence vector p 1i (p 2i ). The complete version of our method is illustrated in <ref type="figure">Figure 1</ref> (a) and we have not included the loss supervision in the above equations.</p><p>The training objective contains two losses: supervision loss L s and cross pseudo supervision loss L cps . The supervision loss L s is formulated using the standard pixel-wise cross-entropy loss on the labeled images over the two parallel segmentation networks:</p><formula xml:id="formula_4">L s = 1 |D l | X?D l 1 W ? H W ?H i=0 ( ce (p 1i , y * 1i ) + ce (p 2i , y * 2i )),<label>(4)</label></formula><p>where ce is the cross-entropy loss function and y * 1i (y * 2i ) is the ground truth. W and H represent the width and height of the input image.</p><p>The cross pseudo supervision loss is bidirectional: One is from f (? 1 ) to f (? 2 ). We use the pixel-wise one-hot label map Y 1 output from one network f (? 1 ) to supervise the pixel-wise confidence map P 2 of the other network f (? 2 ), and the other one is from f (? 2 ) to f (? 1 ). The cross pseudo supervision loss on the unlabeled data is written as</p><formula xml:id="formula_5">L u cps = 1 |D u | X?D u 1 W ? H W ?H i=0 ( ce (p 1i , y 2i ) + ce (p 2i , y 1i )).<label>(5)</label></formula><p>We also define the cross pseudo supervision loss L l cps on the labeled data in the same way. The whole cross pseudo supervision loss is the combination of the losses on both the labeled and unlabeled data: L cps = L l cps + L u cps . The whole training objective is written as:</p><formula xml:id="formula_6">L = L s + ?L cps ,<label>(6)</label></formula><p>where ? is the trade-off weight.</p><p>Incorporation with the CutMix augmentation. The Cut-Mix augmentation scheme <ref type="bibr" target="#b39">[40]</ref> is applied to the mean teacher framework for semi-supervised segmentation <ref type="bibr" target="#b10">[11]</ref>. We also apply the CutMix augmentation in our approach. We input the CutMixed image into the two networks f (? 1 ) and f (? 2 ). We use the way similar to <ref type="bibr" target="#b10">[11]</ref> to generate pseudo segmentation maps from the two networks: input two source images (that are used to generate the CutMix images) into each segmentation network and mix the two pseudo segmentation maps as the supervision of the other segmentation network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussions</head><p>We discuss the relations of our method with several related works as following.</p><p>Cross probability consistency. An optional consistency across the two perturbed networks is cross probability consistency: the probability vectors (from pixel-wise confidence maps) should be similar (illustrated in <ref type="figure">Figure 1 (b)</ref>). The loss function is written as:</p><formula xml:id="formula_7">L cpc = 1 |D| X?D 1 W ? H W ?H i=0 ( 2 (p 1i , p 2i ) + 2 (p 2i , p 1i )).<label>(7)</label></formula><p>Here an example loss 2 (p 1i , p 2i ) = p 1i ? p 2i 2 2 is used to impose the consistency. Other losses, such as KLdivergence, and the consistency over the intermediate features can also be used. We use D to represent the union of labeled set D l and unlabeled set D u .</p><p>Similar to the feature/probability consistency, the proposed cross pseudo supervision consistency also expects the consistency between the two perturbed segmentation networks. In particular, our approach in some sense augments the training data by exploring the unlabeled data with pseudo labels. The empirical results shown in <ref type="table">Table 4</ref> indicates that cross pseudo supervision outperforms cross probability consistency.</p><p>Mean teacher. Mean teacher <ref type="bibr" target="#b31">[32]</ref> is initially developed for semi-supervised classification and recently applied for semi-supervised segmentation, e.g., in CutMix-Seg <ref type="bibr" target="#b10">[11]</ref>. The unlabeled image with different augmentations is fed into two networks with the same structure: one is student f (?), and the other one is mean teacher f (?) with the parameter? being the moving average of the student network parameter ?:</p><formula xml:id="formula_8">X ? X 1 ? f (?) ? P 1 X 2 ? f (?) P 2 .<label>(8)</label></formula><p>We use X 1 and X 2 to represent the differently augmented version of X. The consistency regularization aims to align the probability map P 1 of X 1 predicted by the student network to the probability map P 2 of X 2 predicted by the teacher network. During the training, we supervise P 1 with P 2 and apply no back propagation for the teacher network. We use to represent "no back propagation" in the following illustration. we have not included the loss supervision in the above equations and illustrate the complete version in <ref type="figure">Figure 1</ref> (c). The results in <ref type="table" target="#tab_0">Table 1</ref> and <ref type="table" target="#tab_1">Table 2</ref> show that our approach is superior to the mean teacher approach.</p><p>Single-network pseudo supervision. We consider a downgraded version of our approach, single-network pseudo supervision, where the two networks are the same:</p><formula xml:id="formula_9">X ? X ? f (?) ? P f (?) ? P Y.<label>(9)</label></formula><p>The structure is similar to <ref type="figure">Figure 1 (d)</ref>, and the only difference is that the inputs to two streams are the same rather than one weak augmentation and one strong augmentation. We use from Y to P to represent the loss supervision. Empirical results show that single-network pseudo supervision performs poorly. The main reason is that supervision by the pseudo label from the same network tends to learn the network itself to better approximate the pseudo labels and thus the network might converge in the wrong direction. In contrast, supervision by the cross pseudo label from the other network, which differs from the pseudo label from the network itself due to network perturbation, is able to learn the network with some probability away from the wrong direction. In other words, the perturbation of pseudo label between two networks in some sense serves as a regularizer, free of over-fitting the wrong direction.</p><p>In addition, we study the single-network pseudo supervision in a way like <ref type="bibr" target="#b10">[11]</ref> with the CutMix augmentation. We input two source images into a network f (?) and mix the two pseudo segmentation maps as a pseudo segmentation map of the CutMixed image, which is used to supervise the output of the CutMixed image from the same network. Back propagation of the pseudo supervision is only done for the CutMixed image. The results show that our approach performs better ( <ref type="table" target="#tab_5">Table 6)</ref>, implying that network perturbation is helpful though there is already perturbation from the way with the CutMix augmentation in <ref type="bibr" target="#b10">[11]</ref>.</p><p>PseudoSeg. PseudoSeg <ref type="bibr" target="#b44">[44]</ref>, similar to FixMatch <ref type="bibr" target="#b27">[28]</ref>, applies weakly-augmented image X w to generate pseudo segmentation map, which is used to supervise the output of strongly-augmented image X s from the same network with the same parameters. X w and X s are based on the same input image X. PseudoSeg only conducts back propagation on the path that processes the strongly-augmented image X s (illustrated in <ref type="figure">Figure 1 (d)</ref>). It is logically formed as:</p><formula xml:id="formula_10">X ? X s ? f (?) ? P s X w ? f (?) ? P w Y w .<label>(10)</label></formula><p>We use from Y w to P s to represent the loss supervision. The above manner is similar to single-network pseudo supervision. The difference is that the pseudo segmentation map is from weak augmentation and it supervises the training over strong augmentation. We guess that besides the segmentation map based on weak augmentation is more accurate, the other reason is same as our approach: the pseudo segmentation map from weak augmentation also introduces extra perturbation to the pseudo supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Setup</head><p>Datasets. PASCAL VOC 2012 [8] is a standard objectcentric semantic segmentation dataset, which consists of more than 13, 000 images with 20 object classes and 1 background class. The standard training, validation and test sets consist of 1, 464, 1, 449 and 1, 456 images respectively. We follow the previous work to use the augmented set <ref type="bibr" target="#b11">[12]</ref> (10, 582 images) as our full training set.</p><p>Cityscapes <ref type="bibr" target="#b6">[7]</ref> is mainly designed for urban scene understanding. The official split has 2, 975 images for training, 500 for validation and 1, 525 for testing. Each image has a resolution of 2048 ? 1024 and is fine-annotated with pixellevel labels of 19 semantic classes.</p><p>We follow the partition protocols of Guided Collaborative Training (GCT) <ref type="bibr" target="#b16">[17]</ref> and divide the whole training set to two groups via randomly sub-sampling 1/2, 1/4, 1/8 and 1/16 of the whole set as the labeled set and regard the remaining images as the unlabeled set.</p><p>Evaluation. We evaluate the segmentation performance using mean Intersection-over-Union (mIoU) metric. For all partition protocols, we report results on the 1, 456 PASCAL VOC 2012 val set (or 500 Cityscapes val set) via only single scale testing. We only use one network in our approach to generate the results for evaluation. Implementation details. We implement our method based on PyTorch framework. We initialize the weights of two backbones in the two segmentation networks with the same weights pre-trained on ImageNet and the weights of two segmentation heads (of DeepLabv3+) randomly. We adopt mini-batch SGD with momentum to train our model with Sync-BN <ref type="bibr" target="#b15">[16]</ref>. The momentum is fixed as 0.9 and the weight decay is set to 0.0005. We employ a poly learning rate policy where the initial learning rate is multiplied by (1 ? iter max iter ) 0.9 . For the supervised baseline trained on the full training set, we use random horizontal flipping and multi-scale as data augmentation if not specified. We train PASCAL VOC 2012 for 60 epochs with base learning rate set to 0.01, and Cityscapes for 240 epochs with base learning rate set to 0.04. OHEM loss is used on Cityscapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results</head><p>Improvements over baselines. We illustrate the improvements of our method compared with the supervised baseline under all partition protocols in <ref type="figure" target="#fig_0">Figure 2</ref>. All the methods are based on DeepLabv3+ with ResNet-50 or ResNet-101. Comparison with SOTA. We compare our method with some recent semi-supervised segmentation methods including: Meat-Teacher (MT) <ref type="bibr" target="#b31">[32]</ref>, Cross-Consistency Training (CCT) <ref type="bibr" target="#b26">[27]</ref>, Guided Collaborative Training (GCT) <ref type="bibr" target="#b16">[17]</ref>, and CutMix-Seg <ref type="bibr" target="#b10">[11]</ref> under different partition protocols. Specifically, we adopt the official open-sourced implementation of CutMix-Seg. For MT and GCT, we use implementations from <ref type="bibr" target="#b16">[17]</ref>. We compare them using the same architecture and partition protocols for fairness. <ref type="table" target="#tab_0">Table 1</ref> shows the comparison results on PASCAL VOC 2012. We can see that over all the partitions, with both ResNet-50 and ResNet-101, our method w/o CutMix augmentation consistently outperforms the other methods except CutMix-Seg that uses the strong CutMix augmentation <ref type="bibr" target="#b39">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PASCAL VOC 2012:</head><p>Our approach w/ CutMix augmentation performs the best and sets new state-of-the-arts under all partition protocols. For example, our approach w/ CutMix augmentation outperforms the CutMix-Seg by 3.08% and 1.92% under 1/16 partition protocol with ResNet-50 and ResNet-101 separately. The results imply that our cross pseudo supervision scheme is superior to mean teacher scheme that is used in CutMix-Seg.</p><p>When comparing the results of our approach w/o and w/ CutMix augmentation, we have the following observation: the CutMix augmentation is more important for the scenario with fewer labeled data. For example, with ResNet-50, the gain 3.77% under the 1/16 partition is higher than 0.47% under the 1/8 partition.</p><p>Cityscapes: <ref type="table" target="#tab_1">Table 2</ref> illustrates the comparison results on the Cityscapes val set. We do not have the results for CutMix-Seg as the official CutMix-Seg implementation only supports single-GPU training and it is not feasible to run CutMix-Seg with DeepLabv3+ on Cityscapes due to the GPU memory limit. In comparison to other SOTA methods,   our method achieves the best performance among all partition protocols with both ResNet-50 and ResNet-101 backbones. For example, our method w/ CutMix augmentation obtains 80.08% under the 1/2 partition with ResNet-101 backbone, which outperforms GCT by 1.50%. We report the additional results on HRNet in <ref type="table" target="#tab_2">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Improving Full-and Few-Supervision</head><p>Full-supervision. We verify our method using the full Cityscapes train set (? 2, 975 images) and randomly sample 3, 000 images from the Cityscapes coarse set as the unlabeled set. For the unlabeled set, we do not use their coarsely annotated ground truth. <ref type="figure">Figure 3</ref> illustrates the results on the Cityscapes val set with single-scale evaluation.</p><p>We can see that even with a large amount of labeled data, our approach could still benefit from training with unlabeled data, and our approach also works well on the state-of-theart segmentation network HRNet.</p><p>Few-supervision. We study the performance of our method on PASCAL VOC 2012 with very few supervision by  <ref type="figure">Figure 3</ref>: Improving the fully-supervised baselines. The baseline models (DeepLabv3+ with ResNet-101 and HRNet-W48) are trained using the full Cityscapes train set. Our approach uses ? 3, 000 images from Cityscapes coarse set as an additional unlabeled set for training. The superiority of our approach implies that our approach works well on the relatively large labeled data.</p><p>following the same partition protocols adopted in Pseu-doSeg <ref type="bibr" target="#b44">[44]</ref>. PseudoSeg randomly samples 1/2, 1/4, 1/8, and 1/16 of images in the standard training set (around 1.5k images) to construct the labeled set. The remaining images in the standard training set, together with the images in the augmented set <ref type="bibr" target="#b11">[12]</ref> (around 9k images), are used as the unlabeled set. We only report the results of our approach w/ CutMix augmentation as CutMix is important for few supervision. Results are listed in <ref type="table">Table 5</ref>, where all methods use ResNet-101 as the backbone except CCT that uses ResNet-50. We can see that our approach performs the best and is supe- <ref type="table">Table 4</ref>: Ablation study of different loss combinations on PASCAL VOC 2012 and Cityscapes. The results are obtained under the 1/8 data partition protocol and the observations are consistent for other partition protocols. Ls represents the supervision loss on the labeled set. L l cps (L u cps ) represents the cross pseudo supervision loss on the labeled (unlabeled) set. L l cpc (L u cpc ) represents the cross probability consistency loss on the labeled (unlabeled) set. The overall performance with the cross pseudo supervision loss on both the labeled and unlabeled data is the best.  <ref type="table">Table 5</ref>: Comparison for few-supervision on PASCAL VOC 2012. We follow the same partition protocols provided in Pseu-doSeg <ref type="bibr" target="#b44">[44]</ref>. The results of all the other methods are from <ref type="bibr" target="#b44">[44]</ref>.  rior to CutMix-Seg again on the few labeled case. Our approach is also better than PseudoSeg that uses a complicated scheme to compute the pseudo segmentation map. We believe that the reason comes from that our approach uses network perturbation and cross pseudo supervision while Pseu-doSeg uses a single network with input perturbation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Empirical Study</head><p>Cross pseudo supervision. We investigate the influence of applying the proposed cross pseudo supervision loss to labeled set (L l cps ) or unlabeled set (L u cps ) in the <ref type="table">Table 4</ref>. We can see that cross pseudo supervision loss on the unlabeled set brings more significant improvements than cross pseudo supervision loss on the labeled set in most cases. For example, with ResNet-50, cross pseudo supervision loss on the labeled set improves the performance of the baseline by 0.56% (1.41%) while cross pseudo supervision loss on the unlabeled set improves by 3.57% (4.07%) on PAS-CAL VOC 2012 (Cityscapes). The performance with cross pseudo supervision loss on both labeled set and unlabeled set is overall the best.</p><p>Comparison with cross probability consistency. We compare our method with the cross probability consistency on the last 2 rows of <ref type="table">Table 4</ref>. We can see that our cross pseudo supervision outperforms the cross probability consistency on both benchmarks. For example, on Cityscapes, cross pseudo supervision outperforms cross probability consistency by 2.36% (1.94%) when applied to both labeled and unlabeled sets with ResNet-50 (ResNet-101).</p><p>The trade-off weight ?. We investigate the influence of different ? that is used to balance the supervision loss and cross pseudo supervision loss as shown in Equation 6. From <ref type="figure" target="#fig_3">Figure 4</ref>, we can see that ? = 1.5 performs best on PASCAL VOC 2012 and ? = 6 performs best on Cityscapes. We use ? = 1.5 and ? = 6 in our approach for all the experiments.</p><p>Single-network pseudo supervision vs. cross pseudo supervision. We compare the proposed approach with singlenetwork pseudo supervision in <ref type="table" target="#tab_5">Table 6</ref>. We can see that our method outperforms the single-network pseudo supervision scheme either with CutMix augmentation or not. The single-network pseudo supervision with the CutMix augmentation is similar to the application of FixMatch <ref type="bibr" target="#b27">[28]</ref> to semantic segmentation (as done in PseudoSeg). We think that this is one of the main reason that our approach is superior to PseudoSeg.</p><p>Combination/comparison with self-training. We empirically study the combination of our method and the conventional self-training <ref type="bibr" target="#b34">[35]</ref>. Results on both benchmarks are summarized in <ref type="table" target="#tab_6">Table 7</ref>. We can see that the combination of self-training and our approach outperforms both our method only and self-training only. The superiority implies that our approach is complementary to self-training. As the self-training scheme consists of multiple stages (train over labeled set ? predict pseudo labels for unlabeled set ? retrain over labeled and unlabeled set with pseudo labels), it takes more training epochs than our approach. For a fairer comparison with self-training, we train our method for more epochs (denoted as Ours + ) to ensure our training epochs are also comparable with self-training. According to the results shown in <ref type="figure">Figure 5</ref>, we can see that ours + consistently outperforms self-training under various partition protocols. We guess that the reason lies in the consistency regularization in our approach. <ref type="figure" target="#fig_4">Figure 6</ref> visualizes some segmentation results on PAS-CAL VOC 2012. We can see the supervised baseline, shown in the <ref type="figure" target="#fig_4">Figure 6</ref> column (c), mis-classifies many pixels due to limited labeled training samples. For example, in the 1-st row, the supervised only method (column (c)) mistakenly classifies many cow pixels as horse pixels while our method w/o CutMix augmentation (column (d)) fixes these errors. In the 2-nd row, both the supervised baseline and our method w/o CutMix augmentation, mislabel some dog pixels as horse pixels while our method w/ CutMix augmentation (column (e)) successfully corrects these errors.  <ref type="figure">Figure 5</ref>: Comparison with self-training on PASCAL VOC 2012. The self-training approach is a two-stage approach which takes more training epochs. For a fair comparison, we train our approach with more training epochs (denoted by 'Ours + ) so that their epochs are comparable. The CutMix augmentation is not used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Qualitative Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>We present a simple but effective semi-supervised segmentation approach, cross pseudo supervision. Our approach imposes the consistency between two networks with the same structure and different initialization, by using the one-hot pseudo segmentation map obtained from one network to supervise the other network. On the other hand, the unlabeled data with pseudo segmentation map, which is more accurate in the later training stage, serves as expanding the training data to improve the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. More Implementation Details</head><p>Training details. The crop size for PASCAL VOC 2012 and Cityscapes are 512 ? 512 and 800 ? 800, respectively. For the multi-scale data augmentation, we randomly select scale from {0.5, 0.75, 1, 1.25, 1.5, 1.75}. For Cityscapes dataset, we use OHEM loss as the supervision loss (L s ), and cross entropy loss as the cross pseudo supervision loss (L cps ).</p><p>Training strategy. We use the similar training strategy as GCT <ref type="bibr" target="#b16">[17]</ref> for semi-supervised segmentation. In the supervised baseline for all the partition protocols, we use the batch size 8. We ensure that the iteration number is the same as semi-supervised methods 2 . For semi-supervised methods, at each iteration, we sample additional 8 unlabeled samples. Our method and all the other semi-supervised methods in <ref type="table" target="#tab_0">Table 1</ref> and <ref type="table" target="#tab_1">Table 2</ref> of the main paper follow the same training strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Network Perturbation</head><p>Our cross pseudo supervision approach (CPS) includes two perturbed segmentation networks, f (? 1 ) and f (? 2 ), which are of the same architecture and initialized differently. In the main paper, we pointed out that the pseudo segmentation results from the two networks are perturbed.</p><p>We empirically show the perturbation using the overlap ratio between them during training. The overlap ratio on the labeled set, the unlabeled set and the whole set are given in <ref type="figure" target="#fig_5">Figure 7</ref>. We can see that (1) the overlap ratio is small at the early training stage and (2) increases during the later training stage. The small overlap ratio at the early stage helps avoid the case the segmentation network converges towards a wrong direction. The large overlap ratio at the later stage implies that the pseudo segmentation results of the two segmentation networks are more accurate. We use DeepLabv3+ with ResNet-50 as the segmentation network. We only calculate the overlap ratio in the object region, and the pixels belong to the 'background' class are ignored.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>/o CutMix Aug.) Ours (w/o CutMix Aug.) Ours (w/ CutMix Aug.) Improvements over the supervised baseline on the Cityscapes val set with (a) ResNet-50 and (b) ResNet-101.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 (</head><label>2</label><figDesc>a) shows our method consistently outperforms the supervised baseline on Cityscapes with ResNet-50. Specifically, the improvements of our method w/o Cut-Mix augmentation over the baseline method w/o CutMix augmentation are 4.89%, 4.07%, 2.74%, and 2.42% under 1/16, 1/8, 1/4, and 1/2 partition protocols separately. Figure 2 (b) shows the gains of our method over the baseline method on Cityscapes with ResNet-101: 3.70%, 3.52%, 2.11%, and 2.02% under 1/16, 1/8, 1/4, and 1/2 partition protocols separately. Figure 2 also shows the improvements brought by the CutMix augmentation. We can see that CutMix brings more gains under the 1/16 and 1/8 partitions than under the 1/4 and 1/2 partitions. For example, on Cityscapes with ResNet-101, the extra gains brought by CutMix augmentation are 4.22%, 1.91%, and 0.13% under 1/16, 1/8, and 1/2 partition protocols separately.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Illustration on how the trade-off weight ? (x-axis) affects the mIoU score (y-axis) on PASCAL VOC 2012 (left) and Cityscapes (right). All results are evaluated under the 1/8 partition protocol.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Example qualitative results from PASCAL VOC 2012. (a) input, (b) ground truth, (c) supervised only, (d) ours (w/o CutMix Aug.), and (e) ours (w/ CutMix Aug.). All the approaches use DeepLabv3+ with ResNet-101 as the segmentation network.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Prediction overlap of the two networks on PASCAL VOC 2012 under the 1/8 partition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison with state-of-the-arts on the PASCAL VOC 2012 val set under different partition protocols. All the methods are based on DeepLabv3+.</figDesc><table><row><cell>Method</cell><cell>1/16 (662)</cell><cell cols="2">ResNet-50 1/8 (1323) 1/4 (2646)</cell><cell>1/2 (5291)</cell><cell>1/16 (662)</cell><cell cols="2">ResNet-101 1/8 (1323) 1/4 (2646)</cell><cell>1/2 (5291)</cell></row><row><cell>MT [32]</cell><cell>66.77</cell><cell>70.78</cell><cell>73.22</cell><cell>75.41</cell><cell>70.59</cell><cell>73.20</cell><cell>76.62</cell><cell>77.61</cell></row><row><cell>CCT [27]</cell><cell>65.22</cell><cell>70.87</cell><cell>73.43</cell><cell>74.75</cell><cell>67.94</cell><cell>73.00</cell><cell>76.17</cell><cell>77.56</cell></row><row><cell>CutMix-Seg [11]</cell><cell>68.90</cell><cell>70.70</cell><cell>72.46</cell><cell>74.49</cell><cell>72.56</cell><cell>72.69</cell><cell>74.25</cell><cell>75.89</cell></row><row><cell>GCT [17]</cell><cell>64.05</cell><cell>70.47</cell><cell>73.45</cell><cell>75.20</cell><cell>69.77</cell><cell>73.30</cell><cell>75.25</cell><cell>77.14</cell></row><row><cell>Ours (w/o CutMix Aug.)</cell><cell>68.21</cell><cell>73.20</cell><cell>74.24</cell><cell>75.91</cell><cell>72.18</cell><cell>75.83</cell><cell>77.55</cell><cell>78.64</cell></row><row><cell>Ours (w/ CutMix Aug.)</cell><cell>71.98</cell><cell>73.67</cell><cell>74.90</cell><cell>76.15</cell><cell>74.48</cell><cell>76.44</cell><cell>77.68</cell><cell>78.64</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison with state-of-the-arts on the Cityscapes val set under different partition protocols. All the methods are based on DeepLabv3+.</figDesc><table><row><cell>Method</cell><cell>1/16 (186)</cell><cell cols="2">ResNet-50 1/8 (372) 1/4 (744)</cell><cell>1/2 (1488)</cell><cell>1/16 (186)</cell><cell cols="2">ResNet-101 1/8 (372) 1/4 (744)</cell><cell>1/2 (1488)</cell></row><row><cell>MT [32]</cell><cell>66.14</cell><cell>72.03</cell><cell>74.47</cell><cell>77.43</cell><cell>68.08</cell><cell>73.71</cell><cell>76.53</cell><cell>78.59</cell></row><row><cell>CCT [27]</cell><cell>66.35</cell><cell>72.46</cell><cell>75.68</cell><cell>76.78</cell><cell>69.64</cell><cell>74.48</cell><cell>76.35</cell><cell>78.29</cell></row><row><cell>GCT [17]</cell><cell>65.81</cell><cell>71.33</cell><cell>75.30</cell><cell>77.09</cell><cell>66.90</cell><cell>72.96</cell><cell>76.45</cell><cell>78.58</cell></row><row><cell>Ours (w/o CutMix Aug.)</cell><cell>69.79</cell><cell>74.39</cell><cell>76.85</cell><cell>78.64</cell><cell>70.50</cell><cell>75.71</cell><cell>77.41</cell><cell>80.08</cell></row><row><cell>Ours (w/ CutMix Aug.)</cell><cell>74.47</cell><cell>76.61</cell><cell>77.83</cell><cell>78.77</cell><cell>74.72</cell><cell>77.62</cell><cell>79.21</cell><cell>80.21</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparison with state of the arts on the Cityscapes val set under different partition protocols using HRNet-W48.</figDesc><table><row><cell>Method</cell><cell cols="4">Cityscapes 1/16 (186) 1/8 (372) 1/4 (744) 1/2 (1488)</cell></row><row><cell>Base</cell><cell>66.90</cell><cell>72.79</cell><cell>75.23</cell><cell>78.09</cell></row><row><cell cols="2">Ours (w/o CutMix Aug.) 72.49</cell><cell>76.32</cell><cell>78.27</cell><cell>80.02</cell></row><row><cell>Ours (w/ CutMix Aug.)</cell><cell>75.09</cell><cell>77.92</cell><cell>79.24</cell><cell>80.67</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Comparison with single-network pseudo supervision on PASCAL VOC 2012 val. SPS = single-network pseudo supervision. All methods are based on DeepLabv3+ are with ResNet-50.</figDesc><table><row><cell cols="5">We can see that for both the two cases, w/ and w/o Cut-Mix augmentation, our approach outperforms the single-network pseudo supervision.</cell></row><row><cell>Method</cell><cell>1/16</cell><cell>1/8</cell><cell>1/4</cell><cell>1/2</cell></row><row><cell>SPS (w/o CutMix Aug.)</cell><cell>59.54</cell><cell>69.05</cell><cell>72.55</cell><cell>75.17</cell></row><row><cell cols="5">Ours (w/o CutMix Aug.) 68.21 73.20 74.24 75.91</cell></row><row><cell>SPS (w/ CutMix Aug.)</cell><cell>65.62</cell><cell>71.27</cell><cell>73.70</cell><cell>74.87</cell></row><row><cell>Ours (w/ CutMix Aug.)</cell><cell cols="4">71.98 73.67 74.90 76.15</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Combination with self-training. The CutMix augmentation is not used. We can see that the combination gets improves over both self-training and our approach.</figDesc><table><row><cell>Method</cell><cell cols="2">ResNet-50 1/4 1/2</cell><cell cols="2">ResNet-101 1/4 1/2</cell></row><row><cell>PASCAL VOC 2012</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ours</cell><cell>74.24</cell><cell>75.91</cell><cell>77.55</cell><cell>78.64</cell></row><row><cell>Self-Training</cell><cell>74.47</cell><cell>75.97</cell><cell>76.63</cell><cell>78.15</cell></row><row><cell>Ours + Self-Training</cell><cell>74.96</cell><cell>76.60</cell><cell>77.60</cell><cell>78.76</cell></row><row><cell>Cityscapes</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ours</cell><cell>76.85</cell><cell>78.64</cell><cell>77.41</cell><cell>80.08</cell></row><row><cell>Self-Training</cell><cell>75.88</cell><cell>77.64</cell><cell>77.55</cell><cell>79.46</cell></row><row><cell>Ours + Self-Training</cell><cell>77.40</cell><cell>79.25</cell><cell>79.16</cell><cell>80.17</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use f (?) to represent f (X; ?) by dropping X for convenience.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In GCT<ref type="bibr" target="#b16">[17]</ref>, the supervised baseline uses the batch size 16, and the number of iterations is much smaller than half of the number of iterations in the semi-supervised methods. Therefore, their supervised baseline results are worse than ours (we sure the same number of iterations and each iteration has the same number, 8, of labeled samples).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning with a probabilistic teacher</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ashok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Agrawala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="373" to="379" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5049" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<title level="m">Semi-Supervised Learning</title>
		<editor>Olivier Chapelle, Bernhard Sch?lkopf, and Alexander Zien</editor>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Naive-student: Leveraging semi-supervised learning in video sequences for urban scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cubuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hartwig Adam Barret Zoph, and Jonathon Shlens</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>ECCV</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The pascal visual object classes challenge: A retrospective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="136" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Semi-supervised semantic segmentation via dynamic self-training and classbalanced curriculum. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangliang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhuang</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning to recognize patterns without a teacher</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fralick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="64" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation needs strong, high-dimensional perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Finlayson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Semantic contours from inverse detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Arbel?ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 International Conference on Computer Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="991" to="998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Adversarial learning for semisupervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Chih</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Hsuan</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan-Ting</forename><surname>Liou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic image segmentation with self-correcting networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mostafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Ibrahim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mani</forename><surname>Vahdat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">G</forename><surname>Ranjbar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macready</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="12715" to="12725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Probability of error of some adaptive pattern-recognition machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Scudder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="363" to="371" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Guided collaborative training for pixel-wise semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanghan</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaican</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rynson Wh</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dual student: Breaking the limits of the teacher in semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanghan</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daoye</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rynson Wh</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6728" to="6736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Structured consistency loss for semi-supervised semantic segmentation. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongmok</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jooyoung</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunwoo</forename><surname>Park</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Kaiming He, and Ross Girshick. Pointrend: Image segmentation as rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="9799" to="9808" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICLR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICMLW</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Jo?o Paulo Papa, and Christoph Palm. Semi-supervised segmentation based on error-correcting supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Mendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Antonio De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rauber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="141" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Semi-supervised semantic segmentation with high-and lowlevel consistency. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudhanshu</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Tatarchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1908" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning. TPAMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shin</forename><surname>Shin-Ichi Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koyama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semisupervised semantic segmentation with cross-consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yassine</forename><surname>Ouali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C?line</forename><surname>Hudelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myriam</forename><surname>Tami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semisupervised learning with consistency and confidence. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semi supervised semantic segmentation using generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasim</forename><surname>Souly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Concetto</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5688" to="5696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5693" to="5703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Gated-scnn: Gated shape cnns for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Towaki</forename><surname>Takikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Acuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5229" to="5238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaorui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Self-training with noisy student improves imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10687" to="10698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Multi-scale context aggregation by dilated convolutions. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Objectcontextual representations for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.11065</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Ocnet: Object context network for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.00916</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Segfix: Model-agnostic boundary refinement for segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="489" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Improving semantic segmentation via self-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongruo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Corr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Rethinking pre-training and self-training. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Pseudoseg: Designing pseudo labels for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Bian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.09713</idno>
	</analytic>
	<monogr>
		<title level="m">Jia-Bin Huang, and Tomas Pfister</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
