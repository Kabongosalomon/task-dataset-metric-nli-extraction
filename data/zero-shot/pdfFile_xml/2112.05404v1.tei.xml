<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">THE LARGE LABELLED LOGO DATASET (L3D): A MULTIPURPOSE AND HAND-LABELLED CONTINUOUSLY GROWING DATASET</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-12-13">December 13, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asier</forename><surname>Guti?rrez-Fandi?o</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Barcelona Supercomputing Center</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>P?rez-Fern?ndez</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad Aut?noma de Madrid</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordi</forename><surname>Armengol-Estap?</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Barcelona Supercomputing Center</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">THE LARGE LABELLED LOGO DATASET (L3D): A MULTIPURPOSE AND HAND-LABELLED CONTINUOUSLY GROWING DATASET</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-12-13">December 13, 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.5281/zenodo.5771006</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we present the Large Labelled Logo Dataset (L3D), a multipurpose, hand-labelled, continuously growing dataset. It is composed of around 770k of color 256x256 RGB images extracted from the European Union Intellectual Property Office (EUIPO) open registry. Each of them is associated to multiple labels that classify the figurative and textual elements that appear in the images. These annotations have been classified by the EUIPO evaluators using the Vienna classification, a hierarchical classification of figurative marks. We suggest two direct applications of this dataset, namely, logo classification and logo generation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Having large labelled datasets is of the uttermost importance for building deep learning applications. The importance of annotated datasets for the advancement of machine learning is unquestionable. Annotated datasets are needed to understand the complexity of human perception and knowledge acquisition. Thanks to the efforts of many researchers, Deep Learning has large and varied datasets. Datasets such as MNIST or CIFAR are at the basis of definitive advances in automated image recognition. It is important that these datasets represent real cases, their contents are sufficiently refined and the amount of data is representative in variety and quantity of data.</p><p>The data set collected corresponds to 0.7M images obtained from the EUIPO trademark register. When a company or individual registers in the EUIPO a logo associated with a company, product or service, the registration is made by standardizing the image used and associating multiple labels describing the figurative elements contained in the image. The objective of the EUIPO evaluators is to verify that no new registration of a logo already exists in the image database nor any of its elements.</p><p>To do so, the human staff use multiple tags for each image following the Vienna Classification: https://www. wipo.int/classifications/vienna/en/ The Vienna Classification of Classification (VCL), whose latest version 9, which is mandatory as of January 1, 2023, can be viewed here: https://www.wipo.int/classifications/ nivilo/vienna.htm is composed of 29 categories organized in a structure of 3 hierarchical levels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There is a wide variety of large image datasets suitable for Deep Learning. The well-known MNIST (LeCun and Cortes, 2010), CIFAR <ref type="bibr" target="#b3">(Krizhevsky, 2009)</ref> and Imagenet <ref type="bibr" target="#b2">(Deng et al., 2009</ref>) are on the hall of fame and are used as de facto sources for validating new Deep Learning architectures. These datasets started to be used for image classification tasks. However, as Deep Learning architectures unlocked additional capabilities, these datasets have been used for other tasks. At the time this was happening new datasets appeared.</p><p>Human perception is based on the understanding of objects and scenes. Multitude of applications, from the development of autonomous cars <ref type="bibr" target="#b0">(Chang et al., 2019;</ref><ref type="bibr" target="#b1">Cordts et al., 2016;</ref><ref type="bibr" target="#b8">Schafer et al., 2018;</ref><ref type="bibr" target="#b10">Yu et al., 2020)</ref>, digitizing text using arXiv:2112.05404v1 [cs.CV] 10 Dec 2021 optical character recognition (OCR) systems, improving video game graphics <ref type="bibr" target="#b7">(Richter et al., 2021)</ref>, transforming drawings to images <ref type="bibr" target="#b5">(Park et al., 2019)</ref> to transferring drawing style <ref type="bibr" target="#b5">(Li et al., 2018)</ref>.</p><p>The most recent datasets and, in turn, most closely linked to human perception are those of DALL-E <ref type="bibr" target="#b6">(Ramesh et al., 2021)</ref> and those being developed by EleutherAI. Both datasets, from the network images and their descriptions, train a text-to-image model.</p><p>The dataset presented in this article consists of digital figurative images created by humans, projecting shapes and objects, according to the human perception of them. In many cases it is an artistic or synthetic view of the figurative elements that compose it. In addition, this data set is rigorously labeled with multiple tags that have a very detailed granularity organized in a hierarchical fashion. Since images may contain text, it also includes the text that is present in the image.</p><p>A very interesting work on how application of supervised learning algorithms in order to automate the manual process of labeling trademark images with Vienna codes can be found in <ref type="bibr" target="#b9">Uzairi (2021)</ref>. This work compares different deep learning algorithms, namely, CNN, recurrent neural networks (LSTMs and GRUs), Support Vector Machines, Decision Trees, Random Forests and Naive Bayes models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">L3D Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">General dataset description</head><p>The European Union Intellectual Property Office (EUIPO), founded in 1994, is the European Union Agency responsible for the registration of the European Union trade mark and the registered Community design, two unitary intellectual property rights valid across the 27 Member States of the EU. The EUIPO stores all the information from trademarks filled at the European Union and distributes them in order to avoid the creation of similar trademarks.</p><p>The EUIPO creates monthly incremental versions of the current year and once the year has passed, creates a final version of that year. In our work we selected images until 2020 for simplicity. However, we encourage researchers parameterizing the download to obtain next years.</p><p>EUIPO's Open Data Platform is a tool to make all the trade mark and design information available and transparent to its users, with quick and efficient access. A new application makes the Register available to the general public for bulk download. 1 EUIPO started in 1998 making its trade mark database available online to firms and national Industrial Property offices under a license contract. Now EUIPO is opening their databases to all users, free of charge, updated daily and without requiring a license. 2</p><p>In order to browse the contents of the database in a user-friendly way, the EUIPO has a trademark viewer web-client. 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Vienna classification</head><p>Images Contained in this database are classified using the Vienna Classification (International Classification of the Figurative Elements of Marks) 4 . Vienna Classification (VCL) is an international classification system used to classify the figurative elements of logos or images registered by companies (company, product or services registered trademarks).</p><p>The Vienna Classification of figurative elements was agreed by the World Intellectual Property Organization (WIPO) in the so-called Vienna Agreement on June 12, 1973, and came into force on August 9, 1985. The use of the Vienna Classification by national industrial property offices is intended to facilitate the registration of trademarks containing figurative elements by coding them according to a single classification system at the international level. This facilitates the search for similar images of other registered trademarks and avoids having to reclassify images when they are registered in multiple industrial property offices at the international level.</p><p>The International Bureau of WIPO also applies the Vienna Classification in the framework of the Madrid System for the international registration of marks. Around 60 offices in the world apply the Vienna Classification. In addition, three regional organizations, namely the African Regional Intellectual Property Organization (ARIPO), the Benelux The VCL is a hierarchical system classifying all figurative elements into 29 categories, further divided into divisions and sections. Additional information can be found at WIPO VCL site 5 . <ref type="table">Table 3</ref>.2 shows the categories of the VCL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Dataset Download &amp; Preparation</head><p>We make freely available the scripts to download and build the dataset 6 as well as the link to download it directly. 7 Each script is modular and is supposed to be adapted to the different needs researchers might have. The pipeline proceeds as follows.</p><p>1. Download: connect to the EUIPO's FTP server and download the files.</p><p>1 9 9 6 1 9 9 7 1 9 9 8 1 9 9 9 2 0 0 0 2 0 0 1 2 0 0 2 2 0 0 3 2 0 0 4 2 0 0 5 2 0 0 6 2 0 0 7 2 0 0 8 2 0 0 9 2 0 1 0 2 0 1 1 2 0 1 2 2 0 1 3 2 0 1 4 2 0 1 5 2 0 1 6 2 0 1 7 2 0 1 8 2 0 1 9 2 0 2 0 Years Trademark count by year 2. Process: previously downloaded files are unziped. Extracted images are renamed as UUIDv4 and their metadata is written into a file. Metadata includes the text contained in the image, the label associated to it and the date of the trademark. 3. Statistics: compute statistics to obtain number of images, minimum image size, maximum image size, standard deviation of image size and mean image size. 4. Filter: remove invalid images (i.e. corrupted images) and too small images whose width or height is less than 20 pixels. 5. Fix (image): transform the TIFF to JPG, rename the images to JPG and set images in fixed sizes of 256 ? 256 and rename. 6. Fix (metadata): remove metadata of the invalid images. 7. Clean: Remove invalid images.</p><p>The dataset will consist of 256 images. Note that the total storage requirements are more than 256 GB as of December 2021. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Statistics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Labelling</head><p>The Vienna Classification is an international classification system used to classify the figurative elements of marks. The complete title of the Classification is International Classification of the Figurative Elements of Marks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Applications</head><p>We foresee several potential applications of this dataset:</p><p>1. Unconditional trademark generation. 1 2 3 4 5 6 7 8 9 1 0 1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 2 0 2 1 2 2 2 3 2 4 2 5 2 7 2 9 3 1 3 2 3 5 3 8 5 3 Assignment </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Baselines</head><p>In this section, we describe the baselines we built for two of the applications we mentioned, namely, logo generation and multi-label logo classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Trademark Generation</head><p>Awaiting results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Multi-Label Classification</head><p>We apply a neural architecture search algorithm out of the box to learn multi-label classification using Vienna categories. Specifically, a 20-layer pretrained NASNET <ref type="bibr" target="#b11">(Zoph et al., 2017)</ref>, training half of its layers. We obtain an accuracy of 0.1155 in the level 3 of the hierarchy and an accuracy of 0.2786 in the level 2, showing the difficulty of the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions &amp; Future Work</head><p>The dataset presented in this paper is a continuously growing dataset of figurative images that is manually annotated.</p><p>This dataset can be used to generate systems that proceed in the artistic generation of logos in the same way as humans do, or to develop systems that understand the abstract artistic capacity of humans.</p><p>We provided simple baselines for two tasks. We expect that the scientific community will creatively contribute new ways to use this dataset either as a benchmark or to develop downstream applications.</p><p>As future work, we suggest 1. extending the dataset with information from other offices (see WIPO), 2. segmenting the images according to their figurative marks and textual elements to conform two separate datasets ("pure" images and logos), 3. applying the dataset to other tasks (such as OCR), 4. aligning Vienna classification with other existing classifications (e.g., CIFAR), and 5. Outperforming the discriminative and generative baselines we provided.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>4 shows the trademark count by year, while Figure 3.5 shows the trademark assignment by category. The dataset is clearly imbalanced.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://euipo.europa.eu/ohimportal/en/open-data 2 https://euipo.europa.eu/ohimportal/en/news?p_p_id=csnews_WAR_csnewsportlet&amp;p_p_lifecycle=0&amp;p_p_ state=normal&amp;p_p_mode=view&amp;p_p_col_id=column-1&amp;p_p_col_count=2&amp;journalId=3584337&amp;journalRelatedId= manual/ 3 https://www.tmdn.org/tmview/ 4 https://www.wipo.int/classifications/vienna/en/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://www.wipo.int/classifications/vienna/en/ 6 https://github.com/lhf-labs/tm-dataset 7 https://doi.org/10.5281/zenodo.5771006</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Argoverse: 3d tracking and forecasting with rich maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sangkloy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hartnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<title level="m">MNIST handwritten digit database</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning linear transformations for fast arbitrary style transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Semantic image synthesis with spatially-adaptive normalization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Zero-shot text-to-image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavlov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Alhaija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.04619</idno>
		<title level="m">Enhancing photorealism enhancement</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schafer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Santana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Haden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Biasini</surname></persName>
		</author>
		<title level="m">A commute in data: The comma2k19 dataset</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deep learning for identification of figurative elements in trademark images using vienna codes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Uzairi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
		<respStmt>
			<orgName>Linnaeus University, Department of computer science and media technology (CM</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Bdd100k: A diverse driving dataset for heterogeneous multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Madhavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno>abs/1707.07012</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
