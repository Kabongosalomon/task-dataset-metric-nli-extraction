<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting CCS CONCEPTS ? Information systems ? Data mining. KEYWORDS multivariate time series forecasting, spatial-temporal graph neural network, pre-training model ACM Reference Format</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>August 14-18, 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zezhi</forename><surname>Shao</surname></persName>
							<email>shaozezhi19b@ict.ac.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Zhang</surname></persName>
							<email>zhangzhao2021@ict.ac.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
							<email>wangfei@ict.ac.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zezhi</forename><surname>Shao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Xu</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute of Computing Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computing Technology, Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Institute of Computing Technology, Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Institute of Computing Technology, Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Pre-training Enhanced Spatial-temporal Graph Neural Network for Multivariate Time Series Forecasting CCS CONCEPTS ? Information systems ? Data mining. KEYWORDS multivariate time series forecasting, spatial-temporal graph neural network, pre-training model ACM Reference Format</title>
					</analytic>
					<monogr>
						<title level="j" type="main">KDD</title>
						<meeting> <address><addrLine>Washington, DC, USA</addrLine></address>
						</meeting>
						<imprint>
							<biblScope unit="volume">22</biblScope>
							<date type="published">August 14-18, 2022</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3534678.3539396</idno>
					<note>. 2022. Pre-training En-hanced Spatial-temporal Graph Neural Network for Multivariate Time Se-ries Forecasting. In Proceedings of the 28th ACM SIGKDD Conference on * Corresponding author. This work is licensed under a Creative Commons Attribution International 4.0 License.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T11:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multivariate Time Series (MTS) forecasting plays a vital role in a wide range of applications. Recently, Spatial-Temporal Graph Neural Networks (STGNNs) have become increasingly popular MTS forecasting methods. STGNNs jointly model the spatial and temporal patterns of MTS through graph neural networks and sequential models, significantly improving the prediction accuracy. But limited by model complexity, most STGNNs only consider short-term historical MTS data, such as data over the past one hour. However, the patterns of time series and the dependencies between them (i.e., the temporal and spatial patterns) need to be analyzed based on long-term historical MTS data. To address this issue, we propose a novel framework, in which STGNN is Enhanced by a scalable time series Pre-training model (STEP). Specifically, we design a pre-training model to efficiently learn temporal patterns from very long-term history time series (e.g., the past two weeks) and generate segment-level representations. These representations provide contextual information for short-term time series input to STGNNs and facilitate modeling dependencies between time series. Experiments on three public real-world datasets demonstrate that our framework is capable of significantly enhancing downstream STGNNs, and our pre-training model aptly captures temporal patterns. (a) Traffic flow over 9 days in PeMS04 datasets. (b) Similar traffic trend in different context. (c) Different traffic trend between similar series.</p><p>Figure 1: Examples of traffic flow multivariate time series data. (a) The two time series exhibit complex temporal patterns and strong spatial correlations. (b) Similar traffic trends within small windows in different contexts. (c) Different traffic trends within a small window between two similar series.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Multivariate time series data is ubiquitous in our lives, from transportation and energy to economics. It contains time series from multiple interlinked variables. Predicting future trends based on historical observations is of great value in helping to make better decisions. Thus, multivariate time series forecasting has remained an enduring research topic in both academia and industry for decades.</p><p>Indeed, multivariate time series can be generally formalized as spatial-temporal graph data <ref type="bibr" target="#b35">[36]</ref>. On the one hand, multivariate time series have complex temporal patterns, e.g., multiple periodicities. On the other hand, different time series can affect other's evolutionary processes because of the underlying interdependencies between variables, which is non-Euclidean and is reasonably modeled by the graph structure. To illustrate, we take the traffic flow system as an example, where each sensor corresponds to a variable. <ref type="figure">Figure 1</ref>(a) depicts the traffic flow time series generated from two sensors deployed on the road network. Apparently, there are two repeating temporal patterns, i.e., daily and weekly periodicities. The morning/evening peaks occur every day, while the weekdays and weekends exhibit different patterns. Furthermore, the two time series share very similar trends because the selected sensors 20 and 301 are closely connected in the traffic network. Consequently, accurate time series forecasting depends not only on the pattern of its temporal dimension but also on its interlinked time series. Besides, it is worth noting that we made the above analysis on the basis of observing a sufficiently long time series.</p><p>To make accurate predictions, Spatial-Temporal Graph Neural Networks (STGNNs) have attracted increasing attention recently. STGNNs combine Graph Neural Networks (GNNs) <ref type="bibr" target="#b17">[18]</ref> and sequential models. The former is used to deal with the dependencies between time series, and the latter is used to learn the temporal patterns. Benefitting from jointly modeling the spatial and temporal patterns, STGNNs have achieved state-of-the-art performance. In addition, an increasing number of recent works are further exploring the joint learning of graph structures and STGNNs since the dependency graph between time series, which is handcrafted by prior knowledge, is often biased and incorrect, even missing in many cases. In short, spatial-temporal graph neural networks have made significant progress for multivariate time series forecasting in many real-world applications. However, there is no free lunch. More powerful models require more complex structures. The computational complexity usually increases linearly or quadratically with the length of the input time series. Further considering the number of time series (e.g., hundreds), it is not easy for STGNNs to scale to very long-term historical time series. In fact, most models use historical data in a small window to make predictions, e.g., use the past twelve time steps (one hour) to predict the future twelve time steps <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b40">41]</ref>. The inability to explicitly learn from long-term information brings up some intuitive concerns.</p><p>Firstly, the STGNN model is blind to the context information beyond the window. Considering that time series are usually noisy, it may be difficult for the model to distinguish short-term time series in different contexts. For example, when observing data within two small windows of length twelve shown in <ref type="figure">Figure 1</ref>(b), we find that the two time series in different contexts are similar. Therefore, it is difficult for models to make accurate predictions about their different future trends based on limited historical data. Secondly, short-term information is unreliable for modeling the dependency graph, which is represented by the similarity (or correlation) between time series. As shown in <ref type="figure">Figure 1</ref>(c), the two time series are not similar when we observe data within the small window, neither in number nor in trend. On the contrary, long-term historical time series are beneficial for resisting noise, which facilitates obtaining more robust and accurate dependencies. Although long-term historical information is beneficial, as mentioned above, it is expensive for the STGNNs to scale to very long-term historical time series directly. Furthermore, the optimization of the model can also become problematic as the length of the input sequence increases.</p><p>To address these challenges, we propose a novel framework, in which STGNN is Enhanced by a scalable time series Pre-training model (STEP). The pre-training model aims to efficiently learn the temporal patterns from very long-term historical time series and generate segment-level representations, which contain rich contextual information that is beneficial to address the first challenge.</p><p>In addition, the learned representations of these segments (i.e., the short-term time series) are able to incorporate the information from the whole long historical time series to calculate the correlation between time series, thus solving the second challenge, the problem of missing the dependency graph. Specifically, we design an efficient unsupervised pre-training model for Time Series based on TransFormer blocks <ref type="bibr" target="#b32">[33]</ref> (TSFormer), which is trained through the masked autoencoding strategy <ref type="bibr" target="#b12">[13]</ref>. TSFormer efficiently captures information over very long-term historical data over weeks, and produces segment-level representations that correctly reflect complex patterns in time series. Second, we design a graph structure learner based on the representation of TSFormer, which learns discrete dependency graph and utilizes the NN graph computed based on the representation of TSFormer as a regularization to guide the joint training of graph structure and STGNN. Notably, STEP is a general framework that can extend to almost arbitrary STGNNs. In summary, the main contributions are the following:</p><p>? We propose a novel framework for multivariate time series forecasting, where the STGNN is enhanced by a pretraining model. Specifically, the pre-training model generates segment-level representations that contain contextual information to improve the downstream models. ? We design an efficient unsupervised pre-training model for time series based on Transformer blocks and train it by the masked autoencoding strategy. Furthermore, we design a graph structure learner for learning the dependency graph. ? Experimental results on three real-world datasets show that our method can significantly enhance the performance of downstream STGNNs, and our pre-training model aptly captures temporal patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>We first define the concept of multivariate time series, the dependency graph. Then, we define the forecasting problem addressed. Definition 1. Multivariate Time Series. A multivariate time series has multiple time-dependent variable, such as observations from multiple sensors. It can be denoted as a tensor X ? R ? ? , where is the number of time steps, is the number of variables, e.g., the sensors, and is the number of channels. We additionaly denote the data of time series as S ? R ? . Definition 2. Dependency Graph. Each variable depends not only on its past values but also on other variables. Such dependencies are captured by a dependency graph G = ( , ), where is the set of | | = nodes, and each node corresponds to a variable, e.g., a sensor.</p><p>is the set of | | = edges. The graph can also be denoted as an adjacent matrix A ? R ? . Definition 3. Multivariate Time Series Forecasting. Given historical signals X ? R ? ? ? from the past ? time steps, multivariate time series forecasting aims to predict the values Y ? R ? ? of the nearest future time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MODEL ARCHITECTURE</head><p>As shown in <ref type="figure">Figure 2</ref>, STEP has two stages: the pre-training stage and the forecasting stage. In the pre-training stage, we design a masked autoencoding model for Time Series based on TransFormer  <ref type="figure">Figure 2</ref>: The overview of the proposed STEP framework. Left: the pre-training stage. We split very long-term time series into segments and feed them into TSFormer, which is trained via the masked autoencoding strategy. Right: the forecasting stage. We enhance the downstream STGNN based on the segment-level representations of the pre-trained TSFormer.</p><formula xml:id="formula_0">S i P S i 1 S i 2 ? Graph Structure Learning Spatial-Temporal Graph Neural Network A H i P S i P H i? S i P S i P? 2 S i 1 S i 3</formula><p>blocks (TSFormer) to efficiently learn temporal patterns. TSFormer is capable of learning from the very long-term sequence and gives segment-level representations that contain rich context information.</p><p>In the forecasting stage, we use the pre-trained encoder to provide context information to enhance the downstream STGNN. Furthermore, based on the representations of the pre-training model, we further design a discrete and sparse graph learner to deal with the cases that the pre-defined graph is missing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The Pre-training Stage</head><p>In this part, we aim at designing an efficient unsupervised pretraining model for time series. While the pre-training model has made significant progress in natural language processing <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b26">27]</ref>, progress in time series lags behind them. First, we would like to discuss the difference between time series and natural language, which will motivate the design of TSFormer. We attempt to distinguish them from the following two perspectives:</p><p>(i) Time series information density is lower. As humangenerated signals, each data point in natural language (i.e., a word in a sentence) has rich semantics and is suitable as the data unit for model input. On the contrary, isolated data points in time series give less semantic information. Semantics only arise when we observe at least segment-level data, such as going up or down. On the other hand, language models are usually trained by predicting only a few missing words per sentence. However, masked values in time series can often be trivially predicted by simple interpolation <ref type="bibr" target="#b38">[39]</ref>, making the pre-training model only focuses on low-level information. To address this problem, a simple strategy that works well is to mask a very high portion of the model's input to encourage the learning of high-level semantics, motivated by recent development in computer vision <ref type="bibr" target="#b12">[13]</ref>. It creates a challenging self-supervised task that forces the model to obtain holistic understanding of time series.</p><p>(ii) Time series require longer sequences to learn the temporal patterns. In natural languages, sequences of hundreds of lengths have contained rich semantic information. Thus, language pre-training models usually cut or pad the input sequence to hundreds <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b26">27]</ref>. However, although time series have relatively more straightforward semantics than natural languages, they require longer sequences to learn it. For example, traffic system records data every five seconds, and if we want to learn the weekly periodicity, we need at least consecutive 2016 time slices. Although sampling at a lower frequency is a possible solution, it inevitably loses information. Fortunately, although longer time series will increase the model complexity, we can alleviate it by stacking fewer Transformer blocks and fix model parameters during the forecasting stage to reduce computational and memory overhead.</p><p>Motivated by the above analyses and recent computer vision models <ref type="bibr" target="#b8">[9]</ref>, especially Masked AutoEncoder (MAE) <ref type="bibr" target="#b12">[13]</ref>, we propose a masked autoencoding model for time series based on Transformer blocks (i.e., TSFormer). TSFormer reconstructs the original signal based on the given partial observed signals. We use an asymmetric design to largely reduce computation: the encoder operates on only partially visible signals, and the decoder uses a lightweight network on the full signals. The model is shown in <ref type="figure">Figure 2</ref>(left), and we will introduce each component in detail next. Masking. We divide the input sequence S from node into nonoverlapping patches of length (Input sequences are obtained over the original time series through a sliding window of length * ). The th patch can be denoted as S ? R , where is the input channel. We assume is the commonly used length of input time series of STGNNs. We randomly mask a subset of patches with masking ratio set to a high number of 75% to create a challenging self-supervised task. Here, we emphasize that the strategy of using patches as input units serves multiple purposes. Firstly, segments (i.e., patches) are more appropriate for explicitly providing semantics than separate points. Secondly, it facilitates the use of downstream models, as downstream STGNNs take a single segment as input. Last but not least, it significantly reduces the length of sequences input to the encoder, and the high masking ratio makes the encoder more efficient during the pre-training stage. Encoder. Our encoder is a series of Transformer blocks <ref type="bibr" target="#b32">[33]</ref> with an input embedding layer and a positional encoding layer. The encoder only operates on unmasked patches. As the semantics of time series are more straightforward than languages, we use four layers of Transformer blocks, far less than the depth of Transformer-based models in computer vision <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b12">13]</ref> and natural languages <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8]</ref>. Specifically, the input embedding layer is a linear projection to transform the unmasked patches into latent space:</p><formula xml:id="formula_1">U = W ? S + b,<label>(1)</label></formula><p>where W ? R ?( ) and b ? R are learnable parameters, U ? R are the model input vectors, and is the hidden dimension. For masked patches, we use a shared learnable mask token to indicate the presence of a missing patch to be predicted. Next, the positional encoding layer is used to add sequential information.</p><p>Notably, the positional encoding operates on all patches, although the mask tokens are not used in the encoder. Moreover, unlike the deterministic, sinusoidal embeddings used in MAE <ref type="bibr" target="#b12">[13]</ref>, we use learnable positional embeddings. On the one hand, in this work, learnable embeddings significantly outperform sinusoidal ones for all datasets. On the other hand, we observe that learned positional embeddings are crucial in learning time series' periodic features, which will be demonstrated in Section 4.3. Finally, we obtain the latent representations H ? R through Transformer blocks for all unmasked patches .</p><p>Decoder. The decoder is also a series of Transformer blocks that reconstruct the latent representations back to a lower semantic level, i.e., numerical information. The decoder operates on the full set of patches, including the mask tokens. Unlike MAE <ref type="bibr" target="#b12">[13]</ref>, we no longer add positional embeddings here since all patches already have positional information added in the encoder. Notably, the decoder is only used during the pre-training stage to perform the sequence reconstruction task, and can be designed independently of the encoder. We use only a single layer of Transformer block for balancing efficiency and effectiveness. Finally, we apply Multi-Layer Perceptions (MLPs) to make predictions whose number of output dimensions equals the length of each patch. Specifically, given the latent representation H ? R of patch , the decoder gives the reconstructed sequence? ? R . Reconstruction target. Our loss function compute mean absolute error between the original sequence S and reconstructed sequenc? S . Kindly note that we only compute loss over the masked patches, which is in line with other pre-training models <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13]</ref>. Moreover, all these operations are computed in parallel for all time series .</p><p>In summary, TSFormer is efficient thanks to the high masking ratio and fewer Transformer blocks. TSFormer is capable of learning from the very long-term sequence (e.g., weeks) and can be trained on a single GPU. The encoder generates representations for the input patches (segments). Furthermore, another noteworthy difference from MAE <ref type="bibr" target="#b12">[13]</ref> is that we pay more attention to the representations of the patches. On the one hand, we can use the representations to verify periodic patterns in the data, which will be demonstrated in Section 4.3. More importantly, they can conveniently act as contextual information for short-term input of downstream STGNNs, which will be introduced in the next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Forecasting Stage</head><p>For a given time series , TSFormer takes its historical signals S ? R ? of the past = ? time steps as input. We divide it into non-overlapping patches of length : S 1 , ? ? ? , S , where S ? R ? . The pre-trained TSFormer encoder generates representations H ? R for each S , where is the dimension of hidden states. Considering that the computational complexity usually increases linearly or quadratically with the length of the input time series, STGNNs can only take the latest, i.e., the last patch S ? R ? for each time series as input. For example, the most typical setting is = 12. In the forecasting stage, we aim at enhancing the STGNNs based on the representations of the pre-trained TSFormer encoder. Graph structure learning. Many STGNNs <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b40">41]</ref> depend on a pre-defined graph to indicate the relationship between nodes (i.e., time series). However, such a graph is not available or is incomplete in many cases. An intuitive idea is to train a matrix A ? R ? , where A ? [0, 1] indicates the dependency between time series and . However, since the learning of graph structure and STGNNs are coupled compactly, and there is no supervised loss information for graph structure learning <ref type="bibr" target="#b20">[21]</ref>, optimizing such a contiguous matrix usually leads to a complex bilevel optimization problem <ref type="bibr" target="#b9">[10]</ref>. In addition, the dependency A is usually measured by the similarity between time series, which is also a challenging task.</p><p>Fortunately, we can alleviate these problems based on the pretrained TSFormer. Motivated by recent works <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b28">29]</ref>, we aim to learn a discrete sparse graph, where ? parameterizes the Bernoulli distribution from which the discrete dependency graph A is sampled. First, we introduce graph regularization to provide supervised information for graph optimization based on the representations of TSFormer. Specifically, we denote</p><formula xml:id="formula_2">H = H 1 ? H 2 ...H ?1 ? H ?</formula><p>R as the feature of time series , where ? means the concatenation operation. Then we calculate a NN graph A among all the nodes. We can control the sparsity of the learned graph by setting different . Benefiting from the ability of TSFormer, A can reflect the dependencies between nodes, which is helpful to guide the training of the graph structure. Then, we compute ? as follows:</p><formula xml:id="formula_3">? = FC(relu(FC(Z ? Z ))) Z = relu(FC(H )) + G ,<label>(2)</label></formula><p>where ? ? R 2 is the unnormalized probability. The first dimension indicates the probability of positive, and the second dimension indicates the probability of negative. G is the global feature of time series , which is obtained by a convolutional network G = FC(vec(Conv(S ))), where S ? R is the entire sequence over training dataset, and is the length of the training dataset. S is static for all samples during training, helping to make the training process more robust and accurate. The feature H is dynamic for different training samples to reflect the dynamics of dependency graphs <ref type="bibr" target="#b18">[19]</ref>. As such, we use the cross-entropy between ? and the NN graph as graph structure regularization:</p><formula xml:id="formula_4">L ? = ?? ?A log ? ? ? (1 ? A ) log(1 ? ? ? ),<label>(3)</label></formula><p>where</p><formula xml:id="formula_5">? ? = softmax(? ) ? R is the normalized probability.</formula><p>The last problem of discrete graph structure learning is that the sampling operation from ? to adjacent matrix A is not differentiable. Hence, we apply the Gumbel-Softmax reparametrization trick proposed by <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b24">25]</ref>:</p><formula xml:id="formula_6">A = softmax((? + g)/ ),<label>(4)</label></formula><p>where g ? R 2 is a vector of i.i.d. samples drawn from a Gumbel(0,1) distribution. is the softmax temperature parameter. The Gumbel-Softmax converges to one-hot samples (i.e., discrete) when ? 0. Downstream spatial-temporal graph neural network. A normal downstream STGNN takes the last patch and the dependency graph as input, while the enhanced STGNN also considers the input patch's representation. Since the TSFormer has strong power at extracting very long-term dependencies, the representation H contains rich context information. STEP framework can extend to almost any STGNN, and we choose a representative method as our backend, the Graph WaveNet <ref type="bibr" target="#b35">[36]</ref>. Graph WaveNet captures spatial-temporal dependencies efficiently and effectively by combining graph convolution with dilated casual convolution. It makes predictions based on its output latent hidden representations H ? R ? ? by a regression layer, which is a Multi-Layer Perception (MLP). For brevity, we omit its details, and interested readers can refer to the paper <ref type="bibr" target="#b35">[36]</ref>. Denoting the representations H of TSFormer for all node as H ? R ? , we fuse the representations of Graph WaveNet and TSFormer by:</p><formula xml:id="formula_7">H = SP(H ) + H ,<label>(5)</label></formula><p>where SP(?) is the semantic projector to transform the H to the semantic space of H . We implement it with a MLP. Finally, we make predictions by the regression layer:? ? R ? ? . Given the ground truth Y ? R ? ? , we use mean absolute error as the regression loss:</p><formula xml:id="formula_8">L = L (?, Y) = 1 ?? =1 ?? =1 ?? =1 |? ? Y |,<label>(6)</label></formula><p>where is the number of nodes, is the number of forecasting steps, and is the dimensionality of the output. The downstream STGNN and the graph structure is trained in an end-to-end manner:</p><formula xml:id="formula_9">L = L + L ? .<label>(7)</label></formula><p>We set the graph regularization term gradually decay during the training process to go beyond the NN graph. Notably, the pretrained TSFormer encoder is fixed in the forecasting stage to reduce computational and memory overhead. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we present experiments on three real-world datasets to demonstrate the effectiveness of the proposed STEP and TS-Former. Furthermore, we conduct comprehensive experiments to evaluate the impact of important hyper-parameters and components. More experimental details, such as optimization settings and efficiency study, can be found in Appendix A, B, and C. It is notable that we conduct pre-training for each dataset since these datasets are heterogeneous in terms of length of time series, physical nature, and temporal patterns. Our code can be found in this repository 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>Datasets. Following previous works <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>, we conduct experiments on three commonly used multivariate time series datasets:</p><p>? METR-LA is a traffic speed dataset collected from loopdetectors located on the LA County road network <ref type="bibr" target="#b13">[14]</ref>. It contains data of 207 selected sensors over a period of 4 months from Mar to Jun in 2012 <ref type="bibr" target="#b19">[20]</ref>. The traffic information is recorded at the rate of every 5 minutes, and the total number of time slices is 34,272. ? PEMS-BAY is a traffic speed dataset collected from California Transportation Agencies (CalTrans) Performance Measurement System (PeMS) <ref type="bibr" target="#b4">[5]</ref>. It contains data of 325 sensors in the Bay Area over a period of 6 months from Jan 1st 2017 to May 31th 2017 <ref type="bibr" target="#b19">[20]</ref>. The traffic information is recorded at the rate of every 5 minutes, and the total number of time slices is 52,116. ? PEMS04 is a traffic flow dataset also collected from CalTrans PeMS <ref type="bibr" target="#b4">[5]</ref>. It contains data of 307 sensors in the Bay Area over a period of 2 months from Jan 1st 2018 to Feb 28th 2018 <ref type="bibr" target="#b10">[11]</ref>. The traffic information is recorded at the rate of every 5 minutes, and the total number of time slices is 16,992. The statistical information is summarized in <ref type="table" target="#tab_1">Table 1</ref>. For a fair comparison, we follow the dataset division in previous works. For METR-LA and PEMS-BAY, we use about 70% of data for training, 20% of data for testing, and the remaining 10% for validation <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b35">36]</ref>. For PEMS04, we use about 60% of data for training, 20% of data for testing, and the remaining 20% for validation <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>. Baselines. We select a wealth of baselines that have official public code. Historical Average (HA), VAR <ref type="bibr" target="#b22">[23]</ref>, and SVR <ref type="bibr" target="#b29">[30]</ref> are traditional methods. FC-LSTM <ref type="bibr" target="#b31">[32]</ref>, DCRNN <ref type="bibr" target="#b19">[20]</ref>, Graph WaveNet <ref type="bibr" target="#b35">[36]</ref>, ASTGCN <ref type="bibr" target="#b10">[11]</ref>, and STSGCN <ref type="bibr" target="#b30">[31]</ref> are typical deep learning methods. GMAN <ref type="bibr" target="#b40">[41]</ref>, MTGNN <ref type="bibr" target="#b34">[35]</ref>, and GTS <ref type="bibr" target="#b28">[29]</ref> are recent state-of-the-art works. More details of baselines can be found in Appendix A.1. Metrics. We evaluate the performances of all baselines by three commonly used metrics in multivariate time series forecasting, including Mean Absolute Error (MAE), Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE). Implementation. We set patch size to 12. We set the number of patches to 168 for METR-LA and PEMS-BAY, and 336 for PEMS04, i.e., we use historical information for a week for METR-LA and PEMS-BAY, and two weeks for PEMS04. We aim at forecasting the next 12 time steps. The masking ratio is set to 75%. The hidden dimension of the latent representations of TSFormer is set to 96. The TSFormer encoder uses 4 layer of Transformer blocks, and the decoder uses 1 layer. The number of attention heads in Transformer blocks is set to 4. The hyper-parameter of Graph WaveNet is set to default in their papers <ref type="bibr" target="#b35">[36]</ref>. For the NN graph A , we set to 10. We perform significance tests (t-test with p-value &lt; 0.05) over all the experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Main Results</head><p>As shown in <ref type="table" target="#tab_2">Table 2</ref>, our STEP framework consistently achieves the best performance in almost all horizons in all datasets, indicating the effectiveness of our framework. GTS and MTGNN jointly learn the graph structure among multiple time series and the spatialtemporal graph neural networks. GTS extends DCRNN by introducing a neighborhood graph as a regularization to improve graph quality and reformulates the problem as a unilevel optimization problem. MTGNN replaces the GNN and Gated TCN in Graph WaveNet with mix-hop propagation layer <ref type="bibr" target="#b0">[1]</ref> and dilated inception layer, and proposes to learn latent adjacency matrix to seek further improvement. However, they can not consistently outperform other baselines. Kindly note that the results of GTS may have some gaps with the original paper because it calculates the evaluation metrics in a slightly different manner. Some details can be found in the appendix in the original paper <ref type="bibr" target="#b28">[29]</ref> and similar issues in its official code repository 2 . We unify the evaluation process with other baselines, run GTS five times, and report its best performance. GMAN performs better in long-term prediction benefiting from the powerful ability of the attention mechanism in capturing long-term dependency. DCRNN and Graph WaveNet are two typical spatialtemporal graph neural networks. Even compared with many newer works such as ASTGCN and STSGCN, their performance is still very promising. This may be due to their refined and reasonable model architecture. FC-LSTM, a classic recurrent neural network, can not perform well since it only considers temporal features, ignoring the dependencies between time series. Other non-deep learning methods HA, VAR, and SVR perform worst since they have strong assumptions about the data, e.g., stationary or linear. Thus, they can not capture the strong nonlinear and dynamic spatial and temporal correlations in real-world datasets.</p><p>In a nutshell, STEP provides stable performance gains for Graph WaveNet by fully exploiting representations extracted by TSFormer from very long-term historical time series. However, despite the significant performance improvements, it is difficult for us to intuitively understand what TSFormer has learned and how it can help STGNNs. In the next subsection, we will inspect the TSFormer and demonstrate the learned multiple periodicities temporal pattern.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Inspecting The TSFormer</head><p>In this subsection, we would like to intuitively explore what TS-Former has learned. We conduct experiments on the PEMS04 dataset. Specifically, we randomly select a time series in the PEMS04 and then randomly choose a sample of the test dataset to analyze TS-Former. Note that each input sample in PEMS04 has 336 patches of length 12, which means it covers data of the past two weeks. Learned temporal pattern. Firstly, we would like to explore whether TSFormer learned temporal patterns. We expect it to generate meaningful representations and be able to solve the problem in <ref type="figure">Figure  1(b)</ref>. Therefore, we randomly select a patch, compute the cosine similarity with the representations of all the other patches, and select the most similar 3 patches. The result is shown in <ref type="figure" target="#fig_0">Figure  3</ref>(a), where the original patch is in the black circle, and the selected most similar patches are in the red circle. Apparently, TSFormer has a strong ability to identify similar patches. Furthermore, in order to get the bigger picture, we also calculate the pairwise similarity between all patches and get a 336 ? 336 heat map, where element in -th column and -th row indicates the cosine similarity between patch and patch . The result shown in <ref type="figure" target="#fig_0">Figure 3</ref>(c) presents clear daily and weekly periodicities. For each patch, it is similar to the patch at the same time of a day, and the most similar patch usually falls on the same time of the week on the same day. The observation is in line with human intuition. The blue columns or rows mean that the sensor is down or has a large noise fluctuation at this moment, which makes it different from other patches. Since TSFormer has learned the correct relationship between patches, it is reasonable that it can significantly enhance the downstream STGNNs. Reconstruction visualization. Additionally, we also visualized the results of the TSFormer reconstruction, which is shown in <ref type="figure" target="#fig_0">Figure 3(b)</ref>, where the grey line presents masked patches and the red line demonstrates the reconstruction. The results show that TSFormer can effectively reconstruct masked patches based on a small number of unmasked patches (blue line). Positional embeddings. Another important difference between TSFormer and MAE <ref type="bibr" target="#b12">[13]</ref> and the original Transformer <ref type="bibr" target="#b32">[33]</ref> is the We compute the cosine similarity between the positional embeddings of 336 patches and get a 336 ? 336 heat map, shown in <ref type="figure" target="#fig_0">Figure  3(d)</ref>. We find that the positional embedding of TSFormer better reflects the multi-periodicity in time series. This is because, unlike the representation of the encoder, which needs to depend on the input patches, the positional embeddings are completely free to optimize and are less affected by the noise of the input data. We conjecture that such positional embedding is the key factor for the success of TSFormer since we found that TSFormer could not get meaningful representations if we replace the learnable positional embeddings with the deterministic, sinusoidal ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Study</head><p>In this part, we conduct experiment to verify the impact of some key components. First, we set STEP w/o GSL to test the performance without the graph structure learning model. Second, we  set STEP w/o reg to replace the NN graph computed by the representations of TSFormer with the NN graph in GTS <ref type="bibr" target="#b28">[29]</ref>, which is computed based on the cosine similarity of raw time series S , to test the superiority of the long sequence representations of TS-Former. Finally, we also test more downstream STGNNs to verify the generality of STEP. We choose DCRNN as another backend, i.e., STEP-DCRNN. Additionally, we also present the performance of DCRNN for comparison. The results are shown in <ref type="figure" target="#fig_2">Figure 4(a)</ref>.</p><p>As can be seen from the figure, STEP outperforms STEP w/o GSL, which shows that our graph structure learning module consistently plays a positive role. Meanwhile, STEP w/o GSL still achieves satisfactory performance, demonstrating that segment-level representation plays a vital role. STEP also outperforms STEP w/o reg, showing that the long sequence representations of TSFormer is superior in improving the graph quality. In addition, as mentioned in Section 1, DCRNN represents a large class of STGNNs <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b40">41]</ref> that are based on the seq2seq <ref type="bibr" target="#b31">[32]</ref> architecture. We fuse the representation of TSFormer to the latent representations of the seq2seq encoder according to Eq.(5). We can see that STEP significantly enhances the performance of DCRNN, which verifies the generality of STEP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Hyper-parameter Study</head><p>We conduct experiments to analyze the impacts of two hyperparameters: the masking ratio , the of the NN graph in graph structure learning. We present the results on METR-LA dataset.</p><p>The effect of and are shown in <ref type="figure" target="#fig_2">Figure 4</ref>(b) and <ref type="figure" target="#fig_2">Figure 4</ref>(c), respectively. We find there exist optimal values for both and . For masking ratio , when is small, masked values in time series can be predicted by simple average or interpolation. Thus it creates a trivial self-supervised learning task and can not get useful representations. When is large, the model would lose too much information and fail to learn temporal patterns. For of the NN graph in graph structure learning, a small value of would make the learned graph incomplete and lose dependency information, thus the performance is worse. A large value of would introduce redundancies, which may hurt the information aggregation of graph neural networks, leading to unsatisfactory performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK 5.1 Spatial-Temporal Graph Neural Networks</head><p>The accuracy of multivariate time series forecasting has been largely improved by artificial intelligence <ref type="bibr" target="#b36">[37]</ref>, especially deep learning techniques. Among these techniques, Spatial-Temporal Graph Neural Networks (STGNNs) are the most promising methods, which combine Graph Neural Networks (GNNs) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18]</ref> and sequential models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b31">32]</ref> to model the spatial and temporal dependency jointly. Graph WaveNet <ref type="bibr" target="#b35">[36]</ref>, MTGNN <ref type="bibr" target="#b34">[35]</ref>, STGCN <ref type="bibr" target="#b37">[38]</ref>, and StemGNN <ref type="bibr" target="#b3">[4]</ref> combine graph convolutional networks and gated temporal convolutional networks with their variants. These methods are based on convolution operation, which facilitates parallel computation. DCRNN <ref type="bibr" target="#b19">[20]</ref>, ST-MetaNet <ref type="bibr" target="#b25">[26]</ref>, AGCRN <ref type="bibr" target="#b1">[2]</ref>, and TGCN <ref type="bibr" target="#b39">[40]</ref> combine diffusion convolutional networks and recurrent neural networks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b31">32]</ref> with their variants. They follow the seq2seq <ref type="bibr" target="#b31">[32]</ref> architecture to predict step by step. Moreover, attention mechanism is widely used in many methods, such as GMAN <ref type="bibr" target="#b40">[41]</ref> and ASTGCN <ref type="bibr" target="#b10">[11]</ref>. Although STGNNs have made significant progress, the complexity of STGNNs is high because it needs to deal with both temporal and spatial dependency at every step. Therefore, STGNNs can only take short-term historical time series as input, such as the past 1 hour (twelve time steps in many datasets).</p><p>More recently, an increasing number of works <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b28">29]</ref> have focused on joint learning of graph structures and graph neural networks to model the dependencies between nodes. LDS <ref type="bibr" target="#b9">[10]</ref> models the edges as random variables whose parameters are treated as hyperparameters in a bilevel learning framework. The random variables parameterize the element-wise Bernoulli distribution from which the adjacency matrix A is sampled. GTS <ref type="bibr" target="#b28">[29]</ref> introduces a neighborhood graph as a regularization that improves graph quality and reformulates the problem as a unilevel optimization problem. Notably, We follow the framework of GTS but enhance it by the pretraining model since TSFormer gives better latent representations of time series for calculating their correlations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Pre-training Model</head><p>The pre-training model is used to learn a good representation from massive unlabeled data and then use these representations for other downstream tasks. Recent studies have demonstrated significant performance gains on many natural language processing tasks with the help of the representation extracted from pre-training models <ref type="bibr" target="#b27">[28]</ref>. Prominent examples are the BERT <ref type="bibr" target="#b7">[8]</ref> and GPT <ref type="bibr" target="#b2">[3]</ref>, which are based on the Transformer encoder and decoder, respectively. The Transformer architecture is more powerful and more efficient than LSTM architecture <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b31">32]</ref> and has become the mainstream approach for designing pre-training models. More recently, Transformer for images has attracted increasing attention because of its powerful performance. ViT <ref type="bibr" target="#b8">[9]</ref> proposes to split an image into patches and provide the sequence of linear embeddings of these patches as an input to a Transformer, showing impressive performance. However, ViT needs supervised training, which requires massive labeled data. On the contrary, MAE <ref type="bibr" target="#b12">[13]</ref> uses selfsupervised learning based on the masked autoencoding strategy. MAE enables us to train large models efficiently and effectively and outperforms supervised pre-training. Although the pre-training model has made significant progress in natural language processing and computer vision, progress in time series lags behind them. In this paper, we propose a pre-training model (named TSFormer) for time series based on Transformer blocks and improve the performance of the downstream forecasting task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we propose a novel STEP framework for multivariate time series forecasting to address the inability of STGNNs to learn long-term information. The downstream STGNN is enhanced by a scalable time series pre-training model TSFormer. TSFormer is capable of efficiently learning the temporal pattern from very long-term historical time series and generating segment-level representations, which provide rich contextual information for short-term input of STGNNs and facilitate modeling dependencies between time series. Extensive experiments on three real-world datasets show the superiority of the STEP framework and the proposed TSFormer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A MORE EXPERIMENTS DETAILS A.1 Baseline Details</head><p>? HA: Historical Average model, which models time series as a periodic process and uses weighted averages from previous periods as predictions for future periods. ? VAR: Vector Auto-Regression <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref> assumes that the past time series is stationary and estimates the relationship between the time series and their lag value. <ref type="bibr" target="#b33">[34]</ref> ? SVR: Support Vector Regression (SVR) uses linear support vector machine for classical time series regression task. ? FC-LSTM <ref type="bibr" target="#b31">[32]</ref>: Long Short-Term Memory network with fully connected hidden units is a well-known network architecture that is powerful in capturing sequential dependency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>? DCRNN [20]: Diffusion Convolutional Recurrent Neural</head><p>Network <ref type="bibr" target="#b19">[20]</ref> replaces the fully connected layer in GRU <ref type="bibr" target="#b5">[6]</ref> by diffusion convolutional layer to form a new Diffusion Convolutional Gated Recurrent Unit (DCGRU). ? Graph WaveNet <ref type="bibr" target="#b35">[36]</ref>: Graph WaveNet stacks gated temporal convolutional layer and GCN layer by layer to jointly capture the spatial and temporal dependencies. ? ASTGCN <ref type="bibr" target="#b10">[11]</ref>: ASTGCN combines the spatial-temporal attention mechanism to capture the dynamic spatial-temporal characteristics simultaneously. ? STSGCN <ref type="bibr" target="#b30">[31]</ref>: STSGCN is proposed to effectively capture the localized spatial-temporal correlations and consider the heterogeneity in spatial-temporal data.  Pre-training stage. The default setting is shown in <ref type="table" target="#tab_3">Table 3</ref>. We use uniform distribution to initialize the positional embeddings, and we use truncated normal distribution with = 0 and = 0.02 to initialize the mask token, similar to MAE <ref type="bibr" target="#b12">[13]</ref>. We use PyTorch official implementation to implement the Transformer blocks. We use the linear scaling rule for learning rate and batch size: lr = base_lr ? (batch_size/8) for all datasets in the pre-training stage. Forecasting stage. All the settings are shown in <ref type="table" target="#tab_4">Table 4</ref>. Following many recent works, such as MTGNN <ref type="bibr" target="#b34">[35]</ref> and GTS <ref type="bibr" target="#b28">[29]</ref>, we use the curriculum learning strategy for the forecasting task. The strategy gradually increases the prediction length of the model with the increase in iteration number. We increase the prediction length by one per cl_num epochs. Moreover, we additionally perform a warm-up of warm_num epochs to better initialize the model for curriculum learning. In addition, in Equation <ref type="formula" target="#formula_9">(7)</ref>   the efficiency of TSFormer in the pre-training stage under different masking ratios. The result is shown in <ref type="figure">Figure 5</ref>. As the masking ratio increases, the TSFormer will be more efficient. In summary, thanks to the high masking ratio and fewer Transformer blocks in the encoder and decoder, the TSFormer is lightweight and can be trained efficiently on a single NVIDIA 3090 GPU. Second, we compare the efficiency of STEP framework in the forecasting stage with its variants. Recalling that the parameter of TSFormer is fixed during the forecasting stage, we can use TSFormer to provide off-the-shelf representations by preprocessing the whole dataset to reduce redundant calculations in the training process. We also test the efficiency of STEP without preprocessing, denoting the variant as STEP w/o pre. In addition, we test the efficiency of STEP without graph structure learning, i.e., STEP w/o GSL. The result is shown in <ref type="figure">Figure 6</ref>. We have the following findings: (i) the graph structure learning module accounts for about 55s per epoch on average. (ii) preprocessing does significantly reduce repetitive computations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Optimization Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C VISUALIZATION</head><p>In order to further intuitively understand and evaluate our model, in this section, we give more visualizations. First, we provide more visualizations about reconstructions of the TSFormer on PEMS04 dataset like <ref type="figure" target="#fig_0">Figure 3(b)</ref>. The results are shown in <ref type="figure" target="#fig_5">Figure 7</ref>. Note that due to space limitation, we only visualize time series in a small window rather than the whole input time series S . Surprisingly, we find that even given very limited information surrounding the unmasked patches, TSFormer reconstructs the masked patches accurately. These results again indicate that our model has a strong ability to learn rich temporal patterns from very long-term time series. Then, we visualize the prediction of our model and the groundtruth data based on METR-LA dataset. We randomly selected six time series and displayed their data from June 13th 2012 to June 16th 2012 (located the test dataset). The forecasting results on six randomly selected time series are shown in <ref type="figure" target="#fig_6">Figure 8</ref>. We can see that our model can accurately make predictions for different time series. Furthermore, we find that the model has the ability to resist noise. For example, in the right top figure, the traffic sensor apparently failed in the afternoon of June 13th, 2012. However, the model does not overfit the noise.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>2 https://github.com/chaoshangcs/GTS/issues Inspecting the TSFormer. (a) Learned temporal periodicity. (b) Reconstruction. (c) Similarity of latent representations among different patches. (d) Similarity of positional embeddings among different patches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Ablation study and hyper-parameter study.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>? MTGNN<ref type="bibr" target="#b34">[35]</ref>: MTGNN extends Graph WaveNet through the mix-hop propagation layer in the spatial module, the dilated inception layer in the temporal module, and a more delicate graph learning layer.? GMAN<ref type="bibr" target="#b40">[41]</ref>: GMAN is an attention-based model which stacks spatial, temporal and transform attentions. ? GTS<ref type="bibr" target="#b28">[29]</ref>: GTS learns a graph structure among multiple time series and forecasts them simultaneously with DCRNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Training speed of different masking ratio .B EFFICIENCYIn this part, we compare the efficiency of STEP with other models and their own variants based on the METR-LA dataset. For a more intuitive and effective comparison, we compare the average training time required for each epoch. All the experiments are running on an Intel(R) Xeon(R) Gold 5217 CPU @ 3.00GHz, 128G RAM computing server, equipped with RTX 3090 graphics cards. First, we compare Training speed of different methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Reconstruction visualizations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Forecasting visualizations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Statistics of datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="4"># Samples # Node Sample Rate Time Span</cell></row><row><cell>METR-LA</cell><cell>34272</cell><cell>207</cell><cell>5mins</cell><cell>4 months</cell></row><row><cell>PEMS-BAY</cell><cell>52116</cell><cell>325</cell><cell>5mins</cell><cell>6 months</cell></row><row><cell>PEMS04</cell><cell>16992</cell><cell>307</cell><cell>5mins</cell><cell>2 months</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Multivariate time series forecasting on the METR-LA, PEMS-BAY, and PEMS04 datasets. Numbers marked with * indicate that the improvement is statistically significant compared with the best baseline (t-test with p-value&lt; 0.05). 29.81 * 12.00% * 19.27 * 31.33 12.78% * learnable positional embedding. Therefore, we would like to explore whether TSFormer has learned reasonable positional embeddings.</figDesc><table><row><cell>Datasets</cell><cell>Methods</cell><cell></cell><cell>Horizon 3</cell><cell></cell><cell></cell><cell>Horizon 6</cell><cell></cell><cell></cell><cell>Horizon 12</cell><cell></cell></row><row><cell></cell><cell></cell><cell>MAE</cell><cell>RMSE</cell><cell cols="2">MAPE MAE</cell><cell>RMSE</cell><cell cols="3">MAPE MAE RMSE</cell><cell>MAPE</cell></row><row><cell></cell><cell>HA</cell><cell>4.79</cell><cell>10.00</cell><cell>11.70%</cell><cell>5.47</cell><cell>11.45</cell><cell>13.50%</cell><cell>6.99</cell><cell>13.89</cell><cell>17.54%</cell></row><row><cell></cell><cell>VAR</cell><cell>4.42</cell><cell>7.80</cell><cell>13.00%</cell><cell>5.41</cell><cell>9.13</cell><cell>12.70%</cell><cell>6.52</cell><cell>10.11</cell><cell>15.80%</cell></row><row><cell></cell><cell>SVR</cell><cell>3.39</cell><cell>8.45</cell><cell>9.30%</cell><cell>5.05</cell><cell>10.87</cell><cell>12.10%</cell><cell>6.72</cell><cell>13.76</cell><cell>16.70%</cell></row><row><cell></cell><cell>FC-LSTM</cell><cell>3.44</cell><cell>6.30</cell><cell>9.60%</cell><cell>3.77</cell><cell>7.23</cell><cell>10.09%</cell><cell>4.37</cell><cell>8.69</cell><cell>14.00%</cell></row><row><cell></cell><cell>DCRNN</cell><cell>2.77</cell><cell>5.38</cell><cell>7.30%</cell><cell>3.15</cell><cell>6.45</cell><cell>8.80%</cell><cell>3.60</cell><cell>7.60</cell><cell>10.50%</cell></row><row><cell></cell><cell>STGCN</cell><cell>2.88</cell><cell>5.74</cell><cell>7.62%</cell><cell>3.47</cell><cell>7.24</cell><cell>9.57%</cell><cell>4.59</cell><cell>9.40</cell><cell>12.70%</cell></row><row><cell>METR-LA</cell><cell>Graph WaveNet ASTGCN</cell><cell>2.69 4.86</cell><cell>5.15 9.27</cell><cell>6.90% 9.21%</cell><cell>3.07 5.43</cell><cell>6.22 10.61</cell><cell>8.37% 10.13%</cell><cell>3.53 6.51</cell><cell>7.37 12.52</cell><cell>10.01% 11.64%</cell></row><row><cell></cell><cell>STSGCN</cell><cell>3.31</cell><cell>7.62</cell><cell>8.06%</cell><cell>4.13</cell><cell>9.77</cell><cell>10.29%</cell><cell>5.06</cell><cell>11.66</cell><cell>12.91%</cell></row><row><cell></cell><cell>GMAN</cell><cell>2.80</cell><cell>5.55</cell><cell>7.41%</cell><cell>3.12</cell><cell>6.49</cell><cell>8.73%</cell><cell>3.44</cell><cell>7.35</cell><cell>10.07%</cell></row><row><cell></cell><cell>MTGNN</cell><cell>2.69</cell><cell>5.18</cell><cell>6.88%</cell><cell>3.05</cell><cell>6.17</cell><cell>8.19%</cell><cell>3.49</cell><cell>7.23</cell><cell>9.87%</cell></row><row><cell></cell><cell>GTS</cell><cell>2.67</cell><cell>5.27</cell><cell>7.21%</cell><cell>3.04</cell><cell>6.25</cell><cell>8.41%</cell><cell>3.46</cell><cell>7.31</cell><cell>9.98%</cell></row><row><cell cols="4">STEP HA VAR SVR FC-LSTM DCRNN STGCN Graph WaveNet 4.98  PEMS-BAY 2.61  *  1.89 4.30 1.74 3.16 1.85 3.59 2.05 4.19 1.38 2.95 1.36 2.96 1.30 2.74 ASTGCN 1.52 3.13</cell><cell>4.16% 3.60% 3.80% 4.80% 2.90% 2.90% 2.73% 3.22%</cell><cell>2.50 2.32 2.48 2.20 1.74 1.81 1.63 2.01</cell><cell>5.82 4.25 5.18 4.55 3.97 4.27 3.70 4.27</cell><cell>5.62% 5.00% 5.50% 5.20% 3.90% 4.17% 3.67% 4.48%</cell><cell>3.31 2.93 3.28 2.37 2.07 2.49 1.95 2.61</cell><cell>7.54 5.44 7.08 4.96 4.74 5.69 4.52 5.42</cell><cell>7.65% 6.50% 8.00% 5.70% 4.90% 5.79% 4.63% 6.00%</cell></row><row><cell></cell><cell>STSGCN</cell><cell>1.44</cell><cell>3.01</cell><cell>3.04%</cell><cell>1.83</cell><cell>4.18</cell><cell>4.17%</cell><cell>2.26</cell><cell>5.21</cell><cell>5.40%</cell></row><row><cell></cell><cell>GMAN</cell><cell>1.34</cell><cell>2.91</cell><cell>2.86%</cell><cell>1.63</cell><cell>3.76</cell><cell>3.68%</cell><cell>1.86</cell><cell>4.32</cell><cell>4.37%</cell></row><row><cell></cell><cell>MTGNN</cell><cell>1.32</cell><cell>2.79</cell><cell>2.77%</cell><cell>1.65</cell><cell>3.74</cell><cell>3.69%</cell><cell>1.94</cell><cell>4.49</cell><cell>4.53%</cell></row><row><cell></cell><cell>GTS</cell><cell>1.34</cell><cell>2.83</cell><cell>2.82%</cell><cell>1.66</cell><cell>3.78</cell><cell>3.77%</cell><cell>1.95</cell><cell>4.43</cell><cell>4.58%</cell></row><row><cell></cell><cell>STEP</cell><cell>1.26  *</cell><cell>2.73  *</cell><cell cols="2">2.59%  *  1.55  *</cell><cell>3.58  *</cell><cell cols="2">3.43%  *  1.79  *</cell><cell>4.20  *</cell><cell>4.18%  *</cell></row><row><cell></cell><cell>HA</cell><cell>28.92</cell><cell>42.69</cell><cell cols="2">20.31% 33.73</cell><cell>49.37</cell><cell cols="2">24.01% 46.97</cell><cell>67.43</cell><cell>35.11%</cell></row><row><cell></cell><cell>VAR</cell><cell>21.94</cell><cell>34.30</cell><cell cols="2">16.42% 23.72</cell><cell>36.58</cell><cell cols="2">18.02% 26.76</cell><cell>40.28</cell><cell>20.94%</cell></row><row><cell></cell><cell>SVR</cell><cell>22.52</cell><cell>35.30</cell><cell cols="2">14.71% 27.63</cell><cell>42.23</cell><cell cols="2">18.29% 37.86</cell><cell>56.01</cell><cell>26.72%</cell></row><row><cell></cell><cell>FC-LSTM</cell><cell>21.42</cell><cell>33.37</cell><cell cols="2">15.32% 25.83</cell><cell>39.10</cell><cell cols="2">20.35% 36.41</cell><cell>50.73</cell><cell>29.92%</cell></row><row><cell></cell><cell>DCRNN</cell><cell>20.34</cell><cell>31.94</cell><cell cols="2">13.65% 23.21</cell><cell>36.15</cell><cell cols="2">15.70% 29.24</cell><cell>44.81</cell><cell>20.09%</cell></row><row><cell></cell><cell>STGCN</cell><cell>19.35</cell><cell>30.76</cell><cell cols="2">12.81% 21.85</cell><cell>34.43</cell><cell cols="2">14.13% 26.97</cell><cell>41.11</cell><cell>16.84%</cell></row><row><cell>PEMS04</cell><cell cols="2">Graph WaveNet 18.15 ASTGCN 20.15</cell><cell>29.24 31.43</cell><cell cols="2">12.27% 19.12 14.03% 22.09</cell><cell>30.62 34.34</cell><cell cols="2">13.28% 20.69 15.47% 26.03</cell><cell>33.02 40.02</cell><cell>14.11% 19.17%</cell></row><row><cell></cell><cell>STSGCN</cell><cell>19.41</cell><cell>30.69</cell><cell cols="2">12.82% 21.83</cell><cell>34.33</cell><cell cols="2">14.54% 26.27</cell><cell>40.11</cell><cell>14.71%</cell></row><row><cell></cell><cell>GMAN</cell><cell>18.28</cell><cell>29.32</cell><cell cols="2">12.35% 18.75</cell><cell>30.77</cell><cell cols="2">12.96% 19.95</cell><cell>30.21</cell><cell>12.97%</cell></row><row><cell></cell><cell>MTGNN</cell><cell>18.22</cell><cell>30.13</cell><cell cols="2">12.47% 19.27</cell><cell>32.21</cell><cell cols="2">13.09% 20.93</cell><cell>34.49</cell><cell>14.02%</cell></row><row><cell></cell><cell>GTS</cell><cell>18.97</cell><cell>29.83</cell><cell cols="2">13.06% 19.29</cell><cell>30.85</cell><cell cols="2">13.92% 21.04</cell><cell>34.81</cell><cell>14.94%</cell></row><row><cell></cell><cell>STEP</cell><cell>17.34</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* 6.60%* 2.96* 5.97* 7.96%* 3.37* 6.99* 9.61%** 28.44* 11.57%* 18.12*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Pre-training setting.</figDesc><table><row><cell>config</cell><cell>value</cell></row><row><cell>optimizer</cell><cell>AdamW [22]</cell></row><row><cell>base learning rate</cell><cell>5.0e-4</cell></row><row><cell>weight decay</cell><cell>0</cell></row><row><cell>epsilon</cell><cell>1.0e-8</cell></row><row><cell>optimizer momentum</cell><cell>1 , 2 = 0.9, 0.95</cell></row><row><cell>learning rate schedule</cell><cell>MultiStepLR</cell></row><row><cell>milestones</cell><cell>50</cell></row><row><cell>gamma</cell><cell>0.5</cell></row><row><cell>gradient clip</cell><cell>5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Forecasting setting.</figDesc><table><row><cell>config</cell><cell>value</cell></row><row><cell>optimizer</cell><cell>Adam [16]</cell></row><row><cell>learning rate</cell><cell>0.001/0.005/0.002</cell></row><row><cell></cell><cell>(PEMS-BAY/METR-LA/PEMS04)</cell></row><row><cell>batch size</cell><cell>64/64/32</cell></row><row><cell></cell><cell>(PEMS-BAY/METR-LA/PEMS04)</cell></row><row><cell>weight decay</cell><cell>1.0e-5</cell></row><row><cell>epsilon</cell><cell>1.0e-8</cell></row><row><cell>learning rate schedule</cell><cell>MultiStepLR</cell></row><row><cell>milestones</cell><cell>[1, 18, 36, 54, 72]</cell></row><row><cell>gamma</cell><cell>0.5</cell></row><row><cell>gradient clip</cell><cell>5</cell></row><row><cell>cl_num</cell><cell>3</cell></row><row><cell>warm_num</cell><cell>30</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>6?), where ??? means ceiling function and epoch is the epoch number.</figDesc><table><row><cell></cell><cell>decays by</cell></row><row><cell>= 1/(? 0 100 200 300 400 500 600 1000 900 800 700 Speed(s/epoch)</cell><cell>?/20% 40% 50% 60% 75% 80% 90% Model 738.6 581.3 491.1 447.7 341.5 312.9 279.3</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/zezhishao/STEP</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">MixHop: Higher-Order Graph Convolutional Architectures via Sparsified Neighborhood Mixing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Abu-El-Haija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amol</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nazanin</forename><surname>Alipourfard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrayr</forename><surname>Harutyunyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Greg Ver Steeg, and Aram Galstyan</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>ICML</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Adaptive Graph Convolutional Recurrent Network for Traffic Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lina</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language Models are Few-Shot Learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spectral Temporal Graph Neural Network for Multivariate Time-series Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Defu</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanyong</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congrui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhai</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bixiong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Freeway performance measurement system: mining loop detector data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Petty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Skabardonis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Record</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>Pravin Varaiya, and Zhanfeng Jia</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SSST@EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?l</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Jakob Uszkoreit, and Neil Houlsby. 2021. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning Discrete Structures for Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Franceschi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning dynamics and heterogeneity of spatial-temporal graph data for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiucheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TKDE</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.06377</idno>
		<title level="m">Piotr Doll?r, and Ross Girshick. 2021. Masked autoencoders are scalable vision learners</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Big data and its technical challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hosagrahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Labrinidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Papakonstantinou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jignesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raghu</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shahabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Categorical Reparameterization with Gumbel-Softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Neural relational inference for interacting systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Fetaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Dynamic Graph Convolutional Recurrent Network for Traffic Prediction: Benchmark and Solution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuxian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyin</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Depeng</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.14917</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rose</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyrus</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">REST: Reciprocal Framework for Spatiotemporal-coupled Predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushun</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TheWebConference</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Decoupled Weight Decay Regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Integrating Granger Causality and Vector Auto-Regression for Traffic Prediction of Large-Scale WLANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songyue</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KSII Trans. Internet Inf. Syst</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">New introduction to multiple time series analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helmut</forename><surname>L?tkepohl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Urban traffic prediction from spatio-temporal data using deep meta learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheyi</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1720" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pre-trained models for natural language processing: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianxiang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yige</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfan</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science China Technological Sciences</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Discrete Graph Structure Learning for Forecasting Multiple Time Series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinbo</forename><surname>Bi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A tutorial on support vector regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stat. Comput</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Spatial-Temporal Synchronous Graph Convolutional Networks: A New Framework for Spatial-Temporal Network Data Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youfang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengnan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyu</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Sequence to Sequence Learning with Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>In NeurIPS</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Traffic Flow Prediction via Spatial Temporal Graph Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiyan</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Connecting the Dots: Multivariate Time Series Forecasting with Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Graph WaveNet for Deep Spatial-Temporal Graph Modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Artificial intelligence: A powerful paradigm for scientific research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enke</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengliang</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Wei</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Innovation</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoteng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanxing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Anuradha Bhamidipaty, and Carsten Eickhoff. 2021. A Transformer-based Framework for Multivariate Time Series Representation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zerveas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srideepika</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhaval</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGKDD</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">T-GCN: A Temporal Graph Convolutional Network for Traffic Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujiao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TITS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">GMAN: A Graph Multi-Attention Network for Traffic Prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanpan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhong</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
