<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Pushing the Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make a Difference</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shell</forename><forename type="middle">Xu</forename><surname>Hu</surname></persName>
							<email>shell.hu@samsung.com</email>
							<affiliation key="aff0">
								<orgName type="department">Samsung AI Center Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Li</surname></persName>
							<email>da.li1@samsung.com</email>
							<affiliation key="aff0">
								<orgName type="department">Samsung AI Center Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>St?hmer</surname></persName>
							<email>jan.stuhmer@samsung.com</email>
							<affiliation key="aff0">
								<orgName type="department">Samsung AI Center Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minyoung</forename><surname>Kim</surname></persName>
							<email>k.minyoung@samsung.com</email>
							<affiliation key="aff0">
								<orgName type="department">Samsung AI Center Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
							<email>t.hospedales@samsung.com</email>
							<affiliation key="aff0">
								<orgName type="department">Samsung AI Center Cambridge</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Edinburgh</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Pushing the Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make a Difference</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T19:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Few-shot learning (FSL) is an important and topical problem in computer vision that has motivated extensive research into numerous methods spanning from sophisticated metalearning methods to simple transfer learning baselines. We seek to push the limits of a simple-but-effective pipeline for more realistic and practical settings of few-shot image classification. To this end, we explore few-shot learning from the perspective of neural network architecture, as well as a three stage pipeline of network updates under different data supplies, where unsupervised external data is considered for pre-training, base categories are used to simulate few-shot tasks for meta-training, and the scarcely labelled data of an noval task is taken for fine-tuning. We investigate questions such as: 1 How pre-training on external data benefits FSL? 2 How state-of-the-art transformer architectures can be exploited? and 3 How fine-tuning mitigates domain shift? Ultimately, we show that a simple transformer-based pipeline yields surprisingly good performance on standard benchmarks such as Mini-ImageNet, CIFAR-FS, CDFSL and Meta-Dataset. Our code and demo are available at</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Mainstream supervised deep learning achieves excellent results in applications where huge annotated datasets are available. However, this assumption is not met in many applications where data (e.g., rare categories), or the cost of human annotation are prohibitive bottlenecks. This has motivated a large and growing set of research in few-shot learning (FSL), which aims to emulate the human ability to learn new concepts from few training examples. The FSL challenge has proven fertile ground for developing and testing a vast array of sophisticated research ideas spanning metric learning <ref type="bibr" target="#b59">[59,</ref><ref type="bibr" target="#b61">61]</ref>, gradient-based meta-learning <ref type="bibr" target="#b28">[29]</ref>, program induction <ref type="bibr" target="#b40">[41]</ref>, differentiable optimization layers <ref type="bibr" target="#b41">[42]</ref>, hy-* Equal contributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN-4-64 RN12</head><p>RN18 WRN-28-10 ViT-base 50 <ref type="bibr" target="#b60">60</ref> 70 80 90 100 miniImageNet 5-way-5-shot accuracy <ref type="figure" target="#fig_1">Figure 1</ref>. How does pre-training and architecture affect fewshot learning? Learning from a few shots can be achieved by a) meta-learning <ref type="bibr" target="#b66">[66,</ref><ref type="bibr" target="#b72">72]</ref> and b) transfer learning from self-supervised foundation models pre-trained on large-scale external data <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b53">53]</ref>. While the majority of FSL community focuses on the former, we show that the latter can be more effective because it enables the use of stronger architectures such as vision transformer (ViT) <ref type="bibr" target="#b24">[25]</ref> -and can be combined with simple meta-learners such as ProtoNet. The figure shows results aggregated from dozens of studies from the past 5 years of FSL research and the result of ProtoNet + ViT backbone + contrastive language-image pretraining (CLIP) <ref type="bibr" target="#b53">[53]</ref> (yellow star). To emphasize the importance of pre-training, ProtoNet + randomly initialized ViT (blue square) is also compared.</p><p>pernetworks <ref type="bibr" target="#b8">[9]</ref>, neural optimizers <ref type="bibr" target="#b54">[54]</ref>, transductive label propagation <ref type="bibr" target="#b55">[55]</ref>, neural loss learning <ref type="bibr" target="#b3">[4]</ref>, Bayesian neural priors <ref type="bibr" target="#b72">[72]</ref> and more <ref type="bibr" target="#b69">[69]</ref>. But how much practical progress have we made based on all these technical advances? A few studies <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr">51,</ref><ref type="bibr" target="#b63">63,</ref><ref type="bibr" target="#b68">68]</ref> have investigated whether simpler baselines can offer comparable performance to sophisticated state of the art few-shot learners. While there is no conclusive answer, due to on-going developments in both sophisticated learners <ref type="bibr" target="#b72">[72]</ref> and simple baselines, there is a trend that simple approaches often perform surprisingly well compared to sophisticated counterparts. Their simplicity and efficacy leads these simple methods to be taken up in many practical applications of few-shot learning from medical data analysis <ref type="bibr" target="#b10">[11]</ref> to electronic engineering <ref type="bibr" target="#b39">[40]</ref>.</p><p>We follow this line of enquiry, but go further in investigating previously under-studied factors that influence the performance of simple few-shot pipelines. In particular we start with a ProtoNet <ref type="bibr" target="#b59">[59]</ref> few-shot learner, and investigate three practically important design choices: pre-training data, neural network architecture, and meta-test time fine-tuning. Source data While FSL addresses the small data regime, in reality FSL research is almost always about algorithms to transfer knowledge from large scale source tasks (aka metatrain) to small scale target tasks (aka meta-test). Existing literature almost always controls the source data, in order to carefully compare the impact of different knowledge transfer mechanisms of interest from hyper-networks <ref type="bibr" target="#b8">[9]</ref> to gradientbased meta-learners <ref type="bibr" target="#b28">[29]</ref>. While this is helpful to drive research on sophisticated algorithms, it does not answer the question of how choice of source data impacts performance? This question has been studied in other areas of vision and pattern recognition <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b60">60]</ref>, but not for FSL. This is unhelpful for consumers of computer vision FSL research, who would be interested to know how much a simple change of source data can improve their applications? Especially since freely available large datasets already exist <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b62">62]</ref>, and exploiting more external source data is easier in practice than implementing sophisticated state-of-the-art meta-learners. To this end we investigate the impact of unsupervised pretraining on external data -a workflow recently termed as exploiting a foundation model <ref type="bibr" target="#b9">[10]</ref> -on FSL tasks. This small change has substantial impact compared to 5 years of FSL research <ref type="figure" target="#fig_1">(Figure 1</ref>). Although this may violate definitions of the FSL problem that strictly prescribe the source set, the efficacy of the approach may prompt reflection on whether this is the best problem definition to focus on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neural architecture</head><p>Similarly to the situation with source data, FSL studies often control neural architecture to a handful of small networks such as CNN-4-64 and ResNet-12. This is partly to enable fair comparison of FSL algorithms, but this particular suite of networks is also a consequence of the small size of the source datasets used for training in common benchmarks such as miniImageNet. Thus the architectures commonly studied in FSL are somewhat out-of-date with regard to state-of-the-art computer vision. We therefore ask to what extent state-of-the-art architectures such as vision transformers <ref type="bibr" target="#b24">[25]</ref> can benefit few-shot performance, especially in conjunction with larger pre-training datasets? Fine-tuning The many studies in the FSL literature are somewhat divided in whether they advocate <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b54">54,</ref><ref type="bibr" target="#b65">65]</ref> some kind of fine-tuning during model deployment (aka meta-test) for individual tasks, or whether a fixed feature representation should be sufficient <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b59">59,</ref><ref type="bibr" target="#b68">68]</ref>. We also investigate </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meta-trained backbone</head><p>Task-specifically fine-tuned backbone <ref type="figure">Figure 2</ref>. Overview -A schematic of the simple-but-effective pipeline that we consider: Pre-training ? Meta-training ? Finetuning (P&gt;M&gt;F). Following the red arrows, the pipeline turns a class-agnostic feature backbone into a generic feature backbone and ultimately a task-specific feature backbone.</p><p>this issue, and suggest that fine-tuning is necessary for deploying foundation models to out-of-distribution tasks. We also introduce an algorithmic improvement to fine-tuning by automating the learning rate selection via validation, which leads to a more performant pipeline for cross-domain FSL.</p><p>In summary, we advance few-shot learning by studying design choices of a simple pipeline <ref type="bibr" target="#b59">[59]</ref>  <ref type="figure">(Figure 2</ref>), rather than developing new algorithms. We answer questions including: How does pre-training impact FSL? Can recent transformer architectures be adapted to FSL? and How to best exploit fine-tuning? Based on this analysis we demonstrate a new baseline for FSL that surpasses state-of-the-art performance, while being simple and easy to implement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Few-shot learning Few-shot learning is now a deep and widely studied area too large to review in detail here, and we refer to relevant surveys for an overview <ref type="bibr">[35,</ref><ref type="bibr" target="#b69">69]</ref>. A key point is that, despite the name, almost all FSL methods provide algorithms for transferring knowledge from a large set of source data, to a set of sparsely annotated target categories of interest. Much activity in the field falls under the umbrella of meta-learning <ref type="bibr">[35]</ref>, which aims to construct a data-efficient learner from the source (aka meta-train) dataset by simulating few-shot learning problems, and then deploy the customized learner on the target (aka meta-test) set. The resulting learner may take the form of an initialization <ref type="bibr" target="#b28">[29]</ref>, learned metric <ref type="bibr" target="#b59">[59]</ref>, Bayesian prior <ref type="bibr" target="#b72">[72]</ref>, or optimizer <ref type="bibr" target="#b54">[54]</ref>. Simple-but-effective baselines In competition with the plethora of sophisticated few-shot learners <ref type="bibr">[35,</ref><ref type="bibr" target="#b69">69]</ref> such as those mentioned above, a number of recent studies have advocated strong baselines that perform comparably well while being simpler. These are often based on a transfer learning <ref type="bibr" target="#b70">[70]</ref> pipeline. They apply a conventional deep learner on the source data, before adapting to the few-shot target data by training a simple linear <ref type="bibr" target="#b18">[19,</ref><ref type="bibr">51,</ref><ref type="bibr" target="#b63">63]</ref> or centroid <ref type="bibr" target="#b68">[68]</ref> classifier on the fixed representation, or fine-tuning the feature backbone as well <ref type="bibr" target="#b22">[23]</ref>. These methods mostly use standardized FSL source datasets (such as miniImageNet) and architectures (such as ResNet-12 and WRN-10-28) to enable direct comparisons of the advocated simple baselines to sophisticated learners. In contrast, we specifically aim to explore how far practical FSL performance can be pushed by exploiting other available pre-training datasets and architectures.</p><p>A few studies have evaluated FSL on a larger scale using datasets such as ImageNet1K <ref type="bibr" target="#b19">[20]</ref> or ImageNet21K <ref type="bibr" target="#b22">[23]</ref>. However by changing both the source and target sets, this does not make it clear how choice/scale of source data impacts a given target problem -the question that we answer here. Others have explored the impact of conventional pretraining prior to meta-learning <ref type="bibr" target="#b19">[20]</ref> or as a regularizer during meta-learning <ref type="bibr" target="#b29">[30]</ref> -but without exploiting extra data.</p><p>Bigger data and architectures The impact of source datasets is widely studied in standard supervised <ref type="bibr" target="#b60">[60]</ref> and self-supervised <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b30">31]</ref> learning in vision, and in pattern recognition applications outside of vision <ref type="bibr">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr">13,</ref><ref type="bibr" target="#b21">22]</ref>. However, it is not widely evaluated in FSL, which is a surprising omission, since as we shall see it may well be the easiest way to improve practical FSL performance. Similarly, existing FSL methods are almost exclusively based on a few less common architectures (e.g., Conv-4-64 and ResNet-12), which maybe due to the very first experimental setup on small datasets like Omniglot <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b66">66]</ref>. Transformers have seen limited use in FSL, mainly for metric learning <ref type="bibr" target="#b23">[24]</ref>, but not for feature extraction. We explore how recent transformer feature extractors can be trained and applied to FSL, especially when combined with a foundation model <ref type="bibr" target="#b9">[10]</ref> pre-trained on larger source datasets.</p><p>Self-supervised &amp; few-shot Our pipeline extends the typical unsupervised pre-train ? supervised fine-tune workflow of the self-supervised research community <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b38">39]</ref>, which has recently demonstrated strong performance for low-shot supervised learning <ref type="bibr">[15,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b26">27]</ref>. However, there has been limited direct comparison of self-supervised (SSL) and FSL community methods for data efficient learning due to different typical evaluation practices and benchmarks. For example, many SSL evaluations perform unsupervised representation learning on ImageNet, before performing few-shot supervised learning within ImageNet <ref type="bibr">[15,</ref><ref type="bibr" target="#b17">18]</ref>, which violates usual FSL community requirement of disjoint source and target data. One contribution of this paper is to provide a degree of comparison between and combination of the SSL and FSL approaches. For example, our MetaDataset, CDFSL and teaser <ref type="figure" target="#fig_1">Figure 1</ref> results, use disjoint source and target data but benefit from external self-supervised pre-training.</p><p>Cross-domain few-shot A FSL variant of particular practical interest is cross-domain few-shot <ref type="bibr" target="#b32">[33]</ref>, where the source/meta-train dataset is significantly different to the target/meta-test dataset. This is more challenging than the standard within-domain setting, but more practically relevant. This is because in many scenarios where FSL is of interest such as medical or earth observation imaging <ref type="bibr" target="#b32">[33]</ref>, the target data for FSL is significantly different to available source data (such as (mini-)ImageNet <ref type="bibr" target="#b20">[21]</ref>). Major benchmarks of this type are CDFSL <ref type="bibr" target="#b32">[33]</ref> and meta-dataset <ref type="bibr" target="#b65">[65]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A Simple Pipeline for FSL</head><p>Problem formulation Few-shot learning (FSL) aims to learn a model with only a few annotated examples. One widely adopted formulation for FSL was introduced by Vinyals et al. <ref type="bibr" target="#b66">[66]</ref> from a meta-learning perspective, where the assumption is that one should learn to solve new few-shot tasks based on previously seen experience of many similar few-shot tasks. Therefore, the FSL problem is usually organized in two phases: meta-training a few-shot learner on a distribution of training tasks and meta-testing the resulting learner by evaluating it on novel few-shot tasks. Within each phase, data arrives in an episodic fashion, where the "train-set" and "test-set" of each task are called support set and query set respectively to avoid terminology confusion. In the case of classification, the difficulty level of an episode is described as K-way-N-shot, which corresponds to learning a classifier for K classes given N examples per class in the support set. It is common to learn one model for each difficulty level, but a more realistic setting <ref type="bibr" target="#b65">[65]</ref> is to learn a global model for various K's and N's. This is sometimes called various-way-various-shot, and we address this more practical setting here. This is also a reason to prefer simple pipelines over sophisticated meta-learners that may not be easily extended to the various-way-various-shot setting.</p><p>A different approach to small-data learning appears in the transfer learning <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b70">70]</ref> and self-supervision <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17]</ref> literature. In this case one pre-trains a model using some large source data, and then re-purposes it for the sparse data target task of interest. The pre-training step aims to reduce the sample complexity of learning the target problem in the adaptation step.</p><p>Although typically studied separately, both families of approach provide mechanisms for knowledge transfer from source data to the target few-shot problem of interest. Towards the goal of high performance few-shot learning, we combine both pre-training (typically on auxiliary unlabeled data, which is freely and ubiquitously available) and metalearning (episodic training with labels) together in a simple sequential pipeline using a single feature extractor backbone. Our pipeline consists of three phases: 1) pre-training the feature backbone on unlabeled external data using selfsupervised loss, 2) meta-training the feature backbone on labeled simulated few-shot tasks using ProtoNet <ref type="bibr" target="#b59">[59]</ref> loss, and 3) deploying the feature backbone on novel few-shot tasks with optional fine-tuning on the augmented support set of each task. A schematic of our pipeline is shown in <ref type="figure">Figure</ref> 2, which we call P&gt;M&gt;F (i.e., the pipeline Pre-training ? Meta-training ? Fine-tuning ). We next outline how the feature backbone is updated in different stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Pre-training of backbone</head><p>We consider the feature backbones of ResNet <ref type="bibr" target="#b33">[34]</ref> or ViT <ref type="bibr" target="#b24">[25]</ref>, to provide the foundation models in our pipeline. There are then several well-established self-supervised learning algorithms for the pre-training step: DINO <ref type="bibr">[15]</ref> uses ImageNet1K and exploits the consistency in prediction between a large crop and multiple local crops of the same image, where a large crop is highly likely to overlap with a foreground object in the case of ImageNet images; BEiT <ref type="bibr" target="#b5">[6]</ref> amounts to solving a masked image reconstruction task on the ImageNet-21K dataset in line with the original BERT pre-training <ref type="bibr" target="#b21">[22]</ref> for text data; and CLIP <ref type="bibr" target="#b53">[53]</ref> leverages image captions in the YFCC100m dataset to align image and caption representations in a common feature space. For more flexible architectures like ViT <ref type="bibr" target="#b24">[25]</ref>, pre-training on external data is important, as they are hard to train on common small-sized FSL benchmarks ( <ref type="figure" target="#fig_1">Figure 1</ref> and <ref type="table">Table 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Meta-training with ProtoNet</head><p>As the goal is to build a simple pipeline, we consider the prototypical network (ProtoNet) <ref type="bibr" target="#b59">[59]</ref>, which constructs class centroids dynamically for each episode and then performs nearest centroid classification. Specifically, ProtoNet only requires a feature backbone f to map data points to a mdimensional feature space: f : X ? R m , and the probability of a query image x belonging to class k is given by</p><formula xml:id="formula_0">p(y = k|x) = exp ? d(f (x), c k ) k exp ? d(f (x), c k ) ,<label>(1)</label></formula><p>where d is implemented by a cosine distance in our work as opposed to the commonly chosen Euclidean distance and c k is the prototype of class k, defined as c k = 1 N k i:yi=k f (x i ) and N k = i:yi=k 1 on the support set. Note that the prototypes can be computed regardless of the value of k. This enables ProtoNet to be trained and deployed under various-way-various-shot setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Meta-testing with fine-tuning</head><p>To be consistent with meta-training, by default, we deploy the meta-trained ProtoNet directly on all novel tasks. However, if the a novel task is drawn from an unseen domain, the learned feature representation may fail to generalize due to a substantial shift in the data distribution. To this end, we propose to fine-tune the feature backbone by a few gradient steps with the assistance of data augmentation. The details are summarized as PyTorch pseudo code in Algorithm 1. Our fine-tuning algorithm is similar to that of <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b42">43]</ref> who fine-tune the model weights using the support set since this is the only accessible labeled data at meta-test time. We exploit the support set slightly differently: we use data augmentation to create a pseudo query set derived from the support set; as such, we do not need to compute prototypes using the support set and then again apply the prototypes on the same support set using eq. (1). Besides, we simply update the entire backbone rather than exploring partial model adaptation.</p><p>Learning rate selection We observe that the fine-tuning performance is relatively sensitive to the choice of learning rate (see supplemental material for more analysis). However, existing few-shot learning problem formulation does not offer a validation set for each task to choose the best learning rate for fine-tuning. Previous work <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b42">43]</ref> choose a learning rate a priori and fix it for every task. This strategy requires a good understanding of the backbone architecture but still leads to sub-optimal performance in general. Given a task with very few labeled images (i.e. the support set), it is almost unlikely to identify which learning rate yields good generalization for unlabeled images (i.e. the query set). The good news is that we find empirically the best learning rate is relatively stable across tasks within the same domain. To this end we propose to sample N = 5 extra tasks from each domain and automate domain-wise learning rate search within a reasonable range (e.g., {0.01, 0.001, 0.0001, 0}). The best learning rate is then used for every task within the domain. This additional step amounts to preparing a few labeled images per domain to create a validation set, which makes sense in practice as we can easily organize tasks by domains and identify domain for individual tasks to look up the corresponding learning rate once searched.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Meta-training datasets We use standard benchmarks to evaluate our proposed pipeline. miniImageNet <ref type="bibr" target="#b66">[66]</ref> contains 100 classes from ImageNet-1k, which is then split into 64 training, 16 validation and 20 testing classes; each image is downsampled to 84?84. CIFAR-FS Each dataset has train/val/test splits. We follow the two training protocols proposed by <ref type="bibr" target="#b65">[65]</ref> and <ref type="bibr" target="#b23">[24]</ref> respectively. For the former, the train/val splits of the first 8 datasets (indomain) are used for meta-training and validation, and the test splits of all datasets are used for meta-testing. The latter considers only ImageNet-1k's train-split for meta-training, and the other settings remain the same. For more details on Meta-Dataset we refer the readers to Appendix.3 of <ref type="bibr" target="#b65">[65]</ref>. Evaluation For evaluating few-shot classification performance, we simulate 600 episodes/tasks from the test-split for each dataset of interest. The evaluation metric is the average classification accuracy over tasks. For miniImageNet and CIFAR-FS, the convention is to evaluate 5-way-1-shot (5w1s) and 5-way-5-shot episodes, and the size of the query set for each episode is fixed to 15 ? 5. For Meta-Dataset, the number of ways, shots and query images are sampled uniformly at random with respect to the dataset specifications, except for ImageNet-1k and Omniglot (they have specific sampling strategies according to the hierarchy of classes). In addition, we evaluate the (5w5s) meta-trained model from miniImageNet for a cross-domain evaluation (CDFSL) <ref type="bibr" target="#b32">[33]</ref>, where 4 out-of-domain datasets are considered, and the results are reported under 5-way-5/20/50-shot settings. Training details To avoid over-engineering training for different datasets and architectures, we adopt a common training strategy for meta-training the backbone from pretrained model checkpoints (for both ResNet and ViT). This may lead to sub-optimal results for some cases, but it simplifies comparison. Specifically, we train the backbone for 100 epochs, where each epoch consists of 2000 episodes/tasks. We use a warm-up plus cosine annealing learning rate schedule: the learning rate starts from 10 ?6 , increases to 5 ? 10 ?5 in 5 epochs and then gradually decreases to 10 ?6 with a cosine annealing. We use the validation set to decide when to early stop, and turn off strong regularization and data augmentation techniques for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Analysis</head><p>We now use the pipeline outlined in Sec 3 to answer a series of questions about few-shot learner pipeline design. Notably, 1 How does pre-training regime affect FSL? <ref type="bibr">2</ref> Can contemporary architectures such as ViT be adapted to FSL? <ref type="bibr">3</ref> How to exploit fine-tuning in meta-testing?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Pre-training and architectures</head><p>We first evaluate the impact of pre-training regime (including algorithm and dataset), as well as neural architecture on FSL benchmarks Meta-Dataset <ref type="bibr" target="#b65">[65]</ref> (train on 8 datasets), miniImageNet <ref type="bibr" target="#b66">[66]</ref>, and CIFAR-FS <ref type="bibr" target="#b7">[8]</ref>. To clearly convey the configuration of each experiment, results in <ref type="table">Table 1</ref> are organized by architecture, pre-training algorithm (and dataset) and meta-training algorithm. We assume ProtoNet (nearest-centroid) classifier as the standard approach for meta-testing throughout, and compare either episodically trained ProtoNet or nothing as the meta-learning step between pre-training and meta-testing (column MetaTr). We remark that our ResNet50 baseline also performs comparitively poorly without pre-training, especially on the smaller miniImageNet and CIFAR, suggesting that it is also too large to train well on the target datasets alone.</p><p>Other foundation models Overall we can see that larger pre-training data sources, and recent architectures make a huge difference to downstream FSL performance on standard benchmarks. We also compared a selection of other foundation models <ref type="bibr" target="#b9">[10]</ref> in M11-15. We can see that (i) All the foundation models lead to substantial improvements on standard within-dataset training (M10,M9), (ii) The largest foundation models using, e.g., ViT-base and ImageNet21K or YFCC data source lead to strongest performance across the board, but do not outperform hugely the more economic DINO+ImageNet1K-based ViT-small (M4). For efficiency of pre-training and deployment, we take this to be our default model in the following section. <ref type="bibr">1</ref> In the case of miniImageNet and Meta-Dataset, parts of ImageNet1K are used in both meta-train and meta-test splits. EG: since Meta-Dataset's ImageNet uses a 712/288 source/target class split, this means that for one of Meta-Dataset's 10 domains, there is some data (but not label) overlap between pre-train and meta-test for some foundation models. As discussed in Sec. 2, this overlap is ubiquitious in typical self-supervision evaluation pipelines <ref type="bibr">[15,</ref><ref type="bibr" target="#b16">17]</ref>. It is less common in FSL evaluation pipelines, but corresponds to making a semi-supervised or transductive assumption in terms of data access as per <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b55">55]</ref>. Nevertheless, we do not think this is a significant factor in the strong results, as CLIP's YFCC does not have this overlap and performs similarly to the ImageNet1K based models. explore how our pipeline impacts two few-shot learners that are more representative of recent state of the art, namely MetaOptNet <ref type="bibr" target="#b41">[42]</ref> and MetaQDA <ref type="bibr" target="#b72">[72]</ref>. From the results in Few-shot learning v.s. self-supervised learning Existing literature generally fails to directly compare algorithms from the few-shot learning community (such as ProtoNet, <ref type="bibr" target="#b59">[59]</ref>, MAML <ref type="bibr" target="#b28">[29]</ref>, MetaOptNet <ref type="bibr" target="#b41">[42]</ref>, etc), with those from the self-supervised community (such as DINO <ref type="bibr">[15]</ref>, Sim-CLR <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, etc). This is partly because the popular evaluation protocol is different: For example 5-way-1-shot regime is popular the FSL community, vs 1% labels (? 1000-way-10-shot in the case of ImageNet) in the SSL community; network architectures differ (?ResNet18 vs ?ResNet50 respectively); and image resolutions differ (84? vs full). Our results provide a taster of such a direct comparison. Overall they suggest that frozen self-supervised foundation models (using extra pre-training data) are competitive out of the box compared to standard few-shot learners (using only metatraining data). However, more interestingly, combining these two paradigms as we have done, easily leads to state of the art performance on typical FSL metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class overlap between pre-training and meta-testing</head><p>Although unsupervised pre-training does not utilize labels, it is very likely that some classes used by pre-training also appear in meta-testing. Does this class overlap go against the very definition of few-shot learning? From a meta-learning point of view, the answer is yes. But we argue that class overlap is almost unavoidable unless a careful data split is simulated. For example, in the case of Meta-Dataset, the CUB dataset <ref type="bibr" target="#b67">[67]</ref>, the Aircraft dataset <ref type="bibr" target="#b50">[50]</ref> and the COCO dataset <ref type="bibr" target="#b46">[47]</ref> have a class overlap with ImageNet <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b31">32]</ref> but they are still used in meta-testing. As we consider more practical large-scale experiments, the class overlap issue be- comes ubiquitous. We should worry about this issue if we were benchmarking a meta-learning algorithm, but for the nature of few-shot learning, benchmarking the capability of quickly constructing a classifier from very few labels is not hindered by class overlap. This is why self-supervised learning community is not bothered by this issue at all. It is worth mentioning that a similar setting called "few-shot few-shot learning" has been proposed by <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b71">71]</ref>, where they avoid overlap by either carefully picking up pre-training data from a different domain or crawling pre-training data of base categories from Internet. Alternatively, one may avoid overlap by using a different modality. We advocate meta-learning researchers to consider this controlled setting as a testing bed for incorporating powerful pre-trained feature backbones.  <ref type="figure" target="#fig_8">Figure 3</ref>. The impact of fine-tuning during meta-test on Meta-Dataset. Held out datasets such as Signs and COCO benefit from fine-tuning; as do those very different from ImageNet such as omniglot and QuickDraw.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Fine-tuning</head><p>The previous experiments used a fixed feature extractor together with ProtoNet for meta-testing. We next investigate use of fine-tuning during meta-testing to further improve performance. We focus on the DINO pre-trained ViT models, based on their strong performance in Section 4.1.1.</p><p>3 How to best exploit fine-tuning for meta-testing?  <ref type="bibr" target="#b19">[20]</ref> 68.6 83.7 RS-FSL (ResNet12) <ref type="bibr">[2]</ref> 65.3 Transductive Fine-tuning (WRN-28-10) <ref type="bibr" target="#b22">[23]</ref> 76.6 85.8 65.7 78.4 SIB (WRN-28-10) <ref type="bibr" target="#b35">[36]</ref> 80.0 85.3 70.0 79.2 PT-MAP (WRN-28-10) <ref type="bibr" target="#b36">[37]</ref> 87.7 90.7 82.9 88.8 CNAPS + FETI (ResNet18) <ref type="bibr" target="#b6">[7]</ref> 79.9 91.5 Self-supervised ProtoNet (WRN-28-10) <ref type="bibr" target="#b29">[30]</ref> 73.6 86.1 62.9 79.9 ProtoNet (AMDIM ResNet) <ref type="bibr" target="#b15">[16]</ref> 76.8 91.0 EPNet + SSL (WRN-28-10) <ref type="bibr" target="#b57">[57]</ref> 79.2 88.1 Semi-supervised LST (ResNet12) <ref type="bibr" target="#b44">[45]</ref> 70.1 78.7 PLCM (ResNet12) <ref type="bibr" target="#b37">[38]</ref> 77.6 86.  To answer this question, we compare vanilla feature transfer as explored previously, with ProtoNet, and ProtoNet with episode-wise fine-tuning on the support set (ProtoNet+FT) as outlined in Section 3.3. We use Meta-Dataset including both conditions of treating ImageNet alone as the source, and joint meta-training on all of Meta-Dataset. From the results in <ref type="figure" target="#fig_8">Figure 3</ref> and <ref type="table" target="#tab_9">Table 3</ref> we can draw the following conclusions: (i) Meta-training on the full Meta-Dataset improves on meta-training on ImageNet-training alone (M5 vs M1).</p><p>(ii) Fine-tuning during meta-test improves substantially in the out-of-distribution datasets, and especially in the case where meta-training is conducted on ImageNet, and then deployed across-domain to all the other Meta-Dataset tasks: See Out-D column and M2 vs M1 in <ref type="table" target="#tab_9">Table 3</ref>; blue vs orange bars in <ref type="figure" target="#fig_8">Figure 3</ref> for OmniGlot, QuickDraw, traffic signs, etc. However, for the condition where more Meta-Dataset domains are used for training and testing, fine-tuning has inconsistent impact across domains: While it is helpful for the remaining OOD datasets, it is not helpful overall (M5 vs M6 for Avg and Out-D). Overall feature backbone updates by fine-tuning are more helpful for domains unseen during meta-training, concurring with <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b65">65]</ref>. On analysing the inconsistent impact of fine-tuning, we found this is due to difficulty in choosing an appropriate learning rate. Using any single learning rate throughout, as we did above (lr=0.01) is poorly tuned for some datasets. We therefore also explore our learning rate selection heuristic proposed in Section 3.3, and we see this leads to the best performance (M4 vs M2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results on standard benchmarks</head><p>We call our pipeline P&gt;M&gt;F, which can be instantiated with any pre-training algorithm and backbone architectures, <ref type="bibr" target="#b7">8</ref>   <ref type="table">Table 6</ref>. Broader study of cross-domain few-shot learning -Comparison with SOTA FSL algorithms. e.g., DINO &gt; ProtoNet (PN) &gt; Fine-tuning (FT). We next compare our pipeline with prior state of the art. We emphasize that our results are not directly comparable to much prior SOTA in terms of architecture and use of external data. We draw this comparison to see how simple changes (such as upgrading feature backbone to a modern network architecture and exploiting publicly available data for a largescale pre-training) compare against 5 years of intensive research on FSL algorithms. The results for the single-domain cases, i.e., mini-ImageNet and CIFAR-FS, are summarized in <ref type="table" target="#tab_7">Table 4</ref>, while the results for the cross-domain datasets, i.e., Meta-Dataset and Broader Study CDFSL, are shown in <ref type="table">Table 5</ref> and 6 respectively. From the results we can see that our framework outperforms much the state of the art in both within-domain and cross-domain conditions despite being significantly simpler than some sophisticated competitors. We remark that for the single source benchmarks in <ref type="table" target="#tab_7">Table 4</ref>, a few competitors also used external data or Im-ageNet pre-training as indicated. Meanwhile our hybrid pipeline outperforms SOTA pure external self-supervision <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b26">27]</ref> for CDFSL in <ref type="table">Table 6</ref>. Our code is available at https://github.com/hushell/pmf_cvpr22.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Discussion</head><p>Taken together, the results show that our simple pipeline of exploiting available pre-training data and a modern architecture often outperforms sophisticated state of the art in few-shot learning. This margin is increased using our proposed adaptive fine-tuning mechanism in the meta-test stage. Based on these observations we make recommendations both for practitioners and few-shot learning researchers. Practitioners: Increasing pre-training data size or simply using a foundation model <ref type="bibr" target="#b9">[10,</ref><ref type="bibr">15]</ref> and upgrading to modern architectures is likely to be more productive (and much easier to implement) than keeping up with and implementing state of the art few-shot learning algorithms. Fine-tuning is likely to be important if the target few-shot task of interest is less similar to the pre-training and meta-training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FSL researchers:</head><p>Our results show that using external data and modern architectures is an easy and effective way to achieve strong FSL performance, and also that some SOTA meta-learners fail to provide expected improvements in this regime. While external data violates definitions of the FSL problem that insist on a specific limited meta-train set, we should take this setting seriously to maintain practical relevance in the face of advancing self-supervision <ref type="bibr">[15,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b53">53]</ref>. In particular, we recommend a new evaluation setting for all the standard FSL benchmarks, where pre-train data and architecture are freely chosen and clearly reported. Few-shot meta-learning methods are then evaluated on their ability to improve on linear readout, fine-tuning, or our PMF baseline for the given external dataset and architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We advanced few-shot learning from the perspective of pushing the limits of a simple pre-train + ProtoNet pipeline in terms of dataset, architecture and fine-tuning strategy. We showed that source dataset, and neural architecture are dominant factors in FSL performance. When there is a domain shift between training and testing, we showed that fine-tuning the feature backbone with data augmentation is also important. We verified that our simple pipelines achieve very competitive performance in four FSL benchmarks.</p><p>Limitations and future work There are several limitations of our empirical study. We only scratched the surface of the impact of external data and correspondingly larger architectures on FSL. Our renewed focus on external data emphasizes the need for algorithms from the FSL community <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b59">59]</ref> to be directly compared against algorithms from the self-supervised community <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b16">17]</ref>, or possibly synergistically combined, as we attempt here. The hybrid pipeline that we propose is obviously restricted to modalities where large external datasets already exist, and would require significant up-front investment in compute and energy cost where pre-trained foundation models do not already exist. Possible bias within foundation models is also a potential risk <ref type="bibr" target="#b9">[10]</ref>. Finally, while effective, our adaptive fine-tuning strategy, is rather computationally expensive at meta-test time, and may be unsupported on embedded platforms without backpropagation. Feed-forward representation adaptation methods <ref type="bibr" target="#b56">[56]</ref> may be important for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pushing the Limits of Simple Pipelines for Few-Shot Learning: Supplemental Material</head><p>In this supplemental material, we present:</p><p>? In Section 1, we include additional results for <ref type="table">Table 1</ref> in the main paper.</p><p>? In Section 2, we include additional results for <ref type="table">Table 1</ref> and <ref type="table" target="#tab_7">Table 4</ref> in the main paper.</p><p>? In Section 3, we investigate the impact of the hyper-parameters for the fine-tuning phase.</p><p>? In Section 4, we show the T-SNE plots before and after ProtoNet meta-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Additional results for Meta-Dataset</head><p>In this section, we show a complete view of the results presented in <ref type="table">Table 1</ref> in the main paper, including the outcomes of different pre-training methods (see <ref type="table">Table 1</ref>), the outcomes of meta-training on ImageNet domain (see <ref type="table" target="#tab_2">Table 2</ref>), and the outcomes of meta-training on eight pre-specified domains (see <ref type="table" target="#tab_9">Table 3</ref>).</p><p>As indicated in the main paper, our pipeline is named in a form of "P &gt; M &gt; F (backbone)", where "P", "M" and "F" are taken from the first letters of pre-training, meta-training and fine-tuning respectively. In this section, we only examine the pre-training and backbone architecture parts with meta-training fixed to ProtoNet. As an example, in <ref type="table" target="#tab_2">Table 2</ref>, we use "DINO &gt; PN (ViT-small)" to denote the pipeline that uses DINO pre-training, ProtoNet meta-training with backbone architecture being ViT-small.</p><p>To clarify the shorten notations in <ref type="table">Table 1</ref>, <ref type="table" target="#tab_2">Table 2</ref> and <ref type="table" target="#tab_9">Table 3</ref>, we make a list here:</p><p>? DINO: self-distillation pre-training on ImageNet-1k dataset by <ref type="bibr">[2]</ref>.</p><p>? BEiT: BERT pre-training on ImageNet-21k dataset by <ref type="bibr">[1]</ref>.</p><p>? CLIP: Contrastive language-image pre-training on YFCC100M dataset by <ref type="bibr">[3]</ref>.</p><p>? Sup21k: Supervised pre-training on ImageNet-21k dataset.</p><p>? Sup1k: Supervised pre-training on ImageNet-1k dataset.</p><p>? BEiT + Sup21k: BERT unsupervised pre-training first on ImageNet-21k dataset and then using the labels of ImageNet-21k to fine-tune the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Additional results for miniImageNet and CIFAR-FS</head><p>We also evaluate different pre-training methods and backbones on miniImageNet and CIFAR-FS, which is shown in <ref type="table" target="#tab_7">Table 4</ref>. We do not include some of the results to the main paper because supervised pre-training on ImageNet is only useful to check the upper bound performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Ablation study on fine-tuning's hyper-parameters</head><p>There are three hyper-parameters for the fine-tuning stage: the learning rate, the number of gradient descent steps and the probability of switching on data augmentation for the support set. We show in <ref type="figure" target="#fig_1">Figure 1</ref> that the dominant hyper-parameter is the learning rate. From the results, we also see that the higher the probability of switching on data augmentation the better, while 50 gradient steps give relatively good performance with the right learning rate. Therefore, we fix the probability to 0.9 and let the numbers of steps to be 50 in the fine-tuning phase. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">T-SNE plots: before and after meta-training</head><p>By using T-SNE visualization, We identify that the feature representation of DINO pre-training is already of high quality in multiple domains. Three examples are shown in <ref type="figure">Figure 2</ref>, <ref type="figure" target="#fig_8">Figure 3</ref> and <ref type="figure">Figure 4</ref>. In general, many semantic clusters have already emerged, even though these domains where the clusters are sitting are not necessarily similar to ImageNet. This gives a very good initialization to ProtoNet so that it can refine the clusters to be much tighter. While the situation would be quite different if we were training the ProtoNet from scratch, which are confirmed by the no-pre-training results in <ref type="table" target="#tab_9">Table 3</ref>. This can be explained in the sense of K-means clustering, where a good initialization is always desired.   <ref type="table" target="#tab_7">13  13  13 13  13  13  13 13  13  13   13  13   13   13  13  13  13   13  13  13 13  13  13  1313   13   13   13  13   13   13 13  13  13 13  13  13  13   13 13  13   13  13  13  13 13  13  13  13   13  13  13  13   13   13   13   13 13  13  13   13  13 13  13  13  13 13  13   13  13   13  13  13  13 13   13   13  13  13   13  13  13 13   13  13  13   13  13  13 13 13  13 13  13  13  14</ref>   <ref type="table" target="#tab_2">20  20  20  20  20  20  20  22   22   22  22  22 22  22  22  22  22 22  22  22  22   22   22   22  22  22  22   22   22   22   22  22  22  22 22  22  22  22  22   22   22   22   22   22  22 22  22  22  22 22 22   22  22  22  22  22  22   22  22 22  22  22  22 22  27  27 27  2727 27  27  27 27</ref>   <ref type="table" target="#tab_2">12   13 13  13 13  13  13  13  13  13 13 13 13  13  13  13   13   13  13   13   13  13  13  13  13 13  13  13  13   13   13  13 13  13  13  13  13  13  13  13   13   13 13   13 13  13  13  13   13  13  13  13 13  13 13  13  13   13   13  13 13  20</ref>     <ref type="table" target="#tab_2">21  21  21  21 21  21  21 21 21  21  21 21  21 21  21  21  21  21 21  22 22 22  22   22  22  22  22   22   22  22  22   22  22 22  22   22  22  22  22  27  27  27  27   27   27  27  27 27  27  27  27  27 27  27  27 27  27  27 27   28  28 28 28 28  28 28  28 28 28  28 28 28  28 28 28  28 28 28  28   29  29 29  29  29 29 29  29  29 29  29 29  29  29  29  29 29 29  29 29  30  30  30 30  30 30  30 30  30 30  30 30 30  30 30  30 30  30 30 30   31  31 31  31 31  31 31  31  31 31  31  31  31 31  31  31  3131  31  31  46  46  46  46   46   46 46  46 46 46  46 46  46  46  46 46   47  47</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meta-training</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Algorithm 1</head><label>1</label><figDesc>PyTorch pseudo code for fine-tuning # Inputs: a task including supp_x, supp_y, query_x # backbone_state: meta-trained backbone weights #</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>[ 8 ]</head><label>8</label><figDesc>is created by dividing the original CIFAR-100 into 64 training, 16 validation and 20 testing classes. The images are of size 32?32. Meta-Dataset [65] subsumes 10 public image datasets of a diverse range of domains: ImageNet-1k, Omniglot, FGVC-Aircraft, CUB-200-2011, Describable Textures, QuickDraw, FGVCx Fungi, VGG Flower, Traffic Signs and MSCOCO.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>+ PN (IN) M2: DINO + PN (IN) + FT M5: DINO + PN (MD)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 .</head><label>1</label><figDesc>Ablation study of fine-tuning's hyper-parameters -The experiments are done in the validation set of the traffic sign domain and the MSCOCO domain with learning rate fixed to either 0.001 or 0.01.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3</head><label>3</label><figDesc>Figure 3. CUB domain</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>From the results inTable 1we can draw the following conclusions: (i) Pre-training on ImageNet1K generally provides a significant improvement across the board compared to the conventional pipeline used by prior work which does not make use of pretraining (compare model M9 with M7 and M8, etc). (ii) We are primarily interested in unsupervised pre-training, with supervised pre-training being included as an unfair upper bound. However, state of the art unsupervised pre-training with DINO performs close to supervised pre-training (compare M3 vs M2, etc). This is noteworthy, because while there is some semantic overlap between some of the source (ImageNet1K) and target (Meta-Dataset, miniImageNet, CI-FAR) datasets considered here, good performance can be achieved without using source labels, where there is no traintest label leakage 1 . (iii) Given a strong pre-training regime such as DINO, simple nearest centroid classification based on pre-trained features performs well (top block including M2, etc). In particular, off-the-shelf features from a foundation model without dataset-specific meta-learning perform favorably compared to conventional dataset-specific training of ProtoNet-ResNet18 (M2 vs M10), which is arguably the closest to industry standard in FSL. (iv) Nevertheless, dataset specific meta-learning does improve further (M7 vs M2, etc).</figDesc><table><row><cell>Simple linear readout of a frozen foundation model [18, 27] is not competitive.</cell></row></table><note>1 How does pre-training regime affect FSL?2 Can state of the art architectures such as ViT be adapted to FSL? Using the results in Table 1, we can also answer this question. In particular, while ViT does not train well on the smaller meta-train benchmarks (miniIma- geNet, CIFAR) compared to smaller architectures (see M6 vs M9, M10), it generally performs excellently when bene- fiting from large pre-training data (M6 vs M4). Overall ViT outperforms the industry standard ResNet18, as well as our ResNet50 baseline, across the board when benefitting from pre-training.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Impact of architecture and pre-training on state-of-the-art few-shot learners: MetaQDA<ref type="bibr" target="#b72">[72]</ref>, MetaOptNet<ref type="bibr" target="#b41">[42]</ref>.</figDesc><table><row><cell></cell><cell></cell><cell>Train Config</cell><cell></cell><cell>Benchmark</cell></row><row><cell cols="2">ID Arch</cell><cell>Pre Train</cell><cell>MetaTr</cell><cell>miniIN 5/1 5/5 5/1 5/5 CIFAR</cell></row><row><cell>0 1</cell><cell cols="3">ViT-small DINO (IN1K) -ViT-small DINO (IN1K) ProtoNet</cell><cell>88.8 97.0 59.1 79.8 93.1 98.0 81.1 92.5</cell></row><row><cell>2 3</cell><cell cols="4">ResNet18 -ViT-small DINO (IN1K) MetaQDA 92.0 97.0 77.2 90.1 MetaQDA 65.1 81.0 --</cell></row><row><cell>4 5</cell><cell cols="4">ResNet12 -ViT-small DINO (IN1K) MetaOptNet 92.2 97.8 70.2 84.1 MetaOptNet 64.1 80.0 72.8 85.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 ,</head><label>2</label><figDesc></figDesc><table /><note>we can see that: (i) MetaQDA and MetaOptNet do improve on direct feature transfer (M5 and M3 vs M0) and on the simpler ResNet features they were initially evaluated with (M5 vs M4, M3 vs M2). But (ii) With the stronger features, they are outperformed by the simpler ProtoNet learner (M3 and M5 vs M1). This suggests previous con- clusions about comparative meta-learner performance may need re-evaluating in this new regime of stronger features.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 .</head><label>4</label><figDesc></figDesc><table /><note>miniImageNet &amp; CIFAR -Comparison with represen- tative SOTA FSL algorithms. Methods using external data and/or labels are indicated.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 3 .</head><label>3</label><figDesc>Meta-training results on Meta-Dataset -Comparison of different pre-training methods and backbone architectures.</figDesc><table><row><cell>INet</cell><cell cols="7">Omglot Acraft CUB DTD QDraw Fungi Flower Sign</cell><cell>COCO Avg</cell></row><row><cell cols="2">DINO (ViT-small) DINO (ViT-base) BEiT (ViT-base) CLIP (ViT-base) DINO (ResNet50) CLIP (ResNet50) Sup21k (ViT-base) BEiT + Sup21k (ViT-base) 33.85 23.95 73.48 54.33 74.85 59.44 17.12 23.96 60.66 62.12 64.13 52.51 51.67 44.16 67.00 37.02 Sup1k (ViT-base) 89.1 60.71 Sup1k (ResNet50) 76.22 47.31</cell><cell cols="2">62.17 55.36 17.21 54.08 57.02 44.18 47.72 33.92 55.36 55.75</cell><cell cols="2">85.37 83.67 60.59 80.08 84 59.61 18.59 39.79 23.89 80.26 76.51 62.90 62.63 84.5 60.78 70.2 70.64 47.88 82.9 79.77 52.25 52.07 63.79 32.60 79.8 79.75 61.28 76.40 80.40 51.26</cell><cell>56.26 94.45 56.65 94.84 13.69 45.81 30.76 68.43 50.41 92.18 34.13 87.97 41.98 95.7 28.19 67.3 47.45 88.44 43.42 85.48</cell><cell>53.7 51.81 57.1 54.58 16.16 16.36 47.33 41.95 58.27 55.43 39.59 41.63 46.22 53.46 27.18 29.65 56.3 57.20 50.46 57.10</cell><cell>67.86 67.374 23.258 58.5 63.786 53.205 60.402 39.25 67.539 62.38</cell></row><row><cell cols="8">Table 1. Pre-training results on Meta-Dataset -Comparison of different pre-training methods and backbone architectures.</cell></row><row><cell cols="2">In-domain INet</cell><cell cols="6">Out-of-domain Omglot Acraft CUB DTD QDraw Fungi Flower Sign</cell><cell>COCO Avg</cell></row><row><cell>DINO &gt; PN (ViT-small) DINO &gt; PN (ViT-base) CLIP &gt; PN (ViT-base) DINO &gt; PN (ResNet50) CLIP &gt; PN (ResNet50) Sup21k &gt; PN (ViT-base) BEiT+Sup21k &gt; PN (ViT-base) 84.39 74.69 76.69 76.03 67.08 69.41 85.88 Sup1k &gt; PN (ViT-base) 90.48</cell><cell></cell><cell>56.91 62.2 59 49.21 60.72 39.72 60.54 62.96</cell><cell cols="2">60.5 54.76 65.75 58.46 57.53 52.03 74.04 54.89</cell><cell>85.04 84.21 61.54 81.58 84.48 60.64 90.2 83.08 65.45 72.08 85.01 59.2 83.66 80.03 55.58 94.54 83.42 54.58 95.66 86.14 65.24 78.88 80.02 61.81</cell><cell>54.78 94.57 55.93 95.14 53.2 96.35 50.53 89.91 50.07 93.39 57.06 99.01 64.25 99.19 45.52 88.56</cell><cell>54.21 57.35 56.81 60.27 58.65 61.2 55.44 53.94 48.56 50.14 47.74 69.02 63.02 69.91 55.61 59.12</cell><cell>68.38 68.85 70.891 64.086 64.909 68.3 76.238 67.785</cell></row><row><cell cols="8">Table 2. Meta-training results on Meta-Dataset (ImageNet only) -Comparison of different pre-training methods and backbone architec-tures.</cell></row><row><cell>INet</cell><cell cols="7">In-domain Omglot Acraft CUB DTD QDraw Fungi Flower Sign Out-of-domain COCO Avg</cell></row><row><cell cols="3">DINO &gt; PN (ViT-small) DINO &gt; PN (ViT-base) CLIP &gt; PN (ViT-base) DINO &gt; PN (ResNet50) CLIP &gt; PN (ResNet50) Sup21k &gt; PN (ViT-base) BEiT+Sup21k &gt; PN (ViT-base) 81.96 94.19 73.54 91.79 73.55 91.54 74.76 92.26 63.7 85.91 64.86 92.09 84.86 85.71 Sup1k &gt; PN (ViT-small) 83.87 91.22 Sup1k &gt; PN (ViT-base) 89.75 93.48 Sup1k &gt; PN (ResNet50) 68.04 86.17 None &gt; PN (ViT-small) 37.25 74.14 None &gt; PN (ResNet50) 40.74 90.67</cell><cell>88.33 89.73 91.42 80.3 89.19 83.77 91.62 87.9 91.15 80.72 45.25 80.67</cell><cell></cell><cell>91.02 81.64 79.23 92.94 81.52 80.2 93.55 80.97 80.8 81.67 82.69 72.84 89.17 71.67 78.71 95.89 85.1 78.47 93.76 81.3 83.48 89.2 78.11 78.7 92.48 78.52 80.65 80.48 71.65 70.78 49.66 61.49 70.24 68.88 62.4 75.96</cell><cell>74.2 78.28 94.53 94.12 79.13 95.64 60.03 91.75 76.15 91.25 74 99.17 81.76 98.84 70.33 94 75.97 95.78 59.58 84.33 43.23 72.03 55.72 75.37</cell><cell>54.37 57.04 53.65 59.13 54.52 56.8 54.26 50.67 51.1 45.88 59.86 67.57 58.83 61.81 56.24 57.16 53.47 55.89 50.06 50.29 39.33 35.43 43.11 35.49</cell><cell>78.528 79.507 79.985 72.382 75.007 81.44 82.755 78.673 80.714 70.21 52.805 62.901</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>28 28 28 28 2828 28 28 28 28 28 28 28 28 28 28 28 28 28 28 29 29 29 29 29 29 29 29 2929 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 2929 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29 29</head><label></label><figDesc></figDesc><table><row><cell>27</cell><cell>28</cell></row><row><cell>27</cell><cell></cell></row><row><cell cols="2">22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 22 23 23 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 2727 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28 28</cell></row><row><cell>27</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">+ 2 How does pre-training and architecture impact other Few-Shot Learners? Our main experiments built upon ProtoNet as a widely used industry standard. We next</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank the anonymous reviewers and meta-reviewers of CVPR2022 for their careful reading and thorough discussion of our manuscript. We also thank our colleagues at SAIC-Cambridge, especially Gabor Gyorkei, Taekwon Jang and Brais Martinez, for their help and support.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 12 <ref type="bibr" target="#b11">12</ref>   <ref type="table">1   1  2  2 2  3  3 3  3  33   3   3  3  3 3  3 3   3   3   3   3  3  3   3  3  3  3   3  3  3   3   3  3  3   3   3   3  3 3  3   3  3 3  3 3  3  3  3  3   3   3   3 3  3  3 3  3 3  3</ref>   <ref type="table">1  3 3  3  3  3  3 3  3  3 3  3  3   3 3   3   3  3 3  3   3   3  3  3  3  33 3   3   3  3  3  3   3   3  3  3 3 3  3  3  3  3  3 3   3  3  3  3  3  3  3  3 3  3  3  3</ref>   88 88 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 1111 11 <ref type="bibr" target="#b10">11</ref>   <ref type="table">19   19  19  19  19 19  19  19  19  19  19  19  19  19  19  19  19  19 19  19  19  19  19  19   19  19   19  19  21  21  21 21  21   21   21   21  21 21  21 21  21  21   21   21  21   21   21  21 21   21   21  21  21 21  21   21  21   21  21  21   21   21 21   21   21  21  21 21  21 21  21  21 21   21   21   21   21   21 21  21  21   21   21  21  21  21  21   21  23  23  23 23  23   23   23 23  23  23   23  23   23  23  23  23  23  23   23   23   23  23  23  23  23  23  23  23  23  23   23  23   23  23  23   23  23  23  23 23  23   23   23 23  23  23 23  23   23   23  23  23   23   23   23   23   23  23</ref>    <ref type="table">2 2 2  2 2  2  2  2  2 2  2 2 2  2 222 2 2  2   3  3 3  3  3 3 3  3  3  3 3  3   3  3  3  3   3  3  3</ref>   <ref type="table">23  23  23  23  23  23  23  23  23  23  23 23  23  23 23 23  23  23  23   24</ref>  37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 37 38 38 38 <ref type="table">38 38  38  38  38 38 38  38  38 38 38 38  38 38  38 38  38   39  39 39  39 39 39  39 39  39 39 39 39  39 39 39  39  39  39 39  39  40  40  40  40  40 40 40  40  40 40  40 40 40  40 40  40 40 40  40  40   41  41  41  41 41  41  41  4141 41  41  41  41  41  41 41  41  41 41  41  42 42  42  42 42  42  42  42 42 42  42  42 42 42 42  42 42  42  42 42   43  43  43  43  43 43  43  43 43  43  43 43  43 43  43  43  43 43  43</ref>  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Cross-domain few-shot learning by representation fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Brandstetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Widrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Kreil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kopp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?nter</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<idno>arXiv, 2021. 8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Rich semantics improve few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Afham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Haris</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muzammal</forename><surname>Naseer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad Shahbaz</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Abdelrahman Mohamed, and Michael Auli. wav2vec 2.0: A framework for self-supervised learning of speech representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Meta-learning with taskadaptive loss function for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungyong</forename><surname>Baik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janghoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dohee</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesik</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Meta-learning with adaptive hyperparameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungyong</forename><surname>Baik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myungsub</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janghoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heewon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Beit: Bert pre-training of image transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangbo</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<idno>ICLR, 2022. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Enhancing few-shot image classification with unlabelled examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyman</forename><surname>Bateni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jarred</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Willem</forename><surname>Van De Meent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV, 2022</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable closedform solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning feed-forward oneshot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Valmadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">On the opportunities and risks of foundation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Drew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russ</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simran</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sydney Von Arx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeannette</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brunskill</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.07258</idno>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Few-shot learning for decoding brain signals. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myriam</forename><surname>Bontonou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Farrugia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Gripon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Reminder of the first paper on transfer learning in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stevo</forename><surname>Bozinovski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Informatica</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">2020</biblScope>
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Tom B Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Askell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Emerging properties in self-supervised vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Self-supervised learning for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Da</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuefeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML, 2020. 3</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Big self-supervised models are strong semi-supervised learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A closer look at few-shot classification. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Meta-baseline: Exploring simple meta-learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinbo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huijuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Avinash Ravichandran, and Stefano Soatto. A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guneet</forename><surname>Singh Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Chaudhari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Crosstransformers: spatially-aware few-shot transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankush</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2021. 3, 5</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR, 2021. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Selecting relevant features from a multi-domain representation for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Dvornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">How well do self-supervised models transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linus</forename><surname>Ericsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Gouk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2021. 3</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Self-supervised representation learning: Introduction, advances and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linus</forename><surname>Ericsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Gouk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>IEEE Signal Processing Magazine</publisher>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Boosting few-shot visual learning with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Scaling and benchmarking self-supervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Guo</surname></persName>
		</author>
		<title level="m">Overlap between imagenet and cub</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A broader study of cross-domain few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhui</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Karlinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tajana</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Rosing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Feris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020. 3, 4</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Meta-learning in neural networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Micaelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Empirical bayes transductive meta-learning with synthetic gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Shell Xu Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Damianou</surname></persName>
		</author>
		<idno>ICLR, 2020. 7</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Leveraging the feature distribution in transfer-based few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Gripon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Pateux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICANN, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Pseudo-loss confidence metric for semi-supervised few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Self-supervised visual feature learning with deep neural networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A flash-based multi-bit content-addressable memory with euclidean squared distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Kazemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubham</forename><surname>Sahay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayush</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Mehdi</forename><surname>Sharifi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Niemier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">Sharon</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/ACM International Symposium on Low Power Electronics and Design</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brenden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Improving task adaptation for cross-domain few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Hong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xialei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hakan</forename><surname>Bilen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.00358</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Universal representation learning from multiple domains for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Hong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xialei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hakan</forename><surname>Bilen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning to self-train for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinzhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianru</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoyao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibao</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Tat-Seng Chua, and Bernt Schiele</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Fewshot few-shot learning and the role of spatial attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lifchitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Avrithis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvaine</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 25th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2693" to="2700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">A universal representation transformer layer for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<idno>ICLR, 2021. 8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning to propagate labels: Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minseop</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saehoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunho</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung</forename><forename type="middle">Ju</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Fine-grained visual classification of aircraft</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esa</forename><surname>Rahtu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.5151</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Charting the right manifold: Manifold mixup for fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puneet</forename><surname>Mangla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nupur</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayank</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vineeth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balasubramanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Self-training for few-shot transfer across extreme task differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Cheng Perng Phoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML, 2021. 1</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Meta-learning for semi-supervised fewshot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell Sachin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Fast and flexible multi-task classification using conditional neural adaptive processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Requeima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bronskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Embedding propagation: Smoother manifold for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issam</forename><surname>Pau Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Laradji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Drouin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lacoste</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Optimized generic feature learning for few-shot classification across domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<idno>arXiv, 2020. 8</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Revisiting unreasonable effectiveness of data in deep learning era</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Yfcc100m: The new data in multimedia research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Thomee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Friedland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Elizalde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Poland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damian</forename><surname>Borth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="64" to="73" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Rethinking few-shot image classification: a good embedding is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Learning a universal template for fewshot dataset generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Meta-dataset: A dataset of datasets for learning to learn from few examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Utku</forename><surname>Evci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carles</forename><surname>Gelada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">The caltech-ucsd birds-200-2011 dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note type="report_type">Tech. Report</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Simpleshot: Revisiting nearest-neighbor classification for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Generalizing from a few examples: A survey on fewshot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lionel</forename><forename type="middle">M</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">How transferable are features in deep neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hod</forename><surname>Lipson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Adargcn: adaptive aggregation gcn for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manli</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3482" to="3491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Shallow bayesian meta learning for real-world few-shot recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gouk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV, 2021. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Beit: Bert pre-training of image transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hangbo</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Emerging properties in self-supervised vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
