<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Advance Access Publication Date: Day Month Year Application Note Data and text mining Enhancing Label Consistency on Document-level Named Entity Recognition Associate Editor: XXXXXXX Received on XXXXX; revised on XXXXX; accepted on XXXXX</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minbyul</forename><surname>Jeong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<postCode>02841</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<postCode>02841</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Interdisciplinary Graduate Program in Bioinformatics</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">AIGEN Sciences</orgName>
								<address>
									<postCode>04778</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Advance Access Publication Date: Day Month Year Application Note Data and text mining Enhancing Label Consistency on Document-level Named Entity Recognition Associate Editor: XXXXXXX Received on XXXXX; revised on XXXXX; accepted on XXXXX</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1093/bioinformatics/xxxxxx</idno>
					<note>&quot;main&quot; -2022/10/25 -0:49 -page 1 -#1 Bioinformatics * To whom correspondence should be addressed. Contact: kangj@korea.ac.kr Supplementary information: Supplementary data are available at Bioinformatics online.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Named entity recognition (NER) is a fundamental part of extracting information from documents in biomedical applications. A notable advantage of NER is its consistency in extracting biomedical entities in a document context. Although existing document NER models show consistent predictions, they still do not meet our expectations. We investigated whether the adjectives and prepositions within an entity cause a low label consistency, which results in inconsistent predictions. In this paper, we present our method, ConNER, which enhances the label dependency of modifiers (e.g., adjectives and prepositions) to achieve higher label agreement. ConNER refines the draft labels of the modifiers to improve the output representations of biomedical entities. The effectiveness of our method is demonstrated on four popular biomedical NER datasets; in particular, its efficacy is proved on two datasets with 7.5-8.6% absolute improvements in the F1 score. We interpret that our ConNER method is effective on datasets that have intrinsically low label consistency. In the qualitative analysis, we demonstrate how our approach makes the NER model generate consistent predictions. Availability and implementation: Our code and resources are available at https://github.com/dmislab/ConNER/.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named entity recognition (NER) is the task of determining entity boundaries and classifying categories of named entities. NER is a fundamental part of biomedical applications <ref type="bibr" target="#b12">(Kim et al., 2019;</ref><ref type="bibr" target="#b30">Wei et al., 2019;</ref><ref type="bibr" target="#b15">Lee et al., 2020a;</ref><ref type="bibr" target="#b29">Weber et al., 2021;</ref><ref type="bibr" target="#b19">Lewis et al., 2021;</ref><ref type="bibr" target="#b27">Sung et al., 2022)</ref>. In the general domain, recent studies have attempted to train and evaluate NER models in a document-level context <ref type="bibr" target="#b32">(Yu et al., 2020;</ref><ref type="bibr" target="#b31">Yamada et al., 2020;</ref><ref type="bibr" target="#b28">Wang et al., 2021;</ref><ref type="bibr" target="#b7">Gui et al., 2021)</ref>. Likewise, the biomedical domain has shifted its focus on evaluating document contexts rather than sentence contexts <ref type="bibr" target="#b30">(Wei et al., 2019;</ref><ref type="bibr" target="#b28">Wang et al., 2021;</ref><ref type="bibr" target="#b29">Weber et al., 2021)</ref>.</p><p>There are several advantages of using document NER models: (1) The models suggest a better way to bridge the gap between research and application fields. Following previous studies, several researches have leveraged sentence NER models in biomedical domains <ref type="bibr" target="#b0">(Cho and Lee, 2019;</ref><ref type="bibr" target="#b22">Perera et al., 2020;</ref><ref type="bibr" target="#b10">Jeong and Kang, 2021)</ref>. However, biomedical applications require an evaluation of the document rather than the sentence context <ref type="bibr" target="#b30">(Wei et al., 2019;</ref><ref type="bibr" target="#b12">Kim et al., 2019;</ref><ref type="bibr" target="#b29">Weber et al., 2021;</ref><ref type="bibr" target="#b27">Sung et al., 2022)</ref>. (2) Document NER models provide proper and consistent predictions owing to context completeness. Recent works <ref type="bibr" target="#b31">(Yamada et al., 2020;</ref><ref type="bibr" target="#b28">Wang et al., 2021;</ref><ref type="bibr" target="#b7">Gui et al., 2021)</ref> have shown that using document contexts improves the accuracy of the models. Although the authors of <ref type="bibr" target="#b7">(Gui et al., 2021)</ref> used powerful context representations such as BERT <ref type="bibr" target="#b3">(Devlin et al., 2018)</ref> or ELMo <ref type="bibr" target="#b23">(Peters et al., 2018)</ref>, their inability to model document-level label consistency resulted in insufficient performance. Therefore, it is challenging to understand which factors contribute to creating document NER models that produce a consistent prediction in the same manner.</p><p>To tackle the above challenges, a series of studies <ref type="bibr" target="#b5">(Fu et al., 2020</ref><ref type="bibr" target="#b6">(Fu et al., , 2021</ref> have provided an interpretable evaluation to identify the attributes of datasets depending on their characteristics. Our intuitive motivation  <ref type="bibr" target="#b16">(Lee et al., 2020b)</ref> and BioLM <ref type="bibr" target="#b17">(Lewis et al., 2020a)</ref> to compare the predictions between different context levels. We report the F1 score to evaluate the models. is that entity-aware attributes are beneficial for achieving higher label consistency, which can also improve the accuracy of the NER models. In this paper, our goal is to develop a NER model that can be trained to predict an entity consistently in a document context. We first clarify why we need the NER model to make consistent predictions. We provide our motivating example in <ref type="figure">Figure 1</ref>. For example, the mention 'colorectal cancer' is an entity of the disease type. Predicting such a mention is challenging in a sentence context owing to context incompleteness. As a result, the sentence model produces an error in predicting 'non -FAP' or 'colorectal'. Meanwhile, the NER model trained on document contexts shows consistent predictions because the token 'colorectal' occurs frequently within the documents. Therefore, the document provides sufficient label agreement to learn label representations of 'colorectal'. Although the document NER model shows consistent predictions and much better performance than the sentence NER model <ref type="table">(Table 1)</ref>, it still falls behind our expectations. Models trained on document contexts continue to produce 64% errors that contain modifiers (i.e., prepositions or adjectives), such as primary, hereditary, and congenital <ref type="table">(Table 7)</ref>. Because modifiers are used as both entity and non-entity tokens depending on the context situation, they are difficult to predict. Therefore, the modifiers exhibit a low label consistency score and occur at short entity lengths ( <ref type="figure" target="#fig_0">Figure 2)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context</head><p>To avoid the aforementioned errors, we present ConNER which enhances the label dependency of modifiers to achieve higher label agreement. An abstract of biomedical literature is fed into the biomedical pre-trained language model, BioBERT <ref type="bibr" target="#b16">(Lee et al., 2020b)</ref> or BioLM <ref type="bibr" target="#b17">(Lewis et al., 2020a)</ref>, to output context representation (Section 3.1). On top of the pre-trained language model, we propose label refinement to improve the label representations of uncertain tokens within entities (Section 3.2). We also suggest our loss term for biomedical entities to resemble the label representations on two different architectures: fully connected layers (MLP) and bidirectional long-short term memory (BiLSTM) architecture. We use MLP as the main classification layer to generate final output representations of raw text and use the BiLSTM architecture to generate label representations of biomedical entities. We adopt the notion that the MLP layer is more robust to long entities <ref type="bibr" target="#b13">(Lafferty et al., 2001)</ref>, which is an essential property of biomedical entities. We employ the BiLSTM architecture to improve the label dependency of biomedical entities <ref type="bibr" target="#b1">(Collobert et al., 2011;</ref><ref type="bibr" target="#b14">Lample et al., 2016)</ref>. To demonstrate the effectiveness of the proposed ConNER approach, we use four biomedical benchmarks. On three datasets, we achieve a higher F1 score than previous state-of-the-art models <ref type="bibr" target="#b28">(Wang et al., 2021;</ref><ref type="bibr" target="#b17">Lewis et al., 2020a)</ref>. In particular, our model achieves higher label agreement and proves its efficacy on two datasets with 7.5-8.6% absolute improvements in the F1 score (Section 4.4). We provide an interpretation of the effectiveness of our method for a dataset that intrinsically has a low label consistency score (Section 5.2).</p><p>The contributions of this study are summarized as follows.</p><p>(1) We investigate why document NER models make inconsistent predictions in biomedical domains. Based on our observations, we observe that modifiers (i.e., adjectives and prepositions) exhibit a low label consistency score and produce errors by making inconsistent predictions. (2) We present our method, ConNER, which enhances the label dependency of modifiers to generate improved label representations. (3) The results of the experiments show that our ConNER approach significantly improves the accuracy of document NER models, indicating that it can help achieve the highest level of label agreement. (4) For different tasks related to low label consistency, we show that ConNER outperforms various baselines, and we analyze the factors influencing its performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Named Entity Recognition</head><p>The goal of NER is to find a word or phrase that corresponds to a specific instance, such as a person, location, organization, or any other miscellaneous entity. The NER task primarily involves the extraction and classification of named entities found in a corpus with pre-defined entity tags. We use BIO tagging <ref type="bibr" target="#b26">(Ramshaw and Marcus, 1999)</ref>, where a B-  prefix (Beginning) indicates the beginning of the chunk following an Iprefix (Inside), and an O-prefix (Outside) indicates being inside and not belonging to the chunk. The task commonly uses two different decoding strategies: tag-independent decoding (i.e., MLP <ref type="bibr" target="#b1">(Collobert et al., 2011)</ref>) and tag-dependent decoding (i.e., CRF <ref type="bibr" target="#b13">(Lafferty et al., 2001;</ref><ref type="bibr" target="#b14">Lample et al., 2016)</ref>). Here, we use only the tag-independent decoding strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Attribute Definition</head><p>Following previous works <ref type="bibr" target="#b5">(Fu et al., 2020</ref><ref type="bibr" target="#b6">(Fu et al., , 2021</ref>, we define the term attribute as a value that characterizes the properties of an entity that may be correlated with performance. The authors introduced attributes bridging the gap between the final performance (we use the F1 score) and interpretable evaluation based on model predictions. Assuming that one attribute is given, the test set of NER tasks naturally partitions into several interpretable buckets, we investigate whether the attribute affects the final performance bucket-wise. Formally, we define notations to facilitate the definition of attributes. Given a set of documents D, entity tagging aims to extract a set of entities E as spans or tokens. We first denote a span set E tr ? E as an argument. Specifically, <ref type="bibr" target="#b5">(Fu et al., 2020)</ref> introduced a feature function ?(?) to aggregate features to interpret the properties of tagged entities E tr :</p><formula xml:id="formula_0">F (x, ?(?), D(E)) = |{?|?(?) = ?(x), ?? ? D(E)}| |D(E)| ,<label>(1)</label></formula><p>where x denotes an entity span that can also replace it as token x. Similarly, we define some training set-independent attribute functions as follows:</p><formula xml:id="formula_1">? tLen (x) = |x| : token span length (2) ? eLen (x) = |x| : entity span length (3) ? dLen (x) = |doc(x)| : document length (4) ? eDen (x) = |ent(doc(x))|/? dLen (x) : entity density (5) ? oDen (x) = |oov(doc(x))|/? dLen (x) : OOV density<label>(6)</label></formula><p>Rather than using a sentence-level context, we provide a document-length attribute based on the usage of the document-level context. We use two functions to define the density of entity ent(?), which counts the number of entity words, and the density of out-of-vocabulary words oov(?), which counts the number out of training set words. We also leverage the training set-dependent attribute functions, as follows:</p><formula xml:id="formula_2">? tF re (x) := F (x, ?str(?), D(E tr )) : token frequency (7) ? eF re (x) := F (x, ?str(?), D(E tr )) : entity frequency (8) ? tCon (x) := F (x, ? label (?), D(E tr )) : label consistency of token (9) ? eCon (x) := F (x, ? label (?), D(E tr ))</formula><p>: label consistency of entity (10) where ?str(?) and ? label (?) denote a string and label of the corresponding argument, respectively, and ? tCon (x) and ? eCon (x) refer to measuring how consistently a certain token or entity span is assigned to a predefined label, respectively. Here, we define label consistency as the degree of label agreement of n tokens/entities in the training set. We use attribute functions to interpret which dataset attributes have an impact on performance improvement <ref type="figure" target="#fig_1">(Figure 3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In this section, we start by learning the document-level model through the supervision of named entity recognition tasks. Our goal is to learn how to enrich the label representations of biomedical entities by improving their label consistency (Section 3.1). We then introduce our label refinement on biomedical entities, which encourages label representations of uncertain tokens within entities (Section 3.2). Finally, we discuss the use of a loss term for biomedical entities to resemble the label representations of two different architectures. <ref type="figure" target="#fig_3">Figure 4</ref> depicts the overall structure of ConNER approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Document Named Entity Recognition</head><p>ConNER consists of a pre-trained language model M LM and labelrefinement process, as shown in <ref type="figure" target="#fig_3">Figure 4</ref>. For document tagging, we use abstracts of biomedical literature as raw input and make predictions for each word. Let D i = {T i1 , T i2 , ..., T iN } represent a sequence of tokens, where N denotes the total number of tokens in a document D i . First, we apply a biomedical pre-trained language model (e.g., BioBERT <ref type="bibr" target="#b16">(Lee et al., 2020b)</ref> or BioLM <ref type="bibr" target="#b17">(Lewis et al., 2020a)</ref>) to obtain contextualized word representations for each token: T i1 , T i2 , ..., T iN ? R d . Then, we represent a biomedical entity e as the concatenation of start-to-end vector  <ref type="table" target="#tab_3">Ti+1  Ti  Ti+2  Ti+3  Ti+4  Ti+7  Ti+8  Ti+9  Ti+10  Ti+11  Ti+12</ref> Label Refinement In the label-refinement process, we use a mask tensor M ASK to find the position of biomedical entities and feed it into the BiLSTM architecture M LST M to improve label dependency of modifiers within entities that induce low label agreement. On top of the fully connected layer, we compute an uncertainty score U to determine which tokens need to be modified for their predicted label.</p><p>representations, as follows:</p><formula xml:id="formula_3">M LM (e) = [Tstart : T end ] ? R ? eLen (e)?d<label>(11)</label></formula><p>where Tstart and T end denote the start and end of biomedical entity e ? E, respectively, and d denotes the final hidden dimension of language model M LM . Note that we use the notation e as an example to help understand our method ConNER. We use tag-independent decoding (i.e., MLP) on the model M LM as the main classification layer, which is useful for predicting long-named entities <ref type="bibr" target="#b5">(Fu et al., 2020)</ref>. Formally, we can define our classification loss L class using cross-entropy objectives to optimize our model as follows:</p><formula xml:id="formula_4">L class = ? 1 N N j=1 y j ? log(p j )<label>(12)</label></formula><p>where y j denotes the ground-truth label and p j denotes the probability of the main classification layer.</p><p>Sentence vs. Document. In our pilot experiments, we first observe that the label consistency of entity ? eCon (x) is enhanced when we expand the context from sentences to documents. We also observe that using a larger context is helpful in achieving better performance (+1.4-1.8% in F1 score), as shown in <ref type="table">Table 1</ref>. Based on our positive observations, we hypothesize that one key reason for the performance gain is that biomedical entities are challenging to predict at the sentence level owing to context incompleteness. Learning from the limited context makes it difficult to predict a token within an entity such as 'colorectal' (see <ref type="figure">Figure 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Label Refinement on Biomedical Entities</head><p>Overall, we propose a label-refinement process that depends on an entitylength attribute ? eLen (e) to enrich the label representations of the entity spans. To encourage label representations, we add a loss term of the entity span to make the label distribution similar between the main classification layer and the refinement process. We use the MLP layer to obtain a final output representation and both an uncertainty and a draft label for each token representation. We use a BiLSTM architecture <ref type="bibr" target="#b13">(Lafferty et al., 2001)</ref> to improve the label dependency of tokens within biomedical entities and to generate label representations of entities. These label representations from the BiLSTM architecture provide a precise label to the main classification layer by verifying the uncertainty of the draft label (see <ref type="figure">Figure 1</ref>). The independent decoder predicts well for longer entities, especially biomedical entities <ref type="bibr" target="#b5">(Fu et al., 2020</ref><ref type="bibr" target="#b6">(Fu et al., , 2021</ref><ref type="bibr" target="#b10">Jeong and Kang, 2021)</ref>. With the preceding observation, we find that the modifiers (i.e., prepositions or adjectives) are both used as entity and non-entity tokens. We also find that a low label consistency occurs at short lengths of entities (i.e., ? eLen (e) &lt; 5), which most modifiers consist of in this scope. As a result, we attempted to deal with long entities by employing the MLP layer and developing a label-refinement process to target those modifiers to be predicted consistently.</p><p>Uncertainty. We ask the natural question: How can we decide what tokens should be refined? We choose this criterion for the certainty of the draft label on token representations <ref type="bibr" target="#b7">(Gui et al., 2021)</ref>. We calculate the uncertainty U of the probability distributions of the MLP layer as follows:</p><formula xml:id="formula_5">U = H(pc) = ? C c=1 pc log pc.<label>(13)</label></formula><p>where C denotes the number of pre-defined entity types per dataset. We use the entropy of the probability distribution pc to define the uncertainty U . Given this uncertainty score, label refinement proposes a positive training signal to shift the draft label.</p><p>Label Refinement. We decide to improve the label dependency on modifiers (i.e., adjectives or prepositions) used in the entities during training. Specifically, we create an entity-aware mask tensor M ASK ? R B?N ?N to indicate the position of the padded indices such that our model does not attend to non-entities, where B denotes the batch size. The mask tensor is applied to the BiLSTM layers M LST M to obtain a label representation l(e), as follows:</p><formula xml:id="formula_6">l(e) = M LST M {M ASK(M LM (e))} ? R ? eLen (e)?C .<label>(14)</label></formula><p>Then, M LST M trains to softly assist the main classification layer in performing precise predictions with improved consistency. Note that we use the term softly assist to describe a process that assists the main classification layer in shifting its draft label during training. That is, the trained model M LST M enhances the label dependency of an uncertain token and softly assists in refining the draft label of the uncertain token. Formally, we add element-wisely to assist predictions before calculating a label loss L label , as shown below:</p><formula xml:id="formula_7">p = p ? l,<label>(15)</label></formula><formula xml:id="formula_8">L label = ? 1 N N j=1 y j ? log(l j )<label>(16)</label></formula><p>where y j and l j denote the ground-truth label and probability of the M LST M layer, respectively, and p is used to compute the classification loss in Equation <ref type="formula" target="#formula_0">(12)</ref>. Finally, we determine the criterion using the precomputed uncertainty score U in Equation <ref type="formula" target="#formula_0">(13)</ref>. We set an uncertainty threshold ? to distinguish the tokens that should be refined within entities. For example, in <ref type="figure" target="#fig_3">Figure 4</ref>, a token 'colorectal' of the entity 'colorectal cancer' is first predicted as an Outside tag. During training, the token 'colorectal' is converted to a Beginning tag because of the high uncertainty score. We found that ? = 0.3 worked well in practice. See <ref type="figure" target="#fig_6">Figure 5</ref> for an ablation study.</p><p>Distillation. We propose improving the label representations of biomedical entities by distilling knowledge <ref type="bibr" target="#b9">(Hinton et al., 2015)</ref> from our decoding layers. We minimize the Kullback-Leibler divergence between the probability distribution from the tag-independent layer (i.e., MLP) and the tag-dependent layer (i.e., BiLSTM) on top of the biomedical pre-trained language model. The distillation loss was computed as follows:</p><formula xml:id="formula_9">L distill = KL(p||l) + KL(l||p) 2 ,<label>(17)</label></formula><p>where p and l denote the probability distributions of the MLP and BiLSTM layers, respectively. Note that distillation is computed before Equation (15).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Training Objective</head><p>We optimize the three losses altogether to improve the label agreement of the entity through label refinement and distilling knowledge while predicting on the tag-independent layer. Our final loss is computed as follows:</p><formula xml:id="formula_10">L = ? 1 L class + ? 2 L label + ? 3 L distill<label>(18)</label></formula><p>where ? 1 , ? 2 , ? 3 scale the importance of each loss term. We observe that ? 1 = 1, ? 2 = 1e ? 1, and ? 3 = 1e ? 3 exhibit the best performance in our framework. See <ref type="table">Table 5</ref> for an ablation study of the other components.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We use four biomedical NER benchmarks across four entity types: NCBIdisease <ref type="bibr" target="#b4">(Dogan et al., 2014)</ref>, CDR <ref type="bibr" target="#b20">(Li et al., 2016)</ref>, AnatEM <ref type="bibr" target="#b24">(Pyysalo and Ananiadou, 2014)</ref>, and Gellus <ref type="bibr" target="#b11">(Kaewphan et al., 2016)</ref>, following the standard train/dev/test splits for biomedical NER evaluation.</p><p>(1) NCBIdisease <ref type="formula">(</ref>  <ref type="bibr" target="#b21">(Ohta et al., 2012)</ref>, and the other half were drawn from the BioNLP ST'13 Cancer Genetics (CG) task documents <ref type="bibr" target="#b25">Pyysalo et al. (2013)</ref>. <ref type="table" target="#tab_3">Table 2</ref> shows the dataset statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison Methods</head><p>We evaluate the sentence-and document-level contexts and compare ConNER with several neural network models commonly used in biomedical domains. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Implementation Details</head><p>We train ConNER using BioLM <ref type="bibr" target="#b18">(Lewis et al., 2020b)</ref> or BioBERT <ref type="bibr" target="#b16">(Lee et al., 2020b)</ref> to treat biomedical entity types. These two pre-trained language models are commonly used as backbone models in the biomedical domain, and we adopt these models to generate contextualized representations. We set 128 tokens as the maximum sequence length for the sentence-level context and 512 tokens for the document-level context, and tokens with more than the maximum sequence length were truncated. The batch size was set to 32 for the sentence level and 6 for the document level. We select a learning rate in the range {3e-5, 5e-5}. We search for a training epoch in the range {30, 40, 50}. We suggest our total hyperparameter settings in <ref type="table" target="#tab_4">Table 3</ref>. We train our model with a single NVIDIA Titan RTX (24GB) GPU for fine-tuning, and the training time took less than 2 hours. <ref type="table" target="#tab_5">Table 4</ref> reports the results of ConNER approach. To show the effectiveness of ConNER approach, we evaluate our model in the named entity recognition setting in four biomedical domains and compare its performance with that of other methods in different contexts. Compared to previous biomedical NER models, our approach achieves the best performance compared to all other baselines on three datasets: NCBIdisease <ref type="bibr" target="#b4">(Dogan et al., 2014)</ref>, CDR <ref type="bibr" target="#b20">(Li et al., 2016)</ref>, and AnatEM <ref type="bibr" target="#b24">(Pyysalo and Ananiadou, 2014)</ref>. This demonstrates that improving the label agreement of modifiers is effective in a document context. In addition, the performance gap between BioLM and ConNER on AnatEM (74.9 vs. 83.5) and Gellus (57.9 vs. 63.4) shows that the label refinement based on the dataset bias, which has low label consistency, is effective. Although it still lags behind the BiLSTM-CRF model, the gap is reduced. We provide additional ablation studies of ConNER approach in the following sections. <ref type="table">Table 5</ref> shows our ablation result on four biomedical NER benchmarks. We evaluate our approach ConNER by removing its components: 1) distillation (-L distill ) and 2) the label-refinement process (-L label ). The experiments show that ConNER is effective for all four benchmarks. Specifically, we observe that the AnatEM and Gellus datasets show significant improvement, demonstrating that our approach ConNER is effective for datasets with low label consistency on the entities shown in <ref type="figure" target="#fig_1">Figure 3</ref>. We also observe that adding each component consistently improves the recall metrics. These observations correspond to an advantage of ConNER approach, whereby it decides which token should be refined by relying on the uncertainty threshold ?. <ref type="table">Table 6</ref>. A sample prediction of ConNER on the AnatEM and CDR datasets. yellow highlight refers to the correct prediction and red signifies to the wrong prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Ablation studies</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ConNER</head><p>Dataset: AnatEM <ref type="bibr" target="#b24">(Pyysalo and Ananiadou, 2014)</ref> PMID: 10420526 Title: [Histopathologic examination of rectal carcinoma (1) ] Abstract: In patients with rectal carcinoma, the histopathological evaluation of the surgical specimen (2) provides pivotal prognostic and therapeutic information. Important parameters are tumor site, depth of invasion, histological type and grade, pattern of invasion (diffusely infiltrating versus expanding margin (3) ), degree of peritumoral lymphocytic infiltration, and tumor involvement of surgical margins and lymph nodes <ref type="bibr">(3)</ref> . Evaluation of the circumferential (deep, lateral) margin is of utmost importance. It should be labeled with ink in the gross specimen and should be examined histologically using several tissue blocks. The number of lymph node metastases and the total number of lymph nodes examined should be reported. A histological evaluation of the distal mesorectum in its entirety is recommended to detect discontinuous distal mesorectal tumor spread. The histopathological findings should be summarized using the TNM-classification.</p><p>Dataset: CDR <ref type="bibr" target="#b20">(Li et al., 2016)</ref> PMID: 9158667 Title: Thrombotic complications in acute promyelocytic leukemia during all-trans-retinoic acid therapy Abstract: A case of acute renal failure, due to occlusion of renal vessels in a patient with acute promyelocytic leukemia (APL) treated with all-trans-retinoic acid (ATRA) and tranexamic acid has been described recently. We report a case of acute renal failure in an APL patient treated with ATRA alone. This case further supports the concern about thromboembolic complications associated with ATRA therapy in APL patients. The patients, a 43-year-old man, presented all the signs and symptoms of APL and was included in a treatment protocol with ATRA. After 10 days of treatment, he developed acute renal failure that was completely reversible after complete remission of APL was achieved and therapy discontinued. We conclude that ATRA is a valid therapeutic choice for patients with APL, although the procoagulant tendency is not completely corrected. Thrombotic events, however, could be avoided by using low-dose heparin. <ref type="table">Table 7</ref>. Case studies of inconsistent predictions in document NER models. The below case was taken from the NCBI-disease dataset <ref type="bibr" target="#b4">Dogan et al. (2014)</ref>. ? tCon refers to the token label consistency. The predictions of BioLM <ref type="bibr" target="#b17">(Lewis et al., 2020a)</ref>  We also provide an interpretation of the threshold ? (see <ref type="figure" target="#fig_6">Figure 5</ref>). We observe that ? = 0.3 works well in our four benchmarks, except for the Gellus dataset. When ? is higher than 0.6 in the NCBIdisease dataset, the F1 score yields the same results. We analyze the situation in which a biomedical pre-trained language model has already demonstrated stable performance in predicting biomedical entities. We find that ConNER approach does not have to interfere with the predictions of the main classification layer. In contrast, in the Gellus dataset, ? = 0.8 shows the best performance with high precision and recall metrics. The results were found to be steady when we compute five times using different seeds. However, we suggest using ? = 0.3 to achieve a stable performance on all benchmarks.</p><p>We also see if our ConNER approach can improve the label consistency of entities containing modifier tokens. <ref type="table">Table 7</ref> shows the cases of inconsistent predictions in document NER models. We analyze the modifier tokens used as both entity and non-entity tokens depending on the context. For example, in the training dataset of NCBI-disease, the 'primary' token is used as an entity only 11 times out of 100 times (i.e., we denote this 0.11 in <ref type="table">Table 7</ref>). However, the corresponding token has not occurred as an entity in the test dataset. We observe that BioLM trained on document context did not predict consistently on these modifier tokens. Owing to the improvement of label dependency on the tokens within entities, the ConNER approach achieves consistent predictions on the modifier tokens. <ref type="table">Table 6</ref> shows our ConNER prediction on the AnatEM dataset. We investigate which examples could show the advantages and disadvantages of our approach and find three different examples: (1) Our model consistently predict 'rectal carcinoma' mention as an entity. Compared to ConNER prediction, a model without label refinement and distillation process (i.e., ConNER -{L distill ,L label }) predicts 'rectal' as an entity token in the first appearance and as a non-entity token in the second appearance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Qualitative analysis</head><p>(2) Another surprising example is the token 'surgical'. In the training dataset, the 'surgical' token achieved a consistency score of 92.3% in the entity dictionary. In other words, it was mostly used as an entity token, accounting for 92.3% of the total. The ConNER approach performs well in predicting the 'surgical' token as an entity token. As the intention was to enhance the label dependency of adjectives within entities, it surely works well as per our observations. However, ConNER still has several limitations in that it cannot generalize on out-of-density tokens such as 'mesorectum' or 'margin' that never occur in the training dataset. ConNER approach cannot predict these tokens as biomedical entities which is a common situation in real-world scenarios. On comparing the predictions 'peritumoral lymphocytic' and 'lymph nodes', we can see that the subtoken 'lymph' was predicted inconsistently even if they were composed of the same subtoken. After analyzing the reason why 'lymph' subtoken was mispredicted, we interpret that it has a low degree of label agreement in a given paragraph or even in the entire dataset (0.62 of consistency score). In our future work, we will perform an investigation on ways to make ConNER more generalizable in out-of-density tokens and more consistent in inconsistent subtokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we present ConNER approach, which enhances label dependency to construct consistent biomedical NER models in document contexts. We present a label-refinement process and encouragement of label representation to consistently predict biomedical entities. The ConNER approach outperforms existing biomedical NER methods in three biomedical domains while providing a view of connecting dataset attributes with a training framework. We also achieve a powerful performance on low-resource datasets, showing the possibility of adopting our approach for biomedical NER applications. In our future work, we will attempt to handle out-of-density tokens that never occur in the training datasets, which is a common situation in real-world scenarios. We expect that our solution will be more sophisticated by not only using golden paragraphs but also utilizing retrieved contexts based on out-of-density tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Consistent score per entity length. The x-axis denotes the entity length (i.e., ? eLen ), and the y-axis denotes the consistent score (i.e., ? eCon ). Short lengths of entities show low consistent scores due to the low label agreement of the modifier tokens.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Overview of Dataset Biases. Each dot denotes an attribute score of entities. Intuitively, these intrinsic differences in datasets explain what factors have a significant influence on improving performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>non -FAP colorectal cancer . The APC gene was analysed ?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Overview of ConNER performing label refinement on biomedical entities. The abstract of biomedical literature is fed into the pre-trained language model M LM to output context representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc><ref type="bibr" target="#b4">Dogan et al., 2014)</ref> consists of 793 PubMed abstracts with manually annotated disease entities.(2) CDR (Li et al., 2016) contains 1,500 PubMed abstracts manually annotated with disease and chemical entities in the same context. (3) AnatEM (Pyysalo and Ananiadou, 2014) consists of 1,212 PubMed abstract and full-text extracts annotated with 12 anatomical entity types. (4) Gellus (Kaewphan et al., 2016) consists of annotating cell lines in 1,212 documents from PubMed abstracts and PMC full-text extracts. Half of the corpora were drawn from the AnEM corpus</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>(1) B-MTM<ref type="bibr" target="#b2">(Crichton et al., 2017</ref>) developed a multi-task learning model using various biomedical sources annotated with different entity types. (2) BiLSTM-CRF<ref type="bibr" target="#b8">(Habibi et al., 2017)</ref> proposed a combination of word embeddings and LSTM with the CRF decoding strategy in the biomedical domain.(3) BioBERT (Lee et al., 2020b) introduced a biomedical-specific language representation model pre-trained on large-scale biomedical corpora. (4) BioLM (Lewis et al., 2020a) suggested a biomedical-specific language representation model pre-trained on biomedical and clinical corpora. (5) CL-KL and CL-L2 (Wang et al., 2021) proposed a method that can retrieve and select a semantically relevant context using a search engine to improve contextual representations, with the original sentence as a query.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 :</head><label>5</label><figDesc>An analysis of uncertainty threshold ?. The x-axis refers to the threshold ?, and the y-axis denotes the F1 score. The overall results show that ? = 0.3 results in stable performance on the four biomedical benchmarks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Statistics of four biomedical named entity recognition datasets. The CDR dataset suggests two entity types that share the same text. Annotations (Ann.) and Unique Ann. refer to the entire entity and its unique numbers respectively.</figDesc><table><row><cell>Corpora</cell><cell cols="6">Entity Type Documents Sentences Tokens Annotations Unique Ann.</cell></row><row><cell cols="2">NCBI-disease Disease</cell><cell>793</cell><cell>7,142</cell><cell>180,992</cell><cell>6,881</cell><cell>2,502</cell></row><row><cell>CDR</cell><cell>Disease / Chemical</cell><cell>1,500</cell><cell cols="2">14,503 346,019</cell><cell>12,957 / 15,837</cell><cell>4,477 / 3,765</cell></row><row><cell>AnatEM</cell><cell>Anatomic</cell><cell>1,212</cell><cell cols="2">11,809 298,780</cell><cell>13,692</cell><cell>5,042</cell></row><row><cell>Gellus</cell><cell>Cell Lines</cell><cell>1,212</cell><cell cols="2">11,809 312,584</cell><cell>650</cell><cell>243</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Hyperparameters of the four biomedical named entity recognition settings. For common hyperparameter settings, we focus on searching batch size, learning rate, and training epoch for learning schemes. We also focus on searching for the optimal hyperparameters of the uncertainty threshold ?.</figDesc><table><row><cell>Context</cell><cell>Corpora</cell><cell>Pretrained LM</cell><cell>Batch Size</cell><cell>Learning Rate</cell><cell>Training Epoch</cell><cell>Sequence Length</cell><cell>Threshold ?</cell><cell>?1</cell><cell>?2</cell></row><row><cell></cell><cell cols="2">NCBI-disease BioLM</cell><cell>6</cell><cell>3e-5</cell><cell>50</cell><cell>512</cell><cell>0.3</cell><cell cols="2">1e-1 1e-3</cell></row><row><cell>Document</cell><cell>CDR AnatEM</cell><cell>BioLM BioLM</cell><cell>6 6</cell><cell>3e-5 5e-5</cell><cell>30 30</cell><cell>512 512</cell><cell>0.3 0.3</cell><cell cols="2">1e-1 1e-3 1e-1 1e-3</cell></row><row><cell></cell><cell>Gellus</cell><cell>BioLM</cell><cell>6</cell><cell>3e-5</cell><cell>40</cell><cell>512</cell><cell>0.3</cell><cell cols="2">1.0 1e-3</cell></row><row><cell cols="4">4 Experimental Setup</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Results on biomedical NER benchmarks. F1 score is reported. The best score is displayed in bold and the second-best score is underlined. ? numbers are estimated from the figures in the original papers.</figDesc><table><row><cell>Context</cell><cell></cell><cell>Model</cell><cell></cell><cell cols="3">Evaluation (F1)</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">NCBI-disease CDR AnatEM Gellus</cell></row><row><cell></cell><cell cols="2">B-MTM (Crichton et al., 2017)  ?</cell><cell></cell><cell>80.4</cell><cell>89.2</cell><cell>82.2</cell><cell>-</cell></row><row><cell></cell><cell cols="2">BiLSTM-CRF (Habibi et al., 2017)  ?</cell><cell></cell><cell>84.6</cell><cell>-</cell><cell>-</cell><cell>75.6</cell></row><row><cell>Sentence</cell><cell cols="2">BioBERT (Lee et al., 2020b) BioLM (Lewis et al., 2020a)</cell><cell></cell><cell>89.0 88.3</cell><cell>89.1 89.5</cell><cell>73.9 74.9</cell><cell>54.9 55.9</cell></row><row><cell></cell><cell cols="3">CL-L2 (w/o context) (Wang et al., 2021)  ?</cell><cell>89.2</cell><cell>90.7</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell cols="3">CL-KL (w/o context) (Wang et al., 2021)  ?</cell><cell>89.2</cell><cell>90.7</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell cols="3">CL-L2 (w/ context) (Wang et al., 2021)  ?</cell><cell>89.2</cell><cell>91.0</cell><cell>-</cell><cell>-</cell></row><row><cell>Document</cell><cell cols="3">CL-KL (w/ context) (Wang et al., 2021)  ?</cell><cell>89.0</cell><cell>90.9</cell><cell>-</cell><cell>-</cell></row><row><cell></cell><cell>ConNER (Ours)</cell><cell></cell><cell></cell><cell>89.9</cell><cell>91.3</cell><cell>83.5</cell><cell>63.4</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>, 2020a)</cell></row><row><cell cols="3">model equally. The best scores are displayed in bold.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Model Description</cell><cell></cell><cell cols="2">Evaluation (P/R/F1)</cell><cell></cell></row><row><cell></cell><cell></cell><cell>NCBI-disease</cell><cell>CDR</cell><cell cols="2">AnatEM</cell><cell>Gellus</cell></row><row><cell>ConNER</cell><cell></cell><cell cols="5">88.8 / 91.1 / 89.9 89.9 / 92.7 / 91.3 83.2 / 83.7 / 83.5 62.6 / 64.2 / 63.4</cell></row><row><cell cols="2">ConNER -{L distill }</cell><cell cols="5">87.5 / 89.9 / 88.7 89.2 / 92.3 / 90.7 81.6 / 81.1 / 81.3 54.3 / 60.3 / 57.1</cell></row><row><cell cols="2">ConNER -{L label }</cell><cell cols="5">87.4 / 90.4 / 88.8 89.4 / 92.1 / 90.7 81.0 / 81.9 / 81.5 54.2 / 61.2 / 57.5</cell></row><row><cell cols="7">ConNER -{L distill ,L label } 87.4 / 89.7 / 88.5 89.8 / 90.7 / 90.2 80.3 / 80.4 / 80.3 54.8 / 59.1 / 56.9</cell></row></table><note>Table 5. An ablation study of ConNER components. We perform three different experiments: removing distillation (-{L distill }), label refinement (-{L label }), and both of these process (-{L distill ,L label }). We used our best hyperparameter setting on the BioLM (Lewis et al.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>and our ConNER approach are compared. Our ConNER approach achieves consistent predictions on the modifier examples.</figDesc><table><row><cell cols="2">Data Criteria</cell><cell></cell><cell></cell><cell cols="3">Modifier Token Examples</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="6">primary genetic hereditary inherited congenital abnormal</cell></row><row><cell cols="2">Train ?tCon</cell><cell>0.11</cell><cell>0.79</cell><cell>0.13</cell><cell>0.58</cell><cell>0.27</cell><cell>0.94</cell></row><row><cell></cell><cell>?tCon</cell><cell>0</cell><cell>0.81</cell><cell>0.08</cell><cell>0.55</cell><cell>0.25</cell><cell>1</cell></row><row><cell>Test</cell><cell>BioLM</cell><cell>0%</cell><cell>50%</cell><cell>50%</cell><cell>66%</cell><cell>77%</cell><cell>44%</cell></row><row><cell></cell><cell cols="2">ConNER 100%</cell><cell>75%</cell><cell>94%</cell><cell>100%</cell><cell>100%</cell><cell>78%</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">"main" -2022/10/25 -0:49 -page 2 -#2</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">"main" -2022/10/25 -0:49 -page 6 -#6</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Biomedical named entity recognition using deep neural networks with contextual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2493" to="2537" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A neural network multi-task learning approach to biomedical named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Crichton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ncbi disease corpus: a resource for disease name recognition and concept normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">I</forename><surname>Dogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Interpretable multi-dataset evaluation for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.06854</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.04434</idno>
		<title level="m">Larger-context tagging: When and why does it work? arXiv preprint</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Leveraging document-level label consistency for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence</title>
		<meeting>the Twenty-Ninth International Conference on International Joint Conferences on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3976" to="3982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep learning with word embeddings improves biomedical named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Habibi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="37" to="48" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<title level="m">Regularization for long named entity recognition. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">2104</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cell line name recognition in support of the identification of synthetic lethality in cancer from text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kaewphan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="276" to="282" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A neural named entity recognition and multi-type normalization tool for biomedical text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>IEEE Access</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01360</idno>
		<title level="m">Neural architectures for named entity recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Answering questions on covid-19 in real-time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.15830</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">BioBERT: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pretrained language models for biomedical and clinical tasks: Understanding and extending the state-of-the-art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Clinical Natural Language Processing Workshop</title>
		<meeting>the 3rd Clinical Natural Language Processing Workshop</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pretrained language models for biomedical and clinical tasks: understanding and extending the state-of-the-art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Clinical Natural Language Processing Workshop</title>
		<meeting>the 3rd Clinical Natural Language Processing Workshop</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="146" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Paq: 65 million probably-asked questions and what you can do with them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1098" to="1115" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Biocreative v cdr task corpus: a resource for chemical disease relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Database</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Open-domain anatomical entity mention detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the workshop on detecting structure in scholarly discourse</title>
		<meeting>the workshop on detecting structure in scholarly discourse</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="27" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Named entity recognition and relation detection for biomedical information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Perera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in cell and developmental biology</title>
		<imprint>
			<biblScope unit="page">673</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Anatomical entity mention recognition at literature scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="868" to="875" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Overview of the cancer genetics (cg) task of bionlp shared task 2013</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BioNLP Shared Task 2013 Workshop</title>
		<meeting>the BioNLP Shared Task 2013 Workshop</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="58" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Text chunking using transformation-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Natural language processing using very large corpora</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="157" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Bern2: an advanced neural biomedical named entity recognition and normalization tool</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.02080</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Improving named entity recognition by external context retrieving and cooperative learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.03654</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Hunflair: an easy-to-use tool for state-of-the-art biomedical named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Pubtator central: automated concept annotation for biomedical full text articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-H</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic acids research</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Luke: deep contextualized entity representations with entity-aware self-attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Yamada</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.01057</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.07150</idno>
		<title level="m">Named entity recognition as dependency parsing</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
