<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LiDAM: Semi-Supervised Learning with Localized Domain Adaptation and Iterative Matching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Palo Alto Research Center Palo Alto</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Shreve</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Palo Alto Research Center Palo Alto</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raja</forename><surname>Bala</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Palo Alto Research Center Palo Alto</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LiDAM: Semi-Supervised Learning with Localized Domain Adaptation and Iterative Matching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Although data is abundant, data labeling is expensive. Semisupervised learning methods combine a few labeled samples with a large corpus of unlabeled data to effectively train models. This paper introduces our proposed method LiDAM, a semi-supervised learning approach rooted in both domain adaptation and self-paced learning. LiDAM first performs localized domain shifts to extract better domain-invariant features for the model that results in more accurate clusters and pseudo-labels. These pseudo-labels are then aligned with real class labels in a self-paced fashion using a novel iterative matching technique that is based on majority consistency over high-confidence predictions. Simultaneously, a final classifier is trained to predict ground-truth labels until convergence. Li-DAM achieves state-of-the-art performance on the CIFAR-100 dataset, outperforming FixMatch (73.50% vs. 71.82%) when using 2500 labels.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Although the amount of data being generated is increasing every year <ref type="bibr" target="#b13">(Mittal and Sangwan 2019)</ref>, most of this data is unlabeled. Acquiring labels to sufficiently train fully supervised models is often prohibitively expensive and timeconsuming. Given that data-driven deep networks require millions of labeled samples to train, there is a growing interest in semi-supervised methods that learn from a combination of a few labeled samples and a large quantity of unlabeled data <ref type="bibr" target="#b1">(Berthelot et al. 2019b;</ref><ref type="bibr" target="#b0">2019a;</ref><ref type="bibr" target="#b15">Sohn et al. 2020)</ref>. We focus on the task of deep image classification. A fundamental component of semi-supervised learning is the detection of clusters that form in the feature projections of unlabeled data. These clusters are assigned pseudo-labels that, when combined with a handful of real labels, can be used to train and update the classifier. The ultimate goal is to group samples together by propagating real labels to nearby samples with a high degree of confidence. In fact, it was recently shown that iteratively applying a combination of clustering and supervised learning (using only pseudo-labels) on a randomly initialized model can achieve remarkable accuracy for image classification <ref type="bibr" target="#b4">(Caron et al. 2018)</ref>. In our work, we adopt a similar approach but push performance further by borrowing concepts from transfer learning, and domain In this figure, we use t-SNE to plot the features extracted from a pretrained imagenet model on the CIFAR-10 training dataset. For each class (represented by a unique color), we select the top k samples (dotted circle). Within this circle, we observe multiple domains for each class. By performing random domain shifts within each of these subregions, we generate domain-invariant feature representations that improve pseudo-labeling and downstream training for classification.</p><p>adaptation. Additionally our method takes as input initial feature representations from a pretrained or a self-supervised model that requires no human-annotated labels (e.g., MoCo <ref type="bibr" target="#b7">(He et al. 2019)</ref> or SimCLR <ref type="bibr" target="#b5">(Chen et al. 2020)</ref>). Our work is in large part motivated by the observation that many large datasets, especially those collected from online scraping algorithms (e.g., CIFAR, ImageNet, etc.), exhibit high intra-class variance due to diversity in the domains from which the images arise. For example, images within a given class may be sourced from official product advertisements, low quality mobile captures for social networking, images captured from surveillance feeds at oblique poses, etc. In addition intra-class shifts can also arise from regional trends (e.g., images of different dog breeds popular within different populations, but all labeled dog). We relieve the impact from intra-class domain variance using localized domain adaptation for learning better essential features of classes.</p><p>We propose a two-stage approach as shown in <ref type="figure">Figure  2</ref>. In the first stage, we begin by generating feature rep-  <ref type="figure">Figure 2</ref>: Overview of proposed two-stage method. In stage (a), feature points and pseudo-labels from K-means are used to train the Domain Adaptation Model (DAM, red circle). DAM generates an initial prediction of class labels, which are fed to stage (b) where labels and the classifier (green circle) are iteratively updated until convergence. Iterations are shown unrolled for illustration (figure best viewed in color).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Real class labels</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Centricity-based Confidence</head><p>resentations from the unlabeled images using a pretrained or self-supervised model. We then apply K-means clustering and assign a pseudo-label to each sample based on the cluster ID. For each cluster, a centricity-based confidence measure is used to extract two data subsets corresponding to a source and target domain, denoted S s and S t . Next, a generative domain adaptation model (DAM) is trained to learn domain-invariant feature representations and to predict pseudo-labels in a space with compact clusters. This is followed by an initial alignment between true and pseudolabels, achieved by feeding labeled samples to DAM, and assigning true labels to all unlabeled data via a majority consistency rule. In the second stage, we perform a proposed self-paced iterative matching technique to train the final classifier to predict true class labels for all unlabeled samples.</p><p>Our novel contributions are twofold: i) the use of deep domain adaptation on artificially induced domain shifts to generate high-quality initial data representations and labels; and ii) introduction of a novel iterative scheme to improve at once the data labels and the final classifier.</p><p>Our experimental results demonstrate that our method can align pseudo-labels to ground-truth labels with a high degree of accuracy. Overall, our method achieves competitive performance on both the CIFAR-10 and CIFAR-100 datasets under the same semi-supervised setting. On the CIFAR-100 dataset, we outperform the state-of-the-art (73.50% vs. 72.88%) when only using 5% of the available labels, while outperforming the majority of methods when a larger number of labels is used. To the best of our knowledge, LiDAM is the first approach that combines unsupervised clustering with localized domain adaptation and an iterative matching mechanism to generate accurate pseudo-labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Domain adaptation and transfer learning Recently, adversarial learning has been used to improve the marginal and conditional distributions of cross-domain sample populations for the purpose of transfer learning <ref type="bibr" target="#b18">(Yu et al. 2019;</ref><ref type="bibr" target="#b20">Zhao et al. 2018)</ref>. Such approaches jointly train a feature generator (G f ) and discriminator (G d ) so that the final distributions between the source and target domains are as close as possible, resulting in a domain invariant set of features. <ref type="bibr" target="#b11">(Lee et al. 2019</ref>) improves on this idea by proposing an additional filter that ignores portions of visual data that do not transfer well through the use of a residual transferability aware bottleneck. Alternatively, negative and positive transfer measures can determine how effective features learned for some previous task transfer to a new target task. In the work by <ref type="bibr" target="#b2">(Cao et al. 2018a)</ref>, these measures are explored on each class separately to determine if a class should be learned in the source domain and if so, how it should be weighted in a transfer process. In contrast to these approaches which seek to generally globally adapt interclass features across two domains, we locally adapt features learned from the unaltered source domain by locally adapting features learned for each class to suppress intra-class domain variances. Semi-supervised learning The sample-efficient method proposed in (Lee 2013) assigns pseudo-labels to unlabeled data for classes that are predicted with high probability. These labels are then aligned with true labels (using a majority rule) to train a proposed network in supervised fashion. Recent work has dramatically achieved better performance for semi-supervised learning including the work by <ref type="bibr" target="#b1">(Berthelot et al. 2019b</ref>) which introduces the MixMatch algorithm, which proposes the notion of using low-entropy labels for </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inferred True labels</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pseudolabels</head><p>Label-correction</p><formula xml:id="formula_0">Infer T Confident Centric-Match T D(S s ; ? d ) Finetune T S ? c I? Confident Centric-Match S ? ? c I S s Corrected R Cold-start</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Iterative matching</head><p>Stages: <ref type="figure">Figure 3</ref>: Detailed illustration of our proposed approach. A domain adaptation model trained on pseudo-labels is initially used to predict real class labels for an unlabeled dataset T , solving the cold start problem (dashed loops in red). These predictions are then used initially train a separate classifier D that is iteratively updated using alternating label mapping mechanisms (solid green loops). unlabeled data. Their approach also mixes augmented data with labeled data to predict the classes of unlabeled data. Their approach was later improved in ReMixMatch (Berthelot et al. 2019a) by aligning the distributions ofaugmentation anchoring techniques, to align marginal distributions between predictions of unlabeled data and true labels and to make the output of strongly augmented input close to that of the weakly augmented one. Same authors <ref type="bibr" target="#b15">(Sohn et al. 2020)</ref> proposed FixMatch simply combines consistency regularization and pseudo-labeling to align the predictions of pseudo labels between weakly and strongly augmented unlabeled images. Our approach is different from above. In general, we initiate our model with pseudo labels from unsupervised clustering, then align pseudo labels to true labels using our proposed iteratively matching based on cold start from localized domain adaptation (see more details in Section 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>In this section, we describe in detail our proposed LiDAM approach. We acquired pseudo-labels for unlabeled datasets using unsupervised clustering approaches (in Section 3.1). Then, we introduce the domain adaptation model in selfsupervised training to solve cold-start problem (in Section 3.2). Finally, iteratively matching mechanism for mapping pseudo-labels to true labels introduces in Section 3.3 and 3.4. Our proposed method is shown in the Figure 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Unsupervised Clustering</head><p>We perform K-means clustering on features extracted from each image and assign an initial pseudo-label prediction based on cluster ID. Rather than cluster on features from a randomly initialized model as performed in <ref type="bibr" target="#b4">(Caron et al. 2018)</ref>, we cluster on the feature space generated from either a model pretrained on a different dataset, or one trained using a self-supervised learning pretext task <ref type="bibr" target="#b7">(He et al. 2019</ref>). Next we randomly split the high-confidence central nearest points into two subsets that we treat as source and target domains. Since the compact groups of samples that tightly surround each cluster's mean location are more likely belong to the same class, as demonstrated in <ref type="bibr" target="#b6">(Garg and Kalai 2017)</ref>. In addition, as we observe that even though these points have a high likelihood of belonging to the same class, they also belong to different domains (recall that images of a car that could be taken from cameras, phones, product advertisements, or other device resources). Here, we do not have a distance-based heuristic for deciding source and target domains. Instead, within the center-nearest points, we select the majority of points as a dominant domain/source domain since we believe these data points have a high probability of capturing most of the generalizable features. We reduce the impact from each intra-class domains shift (whatever an image of a car is cartoon or real) by forcing the model sufficiently learn cross-domain features over all data points. These improved features are then subsequently used to more accurately assign labels to low-confidence samples outside of this fixed radius in the future iterative matching stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Domain Adaptation Model</head><p>Several recent domain adaptation techniques attempt to learn domain-invariant features from data arising from multiple domains. We adopt the adversarial domain adaption strategy described in (Ganin and Lempitsky 2015) comprising 3 subnets. First, a subnet M (?) with parameters ? m learns domain-invariant feature representations. These are then fed to both a domain discriminator G(?) with parameters ? g that distinguishes between source and target domain; and a classifier C(?) with parameters ? c that predicts class labels. Training proceeds as a two-player minmax game that simultaneously maximises the loss L g of G(?) while minimizing the loss L c of C(?). The overall network loss is given by:</p><formula xml:id="formula_1">L ori (? m , ? c , ? g ) = 1 N s Ns i=1 L c (y i , C(M (X i ))) ? ? N N j=1 L g (l j , G(M (X j )))<label>(1)</label></formula><p>where X i and y i are input images and pseudo-labels respectively, N s and N t are the number of samples in the source and target domains respectively, and N is the total dataset size. Hyperparameter ? balances the importance of classifier loss L c vs. domain discriminator loss L g . The binary variable l j ? {0, 1} denotes whether a sample is from the source or target domain. Network parameters are learned through the min-max optimization shown below,</p><formula xml:id="formula_2">(? m ,? c ) = arg min ?m,?c L ori (? m , ? c , ? g ), (? g ) = arg min ?g L ori (? m , ? c , ? g ).<label>(2)</label></formula><p>Since the overall number of domains present in each class is unknown and therefore we do not know how many will fall into the source and target domain sets, we adopt a partial domain adaptation technique. In general, aligning the source label space L s to the target label space L t can result in classification performance decay due to effects from the outlier label space (subspace of source labels space that are not represented in the target domain). We define L s \L t as a target label space that is a subspace of source label space, where |L t | |L s \L t | since transferring from a large source set to a small target set is a normal scenario (this is reflected in our choice of source and domain set sizes in Section 4). We implement the partial adversarial domain adaptation approach defined in <ref type="bibr" target="#b3">(Cao et al. 2018b</ref>) by assigning weights on source domain classes to reduce the interference from other classes when learning transferable features. The weight v is a |L s | dimensional vector to augment weights on L s ? L t which forces the weights on L s \L t to be very small. Specifically, v quantifies contributions from each class by averaging the label predictions over target data</p><formula xml:id="formula_3">, v = 1 N t Nt i=1? i ,<label>(3)</label></formula><p>Note that the weight v satisfies |Ls| i=1 v i = 1. By normalizing the weight v by its maximum value, v/ max(v) learns to assign small valued weights on L s \L t . We apply the weight v to the source classifier C(?) and the discriminator G(?) over source domain data to equations (1) and (2) and derive the partial domain adaptation,</p><formula xml:id="formula_4">L par (? m , ? c , ? g ) = 1 N s Ns i=1 v yi L c (y i , C(M (X i ))) ? ? N s Ns i=1 v yi L g (l i , G(M (X i ))) ? ? N t Nt j=1 L g (l j , G(M (X j )))<label>(4)</label></formula><p>where the hyper-parameter ? is same as defined in equation (1) and v yi is the weight corresponding to the groundtruth label y i with source data X i . The parameters are then learned through minmax optimization thus shown below, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Label initialization</head><p>Given an initially pseudo-labeled training set R, we identify a subset of samples S c for which we have a high degree of confidence in the pseudo-label prediction. This is achieved by selecting the k neighbors nearest to each cluster centroid based on Euclidean distance. S c is randomly divided into a source domain set S s and a target domain set S t . We report the performance of LiDAM using multiple choices of k that are selected based on balancing psuedo-label and groundtruth label prediction (this is explained in more detail in Section 4 and <ref type="figure" target="#fig_2">Figure 4</ref>).</p><p>To start the iterative matching process and address the cold-start problem of predicting ground-truth labels for unlabeled samples, we adopt the following majority consistency approach. We run the small set T of labeled samples through DAM (?) to get predicted pseudo-labels. Note that samples from a given true class can map to multiple pseudo-labels. We count the occurrences of pseudo-label predictions within a given true class, and assign to that class the pseudo-label with the majority count. Now every labeled sample has both a true and pseudo label. Next, the loop is closed by reversing this mapping and aligning each pseudo-label with a groundtruth label for all unlabeled samples, as shown in the right half of <ref type="figure">Figure 3</ref>. To this end, we define a function M ap that matches pseudo-class label l p to a true class label l t ? [0, Z] and returns the true label l t as correct label l new ,</p><formula xml:id="formula_5">l new = M ap(I lp ? T lt ).<label>(6)</label></formula><p>To do this, M ap first counts the frequency of the groundtruth labels associated with each group of samples that have the same high-confidence pseudo-label prediction from DAM (?). Initially, all high confidence pseudo-label predictions are stored in S c = {x j i |P r (I i ) &gt;= 1 ? ?, i ? 1, 2, ..., |T |, j ? 1, 2, ..., Z} where ? is a hyper-parameter (? = 1e?5 in our experiments). Then, all samples S c with the same psuedo-label prediction l p are collected in the set x lp ? S c . After determining the most frequently occurring ground-truth label l t , we propagate the ground-truth label to all members of x lp by replacing the pseudo-label with the true class label l t . After each pseudo-class label has been matched and updated in R, then we use this newly labeled dataset to train a new classifier D(?) (ResNet-50) which is subsequently finetuned with T for downstream classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Iterative matching</head><p>After the cold-start initialization using T , D(?) is able to start inferring true class labels I for S s (the initial high centricity-based confidence source set). During each iteration (denoted as a solid green line in <ref type="figure">Figure 3</ref>), the assigned pseudo-label S s is updated based on high confidence predictions by D(?). To achieve this, the mapping rule as described in is in the reverse direction as described in Eq. 6 since D(?) predicts true labels as opposed to the pseudolabels predicted by DAM (?). Thus, M ap follows the same process but maps each pseudo-label l p of S s to a true class label l t of I and returns the true class label as the correct label l new ,</p><formula xml:id="formula_6">l new = M ap(S l p s ? I l t ).<label>(7)</label></formula><p>where l t is the most frequent inferred true label on x l p with associated pseudo-label l p , and x l p ? S c and S c is an inferred true label set that contains samples with high probability detections from D(?). That is, S c = {x j i |P r (I i ) &gt;= 1 ? ? , i ? 0, 1, 2, ..., |S s |, j ? 0, 1, 2, ..., Z} where ? is a hyper-parameter that thresholds predicted confidence values (? = 1e?2 in our experiments). Note that S s can potentially affect downstream classification performance if the initial K-means clustering performance is poor. Thus, choosing a good size for S c in critical (we explore different sizes for S s in our experimental results and in <ref type="table" target="#tab_2">Table 1 and Table 2</ref>). Finally, after pseudo-class labels are matched and updated in R with T , we again finetune the classifier D(?) and continue iterating. As the number of iterations increase, more and more pseudo-labels will be correctly aligned to true labels (as illustrated in <ref type="figure" target="#fig_0">Figure 1-b)</ref>. The classifier D(?) is thus progressively improved by optimizing the following problem, arg min</p><formula xml:id="formula_7">? d |R| i=1 L d (y i , D(x i ; ? d ))<label>(8)</label></formula><p>where ? d is the parameters of classifier D(?) with the loss L d for x i ? R. The iterative matching algorithm is provided  in Algorithm 1. At the end of our approach, the best local model D(?) is used for inferring true labels for all samples until the predicted class labels converge with the groundtruth labels for all samples in T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We demonstrate the performance of our method on image classification, making comparisons to several state-ofthe-art methods. Our experiments are performed on two benchmark image classification datasets, CIFAR-10 and CIFAR-100(Krizhevsky, Nair, and Hinton 2009) using standard ground-truth partitioning techniques used for measuring semi-supervised learning performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>CIFAR-10 contains a total of 60000 RGB images from ten classes. The image size is 32?32 and each class has 6000 images. 1000 images from each class are randomly selected to form a test set, while the remaining images are used for training. CIFAR-100 is similar to CIFAR-10 except with 100 classes, each containing 600 RGB images. 500 images from each class comprisd a training dataset of 50000 images and the remainder are used for testing. CIFAR-100 is more challenging as it has much more classes and fewer images for training than CIFAR-10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation details</head><p>Our approach relies on an initial set of feature representations that are used in two different stages: (1) in the initial feature extraction and clustering stage; (2) in the classifier that is finetuned during the iterative matching stage. We test our approach by using a ResNet-152 pretrained on ImageNet for the initial feature extracting and clustering stage, and ResNet-50 pretrained on ImageNet as the backbone for the classifier in the iterative matchinng stage.</p><p>To collect the source and target domain datasets, we randomly divide S c using an 80 / 20 split. For selecting the number of ground-truth samples used to train our models, we follow standard practice: for CIFAR-10, the test on ground-truth selections sizes of 250, 1000, and 4000 which comprise images randomly selected from each class in groups of 25, 100, and 400, respectively; for CIFAR-100, ground-truth selections of 2500, 5000, and 10000 are comprised by randomly selecting 25, 50, and 100 images per class, respectively. For our reported image classification tests, we use the standard test data partition from CIFAR-10 and CIFAR-100. Experiments on CIFAR-10 conducted on 3 Tesla V100 GPUs and experiments on CIFAR-100 conducted on 3 GTX 1080 Ti GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluation</head><p>We first evaluate how well we K-means clustering performs when choosing the closest N samples around each cluster center S c . As can be seen from <ref type="table" target="#tab_2">Table 1 and Table 2</ref>, different choices of N lead to different levels of cluster accuracy or purity (i.e., the number of samples with a common groundtruth label that is unique from other clusters). One intuitive but clear takeaway from both of these results is that as the distance increases from the cluster center, the more likely we are to find samples of different classes. As discussed in Section 3, this is important for two reasons. The first reason is that since the subset S c is used for selecting the intra-class source and target domain sets around each cluster which are used to train DAM , any impurity will likely increase interclass confusion. The second reason is that these samples are expected to be of a singular class when training the final classification model during the iterative matching stage.</p><p>To get an insight of how the choice of S c and its subdivisions S t , and S s will effect the training performance of DAM, we conducted a series of experiments as shown in <ref type="figure" target="#fig_2">Figure 4</ref>. In these experiments, S t serves as test data except for the experiment shown in <ref type="figure" target="#fig_2">Figure 4</ref>(c) where we use the standard CIFAR-10 test data partition. We propose two approaches for subdividing S c into the source (S s ) and target (S t ) domains. In the first approach, each sample is randomly assigned to a domain based on a predefined ratio (e.g., 80/20 split). This approach captures the intuition that multiple domains are spread across the each cluster, and so features can be best extracted after performing multiple local domain shifts in random directions. In the second approach, the distance to the cluster center is used to separate the two domains. This is defined by selecting points that fall within or outside an inscribed circle/sphere (i.e., the closest 80% are assigned to the source domain, the remaining 20% to target domain). The intuition behind this approach is that sample points nearest to cluster centroids will likely belong to a single domain; thus features are best extracted by shifting outward to domains in the periphery. As a baseline approach, we compare the perfomance of each of these experiments to a ResNet-50 model finetuned on S s .</p><p>In <ref type="figure" target="#fig_2">Figure 4(a)</ref>, we observe the performance of the DAM model at predicting psuedo-labels using both of these partitioning approaches on S t . They key takeaway from this plot is that randomized domain shifts (DAM-Random) result in the extraction of more robust features compared to DAM-Circle and Finetune as the size of S c increases and it's purity decreases (see <ref type="table" target="#tab_2">Table 1</ref>). For comparison in <ref type="figure" target="#fig_2">Figure 4(b)</ref>, we use the same partitions used in <ref type="figure" target="#fig_2">Figure 4</ref>(a), but instead train and predict on ground-truth labels. Here we can see that the model does not suffer from poor K-means psueudo-label assignment and instead leverages the true labels to progressively improve performance as more of it is provided. Finally, in <ref type="figure" target="#fig_2">Figure 4</ref>(c) we run this same experiment but test performance on the CIFAR-10 test partition. Overall, we conclude from these experiments that the DAM-Random approach performs better than the DAM-Circle approach, DAM is more accurate at predicting pseudo-labels with smaller sizes (e.g., 500) of S c , and lastly DAM performs better than a finetuned ResNet-50 for learning essential features across multi-source domains. Therefore, we select this configuration and combine it with our iterative matching algorithm test our full LiDAM framework.</p><p>CIFAR-10 Results We compare our results with other methods using varying amounts of ground-truth training data. We follow standard practice by randomly sampling 25,  <ref type="table" target="#tab_4">Table 3</ref>. We provide the highest accuracies reported for each method by the original authors. Top accuracies are indicated in bold, including those that fall within the reported error margins. Our approach is competitive but is outperformed in all labeling cases for CIFAR-10. For 250 labels provided from CIFAR-10, FixMatch <ref type="bibr" target="#b15">(Sohn et al. 2020</ref>) achieved the overall best accuracy 0.9558 which is slightly better than ReMixMatch <ref type="bibr" target="#b0">(Berthelot et al. 2019a)</ref> and than our method. Our method performs better on 1000 labels and 4000 labels, but still outperforms most of methods on 250 labels such as MeanTeacher, VAT, etc. For 1000 labels, MixMatch achieved best accuracy 0.9257, outperforms our method by 3.53%. Our method obtains accuracy of 0.8904 which has 2.36% improved than the third best method. For 4000 labels, our method obtained 0.9252 while the best method FixMatch obtained 0.9579. As we can see from the table, even only 1000 labels provided, our method is also competitive to the most of other methods with 4000 labels.</p><p>CIFAR-100 Results We also compare our results on the CIFAR-100. Results are also provided in <ref type="table" target="#tab_4">Table 3</ref>. Our proposed method outperforms all other methods on 2500 labels and 5000 labels. On 2500 labels, we observe a 0.6% improvement compared to ReMixMatch and 1.68% improvement compared to FixMatch. Similar to the results on CIFAR-10, we outperform most other methods when using the minimal amount of data (2500 labels) even when other approaches use the all available data (10000 labels). Our method achieves competitive accuracies on 10000 labels but ultimately falls short of ReMixMatch (0.7641).</p><p>Overall, our method achieves state-of-the-art accuracies for CIFAR-100, but performs worse on CIFAR-10. Our main hypothesis for this discrepancy is that for the CIFAR-100 case, the number of samples in each class are small but the domain variance is large. This is likely an optimal scenario for LiDAM which primarily address such domain variance.</p><p>On the other hand, CIFAR-10 contains fewer classes but a large number of samples per class. Therefore, there is an increased chance that the clusters identified by K-means will have accurately identified all samples across all domains, leading to less domain variance in the regions selected around each cluster centroid. Another point worth noting is that that when using a large number of labels such as 10000 labels from CIFAR-100, as shown in <ref type="table" target="#tab_4">Table 3</ref>), our method approaches the top accuracy but falls slightly short. One explanation for this small gap is our choice to use ResNet-50 as our backbone, opposed to the other methods. For example, both FixMatch and ReMixMatch use wide ResNet models <ref type="bibr" target="#b8">(Huang et al. 2017</ref>) (e.g. Wide ResNet-28-2, Wide ResNet-28-10, etc.) which both perform better than ResNet-50 in their experiments. Our choice of using a ResNet-50 backbone is based on the availability of pretrained version of this network. In future work, we will explore other backbone architectures. To address the performance gaps on CIFAR-10, we will also explore methods for generating improved feature representations such as self-supervised approaches that train using pretext tasks on the CIFAR dataset. In addition, we will explore the integration of active learning approaches that selectively request labels for the most informative samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, our proposed method LiDAM applies deep domain adaptation on artificially induced domain shifts to generate high-quality initial data representations that are used to map pseudo-labels to ground-truth labels. We also introduced a novel iterative matching scheme that progressively improves these predicted data labels and trains a final classifier. To the best of our knowledge, LiDAM is the first approach that utilizes localized domain adaptation to reduce intra-class domain variance for the purpose of boosting selfsupervised learning. We experimentally demonstrated the effectiveness of our method on benchmark datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Domains of classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>(U</head><label></label><figDesc>? m ,? c ) = arg min ?m,?c L par (? m , ? c , ? g ), (? g ) = arg min ?g L par (? m , ? c , ? g ). (5) Algorithm 1: Iterative Matching 1 Pretrain(DAM ) 2 DAM (T ; ? c ) ? I inferred pseudo-labels 3 I ? S c select confident pseudo-label set 4 Initialize(Loop) 5 while Acc L &gt;= Acc best do 6 if M odel L not exist then 7 for number of classes do 8 l new = M ap(I lp ? T lt ) match to true labels 9 D(R; ? d ) and finetune with T 22 Save(M odel L , Acc L ) save model, accuracy 23 end</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>f i c ation a c c ur acy on p se u d o -l a be ls f i c ation a c c ur acy on t e st d a ta of CIFA Rperformance at various source and target sizes (Sc) on CIFAR-10 and using test data from CIFAR-10 Explorations and comparisons for pretraining DAM. These experiments test both the size of S c as well as how S c is partitioned into the source (S s ) and target (S t ) subsets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>The effect from the size of confident pseudo label set for the performance of Kmeans clustering on CIFAR-10.Cluster subset |S c | Total correct K-means acc.</figDesc><table><row><cell>500</cell><cell>4762</cell><cell>0.9524</cell></row><row><cell>1000</cell><cell>9326</cell><cell>0.9326</cell></row><row><cell>1500</cell><cell>13732</cell><cell>0.9155</cell></row><row><cell>2000</cell><cell>18089</cell><cell>0.9045</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>The effect of the size of confident pseudo label set for the performance of Kmeans clustering on CIFAR-100.</figDesc><table><row><cell cols="3">Cluster subset |S c | Total correct Kmeans acc.</cell></row><row><cell>30</cell><cell>1775</cell><cell>0.5917</cell></row><row><cell>60</cell><cell>3415</cell><cell>0.5692</cell></row><row><cell>90</cell><cell>5052</cell><cell>0.5613</cell></row><row><cell>120</cell><cell>6553</cell><cell>0.5461</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Comparison of classification accuracy on CIFAR-10 and CIFAR-100 with baseline models such as ?-model (Laine and Aila 2016), PseudoLabel (Lee 2013), MixUp (Zhang et al. 2017), VAT (Miyato et al. 2018) MeanTeacher (Tarvainen and Valpola 2017), MixMatch (Berthelot et al. 2019b), EnAET (Wang et al. 2019), UDA (Xie et al. 2019), ReMixMatch<ref type="bibr" target="#b0">(Berthelot et al. 2019a)</ref>, and FixMatch<ref type="bibr" target="#b15">(Sohn et al. 2020</ref>). The highest reported accuracies are used for baseline models. Top accuracies are reported in bold, including those that fall within the reported error margins.</figDesc><table><row><cell></cell><cell cols="2">CIFAR-10</cell><cell></cell><cell></cell><cell cols="2">CIFAR-100</cell><cell></cell></row><row><cell>Method</cell><cell cols="3">250 labels 1000 labels 4000 labels</cell><cell>Method</cell><cell cols="3">2500 labels 5000 labels 10000 labels</cell></row><row><cell>?-model</cell><cell>0.4903</cell><cell>0.6945</cell><cell>0.8296</cell><cell>?-model</cell><cell>0.4323</cell><cell>-</cell><cell>0.6223</cell></row><row><cell>PseudoLabel</cell><cell>0.5119</cell><cell>0.7082</cell><cell>0.8390</cell><cell>PseudoLabel</cell><cell>0.4308</cell><cell>-</cell><cell>0.6398</cell></row><row><cell>MixUp</cell><cell>0.5349</cell><cell>0.7494</cell><cell>0.8705</cell><cell>Mean Teacher</cell><cell>0.4666</cell><cell>-</cell><cell>0.6441</cell></row><row><cell>VAT</cell><cell>0.6679</cell><cell>0.8172</cell><cell>0.8926</cell><cell>MixMatch</cell><cell>0.6043</cell><cell>-</cell><cell>0.7202</cell></row><row><cell>MeanTeacher</cell><cell>0.5739</cell><cell>0.8668</cell><cell>0.8989</cell><cell>EnAET</cell><cell>-</cell><cell>0.6817</cell><cell>0.7328</cell></row><row><cell>MixMatch</cell><cell>0.8979</cell><cell>0.9257</cell><cell>0.9382</cell><cell>UDA</cell><cell>0.6709</cell><cell>-</cell><cell>0.7575</cell></row><row><cell>ReMixMatch</cell><cell>0.9461</cell><cell>-</cell><cell>0.9541</cell><cell>ReMixMatch</cell><cell>0.7288</cell><cell>-</cell><cell>0.7753</cell></row><row><cell>FixMatch (RA)</cell><cell>0.9558</cell><cell>-</cell><cell>0.9579</cell><cell>FixMatch (RA)</cell><cell>0.7182</cell><cell>-</cell><cell>0.7752</cell></row><row><cell>LiDAM</cell><cell>0.8083</cell><cell>0.8904</cell><cell>0.9252</cell><cell>LiDAM</cell><cell>0.7350</cell><cell>0.7514</cell><cell>0.7678</cell></row><row><cell cols="4">100, and 400 labels per class. A full comparison of results</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>is provided in</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09785</idno>
		<title level="m">Remixmatch: Semisupervised learning with distribution alignment and augmentation anchoring</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5049" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Partial transfer learning with selective adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2724" to="2732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Partial adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="135" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Big self-supervised models are strong semisupervised learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10029</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1180" to="1189" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Unsupervised domain adaptation by backpropagation</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Supervising unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">K</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kalai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.05722</idno>
		<title level="m">Momentum contrast for unsupervised visual representation learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Cifar-10 and cifar-100 datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="https://www.cs.toronto.edu/kriz/cifar.html" />
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Temporal ensembling for semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aila</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02242</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Drop to adapt: Learning discriminative features for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-G</forename><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Big data analytics using machine learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">P</forename><surname>Sangwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 9th International Conference on Cloud Computing</title>
		<meeting><address><addrLine>Confluence</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="203" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1979" to="1993" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Fixmatch: Simplifying semi-supervised learning with consistency and confidence</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Enaet: Self-trained ensemble autoencoding transformations for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09265</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12848</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Transfer learning with dynamic adversarial adaptation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="778" to="786" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adversarial multiple source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Moura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Costeira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8568" to="8579" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
