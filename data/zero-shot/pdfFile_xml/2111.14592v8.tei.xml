<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with Semi-Supervised Learning and Explicit Policy Injection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanwei</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Shenzhen Institute of Advanced Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinpei</forename><surname>Dai</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhe</forename><surname>Zheng</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchuan</forename><surname>Wu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Cao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dermot</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Jiang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Yang</surname></persName>
							<email>min.yang@siat.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Shenzhen Institute of Advanced Technology</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luo</forename><surname>Si</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
							<email>jian.sun@alibaba-inc.com</email>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Li</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Alibaba Group</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">GALAXY: A Generative Pre-trained Model for Task-Oriented Dialog with Semi-Supervised Learning and Explicit Policy Injection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pre-trained models have proved to be powerful in enhancing task-oriented dialog systems. However, current pre-training methods mainly focus on enhancing dialog understanding and generation tasks while neglecting the exploitation of dialog policy. In this paper, we propose GALAXY, a novel pre-trained dialog model that explicitly learns dialog policy from limited labeled dialogs and large-scale unlabeled dialog corpora via semi-supervised learning. Specifically, we introduce a dialog act prediction task for policy optimization during pre-training and employ a consistency regularization term to refine the learned representation with the help of unlabeled dialogs. We also implement a gating mechanism to weigh suitable unlabeled dialog samples. Empirical results show that GALAXY substantially improves the performance of task-oriented dialog systems, and achieves new state-of-the-art results on benchmark datasets: In-Car, MultiWOZ2.0 and Multi-WOZ2.1, improving their end-to-end combined scores by 2.5, 5.3 and 5.5 points, respectively. We also show that GALAXY has a stronger few-shot ability than existing models under various low-resource settings.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Task-oriented dialog (TOD) systems aim to help users accomplish certain tasks through conversations. Fundamental abilities of a TOD system include: (1) Dialog understanding: extracting structured semantics from user utterances; (2) Policy planning: determining a Dialog Act (DA) that leads to successful task completion; and (3) Dialog generation: producing appropriate responses <ref type="figure">(Figure 1</ref>). With the recent progress of Pre-trained Language Models (PLMs), remarkable performances improvements are achieved by casting TODs as generative language modeling tasks <ref type="bibr" target="#b46">(Peng et al. 2020a;</ref><ref type="bibr" target="#b34">Lin et al. 2020)</ref>, which benefit from the rich linguistic knowledge embedded in PLMs.</p><p>However, as reported in previous studies <ref type="bibr" target="#b71">(Zhang et al. 2020b;</ref><ref type="bibr" target="#b28">Kulh?nek et al. 2021)</ref>, there are intrinsic differences <ref type="figure">Figure 1</ref>: Given the input user utterance, a task-oriented dialog system needs to perform understanding, policy planning, and generation successively to complete the reply.</p><p>between the distribution of human conversations and plain texts. Directly fine-tuning plain-text-trained PLMs on downstream dialog tasks hinders the model from effectively capturing conversational linguistic knowledge and thus leads to sub-optimal performances <ref type="bibr" target="#b67">Zeng and Nie 2021;</ref>. Current attempts to tackle this issue try to build Pre-trained Conversation Models (PCMs) by directly optimizing vanilla language model objectives on dialog corpora <ref type="bibr" target="#b38">(Mehri, Eric, and Hakkani-Tur 2020;</ref><ref type="bibr" target="#b71">Zhang et al. 2020b;</ref><ref type="bibr" target="#b23">Henderson et al. 2019)</ref>, which shows improved results on both dialog understanding ) and generation <ref type="bibr" target="#b47">(Peng et al. 2020b)</ref>.</p><p>Despite these reported advances, few approaches are proposed to further enrich the pre-training process of PCMs with the knowledge of dialog policy. Specifically, existing methods either ignore explicit policy modeling or use latent variables without considering external dialog policy information <ref type="bibr" target="#b2">(Bao et al. 2020)</ref>, which hinders the possibility of learning controllable policy during pre-training. The optimization of dialog policy is usually formulated as a DA prediction task, which is crucial in TOD systems <ref type="bibr" target="#b35">Liu et al. 2018)</ref>. Therefore, we hypothesize that explicitly incorporating the DA annotations into the pre-training process can also facilitate learning better representations for policy optimization to improve the overall end-to-end performance.</p><p>A naive way to utilize these labels is to design a multitask learning process <ref type="bibr" target="#b57">(Sun et al. 2020</ref>) that directly combines vanilla unsupervised pre-training losses such as MLM <ref type="bibr">(De-vlin et al. 2018</ref>) with a supervised DA classification loss. However, this approach has several drawbacks when generalizing to large-scale pre-training paradigms: (1) The DA annotation schema is inconsistent among existing corpora, making it challenging to collect large-scale DA annotations;</p><p>(2) A vast majority of available dialogs do not have DA labels. A naive joint training process without careful regularization would lead to highly over-fitting on those labeled samples, resulting in low performance; (3) All supervision signals from unlabeled data are self-supervised without any explicit inference over the DA space, so the linguistic knowledge PCMs can extract is only the general type, and the knowledge of dialog policy can not be effectively explored.</p><p>In this study, we propose a novel generative pre-trained model called GALAXY, aiming to inject the knowledge of dialog policy explicitly into pre-training at low cost while maintaining its strong ability on dialog understanding and generation. To begin with, we build a unified DA taxonomy for TOD and examine eight existing datasets to develop a new labeled dataset named UniDA with a total of 975K utterances. We also collect and process a large-scale unlabeled dialog corpus called UnDial with 35M utterances, whose scenarios ranging from online forums to customer services. Then, we propose a semi-supervised pre-training paradigm that applies consistency regularization <ref type="bibr" target="#b59">(Verma et al. 2019</ref>) on all data. It minimizes the bi-directional KLdivergence between model predictions made on dropoutperturbed samples, which facilitates better representation learning from unlabeled dialog corpora. Since a large proportion of UnDial is from the Internet and not well-suited to our DA taxonomy, we add a learnable control gate on the KL loss of unlabeled data, so that only good samples are allowed for the consistent regularization, other samples are restricted back to normal self-supervised objectives. Experiments show that GALAXY substantially improves TOD systems and achieves new state-of-the-art results on In-Car, MultiWOZ2.0, and MultiWOZ2.1, pushing the end-to-end combined score to <ref type="bibr">107.45, 110.35, and 110.76, respectively.</ref> We also observe that GALAXY has a strong few-shot ability under various low-resource settings.</p><p>In summary, our main contributions are three-fold:</p><p>? To the best of our knowledge, this is the first study to use semi-supervised pre-training to model explicit dialog policy for PCMs. ? Experiments show our model has learned the knowledge of dialog policy, and achieves new state-of-the-art performance on several TOD benchmarks; ? We collect a new labeled dataset UniDA as well as a large-scale unlabeled dialog corpus UnDial, hoping that can help bring forward the research in this area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Pre-trained Language Models (PLMs) are trained on large-scale textual corpora with Transformer <ref type="bibr" target="#b13">(Devlin et al. 2018;</ref><ref type="bibr" target="#b48">Radford et al. 2019)</ref>, which significantly improve dialog systems performance. <ref type="bibr" target="#b3">Budzianowski and Vuli? (2019)</ref> is the first work to validate the possibility of fine-tuning the information of all sub-tasks in a single paragraph of text on <ref type="bibr">GPT-2. SimpleTOD (Hosseini-Asl et al. 2020</ref>) and SOLOIST <ref type="bibr" target="#b46">(Peng et al. 2020a</ref>) further generalize this idea to an end-to-end setting where the semantic labels are generated instead of using ground truth values and also consider database results in the training process. <ref type="bibr" target="#b65">Yang, Li, and Quan (2020)</ref> leverage the entire dialog session as the input sequence and demonstrate superior performance using selfgenerated responses during evaluation.  <ref type="bibr" target="#b2">(Bao et al. 2020;</ref><ref type="bibr" target="#b22">He et al. 2020</ref><ref type="bibr" target="#b21">He et al. , 2021</ref><ref type="bibr" target="#b64">Xu and Zhao 2021;</ref><ref type="bibr" target="#b56">Su et al. 2021;</ref><ref type="bibr" target="#b58">Dai et al. 2021)</ref>. <ref type="bibr" target="#b2">Bao et al. (2020)</ref> use discrete latent variables to tackle the one-to-many mapping problem in open-domain dialog generation. <ref type="bibr" target="#b64">Xu and Zhao (2021)</ref> propose to simulate the conversation features only using plain texts. The third is to integrate dialog annotations into the pre-training stage. <ref type="bibr" target="#b66">Yu et al. (2020)</ref> use labels of dialog understanding as supervision to pre-train BERT. <ref type="bibr" target="#b47">Peng et al. (2020b)</ref> use labeled conditional generation data to enhance dialog generation performance. Different from them, we are the first to utilize labels of dialog policy to improve PCMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre</head><p>Semi-supervised Learning (SSL) learns from both unlabeled and labeled data. Approaches differ on what information to acquire from the structure of the unlabeled samples. Many initial results were based on generative models, such as variational autoencoders <ref type="bibr" target="#b28">(Kingma and Welling 2019)</ref> and generative adversarial networks <ref type="bibr">(Goodfellow et al. 2014)</ref>. Pseudo-Labeling <ref type="bibr" target="#b29">(Lee et al. 2013</ref>) is another widely used method, where unlabeled data is used as further training data after predicted by a model trained on labeled data. One line of recent research shows promising results by jointly training labeled data with supervised learning and unlabeled data with self-supervised learning <ref type="bibr" target="#b57">(Sun et al. 2020)</ref>. This lies in the paradigm of multi-task learning, where lower layers are often shared across all tasks while the top layers are task-specific. Consistency regularization <ref type="bibr" target="#b59">(Verma et al. 2019</ref>) is also a prominent method in SSL, which improves classification performance by minimizing the discrepancy between predictions made on perturbed unlabeled data points. Recently, SimCSE <ref type="bibr" target="#b17">(Gao, Yao, and Chen 2021)</ref> leverages dropout as the perturbed method and uses a contrastive objective as the regularization loss to learn sentence representations. Inspired by SimCSE, we adopt the same dropout method for perturbation, and use the bidirectional KL-divergence as in <ref type="bibr">Liang et al. (2021)</ref> as our regularization loss, hoping to learn better representations that encodes the knowledge of dialog policy for downstream tasks. There are also some works <ref type="bibr" target="#b69">Zhang et al. 2020a;</ref><ref type="bibr" target="#b36">Liu et al. 2021)</ref> focusing on using latent variable models to alleviate the reliance on dialog labels via semi-supervised learning, but our work mainly targets the semi-supervised dialog pre-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Pre-training Dialog Datasets</head><p>In this section, we describe the new dialog datasets used for pre-training, including a labeled dialog dataset (UniDA) and a large-scale unlabeled dialog corpus (UnDial).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Labeled Dataset: UniDA</head><p>Dialog policy 1 is tasked to predict dialog acts (DAs) given dialog context. Although DAs are general tags to describe speakers' communicative behaviors <ref type="bibr" target="#b5">(Bunt 2009</ref>), current DA annotations in task-oriented dialog are still limited and lack of unified taxonomy because each dataset is small and scattered. Recently, <ref type="bibr" target="#b45">Paul, Goel, and Hakkani-T?r (2019)</ref> propose a universal task-oriented DA schema, but their dataset is still insufficient for pre-training purposes and the schema lacks some important features such as not sure and dont understand. To this end, we follow ISO <ref type="bibr" target="#b6">(Bunt et al. 2010</ref>) and propose a more comprehensive unified DA taxonomy for task-oriented dialog, which consists of 20 frequently-used DAs. A complete description of the taxonomy is in Appendix A. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Unlabeled Dataset: UnDial</head><p>Large clean dialogs are difficult to acquire. We build the unlabeled dialog corpora from various available sources, ranging from online forum chatting logs to customer service conversations. We select 14 existing dialog corpora and perform careful processing on all data. Then we acquire a large-scale unlabeled dialog dataset UnDial, which consists of 35M utterances. <ref type="table" target="#tab_4">Table 2</ref> shows the statistics of our final pre-training unlabeled data. For more details about the data statistics and the text processing method, please refer to Appendix A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head><p>In this section, we first introduce the model architecture.</p><p>Then we describe each objective used in our pre-training and the proposed semi-supervised pre-training paradigm.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model Architecture</head><p>We choose UniLM <ref type="bibr" target="#b14">(Dong et al. 2019</ref>) as our backbone model. It contains a bi-directional encoder for understanding and a uni-directional decoder for generation, which is naturally suitable for task-oriented dialog modeling. The encoder and the decoder are weight-shared. We adopt a similar scheme of input representation in <ref type="bibr" target="#b2">Bao et al. (2020)</ref>, where the input embeddings consist of four elements: tokens, roles, turns, and positions. Role embeddings are like segmentation embeddings in BERT and are used to differentiate which role the current token belongs to, either user or system. Turn embeddings are assigned to each token according to its turn number. Position embeddings are assigned to each token according to its relative position within its belonging sentence. More details can be found in Appendix B.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Pre-training Objectives</head><p>Four objectives are employed in our dialog pre-training process: response selection, response generation, DA prediction and consistency regularization. <ref type="figure" target="#fig_0">Figure 2</ref> illustrates the procedure of pre-training.</p><p>Response Selection. Many work <ref type="bibr" target="#b2">Bao et al. 2020;</ref><ref type="bibr" target="#b23">Henderson et al. 2019)</ref> show that the response selection task can capture the coherency between dialog contexts and responses and thus benefit dialog understanding. We follow their implementation and model this task as a binary classification problem. Specifically, for a context response pair (c, r) from the corpus, the positive example (with label l = 1) is obtained by concatenating c with its corresponding response r, and the negative example (with label l = 0) is constructed by concatenating c with a response r ? that is randomly selected from the corpus. A binary cross-  entropy loss is defined as:</p><formula xml:id="formula_0">? "# ? "# ? "# ? "#</formula><formula xml:id="formula_1">L RS = ? log p (l = 1|c, r) ? log p l = 0|c, r ?<label>(1)</label></formula><p>in which the classification probability p (l|c, r) is calculated by feeding the concatenated sequence of c and r into the bidirectional encoder and adding a binary classification head on the extracted representation h cls of token [CLS] from the last transformer layer:</p><formula xml:id="formula_2">p (l = 1|c, r) = sigmoid (? a (h cls )) ? R 1 (2)</formula><p>where ? a is a fully-connected neural network with the output layer of size 1. sigmoid is the sigmoid function acts on each dimension of the input vector.</p><p>Response Generation. The response generation task aims to predict the dialog response r auto-regressively based on the dialog context c. We adopt the standard negative loglikelihood loss for the generation task:</p><formula xml:id="formula_3">L RG = ? T t=1 log p (r t |c, r &lt;t )<label>(3)</label></formula><p>where r t is the t-th word in r, r &lt;t = {r 1 , ..., r t?1 } represents the words of previous steps.</p><p>DA Prediction. For a context response pair (c, r) sampled from UniDA, the DA prediction task aims to predict the DA label a of the response r based merely on the context c. Note that, since there are some responses in UniDA are associated with multiple DAs, we model the DA prediction task as a multi-label classification problem. We denote a = (a 1 , a 2 , ..., a N ), where N is the total number of dialog acts. A multi-dimensional Bernoulli distribution is used for dialog acts: p(a|c) = N i p(a i |c). Taking the dialog context c as input, we add a multi-dimensional binary classifiers on h cls to predict each act a i . The binary classification loss is:  Consistency Regularization. For UnDial, the DA annotations are unavailable. In that case, we need to infer the DA labels based on the given dialog context c. Instead of using p(a|c) in Eq. <ref type="formula">(5)</ref>, we use a categorical distribution q(a|c) for dialog acts:</p><formula xml:id="formula_4">L DA = ? N i=1 {y i log p(a i |c) + (1 ? y i ) log (1 ? p(a i |c))} (4) p (a|c) = sigmoid (? b (h cls )) ? R N (5) where ? b is</formula><formula xml:id="formula_5">q (a|c) = softmax (? b (h cls )) ? R N (6)</formula><p>where softmax is the softmax function, ? b is the same feedforward neural network in Eq. (5). So N i=1 q(a i |c) = 1. Then we employ a dropout-based consistency regularization to learn better representations <ref type="bibr" target="#b17">(Gao, Yao, and Chen 2021)</ref>. Concretely, given the same dialog context c, we feed c to go through the forward pass of the model twice. Due to the randomness of the dropout mechanism in transformers, we can get two different sets of hidden features, and therefore, two different categorical distributions of dialog policy, denoted as q 1 (a|c) and q 2 (a|c). Then the Kullback-Leibler (KL) divergence between these two output distributions is calculated as D KL (q 1 q 2 ). We minimize the bidirectional KL divergence as in <ref type="bibr">(Liang et al. 2021)</ref> between the two distributions to regularize the model predictions, which is defined as:</p><formula xml:id="formula_6">L KL = 1 2 (D KL (q 1 q 2 ) + D KL (q 2 q 1 ))<label>(7)</label></formula><p>Figure 3 illustrate the procedure of computing D KL .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Semi-supervised Pre-training Paradigm</head><p>We aim to leverage semi-supervised pre-training to learn better pre-trained representations from both the labeled and unlabeled data. For the labeled dataset UniDA, we use all objectives to optimize. The total loss L label is computed as:</p><formula xml:id="formula_7">L label = L RS + L RG + L DA + L KL<label>(8)</label></formula><p>For the unlabeled data UnDial, since some dialogs collected from the open-domain Internet are too noisy to be compatible with our DA taxonomy, we propose to use a gating mechanism to select a high-quality subset of UnDial for prediction. In practice, we compute a soft gating score g ? [0, 1] based on the entropy of q(a|c) to control whether a data point is adopted for consistency regularization in the current iteration.</p><formula xml:id="formula_8">g = min max 0, E max ? (E + log E) E max , 1<label>(9)</label></formula><p>where E max = log N is the Maximum Entropy of Ndimensional probability distribution. E is the current entropy of q(a|c), i.e., E = N i q(a i |c) log q(a i |c). In practice, we use the perturbed distribution q 1 (a|c) as the approximation of q(a|c) to calculate the gate score.</p><p>Hence, we have the loss L unlabel for the unlabeled data to adjust it adaptively by the gate g as following:</p><formula xml:id="formula_9">L unlabel = L RS + L RG + gL KL<label>(10)</label></formula><p>The final loss L pre is computed as:</p><formula xml:id="formula_10">L pre = L unlabel + L label<label>(11)</label></formula><p>In the pre-training process, we mix and shuffle UniDA and UnDial, and randomly sample batches from the mixed corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Fine-tuning and Inference</head><p>In the fine-tuning stage, we concentrate on task-oriented dialog tasks. For tasks that contained necessary semantic labels (e.g., belief states and dialog acts), we re-organize the response r to contain those labels, and generate them together. Suppose the sequence of the labels is d. Thus the new response r * = (d, r) is the concatenation of d and r and is generated in the downstream tasks. For tasks that do not have semantic labels, we generate the initial response r. We also maintain the DA prediction task to alleviate the model discrepancy between pre-training and fine-tuning <ref type="bibr" target="#b67">(Zeng and Nie 2021)</ref>. Therefore, The fine-tuning loss is as follows:</p><formula xml:id="formula_11">L fine = L RS + L RG + ?L DA<label>(12)</label></formula><p>where ? = 1 for tasks that provide DA annotations and ? = 0 for tasks that contain no DA annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation Datasets</head><p>We evaluate the end-to-end dialog system performance of GALAXY on two well-studied task-oriented dialog benchmarks: Stanford In-Car Assistant (In-Car) (Eric and Manning 2017), MultiWOZ <ref type="bibr" target="#b4">(Budzianowski et al. 2018</ref>). In-Car consists of dialogs between a user and an in-car assistant system covering three tasks: calendar scheduling, weather information retrieval, and point-of-interest navigation. Following the data processing in <ref type="bibr" target="#b69">(Zhang et al. 2020a</ref>), we divide the dataset into training/validation/testing sets with 2425/302/304 dialogs respectively. MultiWOZ is a largescale human-human dataset spanning seven domains, which is one of the most challenging datasets in task-oriented dialog due to its complex ontology and diverse language styles. We evaluate our model on MultiWOZ2.0 (the original version) and MultiWOZ2.1 (a revised version) since both are popular benchmarks with various competing models. Following the data processing in <ref type="bibr" target="#b65">Yang, Li, and Quan (2020)</ref>, we obtain 8438/1000/1000 dialogs for training/validation/testing respectively. We also adopt delexicalized responses for task-oriented generation, which allows the model to learn value-independent parameters (Zhang, Ou, and Yu 2020).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Metrics</head><p>We use BLEU <ref type="bibr" target="#b44">(Papineni et al. 2002)</ref> to measure the response generation quality. Metrics relate to task completion are used for separate datasets to facilitate comparison with prior works. For MultiWOZ, we report Inform, Success, as a combined score (Comb) is also computed via (Inform + Success)?0.5+BLEU as an overall quality measure as in <ref type="bibr" target="#b40">Mehri, Srinivasan, and Eskenazi (2019)</ref>. For In-Car, we use Match and SuccF1 following <ref type="bibr" target="#b30">Lei et al. (2018)</ref>, and calculate a similar combined score (Comb) via (Match + SuccF1)?0.5+BLEU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental Results</head><p>In our experiments, we focus on the setting of end-to-end dialog modeling (E2E), in which no ground-truth immediate labels are provided to the model. GALAXY is initialized with UniLM and then performs semi-supervised pretraining with UniDA and UnDial. Notably, we removed the validation and testing set of MultiWOZ from UniDA during pre-training for fairness. We compare GALAXY with all published work on respective datasets. We also compare different pre-trained conversation models (PCMs) and different semi-supervised pre-training methods to verify the efficacy of GALAXY. In addition, we conduct an extensive discussion and analysis to reveal the internal performance of GALAXY. More details about implementation can be found in Appendix B.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Benchmark Performance</head><p>As shown in <ref type="table" target="#tab_8">Table 3</ref> and   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Comparison with Other PCMs</head><p>We verify that GALAXY has a much better ability to fulfill task-oriented dialog tasks than other PCMs due to modeling dialog policy during pre-training. To alleviate the discrepancy brought from model structure, we use UniLM <ref type="bibr" target="#b14">(Dong et al. 2019</ref>) and PLATO <ref type="bibr" target="#b2">(Bao et al. 2020</ref>) as our baselines. We also train both models on our pre-training dialog datasets (UniDA and UnDial) with their original objectives and perform the same fine-tuning process on MultiWOZ2.0. We denote the new models as TOD-UniLM and TOD-PLATO, respectively. As shown in <ref type="table" target="#tab_11">Table 5</ref>, the results of both models are worse than GALAXY due to the lack of using important information of dialog policy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Comparison with Other Semi-supervised Pre-training Methods</head><p>As shown in <ref type="table" target="#tab_12">Table 6</ref>, we also compare GALAXY with other semi-supervised pre-training methods on MultiWOZ2.0. Specifically, we employ three baselines: Pseudo-Labeling, Variation Autoencoder (VAE), and multi-task learning. More details about the first two approaches are offered in Appendix C. For multi-task learning, we discard the L KL loss for GALAXY, which represents that model does not perform any inference over DA labels on UnDial. We denote this method as GALAXY multi . The results in <ref type="table" target="#tab_12">Table 6</ref> show that VAE has the worst performance because it is difficult to pre-train stochastic latent variables well. Multi-task learning is the most substantial baseline among the three methods, which indicates the importance of integrating DA annotations in the pre-training process. However, without inference on unlabeled dialog samples, GALAXY multi can not explore the stored knowledge of dialog policy thoroughly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Low Resource Evaluation</head><p>Many recent works <ref type="bibr" target="#b47">(Peng et al. 2020b;</ref> have demonstrated that pre-trained models have a solid fewshot ability in the understanding and conditional generation   tasks. We also evaluate GALAXY in the simulated low resource setting on MultiWOZ2.0, showing that it is more sample-efficiency than existing models. Specifically, we use 5%, 10%, 20%, and 50% of the training set data to train our models and baselines. To be fair, we discard the (1-X%) training data of MultiWOZ from UniDA in the pretraining process under each X% setting, eliminating the influence of using any external data. Compared baselines include: DAMD <ref type="bibr" target="#b70">(Zhang, Ou, and Yu 2020)</ref>, SOLOIST <ref type="bibr" target="#b46">(Peng et al. 2020a</ref>), MinTL , PPTOD <ref type="bibr" target="#b56">(Su et al. 2021)</ref> and UBAR <ref type="bibr" target="#b65">(Yang, Li, and Quan 2020)</ref>. Experimental results in <ref type="table" target="#tab_14">Table 7</ref> show that GALAXY significantly outperforms other models under all low-resource settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Analysis and Discussion</head><p>In this section, we try to answer three questions: (1) How does our semi-supervised method work during the pretraining process? (2) How much improvements does L DA , L KL and the gating mechanism contribute? (3) How can our model improve task completion in real cases?</p><p>Learning Curve. In order to figure out how consistency regularization loss can influence the pre-training, we monitor the predicted DA accuracy and L KL . Specifically, we conduct a simulated experiment where 10% UniDA and 100% UnDial are used for training, and the rest of UniDA is held out as a testing set. Then we observe the testing DA F1 score and the L KL loss on the rest of UniDA data. Note that our goal is to mimic the actual case that whether the model can learn well given limited labeled data and large unlabeled data. As we can see from <ref type="figure">Figure 5</ref>, L KL decreases to zero at   the beginning, indicating that the model falls into the collapsing mode <ref type="bibr" target="#b9">(Chen and He 2021)</ref>, which means all outputs collapse to a constant. However, since we have the L DA loss on labeled data, the collapsing problem can be tackled in the following iterations. On the other hand, the regularization loss L KL performs on the labeled data can also avoid overfitting to some extent, which is shown in <ref type="figure">Figure 5</ref> that the testing DA F1 score keeps increasing during the pre-training without degradation.</p><p>Ablation Results. <ref type="table" target="#tab_15">Table 8</ref> shows the ablation results of GALAXY on MultiWOZ2.0. Without L DA , GALAXY performs worst because of the collapsing problem. GALAXY without L KL equals to multi-task learning, but the results are not as good as our semi-supervised learning due to the inadequate utilization of unlabeled data. If we discard both losses, which backs to the use of common pre-training objectives L RS and L RG , we can acquire 106.79 in Comb, suggesting that our pre-training dialog datasets are high-quality and can facilitate task-oriented dialog training. We also examine the function of the gating mechanism. Note that adding the gate g is essential for improving model performance <ref type="formula">(</ref>  <ref type="table">Table 9</ref>: Examples of predicted gating scores give the context. Responses are also annotated with DAs for analysis. 'N.A.' means we cannot find a suitable DA for the response. ble 9 shows the predicted gating scores of four utterances from UnDial and the DAs annotated manually for the corresponding responses.</p><p>Case Study. <ref type="figure">Figure 4</ref> illustrates a case where GALAXY chooses correct dialog acts for the first two turns so that the whole conversation can steer towards successful task completion. On the contrary, UBAR takes a wrong DA notifyfailure at the beginning turn and a redundant DA request at the second turn, which leads to a failure for the interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>In this paper, we propose GALAXY, a pre-trained conversation model that learns dialog policy explicitly in the pretraining process via semi-supervised learning. We introduce a dialog act prediction task for policy optimization and use a consistency regularization loss to learn better representations on unlabeled dialog corpora. A gating mechanism is also used to weigh suitable unlabeled samples. Experiments show that our model creates new SOTA results on several task-oriented dialog benchmarks and outperforms existing models by a large margin in various low-resource settings. We hope that GALAXY, and the newly collected labeled dataset UniDA and large-scale unlabeled corpus UnDial, can inspire researchers to explore the new paradigm to build pretrained conversation models for task-oriented dialog.</p><p>Information Providing. This group consists of DAs that provides specific answers to the user.</p><p>? affirm denotes the affirmative responses. e.g., 'Yes, it is.' ? not sure means the system is not certain about the user's confirmation. ? negate denotes the negating responses. 'Noe, it is not.' ? inform denotes the normal answers to give the information required by the user. e.g., 'The hotel is in the east area.' ? offer means the system offer the current searching results from the database that match the user's need. e.g., 'There are 10 restaurants I've found for you.'</p><p>? notify-success means the system notifies the user that his/her goal is finished successfully . e.g., 'Sure, the XXX is a good one, I've booked it for you.' ? notify-failure means the system notifies the user that his/her goal is not finished successfully . e.g., 'Sorry, I can not book it for you now, because it is full'</p><p>Information Checking. This group consists of DAs that the system ask the user about something to confirm whether it is true or correct.</p><p>? expl-confirm means to ask the user explicitly to check something. e.g. 'Do you need to cheap restaurant ?' ? impl-confirm means to check something implicitly, often in a statement that repeats what user says. e.g. 'You want a cheap restaurant, OKay.'</p><p>A.2. Details for UnDial. The Detailed statistics are given in <ref type="table" target="#tab_3">Table 10</ref>. We totally aggregate 14 dialog corpora from the Internet. The processing methods includes: (1) Removing the instances where there is a URL in utterances.</p><p>(2) Removing the instances containing word repetitions of at least three words (3) removing non-English sentences. (4) removing sentence containing special markers such as "[" or "]", as this could be markup. (5) removing offensive language.</p><p>(6) Replacing the non-unicode characters like emojis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B</head><p>B.1. Inputs and Outputs. <ref type="figure" target="#fig_4">Figure 8</ref> illustrates the input representations in the pre-training stage, we use special tokens [CLS], [BOS] and [EOS] to concatenate sentences in context and the response. Apart from token embeddings, we also have position emebddings, role embeddings and turn embeddings as in <ref type="bibr" target="#b2">Bao et al. (2020)</ref>. For the fine-tuning stage, we need to consider the semantic labels, such as 'belief states' and 'database results', so we add more special tokens to concatenate them as in <ref type="bibr" target="#b65">Yang, Li, and Quan (2020)</ref>. <ref type="figure">Figure 9</ref> shows the input sequence of GALAXY in downstream tasks: In-Car and MultiWOZ.</p><p>B.2. Implementation Details. We introduce hyperparameters used in pre-training and fine-tuning as follows. The number of transformer blocks in GALAXY is 12 and the hidden embedding dimension is 768. The total number of dialog acts N is 20. In the pre-training stage, GALAXY is initialized with UniLM. The maximum sequence length of dialog context and response is set to 256 and 50, respectively. The batch size is set to 128 and AdamW optimizer is employed for optimization with an initial learning rate of 1e-5. The dropout rate is set to 0.3 for consistency regularization. For semi-supervised pre-training, at each iteration, we mix and shuffle the labeled dataset UniDA and unlabeled dataset UnDial, then randomly sample batches from the mixed corpus as the input of GALAXY. We use a random seed 11, and choose the model checkpoint at the 14th epoch as the final pre-trained model.</p><p>For the fine-tuning stage, the maximum sequence length of dialog context and response is set to 1024 and 100 due to longer responses including semantic labels. The grid search algorithm is applied on the validation set to automatically    tune the hyper-parameters. We use AdamW optimizer with an initial learning rate of 1e-4. For MultiWOZ dataset, the batch size is set to 32 and the dropout rate is set to 0.1. For In-Car dataset, the batch size is set to 64 and the dropout rate is set to 0.35.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C</head><p>C.1. Other Semi-supervised Pre-training Methods.</p><p>Pseudo-Labelling. This method is to train the model with the self-predicted pseudo labels. Specifically, we first train a model with the same architecture as GALAXY with the loss L = L DA + L RS + L RG on labeled data, then we use the trained model to predict all pseudo labels on the UnDial. We then train another model the same architecture as GALAXY on all data with the labeled loss in Eq.(8).  <ref type="figure">Figure 9</ref>: An example of input sequence in downstream tasks. Different colors denote different semantic labels and all labels are converted to text spans: blue for user utterances, orange for belief states, green for database results, red for dialog acts and purple for delexicalized responses.</p><p>Variational Autoencoder (VAE). <ref type="figure" target="#fig_3">Figure 7</ref> shows the framework for the VAE method. We leverage a hidden variable z that has the same size as dialog act a. For unlabeled data, the generative process of r is <ref type="figure" target="#fig_3">(Figure 7 (a)</ref>):</p><p>1. Sample a latent variable z based on the dialog context c and response r for training: q ? (z|c, r) while only based on the dialog context c for testing: p ? (z|c).</p><p>2. Generate the response r based on the dialog context c and latent variable z: p ? (r|z, c).</p><p>which is computed as:</p><formula xml:id="formula_12">L unlabel = L(?, ?; r, c) = KL (q ? (z|r, c) p ? (z|c)) ? E q ? (z|c,r) [log p ? (r|z, c)] + L RS<label>(13)</label></formula><p>For labeled data, the generative process of r is <ref type="figure" target="#fig_3">(Figure 7  (b)</ref>):</p><p>1. Sample a latent variable z based on the dialog context c, response r and dialog act a for training: q ? (z|c, r, a) while only based on the dialog context c for testing: p ? (z|c).</p><p>2. Predict the dialog act a based on the dialog context c and latent variable z: p ? (a|z, c).</p><p>3. Generate the response r based on the dialog context c, latent variable z and dialog act a: p ? (r|z, c, a).</p><p>which is computed as: </p><p>To sum up, the final loss L pre for the semi-supervised pretraining is computed as</p><formula xml:id="formula_14">L pre = L unlabel + L label<label>(15)</label></formula><p>Appendix D <ref type="table" target="#tab_3">Table 11</ref> shows the total end-to-end results given oracle belief states on MultiWOZ2.0 and MultiWOZ2.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Architecture of our pre-trained dialog model. The left part illustrate the input representations, which contain embeddings of tokens, roles, turns, and positions. The right part shows the pre-trained objectives. Blue lines denote the bi-directional attention. Dashed yellow lines denote the uni-directional attention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>LKLFigure 3 :</head><label>3</label><figDesc>The procedure of computing L KL .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>The proposed unified DA taxonomy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 7 :</head><label>7</label><figDesc>Graphical models of VAE method for semisupervised pre-training, in which z is the latent variable. The model for unlabeled data is on the left and the model for labeled data is on the right.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>Input representations for the pre-training process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>L</head><label></label><figDesc>label = L(?, ?; r, c, a) = KL (q ? (z|r, c, a) p ? (z|c)) ? E q ? (z|c,r,a) [log p ? (r|z, c, a)] ? E q ? (z|c,r,a) [log p ? (a|z, c)]+ L RS + L DA</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the labeled dataset UniDA.</figDesc><table><row><cell># Datasets</cell><cell>14</cell></row><row><cell># Dialog Sessions</cell><cell>14M</cell></row><row><cell># Utterances</cell><cell>35M</cell></row><row><cell>Avg. Utterances per Dialog</cell><cell>2.5</cell></row><row><cell>Avg. Tokens per Utterance</cell><cell>14.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Statistics of the unlabeled dataset UnDial.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>a fully-connected neural network with the output layer of size N . y i ? {0, 1} is the true label of a i .</figDesc><table><row><cell></cell><cell>p1(a|c)</cell><cell>p2(a|c)</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Sigmoid</cell><cell></cell></row><row><cell></cell><cell>Softmax</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>FC</cell><cell></cell></row><row><cell>LKL</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Multi-label classification</cell><cell>DA Distribution</cell><cell></cell><cell></cell></row><row><cell>LDA</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Softmax</cell><cell>Softmax</cell></row><row><cell>Sigmoid</cell><cell>Softmax</cell><cell>Transformer Blocks</cell><cell>Transformer Blocks</cell></row><row><cell></cell><cell>(XX dim)</cell><cell></cell><cell></cell></row><row><cell>FC</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>(768 dim)</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>, GALAXY achieves new</cell></row></table><note>tables, GALAXY also achieves comparable results with pre- vious best models, indicating that our model architecture is competitive for dialog modeling. More E2E results given or- acle belief states on MultiWOZ are shown in Appendix D.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 :</head><label>3</label><figDesc>E2E performances on MultiWOZ2.0/2.1. All results are from original papers. 'w/o pre-train' means using original weights of UniLM for initialization.</figDesc><table><row><cell>Model</cell><cell cols="3">Match SuccF1 BLEU Comb</cell></row><row><cell>SEDST (Jin et al. 2018)</cell><cell>84.50</cell><cell>82.90</cell><cell>19.30 103.00</cell></row><row><cell>TSCP (Lei et al. 2018)</cell><cell>84.50</cell><cell>81.10</cell><cell>21.90 104.70</cell></row><row><cell>LABES (Zhang et al. 2020a)</cell><cell>85.80</cell><cell>77.00</cell><cell>22.80 104.20</cell></row><row><cell>FSDM (Shu et al. 2019)</cell><cell>84.80</cell><cell>82.10</cell><cell>21.50 104.95</cell></row><row><cell>GALAXY (w/o pre-train)</cell><cell>81.90</cell><cell>83.30</cell><cell>22.00 104.60</cell></row><row><cell>GALAXY</cell><cell>85.30</cell><cell>83.60</cell><cell>23.00 107.45</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: E2E performances on In-Car. All results are from</cell></row><row><cell>original papers. 'w/o pre-train' means using original weights</cell></row><row><cell>of UniLM for initialization.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell cols="5">: E2E performances of different pre-trained conver-</cell></row><row><cell cols="2">sation models on MultiWOZ2.0.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell cols="4">Inform Success BLEU Comb</cell></row><row><cell>Pseudo-Labeling</cell><cell>90.10</cell><cell>80.30</cell><cell cols="2">16.79 101.99</cell></row><row><cell>VAE</cell><cell>89.00</cell><cell>76.40</cell><cell>16.48</cell><cell>99.18</cell></row><row><cell>GALAXY multi</cell><cell>93.90</cell><cell>82.30</cell><cell cols="2">19.17 107.27</cell></row><row><cell>GALAXY</cell><cell>94.40</cell><cell>85.30</cell><cell cols="2">20.50 110.35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 6 :</head><label>6</label><figDesc>E2E performance of different semi-supervised pretraining methods on MultiWOZ2.0.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 7 :</head><label>7</label><figDesc>E2E results of low-resource experiments. 5% (400 dialogs), 10% (800 dialogs), 20% (1600 dialogs), 50% (4000 dialogs) of training data is used to train each model. * denotes our re-implementation results.</figDesc><table><row><cell>Model</cell><cell cols="3">Inform Success BLEU Comb</cell></row><row><cell>GALAXY</cell><cell>94.40</cell><cell>85.30</cell><cell>20.50 110.35</cell></row><row><cell>?g</cell><cell>94.20</cell><cell>83.50</cell><cell>19.26 108.11</cell></row><row><cell>?L DA</cell><cell>89.10</cell><cell>79.90</cell><cell>18.77 103.27</cell></row><row><cell>?L KL</cell><cell>93.90</cell><cell>82.30</cell><cell>19.17 107.27</cell></row><row><cell>?L DA ? L KL</cell><cell>93.30</cell><cell>81.20</cell><cell>19.54 106.79</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 8 :</head><label>8</label><figDesc>E2E results of ablation study on MultiWOZ2.0.</figDesc><table><row><cell cols="3">User: are there any restaurants that serve proper british food in town?</cell><cell>Turn 1</cell></row><row><cell cols="3">Ground Truth Response: oh yes [value_choice]. which part of town</cell></row><row><cell>will you be dining in?</cell><cell></cell><cell>DA: [inform; request]</cell></row><row><cell cols="3">UBAR: there are no [value_food] restaurants in [value_area]. do you</cell></row><row><cell cols="3">want to try a different type of cuisine? DA: [notify-failure; request]</cell></row><row><cell cols="3">GALAXY: there are [value_choice] restaurants that serve [value_food]</cell></row><row><cell>food. what area would you like to dine in?</cell><cell cols="2">DA: [inform; request]</cell></row><row><cell>User: west, if possible.</cell><cell></cell><cell>Turn 2</cell></row><row><cell cols="3">Ground Truth Response: we have [value_choice]: [value_name],</cell></row><row><cell>[value_name] and [value_name].</cell><cell></cell><cell>DA [inform]</cell></row><row><cell cols="3">UBAR: would you like to try a different type of cuisine? DA: [request]</cell></row><row><cell cols="3">GALAXY: there are [value_choice] restaurants in the [value_area]:</cell></row><row><cell cols="2">[value_name], [value_name] and [value_name].</cell><cell>DA: [inform]</cell></row><row><cell cols="3">Figure 4: Case Study: Delexicalized responses generated by</cell></row><row><cell cols="3">GALAXY and UBAR on MultiWOZ2.0 test data.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 10 :</head><label>10</label><figDesc>Statistics for each corpus in UnDial.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 11 :</head><label>11</label><figDesc>E2E performances given oracle belief states on MultiWOZ2.0/2.1. All results are from original papers. 'w/o pre-train' means using original weights of UniLM for initialization.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In some datasets, the dialog act is defined as a combination of an act and its semantic contents. To unify different datasets, we neglect the contents and only use dialog acts as the annotations. We also focus on the text-in-text-out TOD systems in this paper, and leave the spoken DA in the future research.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was supported by Alibaba Group through Alibaba Research Intern Program. This work was partially supported by National Natural Science Foundation of China (No. 61906185), Youth Innovation Promotion Association of CAS China (No. 2020357), Shenzhen Science and Technology Innovation Program (Grant No. KQTD20190929172835662), Shenzhen Basic Research Foundation (No. JCYJ20200109113441941). We also thank Dr. Yichi Zhang for the cute cartoon in <ref type="figure">Figure 1.</ref> </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix Appendix A</head><p>A.1. Unified DA Taxonomy. The hierarchical structure of our proposed unified DA taxonomy is illustrated in <ref type="figure">Figure 6</ref>. There are totally 20 labels.</p><p>Social Convention. This group consists of DAs about regular actions for social behaviors: hi, bye, thank you, repeat, welcome, dont understand.</p><p>? hi means greeting responses, like 'hello', 'how are you'. ? bye means the responses for saying goodbye.</p><p>? thank you means the responses for appreciation.</p><p>? repeat means asking the user to repeat what he/she said last turn again. ? welcome denotes a paragraph of official texts to broadcast the information that the system can offer, like 'welcome to Cambridge restaurant, we can help you to order food, you can find restaurants by talking about your favorite foods, area, price range.' ? dont understand means the system can not understand what the user says, which is normal when the user talk about something beyond the semantic scope that the system can process.</p><p>Directive. This group consists of DAs about providing suggestions or imperative orders.</p><p>? propose means suggesting to do/offer/recommend something, in order to make the user consider the performance of a certain action, which the system believes is in the user's interests. For example 'How about we find a good place to have fun.' ? direct means imperative responses that expresses an order, e.g., 'you need to open the light before going to bad.'</p><p>Information Seeking. This group consists of DAs that perform actions about asking.</p><p>? request means asking the user about specific attributes, like 'what area do you like?' ? select means asking the user to choose a preferred choices from a set of candidates. ? reqalts means asking the user for more information. e.g., 'what else information do you want?'</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Adiwardana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nemade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.09977</idno>
		<title level="m">Towards a human-like open-domain chatbot</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Frames: a corpus for adding memory to goal-oriented dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Asri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mehrotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Suleman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.00057</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Hello, it&apos;s GPT-2-how can I help you? towards the use of pretrained language models for task-oriented dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vuli?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.05774</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">MultiWOZ-A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-H</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ramadan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ga?i?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.00278</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The DIT++ taxonomy for functional dialogue markup</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bunt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAMAS 2009 Workshop, Towards a Standard Markup Language for Embodied Dialogue Acts</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards an ISO standard for dialogue act annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Alexandersson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carletta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hasida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Petukhova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Popescu-Belis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh conference on International Language Resources and Evaluation (LREC&apos;10)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Krishnamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duckworth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cedilnik</surname></persName>
		</author>
		<title level="m">Taskmaster-1: Toward a Realistic and Diverse Dialog Dataset</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Action-Based Conversations Dataset: A Corpus for Building More In-Depth Task-Oriented Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.00783</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exploring simple siamese representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15750" to="15758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Attend and Review: Schema-Aware Curriculum Learning for Multi-Domain Dialogue State Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Preview</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-IJCNLP</title>
		<imprint>
			<biblScope unit="page" from="879" to="885" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Chameleons in Imagined Conversations: A New Approach to Understanding Coordination of Linguistic Style in Dialogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Cognitive Modeling and Computational Linguistics</title>
		<meeting>the 2nd Workshop on Cognitive Modeling and Computational Linguistics<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="76" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unified Language Model Pre-training for Natural Language Understanding and Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Hon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">33rd Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Key-value retrieval networks for task-oriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.05414</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Talking to myself: self-dialogues as data for conversational agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fainberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dobre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Damonte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kahembwe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Webber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fancellu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.06641</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.08821</idno>
		<title level="m">SimCSE: Simple Contrastive Learning of Sentence Embeddings</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hedayatnia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gottardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-T?r</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
	<note>Advances in neural information processing systems. In Interspeech 2019</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">AmazonQA: A Review-Based Question Answering Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rayasam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Multi-goal multi-agent learning for task-oriented dialogue with bidirectional teacher-student learning. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">213</biblScope>
			<biblScope unit="page">106667</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Amalgamating knowledge from two teachers for taskoriented dialogue system with adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3498" to="3507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrk?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vuli?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03688</idno>
		<title level="m">Convert: Efficient and accurate conversational representations from transformers</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The second dialog state tracking challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th annual meeting of the special interest group on discourse and dialogue (SIGDIAL)</title>
		<meeting>the 15th annual meeting of the special interest group on discourse and dialogue (SIGDIAL)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="263" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">A simple language model for task-oriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hosseini-Asl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mccann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yavuz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00796</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Domain State Tracking for a Simplified Dialogue System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.06648</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Explicit state tracking with semi-supervision for neural dialogue generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1403" to="1412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Augpt: Dialogue with pre-trained language models and data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kulh?nek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hude?ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nekvinda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Du?ek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02691</idno>
		<idno>arXiv:2102.05126</idno>
	</analytic>
	<monogr>
		<title level="m">An introduction to variational autoencoders</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">896</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sequicity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1437" to="1447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Microsoft dialogue challenge: Building endto-end task-completion dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.11125</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Niu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.03957</idno>
		<title level="m">Dailydialog: A manually labelled multi-turn dialogue dataset</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.14448</idno>
		<title level="m">2021. R-Drop: Regularized Dropout for Neural Networks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">I</forename><surname>Winata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.12005</idno>
		<title level="m">Mintl: Minimalist transfer learning for task-oriented dialogue systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.06512</idno>
		<title level="m">Dialogue learning with human teaching and feedback in end-to-end trainable task-oriented dialogue systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Variational Latent-State GPT for Semisupervised Task-Oriented Dialog Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.04314</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">LAVA: Latent Action Spaces via Variational Auto-encoding for Dialogue Policy Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lubis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Geishauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Niekerk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Dialoglue: A natural language understanding benchmark for task-oriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.13570</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Razumovskaia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.00414</idno>
		<title level="m">Pretraining methods for dialog context representation learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.10016</idno>
		<title level="m">Structured fusion networks for dialog</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Star: A schemaguided dialog dataset for transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Mosig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kober</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11853</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Neural Belief Tracker: Data-Driven Dialogue State Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>S?aghdha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Conversational Scaffolding: An Analogy-Based Approach to Response Prioritization in Open-Domain Dialogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Etchart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fulda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">BLEU: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Towards universal dialogue act tagging for task-oriented dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-T?r</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.03020</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shayandeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.05298</idno>
		<title level="m">SOLOIST: Building Task Bots at Scale with Transfer Learning and Machine Teaching</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Few-shot natural language generation for taskoriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.12328</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Coached Conversational Preference Elicitation: A Case Study in Understanding Movie Preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Radlinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Krishnamoorthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 20th Annual SIGdial Meeting on Discourse and Dialogue<address><addrLine>Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="353" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sunkara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Khaitan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8689" to="8696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13637</idno>
		<title level="m">Recipes for building an open-domain chatbot</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Bootstrapping a neural conversational agent with dialogue selfplay, crowdsourcing and on-line reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL (Industry Papers)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="41" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Few-Shot Dialogue Generation Without Annotated Data: A Transfer Learning Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shalyminov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Eshghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Lemon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 20th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Namazifar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tur</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.02402</idno>
		<title level="m">Flexibly-structured model for taskoriented dialogues</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Sample-efficient actor-critic reinforcement learning with supervised data for dialogue management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.00130</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Mansimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<idno>abs/2109.14739</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Ernie 2.0: A continual pre-training framework for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="8968" to="8975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Transferable Dialogue Systems and User Simulators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-H</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kreyssig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="152" to="166" />
		</imprint>
	</monogr>
	<note>Online: Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Interpolation consistency training for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kawaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.03825</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Modelling hierarchical structure between dialogue policy and natural language generator with option framework for task-oriented dialogue system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>ICLR 2021</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Multi-Domain Dialogue Acts and Response Co-Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">TOD-BERT: pre-trained natural language understanding for taskoriented dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Probing task-oriented dialogue representation from language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.13912</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.00420</idno>
		<title level="m">Dialogue-oriented Pre-training</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">UBAR: Towards Fully End-to-End Task-Oriented Dialog Systems with</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Quan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.03539</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">GPT-2. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">SCoRe: Pre-Training for Context Representation in Conversational Semantic Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Awadallah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">An Investigation of Suitability of Pre-Trained Language Models for Dialogue Generation-Avoiding Discrepancies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Personalizing Dialogue Agents: I have a dog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>do you have pets too</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9207" to="9219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Task-oriented dialog systems that consider multiple appropriate responses under the same context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9604" to="9611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Dialogpt: Large-scale generative pre-training for conversational response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
