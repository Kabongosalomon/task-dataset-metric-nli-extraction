<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A unifying mutual information view of metric learning: cross-entropy vs. pairwise losses</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-11-26">26 Nov 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malik</forename><surname>Boudiaf</surname></persName>
							<email>malik.boudiaf.1@etsmtl.net</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire d&apos;Imagerie, de Vision et d&apos;Intelligence Artificielle (LIVIA)</orgName>
								<orgName type="institution">?TS Montreal</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?r?me</forename><surname>Rony</surname></persName>
							<email>jerome.rony.1@etsmtl.net</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire d&apos;Imagerie, de Vision et d&apos;Intelligence Artificielle (LIVIA)</orgName>
								<orgName type="institution">?TS Montreal</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imtiaz</forename><forename type="middle">Masud</forename><surname>Ziko</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire d&apos;Imagerie, de Vision et d&apos;Intelligence Artificielle (LIVIA)</orgName>
								<orgName type="institution">?TS Montreal</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Granger</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire d&apos;Imagerie, de Vision et d&apos;Intelligence Artificielle (LIVIA)</orgName>
								<orgName type="institution">?TS Montreal</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pedersoli</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire d&apos;Imagerie, de Vision et d&apos;Intelligence Artificielle (LIVIA)</orgName>
								<orgName type="institution">?TS Montreal</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Piantanida</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Laboratoire des Signaux et Syst?mes (L2S), CentraleSupelec-CNRS-Universit? Paris-Saclay</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><forename type="middle">Ben</forename><surname>Ayed</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire d&apos;Imagerie, de Vision et d&apos;Intelligence Artificielle (LIVIA)</orgName>
								<orgName type="institution">?TS Montreal</orgName>
								<address>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A unifying mutual information view of metric learning: cross-entropy vs. pairwise losses</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-11-26">26 Nov 2021</date>
						</imprint>
					</monogr>
					<note>2 M. Boudiaf et al.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:56+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Metric Learning</term>
					<term>Deep Learning</term>
					<term>Information Theory * Equal contributions ? Code available at: https</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, substantial research efforts in Deep Metric Learning (DML) focused on designing complex pairwise-distance losses, which require convoluted schemes to ease optimization, such as sample mining or pair weighting. The standard cross-entropy loss for classification has been largely overlooked in DML. On the surface, the cross-entropy may seem unrelated and irrelevant to metric learning as it does not explicitly involve pairwise distances. However, we provide a theoretical analysis that links the cross-entropy to several well-known and recent pairwise losses. Our connections are drawn from two different perspectives: one based on an explicit optimization insight; the other on discriminative and generative views of the mutual information between the labels and the learned features. First, we explicitly demonstrate that the cross-entropy is an upper bound on a new pairwise loss, which has a structure similar to various pairwise losses: it minimizes intra-class distances while maximizing inter-class distances. As a result, minimizing the cross-entropy can be seen as an approximate bound-optimization (or Majorize-Minimize) algorithm for minimizing this pairwise loss. Second, we show that, more generally, minimizing the cross-entropy is actually equivalent to maximizing the mutual information, to which we connect several well-known pairwise losses. Furthermore, we show that various standard pairwise losses can be explicitly related to one another via bound relationships. Our findings indicate that the cross-entropy represents a proxy for maximizing the mutual information -as pairwise losses do -without the need for convoluted sample-mining heuristics. Our experiments ? over four standard DML benchmarks strongly support our findings. We obtain state-of-the-art results, outperforming recent and complex DML methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Abstract. Recently, substantial research efforts in Deep Metric Learning (DML) focused on designing complex pairwise-distance losses, which require convoluted schemes to ease optimization, such as sample mining or pair weighting. The standard cross-entropy loss for classification has been largely overlooked in DML. On the surface, the cross-entropy may seem unrelated and irrelevant to metric learning as it does not explicitly involve pairwise distances. However, we provide a theoretical analysis that links the cross-entropy to several well-known and recent pairwise losses. Our connections are drawn from two different perspectives: one based on an explicit optimization insight; the other on discriminative and generative views of the mutual information between the labels and the learned features. First, we explicitly demonstrate that the cross-entropy is an upper bound on a new pairwise loss, which has a structure similar to various pairwise losses: it minimizes intra-class distances while maximizing inter-class distances. As a result, minimizing the cross-entropy can be seen as an approximate bound-optimization (or Majorize-Minimize) algorithm for minimizing this pairwise loss. Second, we show that, more generally, minimizing the cross-entropy is actually equivalent to maximizing the mutual information, to which we connect several well-known pairwise losses. Furthermore, we show that various standard pairwise losses can be explicitly related to one another via bound relationships. Our findings indicate that the cross-entropy represents a proxy for maximizing the mutual information -as pairwise losses do -without the need for convoluted sample-mining heuristics. Our experiments ? over four standard DML benchmarks strongly support our findings. We obtain state-of-the-art results, outperforming recent and complex DML methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keywords: Metric Learning, Deep Learning, Information Theory</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The core task of metric learning consists in learning a metric from high-dimensional data, such that the distance between two points, as measured by this metric, reflects their semantic similarity. Applications of metric learning include image retrieval, zero-shot learning or person re-identification, among others. Initial attempts to tackle this problem tried to learn metrics directly on the input space <ref type="bibr" target="#b15">[16]</ref>. Later, the idea of learning suitable embedding was introduced, with the goal of learning Mahalanobis distances <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b43">44]</ref>, which corresponds to learning the best linear projection of the input space onto a lower-dimensional manifold, and using the Euclidean distance as a metric. Building on the embedding-learning ideas, several papers proposed to learn more complex mappings, either by kernelization of already existing linear algorithms <ref type="bibr" target="#b2">[3]</ref>, or by using a more complex hypothesis such as linear combinations of gradient boosted regressions trees <ref type="bibr" target="#b10">[11]</ref>.</p><p>The recent success of deep neural networks at learning complex, nonlinear mappings of high-dimensional data aligns with the problem of learning a suitable embedding. Following works on Mahalanobis distance learning, most Deep Metric Learning (DML) approaches are based on pairwise distances. Specifically, the current paradigm is to learn a deep encoder that maps points with high semantic similarity close to each other in the embedded space (w.r.t. pairwise Euclidean or cosine distances). This paradigm concretely translates into pairwise losses that encourage small distances for pairs of samples from the same class and large distances for pairs of samples from different classes. While such formulations seem intuitive, the practical implementations and optimization schemes for pairwise losses may become cumbersome, and randomly assembling pairs of samples typically results in slow convergence or degenerate solutions <ref type="bibr" target="#b8">[9]</ref>. Hence, research in DML focused on finding efficient ways to reformulate, generalize and/or improve sample mining and/or sample weighting strategies over the existing pairwise losses. Popular pairwise losses include triplet loss and its derivatives <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b49">50]</ref>, contrastive loss and its derivatives <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b39">40]</ref>, Neighborhood Component Analysis and its derivatives <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b42">43]</ref>, among others. However, such modifications are often heuristic-based, and come at the price of increased complexity and additional hyper-parameters, reducing the potential of these methods in realworld applications. Furthermore, the recent experimental study in <ref type="bibr" target="#b17">[18]</ref> showed that the improvement brought by an abundant metric learning literature in the last 15 years is at best marginal when the methods are compared fairly.</p><p>Admittedly, the objective of learning a useful embedding of data points intuitively aligns with the idea of directly acting on the distances between pairs of points in the embedded space. Therefore, the standard cross-entropy loss, widely used in classification tasks, has been largely overlooked by the DML community, most likely due to its apparent irrelevance for Metric Learning <ref type="bibr" target="#b41">[42]</ref>. As a matter of fact, why would anyone use a point-wise prediction loss to enforce pairwisedistance properties on the embedding space? Even though the cross-entropy was shown to be competitive for face recognition applications <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>, to the best of our knowledge, only one paper empirically observed competitive results of a normalized, temperature-weighted version of the cross-entropy in the context of deep metric learning <ref type="bibr" target="#b48">[49]</ref>. However, the authors did not provide any theoretical insights for these results.</p><p>On the surface, the standard cross-entropy loss may seem unrelated to the pairwise losses used in DML. Here, we provide theoretical justifications that connect directly the cross-entropy to several well-known and recent pairwise losses. Our connections are drawn from two different perspectives; one based on an explicit optimization insight and the other on mutual-information arguments. We show that four of the most prominent pairwise metric-learning losses, as well as the standard cross-entropy, are maximizing a common underlying objective: the Mutual Information (MI) between the learned embeddings and the corresponding samples' labels. As sketched in Section 2, this connection can be intuitively understood by writing this MI in two different, but equivalent ways. Specifically, we establish tight links between pairwise losses and the generative view of this MI. We study the particular case of contrastive loss <ref type="bibr" target="#b6">[7]</ref>, explicitly showing its relation to this MI. We further generalize this reasoning to other DML losses by uncovering tight relations with contrastive loss. As for the cross-entropy, we demonstrate that the cross-entropy is an upper bound on an underlying pairwise loss -on which the previous reasoning can be applied -which has a structure similar to various existing pairwise losses. As a result, minimizing the cross-entropy can be seen as an approximate bound-optimization (or Majorize-Minimize) algorithm for minimizing this pairwise loss, implicitly minimizing intra-class distances and maximizing inter-class distances. We also show that, more generally, minimizing the cross-entropy is equivalent to maximizing the discriminative view of the mutual information. Our findings indicate that the cross-entropy represents a proxy for maximizing the mutual information, as pairwise losses do, without the need for complex sample-mining and optimization schemes. Our comprehensive experiments over four standard DML benchmarks (CUB200, Cars-196, Stanford Online Product and In-Shop) strongly support our findings. We consistently obtained state-of-the-art results, outperforming many recent and complex DML methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary of contributions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Establishing relations between several pairwise DML losses and a generative</head><p>view of the mutual information between the learned features and labels;</p><p>2. Proving explicitly that optimizing the standard cross-entropy corresponds to an approximate bound-optimizer of an underlying pairwise loss;</p><p>3. More generally, showing that minimizing the standard cross-entropy loss is equivalent to maximizing a discriminative view of the mutual information between the features and labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>Demonstrating state-of-the-art results with cross-entropy on several DML benchmark datasets. <ref type="table">Table 1</ref>. Definition of the random variables and information measures used in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General</head><p>Labeled dataset</p><formula xml:id="formula_0">D = {(xi, yi)} n i=1 Input feature space X Embedded feature space Z ? R d Label/Prediction space Y ? R K Euclidean distance Dij = zi ? zj 2 Cosine distance D cos ij = z T i z j z i z j Model Encoder ?W : X ? Z Soft-classifier f ? : Z ? [0, 1] K Random variables (RVs) Data X, Y Embedding Z|X ? ?W (X) Prediction Y | Z ? f ? ( Z) Information measures Entropy of Y H(Y ) := Ep Y [? log pY (Y )] Conditional entropy of Y given Z H(Y | Z) := Ep Y Z ? log p Y | Z (Y | Z) Cross entropy (CE) between Y and Y H(Y ; Y ) := Ep Y ? log p Y (Y ) Conditional CE given Z H(Y ; Y | Z) := Ep ZY ? log p Y | Z (Y | Z) Mutual information between Z and Y I( Z; Y ) := H(Y ) ? H(Y | Z)</formula><p>2 On the two views of the mutual information</p><p>The Mutual Information (MI) is a well known-measure designed to quantify the amount of information shared by two random variables. Its formal definition is presented in <ref type="table">Table 1</ref>. Throughout this work, we will be particularly interested in I( Z; Y ) which represents the MI between learned features Z and labels Y . Due to its symmetry property, the MI can be written in two ways, which we will refer to as the discriminative view and generative view of MI:</p><formula xml:id="formula_1">I( Z; Y ) = H(Y ) ? H(Y | Z) discriminative view = H( Z) ? H( Z|Y ) generative view<label>(1)</label></formula><p>While being analytically equivalent, these two views present two different, complementary interpretations. In order to maximize I( Z; Y ), the discriminative view conveys that the labels should be balanced (out of our control) and easily identified from the features. On the other hand, the generative view conveys that the features learned should spread as much as possible in the feature space, while keeping samples sharing the same class close to each other. Hence, the discriminative view is more focused on label identification, while the generative view focuses on more explicitly shaping the distribution of the features learned by the model. Therefore, the MI enables us to draw links between classification losses (e.g. cross-entropy) and feature-shaping losses (including all the well-known pairwise metric learning losses).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Pairwise losses and the generative view of the MI</head><p>In this section, we study four pairwise losses used in the DML community: center loss <ref type="bibr" target="#b41">[42]</ref>, contrastive loss <ref type="bibr" target="#b6">[7]</ref>, Scalable Neighbor Component Analysis (SNCA) loss <ref type="bibr" target="#b42">[43]</ref> and Multi-Similarity (MS) loss <ref type="bibr" target="#b39">[40]</ref>. We show that these losses can be interpreted as proxies for maximizing the generative view of mutual information I( Z; Y ). We begin by analyzing the specific example of contrastive loss, establishing its tight link to the MI, and further generalize our analysis to the other pairwise losses (see <ref type="table">Table 2</ref>). Furthermore, we show that these pairwise metric-learning losses can be explicitly linked to one another via bound relationships.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The example of contrastive loss</head><p>We start by analyzing the representative example of contrastive loss <ref type="bibr" target="#b6">[7]</ref>. For a given margin m ? R + , this loss is formulated as:</p><formula xml:id="formula_2">L contrast = 1 n n i=1 j:yj =yi D 2 ij Tcontrast + 1 n n i=1 j:yj =yi [m ? D ij ] 2 + Ccontrast<label>(2)</label></formula><p>where [x] + = max(0, x). This loss naturally breaks down into two terms: a tightness part T contrast and a contrastive part C contrast . The tightness part encourages samples from the same class to be close to each other and form tight clusters. As for the contrastive part, it forces samples from different classes to stand far apart from one another in the embedded feature space. Let us analyze these two terms from a mutual-information perspective. As shown in the next subsection, the tightness part of contrastive loss is equivalent to the tightness part of the center loss <ref type="bibr" target="#b41">[42]</ref>:</p><formula xml:id="formula_3">T contrast c = T center = 1 2 n i=1 z i ? c yi 2 , where c k = 1 |Z k |</formula><p>z?Z k z denotes the mean of feature points from class k in embedding space Z and symbol c = denotes equality up to a multiplicative and/or additive constant. Written in this way, we can interpret T contrast as a conditional cross entropy between Z and another random variableZ, whose conditional distribution given Y is a standard Gaussian centered around c Y :Z|Y ? N (c Y , I):</p><formula xml:id="formula_4">T contrast c = H( Z;Z|Y ) = H( Z|Y ) + D KL ( Z||Z|Y )<label>(3)</label></formula><p>As such, T contrast is an upper bound on the conditional entropy that appears in the mutual information:</p><formula xml:id="formula_5">T contrast ? H( Z|Y )<label>(4)</label></formula><p>This bound is tight when Z|Y ? N (c Y , I). Hence, minimizing T contrast can be seen as minimizing H( Z|Y ), which exactly encourages the encoder ? W to produce low-entropy (=compact) clusters in the feature space for each given class. Notice that using this term only will inevitably lead to a trivial encoder that maps all data points in X to a single point in the embedded space Z, hence achieving a global optimum.</p><p>To prevent such a trivial solution, a second term needs to be added. This second term -that we refer to as the contrastive term -is designed to push each point away from points that have a different label. In this term, only pairs such that D ij ? m produce a cost. Given a pair (i, j), let us define x = D ij /m. Given that x ? [0, 1], one can show the following:</p><formula xml:id="formula_6">1 ? 2x ? (1 ? x) 2 ? 1 ? x. Using linear approximation (1 ? x) 2 ? 1 ? 2x (with error at most x), we obtain: C contrast c ? ? 2m n n i=1 j:yj =yi D ij = ? 2m n n i=1 n j=1 D ij + 2m n n i=1 j:yj =yi D ij<label>(5)</label></formula><p>While the second term in Eq. 5 is redundant with the tightness objective, the first term is close to the differential entropy estimator proposed in <ref type="bibr" target="#b37">[38]</ref>:</p><formula xml:id="formula_7">H( Z) = d n(n ? 1) n i=1 n j=1 log D 2 ij c = n i=1 n j=1 log D ij<label>(6)</label></formula><p>Both terms measure the spread of Z, even though they present different gradient dynamics. All in all, minimizing the whole contrastive loss can be seen as a proxy for maximizing the MI between the labels Y and the embedded features Z:</p><formula xml:id="formula_8">L contrast = 1 n n i=1 j:yj =yi (D 2 ij + 2mD ij ) ?H( Z|Y ) ? 2m n n i=1 n j=1 D ij ?H( Z) ? ?I( Z; Y ) (7)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Generalizing to other pairwise losses</head><p>A similar analysis can be carried out on other, more recent metric learning losses. More specifically, they can also be broken down into two parts: a tightness part that minimizes intra-class distances to form compact clusters, which is related to the conditional entropy H( Z|Y ), and a second contrastive part that prevents trivial solutions by maximizing inter-class distances, which is related to the entropy of features H( Z). Note that, in some pairwise losses, there might be some redundancy between the two terms, i.e., the tightness term also contains some contrastive subterm, and vice-versa. For instance, the cross-entropy loss is used as the contrastive part of the center-loss but, as we show in Section 4.2, the cross-entropy, used alone, already contains both tightness (conditional entropy) and contrastive (entropy) parts. <ref type="table">Table 2</ref> presents the split for four DML losses. The rest of the section is devoted to exhibiting the close relationships between several pairwise losses and the tightness and contrastive terms (i.e., T and C). Links between losses: In this section, we show that the tightness and contrastive parts of the pairwise losses in <ref type="table">Table 2</ref>, even though different at first sight, can actually be related to one another. <ref type="table">Table 2</ref>. Several well-known and/or recent DML losses broken into a tightness term and a contrastive term. Minimizing the cross-entropy corresponds to an approximate bound optimization of PCE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss</head><p>Tightness part ? H( Z|Y ) Contrastive part ? H( Z)</p><formula xml:id="formula_9">Center [42] 1 2 n i=1 zi ? cy i 2 ? 1 n n i=1 log piy i Contrast [7] 1 n n i=1 j:y j =y i D 2 ij 1 n n i=1 j:y j =y i [m ? Dij] 2 + SNCA [43] ? 1 n n i=1 log j:y j =y i exp D cos ij ? 1 n n i=1 log k =i exp D cos ik ? MS [40] 1 n n i=1 1 ? log 1 + j:y j =y i e ??(D cos ij ?m) 1 n n i=1 1 ? log 1 + j:y j =y i e ?(D cos ij ?m) PCE Prop. 1 ? 1 2?n 2 n i=1 j:y j =y i z T i zj 1 n n i=1 log K k=1 exp 1 ?n n j=1 p jk z T i zj ? 1 2K 2 ? 2 K k=1 c s k 2 Lemma 1.</formula><p>Let T A denote the tightness part of the loss from method A. Assuming that features are 2 -normalized, and that classes are balanced, the following relations between Center <ref type="bibr" target="#b41">[42]</ref>, Contrastive <ref type="bibr" target="#b6">[7]</ref>, SNCA <ref type="bibr" target="#b42">[43]</ref> and MS <ref type="bibr" target="#b39">[40]</ref> losses hold:</p><formula xml:id="formula_10">T SNCA c ? T Center c = T Contrastive c ? T MS<label>(8)</label></formula><p>Where c ? stands for lower than, up to a multiplicative and an additive constant, and c = stands for equal to, up to a multiplicative and an additive constant.</p><p>The detailed proof of Lemma 1 is deferred to the supplemental material. As for the contrastive parts, we show in the supplemental material that both C SN CA and C M S are lower bounded by a common contrastive term that is directly related to H(?). We do not mention the contrastive term of center-loss, as it represents the cross-entropy loss, which is exhaustively studied in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Cross-entropy does it all</head><p>We now completely change gear to focus on the widely used unary classification loss: cross-entropy. On the surface, the cross-entropy may seem unrelated to metric-learning losses as it does not involve pairwise distances. We show that a close relationship exists between these pairwise losses widely used in deep metric learning and the cross-entropy classification loss. This link can be drawn from two different perspectives, one is based on an explicit optimization insight and the other is based on a discriminative view of the mutual information. First, we explicitly demonstrate that the cross-entropy is an upper bound on a new pairwise loss, which has a structure similar to all the metric-learning losses listed in <ref type="table">Table 2</ref>, i.e., it contains a tightness term and a contrastive term. Hence, minimizing the cross-entropy can be seen as an approximate bound-optimization (or Majorize-Minimize) algorithm for minimizing this pairwise loss. Second, we show that, more generally, minimization of the cross-entropy is actually equivalent to maximization of the mutual information, to which we connected various DML losses. These findings indicate that the cross-entropy represents a proxy for maximizing I( Z, Y ), just like pairwise losses, without the need for dealing with the complex sample mining and optimization schemes associated to the latter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The pairwise loss behind unary cross-entropy</head><p>Bound optimization: Given a function f (W) that is either intractable or hard to optimize, bound optimizers are iterative algorithms that instead optimize auxiliary functions (upper bounds on f ). These auxiliary functions are usually more tractable than the original function f . Let t be the current iteration index, then a t is an auxiliary function if:</p><formula xml:id="formula_11">f (W) ? a t (W) , ? W f (W t ) = a t (W t )<label>(9)</label></formula><p>A bound optimizer follows a two-step procedure: first an auxiliary function a t is computed, then a t is minimized, such that:</p><formula xml:id="formula_12">W t+1 = arg min W a t (W)<label>(10)</label></formula><p>This iterative procedure is guaranteed to decrease the original function f :</p><formula xml:id="formula_13">f (W t+1 ) ? a t (W t+1 ) ? a t (W t ) = f (W t )<label>(11)</label></formula><p>Note that bound optimizers are widely used in machine learning. Examples of well-known bound optimizers include the concave-convex procedure (CCCP) <ref type="bibr" target="#b47">[48]</ref>, expectation maximization (EM) algorithms or submodular-supermodular procedures (SSP) <ref type="bibr" target="#b18">[19]</ref>. Such optimizers are particularly used in clustering <ref type="bibr" target="#b31">[32]</ref> and, more generally, in problems involving latent-variable optimization. Pairwise Cross-Entropy: We now prove that minimizing cross-entropy can be viewed as an approximate bound optimization of a more complex pairwise loss.</p><p>Proposition 1. Alternately minimizing the cross-entropy loss L CE with respect to the encoder's parameters W and the classifier's weights ? can be viewed as an approximate bound-optimization of a Pairwise Cross-Entropy (PCE) loss, which we define as follows:</p><formula xml:id="formula_14">L PCE = ? 1 2?n 2 n i=1 j:yj =yi z T i z j tightness part + 1 n n i=1 log K k=1 e 1 ?n n j=1 p jk z T i zj ? 1 2? K k=1 c s k 2 contrastive part (12) Where c s k = 1</formula><p>n n i=1 p ik z i represents the soft-mean of class k, p ik represents the softmax probability of point z i belonging to class k, and ? ? R, ? &gt; 0 depends on the encoder ? W .</p><p>The full proof of Proposition 1 is provided in the supplemental material. We hereby provide a quick sketch. Considering the usual softmax parametrization for our model's predictions Y , the idea is to break the cross-entropy loss in two terms, and artificially add and remove the regularization term ? 2 K k=1 ? T k ? k :</p><formula xml:id="formula_15">L CE = ? 1 n n i=1 ? T yi z i + ? 2 k ? T k ? k f1(?) + 1 n n i=1 log K k=1 e ? T k zi ? ? 2 K k=1 ? T k ? k f2(?)<label>(13)</label></formula><p>By properly choosing ? ? R in Eq. (13), both f 1 and f 2 become convex functions of ?. For any class k, we then show that the optimal values of ? k for f 1 and f 2 are proportional to, respectively, the hard mean c k = 1 |Z k | i:yi=k z i and the soft mean c s k = 1 n n i=1 p ik z i of class k. By plugging-in those optimal values, we can lower bound f 1 and f 2 individually in Eq. 13 and get the result.</p><p>Proposition 1 casts a new light on the cross-entropy loss by explicitly relating it to a new pairwise loss (PCE), following the intuition that the optimal weights ? * of the final layer, i.e., the linear classifier, are related to the centroids of each class in the embedded feature space Z. Specifically, finding the optimal classifier's weight ? * for cross-entropy can be interpreted as building an auxiliary function a t (W) = L CE (W, ? * ) on L P CE (W). Subsequently minimizing crossentropy w.r.t. the encoder's weights W can be interpreted as the second step of bound optimization on L P CE (W). Similarly to other metric learning losses, PCE contains a tightness part that encourages samples from the same classes to align with one another. In echo to Lemma 1, this tightness term, noted T PCE , is equivalent, up to multiplicative and additive constants, to T center and T contrast , when the features are assumed to be normalized:</p><formula xml:id="formula_16">T PCE c = T center c = T contrast<label>(14)</label></formula><p>PCE also contains a contrastive part, divided into two terms. The first pushes all samples away from one another, while the second term forces soft means c s k far from the origin. Hence, minimizing the cross-entropy can be interpreted as implicitly minimizing a pairwise loss whose structure appears similar to the well-established metric-learning losses in <ref type="table">Table 2</ref>.</p><p>Simplified Pairwise Cross-Entropy: While PCE brings interesting theoretical insights, the computation of the parameter ? at every iteration requires computating the eigenvalues of a d ? d matrix at every iteration (cf. full proof in supplemental material), which makes the implementation of PCE difficult in practice. In order to remove the dependence upon ?, one can plug in the same ? for both f 1 and f 2 in Eq. 13. We choose to use ? *</p><formula xml:id="formula_17">1 = arg min ? f 1 (?) ? [c 1 , ..., c K ] T .</formula><p>This yields a simplified version of PCE, that we call SPCE:</p><formula xml:id="formula_18">L SP CE = ? 1 n 2 n i=1 j:yj =yi z T i z j tightness + 1 n n i=1 log K k=1 exp 1 n j:yj =k z T i z j contrastive<label>(15)</label></formula><p>SPCE and PCE are similar (the difference is that PCE was derived after plugging in the soft means instead of hard means in f 2 ). Contrary to PCE, however, SPCE is easily computable, and the preliminary experiments we provide in the supplementary material indicate that CE and SPCE exhibit similar behaviors at training time. Interestingly, our derived SPCE loss has a form similar to contrastive learning losses in unsupervised representation learning <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b32">33]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">A discriminative view of mutual information</head><p>Lemma 2. Minimizing the conditional cross-entropy loss, denoted by H(Y ; Y | Z), is equivalent to maximizing the mutual information I( Z; Y ).</p><p>The proof of Lemma 2 is provided in the supplementary material. Such result is compelling. Using the discriminative view of mutual information allows to show that minimizing cross-entropy loss is equivalent to maximizing the mutual information I( Z; Y ). This information theoretic argument reinforces our conclusion from Proposition 1 that cross-entropy and the previously described metric learning losses are essentially doing the same job.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Then why would cross-entropy work better?</head><p>We showed that cross-entropy essentially optimizes the same underlying mutual information I( Z; Y ) as other DML losses. This fact alone is not enough to explain why the cross-entropy is able to consistently achieve better results than DML losses as shown in Section 5. We argue that the difference is in the optimization process. On the one hand, pairwise losses require careful sample mining and weighting strategies to obtain the most informative pairs, especially when considering minibatches, in order to achieve convergence in a reasonable amount of time, using a reasonable amount of memory. On the other hand, optimizing cross-entropy is substantially easier as it only implies minimization of unary terms. Essentially, cross-entropy does it all without dealing with the difficulties of pairwise terms. Not only it makes optimization easier, but also it simplifies the implementation, thus increasing its potential applicability in real-world problems.  <ref type="bibr" target="#b28">[29]</ref> House furniture 22 634 120 053 In-shop Clothes Retrieval <ref type="bibr" target="#b14">[15]</ref> Clothes 7 982 52 712</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Metric</head><p>Most methods, especially recent ones, use the cosine distance to compute the recall for the evaluation. They include 2 normalization of the features in the model <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref><ref type="bibr" target="#b48">49]</ref>, which makes cosine and Euclidean distances equivalent. Computing cosine similarity is also more memory efficient and typically leads to better results <ref type="bibr" target="#b25">[26]</ref>. For these reasons, the Euclidean distance on non normalized features has rarely been used for both training and evaluation.</p><p>In our experiments, 2 -normalization of the features during training actually hindered the final performance, which might be explained by the fact that we add a classification layer on top of the feature extractor. Thus, we did not 2 -normalize the features during training and reported the recall with both Euclidean and cosine distances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Datasets</head><p>Four datasets are commonly used in metric learning to evaluate the performances. These datasets are summarized in <ref type="table" target="#tab_0">Table 3</ref>. CUB <ref type="bibr" target="#b33">[34]</ref>, Cars <ref type="bibr" target="#b12">[13]</ref> and SOP <ref type="bibr" target="#b28">[29]</ref> datasets are divided into train and evaluation splits. For the evaluation, the recall is computed between each sample of the evaluation set and the rest of the set. In-Shop <ref type="bibr" target="#b14">[15]</ref> is divided into a query and a gallery set. The recall is computed between each sample of the query set and the whole gallery set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Training specifics</head><p>Model architecture and pre-training: In the metric learning literature, several architectures have been used, which historically correspond to the state-ofthe-art image classification architectures on ImageNet <ref type="bibr" target="#b3">[4]</ref>, with an additional constraint on model size (i.e., the ability to train on one or two GPUs in a reasonable time). These include GoogLeNet <ref type="bibr" target="#b29">[30]</ref> as in <ref type="bibr" target="#b11">[12]</ref>, BatchNorm-Inception <ref type="bibr" target="#b30">[31]</ref> as in <ref type="bibr" target="#b39">[40]</ref> and ResNet-50 <ref type="bibr" target="#b7">[8]</ref> as in <ref type="bibr" target="#b45">[46]</ref>. They have large differences in classification performances on ImageNet, but the impact on performances over DML benchmarks has rarely been studied in controlled experiments. As this is not the focus of our paper, we use ResNet-50 for our experiments. We concede that one may obtain better performances by modifying the architecture (e.g., reducing model stride and performing multi-level fusion of features). Here, we limit our comparison to standard architectures. Our implementation uses the PyTorch <ref type="bibr" target="#b22">[23]</ref> library, and initializes the ResNet-50 model with weights pre-trained on ImageNet. Sampling: To the best of our knowledge, all DML papers -including [49]use a form of pairwise sampling to ensure that, during training, each mini-batch contains a fixed number of classes and samples per class (e.g. mini-batch size of 75 with 3 classes and 25 samples per class in <ref type="bibr" target="#b48">[49]</ref>). Deviating from that, we use the common random sampling among all samples (as in most classification training schemes) and set the mini-batch size to 128 in all experiments (contrary to <ref type="bibr" target="#b39">[40]</ref> in which the authors use a mini-batch size of 80 for CUB, 1 000 for SOP and did not report for Cars and In-Shop).</p><p>Data Augmentation: As is common in training deep learning models, data augmentation improves the final performances of the methods. For CUB, the images are first resized so that their smallest side has a length of 256 (i.e., keeping the aspect ratio) while for Cars, SOP and In-Shop, the images are resized to 256 ? 256. Then a patch is extracted at a random location and size, and resized to 224 ? 224. For CUB and Cars, we found that random jittering of the brightness, contrast and saturation slightly improves the results. All of the implementation details can be found in the publicly available code.</p><p>Cross-entropy: The focus of our experiments is to show that, with careful tuning, it is possible to obtain similar or better performance than most recent DML methods, while using only the cross-entropy loss. To train with the crossentropy loss, we add a linear classification layer (with bias) on top of the feature extraction -similar to many classification models -which produces logits for all the classes present in the training set. Both the weights and biases of this classification layer are initialized to 0. We also add dropout with a probability of 0.5 before this classification layer. To further reduce overfitting, we use label smoothing for the target probabilities of the cross-entropy. We set the probability of the true class to 1 ? and the probabilities of the other classes to K?1 with = 0.1 in all our experiments.</p><p>Optimizer: In most DML papers, the hyper-parameters of the optimizer are the same for Cars, SOP and In-Shop whereas, for CUB, the methods typically use a smaller learning rate. In our experiments, we found that the best results were obtained by tuning the learning rate on a per dataset basis. In all experiments, the models are trained with SGD with Nesterov acceleration and a weight decay of 0.0005, which is applied to convolution and fully-connected layers' weights (but not to biases) as in <ref type="bibr" target="#b9">[10]</ref>. For CUB and Cars, the learning rate is set to 0.02 and 0.05 respectively, with 0 momentum. For both SOP and In-Shop, the learning rate is set to 0.003 with a momentum of 0.99.</p><p>Batch normalization: Following <ref type="bibr" target="#b39">[40]</ref>, we freeze all the batch normalization layers in the feature extractor. For Cars, SOP and In-Shop, we found that adding batch normalization -without scaling and bias -on top of the feature extractor improves our final performance and reduces the gap between 2 and cosine distances when computing the recall. On CUB, however, we obtained the best recall without this batch normalization. GoogLeNet Proxy-NCA <ref type="bibr" target="#b16">[17]</ref> cos BN-Inception HTL <ref type="bibr" target="#b4">[5]</ref> cos GoogLeNet ABE <ref type="bibr" target="#b11">[12]</ref> cos GoogLeNet HDC <ref type="bibr" target="#b46">[47]</ref> cos GoogLeNet DREML <ref type="bibr" target="#b44">[45]</ref> cos ResNet-18 EPSHN <ref type="bibr" target="#b45">[46]</ref> cos ResNet-50 NormSoftmax <ref type="bibr" target="#b48">[49]</ref> cos ResNet-50 Multi-Similarity <ref type="bibr" target="#b39">[40]</ref> cos BN-Inception D&amp;C <ref type="bibr" target="#b24">[25]</ref> cos ResNet-50 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GoogLeNet</head><p>Proxy-NCA <ref type="bibr" target="#b16">[17]</ref> cos BN-Inception HTL <ref type="bibr" target="#b46">[47]</ref> cos GoogLeNet EPSHN <ref type="bibr" target="#b45">[46]</ref> cos ResNet-50 HDC <ref type="bibr" target="#b46">[47]</ref> cos GoogLeNet Multi-Similarity <ref type="bibr" target="#b39">[40]</ref> cos BN-Inception D&amp;C <ref type="bibr" target="#b24">[25]</ref> cos ResNet-50 ABE <ref type="bibr" target="#b11">[12]</ref> cos GoogLeNet DREML <ref type="bibr" target="#b44">[45]</ref> cos ResNet-18 NormSoftmax <ref type="bibr" target="#b48">[49]</ref> cos ResNet-50 GoogLeNet HDC <ref type="bibr" target="#b46">[47]</ref> cos GoogLeNet HTL <ref type="bibr" target="#b4">[5]</ref> cos GoogLeNet D&amp;C <ref type="bibr" target="#b24">[25]</ref> cos ResNet-50 ABE <ref type="bibr" target="#b11">[12]</ref> cos GoogLeNet Multi-Similarity <ref type="bibr" target="#b39">[40]</ref> cos BN-Inception EPSHN <ref type="bibr" target="#b45">[46]</ref> cos ResNet-50 NormSoftmax <ref type="bibr" target="#b48">[49]</ref> cos ResNet-50  <ref type="bibr" target="#b46">[47]</ref> cos GoogLeNet DREML <ref type="bibr" target="#b44">[45]</ref> cos ResNet-18 HTL <ref type="bibr" target="#b4">[5]</ref> cos GoogLeNet D&amp;C <ref type="bibr" target="#b24">[25]</ref> cos ResNet-50 ABE <ref type="bibr" target="#b11">[12]</ref> cos GoogLeNet EPSHN <ref type="bibr" target="#b45">[46]</ref> cos ResNet-50 NormSoftmax <ref type="bibr" target="#b48">[49]</ref> cos ResNet-50 Multi-Similarity <ref type="bibr" target="#b39">[40]</ref> cos BN-Inception </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-Entropy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head><p>Results for the experiments are reported in <ref type="table" target="#tab_1">Table 4</ref>. We also report the architecture used in the experiments as well as the distance used in the evaluation to compute the recall. 2 refers to the Euclidean distance on non normalized features while cos refers to either the cosine distance or the Euclidean distance on 2 -normalized features, both of which are equivalent.</p><p>On all datasets, we report state-of-the-art results except on Cars, where the only method achieving similar recall uses cross-entropy for training. We also notice that, contrary to common beliefs, using Euclidean distance can actually be competitive as it also achieves near state-of-the-art results on all four datasets. These results clearly highlight the potential of cross-entropy for metric learning, and confirm that this loss can achieve the same objective as pairwise losses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>Throughout this paper, we revealed non-obvious relations between the crossentropy loss, widely adopted in classification tasks, and pairwise losses commonly used in DML. These relations were drawn under two different perspectives. First, cross-entropy minimization was shown equivalent to an approximate boundoptimization of a pairwise loss, introduced as Pairwise Cross-Entropy (PCE), which appears similar in structure to already existing DML losses. Second, adopting a more general information theoretic view of DML, we showed that both pairwise losses and cross-entropy were, in essence, maximizing a common mutual information I(?, Y ) between the embedded features and the labels. This connection becomes particularly apparent when writing mutual information in both its generative and discriminative views. Hence, we argue that most of the differences in performance observed in previous works come from the optimization process during training. Cross-entropy contains only unary terms, while traditional DML losses are based on pairwise-term optimization, which requires substantially more tuning (e.g. mini-batch size, sampling strategy, pair weighting). While we acknowledge that some losses have better properties than others regarding optimization, we empirically showed that the cross-entropy loss was also able to achieve state-of-the-art results when fairly tuned, highlighting the fact that most improvements have come from enhanced training schemes (e.g. data augmentation, learning rate policies, batch normalization freeze) rather than the intrinsic properties of pairwise losses. We strongly advocate that cross-entropy should be carefully tuned to be compared against as a baseline in future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Acknowledgments</head><p>This project was supported by the NSERC (Discovery Grant RGPIN 2019-05954). This project has received funding from the European Union's Horizon 2020 research and innovation program under the Marie Sk?odowska-Curie grant agreement 792464.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proofs</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Lemma 1</head><p>Proof. Throughout the following proofs, we will use the fact that classes are assumed to be balanced in order to consider Z k , for any class k, as a constant |Z k | = n K . We will also use the feature normalization assumption to connect cosine and Euclidean distances. On the unit-hypersphere, we will use that:</p><formula xml:id="formula_19">D cos i,j = 1 ? zi?zj 2 2</formula><p>result could be established <ref type="bibr" target="#b31">[32]</ref>, linking K-means to pairwise graph clusteirng objectives.</p><p>Now we link contrastive loss to SNCA loss. For any class k, we can write:</p><formula xml:id="formula_20">? zi?Z k log zj ?Z k \{i} e D cos i,j ? c = ? zi?Z k log ? ? 1 |Z k | ? 1 zj ?Z k \{i} e D cos i,j ? ? ? ? ? zi?Z k zj ?Z k \{i} D cos i,j (|Z k | ? 1)? c = zi?Z k zj ?Z k \{i} z i ? z j 2 2?(|Z k | ? 1) c = zi?Z k zj ?Z k \{i} z i ? z j 2</formula><p>where we used the convexity of x ? ? log(x) and Jenson's inequality. The proof can be finished by summing over all classes k.</p><p>Finally, we link MS loss <ref type="bibr" target="#b39">[40]</ref> to contrastive loss:</p><formula xml:id="formula_21">zi?Z k 1 ? log ? ? 1 + zj ?Z k \{i} e ??(D cos i,j ?1) ? ? = zi?Z k 1 ? log zj ?Z k e ??(D cos i,j ?1) c = zi?Z k 1 ? log ? ? 1 |Z k | zj ?Z k e ??(D cos i,j ?1) ? ? ? 1 |Z k | zi,zj ?Z k ?(D cos i,j ? 1) c = zi,zj ?Z k z i ? z j 2 ,</formula><p>where we used the concavity of x ? log(x) and Jenson's inequality.</p><p>Contrastive terms: In this part, we first show that the contrastive terms C SN CA and C M S represent upper bounds on C = ? 1 n n i=1 j:yj =yi D 2 ij :</p><formula xml:id="formula_22">C M S = 1 ?n n i=1 log ? ? 1 + j:yj =yi e ?(D cos ij ?1) ? ? ? 1 ?n n i=1 log ? ? j:yj =yi e ?(D cos ij ?1) ? ? c ? 1 ?n n i=1 j:yj =yi ?(D cos ij ? 1) c = ? 1 n n i=1 j:yj =yi D 2 ij = C</formula><p>where, again, we used Jenson's inequality in the second line above. The link between SNCA and contrastive loss can be established quite similarly:</p><formula xml:id="formula_23">C SN CA = 1 n n i=1 log ? ? j =i e D cos ij ? ? ? = 1 n n i=1 log ? ? j =i:yi=yj e D cos ij ? + j:yj =yi e D cos ij ? ? ? (16) ? 1 n n i=1 log ? ? j:yj =yi e D cos ij ? ? ? (17) c ? 1 n n i=1 j:yj =yi D cos ij ? (18) c = ? 1 n n i=1 j:yj =yi D 2 ij (19) = C<label>(20)</label></formula><p>Now, similarly to the reasoning carried out in Section 3.1, we can write:</p><formula xml:id="formula_24">C = ? 1 n n i=1 j:yj =yi D 2 ij = ? 1 n n i=1 n j=1 D 2 ij contrast ? H(?) + 1 n n i=1 j:yj =yi D 2 ij tightness subterm ? H(?|Y )</formula><p>Where the redundant tightness term is very similar to the tightness term in contrastive loss T contrast treated in details in Section 3.1. As for the truly contrastive part of C, it can also be related to the differential entropy estimator used in <ref type="bibr" target="#b37">[38]</ref>:</p><formula xml:id="formula_25">H( Z) = d n(n ? 1) n i=1 n j=1 log D 2 ij c = 1 n n i=1 n j=1 log D 2 ij<label>(21)</label></formula><p>In summary, we just proved that the contrastive parts of MS and SNCA losses are upper bounds on the contrastive term C. The latter term is composed of a proxy for the entropy of features H(?), as well as a tightness sub-term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Proposition 1</head><p>Proof. First, let us show that L CE ? L P CE . Consider the usual softmax parametrization of point i belonging to class k:</p><formula xml:id="formula_26">p ik = (f ? (z i )) k = exp ? T k zi j exp ? T j zi , where z = ? W (x)</formula><p>. We can explicitly write the cross-entropy loss:</p><formula xml:id="formula_27">L CE = ? 1 n n i=1 log f ? (z i ) = ? 1 n n i=1 ? T yi z i + ? 2 K k=1 ? T k ? k f1(?) + 1 n n i=1 log K j=1 e ? T j zi ? ? 2 K k=1 ? T k ? k f2(?)</formula><p>. <ref type="formula" target="#formula_2">(22)</ref> Where we introduced ? ? R. How to specifically set ? will soon become clear.</p><p>Let us now write the gradients of f 1 and f 2 in Eq. 22 with respect to ? k :</p><formula xml:id="formula_28">?f 1 ?? k = ? 1 n i:yi=k z i + ?? k<label>(23)</label></formula><formula xml:id="formula_29">?f 2 ?? k = 1 n i exp(? T k z i ) K j=1 exp(? T j z i ) p ik z i ? ?? k<label>(24)</label></formula><p>Notice that f 1 is a convex function of ?, regardless of ?. As for f 2 , we set ? such that f 2 becomes a convex function of ?. Specifically, by setting:</p><formula xml:id="formula_30">? = min k,l ? l (A k )<label>(25)</label></formula><p>where A k = 1 n n i=1 (p ik ? p 2 ik )z i z T i and ? l (A) represents the l th eigenvalue of A, we make sure that the hessian of f 2 is semi-definite positive. Therefore, we can look for the minima of f 1 and f 2 .</p><p>Setting gradients in Eq. 23 and Eq. 24 to 0, we obtain that for all k ? [1, K], the optimal ? k for f 1 is, up to a multiplicative constant, the hard mean of features from class k: ? f1 * k = 1 ?n i:yi=k z i ? c k , while the optimal ? k for f 2 is, up to a multiplicative constant, the soft mean of features: ? f2 * k = 1 ?n n i=1 p ik z i = c s k /?. Therefore, we can write:</p><formula xml:id="formula_31">f 1 (?) ? f 1 (? f1 * ) = ? 1 ?n 2 n i=1 j:yj =yi z T i z j + ? 2? 2 n i=1 j:yj =yi z T i z j (26) = ? 1 2?n 2 n i=1 j:yj =yi z T i z j<label>(27)</label></formula><p>And</p><formula xml:id="formula_32">f 2 (?) ? f 2 (? f2 * )<label>(28)</label></formula><formula xml:id="formula_33">= 1 n n i=1 log K k=1 exp ? ? 1 ?n n j=1 p jk z T i z j ? ? ? 1 2? K k=1 c s k 2<label>(29)</label></formula><p>Putting it all together, we can obtain the desired result:</p><formula xml:id="formula_34">L CE ? ? 1 2?n 2 n i=1 j:yj =yi z T i z j + 1 n n i=1 log K k=1 e 1 ?n j p jk z T i zj ? 1 2? K k=1 c s k 2 (30) = L P CE<label>(31)</label></formula><p>where c s k = 1 n n i=1 p ik z i represents the soft mean of class k.</p><p>Let us now justify that minimizing cross-entropy can be seen as an approximate bound optimization on L P CE . At every iteration t of the training, cross-entropy represents an upper bound on Pairwise Cross-entropy.</p><formula xml:id="formula_35">L CE (W(t), ?(t)) ? L P CE (W(t), ?(t))<label>(32)</label></formula><p>When optimizing w.r.t ?, the bound almost becomes tight. The approximation comes from the fact that ? f1 * k and ? f2 * k are quite dissimilar in early training, but become very similar as training progresses and the model's softmax probabilities align with the labels. Therefore, using the notation:</p><formula xml:id="formula_36">?(t + 1) = min ? L CE (W(t), ?)<label>(33)</label></formula><p>We can write:</p><formula xml:id="formula_37">L CE (W(t), ?(t + 1)) ? L P CE (W(t), ?(t + 1))<label>(34)</label></formula><p>Then, minimizing L CE and L P CE w.r.t W becomes approximately equivalent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Lemma 2</head><p>Proof. Using the discriminative view of MI, we can write:</p><formula xml:id="formula_38">I( Z; Y ) = H(Y ) ? H(Y | Z)<label>(35)</label></formula><p>The entropy of labels H(Y ) is a constant and, therefore, can be ignored. From this view of MI, maximization of I( Z; Y ) can only be achieved through a minimization of H(Y | Z), which depends on our embeddings Z = ? W (X). We can relate this term to our cross-entropy loss using the following relation:  In <ref type="figure" target="#fig_1">Fig. 1</ref>, we track the evolution of both loss functions and validation accuracy when training with L CE and L SP CE on MNIST dataset. We use a small CNN composed of four convolutional layers. The optimizer used is Adam. Batch size is set to 128, learning rate to 1e ?4 with cosine annealing, weight decay to 1e ?4 and feature dimension to d = 100. <ref type="figure" target="#fig_1">Fig. 1</ref> supports the theoretical links that were drawn between Cross-Entropy and its simplied pairwise version SPCE. Particularly, this preliminary result demonstrates that SPCE is indeed employable as a loss, and exhibits a very similar behavior to the original cross-entropy. Both losses remain very close to each other throughout the training, and so remain the validation accuracies.</p><formula xml:id="formula_39">H(Y ; Y | Z) = H(Y | Z) + D KL (Y Y | Z)<label>(36)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Analysis of ranking losses for Deep Metric Learning</head><p>Some recent works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b38">39]</ref> tackle the problem of deep metric learning using a rank-based approach. In other words, given a point in feature space z i , the pairwise losses studied throughout this work try to impose manual margins m, so that the distance between z i and any negative point z ? j is at least m. Rank-based losses rather encourage that all points are well ranked, distance-wise, such that</p><formula xml:id="formula_40">d(z i , z + j ) ? d(z i , z ? j )</formula><p>for any positive and negative points z + j and z ? j . We show that our tightness/contrastive analysis also holds for such ranking losses. In particular, we analyse the loss proposed in <ref type="bibr" target="#b0">[1]</ref>. For any given query embedded point z i , let us call D the random variable associated to the distance between z i and all other points in the embedded space, defined over all possible (discretized) distances D. Furthermore, let us call R the binary random variable that describes the relation to the current query point (R + and R ? describe respectively a positive and negative relationship to z i ). The loss maximized in <ref type="bibr" target="#b0">[1]</ref> reads:</p><formula xml:id="formula_41">FastAP = d?D P (D &lt; d|R + )P (R + ) P (D &lt; d) P (D = d|R + )<label>(37)</label></formula><p>Taking the logarithm, and using Jensen's inequality, we can lower bound this loss: </p><p>To intuitively understand what those two terms are doing, let us imagine we approximate each of the expectations with a single point Monte-Carlo approximation. In other words, we sample a positive point z + j , take its associated distance to z i , which we call d + , then we approximate the tightness term as:</p><formula xml:id="formula_43">T AP ? log P (D &lt; d + |R + )<label>(39)</label></formula><p>Maximizing T AP has a clear interpretation: it encourages all positive points to lie inside the hypersphere of radius d + around query point z i . Similarly:</p><formula xml:id="formula_44">C AP ? ? log P (D &lt; d + )<label>(40)</label></formula><p>Maximizing C AP also has a clear interpretation: it encourages all points (both positive and negative ones) to lie outside the hypersphere of radius d + around query point z i . Now, Eq. 38 is nothing more than an expectation over all positive distance d + one could sample. Therefore, such loss can be analyzed through the same lens as other DML losses, i.e., one tightness term that encourages all points from the same class as z i to lie close to it in the embedded space, and one contrastive term that oppositely refrains all points from approaching z i closer than its current positive points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D On the limitations of cross-entropy</head><p>While we demonstrated that the cross-entropy loss could be competitive in comparison to pairwise losses, while being easier to optimize, there still exist scenarios for which a straightforward use of the CE loss becomes prohibitive. Hereafter, we describe two such scenarios.</p><p>Case of relative labels: The current setting assumes that absolute labels are given for each sample, i.e., each sample x i belongs to a single absolute class y i . However, DML can be applied to more general problems where the absolute class labels are not available. Instead, one has access to relative labels that only describe the relationships between points (e.g., a pair is similar or dissimilar). From these relative labels, one could still define absolute classes as sets of samples inside which every pair has a positive relationship. Note that with this definition, each sample may belong to multiple classes simultaneously, which makes the use of standard cross-entropy difficult. However, with such re-formulation, our Simplified Pairwise Cross-Entropy (SPCE), which we hereby remind:</p><formula xml:id="formula_45">L SP CE = ? 1 n 2 n i=1 j:yj =yi z T i z j tightness + 1 n n i=1 log K k=1 exp 1 n j:yj =k z T i z j contrastive<label>(15)</label></formula><p>can handle such problems, just like any other pairwise loss.</p><p>Case of large number of classes: In some problems, the total number of classes K can grow to several millions. In such cases, even simply storing the weight matrix ? ? R K?d of the final classifier required by cross-entropy becomes prohibitive. Note that there exist heuristics to handle such problems with standard cross-entropy, such as sampling subsets of classes and solving those sub-problems instead, as was done in <ref type="bibr" target="#b48">[49]</ref>. However, we would be introducing new training heuristics (e.g., class sampling), which defeats the initial objective of using the cross-entropy loss. Again, the SPCE loss underlying the unary crossentropy could again handle such cases, similarly to other pairwise losses, given that it doesn't require storing such weight matrix.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Evolution of the cross-entropy loss (CE) and the simplified pairwise cross-entropy (SPCE) during training on MNIST, as well as the validation accuracy for both losses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>log(FastAP) ? d?D P (D = d, R + ) log( P (D &lt; d|R + ) P (D &lt; d) ) = E d?P (.,R + ) log P (D &lt; d|R + ) T AP =TIGHTNESS ? E d?P (.,R + ) log P (D &lt; d) C AP =CONTRASTIVE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 3 .</head><label>3</label><figDesc>Summary of the datasets used for evaluation in metric learning.</figDesc><table><row><cell>Name</cell><cell>Objects</cell><cell cols="2">Categories Images</cell></row><row><cell>Caltech-UCSD Birds-200-2011 (CUB) [34]</cell><cell>Birds</cell><cell>200</cell><cell>11 788</cell></row><row><cell>Cars Dataset [13]</cell><cell>Cars</cell><cell>196</cell><cell>16 185</cell></row><row><cell>Stanford Online Products (SOP)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 .</head><label>4</label><figDesc>Performance on CUB200, Cars-196, SOP and In-Shop datasets. d refers to the distance used to compute the recall when evaluating.</figDesc><table><row><cell></cell><cell>Method</cell><cell>d</cell><cell>Architecture</cell><cell>Recall at</cell></row><row><cell>Caltech-UCSD Birds-200-2011</cell><cell>Lifted Structure [29]</cell><cell>2</cell><cell></cell><cell>1 49.2 61.9 67.9 81.9 2 4 8 57.1 68.8 78.7 86.5 92.5 95.5 16 32 --60.6 71.5 79.8 87.4 --60.7 72.4 81.9 89.2 93.7 96.8 63.9 75.0 83.1 89.7 --64.9 75.3 83.5 ---65.3 76.7 85.4 91.8 --65.7 77.0 86.6 91.2 95.0 97.3 65.9 76.6 84.4 90.6 --67.6 78.1 85.6 91.1 94.7 97.2 47.2 58.9 70.2 80.2 89.3 93.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>69.2 79.2 86.9 91.6 95.0 97.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Therefore, while minimizing cross-entropy, we are implicitly both minimizing H(Y | Z) as well as D KL (Y Y | Z). In fact, following Eq. 36, optimization could naturally be decoupled in 2 steps, in a Maximize-Minimize fashion. One step would consist in fixing the encoder's weights W and only minimizing Eq. 36 w.r.t to the classifier's weights ?. At this step, H(Y | Z) would be fixed while Y would be adjusted to minimize D KL (Y || Y | Z). Ideally, the KL term would vanish at the end of this step. In the following step, we would minimize Eq. 36 w.r.t to the encoder's weights W, while keeping the classifier fixed.</figDesc><table><row><cell cols="8">B Preliminary results with SPCE</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ce spce</cell><cell>0.99</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.98</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Training loss</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Validation accuracy</cell><cell>0.95 0.96 0.97</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.94</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.93</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>10</cell><cell>20 Epochs</cell><cell>30</cell><cell>40</cell><cell>50</cell><cell>0</cell><cell>10</cell><cell>20 Epochs</cell><cell>30</cell><cell>40</cell><cell>50</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">? In clustering, the optimization is performed over assignment variables, as opposed to DML, where assignments are already known and optimization is carried out over the embedding.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep metric learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cakir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Information-theoretic metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep metric learning with hierarchical triplet loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neighbourhood components analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07737</idno>
		<title level="m">defense of the triplet loss for person reidentification</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.11205</idno>
		<title level="m">Highly scalable deep learning training system with mixed-precision: Training imagenet in four minutes</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Non-linear metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kedem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tyree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Attention-based ensemble for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV) Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV) Workshops</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sphereface: Deep hypersphere embedding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deepfashion: Powering robust clothes recognition and retrieval with rich annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Similarity metric learning for a variable-kernel classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">No fuss distance metric learning using proxies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Musgrave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Lim</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.08505</idno>
		<title level="m">A metric learning reality check</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A submodular-supermodular procedure with applications to discriminative structure learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-First Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<meeting>the Twenty-First Conference on Uncertainty in Artificial Intelligence (UAI)</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep metric learning via facility location</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bier-boosting independent embeddings robustly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Waltner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Possegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optimizing rank-based metrics with blackbox differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rol?nek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Musil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vlastelica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Martius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Divide and conquer the embedding space for metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanakoyeu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tschernezki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Buchler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning a distance metric from relative comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Improved deep metric learning with multi-class n-pair loss objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">O</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Kernel cuts: Kernel and spectral clustering meet regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ben Ayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Boykov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">On mutual information maximization for representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Rubenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lucic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Additive margin softmax for face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Cosface: Large margin cosine loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep metric learning with angular loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Information theoretical clustering via semidefinite programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AIStats)</title>
		<meeting>the Fourteenth International Conference on Artificial Intelligence and Statistics (AIStats)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Ranked list loss for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multi-similarity loss with general pair weighting for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">K</forename><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2009" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Improving generalization via scalable neighborhood component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Distance metric learning with application to clustering with side-information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep randomized ensembles for metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Souvenir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Improved embeddings with easy positive triplet mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Stylianou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Hard-aware deeply cascaded embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The concave-convex procedure (cccp)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Classification is a strong baseline for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Hardness-aware deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
