<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Locate and Label: A Two-stage Identifier for Nested Named Entity Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongliang</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyin</forename><surname>Ma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeqi</forename><surname>Tan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Lu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">College of Computer Science and Technology</orgName>
								<orgName type="institution">Zhejiang University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Locate and Label: A Two-stage Identifier for Nested Named Entity Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Named entity recognition (NER) is a wellstudied task in natural language processing. Traditional NER research only deals with flat entities and ignores nested entities. The span-based methods treat entity recognition as a span classification task. Although these methods have the innate ability to handle nested NER, they suffer from high computational cost, ignorance of boundary information, under-utilization of the spans that partially match with entities, and difficulties in long entity recognition. To tackle these issues, we propose a two-stage entity identifier. First we generate span proposals by filtering and boundary regression on the seed spans to locate the entities, and then label the boundaryadjusted span proposals with the corresponding categories. Our method effectively utilizes the boundary information of entities and partially matched spans during training. Through boundary regression, entities of any length can be covered theoretically, which improves the ability to recognize long entities. In addition, many low-quality seed spans are filtered out in the first stage, which reduces the time complexity of inference. Experiments on nested NER datasets demonstrate that our proposed method outperforms previous state-of-the-art models.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named entity recognition (NER) is a fundamental task in natural language processing, focusing on identifying the spans of text that refer to entities. NER is widely used in downstream tasks, such as entity linking <ref type="bibr" target="#b8">(Ganea and Hofmann, 2017;</ref><ref type="bibr" target="#b18">Le and Titov, 2018)</ref> and relation extraction <ref type="bibr" target="#b20">(Li and Ji, 2014;</ref><ref type="bibr" target="#b30">Miwa and Bansal, 2016)</ref>.</p><p>Previous works usually treat NER as a sequence labeling task, assigning a single tag to each to- * * Corresponding author ken in a sentence. Such models lack the ability to identify nested named entities. Various approaches for nested NER have been proposed in recent years. Some works revised sequence models to support nested entities using different strategies <ref type="bibr" target="#b0">(Alex et al., 2007;</ref><ref type="bibr" target="#b16">Ju et al., 2018;</ref><ref type="bibr" target="#b41">Strakov? et al., 2019;</ref><ref type="bibr" target="#b44">Wang et al., 2020a)</ref> and some works adopt the hyper-graph to capture all possible entity mentions in a sentence <ref type="bibr" target="#b27">(Lu and Roth, 2015;</ref><ref type="bibr" target="#b17">Katiyar and Cardie, 2018)</ref>. We focus on the span-based methods (Sohrab and <ref type="bibr" target="#b47">Zheng et al., 2019;</ref><ref type="bibr" target="#b42">Tan et al., 2020)</ref>, which treat named entity recognition as a classification task on a span with the innate ability to recognize nested named entities. For example, Sohrab and  exhausts all possible spans in a text sequence and then predicts their categories. However, these methods suffer from some serious weaknesses. First, due to numerous low-quality candidate spans, these methods require high computational costs. Then, it is hard to identify long entities because the length of the span enumerated during training is not infinite. Next, boundary information is not fully utilized, while it is important for the model to locate entities.</p><p>Although some methods <ref type="bibr" target="#b47">(Zheng et al., 2019;</ref><ref type="bibr" target="#b42">Tan et al., 2020)</ref> have used a sequence labeling model to predict boundaries, yet without dynamic adjustment, the boundary information is not fully utilized. Finally, the spans which partially match with entities are not effectively utilized. These methods simply treat the partially matched spans as negative examples, which can introduce noise into the model. Different from the above studies, we observed that NER and object detection tasks in computer vision have a high degree of consistency. They both need to locate regions of interest (ROIs) in the context (image/text) and then assign corresponding categories to them. Furthermore, both flat NER and nested NER have corresponding structures in the object detection task, as shown in <ref type="figure">Figure 1</ref>. For the flat structure, there is no overlap between entities or between objects. While for nested structures, finegrained entities are nested inside coarse-grained entities, and small objects are nested inside large objects correspondingly. In computer vision, the two-stage object detectors <ref type="bibr" target="#b10">(Girshick et al., 2014;</ref><ref type="bibr" target="#b9">Girshick, 2015;</ref><ref type="bibr" target="#b37">Ren et al., 2017;</ref><ref type="bibr" target="#b5">Dai et al., 2016;</ref><ref type="bibr" target="#b2">Cai and Vasconcelos, 2018)</ref> are the most popular object detection algorithm. They divide the detection task into two stages, first generating candidate regions, and then classifying and fine-tuning the positions of the candidate regions.</p><p>Inspired by these, we propose a two-stage entity identifier and treat NER as a joint task of boundary regression and span classification to address the weaknesses mentioned above. In the first stage, we design a span proposal module, which contains two components: a filter and a regressor. The filter divides the seed spans into contextual spans and span proposals, and filters out the former to reduce the candidate spans. The regressor locates entities by adjusting the boundaries of span proposals to improve the quality of candidate spans. Then in the second stage, we use an entity classifier to label entity categories for the number-reduced and quality-improved span proposals. During training, to better utilize the spans that partially match with the entities, we construct soft examples by weighting the loss of the model based on the IoU. In addition, we apply the soft non-maximum suppression (Soft-NMS) <ref type="bibr" target="#b1">(Bodla et al., 2017)</ref> algorithm to entity decoding for dropping the false positives.</p><p>Our main contributions are as follow:</p><p>? Inspired by the two-stage detector popular in object detection, we propose a novel twostage identifier for NER of locating entities first and labeling them later. We treat NER as a joint task of boundary regression and span classification.</p><p>? We make effective use of boundary information. Taking the identification of entity boundaries a step further, our model can adjust the boundaries to accurately locate entities. And when training the boundary regressor, in addition to the boundary-level SmoothL1 loss, we also use a span-level loss, which measures the overlap between two spans.</p><p>? During training, instead of simply treating the partially matched spans as negative examples, we construct soft examples based on the IoU. This not only alleviates the imbalance between positive and negative examples, but also effectively utilizes the spans which partially match with the ground-truth entities.</p><p>? Experiments show that our model achieves state-of-the-art performance consistently on the KBP17, ACE04 and ACE05 datasets, and outperforms several competing baseline models on F1-score by +3.08% on KBP17, +0.71% on ACE04 and +1.27% on ACE05. <ref type="figure" target="#fig_1">Figure 2</ref> illustrates an overview of the model structure. We first obtain the word representation through the encoder and generate seed spans. Among these seed spans, some with higher overlap with the entities are the proposal spans, and others with lower overlap are the contextual spans. In the span proposal module, we use a filter to keep the proposal spans and drop the contextual spans. Meanwhile, a regressor regresses the boundary of each span to locate the left and right boundaries of entities. Next, we adjust the boundaries of the span proposals based on the output of the regressor, and then feed them into the entity classifier module. Finally, the entity decoder decodes the entities using the Soft-NMS algorithm. We will cover our model in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Token Representation</head><p>Consider the i-th word in a sentence with n words, we represent it by concatenating its word embedding x w i , contextualized word embedding x lm i , part- of-speech(POS) embedding x pos i and characterlevel embedding x char i together. The characterlevel embedding is generated by a BiLSTM module with the same setting as <ref type="bibr" target="#b16">(Ju et al., 2018)</ref>. For the contextualized word embedding, we follow <ref type="bibr" target="#b46">(Yu et al., 2020)</ref> to obtain the context-dependent embedding for a target token with one surrounding sentence on each side. Then, the concatenation of them is fed into another BiLSTM to obtain the hidden state as the final word representation h i ? R d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Seed Span Generation</head><p>Seed spans are subsequences sampled from a sequence of words. By filtering, adjusting boundaries, and classifying on them, we can extract entities from the sentence. Under the constraint of a prespecified set of lengths, where the maximum does not exceed L, we enumerate all possible start and end positions to generate the seed spans. We denote the set of seed spans as B = {b 0 , . . . , b K }, where b i = (st i , ed i ) denotes i-th seed span, K denotes the number of the generated seed spans, and st i , ed i denote the start and end positions of the span respectively.</p><p>For training the filter and the regressor, we need to assign a corresponding category and regression target to each seed span. Specifically, we pair each seed span in B and the ground-truth entity with which the span has the largest IoU. The IoU measure the overlap between spans, defined as IoU(A, B) = A?B A?B , where A and B are two spans. Then we divide them into positive and negative spans based on the IoU between the pair. The spans whose IoU with the paired ground truth is above the threshold ? 1 are classified as positive examples, and those less than threshold ? 1 are classified as negative examples. For the positive span, we assign it the same category? with the paired ground truth and compute the boundary offsett between them. For the negative span, we only assign a NONE label. We downsample the negative examples such that the ratio of positive to negative is 1:5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Span Proposal Module</head><p>The quality of the generated seed spans is variable. If we directly input them into the entity classifier, it will lead to a lot of computational waste. High-quality spans have higher overlap with entities, while low-quality spans have lower overlap. We denote them as span proposals and contextual spans, respectively. Our Span Proposal module consists of two components: Span Proposal Filter and Boundary Regressor. The former is used to drop the contextual spans and keep the span proposals, while the latter is used to adjust the boundaries of the span proposals to locate entities.</p><p>Span Proposal Filter For the seed span b i (st i , ed i ), we concatenate the maximum pooled span representation h p i with the inner boundary word representations (h st i , h ed i ) to obtain the span representation h f ilter i . Based on it we calculate the probability p f ilter i that the span b i belongs to the span proposals, computed as follows:</p><formula xml:id="formula_0">h p i = MaxPooling(h st i , h st i +1 , . . . , h ed i ) (1) h f ilter i = [h p i ; h st i ; h ed i ] (2) p f ilter i = Sigmoid MLP h f ilter i (3)</formula><p>where [; ] denotes the concatenate operation, MLP consists of two linear layers and a GELU (Hendrycks and Gimpel, 2016) activation function.</p><p>Boundary Regressor Although the span proposal has a high overlap with the entity, it cannot hit the entity exactly. We design another boundary regression branch where a regressor locates entities by adjusting the left and right boundaries of the span proposals. The boundaries regression requires not only the information of span itself but also the outer boundary words. Thus we concatenate the maximum pooled span representation h p i with the outer boundary word representations (h st i ?1 , h ed i +1 ) to obtain the span representation h reg i . Then we calculate the offsets t i of left and right boundaries:</p><formula xml:id="formula_1">h reg i = [h p i ; h st i ?1 ; h ed i +1 ] (4) t i = W 2 ? GELU(W 1 h reg i + b 1 ) + b 2 (5) where W 1 ? R 3d?d , W 2 ? R d?2 , b 1 ? R d and b 2 ? R 2 are learnable parameters.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Entity Classifier Module</head><p>With the boundary offsets t i predicted by the boundary regressor, we adjust the boundaries of span proposals. The adjusted start postion st i and end position ed i of b i are calculated as follow:</p><formula xml:id="formula_2">st i = max(0, st i + t l i + 1 2 ) (6) ed i = min(L ? 1, ed i + t r i + 1 2 )<label>(7)</label></formula><p>where t l i and t r i denote the left and right offsets, respectively. As in the filter above, we concatenate the maximum pooled span representation h p i with the inner boundary word representations (h st i , h ed i ). Then we perform entity classification:</p><formula xml:id="formula_3">h p i = MaxPooling(h st i , h st i +1 , . . . , h ed i ) (8) h cls i = [ h p i ; h st i ; h ed i ]<label>(9)</label></formula><formula xml:id="formula_4">p i = Softmax MLP h cls i )<label>(10)</label></formula><p>where MLP consists of two linear layers and a GELU activation function, as in the filter above.</p><p>For training the entity classifier, we need to reassign the categories based on the IoU between the new adjusted span proposal and paired ground-truth entity. Specifically, if the IoU between a span and its corresponding entity is higher than the threshold ? 2 , we assign the span the same category with the entity, otherwise we assign it a NONE category and treat the span as a negative example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Training Objective</head><p>The spans that partially match with the entities are very important, but previous span-based approaches simply treat them as negative examples. Such practice not only fails to take advantage of these spans but also introduces noise into the model. We treat partially matched spans as soft examples by weighting its loss based on its IoU with the corresponding ground truth. For the i-th span b i , the weight w i is calculated as follows:</p><formula xml:id="formula_5">IoU(b i , e i ) ? , IoU(b i , e i ) ? ? (1 ? IoU(b i , e i )) ? , IoU(b i , e i ) &lt; ?<label>(11)</label></formula><p>where ? ? {? 1 , ? 2 } denotes the IoU threshold used in the first or the second stage and e i denotes corresponding ground-truth entity of b i . ? is a focusing parameter that can smoothly adjust the rate at which partially matched examples are down-weighted. We can find that if we set ? = 0, the above formula degenerates to a hard one. Also, if a span does not overlap with any entity or match exactly with some entity, the loss weight w i = 1. Then, we calculate the losses for the span proposal filter, boundary regressor and entity classifier respectively. For the span proposal filter, we use focal loss <ref type="bibr" target="#b25">(Lin et al., 2017)</ref> to solve the imbalance problem:</p><formula xml:id="formula_6">L f ilter = ? i w i I? =0 (1 ? p f ilter i ) ? log(p f ilter i ) + w i I? =0 (p f ilter i ) ? log(1 ? p f ilter i )</formula><p>(12) where w i is the weight of i-th example calculated at Equation 11 and ? denotes focusing parameter of focal loss. For the boundary regressor, the loss consists of two components, the smooth L1 loss at the boundary level and the overlap loss at the span level, calculated as follows:</p><formula xml:id="formula_7">L reg t , t = L f 1 + L olp (13) L f 1 t , t = i j?{l,r} smoothL1 t j i , t j i (14) L olp = i 1 ? min (d i ) ? max (e i ) max (d i ) ? min (e i )<label>(15)</label></formula><p>where</p><formula xml:id="formula_8">d i = ed i ,?d i , e i = st i ,?t i .?t i ,?d i ,</formula><p>t l i andt r i denote the ground-truth left boundary, right boundary, left offset and right offset, respectively. For the entity classifier, we simply use the cross-entropy loss:</p><formula xml:id="formula_9">L cls = i w i CELoss(?, p i )<label>(16)</label></formula><p>where w i is the weight of i-th example calculated at Equation 11. We train the filter, regressor and classifier jointly, thus the total loss is computed as:</p><formula xml:id="formula_10">L = ? 1 L f ilter + ? 2 L reg + ? 3 L cls<label>(17)</label></formula><p>where ? 1 , ? 2 and ? 3 are the weights of filter, regressor and classifier losses respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Entity Decoding</head><p>In the model prediction phase, after the above steps, we get the classification probability and boundary offset regression results for each span proposal. Based on them, we need to extract all entities in the sentence (i.e., find the exact start and end positions of the entities as well as their corresponding categories). We assign label y i = argmax(p i ) to span s i and use score i = max(p i ) as the confidence of span s i belonging to the y i category. Now for each span proposal, our model has predicted the exact start and end positions, the entity class and the corresponding score, denoted as s i = (l i , r i , y i , score i ). Given the score threshold ? and the set of span proposals S = {s 1 , . . . , s N }, where N denotes as the number of span proposals, we use the Soft-NMS <ref type="bibr" target="#b1">(Bodla et al., 2017)</ref> algorithm to filter the false positives. As shown in Algorithm 1, we traverse the span proposals by the order of their score (the traversal term is denoted as s i ) and then adjust the scores of other span proposals s j to f (s i , s j ), which is defined as:</p><formula xml:id="formula_11">score j * u, IoU(s i , s j ) ? k score j , IoU(s i , s j ) &lt; k<label>(18)</label></formula><p>where u ? (0, 1) denotes the decay coefficient of the score and k denotes is the IoU threshold. Then we keep all span proposals with a score &gt; ? as the final extracted entities.</p><p>Algorithm 1: Soft-NMS Algorithm </p><formula xml:id="formula_12">Input: S = {s i , . . . , s N }, ?, where s i = (l i , r i , y i , score i ) Output: O 1 O ? {}; 2 Sort(S) by the score of each element in descend order; 3 for s i in S do 4 O ? O ? {s i } ; 5 for s j in S [i : N ] do 6 S ? S ? {s j }; 7 s j ? (l j , r j , y j , f (s i , s j )); 8 Insert (S, k, s j ) where k</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation Metrics</head><p>We use strict evaluation metrics that an entity is confirmed correct when the entity boundary and the entity label are correct simultaneously. We employ precision, recall and F1-score to evaluate the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parameter Settings</head><p>In most experiments, we use GloVE <ref type="bibr" target="#b34">(Pennington et al., 2014)</ref>   <ref type="table">Table 1</ref> illustrates the performance of the proposed model as well as baselines on ACE04, ACE05, GE-NIA and KBP17. Our model outperforms the stateof-the-art models consistently on three nested NER datasets. Specifically, the F1-scores of our model advance previous models by +3.08%, +0.71%, +1.27% on KBP17, ACE04 and ACE05 respectively. And on GENIA, we achieve comparable performance. We analyze the performance on entities of different lengths on ACE04, as shown in <ref type="table" target="#tab_4">Table 2</ref>. We observe that the model works well on the entities whose lengths are not enumerated during training. For example, although entities of length 6 are not enumerated, while those of length  <ref type="table">Table 1</ref>: Results for nested NER tasks 5 and 7 are enumerated, our model can achieve a comparable F1-score for entities of length 6. In particular, the entities whose lengths exceed the maximum length (15) enumerated during training, are still well recognized. This verifies that our model has the ability to identify length-uncovered entities and long entities by boundary regression. We also evaluated our model on two flat NER datasets, as shown in Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablation Study</head><p>We choose the ACE04 and KBP17 datasets to conduct several ablation experiments to elucidate the main components of our proposed model. To illustrate the performance of the model on entities of different lengths, we divide the entities into three groups according to their lengths. The re-  sults are shown in <ref type="table">Table 3</ref>. Firstly, we observe that the boundary regressor is very effective for the identification of long entities. Lack of the boundary regressor leads to a decrease in F1-score for long entities (L ? 10) on ACE04 by 36.73% and KBP17 by 30.54%. Then, compared with the w/o filter setting, the F1-scores of our full model on the two datasets improved by 0.52% and 0.75%, respectively. In addition, experimental results also demonstrate that the soft examples we constructed are effective. This allows the model to take full advantage of the information of partially matched spans in training, improving the F1-score by 0.87% on ACE04 and 0.16% on KBP17. However, Soft-NMS play a limited role and improve the model performance only a little. We believe that text is sparse data compared to images and the number of false positives predicted by our model is quite small, so the Soft-NMS can hardly perform the role of a filter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Time Complexity</head><p>Theoretically, the number of possible spans of a sentence of length N is N (N +1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>. Previous spanbased methods need to classify almost all spans into corresponding categories, which leads to the high computational cost with O(cN 2 ) time complexity where c is the number of categories. The words in a sentence can be divided into two categories: contextual words and entity words. Traditional approaches waste a lot of computation on the spans composed of contextual words. However, our approach retains only the span proposals containing entity words by the filter, and the time complexity is O(N 2 ). Although in the worst case the model keeps all seed spans, generating N (N +1) 2 span proposals, we observe that we generate approximately three times as many span proposals as the entities in practice. Assuming that the number of entities in the sentence is k, the total time complexity of our model is O(N 2 + ck) where k &lt;&lt; N 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Case Study</head><p>Examples of model predictions are shown in <ref type="table" target="#tab_7">Table  4</ref>. The first line illustrates that our model can recognize entities with multi-level nested structures. We can see that the three nested entities from inside to outside are united nations secretary general kofi annan, united nations secretary general and united nations, all of which can be accurately recognized by our model. The second line illustrates that our model can recognize long entities well, although trained without seed spans of the same length as it. The long entity Aceh, which is rich in oil and gas and has a population of about 4.1 million people, with a length of 20, exceeds the maximum length of generated seed spans, but can still be correctly located and classified. However, our model has difficulties in resolving ambiguous entity references. As shown in the third line, our model incorrectly classifies the reference phrase both sides, which refers to ORG, into the PER category.</p><p>6 Related Work 6.1 Nested Named Entity Recognition NER is usually modeled as a sequence labeling task, and a sequence model (e.g., LSTM-CRF <ref type="bibr" target="#b14">(Huang et al., 2015)</ref>) is employed to output the sequence of labels with maximum probability. However, traditional sequence labeling models cannot handle nested structures because they can only assign one label to each token. In recent years, several approaches have been proposed to solve the nested named entity recognition task, mainly including tagging-based <ref type="bibr" target="#b0">(Alex et al., 2007;</ref><ref type="bibr" target="#b44">Wang et al., 2020a)</ref>, hypergraph-based (Muis and <ref type="bibr" target="#b31">Lu, 2017;</ref><ref type="bibr" target="#b17">Katiyar and Cardie, 2018)</ref>, and span-based  <ref type="table">Table 3</ref>: Ablation study on ACE04 and KBP17. To compare the performance of the model on entities of different lengths, we divided the entities into three groups: 1 ? L &lt; 5, 5 ? L &lt; 10 and L ? 10.  (Sohrab and <ref type="bibr" target="#b47">Zheng et al., 2019)</ref> approaches. The tagging based nested NER model transforms the nested NER task into a special sequential tagging task by designing a suitable tagging schema. Layered-CRF <ref type="bibr" target="#b0">(Alex et al., 2007)</ref> dynamically stacks flat NER layers to identify entities from inner to outer. Pyramid <ref type="bibr" target="#b44">(Wang et al., 2020a</ref>) designs a pyramid structured tagging framework that uses CNN networks to identify entities from the bottom up. The hypergraph-based model constructs the hypergraph by the structure of nested NER and decodes the nested entities on the hypergraph. <ref type="bibr" target="#b27">Lu and Roth (2015)</ref> is the first to propose the use of Mention Hypergraphs to solve the overlapping mentions recognition problem. <ref type="bibr" target="#b17">Katiyar and Cardie (2018)</ref> proposed hypergraph representation for the nested NER task and learned the hypergraph structure in a greedy way by LSTM networks. The span-based nested NER model first extracts the subsequences (spans) in a sequence and then classifies these spans. Exhaustive Model (Sohrab and  exhausts all possible spans in a text sequence and then predicts their classes. <ref type="bibr" target="#b47">Zheng et al. (2019)</ref>; <ref type="bibr" target="#b42">Tan et al. (2020)</ref> took a sequence labeling model to identify entity boundaries and then predicted the categories of boundary-relevant regions. Different from the above methods, some works adopt the methods from other tasks. For example, <ref type="bibr" target="#b46">Yu et al. (2020)</ref> reformulated NER as a structured predic-tion task and adopted a biaffine model for nested and flat NER. While  treated NER as a reading comprehension task, and constructed type-specific queries to extract entities from the context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Object Detection</head><p>Object detection is a computer vision technique that can localize and identify objects in an image. With this identification and localization, object detection can determine the exact location of objects while assigning them categories. Neural-based object detection algorithms are divided into two main categories: one-stage and two-stage approach. The one-stage object detector densely proposes anchor boxes by covering the possible positions, scales, and aspect ratios, and then predicts the categories and accurate positions based on them in a singleshot way, such as OverFeat <ref type="bibr" target="#b38">(Sermanet et al., 2013)</ref>, YOLO <ref type="bibr" target="#b36">(Redmon et al., 2016)</ref> and SSD <ref type="bibr" target="#b26">(Liu et al., 2016)</ref>. The two-stage object detector can be seen as an extension of the dense detector and has been the most dominant object detection algorithm for many years <ref type="bibr" target="#b10">(Girshick et al., 2014;</ref><ref type="bibr" target="#b9">Girshick, 2015;</ref><ref type="bibr" target="#b37">Ren et al., 2017;</ref><ref type="bibr" target="#b5">Dai et al., 2016;</ref><ref type="bibr" target="#b2">Cai and Vasconcelos, 2018)</ref>. It first obtains sparse proposal boxes containing objects from a dense set of region candidates, and then adjusts the position and predicts a category for each proposal.</p><p>In this paper, we treat NER as a joint task of boundary regression and span classification and propose a two-stage entity identifier. First we generate span proposals through a filter and regressor, then classify them into the corresponding categories. Our proposed model can make full use of the boundary information of entities and reduce the computational cost. Moreover, by constructing soft samples during training, our model can exploit the spans that partially match with the entities. Experiments illustrate that our method achieves state-of-the-art performance on several nested NER datasets. For future work, we will combine named entity recognition and object detection tasks, and try to use a unified framework to address joint identification on multimodal data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Experiments on Nested NER A.1 Statistics of Nested Datasets</head><p>In <ref type="table" target="#tab_8">Table 5</ref>, We report the number of sentences, the number of sentences containing nested entities, the average sentence length, the total number of entities, the number of nested entities and the nesting ratio on the ACE04, ACE05, GENIA and KBP17 datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Baseline Methods</head><p>We use the following models as baselines for nested NER:</p><p>? Biaffine <ref type="bibr" target="#b46">(Yu et al., 2020)</ref> reformulates NER as a structured prediction task and adopts a dependency parsing approach for NER.</p><p>? Pyramid <ref type="bibr" target="#b44">(Wang et al., 2020a)</ref> consists of a stack of inter-connected layers. Each layer predicts whether a text region of certain length is a complete entity mention.</p><p>? BiFlaG <ref type="bibr" target="#b46">(Yu et al., 2020</ref>) designs a bipartite flat-graph network with two interacting subgraph modules for outermost entities and inner entities, respectively.</p><p>? HIT <ref type="bibr" target="#b45">(Wang et al., 2020b)</ref> leverages the headtail pair and token interaction to express the nested entities.</p><p>? ARN <ref type="bibr" target="#b23">(Lin et al., 2019</ref>) designs a sequence-tonuggets architecture by modeling and levraging the head-driven phrase structures of entity mentions.</p><p>? Seq2seq <ref type="bibr" target="#b41">(Strakov? et al., 2019)</ref> views the nested NER as a sequence-to-sequence problem.</p><p>? KBP17-Best <ref type="bibr" target="#b15">(Ji et al., 2017)</ref> gives an overview of the Entity Discovery task and reports previous best results for the task of nested NER.</p><p>We didn't compare our model with BERT-MRC , because it uses additional external resources to construct the questions, which essentially introduces descriptive information about the categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Detailed Parameter Settings</head><p>In our experiments, the detailed parameter settings for the model are shown in <ref type="table" target="#tab_9">Table 6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Analysis of Boundary Offset Regression</head><p>We analyzed the distribution of the boundary offsets predicted by the model on the ACE04 dataset, as shown in <ref type="figure">Figure 3</ref>. We can find that the numbers of offsets by 0, 1, 2, 3 and ? 4 are 2162, 2440, 888, 368 and 202, respectively. Most of the offsets are 1, indicating that most of the seed spans require slight boundary adjustments to accurately locate the entities. There are also many offsets of 0. This is because many entities in the dataset are short and the seed spans can cover them, and their boundaries do not need to be adjusted. We use two flat NER datasets to evaluate our model:</p><p>CoNLL03 English is an English dataset <ref type="bibr" target="#b43">(Tjong Kim Sang and De Meulder, 2003)</ref> with four types of flat entities: Location, Organization, Person and Miscellaneous. Following <ref type="bibr" target="#b23">Lin et al. (2019)</ref>, we train our model on the concatenation of the train and dev set.</p><p>Weibo Chinese is a Chinese dataset <ref type="bibr" target="#b33">(Peng and Dredze, 2015)</ref> sampled from Weibo with four types of flat entities, including Person, Organization, Location and Geo-political. And we evaluate our model using the same setting with <ref type="bibr" target="#b21">Li et al. (2020a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Baselines</head><p>For English flat NER, we use several taggers as baseline models, including ELMO-Tagger <ref type="bibr" target="#b35">(Peters et al., 2018)</ref>, BERT-Tagger <ref type="bibr" target="#b35">(Peters et al., 2018)</ref>, which using ELMO, BERT as encoder respectively. And for Chinese flat NER, we use Glyce (Meng  <ref type="bibr">-7, 9, 11, 13, 15]</ref> [1-10]  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Results</head><p>We evaluated our model on the flat NER dataset, as shown in <ref type="table" target="#tab_11">Table 7</ref>. Our model outperforms the baseline models on Weibo Chinese, improving the F1-score by 0.61%. On CoNLL03, our model also achieves comparable results, with less than 1% performance drop compared to the <ref type="bibr" target="#b46">(Yu et al., 2020)</ref>.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>S . tourist was detained and accused of spying after photographing a riot in the province of Irian Jaya . 47,000 cars drive by the site daily and because the players have to drive by it every day it could become a hangout for them . A Comparison of Named Entity Recognition and Object Detection. Examples of flat and nesetd entities or objects sampled from the COCO 2017 dataset and the ACE04 dataset, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The overall architecture of the Two-stage Identifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 3: Boundary Offset Statistics</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>KBP17<ref type="bibr" target="#b15">(Ji et al., 2017)</ref> has 5 entity categories, including GPE, ORG, PER, LOC, and FAC. We follow<ref type="bibr" target="#b23">Lin et al. (2019)</ref> to split all documents into 866/20/167 documents for train/dev/test set.</figDesc><table><row><cell>GENIA (Ohta et al., 2002) is a biology nested</cell><cell></cell></row><row><cell>named entity dataset and contains five entity types,</cell><cell></cell></row><row><cell>including DNA, RNA, protein, cell line, and cell</cell><cell></cell></row><row><cell>type categories. Following Yu et al. (2020), we use</cell><cell></cell></row><row><cell>90%/10% train/test split.</cell><cell></cell></row><row><cell>9</cell><cell>end</cell></row><row><cell cols="2">10 end</cell></row><row><cell cols="2">3 Experiment Settings</cell></row><row><cell cols="2">3.1 Datasets</cell></row><row><cell cols="2">To provide empirical evidence for effectiveness of</cell></row><row><cell cols="2">the proposed model, we conduct our experiments</cell></row><row><cell cols="2">on four nested NER datasets: ACE04 1 , ACE05 2 ,</cell></row><row><cell cols="2">KBP17 3 and GENIA 4 . Please refer to Appendix</cell></row><row><cell cols="2">A.1 for statistical information about the datasets.</cell></row><row><cell cols="2">ACE 2004 and ACE 2005 (Doddington et al.,</cell></row><row><cell cols="2">2004; Christopher Walker and Maeda, 2006) are</cell></row><row><cell cols="2">two nested datasets, each of them contains 7 entity</cell></row><row><cell cols="2">categories. We follow the same setup as previous</cell></row><row><cell cols="2">work Katiyar and Cardie (2018); Lin et al. (2019)</cell></row><row><cell cols="2">split them into train, dev and test sets by 8:1:1.</cell></row></table><note>denotes the insertion position of s j in S ordered by score;</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>A comparison of recognition F1-score on entities of different lengths. Regular rows indicate that the entity lengths are enumerated, while bold ones indicate that the entity lengths are not enumerated.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Cases Study. Blue brackets indicate entities predicted by the model, red brackets indicate true entities, the labels in the lower right corner indicate the type of entity, and the superscripts indicate the level of the nesting.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Statistics of the datasets used in the experiments.</figDesc><table><row><cell>P</cell><cell cols="4">ACE04 ACE05 KBP17 GENIA</cell></row><row><cell>lr</cell><cell>3e-05</cell><cell>3e-05</cell><cell>5e-5</cell><cell>5e-6</cell></row><row><cell>windows</cell><cell>[1</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Detailed Parameter(P) Settings et al., 2019), FLAT (Li et al., 2020a) and SLK-NER (Hu and Wei, 2020) as baseline models. They incoprate glyph information, phrase embeddings and second-order lexicon knowledge for Chinese NER respectively.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Results for flat NER tasks</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://catalog.ldc.upenn.edu/LDC2005T09 2 https://catalog.ldc.upenn.edu/LDC2006T06 3 https://catalog.ldc.upenn.edu/LDC2019T02 4 http://www.geniaproject.org/genia-corpus</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Our code is available at https://github.com/ tricktreat/locate-and-label.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Statistics</head> <ref type="table">ACE04  ACE05  KBP17  GENIA   Train  Dev  Test  Train  Dev  Test  Train  Dev  Test  Train  Test   # sentences  6200  745  812  7194  969  1047 10546  545  4267  16692 1854  # sent. nested entities  2712  294  388  2691  338  320  2809  182  1223  3522  446  avg sentence</ref> </div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recognising nested named entities in biomedical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Grover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biological, translational, and clinical language processing</title>
		<meeting><address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Soft-nms -improving object detection with one line of code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bodla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2017.593</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5562" to="5570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cascade r-cnn: Delving into high quality object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2018.00644</idno>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6154" to="6162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">How to train good word embeddings for biomedical NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Billy</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gamal</forename><surname>Crichton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W16-2922</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Workshop on Biomedical Natural Language Processing</title>
		<meeting>the 15th Workshop on Biomedical Natural Language Processing<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="166" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Ace 2005 multilingual training corpus. linguistic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuaki</forename><surname>Maeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">57</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Rfcn: Object detection via region-based fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">https:/dl.acm.org/doi/10.5555/3157096.3157139</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS&apos;16</title>
		<meeting>the 30th International Conference on Neural Information Processing Systems, NIPS&apos;16<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="379" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The automatic content extraction (ACE) program -tasks, data, and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC&apos;04)</title>
		<meeting>the Fourth International Conference on Language Resources and Evaluation (LREC&apos;04)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>European Language Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep joint entity disambiguation with local neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Octavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hofmann</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1277</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2619" to="2629" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2015.169</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV), ICCV &apos;15</title>
		<meeting>the 2015 IEEE International Conference on Computer Vision (ICCV), ICCV &apos;15<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2014.81</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR &apos;14</title>
		<meeting>the 2014 IEEE Conference on Computer Vision and Pattern Recognition, CVPR &apos;14<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2017.322</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Bridging nonlinearities and stochastic regularizers with gaussian error linear units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<idno>abs/1606.08415</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Slk-ner: Exploiting second-order lexicon knowledge for chinese ner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dou</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingwei</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 32nd International Conference on Software &amp; Knowledge Engineering</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Bidirectional lstm-crf models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Overview of TAC-KBP2017 13 languages entity discovery and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cash</forename><surname>Costello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Text Analysis Conference</title>
		<meeting>the 2017 Text Analysis Conference<address><addrLine>Gaithersburg, Maryland, USA</addrLine></address></meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2017-11-13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A neural layered model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meizhi</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1131</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1446" to="1459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Nested named entity recognition revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arzoo</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1079</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Long Papers; New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="861" to="871" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Improving entity linking by modeling latent relations between mentions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phong</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1148</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1595" to="1604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">BioBERT: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonjin</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunkyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chan</forename><surname>Ho So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btz682</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Incremental joint extraction of entity mentions and relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/P14-1038</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="402" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">FLAT: Chinese NER using flatlattice transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaonan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.611</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6836" to="6842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A unified MRC framework for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingrong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxian</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.519</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5849" to="5859" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sequence-to-nuggets: Nested entity mention detection via anchor-region networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaojie</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1511</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5182" to="5192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Italy</forename><surname>Florence</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2017.324</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2999" to="3007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander C</forename><surname>Berg</surname></persName>
		</author>
		<idno type="DOI">https:/link.springer.com/chapter/10.1007/978-3-319-46448-0_2</idno>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Joint mention extraction and classification with mention hypergraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1102</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="857" to="867" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Bipartite flat-graph network for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.571</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6408" to="6418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Glyce: Glyph-vectors for chinese character representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxian</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="2746" to="2757" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">End-to-end relation extraction using LSTMs on sequences and tree structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1105</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1105" to="1116" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Labeling gaps between words: Recognizing overlapping mentions with mention separators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aldrian</forename><surname>Obaja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muis</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D17-1276</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2608" to="2618" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The genia corpus: An annotated research abstract corpus in molecular biology domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">https:/dl.acm.org/doi/10.5555/1289189.1289260</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second International Conference on Human Language Technology Research, HLT &apos;02</title>
		<meeting>the Second International Conference on Human Language Technology Research, HLT &apos;02<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="82" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Named entity recognition for Chinese social media with jointly trained embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dredze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1064</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="548" to="554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1202</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2016.91</idno>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2016.2577031</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1149" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Overfeat: Integrated recognition, localization and detection using convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?l</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>2nd International Conference on Learning Representations</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Nested named entity recognition via second-best sequence learning and decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Shibuya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00334</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="605" to="620" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deep exhaustive model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golam</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Sohrab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miwa</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1309</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2843" to="2849" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Neural architectures for nested NER through linearization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Strakov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1527</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5326" to="5331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Boundary enhanced neural span classification for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosha</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1609/aaai.v34i05.6434</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9016" to="9023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien</forename><surname>De Meulder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</title>
		<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Pyramid: A layered model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidan</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.525</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5918" to="5928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">HIT: Nested named entity recognition via head-tail pair and token interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziye</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.486</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6027" to="6036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Named entity recognition as dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juntao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.577</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6470" to="6476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A boundary-aware neural model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changmeng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guandong</forename><surname>Ho-Fung Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1034</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="357" to="366" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
