<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Graphical Abstract ScanMix: Learning from Severe Label Noise via Semantic Clustering and Semi- Supervised Learning Highlights ScanMix: Learning from Severe Label Noise via Semantic Clustering and Semi- Supervised Learning ScanMix: Learning from Severe Label Noise via Semantic Clustering and Semi-Supervised Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ragav</forename><surname>Sachdeva</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filipe</forename><forename type="middle">Rolim</forename><surname>Cordeiro</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Belagiannis</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ragav</forename><surname>Sachdeva</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filipe</forename><forename type="middle">Rolim</forename><surname>Cordeiro</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Belagiannis</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ragav</forename><surname>Sachdeva</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Engineering Science</orgName>
								<orgName type="laboratory">Visual Geometry Group</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Engineering Science</orgName>
								<orgName type="laboratory">Present Address: Visual Geometry Group</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filipe</forename><forename type="middle">Rolim</forename><surname>Cordeiro</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computing</orgName>
								<orgName type="laboratory">Visual Computing Lab</orgName>
								<orgName type="institution">Universidade Federal Rural de Pernambuco</orgName>
								<address>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Belagiannis</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Otto-von-Guericke-Universit?t Magdeburg</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Australian Institute for Machine Learning</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Australian Institute for Machine Learning</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Centre for Vision, Speech and Signal Processing</orgName>
								<orgName type="institution">University of Surrey</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Graphical Abstract ScanMix: Learning from Severe Label Noise via Semantic Clustering and Semi- Supervised Learning Highlights ScanMix: Learning from Severe Label Noise via Semantic Clustering and Semi- Supervised Learning ScanMix: Learning from Severe Label Noise via Semantic Clustering and Semi-Supervised Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">Preprint submitted to Pattern Recognition October 18, 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Noisy label learning</term>
					<term>Semi-supervised learning</term>
					<term>Semantic clustering</term>
					<term>Self-supervised Learning</term>
					<term>Expectation maximisation * Corresponding author</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a new training algorithm, ScanMix, that explores semantic clustering and semi-supervised learning (SSL) to allow superior robustness to severe label noise and competitive robustness to non-severe label noise problems, in comparison to the state of the art (SOTA) methods. ScanMix is based on the expectation maximisation framework, where the E-step estimates the latent variable to cluster the training images based on their appearance and classification results, and the M-step optimises the SSL classification and learns effective feature representations via semantic clustering. We present a theoretical result that shows the correctness and convergence of ScanMix,</p><p>and an empirical result that shows that ScanMix has SOTA results on CIFAR-10/-100 (with symmetric, asymmetric and semantic label noise), Red Mini-ImageNet (from the Controlled Noisy Web Labels), Clothing1M and WebVision. In all benchmarks with severe label noise, our results are competitive to the current SOTA. 65 31, 32, 33], dimensionality reduction of the image representation [34], and combinations of the techniques above <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b12">12,</ref><ref type="bibr" target="#b38">38]</ref>. Recent advances showed that the most promising strategies are based on the combination of co-training, noise filtering, data augmentation and SSL <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b4">5,</ref> 6]. Below, we do not review approaches that require a clean validation set, such as [39], since that setup imposes a strong constraint on the 70 type of noisy-label learning problem.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Much of the success of deep learning models is attributable to the availability of well-curated large-scale datasets that enables a reliable supervised learning process <ref type="bibr" target="#b0">[1]</ref>.</p><p>However, the vast majority of real-world datasets have noisy labels due to human failure, poor quality of data or inadequate labelling process <ref type="bibr" target="#b1">[2]</ref>. Using noisy label datasets for <ref type="bibr" target="#b4">5</ref> training not only hurts the model's accuracy, but also biases the model to make the same mistakes present in the labels <ref type="bibr" target="#b2">[3]</ref>. Therefore, one of the important challenges in the field is the formulation of robust training algorithms that work effectively with datasets corrupted with noisy labels.</p><p>Successful approaches to address the learning from noisy label (LNL) problem tend <ref type="bibr" target="#b10">10</ref> to rely on semi-supervised learning (SSL) <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr">6,</ref><ref type="bibr" target="#b6">7]</ref>. Such methods run the following steps iteratively: a) automatically split the training set into clean and noisy sets, b) discard the labels of the samples in the noisy set and, c) minimise the classification loss with the labelled (clean) and unlabelled (noisy) data. Consequently, these SSL methods rely on successfully splitting the training set into clean and noisy sets, which for low <ref type="bibr" target="#b15">15</ref> noise rates, is accurate <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr">6,</ref><ref type="bibr" target="#b6">7]</ref> because of the strong support in the training set that associates image representations and their true labels. However, for severe label noise, this support weakens, resulting in the over-fitting of label noise <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr">6,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>To mitigate the issues caused by severe label noise, one can consider self-supervised learning strategies <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr">11]</ref> to build feature representations using appearance <ref type="bibr" target="#b20">20</ref> clustering techniques. These strategies <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">10,</ref><ref type="bibr">11]</ref> show better classification accuracy than recently proposed LNL methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">12]</ref> when the noise rate is large (above 80% symmetric and 40% asymmetric). However, for low noise rates, SSL methods tend to produce better results because self-supervised methods typically tend to cluster images with similar appearance, but such similarity does not imply that the images belong to <ref type="bibr" target="#b25">25</ref> same class. We argue that in a noisy label context, the use of self-supervised learning (without using the training set labels) can create an initial feature representation that is more related to the real hidden representation in comparison to supervised training with noisy labels. However, when the dataset is relatively well-structured and clean, the use of self-supervised learning alone is not enough to bridge the gap to its supervised training counterpart. To this end, we propose a training mechanism that performs semantic clustering and SSL in tandem. We hypothesise that such training 1) enables the model to not get too biased by noisy labels (as it is guided by semantic clustering), and 2) still produces accurate classification results using the SSL strategy. These points are illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>. <ref type="bibr" target="#b35">35</ref> We test this hypothesis with the proposed label-noise robust training algorithm, Scan-Mix, that explores semantic clustering and SSL to enable superior robustness to severe label noise and competitive robustness to non-severe label noise problems, compared with the state of the art (SOTA). ScanMix is based on the expectation maximisation (EM) framework <ref type="bibr" target="#b13">[13]</ref>, where the semantic clustering stage clusters images with similar 40 appearance and classification results, enabling a more effective identification of noisy label images to subsequently be "unlabelled" and used by SSL. Although the use of EM in the context of LNL has been explored in <ref type="bibr" target="#b14">[14]</ref>, ScanMix is the first to propose the joint exploration of semantic clustering and SSL together. The implementation of ScanMix relies on SOTA semantic clustering <ref type="bibr" target="#b10">[10]</ref> and noisy label robust SSL <ref type="bibr" target="#b6">[7]</ref>. We show a <ref type="bibr" target="#b45">45</ref> theoretical result that proves that ScanMix is correct and converges to a stationary point under certain conditions. The main contributions of ScanMix are:</p><p>? A new noisy-label learning algorithm, based on EM optimisation, that explores and combines the advantages of semantic clustering and semi-supervised learning showing remarkable robustness to severe label noise rates;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>50</head><p>? A new theoretical result that shows the correctness and convergence of the noisylabel learning algorithm; and</p><p>? Competitive performance in a wide range of noisy-label learning problems, such as symmetric, asymmetric, semantic or instance dependent, and controlled noisy web labels. <ref type="bibr" target="#b55">55</ref> Empirical results on CIFAR-10/-100 <ref type="bibr" target="#b15">[15]</ref> under symmetric, asymmetric and semantic noise, show that ScanMix outperforms previous approaches. For high-noise rate problems in CIFAR-10/-100 <ref type="bibr" target="#b6">[7]</ref> and Red Mini-ImageNet from the Controlled Noisy Web Labels <ref type="bibr" target="#b16">[16]</ref>, ScanMix presents the best results in the field. Furthermore, we show results on the challenging semantic label noise present in the large-scale real-world datasets <ref type="bibr" target="#b60">60</ref> Clothing1M <ref type="bibr" target="#b17">[17]</ref> and WebVision <ref type="bibr" target="#b18">[18]</ref>, where our proposed method shows SOTA results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Prior Work</head><p>The main noisy label learning techniques are: label cleansing <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b20">20]</ref>, iterative label correction <ref type="bibr" target="#b21">[21]</ref>, robust loss functions [22, <ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b24">24]</ref>, meta-learning <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b16">16,</ref><ref type="bibr" target="#b26">26]</ref>, sample weighting <ref type="bibr" target="#b27">[27]</ref>, ensemble learning <ref type="bibr" target="#b28">[28]</ref>, student-teacher model <ref type="bibr" target="#b29">[29]</ref>, co-teaching <ref type="bibr">[7, 30,</ref> Instead, we focus on methods based on SSL for noisy-label training <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr">6,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b41">41]</ref>, which usually show SOTA results on several benchmarks. These methods rely on: 1) the identification of training samples containing noisy labels and the subsequent removal of their labels; and 2) performing SSL [42] using this set of unlabelled samples 75 and the remaining set of labelled samples. <ref type="bibr" target="#b3">[4]</ref> identify a small portion of clean samples from the noisy training set by associating them with high confidence. Then, they use the filtered samples as labelled and the remaining ones as unlabelled in an SSL approach.</p><p>However, relying on highly confident samples to compose the labelled set may not work well for severe noise rate scenarios because this labelled set can be contaminated with 80 high noise rate. The methods in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b4">5]</ref>  However, these strategies do not perform well for high noise rates because MixUp 85 tends to be ineffective in such scenario. SSL methods can be robust to severe label noise by exploring a feature clustering scheme that pulls together samples that are semantically similar, without considering the noisy labels from the training set, and one way to enable such semantic clustering is provided by self-supervised learning <ref type="bibr">[11,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">10]</ref>.</p><p>Self-supervised learning has been used as a pre-training approach to estimate reliable 90 features from unlabelled datasets, but we are not aware of methods that use it for semantic clustering. For instance, SimCLR [11] generates data augmentations of the input images and trains the model to have similar representation of an image and its augmented samples, while increasing the dissimilarity to the other images. MoCo <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> tackles self-supervised representation learning by conflating contrastive learning with a 95 dictionary look-up. The proposed framework builds a dynamic dictionary with a queue and a moving-averaged encoder to enable building a large and consistent dictionary onthe-fly that facilitates contrastive unsupervised learning. Another example is SCAN <ref type="bibr" target="#b10">[10]</ref> that has several stages of self-supervised training: one based on SimCLR [11], followed by another based on a nearest neighbor clustering scheme, and another based on self-100 labelling. Self-supervised learning approaches usually show results better than the noisy label SOTA methods for severe label noise problems (above 80% noise), but for relatively low label noise rates (below 50% noise), self-supervised learning tends to be worse. Therefore, the main question we address in this paper is how to explore the semantic clustering capability of self-supervised learning approaches together with 105 SSL methods, to improve the current SOTA results in severe label noise problems, and maintain the SOTA results in low noise label scenarios. Even though sophisticated clustering approaches have been proposed in the field <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b46">46,</ref><ref type="bibr">47]</ref>, we opted to use a simple Euclidean-distance based K-nearest neighbour clustering approach. Furthermore, semantic clustering has been explored in LNL problems <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b48">48]</ref>, but without relying on 110 SSL methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dataset and Label Noise Types</head><p>Let the training set be denoted by This latent true label is used by a noise process to produce</p><formula xml:id="formula_0">D = {(x i , y i )} |D| i=1 , with x i ? S ? R</formula><formula xml:id="formula_1">y i ? p(y|x i , Y,? i ), with p(y(j)|x i , Y,? i (c)) = ? jc (x i ), where ? jc (x i ) ? [0, 1] and j?Y ? jc (x i ) = 1.</formula><p>The types of noises considered in this paper are: symmetric <ref type="bibr" target="#b36">[36]</ref>, asymmetric <ref type="bibr" target="#b49">[49]</ref>, 120 semantic [50], and real-world noise <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b17">17]</ref>. The symmetric (or uniform) noise flips the latent true label? i ? Y to any of the labels in Y (including the true label) with a fixed probability ?, so ? jc (x i ) = ? |Y|?1 , ?j, c ? Y, such that j = c, and ? cc (x i ) = 1 ? ?. The asymmetric noise flips the labels between semantically similar classes <ref type="bibr" target="#b49">[49]</ref>, so 125 ? jc (x i ) is based on a transition matrix between classes j, c ? Y, but not on x i . The semantic noise <ref type="bibr">[50]</ref> also uses an estimated transition probability between classes j, c ? Y but takes into account the image x i (i.e., it is an image conditional transition probability).</p><p>Real-world noise <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b18">18,</ref><ref type="bibr" target="#b17">17]</ref>   where we use contrastive loss to approximate features to its data augmented variants, in the feature space, while repelling representations from negative examples. In the training stage we first warm-up the classifier using a simple classification loss. Then, using the classification loss, we train the GMM to separate the samples into a clean set X and a noisy set U that are "MixMatched" [42] for SSL training. In parallel to this SSL training, we use the classification results and feature representations to train the semantic clustering. Please see Algorithm 1 for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">ScanMix</head><p>The proposed ScanMix training algorithm ( </p><formula xml:id="formula_2">p ? (y|x) = p ? (y|f ? (x)),<label>(1)</label></formula><p>where p ? (.) ? [0, 1] |Y| produces a probability distribution over the classes in the</p><formula xml:id="formula_3">classification space Y using the feature representation f ? (x) ? R d of the input image x.</formula><p>The optimal parameters for the classifier are estimated with maximum likelihood estimation (MLE):</p><formula xml:id="formula_4">? * = arg max ? 1 |D| (xi,yi)?D log p ? (y i |x i ),<label>(2)</label></formula><p>where</p><formula xml:id="formula_5">log p ? (y i |x i ) =E q(z) log p ? (y i |x i ) q(z) q(z) = q(z) log p ? (y i , z|x i )q(z) p ? (z|y i , x i )q(z) dz =E q(z) [log(p ? (y i , z|x i ))] ? E q(z) [log q(z)] + KL[q(z)||p ? (z|y i , x i )] = ELBO (q, ?) + KL[q(z)||p ? (z|y i , x i )].<label>(3)</label></formula><p>In Eq.3 above, we have:</p><formula xml:id="formula_6">ELBO (q, ?) = E q(z) [log p ? (y, z|x)] ? E q(z) [log q(z)],<label>(4)</label></formula><p>with KL[?] denoting the Kullback-Leibler divergence, and q(z) representing the variational distribution that approximates p ? (z|y, x), defined as</p><formula xml:id="formula_7">p ? (z ji |x i , y i ) = ? ? ? (1 ? z ji ) , if y j = y i (p ? (: |x j ) p ? (: |x i )) zji (1 ? p ? (: |x j ) p ? (: |x i )) (1?zji) , if y j = y i<label>(5)</label></formula><p>where p ? (: |x) ? [0, 1] |Y| is the probability classification for defined in Eq.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>140</head><p>Hence, Eq.5 defines the probability of z ij ? {0, 1}, denoting the probability of x j to belong to the set of K nearest neighbours (KNN) of x i . In this definition, when their labels are different, or y i = y j , the probability of z ij = 1 is 0 (and consequently, the probability of z ij = 0 is 1). Also, when their labels are equal, or y i = y j , the probability of z ij = 1 depends on the similarity of their classification probabilities 145 denoted by p ? (: |x j ) p ? (: |x i ).</p><p>The maximisation of the log likelihood in Eq.2 follows the EM algorithm <ref type="bibr" target="#b13">[13]</ref> consisting of two steps. The E-step maximizes the lower bound of Eq.3 by zeroing the KL divergence with q(z ji ) = p ? old (z ji |y i , x i ), where ? old denotes the parameter from the previous EM iteration. Then the M-step maximises ELBO in Eq.4, which re-writes Eq.2 as:</p><formula xml:id="formula_8">? * = arg max ? 1 |D| (xi,yi)?D |D| j=1 zij ?{0,1} q(z ji ) log p ? (z ji , y i |x i ) = arg max ? 1 |D| (xi,yi)?D |D| j=1 zij ?{0,1} q(z ji ) log (p ? (z ji |y i , x i )p ? (y i |x i ))</formula><p>which by noting that</p><formula xml:id="formula_9">(xi,yi)?D |D| j=1 zij ?{0,1} q(z ji ) log p ? (y i |x i ) = (xi,yi)?D |D| j=1 log p ? (y i |x i ),</formula><p>we have</p><formula xml:id="formula_10">? * = arg max ? 1 |D| (xi,yi)?D |D| j=1 log p ? (y i |x i ) + zij ?{0,1} q(z ji ) log p ? (z ji |y i , x i ) ,<label>(6)</label></formula><p>where the term E q(z) [log(q(z))] is removed from ELBO since it only depends on the parameter from the previous iteration, ? old . Hence, Eq.6 comprises two terms: 1) the classification term that maximises the likelihood of the label y i for sample x i ; and 2)</p><p>the semantic clustering term that maximises the association between samples that are 150 close in the feature and label spaces, according to q(z ji ) estimated from the E-step.</p><p>According to the Equations 5 and 6, the run-time complexity of ScanMix is quadratic in |D|, making this algorithm impractical for large-scale problems. Therefore, we approximate both steps by running a self-supervised pre-training process <ref type="bibr">[11,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">10]</ref> that forms an initial set of K nearest neighbours in the feature space f ? (x) for each <ref type="bibr">155</ref> training sample. The set of KNN samples for each sample x i ? D is denoted by</p><formula xml:id="formula_11">N xi = {x j } K j=1 (for x j ? D)</formula><p>. Then, q(z ji ) is approximated to be equal to 1, when x j ? N xi and y j = y i , and 0 otherwise. Such an approximation makes the run-time complexity of the E and M steps linear in D 2 . Also, using this approximation to estimate q(z ji ) in Eq.5 reduces even more the complexity of the semantic clustering maximisation 160 because we only consider q(z ji = 1) instead of q(z ji = 1) and q(z ji = 0).</p><p>The optimisation of the classification term in Eq.6 assumes that D is not noisy, so we modify it to enable learning with a noisy dataset. This is achieved by maximising a lower bound of that term, as follows <ref type="bibr" target="#b6">[7]</ref>:</p><formula xml:id="formula_12">maximise 1 |X | (x,y)?X log p ? (y|x) subject to 1 |U| (x,y)?U y ? p ? (: |x) 2 2 = 0 KL ? ? ? |Y| 1 |X | + |U| x?(X U ) p ? (: |x) ? ? = 0,<label>(7)</label></formula><p>where X and U represent the sets of samples extracted from D automatically classified as clean and noisy, respectively, p ? (: |x) denotes the classification probability for all classes in Y, KL[.] represents the Kullback Leibler (KL) divergence, and ? |Y| denotes a vector of |Y| dimensions with values equal to 1/|Y|. The classification of training samples into clean or noisy is first formed with <ref type="bibr" target="#b51">[51,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr">50,</ref><ref type="bibr" target="#b38">38]</ref>:</p><formula xml:id="formula_13">X = {(x i , y i ) : p (clean| i , ?) ? ? } , U = {(x i , y * i ) : p (clean| i , ?) &lt; ? } ,<label>(8)</label></formula><p>with ? denoting a threshold to classify a clean sample, y * i = p ? (: |x i ), i = ?y i log p ? (: |x i ), and p (clean| i , ?) being a function that estimates the probability that (x i , y i ) is a clean label sample. The function p (clean| i , ?) in Eq.8 is a bi-modal Gaussian mixture model (GMM) <ref type="bibr" target="#b6">[7]</ref> (? denotes the GMM parameters), where the component with larger 165 man is the noisy component and the smaller mean is the clean component. Next, we run SSL <ref type="bibr" target="#b6">[7]</ref>, consisting of a data augmentation to increase the number of samples in X and U , followed by MixMatch [42] that combines samples from both sets to form the sets X and U, which are used in Eq.7. The optimisation in Eq. 7 is done with Lagrange multipliers by minimising the loss M LE = X + ? u U + ? r r , where X represents 170 the (negative) objective function, U and r denote the two constraints, and ? u and ? r are the Lagrange multipliers.</p><p>We constrain the optimisation of the semantic clustering term in Eq.6 with a regulariser <ref type="bibr" target="#b10">[10]</ref> to make it robust to semantic drift <ref type="bibr" target="#b52">[52]</ref>. Hence, we maximise a lower bound of the semantic clustering term in Eq.6, as follows:</p><formula xml:id="formula_14">maximise 1 |D| (xi,yi)?D |D| j=1 zij ?{0,1} q(z ji ) log p ? (z ji |y i , x i ) subject to c?Y E x?D [p(c|x, ?)] log E x?D [p(c|x, ?)] = 0,<label>(9)</label></formula><p>where q(z ji ) = 1 if x i and x j have the same classification result, i.e., arg max c?Y p ? (c|x i ) = arg max c?Y p ? (c|x j ) and x j ? N xi . We also use Lagrange multipliers to optimise Eq. 9, where we minimise CLU = N + ? e e , with N denoting the negative objective 175 function, e representing the constraint, and ? e being the Lagrange multiplier. An interesting point from the optimisations in Eq. 7 and Eq. 9 is that the constraints can help mitigate the semantic drift problem <ref type="bibr" target="#b52">[52]</ref> typically present in under-constrained SSL methods.  Best 95.6 -</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Training, Inference, Correctness and Convergence Conditions</head><formula xml:id="formula_15">X , U =FormCleanNoisySets({p(clean| i, ?)} |D| i=1 , ? ) X , U =MixMatch(X , U ) for (xi, yi) ? D do E-step yi = arg max c?Y p ? (c|xi) q(zji) = 0, ?j ? {1, ...,</formula><formula xml:id="formula_16">81.0 - - - 78.6 - 41.2 - Last - - - - - - - - - - MOIT+ [6] Best 94.1 - 75.8 - 93.3 - 75.9 - 51.4 - Last - - - - - - - - - - DivideMix [7]</formula><p>Best 96.  and Eq.9. The inference uses the model in Eq.1 to classify x.</p><p>ScanMix improves ELBO (q, ?) in Eq.4 instead of improving p ? (y|x) in Eq.2.</p><p>Following Theorem 1 in <ref type="bibr" target="#b13">[13]</ref>, Lemma 1 shows the correctness of ScanMix, where an improvement to ELBO (q, ?) implies an increase to p ? (y|x). Following Theorem 2 in <ref type="bibr" target="#b13">[13]</ref>, Lemma 2 shows the convergence conditions of ScanMix. Proof. Following the proof for Theorem 1 in <ref type="bibr" target="#b13">[13]</ref>, from Eq.3, we have</p><formula xml:id="formula_17">log p ? (y|x) = ELBO (q, ?) + KL[q(z)||p ? (z|y, x)],<label>(10)</label></formula><p>where q(z) = p ? old (z|y, x). Subtracting log p ? (y|x) and log p ? old (y|x), we have</p><formula xml:id="formula_18">log p ? (y|x) ? log p ? old (y|x) = ELBO (q, ?) ? ELBO (q, ? old )+ KL[q(z)||p ? (z|y, x)] ? KL[q(z)||p ? old (z|y, x)].<label>(11)</label></formula><p>Given that KL[q(z)||p ? (z|y, x)] ? KL[q(z)||p ? old (z|y, x)] and that ELBO (q, ?) ? </p><formula xml:id="formula_19">ELBO (q, ? old ) = E q(z) [log p ? (y, z|x)] ? E q(z) [log p ? old (y, z|x)], we conclude that logp ? (y|x) ? log p ? old (y|x) ? E q(z) [log p ? (y, z|x)] ? E q(z) [log p ? old (y, z|x)] ? 0<label>(12)</label></formula><formula xml:id="formula_20">1. the sequence {log p ? (e) (y|x)} +? e=1 is bounded above, and 2. E q(z) [log p ? (e+1) (y, z|x)] ? E q(z) [log p ? (e) (y, z|x)] ? ? ? (e+1) ? ? (e) ? (e+1) ? ? (e) , 200</formula><p>for ? &gt; 0 and all e ? 1, and q(z) = p ? (e) (z|y, x).</p><p>Then the sequence {? (e) } +? e=1 converges to some ? ? ?.</p><p>Proof. Following the proof for Theorem 2 in <ref type="bibr" target="#b13">[13]</ref>, the sequence {log p ? (e) (y|x)} +? e=1 is non-decreasing (from Lemma 1) and bounded above (from assumption (1) in Lemma 2), so it converges to L &lt; +?. Therefore, according to Cauchy criterion [57], for any &gt; 0, we have e ( ) such that, for e ? e ( ) and all r ? 1,</p><formula xml:id="formula_21">r j=1 log p ? (e+j) (y|x) ? log p ? (e+j?1) (y|x) = log p ? (e+r) (y|x) ? log p ? (e) (y|x) &lt; .<label>(13)</label></formula><p>From Eq.12,</p><formula xml:id="formula_22">0 ? E q(z) [log p ? (e+j) (y, z|x)] ? E q(z) [log p ? (e+j?1) (y, z|x)] ? log p ? (e+j) (y|x) ? log p ? (e+j?1) (y|x)<label>(14)</label></formula><p>for j ? 1 and q(z) = p ? (e+j?1) (z|y, x). Hence, from Eq.13,</p><formula xml:id="formula_23">r j=1 E q(z) [log p ? (e+j) (y, z|x)]? E q(z) [log p ? (e+j?1) (y, z|x)] &lt; ,<label>(15)</label></formula><p>for e ? e ( ) and all r ? 1. Given assumption (2) in Lemma 2 for e, e + 1, e + 2, ..., e + r ? 1, we have from Eq.15,</p><formula xml:id="formula_24">&gt; ? r j=1 ? (e+j) ? ? (e+j?1) ? (e+j) ? ? (e+j?1) ,<label>(16)</label></formula><p>so</p><formula xml:id="formula_25">&gt; ? ? (e+r) ? ? (e) ? (e+r) ? ? (e) ,<label>(17)</label></formula><p>which is a requirement to prove the convergence of ? (e) to some ? ? ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup 205</head><p>We evaluate our method on CIFAR-10/-100 <ref type="bibr" target="#b15">[15]</ref>, Controlled Noisy Web Labels (CNWL) <ref type="bibr" target="#b38">[38]</ref>, Clothing1M <ref type="bibr" target="#b17">[17]</ref>, and WebVision <ref type="bibr" target="#b18">[18]</ref>. The CIFAR-10 and CIFAR-100 datasets contain 50,000 training images and 10,000 test images of size 32 ? 32 pixels with 10 and 100 classes respectively. Since both these datasets have been annotated with clean labels, we use synthetic noise to evaluate the models. For CIFAR-10/-210 100, we evaluate three types of noise: symmetric <ref type="bibr" target="#b58">[58,</ref><ref type="bibr" target="#b54">54]</ref>, asymmetric <ref type="bibr" target="#b58">[58,</ref><ref type="bibr" target="#b54">54]</ref>  The original image sizes are of 84?84 pixels, which are resized to 32?32 pixels. The 225 noise rates use in this work are 20%, 40%, 60% and 80%, as used in <ref type="bibr" target="#b16">[16]</ref>.</p><p>Clothing1M is a dataset of 14 classes containing 1 million training images downloaded from online shopping websites. All training images are resized to 256 ? 256 pixels <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b62">62]</ref>. The noise rate is estimated to be asymmetric <ref type="bibr" target="#b53">[53]</ref> with a rate of 40% <ref type="bibr" target="#b17">[17]</ref> and class distribution is heavily imbalanced. Clothing1M has 50k and 14k clean images 230 for training and validation, respectively, but we do not use them for training. The testing set has 10k clean-labelled images.</p><p>The WebVision <ref type="bibr" target="#b18">[18]</ref> is a real-world large scale dataset containing 2.4 million images collected from the internet, with the same 1000 classes from ImageNet <ref type="bibr" target="#b63">[63]</ref>. As the images vary in size, we resized them to 227 ? 227 pixels. WebVision provides a clean 235 test set of 50k images, with 50 images per class. We compare our model using the first 50 classes of the Google image subset, as in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b64">64]</ref> All experiments were run on Intel Core i9 computer with 128GB memory and 4x nVidia GeForce RTX 3090.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>240</head><p>CIFAR-10/-100. We use PreAct-ResNet-18 as our backbone model following <ref type="bibr" target="#b6">[7]</ref>. For the self-supervised pre-training learning task, we adopt the standard SimCLR <ref type="bibr">[11]</ref> implementation with a batch size of 512, SGD optimiser with a learning rate of 0.4, decay rate of 0.1, momentum of 0.9 and weight decay of 0.0001, and run it for 500  <ref type="table">Table 4</ref>: Test accuracy (%) for WebVision <ref type="bibr" target="#b18">[18]</ref> by methods trained with 100 epochs. Baseline results are as presented in <ref type="bibr" target="#b6">[7]</ref>. Top methods within 1% are in bold.</p><p>epochs. This pre-trained model produces feature representations of 128 dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>245</head><p>Using these representations we mine K = 20 nearest neighbours (as in <ref type="bibr" target="#b10">[10]</ref>) for each sample to form the sets {N xi } |D| i=1 , defined in the Method Section. For the semantic clustering task, we use a batch size of 128, ? e = 2 as in <ref type="bibr" target="#b10">[10]</ref>, SGD optimiser with momentum of 0.9, weight decay of 0.0005 and learning rate ? {0.001, 0.00001} based on the predicted noise rate, which is estimated with |U|/|D|, defined in Eq.8 -if this 250 ratio is larger than 0.6, then the learning rate is 0.001, otherwise, the learning rate is 0.00001. This accounts for the fact that when the estimated label noise is high, then we want to increase the influence of semantic clustering in the training; but when the label noise is low, then the signal from the labels in the SSL method should carry more weighting. For the SSL, we adopt the implementation of <ref type="bibr" target="#b6">[7]</ref> and use the same 255 hyperparameters, where we rely on SGD with learning rate of 0.02 (which is reduced to 0.002 halfway through the training), momentum of 0.9 and weight decay of 0.0005.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of epochs E = 300.</head><p>Method Test Accuracy Cross-Entropy <ref type="bibr" target="#b6">[7]</ref> 69   Red Mini-ImageNet. We use PreAct-ResNet-18 as our backbone model, following <ref type="bibr" target="#b16">[16]</ref>.</p><p>For the self-supervised pre-training, we adopt the standard SimCLR [11] implementation 260 with batch size 128. All other parameters for the self-supervised pre-training and semantic clustering are the same as for CIFAR, except for the semantic clustering learning rate, which we used 0.001, and the ? u = 0 for all noise rates. The feature representation learned from this process has 128 dimensions. For the SSL, we adopt the implementation of <ref type="bibr" target="#b16">[16]</ref>, where we train for 300 epochs, relying on SGD with learning 265 rate of 0.02 (decreased by a factor of ten at epoch 200 and epoch 250), momentum of 0.9 and weight decay of 5e-4. We also resized the images from 84 ? 84 to 32 ? 32 <ref type="bibr" target="#b16">[16]</ref>.</p><p>Clothing1M. We use ResNet-50 as our backbone model, which is trained for 80 epochs with a WarmUp stage of 1 epoch. For the self-supervised pre-training task we adopt the standard MoCo-v2 method for a 4-GPU training <ref type="bibr" target="#b8">[9]</ref> with a batch size of 128, SGD 270 optimiser with a learning rate of 0.015, momentum of 0.9 and weight decay of 0.0001 and run it for 100 epochs. In this pre-training task we use 100k randomly selected images from Clothing1M training set as the pre-training images. All the other parameters were the same as described above for CIFAR, except for the batch size of semantic clustering task was 64 and the number of epochs E=80. During ScanMix training, we followed <ref type="bibr" target="#b6">[7]</ref>, WebVision. We use InceptionResNet-V2 as our backbone model, following <ref type="bibr" target="#b6">[7]</ref>. For 280 the self-supervised pre-training task we adopt the standard MoCo-v2 method for a 4-GPU training <ref type="bibr" target="#b8">[9]</ref> with a batch size of 128, SGD optimiser with a learning rate of 0.015, momentum of 0.9 and weight decay of 0.0001, and run it for 100 epochs with a WarmUp stage of 1 epoch. The feature representations learned from this process have 128 dimensions. All the other parameters were the same as described above for CIFAR, 285 except the batch size of semantic clustering task was 64, and number of epochs E = 100.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison with State-of-the-Art</head><p>We compare ScanMix with several existing methods using the datasets described in Sec. Experimental Setup. For CIFAR-10 and CIFAR-100 in <ref type="table" target="#tab_2">Table 1</ref>, we evaluate the 290 models using different levels of symmetric label noise, ranging from 20% to 90% and asymmetric noise rates of 40% and 49%. We report both the best test accuracy across all epochs and the averaged test accuracy over the last 10 epochs of training.</p><p>Results show that our method significantly outperforms the previous methods under severe label noise. Specifically, we observe an increase of roughly +13% for CIFAR-10 295 with 90% symmetric noise, +5% for CIFAR-10 with 49% asymmetric noise, +25% for CIFAR-100 with 90% symmetric noise and +5% for CIFAR-100 with 80% symmetric noise. These results show that our ScanMix does make the model more robust to noisy labels than previous methods, particularly for severe label noise. To demonstrate that more clearly, we computed mean and variance accuracy using bootstrapping, and applied 300 a T-test to compare ScanMix and DivideMix. For all cases that we claim to be better in on Cifar10), we obtained p-values &lt; 0.01. <ref type="table" target="#tab_3">Table 2</ref> shows the ability of our method to handle semantic noise, which can be regarded as a harder and more realistic type of label noise that depends not only on label <ref type="bibr">305</ref> transition, but also on the image features.</p><p>The current SOTA for this benchmark is RoG [50], and even though the noise rates are not particularly large, our ScanMix shows results that are better by a large margin varying from 12% to 22%. The results on Red Mini-ImageNet <ref type="bibr" target="#b16">[16]</ref> in <ref type="table" target="#tab_6">Table 3</ref> shows that ScanMix provides substantial gains form 4% to 7% over the SOTA for all noise 310 rates.</p><p>We also evaluate ScanMix on the noisy large-scale dataset WebVision. <ref type="table">Table 4</ref> shows </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>We show the results of the ablation study of ScanMix in <ref type="table" target="#tab_10">Table 6</ref>. Using classification 330 accuracy in the testing set of CIFAR-10 and CIFAR-100 under symmetric and asymmetric noises at several rates, we aim to show the influence of self-supervised training by itself or in combination with SSL. For self-supervised learning, we use the current SOTA method, SCAN <ref type="bibr" target="#b10">[10]</ref>, displayed in the first two rows, with the first row containing the published results, and the second, our replicated results using the authors' code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>335</head><p>The result is the same across different noise rates because it never uses the noisy labels for training. Using the pure SSL method, DivideMix <ref type="bibr" target="#b6">[7]</ref>, which is the current SOTA in noisy label learning, we see that it has much better results for low noise levels, but SCAN is better for severe label noise. When using SCAN for pre-training DivideMix, we note that results become quite good for all types and levels of noise. Neverthless, our 340 ScanMix improves the results of SCAN + DivideMix, showing the efficacy of ScanMix, which combines SSL with semantic clustering.</p><p>A common issue with learning with noisy labels is the tendency of models to overfit the noisy labels during training <ref type="bibr">[22,</ref><ref type="bibr">34]</ref>, causing a reduction of accuracy in the test set.</p><p>To show the robustness of ScanMix to this issue, we present in <ref type="figure">Fig. 3</ref> the prediction 345 accuracy on the test set as a function of the number of training epochs for ScanMix (blue) and DivideMix (black) for 90% asymmetric noise on CIFAR-100 (a), and 40% asymmetric noise on CIFAR-10 (b). Notice that in both cases, ScanMix is shown to be more robust to overfitting than DivideMix.</p><p>We also demonstrate that ScanMix is able to provide a reliable separation between 350 clean and noisy samples. <ref type="figure" target="#fig_9">Figure 4</ref> shows a comparison between the distributions of  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>In this work we presented ScanMix, a novel training strategy that produces superior robustness to severe label noise and competitive robustness to non-severe label noise 360 problems, compared with the SOTA. Results on CIFAR-10/-100, Red Mini-ImageNet,</p><p>Clothing1M and WebVision showed that our proposed ScanMix outperformed SOTA methods, with large improvements particularly in severe label noise problems. Our approach also produced superior results for semantic noise and real-world web label noise, which are regarded to be the most challenging noise types. These results show 365 evidence for our claims in Section 1, that SSL noisy label learning methods (e.g., DivideMix <ref type="bibr" target="#b6">[7]</ref>) depend on an effective way to classify clean and noisy samples, which works well for small noise rates, but not for severe noise rates. Semantic clustering methods (e.g., SCAN <ref type="bibr" target="#b10">[10]</ref>) ignore labels, enabling them to work well for severe noise rates, but poorly for low noise. Hence, our ScanMix explores the advantages of SSL and 370 semantic clustering to achieve SOTA results for severe label noise rates, while being competitive for non-severe label noise.</p><p>The increasing availability of large-scale datasets is associated with a decreasing availability of trustworthy annotations. This can introduce label noise into training sets, and reduce the generalisation ability of machine learning models. Our method can 375 mitigate this issue and enable the use of large-scale datasets by communities that do not have other ways to re-annotate such datasets, thus democratising machine learning.</p><p>A drawback of our approach is the longer training time, compared with the SOTA DivideMix <ref type="bibr" target="#b6">[7]</ref>, so we are currently working on an approach that mitigates this issue by having a joint self-supervised and semi-supervised training algorithm. Another point that can be improved in ScanMix is the semantic clustering algorithm, which can explore more robust methods, such as RBSMF <ref type="bibr" target="#b45">[45]</ref>, MPF <ref type="bibr" target="#b44">[44]</ref>, ClusterNet <ref type="bibr" target="#b46">[46]</ref>, and USADTM [47].</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>ScanMix explores semantic clustering (a) that clusters samples with similar appearances and classification results, and semi-supervised learning (SSL) (c) that trains the classifier by treating the samples classified to have noisy labels, as unlabelled samples. In the figure, circles represent true cat label, and squares, true dog class, where samples 3 and 6 are noisy, but the classifier produces the right classification (see yellow and pink bars). In frames (a),(c) the arrows denote how the training process moves samples in the feature space at each stage, with samples 3 and 6 showing white background in (b),(c) because they are classified as noisy in (b) and have their labels removed for SSL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>H?W being the i th image, and y i ? {0, 1} |Y| a one-hot vector of the noisy label, where 115 Y = {1, ..., |Y|} represents the set of labels, and c?Y y i (c) = 1. The latent true label of the i th training instance is denoted by? i ? Y, where c?Y? i (c) = 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>contains the noise types above in addition to the open-set noise, where the class c /</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>ScanMix has a pre-training stage consisting of a self-supervised training[11,<ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b10">10]</ref>,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 )</head><label>2</label><figDesc>is formulated with an EM algorithm that uses a latent random variable z ji ? {0, 1} which indicates if a sample x j belongs to the set of K nearest neighbours (KNN) of x i , estimated with the Euclidean 135 distance. The classifier trained by ScanMix is parameterised by ? = [?, ?] ? ?, and represented by</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>180 Algorithm 1</head><label>1</label><figDesc>ScanMix Require: D, number of epochs E, clean sample threshold ? f ? (x),{Nx i } |D| i=1 = PreTrain(D) Self-supervised pre-training p ? (y|x) = WarmUp(D,f ? (x)) Warm Up while e &lt; E do for i = {1, ..., |D|} do Estimate p(clean| i, ?), with i = ?y i log p ? (: |xi)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>190 Lemma 1 .</head><label>1</label><figDesc>Assuming that the maximisation of ELBO in Eq.6 estimates ? that makesE q(z) [log p ? (y, z|x)] ? E q(z) [log p ? old (y, z|x)], we have that (log p ? (y|x) ? log p ? old (y|x))is lower bounded by E q(z) [log p ? (y, z|x)] ? E q(z) [log p ? old (y, z|x)] ? 0, with q(z) = p ? old (z|y, x).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>275</head><label></label><figDesc>which relies on 64k randomly selected training images from the entire training for each epoch. As the training images change for every epoch, we adapted ScanMix to update the nearest neighbors before training each batch. Different from<ref type="bibr" target="#b6">[7]</ref>, we do not use the pre-trained weights from ImageNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>10 Figure 3 :</head><label>103</label><figDesc>symmetric on CIFAR-100 b) 40% asymmetric on CIFAR-Test accuracy (%) as a function of the number of training epochs for ScanMix (blue) and DivideMix (black) for 90% asymmetric noise on CIFAR-100 (a), and 40% asymmetric noise on CIFAR-10 (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 :</head><label>4</label><figDesc>Per-sample normalised loss distributions of the training set produced in the early stages of the training by our ScanMix (left) and DivideMix [7] (right) for CIFAR-10 (top) and CIFAR-100 (bottom) affected by 90% label noise, where green bars represent the clean samples and blue bars the noisy samples. losses produced by ScanMix and DivideMix at one of the early epochs of training for CIFAR-10 and CIFAR-100 affected by 90% label noise. This figure shows that semantic clustering combined with SSL in ScanMix enables a much clearer separation between the clean (green bars) and noisy (blue bars) samples, when compared with the 355 distribution produced by DivideMix. Such clearer separation will help the classification of clean samples in Eq.8, which in turn will improve the performance of the SSL in Eq.7.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>classify the noisy and clean samples by fitting a two-component Gaussian Mixture Model (GMM) on the normalised loss values for each training epoch. Next, they use MixMatch [42] to combine the labelled and unlabelled sets with MixUp [43].</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Test accuracy (%) for all competing methods on CIFAR-10 and CIFAR-100 under symmetric and asymmetric noises. Results from related approaches are as presented in<ref type="bibr" target="#b6">[7]</ref>. The results with (*) were produced by locally running the published code provided by the authors.Top methods within 1% are in bold.using the unlabelled images of D and defines the set of KNNs for each training sample{N xi } |D| i=1. Then, we warm-up the classifier by training it for a few epochs on the (noisy) training dataset using cross-entropy loss. Next, we run the EM optimisation using Eq.7</figDesc><table><row><cell>6 31.0</cell></row></table><note>1 94.6 93.2 76.0 93.4 83.7* 77.3 74.6 60.2 31.5 Last 95.7 94.4 92.9 75.4 92.1 76.3* 76.9 74.2 59.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Test accuracy (%) for Semantic Noise. Results from baseline methods are as presented in [50]. The results with (*) were produced by locally running the published code provided by the authors. Top methods within 1% are in bold.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Suppose that {? (e) } +? e=1 denotes the sequence of trained model parameters from the maximisation of ELBO in Eq.6 such that:</figDesc><table /><note>because of the assumption E q(z) [log p ? (y, z|x)] ? E q(z) [log p ? old (y, z|x)] [13].195 Lemma 2.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>, and semantic[50].For symmetric noise we used ? ? {0.2, 0.5, 0.8, 0.9}, where ? was defined in Section Method as the symmetric noise probability. The asymmetric noise was applied to the dataset, similarly to<ref type="bibr" target="#b6">[7]</ref>, which replaces the labels truck ? automobile, bird ? airplane, deer ? horse, and cat ? dog. For asymmetric noise, we use the noise Both images and labels are crawled from the web and the noisy220 labels are determined by matching images. The controlled setting provide different magnitudes of label corruption in real applications, varying from 0 to 80%. CNWL provides controlled web noise for Mini-ImageNet dataset, called red noise. The red Mini-ImageNet consists of 50k training images and 5000 test images, with 100 classes.</figDesc><table><row><cell>215</cell><cell>rates of 40% and 49%. For the semantic noise, we use the same setup from [50], which generates semantically noisy labels based on a trained VGG [59], DenseNet (DN) [60], and ResNet (RN) [61] on CIFAR-10 and CIFAR-100. The CNWL dataset [38] is a benchmark to study real-world web label noise in a 40% 60% 80% Cross-entropy [16] 47.36 42.70 37.30 29.76 Mixup [43] 49.10 46.40 40.58 33.58 DivideMix [7] 50.96 46.72 43.14 34.50 MentorMix [38] 51.02 47.14 43.80 33.46 FaMUS [16] 51.42 48.06 45.10 35.50 controlled setting. Method/ noise ratio 20% ScanMix (Ours) 59.06 54.54 52.36 40.00</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Test accuracy (%) for Red Mini-ImageNet. Results from baseline methods are as presented in [16]. Top methods within 1% are in bold.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Results on Clothing1M<ref type="bibr" target="#b17">[17]</ref> for ScanMix and SOTA approaches (SOTA results collected from<ref type="bibr" target="#b6">[7]</ref> or original papers). Top results within 1% are highlighted in bold.</figDesc><table><row><cell>dataset</cell><cell>CIFAR-10</cell><cell></cell><cell>CIFAR-100</cell></row><row><cell>Noise type</cell><cell>sym.</cell><cell>asym.</cell><cell>sym.</cell></row><row><cell>Method/ noise ratio</cell><cell cols="2">20% 50% 80% 90% 40% 49%</cell><cell>20% 50% 80% 90%</cell></row><row><cell>Self-superv. pre-train =(SCAN) [10]</cell><cell cols="2">81.6 81.6 81.6 81.6 81.6 81.6</cell><cell>44.0 44.0 44.0 44.0</cell></row><row><cell>Self-superv. pre-train* (SCAN) [10]</cell><cell cols="2">77.5 77.5 77.5 77.5 77.5 77.5</cell><cell>37.1 37.1 37.1 37.1</cell></row><row><cell>SSL (DivideMix) [7]</cell><cell cols="3">96.1 94.6 93.2 76.0 93.4 83.7* 77.3 74.6 60.2 31.5</cell></row><row><cell>Self-superv. pre-train + SSL (DivideMix)*</cell><cell cols="2">95.3 94.4 93.7 91.0 93.3 85.9</cell><cell>75.2 74.4 64.4 52.8</cell></row><row><cell>ScanMix (Ours)</cell><cell cols="2">96.0 94.5 93.5 91.0 93.7 88.6</cell><cell>77.0 75.7 66.0 58.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>In this ablation study we show the classification accuracy in the testing set of CIFAR-10 and CIFAR-100 under symmetric and asymmetric noises at several rates. First, we show the results of self-supervised pre-training using the current SOTA SCAN<ref type="bibr" target="#b10">[10]</ref> (first two rows, with the results with (*) produced by locally running the published code provided by the authors). Then we show the current SOTA SSL learning for noisy label DivideMix<ref type="bibr" target="#b6">[7]</ref>. Next, we show the results of DivideMix pre-trained with SCAN. The last row shows our ScanMix that combines SSL and semantic clustering. The top results within 1% are highlighted in bold.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 1 (</head><label>1</label><figDesc>symmetric at 80% and 90% on Cifar10,100 and asymmetric at 40% and 49%</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>the Top-1/-5 test accuracy using the WebVision and ILSVRC12 test sets. Results show that ScanMix is slightly better than the SOTA for both WebVision test sets and top-5 ILSVRC12 test set. This suggests that our approach is also effective in large-scale, 315 low noise rate problems. Results on Clothing1M in Tab. 5 show that ScanMix is on par with the current SOTA in the field, even though our method does use the whole training set for the pre-training stage (recall that we randomly selected 100k out of the 1M training images for pre-training) and differently from most of previous approaches, we do not rely on an ImageNet pre-trained model, as explained in Sec. 4.2. These two 320 issues should have had a significant negative impact on the performance of ScanMix, but these Clothing1M results indicate that ScanMix remained robust in this challenging scenario.For the running time complexity, ScanMix and DivideMix are similar asymptotically since both have linear complexity in terms of the training set size, as described in the</figDesc><table><row><cell>325</cell></row><row><cell>Section 3.2. In practice, ScanMix is two times slower. On CIFAR-10, DivideMix takes</cell></row><row><cell>13.93 GPU hours while ScanMix takes 27.94 hours (where pre-train takes 5.9 GPU</cell></row><row><cell>hours).</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We tested ScanMix without this approximation and preliminary results show that updating neighbors{Nx i } |D| i=1leads to similar results as the ones in this paper, suggesting the validity of our approximation.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by Australian Research Council through grant FT190100525.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey on deep learning in medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A A</forename><surname>Setio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ciompi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghafoorian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">I</forename><surname>S?nchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="60" to="88" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fr?nay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">390 IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="845" to="869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A semi-supervised two-stage approach to 395 learning from noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1215" to="1224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Towards robust learning with different label noise distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 25th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="7020" to="7027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-objective interpolation training for robustness to label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dividemix: Learning with noisy labels as semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<title level="m">Improved Baselines with Momentum</title>
		<imprint>
			<biblScope unit="page">410</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<idno type="arXiv">arXiv:2003.04297arXiv:2003.04297</idno>
		<title level="m">Contrastive Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Scan: Learning to classify images without labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="268" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno>PMLR, 2020</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Self: learning to filter noisy labels with self-ensembling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mummadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beggel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representa-420 tions (ICLR)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Maximum likelihood from incomplete data via the em algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Class noise mitigation through instance weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Rebbapragada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on machine learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">425</biblScope>
			<biblScope unit="page" from="708" to="715" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Faster meta update strategy for noise-robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="volume">430</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<title level="m">Webvision database: Visual 435 learning and understanding from web data</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Photometric transformer networks and label adjustment for breast density prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jaehwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Donggeun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hyo-Eun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Iterative cross learning on 440 noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-S</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mcmains</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="757" to="765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning with feature dependent label noise: a progressive approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Feature Representation (ICLR)</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Early-learning regularization prevents memorization of noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Niles-Weed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernandez-Granda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Imae for noise-robust learning: Mean absolute error does not treat examples equally and gradient magnitude&apos;s 450 variance matters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kodirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Robertson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.12141</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Symmetric cross entropy for robust learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="322" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pumpout: A meta 455 approach for robustly training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Uncertainty and Robustness in Deep Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning to rectify for robust learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">108467</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to reweight examples for robust 460 deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4334" to="4343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rboost: Label noise-robust boosting algorithm based on a nonconvex loss function and the numerically stable base learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2216" to="2228" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<title level="m">Mentornet: Learning data-driven 470 curriculum for very deep neural networks on corrupted labels</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
	<note>International Conference on Machine Learning</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Decoupling&quot; when to update&quot; from&quot; how to update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Malach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="960" to="970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Co-teaching: 475 Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8527" to="8537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">How does disagreement help generalization against label corruption?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7164" to="7173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Dimensionality-driven learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wijewickrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3355" to="3364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning with biased complementary labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="485" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Nlnl: Negative learning for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning to hallucinate clean rep-490 resentations for noisy-labeled visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Metacleaner</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7373" to="7382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Beyond synthetic noise: Deep learning on controlled noisy labels, International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Distilling effective supervision from severe label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">O</forename><surname>Arik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9294" to="9303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Evidentialmix: Learning with combined open-set and closed-set noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sachdeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Cordeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 500 the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>500 the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3607" to="3615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Cordeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sachdeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.04173</idno>
		<title level="m">Longremix: Robust learning with high confidence samples in a noisy label environment</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">510</biblScope>
		</imprint>
	</monogr>
	<note>mixup: Beyond empirical risk minimization</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Detecting coherent groups in crowd scenes by multiview clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="46" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Robust bi-stochastic graph regularized matrix fac-515 torization for data clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="390" to="403" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Semi-supervised clustering with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shukla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Cheema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Anand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE Sixth International Conference on Multimedia Big Data (BigMM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="152" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Unsupervised semantic aggregation and deformable template matching for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9972" to="9982" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Hallucinating a cleanly labeled augmented dataset from a noisy labeled dataset using gan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chiaroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-C</forename><surname>Rahal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hueber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Dufaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Interna-525 tional Conference on Image Processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3616" to="3620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1944" to="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Robust inference via generative classifiers for handling noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3763" to="3772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine 535 Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="312" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Addressing semantic drift in question generation for semisupervised question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.06356</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Probabilistic end-to-end noise correction for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern 540 Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern 540 Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7017" to="7025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning to learn from noisy labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5051" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Understanding and 545 improving early stopping for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning fast sample re-weighting without reward data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="725" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Tutorial on em algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5552" to="5560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<title level="m">Very deep convolutional networks for large-scale 555 image recognition, International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Densely connected convolutional networks</title>
		<imprint>
			<biblScope unit="page" from="4700" to="4708" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deep self-learning from noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5138" to="5147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
	<note>Imagenet: A large-scale 565 hierarchical image database</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Understanding and utilizing deep neural networks trained with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1062" to="1070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Cleannet: Transfer learning for scalable image classifier training with label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5447" to="5456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Ragav Sachdeva is a PhD student in the Visual Geometry Group at the University of Oxford, supervised by Prof. Andrew Zisserman. He obtained his undergraduate degree in computer science at the University of Adelaide</title>
		<imprint/>
	</monogr>
	<note>where he did his honours thesis with Prof</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Carneiro</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">In 2015, he received his Ph.D. in computer science from the Federal University of Pernambuco (UFPE). Filipe&apos;s mains contributions are in the area of computer vision, medical image analysis, and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filipe</forename><forename type="middle">R</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Cordeiro is a professor of the Department of Computing at Universidade Federal Rural de Pernambuco (UFRPE)</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Vasileios Belagiannis is a professor in the Faculty of Computer Science at Otto von Guericke University Magdeburg. His research deals with topics such as representation learning, uncertainty estimation, multi-modal learning, learning with different forms of supervision, learning algorithm for noisy labels, few-shot learning and meta-learning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">of the School of Computer Science at the University of Adelaide, and the senior researcher at the Australian Institute for Machine Learning. His research interests include robotic and active vision, visual tracking, SLAM, human motion capture and intelligent visual surveillance</title>
		<imprint/>
	</monogr>
	<note>Ian Reid is the Head</note>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Director of Medical Machine Learning at the Australian Institute of Machine Learning and an Australian Research Council Future Fellow. His main research interests are in computer vision, medical image analysis and machine learning. He is moving to the CVSSP at the University of Surrey</title>
		<imprint>
			<date type="published" when="2022-12" />
		</imprint>
		<respStmt>
			<orgName>School of Computer Science at the University of Adelaide</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
