<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DADA: Differentiable Automatic Data Augmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonggang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Wangxuan Institute of Computer Technology</orgName>
								<orgName type="institution" key="instit2">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Hu</surname></persName>
							<affiliation key="aff1">
								<address>
									<addrLine>Queens Road</addrLine>
									<settlement>Anyvision, Belfast</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Queens University of Belfast</orgName>
								<address>
									<settlement>Belfast</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongtao</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Wangxuan Institute of Computer Technology</orgName>
								<orgName type="institution" key="instit2">Peking University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">The University of Edinburgh</orgName>
								<address>
									<settlement>Edinburgh</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><forename type="middle">M</forename><surname>Robertson</surname></persName>
							<affiliation key="aff1">
								<address>
									<addrLine>Queens Road</addrLine>
									<settlement>Anyvision, Belfast</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Queens University of Belfast</orgName>
								<address>
									<settlement>Belfast</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">School of Informatics</orgName>
								<orgName type="institution">The University of Edinburgh</orgName>
								<address>
									<settlement>Edinburgh</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DADA: Differentiable Automatic Data Augmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>AutoML</term>
					<term>Data Augmentation</term>
					<term>Differentiable Optimization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data augmentation (DA) techniques aim to increase data variability, and thus train deep networks with better generalisation. The pioneering AutoAugment automated the search for optimal DA policies with reinforcement learning. However, AutoAugment is extremely computationally expensive, limiting its wide applicability. Followup works such as Population Based Augmentation (PBA) and Fast AutoAugment improved efficiency, but their optimization speed remains a bottleneck. In this paper, we propose Differentiable Automatic Data Augmentation (DADA) which dramatically reduces the cost. DADA relaxes the discrete DA policy selection to a differentiable optimization problem via Gumbel-Softmax. In addition, we introduce an unbiased gradient estimator, RELAX, leading to an efficient and effective one-pass optimization strategy to learn an efficient and accurate DA policy. We conduct extensive experiments on CIFAR-10, CIFAR-100, SVHN, and ImageNet datasets. Furthermore, we demonstrate the value of Auto DA in pre-training for downstream detection problems. Results show our DADA is at least one order of magnitude faster than the state-of-theart while achieving very comparable accuracy. The code is available at https://github.com/VDIGPKU/DADA.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Data augmentation (DA) techniques, such as geometric transformations (e.g., random horizontal flip, rotation, crop), color space augmentations (e.g., color jittering), are widely applied in training deep neural networks. DA serves as a regularizer to alleviate over-fitting by increasing the amount and diversity of the training data. Moreover, it is particularly important in scenarios where big training data is not available, e.g. medical image analysis.  <ref type="figure">Fig. 1</ref>: DADA achieves an order of magnitude reduction in computation cost while maintaining comparable test error rate to state of the art DA methods (AA <ref type="bibr" target="#b2">[3]</ref>, PBA <ref type="bibr" target="#b9">[10]</ref> and Fast AA <ref type="bibr" target="#b14">[15]</ref>) using WRN-28-10 backbone.</p><p>Data augmentation is very useful for training neural networks, however, it is nontrivial to automatically select the most effective DA policy (a set of augmentation operations) for one particular task and dataset. The pioneering work, AutoAugment (AA) <ref type="bibr" target="#b2">[3]</ref>, models the process of policy selection as an optimization problem: the objective is to maximize the accuracy on the validation set, the parameters optimized are i) the probabilities of applying different augmentation functions and ii) the magnitudes of chosen functions. Reinforcement learning is used to optimize this problem. AutoAugment achieved excellent performance on image classification, however, the optimization is very expensive: ?5000 GPU hours for one augmentation search. Despite the effectiveness of AutoAugment, the heavy computational cost limits its value to most users. To address the efficiency problem, Population Based Augmentation (PBA) <ref type="bibr" target="#b9">[10]</ref> and Fast AutoAugment (Fast AA) <ref type="bibr" target="#b14">[15]</ref> are proposed. PBA introduces an efficient population based optimization, which was originally used for hyper-parameter optimization. Fast AA models the data augmentation search as a density matching problem and solves it through bayesian optimization. Though PBA and Fast AA greatly improve search speed, augmentation policy learning remains rather slow, e.g. PBA still needs ?5 GPU hours for one search on the reduced CIFAR-10 dataset.</p><p>The inefficiency of the existing DA optimization strategies arises from the fact that the optimization (selecting discrete augmentation functions) is intrinsically non-differentiable, thus precluding joint optimization of network weights and DA parameters, and requiring resorting to multi-pass reinforcement learning, BayesOpt, and evolutionary strategies. Intuitively, optimization efficiency can be greatly improved if we can relax the optimization to a differentiable one and jointly optimize network weights and DA parameters in a single-pass way. Motivated by the differentiable neural architecture search <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26]</ref>, we propose a Differentiable Automatic Data Augmentation (DADA) to relax the optimization problem to be differentiable and then use gradient-based optimization to jointly train model weights and data augmentation parameters. In this way, we can achieve a very efficient and effective DA policy search. DADA follows AA <ref type="bibr" target="#b2">[3]</ref> in using a search space where a policy contains many sub-policies, each of which has two operations (each with probability and magnitude of applying the DA function). DADA first reformulates the discrete search space to a joint distribution that encodes sub-policies and operations. Specifically, we treat the sub-policy selection and augmentation application as sampling from a Categorical distribution and Bernoulli distribution, respectively. In this way, DA optimization becomes a Monte Carlo gradient estimate problem <ref type="bibr" target="#b20">[21]</ref>. However, Categorical and Bernoulli distributions are not differentiable. To achieve differentiable optimization, we relax the two non-differentiable distributions to be differentiable through Gumbel-Softmax gradient estimator <ref type="bibr" target="#b11">[12]</ref> (a.k.a. concrete distribution <ref type="bibr" target="#b19">[20]</ref>). Furthermore, DADA minimizes the loss on validation set rather than the accuracy (used by AutoAugment) to facilitate gradient computation.</p><p>To realise this differentiable optimization framework, we introduce 1) an efficient optimization strategy and 2) an accurate gradient estimator. For 1), a straightforward solution for sampling-based optimization is to iterate two sub-optimizations until convergence: i) optimizing DA policies ii) training neural networks. Clearly, this sequential optimization is very slow. Motivated by DARTS <ref type="bibr" target="#b18">[19]</ref>, we jointly optimize parameters of DA policies and networks through stochastic gradient descent. This one-pass strategy greatly reduces the computational cost. For 2), the classic gradient estimator is the Gumbel-Softmax estimator. In the field of network architecture search (NAS), SNAS <ref type="bibr" target="#b25">[26]</ref> and GDAS <ref type="bibr" target="#b4">[5]</ref> use this estimator and achieved good performance. However, the gradient estimated by Gumbel-Softmax estimator is biased. To overcome this, we propose to use the RELAX <ref type="bibr" target="#b6">[7]</ref> estimator, which can provide an unbiased gradient estimator unlike Gumbel-Softmax, and thus improved policy search.</p><p>We conduct extensive experiments using a variety of deep models and datasets, e.g. CIFAR-10, SVHN <ref type="bibr" target="#b21">[22]</ref>. As shown in <ref type="figure">Fig. 1</ref>, our method achieves comparable performance with the state-of-the-art, while requiring significantly less compute.</p><p>The contributions of this work are threefold:</p><p>1. We propose Differentiable Automatic Data Augmentation (DADA), which uses an efficient one-pass gradient-based optimization strategy and achieves at least one order of magnitude speedup over state-of-the-art alternatives. 2. DADA relaxes the DA parameter optimization to be differentiable via Gumbel-Softmax. To achieve accurate gradient estimation, we introduce an unbiased gradient estimator, RELAX <ref type="bibr" target="#b6">[7]</ref>, to our DADA framework. 3. We perform a thorough evaluation on CIFAR-10, CIFAR-100 <ref type="bibr" target="#b12">[13]</ref>, SVHN <ref type="bibr" target="#b21">[22]</ref> and ImageNet <ref type="bibr" target="#b23">[24]</ref>, as well as object detection benchmarks. We achieve at least an order of magnitude speedup over state-of-the-art while maintaining accuracy. Specifically, on ImageNet, we only use 1.3 GPU (Titan XP) hours for searching and achieve 22.5% top1-error rate with ResNet-50.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In the past few years, handcrafted data augmentation techniques are widely used in training deep Deep Neural Network (DNN) models for image recognition, object detection, etc. For example, rotation, translation, cropping, resizing, and flipping <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b24">25]</ref> are commonly used to augment training examples. Beyond these, there are other techniques manually designed with some domain knowledge, like Cutout <ref type="bibr" target="#b3">[4]</ref>, Mixup <ref type="bibr" target="#b29">[30]</ref>, and CutMix <ref type="bibr" target="#b27">[28]</ref>. Although these methods achieve promising improvements on the corresponding tasks, they need expert knowledge to design the operations and set the hyper-parameters for specific datasets. Recently, inspired by the neural architecture search (NAS) algorithms, some methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref> attempted to automate learning data augmentation policies. AutoAugment <ref type="bibr" target="#b2">[3]</ref> models the policy search problem as a sequence prediction problem, and uses an RNN controller to predict the policy. Reinforcement learning (RL) is exploited to optimize the controller parameters. Though promising results are achieved, AutoAugment is extremely costly (e.g., 15000 GPU hours on ImageNet) due to the low efficiency of RL and multi-pass training. PBA <ref type="bibr" target="#b9">[10]</ref> proposes to use population based training to achieve greater efficiency than AutoAugment, and evaluates on small datasets like CIFAR-10 and SVHN. OHL-Auto-Aug <ref type="bibr" target="#b15">[16]</ref> employs online hyper-parameter learning in searching for an auto-augmentation strategy, leading to a speedup over AutoAugment of 60? on CIFAR-10 and 24? on ImageNet. Fast AutoAugment (Fast AA) <ref type="bibr" target="#b14">[15]</ref> treats policy search as a density matching problem and applies Bayesian optimization to learn the policy, and achieves, e.g., 33? speedup over AutoAugment on Im-ageNet. Although Fast AA achieves encouraging results, its cost is still high on large datasets. E.g., 450 GPU (Tesla V100) hours on ImageNet.</p><p>Since our DADA is inspired by the differentiable neural architecture search <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26]</ref>, we briefly review these methods here. DARTS <ref type="bibr" target="#b18">[19]</ref> first constructs a super-network of all possible operations and controls the super-network with architecture parameters. It then models neural architecture search as a bi-level optimization problem and optimizes architecture parameters through stochastic gradient descent. In order to remove the bias of DARTS for operation selection, SNAS <ref type="bibr" target="#b25">[26]</ref> and GDAS <ref type="bibr" target="#b4">[5]</ref> add stochastic factors to the super-network and utilize the Gumbel-Softmax gradient estimator <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b19">20]</ref> to estimate the gradient. Our baseline method, which also uses the Gumbel-Softmax gradient estimator to optimize the data augmentation policy, is most motivated by these methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Differentiable Automatic Data Augmentation (DADA)</head><p>We first introduce the search space of DADA in Section 3.1. Then we model DA optimization as Monte Carlo sampling of DA policy in Section 3.2. After that, we introduce the Gumbel-Softmax <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b19">20]</ref> as a relaxation of the categorical distribution in Section 3.3. In Section 3.4, we introduce an unbiased gradient estimator with small variance, RELAX <ref type="bibr" target="#b6">[7]</ref>, to compute gradients in our DADA framework. Finally, we propose an efficient one-pass optimization strategy to jointly optimize the network weights and the DA parameters in Section 3.5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Search Space</head><p>Following Fast AutoAugment <ref type="bibr" target="#b14">[15]</ref>, a DA policy P contains several sub-policies</p><formula xml:id="formula_0">s i (1 ? i ? |P |). Each sub-policy s includes k image operations (e.g. flipping, ro- tation) {? s i (x; p s i , m s i )|1 ? i ? k} which are applied in sequence. Each operation O s</formula><p>i is applied to the image x with two continuous parameters: p s i (the probability of applying the operation) and m s i (the magnitude of the operation):</p><formula xml:id="formula_1">O s i (x; p s i , m s i ) = O s i (x; m s i ) : with probability p s i , x : with probability 1 ? p s i .<label>(1)</label></formula><p>Therefore the sub-policy s can be represented by a composition of operations:</p><formula xml:id="formula_2">s(x; p s , m s ) =? s k (x; p s k , m s k ) ?? s k?1 (x; p s k?1 , m s k?1 ) ? ? ? ? ?? s 1 (x; p s 1 , m s 1 ) =? s k (? s k?1 (...? s 1 (x; p s 1 , m s 1 ); p s k?1 , m s k?1 ); p s k , m s k ).<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Policy Sampling from a Joint Distribution</head><p>We model the sub-policy selection and operation applying as sampling from Categorical and Bernoulli distributions, respectively. Then the DA optimization is modelled as a Monte Carlo gradient estimate problem from two distributions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sub-Policy Sampling</head><formula xml:id="formula_3">s(x) = s?S c s s(x), c ? p(c|?), ? s = exp(? s ) s ?S exp(? s ) , for s = 1, . . . , N. (3)</formula><p>After ? optimized, we can select the sub-policies with the top probabilities as the final DA policy P . Therefore, to optimize the DA policy, our task becomes optimizing the parameters ? of the sub-policy sampling distribution.</p><p>Operation Sampling Given a particular sub-policy choice, the constituent operations are executed or not according to a Bernoulli distribution sample. We start from the simple example: a sub-policy s contains only one operation O s 1 . Then, the image operation O (we omit the superscript and subscript of O s 1 for simplicity) with application probability ? and magnitude m can be represented:</p><formula xml:id="formula_4">s(x) =?(x; m) = bO(x; m) + (1 ? b)x, b ? Bernoulli(?).<label>(4)</label></formula><p>To generalize Eq. (4) to a sub-policy with multiple operations, we formulate the composition of O i and O i?1 in Eq. (2) as below:</p><formula xml:id="formula_5">O i (x; ? i , m i ) ?? i?1 (x; ? i?1 , m i?1 ) = b i b i?1 O i (O i?1 (x; m i?1 ); m i ) + b i (1 ? b i?1 )O i (x; m i ) + (1 ? b i )b i?1 O i?1 (x; m i?1 ) + (1 ? b i )(1 ? b i?1 )x. (5) where b i?1 ? Bernoulli(? i?1 ), b i ? Bernoulli(? i ).</formula><p>Optimization Objective With the above formulations, the DA policy can be sampled from a joint distribution p(c, b|?, ?) = p(b|?, c)p(c|?) (we use p(c|?) to describe Eq. <ref type="formula">(3)</ref>). Therefore, our objective can be represented as:</p><formula xml:id="formula_6">E c,b?p(c,b|?,?) [Reward(c, b)] = E c,b?p(c,b|?,?) [L w (c, b)].<label>(6)</label></formula><p>where L w (c, b) is the validation-set loss achieved by the network (with weights w) which is trained using the DA policy {c, b} on training set. Unlike AutoAugment which uses validation accuracy as reward, we use the validation loss to facilitate gradient computation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Differentiable Relaxation with Gumbel-Softmax</head><p>To learn the data augmentation policy, we need to estimate the gradient of the objective w.r.t. the parameters {?, ?} of the categorical (sub-policy) and bernoulli (operation) distributions. In this section, we use Gumbel-Softmax reparameterization trick <ref type="bibr" target="#b11">[12]</ref> (a.k.a. concrete distribution <ref type="bibr" target="#b19">[20]</ref>) to reparameterize the parameters {?, ?} to be differentiable. Then we detail the estimation of the gradient of magnitudes m using the straight-through gradient estimator <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Differentiable Relaxation of Sub-Policy Selection</head><p>The Categorical distribution is not differentiable w.r.t. the parameter ?, therefore we use the Gumbel-Softmax reparameterization trick to achieve the differentiable relaxation. This reparameterization is also used in network architecture search, e.g SNAS <ref type="bibr" target="#b25">[26]</ref> and GDAS <ref type="bibr" target="#b4">[5]</ref>. With the Gumbel-Softmax reparameterization, Eq. (3) becomes:</p><formula xml:id="formula_7">s(x) = s?S c s s(x), c ? RelaxCategorical(?, ? ) = exp((? s + g s )/? ) s ?S exp((? s + g s )/? ) ,<label>(7)</label></formula><p>where g = ? log(? log(u)) with u ? Uniform(0, 1), and ? is the temperature of softmax function. In our implementation, the straight-through gradient estimator is applied: the backward pass uses differentiable variables as Eq. <ref type="formula" target="#formula_7">(7)</ref>, the forward pass uses discrete variables as shown:</p><formula xml:id="formula_8">s(x) = s?S h s s(x), where h = one hot(argmax s (? s + g s )).<label>(8)</label></formula><p>Differentiable Relaxation of Augmentation Operator Sampling Similar to the Categorical distribution, the Bernoulli distribution is not differentiable w.r.t. ?. We apply the same reparameterization trick to the Bernoulli distribution: Optimization of Augmentation Magnitudes Different from optimizing the discrete distribution parameters, we optimize augmentation magnitudes by approximating their gradient. Since some operations (e.g. flipping and rotation) in our search space are not differentiable w.r.t. the magnitude, we apply the straight-through gradient estimator <ref type="bibr" target="#b0">[1]</ref> to optimize the magnitude. For an imag? x = s(x) augmented by sub-policy s, we approximate the gradient of magnitude (of the sampled operations) w.r.t. each pixel of the augmented image:</p><formula xml:id="formula_9">RelaxBernoulli(?, ?) = ?((log ? 1 ? ? + log u 1 ? u )/?),</formula><formula xml:id="formula_10">?x i,j ?m = 1.<label>(10)</label></formula><p>Then the gradient of the magnitude w.r.t. our objective L can be calculated as:</p><formula xml:id="formula_11">?L ?m = i,j ?L ?x i,j ?x i,j ?m = i,j ?L ?x i,j .<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">RELAX Gradient Estimator</head><p>Although the above reparameterization trick make DA parameters differentiable, its gradient estimate is biased <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b19">20]</ref>. To address this problem, we propose to use RELAX <ref type="bibr" target="#b6">[7]</ref> estimator which provides unbiased gradient estimate. We first describe the RELAX estimator for gradient estimation w.r.t distribution parameters. Then, we introduce the use of RELAX estimator to relax the parameters of Categorical p(c|?) and Bernoulli p(b|?) distributions to be differentiable.</p><p>Gradient Estimation Here, we consider how to estimate the gradient of parameters of distribution p(q|?), which can represent either p(c|?) or p(b|?) in our algorithm. Unlike the Gumbel-Softmax estimator, the gradient of RELAX cannot simply be achieved by the backward of loss function. Furthermore, the RELAX estimator even does not require the loss function L to be differentiated w.r.t. the distribution parameters. It means we do not need to apply continuous relaxation the forward stage like Eq. (3) or Eq. (4). Instead, the RELAX estimator requires a differentiable neural network c ? which is a surrogate of loss function, where ? are the parameters of neural network c. To make c ? be differentiable w.r.t. the distribution parameters, we need the same Gumbel-Softmax reparameterized distribution p(z|?) for p(q|?), where ? is the distribution parameter and z is a sampled continuous variable. p(z|?) can be either the Gumbel-Softmax reparameterized distributions of p(c|?) or p(b|?). Then, in the forward stage, the DA policy can also be sampled from z ? p(z|?) but only forward the policy using deterministic mapping q = H(z) = b ? p(b|?) to guarantee the probability distribution curve is the same. Furthermore, since RELAX applies the control variate at the relaxed input z, we also need a relaxed input conditioned on the discrete variable q, denoted asz ? p(z|q, ?). Then the gradient estimated by RELAX can be expressed as:</p><formula xml:id="formula_12">? ? L = [L(q) ? c ? (z)]? ? log p(q|?) + ? ? c ? (z) ? ? ? c ? (z),<label>(12)</label></formula><p>q = H(z), z ? p(z|?),z ? p(z|q, ?).</p><p>To achieve a small variance estimator, the gradient of parameters ? can be computed as Eq. <ref type="formula" target="#formula_1">(13)</ref>, which can be jointly optimized with the parameters ?.</p><formula xml:id="formula_13">? ? (Variance(? ? L)) = ? ? (? ? L) 2 .<label>(13)</label></formula><p>Sub-Policy Sampling As shown in Eq. (3), the sub-policies can be sampled from the Categorical distribution. To apply the RELAX estimator, we first sample z from the relaxed Categorical distribution RelaxCategorical(?, ? ) from Eq. <ref type="formula" target="#formula_7">(7)</ref>, but we only forward the sub-policy with c = one hot(argmax(z)) in Eq. <ref type="bibr" target="#b7">(8)</ref>. We further samplez conditioned on variable c to control the variance:</p><formula xml:id="formula_14">z s =z s s ?Sz s , where? i = ? log(? log v i ) c i = 1 ? log ? log vi pi ? log v c c i = 0 , v ? Uniform(0, 1).<label>(14)</label></formula><p>Operation Sampling As shown in Eq. (4), the parameters b can be sampled from Bernoulli distribution. To adapt to the RELAX gradient estimator, we also utilize the Gumbel-Softmax reparameterization trick for p(z|?) like Eq. <ref type="formula">(9)</ref>, but only forward the operation with b = I(z &gt; 0.5), where I is the indicator function.</p><p>To control the variance, we samplez conditioned as the sampled parameters b:</p><formula xml:id="formula_15">z = ?((log ? 1 ? ? + log v 1 ? v )/? ), where v = v ? (1 ? p), b = 0 v ? p + (1 ? p), b = 1 , v ? Uniform(0, 1).<label>(15)</label></formula><p>As for the gradient of magnitudes, we approximate them following Eq. (10).</p><p>Since we need to estimate the gradient of the parameters of joint distribution p(c, b|?, ?), we feed c ? with the relaxed variables c and b in the same time for the surrogate of loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Bi-Level Optimization</head><p>We have discussed the differentiable optimization of the DA policy in Section 3.1-3.4. We now discuss the joint optimization of DA policy and neural network. Clearly, it is very slow to sequentially iterate 1) the optimization of DA policy, 2) neural network training and performance evaluation until converge. Ideally, we conduct 1) and 2) by training neural network once, i.e. one-pass optimization.</p><p>To achieve this, we propose the following bi-level optimization strategy. Let L train and L val denote the training and validation loss, respectively. The optimization objective is to find the optimal parameters d * = {? * , ? * , m * , ? * } which minimizes the validation loss L val (w * ). The weights w * are obtained by minimizing the expectation of training loss w * = argmin w Ed ?p(d|d) [L train (w,d)] (m and ? are just the original parameters without sampling). For simplicity, we drop the sampling notation of the training loss as E[L train (w, d)]. Therefore, our joint optimization objective can be represented as a bi-level problem:</p><formula xml:id="formula_16">min L val (w * (d)),<label>(16)</label></formula><formula xml:id="formula_17">s.t. w * (d) = argmin w E[L train (w, d)].</formula><p>Directly solving the above bi-level optimization problem would require repeatedly computing the model weights w * (d) as policy parameters d are changed. To avoid that, we optimize w and d alternately through gradient descent. At step k, give the current data augmentation parameters d k?1 , we obtain w k by gradient descent w.r.t. expectation of training loss E[L train (w k?1 , d k?1 )]. Then, we approximate the above bi-level objective through a single virtual gradient step:</p><formula xml:id="formula_18">L val (w k ? ?? w E[L train (w k , d k?1 )]).<label>(17)</label></formula><p>Then, the gradient of Eq. (17) w.r.t. d is (with the step index k removed for simplicity):</p><formula xml:id="formula_19">??? 2 d,w E[L train (w, d)]? w L val (w ),<label>(18)</label></formula><formula xml:id="formula_20">where w = w ? ?? w E[L train (w, d)].</formula><p>The gradient is expensive to compute, therefore we use the finite difference approximation. Let be a small scalar,</p><formula xml:id="formula_21">w + = w + ? w L val (w ) and w ? = w ? ? w L val (w ).</formula><p>Then the gradient can be computed as:</p><formula xml:id="formula_22">?? ? d E[L train (w + , d)] ? ? d E[L train (w ? , d)] 2 .<label>(19)</label></formula><p>As for the gradients</p><formula xml:id="formula_23">? d E[L train (w + , d)] and ? d E[L train (w ? , d)]</formula><p>, they can be estimated by the techniques mentioned in Section 3.3 and Section 3.4. Specifically, we compute those two gradient with the same sampling sub-policy to make the difference of the two gradients more reliable. For the hyper-parameters ? and , we follow the settings of another bi-level optimization DARTS <ref type="bibr" target="#b18">[19]</ref>, where ? = {learning rate of w} and = 0.01/ ? w L val (w ) 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We compare our method with the effective baseline data augmentation method, Cutout <ref type="bibr" target="#b3">[4]</ref>, and the augmentation policy learners: AutoAugment <ref type="bibr" target="#b2">[3]</ref> (AA), Population Based Augmentation <ref type="bibr" target="#b9">[10]</ref> (PBA), Fast AutoAugment <ref type="bibr" target="#b14">[15]</ref> (Fast AA), and OHL Auto-Aug <ref type="bibr" target="#b15">[16]</ref> (OHL AA) on the CIFAR-10 <ref type="bibr" target="#b12">[13]</ref>, CIFAR-100 <ref type="bibr" target="#b12">[13]</ref>, SVHN <ref type="bibr" target="#b21">[22]</ref> and ImageNet <ref type="bibr" target="#b23">[24]</ref> datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Settings</head><p>Search Space For the search space, we follow AA for a fair comparison. Specifically, our search space contains the same 15 data augmentation operations as PBA <ref type="bibr" target="#b9">[10]</ref>, which is also the same as AA and Fast AA except that the SamplePairing <ref type="bibr" target="#b10">[11]</ref> is removed. Following AA, our sub-policy consists of two DA operations (k = 2), and the policy consists of 25 sub-polices.</p><p>Policy Search Following <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15]</ref>, we search the DA policies on the reduced datasets and evaluate on the full datasets. Furthermore, we split half of the reduced datasets as training set, and the remaining half as validation set for the data augmentation search. In the search stage, we search the policy parameters for 20 epochs on the reduced datasets. We use the Adam optimizer for the policy parameters d = {?, ?, m, ?} optimization with learning rate ? d = 5 ? 10 ?3 , momentum ? = (0.5, 0.999) and weight decay 0. For the optimization of neural network parameters, we use momentum SGD as optimizer, with the same hyperparameters as evaluation stage except the batch size and the initial learning rate.</p><p>In the search stage, we only apply the data augmentation policy to training examples, and set the batch size to 128 for CIFAR-10 and 32 for other datasets. The initial learning rate is set according to the batch size by the linear rule. We set ? to 0.5 and use a two layer fully connected neural network with 100 hidden units for c ? . Parameters ? are initialized to 10 ?3 . Parameters ? and magnitudes m are all initialized to 0.5.  Policy Evaluation We use the official publicly available code of Fast AA to evaluate the searched DA policies for a fair comparison. Following Fast AA <ref type="bibr" target="#b14">[15]</ref> and AA <ref type="bibr" target="#b2">[3]</ref>, we use the same hyper-parameters for policy evaluation: weight decay, learning rate, batch size, training epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>CIFAR-10 and CIFAR-100 Both CIFAR-10 and CIFAR-100 have 50, 000 training examples. Following <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15]</ref>, we conduct DA optimization on the reduced CIFAR-10 dataset (4, 000 randomly selected examples) and evaluate the trained policies on the full CIFAR-10 test set. <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15]</ref> use the discovered policies from CIFAR-10 and evaluate these policies on CIFAR-100. Since our DADA is much more efficient than other methods, thus, we conduct both the search (using a reduced dataset of 4, 000 randomly selected examples) and evaluation on CIFAR-100. Following <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b14">15]</ref>, we search the DA policy using a Wide-ResNet-40-2 network <ref type="bibr" target="#b28">[29]</ref> and evaluate the searched policy using Wide-ResNet-40-2 <ref type="bibr" target="#b28">[29]</ref>, Wide-ResNet-28-10 <ref type="bibr" target="#b28">[29]</ref>, Shake-Shake <ref type="bibr" target="#b5">[6]</ref> and PyramidNet+ShakeDrop <ref type="bibr" target="#b26">[27]</ref>. From the results in <ref type="table" target="#tab_1">Table 1</ref> and 2, we can see that DADA requires significantly less computation than the competitors, while providing comparable error rate.  For example, we require only 0.1 GPU hours for policy search on reduced CIFAR-10, which is at least one order of magnitude faster than AA (50, 000?) and Fast AA (35?). Similar to CIFAR-10, we achieve very competitive performance on CIFAR-100 yet with much less searching cost. Despite the lower error rates of OHL AA, OHL AA is not directly comparable to other methods since it uses a larger and dynamic search space.  <ref type="bibr" target="#b5">[6]</ref>. Our results are shown in <ref type="table" target="#tab_3">Table 3</ref>. As shown in <ref type="table" target="#tab_3">Table 3</ref>, our DADA achieves similar error rate to PBA, slightly worse than AA and Fast AA. However, we only use 0.1 GPU hours in the search stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SVHN</head><p>ImageNet Finally, we evaluate our algorithm on the ImageNet dataset. We train the policy on the same ImageNet subset as Fast AA, which consists of 6, 000 examples from a randomly selected 120 classes. We use ResNet-50 <ref type="bibr" target="#b8">[9]</ref> for policy optimization and report the performance trained with the full ImageNet dataset. As shown in <ref type="table" target="#tab_1">Table 1</ref> and <ref type="table" target="#tab_4">Table 4</ref>, we achieve very competitive error rate against AA and Fast AA while requiring only 1.3 GPU hours in the search stage -compared to 15000 and 450 hours respectively for these alternatives.</p><p>Again, OHL AA <ref type="bibr" target="#b15">[16]</ref> uses a larger and dynamics search space, thus, it is not comparable to other methods. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">DADA for Object Detection</head><p>The use of ImageNet pre-training backbone networks is a common technique for object detection <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23]</ref>. To improve the performance of object detection, people usually focus on designing a better detection pipeline, while paying less attention to improving the ImageNet pre-training backbones. It is interesting to investigate whether the backbones trained using our DADA can improve detection performance. With our DADA algorithm, we have reduced the Top-1 error rate of ResNet-50 on ImageNet from 23.7% to 22.5%. In this section, we further conduct experiments on object detection dataset MS COCO <ref type="bibr" target="#b17">[18]</ref> with the better ResNet-50 model. We adopt three mainstream detectors RetinaNet <ref type="bibr" target="#b16">[17]</ref>, Faster R-CNN <ref type="bibr" target="#b22">[23]</ref> and Mask R-CNN <ref type="bibr" target="#b7">[8]</ref> in our experiments. For the same detector, we use the same setting as <ref type="bibr" target="#b1">[2]</ref> except that the ResNet-50 model is trained with or without DADA policy. From <ref type="table" target="#tab_6">Table 5</ref>, the performance of ResNet-50 trained with DADA policy is consistently better than the ResNet-50 trained without DADA policy. The results show that our learned DA policy also improves generalisation performance of downstream deep models that leverage the pre-trained feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Further Analysis</head><p>Comparison with the Gumbel-Softmax Estimator One technical contribution of this paper is the derivation of a RELAX estimator for DA policy search, which removes the bias of the conventional Gumbel-Softmax estimator. To evaluate the significance of this contribution, we conduct the search experiments for both estimators with the same hyper-parameters on the CIFAR-10 dataset. As we can see from <ref type="figure" target="#fig_3">Fig. 3a</ref>, the policy found using our RELAX estimator achieves better performance on CIFAR-10 compared with Gumbel-Softmax estimator.</p><p>Search on the Full Dataset We further evaluate the performance when we train the DA policy on the full dataset rather than on the reduced one, noting that this is feasible for the first time with DADA, due to its dramatically increased efficiency compared to alternatives. We conduct DA policy search on both the reduced and full CIFAR-10 dataset with Wide-ResNet-40-2. As we can   see from <ref type="table" target="#tab_8">Table 6</ref>, the policy searched on the full dataset works better than that on the reduced one evaluated on CIFAR-10. We finally bring together some of these results and compare the speed accuracy trade-off provided by DADA, Fast AA and AA in <ref type="figure" target="#fig_3">Fig. 3b</ref> for CIFAR-10 on WRN-40-2 architecture. Fast AA does not benefit from DA policy on the full CIFAR-10 dataset. However, DADA provides an excellent tradeoff, especially at low resource operating points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we proposed Differentiable Automatic Data Augmentation (DADA) for data augmentation policy learning. DADA relaxes the discrete policy selection process to be differentiable using Gumbel-Softmax. To achieve efficient and accurate optimization, we propose a one-pass optimization strategy. In our differentiable optimization framework, we introduce an unbiased gradient estimator RELAX to achieve an accurate gradient estimation. Experimental results show that DADA achieves comparable image classification accuracy to state-of-the-art with at least one order of magnitude less search cost. DADA's greater efficiency makes it the first practical Auto-DA tool of choice that practitioners can use to optimize DA pipelines for diverse applications on desktop-grade GPUs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>The framework of DADA. The sub-policies and operations are sampled from Categorical and Bernoulli distributions respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>u ? Uniform(0, 1). (9) Similar to Eq. (8), we only execute the operation if b &gt; 0.5 but backpropagate using the gradient estimated by Eq. (9).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Additional Analysis on DADA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Let O be the set of all image pre-processing operations in our search space. Then the candidate N sub-policies S are all the combinations of k operations in O. To determine which sub-policies should be selected, we sample the sub-policy from a Categorical distribution p(c|?) (where we can sample a one-hot random variable) with probabilities ?. Probabilities are computed as a softmax over parameters ? = ? 1:N defining preference for sub-policies:</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>GPU hours spent on DA policy search and corresponding test error (%). We use Wide-ResNet-28-10 model for CIFAR-10, CIFAR-100 and SVHN, and ResNet-50 for ImageNet. We use the Titan XP to estimate the search cost as PBA. AA and Fast AA reported the search cost on Tesla P100 and Tesla V100 GPU respectively.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">(a) GPU hours</cell><cell></cell><cell></cell><cell></cell><cell cols="4">(b) Test set error rate (%)</cell><cell></cell></row><row><cell>Dataset</cell><cell cols="5">AA [3] PBA [10] Fast AA [15] OHL AA [16] DADA</cell><cell cols="6">Dataset AA [3] PBA [10] Fast AA [15] OHL AA [16] DADA</cell></row><row><cell cols="2">CIFAR-10 5000</cell><cell>5</cell><cell>3.5</cell><cell>83.4  *</cell><cell>0.1</cell><cell cols="2">CIFAR-10 2.6</cell><cell>2.6</cell><cell>2.7</cell><cell>2.6</cell><cell>2.7</cell></row><row><cell>CIFAR-100</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.2</cell><cell cols="2">CIFAR-100 17.1</cell><cell>16.7</cell><cell>17.3</cell><cell>-</cell><cell>17.5</cell></row><row><cell>SVHN</cell><cell>1000</cell><cell>1</cell><cell>1.5</cell><cell>-</cell><cell>0.1</cell><cell>SVHN</cell><cell>1.1</cell><cell>1.2</cell><cell>1.1</cell><cell>-</cell><cell>1.2</cell></row><row><cell cols="2">ImageNet 15000</cell><cell>-</cell><cell>450</cell><cell>625  *</cell><cell>1.3</cell><cell cols="2">ImageNet 22.4</cell><cell>-</cell><cell>22.4</cell><cell>21.1</cell><cell>22.5</cell></row></table><note>* : estimated.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>CIFAR-10 and CIFAR-100 test error rates (%).</figDesc><table><row><cell>Dataset</cell><cell>Model</cell><cell cols="6">Baseline Cutout [4] AA [3] PBA [10] Fast AA [15] DADA</cell></row><row><cell cols="2">CIFAR-10 Wide-ResNet-40-2</cell><cell>5.3</cell><cell>4.1</cell><cell>3.7</cell><cell>-</cell><cell>3.6</cell><cell>3.6</cell></row><row><cell cols="2">CIFAR-10 Wide-ResNet-28-10</cell><cell>3.9</cell><cell>3.1</cell><cell>2.6</cell><cell>2.6</cell><cell>2.7</cell><cell>2.7</cell></row><row><cell cols="2">CIFAR-10 Shake-Shake(26 2x32d)</cell><cell>3.6</cell><cell>3.0</cell><cell>2.5</cell><cell>2.5</cell><cell>2.7</cell><cell>2.7</cell></row><row><cell cols="2">CIFAR-10 Shake-Shake(26 2x96d)</cell><cell>2.9</cell><cell>2.6</cell><cell>2.0</cell><cell>2.0</cell><cell>2.0</cell><cell>2.0</cell></row><row><cell cols="2">CIFAR-10 Shake-Shake(26 2x112d)</cell><cell>2.8</cell><cell>2.6</cell><cell>1.9</cell><cell>2.0</cell><cell>2.0</cell><cell>2.0</cell></row><row><cell cols="2">CIFAR-10 PyramidNet+ShakeDrop</cell><cell>2.7</cell><cell>2.3</cell><cell>1.5</cell><cell>1.5</cell><cell>1.8</cell><cell>1.7</cell></row><row><cell cols="2">CIFAR-100 Wide-ResNet-40-2</cell><cell>26.0</cell><cell>25.2</cell><cell>20.7</cell><cell>-</cell><cell>20.7</cell><cell>20.9</cell></row><row><cell cols="2">CIFAR-100 Wide-ResNet-28-10</cell><cell>18.8</cell><cell>18.4</cell><cell>17.1</cell><cell>16.7</cell><cell>17.3</cell><cell>17.5</cell></row><row><cell cols="2">CIFAR-100 Shake-Shake(26 2x96d)</cell><cell>17.1</cell><cell>16.0</cell><cell>14.3</cell><cell>15.3</cell><cell>14.9</cell><cell>15.3</cell></row><row><cell cols="3">CIFAR-100 PyramidNet+ShakeDrop 14.0</cell><cell>12.2</cell><cell>10.7</cell><cell>10.9</cell><cell>11.9</cell><cell>11.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>SVHN test error rates (%).</figDesc><table><row><cell>Model</cell><cell cols="6">Baseline Cutout [4] AA [3] PBA [10] Fast AA [15] DADA</cell></row><row><cell>Wide-ResNet-28-10</cell><cell>1.5</cell><cell>1.3</cell><cell>1.1</cell><cell>1.2</cell><cell>1.1</cell><cell>1.2</cell></row><row><cell>Shake-Shake(26 2x96d)</cell><cell>1.4</cell><cell>1.2</cell><cell>1.0</cell><cell>1.1</cell><cell>-</cell><cell>1.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="6">: Validation set Top-1 / Top-5 error rate (%) on ImageNet using ResNet-</cell></row><row><cell cols="6">50 and DA policy search time (h).  Baseline AA [3] Fast AA [15] OHL AA [16] DADA</cell></row><row><cell cols="4">Error Rate (%) 23.7 / 6.9 22.4 / 6.2 22.4 / 6.3</cell><cell cols="2">21.1 / 5.7 22.5 / 6.5</cell></row><row><cell>Search Time (h)</cell><cell>0</cell><cell>15000</cell><cell>450</cell><cell>625  *</cell><cell>1.3</cell></row></table><note>* : Estimated.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>To verify the generalization ability of our search algorithm for different datasets, we further conduct experiments with a larger dataset: SVHN. SVHN dataset has 73, 257 training examples ('core training set'), 531, 131 additional training examples, and 26, 032 testing examples. Following AA and Fast AA, we also search the DA policy with the reduced SVHN dataset, which has 1, 000 randomly selected training samples from the core training set. Following AA, PBA and Fast AA, we evaluate the learned DA policy performance with the full SVHN training data. Unlike AA, we use the Wide-ResNet-28-10<ref type="bibr" target="#b28">[29]</ref> architecture in the search stage and evaluate the policy on the Wide-ResNet-28-10<ref type="bibr" target="#b28">[29]</ref> and Shake-Shake(26 2x96d)  </figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Object detection bounding box (bb) and mask AP on COCO test-dev. +0.4 59.6 41.1 22.4 40.9 46.6 34.5 +0.3</figDesc><table><row><cell>Method</cell><cell>Model</cell><cell cols="3">AP bb AP bb 50 AP bb 75 AP bb S AP bb M AP bb L AP mask</cell></row><row><cell>RetinaNet</cell><cell cols="2">ResNet-50 (baseline) 35.9</cell><cell>55.8 38.4 19.9 38.8 45.0</cell><cell>-</cell></row><row><cell>RetinaNet</cell><cell cols="3">ResNet-50 (DADA) 36.6 +0.7 56.8 39.2 20.2 39.7 46.0</cell><cell>-</cell></row><row><cell cols="3">Faster R-CNN ResNet-50 (baseline) 36.6</cell><cell>58.8 39.6 21.6 39.8 45.0</cell><cell>-</cell></row><row><cell cols="4">Faster R-CNN ResNet-50 (DADA) 37.2 +0.6 59.1 40.2 22.2 40.2 45.7</cell><cell>-</cell></row><row><cell cols="3">Mask R-CNN ResNet-50 (baseline) 37.4</cell><cell>59.3 40.7 22.0 40.6 46.3</cell><cell>34.2</cell></row><row><cell cols="3">Mask R-CNN ResNet-50 (DADA) 37.8</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>The test error rate (%) with DA policy learned on different training set.</figDesc><table><row><cell>Dataset Model</cell><cell cols="2">Reduced CIFAR-10 Full CIFAR-10</cell></row><row><cell>CIFAR-10 Wide-ResNet-40-2</cell><cell>3.61</cell><cell>3.53</cell></row><row><cell>CIFAR-10 Wide-ResNet-28-10</cell><cell>2.73</cell><cell>2.64</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>This work is supported by National Natural Science Foundation of China under Grant 61673029.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Estimating or propagating gradients through stochastic neurons for conditional computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>L?onard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
		<idno>abs/1308.3432</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Mmdetection: Open mmlab detection toolbox and benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<idno>abs/1906.07155</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno>abs/1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Searching for a robust neural architecture in four gpu hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Shake-shake regularization of 3-branch residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gastaldi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Backpropagation through the void: Optimizing control variates for black-box gradient estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mask R-CNN</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Population based augmentation: Efficient learning of augmentation policy schedules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Data augmentation by pairing samples for images classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Inoue</surname></persName>
		</author>
		<idno>abs/1801.02929</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Categorical reparameterization with gumbel-softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Learning multiple layers of features from tiny images</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Fast autoaugment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Online hyper-parameter learning for auto-augmentation strategy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<title level="m">Microsoft COCO: common objects in context</title>
		<imprint>
			<publisher>ECCV</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">DARTS: differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The concrete distribution: A continuous relaxation of discrete random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Monte carlo gradient estimation in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Figurnov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mnih</surname></persName>
		</author>
		<idno>abs/1906.10652</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<title level="m">Reading digits in natural images with unsupervised feature learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Faster R-CNN: towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">SNAS: stochastic neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Shakedrop regularization for deep residual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iwamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Akiba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="186126" to="186136" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>BMVC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ciss?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
