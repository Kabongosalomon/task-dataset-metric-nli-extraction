<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Iterative Surface Normal Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Eric</forename><surname>Lenssen</surname></persName>
							<email>janeric.lenssen@udo.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">TU Dortmund University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Osendorfer</surname></persName>
							<email>christian@nnaisense.com</email>
							<affiliation key="aff0">
								<orgName type="institution">TU Dortmund University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
							<email>jonathan@nnaisense.com</email>
							<affiliation key="aff0">
								<orgName type="institution">TU Dortmund University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Iterative Surface Normal Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1 NNAISENSE</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents an end-to-end differentiable algorithm for robust and detail-preserving surface normal estimation on unstructured point-clouds. We utilize graph neural networks to iteratively parameterize an adaptive anisotropic kernel that produces point weights for weighted least-squares plane fitting in local neighborhoods. The approach retains the interpretability and efficiency of traditional sequential plane fitting while benefiting from adaptation to data set statistics through deep learning. This results in a state-of-the-art surface normal estimator that is robust to noise, outliers and point density variation, preserves sharp features through anisotropic kernels and equivariance through a local quaternion-based spatial transformer. Contrary to previous deep learning methods, the proposed approach does not require any hand-crafted features or preprocessing. It improves on the state-of-the-art results while being more than two orders of magnitude faster and more parameter efficient.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Normal vectors are local surface descriptors that are used as an input for several computer vision tasks ranging from surface reconstruction <ref type="bibr" target="#b26">[27]</ref> to registration <ref type="bibr" target="#b38">[39]</ref> and segmentation <ref type="bibr" target="#b16">[17]</ref>. For this reason, the task of surface normal estimation has been an important and well studied research topic for a long time, with several methods dating back up to 30 years <ref type="bibr" target="#b22">[23]</ref>. Progress in the field, however, has been plateauing only until recently when a number of works has shown that improvements can be achieved with the use of data-driven deep learning techniques <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b18">19]</ref>, as also shown in related fields like point cloud denoising <ref type="bibr" target="#b41">[42]</ref> or finding correspondences on meshes and point clouds <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b34">35]</ref>. Deep learning methods are known to often achieve better results compared to data-independent methods. However, they have downsides in terms of robustness * Work performed during an internship at NNAISENSE. to small input changes, adversarial attacks, interpretability, and sometimes also computational efficiency. Also, they do not make use of often well-known instrinsic problem structure, which leads to the necessity of having a large amount of training data and model parameters to learn that structure on their own. It is well-known that surface normal estimation can be formulated as a least-squares optimization problem. A way to utilize this problem-specific knowledge with deep learning is to take an iteratively reweighting least squares (IRLS) scheme <ref type="bibr" target="#b21">[22]</ref> for robust model fitting and modify it using deep data-dependent weighting, as it has been done recently (with or without iterations) for other tasks <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46]</ref>.</p><p>It is a promising candidate to combine robustness, interpretability and efficiency with the data prior of deep neural networks (DNNs). From a deep learning perspective, the approach imposes a strong bias on the architecture, heavily constraining the space of solutions to those which are better suited for the given problem.</p><p>Contribution In this work, we present such a trainable reweighting procedure for input graphs with a large number of weighted least square problems and use it to design a fast and accurate algorithm for surface normal estimation on unstructured point clouds (c.f. <ref type="figure">Figure 1)</ref>. The method consists of a light-weight graph neural network (GNN), which parameterizes a local quaternion transformer and a deep kernel function to iteratively re-weight graph edges in a largescale point neighborhood graph. We show that the resulting algorithm</p><p>? reaches state-of-the-art performance in surface normal estimation on unstructured point clouds,</p><p>? is more than two orders of magnitude faster and more parameter efficient than related deep learning approaches, and</p><p>? is robust to noise and point density variation, while being equivariant and able to preserve sharp features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Traditional methods for surface normal estimation make use of plane fitting approaches like unweighted principal component analysis (PCA) <ref type="bibr" target="#b22">[23]</ref> and singular value decomposition (SVD) (c.f. <ref type="bibr" target="#b27">[28]</ref> for an overview). The performance of these approaches usually hinges upon the often cumbersome selection of data-specific hyper-parameters, such as point neighborhood sizes, and it is sensitive to noise, outliers and density variations. Because of this, several heuristics have been proposed to ease such selection, e.g. those for finding a neighborhood size for plane fitting <ref type="bibr" target="#b33">[34]</ref>. Another limitation of plane fitting methods is that they tend to smoothen sharp details, in fact they can be seen as isotropic low-pass filters. In order to preserve sharp features methods that extract normal vectors from estimated Voronoi cells have been proposed <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">33]</ref> and combined with PCA <ref type="bibr" target="#b0">[1]</ref>. Alternative approaches include edgeaware sampling <ref type="bibr" target="#b23">[24]</ref> or normal vector estimation in Hough space <ref type="bibr" target="#b5">[6]</ref>. In addition, several methods arise from more complex surface reconstruction techniques, e.g. moving least squares (MLS) <ref type="bibr" target="#b29">[30]</ref>, spherical fitting <ref type="bibr" target="#b17">[18]</ref>, jet fitting <ref type="bibr" target="#b8">[9]</ref> and multi-scale kernel methods <ref type="bibr" target="#b2">[3]</ref>.</p><p>Deep learning methods. Deep learning based approaches also found their way into surface normal estimation with the recent success of deep learning in a wide range of domains. These approaches can be divided into two groups, depending on the actual type of input data they use. The first group aims at normal estimation from single images <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b44">45]</ref> and has received a lot of interest over the last few years due to the well understood properties of CNNs for grid-structured data.</p><p>The second line of research directly uses unstructured point clouds and emerged only very recently, partially due to the advent of graph neural networks and geometric deep learning <ref type="bibr" target="#b7">[8]</ref>. Boulch et al. <ref type="bibr" target="#b6">[7]</ref> proposed to use a CNN on Hough transformed point clouds in order to find surface planes of the point cloud in Hough space. Based on the recently introduced point processing network, PointNet <ref type="bibr" target="#b39">[40]</ref>, Guerrero et al. <ref type="bibr" target="#b18">[19]</ref> proposed a deep multi-scale architecture for surface normal estimation. Later, Ben-Shabat et al. <ref type="bibr" target="#b4">[5]</ref> improved on those results using 3D point cloud fisher vectors as input features and a three-dimensional CNN architecture consisting of multiple expert networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem and background</head><p>Let S be a manifold in R 3 , P = {p 0 , ..., p m } a finite set of sampled and possibly distorted points from that manifold andN = {n 0 , ...,n m } the tangent plane normal vectors at sample points p i . Surface normal estimation for the point cloud P can be described as the problem of estimating a set of normal vectors N = {n 0 , ..., n m } given P, whose direction match those of the actual surface normalsn i as close as possible. We consider the problem of unoriented normal estimation, determining the normal vectors up to a sign flip. Estimating the correct sign can be done in a post-processing step, depending on the task at hand, and is explicitly tackled by several works <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b46">47]</ref>.</p><p>A standard approach to determine unoriented surface normals is fitting planes to the local neighborhood of every point p i <ref type="bibr" target="#b29">[30]</ref>. Given a radius r or a neighborhood size k, we model the input as a nearest neighbor graph G = (P, E), where we have a directed edge (i, j) ? E if and only if ||p j ? p j || 2 &lt; r or if p j is one of the k nearest neighbors of p i , respectively. Let N (i) denote the local neighborhood of p i , with k i ? |N (i)|, containing all p j with (i, j) ? E. Furthermore, let P(i) ? R ki?3 be the matrix of centered coordinates of the points from this neighborhood, that is</p><formula xml:id="formula_0">P(i) j = p j ? 1 k i m?N (i) p m , p j ? N (i). (1)</formula><p>Fitting a plane to this neighborhood is then described as finding the least squares solution of a homogeneous system of linear equations: n * i = arg min n:|n|=1 ||P(i)n|| 2 2 = arg min n:|n|=1 j?N (i)</p><formula xml:id="formula_1">||P(i) j ? n|| 2<label>(2)</label></formula><p>The simple plane fitting of Eq. 2 is not robust and does not result in high-quality normal vectors: It produces accurate results only if there are no outliers in the data, which is never the case in practice. Additionally, this approach eliminates sharp details because it acts as a low-pass filter on the point cloud. Even when an isotropic radial kernel function ?(||P(i)||) is used to weight points according to their distance to the local mean, fine details cannot be preserved. Both problems can be resolved through integrating weighting functions into Eq. 2. Sharp features can be preserved with an anisotropic kernel that infers weights of point pairs based on their relative positions, i.e.:</p><formula xml:id="formula_2">n * i = arg min n:|n|=1 j?N (i) ?(p j ? p i ) ? ||P(i) j ? n|| 2<label>(3)</label></formula><p>where ?(?) is an anisotropic kernel, considering the full Cartesian relationship between neighboring points, instead of only their distance. However, an anisotrop kernel is no longer rotation invariant, so that equivariance of output normals needs to be ensured additionally. Robustness to outliers can be achieved by another kernel that weights points according to an inlier score s i,j . More specifically, Eq. 2 is changed to</p><formula xml:id="formula_3">n * i = arg min n:|n|=1 j?N (i) s i,j ? ||P(i) j ? n|| 2 ,<label>(4)</label></formula><p>where s i,j weights outliers with a low and inliers with a high score. However, in order to infer information about the outlier status of points an initial model estimation is necessary. A standard solution to this circular dependency is to formulate the problem as a sequence of weighted leastsquares problems <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b42">43]</ref>. Given the residuals r l of the least squares solution from iteration l, the solution for iteration l + 1 is computed as</p><formula xml:id="formula_4">n l+1 i = arg min n:|n|=1 j?N (i) s(r l i,j ) ? ||P(i) j ? n|| 2 .<label>(5)</label></formula><p>That is, the inlier score and the estimated model are refined in an alternating fashion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Deep iterative surface normal estimation</head><p>In this section we present our method, which combines the described properties of robustness, anisotropy and equivariance with the deep learning property of adaptation to large data set statistics. In contrast to existing deep learning methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b18">19]</ref>, we do not directly regress normal vectors from point features but weights for a least-squares optimization step, utilizing the problem specific knowledge outlined above.</p><p>The core of the algorithm is a trainable kernel function ? : R 3 ? R d ? R, which computes weights as </p><formula xml:id="formula_5">w i,j = ?(R i (p j ? p i ), ? i ),<label>(6)</label></formula><formula xml:id="formula_6">N: Normal vector estimations ----------------------- (P, E) ? Neighborhood graph from P and k / r C ? CovMatrices(P, E) U, ? ? ParallelEig(C) N 0 ? Extract Solutions from U for l ? {1, ..., L} do (?, Q) ? GNN(P, E, N l?1 ) R ? QuatsToMats(Q) W ? ApplyKernel ?(R, P, ?, E) C ? WeightedCovMatrices(P, W, E) U, ? ? ParallelEig(C) N l ? Extract Solutions from U end for return N L</formula><p>where ? are kernel parameters and R is a rotation matrix. The kernel is shared by all local neighborhoods of the point graph while ? and R are individual for each node. Because there is no apriori information about the structure of the input data, a reasonable approach is to model ? as an MLP and to find kernel parameters through supervised learning from data. To this end, parameters ? and poses R for each neighborhood are jointly regressed by a graph neural network on the point neighborhood graph. Then, the kernel function ? regresses anisotropic, equivariant weights w i,j for each edge in the graph, which are used to find the normal vectors using traditional weighted least-squares optimization</p><formula xml:id="formula_7">n i = arg min n:|n|=1 j?N (i) softmax j?N (i) (w i,j )||P(i) j ? n|| 2 ,<label>(7)</label></formula><p>in parallel for all i ? P. Similar to iterative re-weighting least squares (c.f. Eq. 5), we apply the method in an iterative fashion to achieve robustness and provide the residuals of the previous solution as input to the graph neural network.</p><p>The core algorithm is formulated as pseudo code in Algorithm 1. The initial weighting of the points in a neighborhood is chosen to be uniform, which results in unweighted least-squares plane fitting in the initial iteration. In the following, we present the graph neural network, the local quaternion rotation and our differentiable least square solver in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">GNN for parameterization and rotation</head><p>For regressing parameters ? and rotations R for the whole point cloud, graph neural networks <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">20]</ref> are a natural fit because the network must be invariant to the ordering of the points in a neighborhood and it must be able to allow weight sharing over neighborhoods with varying cardinality.</p><p>Our graph neural network architecture consists of a neighborhood aggregation procedure, which is applied three consecutive times. Given MLPs h and ?, the neighborhood aggregation scheme, similar to that of PointNet <ref type="bibr" target="#b39">[40]</ref> and to general message passing graph neural network frameworks <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b35">36]</ref>, is given by message function</p><formula xml:id="formula_8">f e (i, j) = h f (i) | d i,j | prf (i, j) ,<label>(8)</label></formula><p>and node update function</p><formula xml:id="formula_9">f (i) = ? 1 |N (i)| j?N (i) f e (i, j) ,<label>(9)</label></formula><p>with | denoting feature concatenation. Using this scheme, we alternate between computing new edge features f e (i, j) and node features f (i). In addition to the Cartesian relation vector d i,j = (p j ? p i ), pair-wise residual features, a modified version of Point Pair Features (PPF) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>, are provided as input:</p><formula xml:id="formula_10">prf (i, j) = (|n i ? d i,j |, |n j ? d i,j |, |n i ? n j |, ||d i,j || 2 2</formula><p>). (10) They are computed directly from the last set of least-squares solutions and contain the residuals as point-plane distances</p><formula xml:id="formula_11">|n i ? d i,j |.</formula><p>After applying the message passing scheme, the output node feature matrix F ? R N ?(d+4) is interpreted as a tuple (? ? R N ?d , Q ? R N ?4 ), containing kernel and rotation parameters for all nodes. We use the row-normalized Q as unit quaternions to efficiently parameterize the rotation group SO(3). We found that using a rotation matrix instead of an arbitrary 3 ? 3 matrix (as in the Spatial Transformer Network <ref type="bibr" target="#b25">[26]</ref>) heavily improves training stability, as also observed by Guerrero et al. <ref type="bibr" target="#b18">[19]</ref>. By applying a custom, differentiable map from quaternion space to the space of rotation matrices we efficiently compute the local rotation matrices R for all nodes in parallel.</p><p>All in all, the graph neural network is permutation invariant, can be efficiently applied in parallel on varying neighborhood sizes, and is a local operator. Locality is an advantage which allows the algorithm to be applied on partial point clouds and scans, without relying on global features or semantics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Parallel differentiable least-squares</head><p>In every iteration of the presented algorithm, the plane fitting problem of Eq. 7 needs to be solved. A standard approach is to utilize the Singular Value Decomposition of the weighted matrix diag( w l i )P(i): Let U?V T be its decomposition, then the column vector of V corresponding to the smallest singular value is the optimal solution for the given least squares problem <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b42">43]</ref>. However, n SVDs (for potentially varying matrix sizes) need to be solved in our scenario, one for every neighborhood, which makes this approach prohibitive. A much more efficient approach in this case is to consider the eigendecomposition of the weighted 3 ? 3 covariance matrix C(i) = P(i) diag(w l i )P(i) which has the columns of V as its eigenvectors <ref type="bibr" target="#b20">[21]</ref>. The solution for Eq. 7 is then the eigenvector associated with the smallest eigenvalue. The computational complexity for the eigendecomposition of this 3 ? 3 matrix is O(1) and hence for one overall iteration O(n).</p><p>Our algorithm is trained end-to-end by minimizing the distance between ground truth normals and the least squares solution, requiring backpropagation through the eigendecomposition. We follow the work of Giles <ref type="bibr" target="#b15">[16]</ref>: Given partial derivatives ?L/?U and ?L/?? for eigenvectors and eigenvalues, respectively, we compute the partial derivatives for a real symmetric 3 ? 3 covariance matrix C as</p><formula xml:id="formula_12">?L ?C = U ( ?L ?? ) diag + F ? U ?L ?U U ,<label>(11)</label></formula><p>where</p><formula xml:id="formula_13">F i,j = (? j ? ? i ) ?1 contains inverse eigenvalue dif- ferences.</formula><p>We implemented forward and backward steps for eigendecomposition of a large number of symmetric 3 ? 3 matrices, where we parallelize over graph nodes, leading to an O(1) implementation (using O(n) processors) of parallel least squares solvers.</p><p>Handling numerical instability. Backpropagation through the eigendecomposition can lead to numerical instabilities due to at least two reasons: 1) Low-rank input matrices with two or more zero eigenvalues. 2) Exploding gradients when two eigenvalues are very close to each other and values of F go to infinity. We apply two tricks to avoid these problems. First, a small amount of noise is added to the diagonal elements of all covariance matrices, making them full-rank. Second, gradients are clipped after the backward step on very large values, to tackle the cases of nearly equal eigenvalues that lead to exploding gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Training</head><p>Training is performed by minimizing the Euclidean distance between estimated normals N and ground truth nor-malsN, averaged over all normal vectors in the training set:</p><formula xml:id="formula_14">L(N, N) = 1 n n i=1 min(||n i ? n i || 2 , ||n i + n i || 2 ),<label>(12)</label></formula><p>where the minimum of the distances to the flipped or nonflipped ground truth vectors is used. While we also experi-  <ref type="table">Table 1</ref>: Results for unoriented normal estimation. Shown are normal estimation errors in angle RMSE. For PCA and Jet, optimal neighborhood size for average error is chosen. For our approach, we display results for a balanced neighborhood size k = 64, which improves on the state of the art for all noise levels. Results for different k are shown in <ref type="table" target="#tab_3">Table 2</ref>.</p><p>mented with different angular losses, we found that the Euclidean distance loss still provides the best result and the most stable training. A loss is computed after each least squares step and the network is trained iteratively by performing a gradient descent step after each iteration of the algorithm. This fights vanishing gradients that occur due to the normalization of vectors in quaternion and eigenvector computations. The weights of our network are shared over iterations, allowing generalization to further iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>Experiments were conducted to compare the proposed Differentiable Iterative Surface Normal Estimation with state-of-the-art methods both quantitatively, measuring normal estimation accuracy, and qualitatively, on a Poisson reconstruction and on a transfer learning task. Section 5.1 introduces the dataset used to train our model whereas Section 5.2 details the architecture and the protocol followed in our experiments. Then, qualitative (Section 5.3) and quantitative (Section G) results are presented and an analysis of complexity and execution time (Section 5.4) is given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">PCPNet dataset</head><p>Our method is trained and validated quantitatively on the PCPNet dataset as provided by Guerrero et al. <ref type="bibr" target="#b18">[19]</ref>. It consists of a mixture of high-resolution scans, point clouds sampled from handmade mesh surfaces and differentiable surfaces. Each point cloud consists of 100k points. We reproduce the experimental setup of <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b18">19]</ref>, training on the provided split containing 32 point clouds under different levels of noise. The test set consists of six categories, containing four sets with different levels of noise (no noise, ? = 0.00125, ? = 0.0065 and ? = 0.012) and two sets with different sampling density (striped pattern and gradient pattern). We evaluate unoriented normal estimation, same as the related approaches. The Root Mean Squared Error (RMSE) on the provided 5k points subset is used as performance metric following the protocol of related work, where the RMSE is first computed for each test point cloud before the results are averaged over all point clouds in one category. Model selection is performed using the provided validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experimental setup and architecture</head><p>The presented graph neural network was implemented using the Pytorch Geometric library <ref type="bibr" target="#b12">[13]</ref>. The neural networks h, ? and ? each consist of two linear layers, with ReLU non-linearity. A detailed description of the architecture is presented in the supplemental materials. During training, output weights from the kernel are randomly set to zero with probability of 0.25.</p><p>It should be noted that despite inheriting the neighborhood size parameter from traditional PCA, it is possible for a network trained on a specific k to be applied for other k as well. This is because all networks can be shared across an arbitrary number of points and the softmax function normalizes weights for neighborhoods of varying sizes. We observed that generalization across different k only leads to a very small increase in average error. However, to fairly evaluate our method for different k, a network is trained for each k ? {32, 48, 64, 96, 128}. Trained consists of 300 epochs using the RMSProp optimization method. All reported test results are given after 4 re-weighting iterations of our algorithm. Iterating longer does not show significant improvements. Quantitative results over iterations, results for extrapolation over iterations and generalization between different k are presented in the supplemental materials. For further realization details, we refer to our implementation, which is available online 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Quantitative Evaluation</head><p>RMSE results for the PCPNet test set of our approach (with k = 64) and related works are shown in <ref type="table">Table 1</ref>. We improve on the state of the art on all noise levels and varying densities. While the improvement is only small, it should be noted that we reach it while being orders of    For error threshholds on the x-axis, the y-axis shows the percentage of normals which have an error lower than that threshhold. Our method and PCA use neighborhood size k = 64. For low noise settings and varying density, our method succeeds in recovering sharp features, as shown by the higher accuracies for low angle threshholds.</p><p>magnitude faster and more parameter efficient (c.f. Section 5.4, which is of importance for many applications in resource constraint environments. For the non deep learning approaches, PCA and Jet, results for medium neighborhood sizes are displayed. In addition, results for different k are provided in <ref type="table" target="#tab_3">Table 2</ref> and compared to errors obtained by PCA with the same respective neighborhood size. Our method performs stronger than the PCA baseline in all scenarios. As expected, varying k leads to a behavior similar to that of PCA, with large k's performing better on more noisy data. However, it can be observed that our approach is more robust to changes of k: Even for small neighbor-hood sizes, high noise is handled significantly better than by PCA and large neighborhoods still produce satisfactory results for low noise data. It should be noted that for all evaluated k we improve on the state of the art w.r.t. average error. An evaluation for smaller k down to k = 2 is provided in the supplemental materials. While the RMSE error metric is well suited for a general comparison, it is not a good proxy to estimate the ability of recovering sharp features since it does not take into account the error distribution over angles. Therefore, as an additional metric, <ref type="figure" target="#fig_2">Figure 2</ref> presents the percentage of angle errors falling below different angle thresholds. The results confirm that our approach is better at preserving details and sharp edges, especially for low noise point clouds and varying density, where it outperforms other approaches. For higher noise, results similar to Nesti-Net are achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Efficiency</head><p>Our model is small, consisting of only 7981 trainable parameters, shared over iterations and spatial locations. On a single Nvidia Titan Xp, a point cloud with 100k points is processed in 5.67 seconds (0.0567 ms per point). A large part of this is the kd-tree used to compute the nearest neighbor graph, which takes 2.1 seconds of the 5.67 seconds. It is run on the CPU and could be further sped-up by utilizing GPUs.</p><p>Ours Nesti-Net <ref type="bibr">[</ref>  <ref type="table">Table 3</ref>: Comparison of efficiency between the approaches using deep learning. We list number of model parameters as well as average execution times for estimating normals on a point cloud with 100k points.</p><p>In <ref type="table">Table 3</ref> we compare our approach against the related deep learning approaches Nesti-Net and PCPNet. Our approach is orders of magnitude (378? and 131?) faster than the related approaches. The comparison was made as fair as possible by excluding nearest neighbor queries (note that this favors the other approaches since they need larger neighborhoods) and the original implementations. The speedup of our method can be contributed to the much smaller network size and the parallel design of the GNN and least-squares optimization steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Qualitative Evaluation</head><p>This section visually presents surface normal errors for various elements of the PCPNet test set in <ref type="figure">Figure 3</ref> and compares them against results from the PCA baseline and related deep learning approaches. It can be seen that the biggest improvements are obtained for low noise scenarios and varying density, where our method is able to preserve sharp features of objects better than the other methods. In general it can be observed that our approach tends to provide sharp, discriminative normals for points on edges in-stead of smooth averages. In rare cases, this can lead to a false assignment of points to planes, as we can see in the example in column 8. It can be observed that, in contrast to Nesti-Net, our approach behaves equivariant to input rotation as is seen clearly on the diagonal edge of the box example in column 3. Sharp edges are kept also in uncommon rotations, which we can attribute to our local rotational transformer. Results for more examples are displayed in the supplemental material.</p><p>Interpretability. In order to interprete the results of our method, <ref type="figure">Figure 4</ref> shows a detailed view of local neighborhoods over several iterations of our algorithm. An example for a sharp edge is shown in <ref type="figure">Figure 4a</ref> and a high noise surface in <ref type="figure">Figure 4b</ref>. Both sets of points were sampled from the real test data. For the sharp edge, the algorithm initially fits a plane with uniform weights, leading to smoothed normals. Over the iterations, high weights concentrate on the more plausible plane, leading to recovering of the sharp edge. In Ours Nesti-Net PCPNet PCA <ref type="figure">Figure 5</ref>: Selected results after applying Poisson surface reconstruction using the estimated normal vectors. In most cases, differences between the methods are very small. Examples 2 and 3 show reconstructions from point clouds with varying density, which show the largest differences.</p><p>the noisy example, we can see that outliers are iteratively receiving lower weights, leading to more stable estimates.</p><p>Surface reconstruction. To further evaluate the quality of the produced normals when used as input to other computer vision pipelines, <ref type="figure">Figure 5</ref> shows the results for Poisson surface reconstruction. Since the methods in this comparison all perform unoriented normal estimation (Guerrero et al. <ref type="bibr" target="#b18">[19]</ref> evaluates both, unoriented and oriented, where we chose the unoriented version for a fair comparison), we determine the signs of the output normals from all four methods using the ground truth normals. Most of the reconstructions show only small differences, with our approach and Nesti-Net retaining slightly more details than the others. Significant differences can be observed for point clouds with varying density, displayed in rows 2 and 3. Here, our approach successfully retains the original structure of the object while still providing sharp edges.</p><p>Transfer to NYU depth dataset. In order to show generality of our approach, our models trained on the PCPNet dataset are validated on the NYU depth v2 dataset <ref type="bibr" target="#b37">[38]</ref>, a common benchmark dataset in the field of estimating normals from single images. It contains 1449 aligned and preprocessed RGBD frames, which are transformed to a point cloud before applying our method. After performing unoriented estimation, the normals are flipped towards the camera position. Evaluation is done qualitatively, since the dataset does not contain ground truth normal vectors. Results for three different neighborhood sizes in comparison  <ref type="figure">Figure 6</ref>: Examples for normal estimation on scanned data from the NYU depth v2 dataset. Colors encode the orientation of normals. Our model generalizes to this dataset while being able to retain more details and sharper edges than PCA. However, scanning artifacts are also kept and visible. Best viewed in the digital version of the paper.</p><p>to PCA are shown in <ref type="figure">Figure 6</ref>. Our approach behaves as expected, as it is able to infer plausible normals for the given scenes. For all k, our approach is able to preserve sharp features while PCA produces very smooth results. However, this also leads to the sharp extraction of scanning artifacts, which can be seen on the walls of the scanned room.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and future work</head><p>We presented a novel method for deep surface normal estimation on unstructured point clouds, consisting of parallel, differentiable least-squares optimization and deep reweighting. In each iterations, the weights are computed using a kernel function that is individually parameterized and rotated for each neighborhood by a task-specific graph neural network. The algorithm is much more efficient than previous deep learning methods, reaches state-of-the-art accuracy, and has favorable properties like equivariance and robustness to noise. For future work, investigating the possibility of utilizing deep data priors to parameterize leastsquares problems holds large potential. We suspect that introducing data-dependency to other traditional methods can lead to progress in other fields of research, by reducing common disadvantages of pure deep learning approaches. On the theoretical side, it is interesting to dive deeper into convergence properties of IRLS with deep re-weighting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Architecture Details</head><p>The graph neural network for the deep kernel parameterization follows a general message passing scheme <ref type="bibr" target="#b12">[13]</ref> with edge update function</p><formula xml:id="formula_15">f e (i, j) = h f (i) | d i,j | prf (i, j)<label>(13)</label></formula><p>and node update function</p><formula xml:id="formula_16">f (i) = ? 1 |N (i)| j?N (i) f e (i, j) ,<label>(14)</label></formula><p>consisting of 6 MLPs, h i and ? i for i ? {1, 2, 3}. Together with the kernel MLP ?, all functions are detailed in <ref type="table" target="#tab_6">Table 4</ref> The h i and ? networks are shared over all edges in the neighborhood graph while the ? i are shared over all points. Additionally, all MLPs are shared over the iterations of the algorithm. Each MLP consists of two linear layers, seperated by a ReLU non-linearity. Layer sizes are given in <ref type="table" target="#tab_6">Table 4</ref>. All in all, the networks contain 7981 parameters and fulfill the following properties.  Permutation Invariance Neighborhood aggregation is performed using an average operator, which is invariant regarding the order of points. Since there are no other functions over sets of points, the resulting network is permutation invariant. We refer to <ref type="bibr" target="#b39">[40]</ref> for further discussion. It should be noted that PointNet can also be expressed in the same message passing scheme and is permutation invariant for the same reasons.</p><p>Varying neighborhood sizes For the cases in which we decide to use a radius graph instead of a k-nn graph, the network allows differently sized neighborhoods in one graph, since all parameters are shared over edge or nodes and the only operation over the whole neighborhood, the average, is agnostic to the neighborhood size.</p><p>Locality Due to using only local operators, the presented algorithm can be applied on partial point clouds, which is of importance for many practical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Implementation Details</head><p>The implementation of the proposed algorithm is based on the Pytorch Geometric library <ref type="bibr" target="#b12">[13]</ref> and uses the provided scheme consisting of scattering and gathering between node and edge feature space. Therefore, varying neighborhood sizes (e.g. varying node degree) can still be handled in parallel on the GPU by parallelization in graph edge space.</p><p>For parallel eigendecomposition of a large number of symmetric 3 ? 3 matrices and for the parallel quaternion to rotation matrix map, we provide our own Pytorch extensions which is available online. We provide efficient forward and backward steps on GPU and CPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Rotational Spatial Transformer</head><p>Our spatial transformer learns to bring the point sets in canonical orientation, which leads to equivariant behaviour, as our results show. Directly parameterizing 3 ? 3 matrices for the spatial transformer would lead to arbitrary affine transformations which can easily collapse or diverge during training. Thus, parameterizing the rotation group SO(3) is the more fitting choice for the given task. Unit quaternions are a good representation choice because they cover SO(3) (twice) without any discontinuities, as exist in e.g. Euler angles or axis-angle representations. Discontinuities in the SO(3) representation would force the network to sometimes predict very different values for SO(3) elements that lie next to each other on the Lie group manifold, which can lead to unstable gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Behaviour over iterations</head><p>The algorithm is trained for L = 8 (performing 8 iterations of re-weighting), where we compute a loss and perform an optimization step after each iteration. It produces normal vector estimations after each iteration, which can be analyzed quantitatively. The RMSE results for the PCPNet test set over algorithm iterations are shown in <ref type="figure" target="#fig_5">Figure 7</ref>. It can be seen that after iteration 4, further iterations do not lead to significant improvements. Also, the algorithm behaves reasonable stable, not diverging immediately after we pass the iterations for which the network was trained. However, we observe a small drift in favor of low-noise datasets over the iterations. Errors for the test sets with no noise or variable density still decrease further while errors for data with higher noise levels slightly increase. Meanwhile, the average error stays nearly constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Transfer between neighborhood sizes</head><p>As stated in the main paper, the proposed algorithm generalizes reasonably well between neighborhood sizes, meaning that a model trained using neighborhood size k train can be applied using a different neighborhood size k test while producing good results. For verification, we report RSME errors for different combinations of k train and k test in <ref type="table" target="#tab_8">Table 5</ref>. It can be seen that if the difference in neighborhood size is not too big, transferred models often only perform slightly worse than models trained directly for the appropriate k. However, transferring over very large difference like from 128 to 32 or the other way around, leads to a significant decrease in performance. The model trained on the balanced k = 64 performs very well on all other neighborhood sizes.</p><p>Additionally, <ref type="table" target="#tab_9">Table 6</ref> provides results for applying the model on even smaller neighborhood sizes, to evaluate the minimum k before the method breaks down. We found that when using a k train &lt;? 30, the training becomes unstable, which is why we transfer the model from k train = 32 to smaller k test = 32. Results show that the algorithm provides good results for noise-free data down to k = 4. For noisy data, the approach breaks down quite fast when lowering k, as expected: At least k = 24 is required to provide reliable    results. For lower k, the results approach the accuracy of random normals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Further qualitative results</head><p>Last, we provide qualitative results for the whole PCP-Net test set in <ref type="figure" target="#fig_6">Figure 8</ref>. For point clouds with varying density, the point size is reduced in order to better visualize the densities. Similar to examples shown in the paper, we can see that the method produces very sharp normal vectors, which usually resemble the plane normal of one of the plausible planes in the neighborhood. The abstract objects are good examples to show equivariance, as all edges show similar errors, independent of orientation. Sometimes, points are assigned to a false plane, leading to high error normal vectors. Compared to other approaches, we do not observe heavy smoothing around edges. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3 Figure 1 :</head><label>31</label><figDesc>Pair-wise residual features prf(i, j) Simplified overview of the proposed method for deep iterative surface normal estimation. The figure shows the process for a subset of three points. (a) Surfaces are fitted by optimizing weighted least squares. (b) A graph neural network infers kernel parameters and local orientation from intermediate pair-wise point descriptors. (c) A trainable, adaptive kernel refines the weights for the next step of the least squares optimization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Comparison for varying angle error threshold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Qualitative comparison between our method (k = 64, L = 4) and related work. We show diverse examples from the test set, sampled from different categories, noise levels and density variations. The color encodes the angle error of estimated normals in degrees. Best viewed in the digital version of the paper. Local behaviour of our method over several iterations for a sharp edge (a) and a noisy surface (b). The partial point clouds where sampled from the PCPNet test dataset. The colors in the first rows show the weights from the kernel network for one normal in the neighborhood while the colors in the second row show the angle error of all neighborhood normals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Test errors (RMSE) over iterations of the proposed algorithm. Iteration 0 shows results for unweighted PCA only. The network was trained on the training set for 8 iterations. For evaluation, we perform four additional iterations to evaluate stability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Qualitative results for all examples of the test set. Colors encode the RMSE in degree for each point. Best viewed in the digital version.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>11.56 12.08 12.71 12.97 Noise (? = 0.006) 18.17 17.36 17.18 17.03 16.90 28.41 23.00 20.68 18.81 18.12 Noise (? = 0.012) 25.17 22.40 21.96 21.80 22.13 45.35 38.48 33.67 28.81 26.67 11.81 11.84 11.94 12.20 19.09 17.52 16.75 16.30 16.26</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Ours L = 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PCA</cell><cell></cell><cell></cell></row><row><cell>Neighborhood size k</cell><cell>32</cell><cell>48</cell><cell>64</cell><cell>96</cell><cell>128</cell><cell>32</cell><cell>48</cell><cell>64</cell><cell>96</cell><cell>128</cell></row><row><cell>No noise</cell><cell>6.09</cell><cell>6.63</cell><cell>6.72</cell><cell>6.82</cell><cell>7.35</cell><cell>9.10</cell><cell>9.94</cell><cell cols="3">10.68 11.93 12.54</cell></row><row><cell cols="11">Noise (? = 0.00125) 11.22 Varying Density (Stripes) 10.22 9.63 9.95 10.45 9.64 7.22 7.63 7.73 7.87 8.67 10.48 11.40 12.07 13.18 14.07</cell></row><row><cell cols="2">Varying Density (Gradients) 6.84</cell><cell>7.19</cell><cell>7.51</cell><cell>7.69</cell><cell>8.49</cell><cell>9.96</cell><cell cols="4">10.74 11.35 12.36 13.21</cell></row><row><cell>Average</cell><cell>12.28</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Comparison of unoriented normal estimation RMSE between the proposed method and PCA for different neighborhood sizes k. It can be seen that our method consistently provides lower errors while being significantly more robust to changes of that parameter, compared to PCA.</figDesc><table /><note>Angle error threshhold ath [degree] Angle Errors &lt; ath [%]</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Details of the used graph neural network for iterative re-weighting. L(x) stands for a fully-connected layer with x output neurons.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Trained on k train = 32 Trained on k train = 64 Trained on k train = 128 .96 7.43 8.25 8.77 6.13 6.47 6.72 7.10 7.27 6.66 7.01 7.24 7.29 7.35 Noise (? = 0.00125) 10.22 10.01 10.09 10.37 10.62 10.19 9.93 9.95 10.18 10.35 9.89 9.57 9.50 9.50 9.64 Noise (? = 0.006) 18.17 17.44 17.22 17.08 17.05 18.28 17.43 17.18 17.01 16.94 20.98 18.40 17.63 17.07 16.90 Noise (? = 0.012) 25.17 22.97 22.33 21.91 21.80 25.20 22.53 21.96 21.69 21.67 30.99 24.94 23.20 22.34 22.13 Density (Stripes) 7.22 7.92 8.51 9.43 9.90 7.21 7.55 7.73 8.16 8.34 7.80 8.14 8.37 8.61 8.67 Density (Gradients) 6.84 7.46 8.06 8.80 9.21 6.89 7.17 7.51 8.04 8.03 7.48 7.75 8.11 8.39 8.49 Average 12.28 12.12 12.27 12.64 12.89 12.31 11.85 11.84 12.00 12.10 13.97 12.63 12.34 12.20 12.20</figDesc><table><row><cell>k test</cell><cell>32</cell><cell>48</cell><cell>64</cell><cell>96</cell><cell>128</cell><cell>32</cell><cell>48</cell><cell>64</cell><cell>96</cell><cell>128</cell><cell>32</cell><cell>48</cell><cell>64</cell><cell>96</cell><cell>128</cell></row><row><cell>No noise</cell><cell cols="2">6.09 6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Results for transferring models between different neighborhood sizes k. Shown are RMSE values for models trained with k train ? {32, 64, 128}, each tested with k test ? {32, 48, 64, 96, 128}. .23 5.63 5.36 5.77 6.09 Noise (? = 0.00125) 54.02 49.66 33.65 13.80 10.74 10.22 Noise (? = 0.006) 61.08 60.91 55.32 28.17 19.78 18.17 Noise (? = 0.012) 61.29 61.26 58.89 41.37 28.99 25.17 Density (Stripes) 19.50 8.14 6.53 6.36 6.71 7.22 Density (Gradients) 22.89 8.44 6.51 6.23 6.57 6.84 Average 39.34 32.59 27.75 16.88 13.09 12.28</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">Trained on k train = 32</cell><cell></cell></row><row><cell>k test</cell><cell>2</cell><cell>4</cell><cell>8</cell><cell>16</cell><cell>24</cell><cell>32</cell></row><row><cell>No noise</cell><cell cols="2">17.26 7</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Results for transferring the model trained on k train = 32 to even smaller k test ? {2, 4, 8, 16, 24, 32} until the method breaks down. Note that k test = 2 means 2 neighbors, excluding point i, so there are still 3 points in total for each neighborhood, avoiding underdefined plane fitting problems.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/nnaisense/ deep-iterative-surface-normal-estimation</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Matthias Fey for his work on Pytorch Geometric. We also thank him and Prof. Dr. Heinrich M?ller for helpful advice and discussions.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Materials</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>The supplemental materials contain details about the graph neural network in Section B, information about the implementation in Section C, a short discussion about the spatial transformer in D, and an additional analysis of accuracy over re-weighting iterations in Section E. Further, we show results for transferring models between different neighborhood sizes in Section F and qualitative results for the whole PCPNet test set in Section G.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Voronoi-based variational reconstruction of unoriented point sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Alliez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Desbrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fifth Eurographics Symposium on Geometry Processing, SGP &apos;07</title>
		<meeting>the Fifth Eurographics Symposium on Geometry Processing, SGP &apos;07</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Surface reconstruction by voronoi filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nina</forename><surname>Amenta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marshall</forename><surname>Bern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourteenth Annual Symposium on Computational Geometry, SCG &apos;98</title>
		<meeting>the Fourteenth Annual Symposium on Computational Geometry, SCG &apos;98</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="39" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Visibility-consistent thin surface reconstruction using multi-scale kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samir</forename><surname>Aroudj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Seemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Langguth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Guthe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Goesele</surname></persName>
		</author>
		<idno>187:1-187:13</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Transaction on Graphics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Marr revisited: 2d-3d alignment via surface normal prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aayush</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5965" to="5974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Nesti-net: Normal estimation for unstructured 3d point clouds using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhak</forename><surname>Ben-Shabat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lindenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anath</forename><surname>Fischer</surname></persName>
		</author>
		<idno>abs/1812.00709</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Fast and Robust Normal Estimation for Point Clouds with Sharp Features. Computer Graphics Forum</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renaud</forename><surname>Marlet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep Learning for Robust Normal Estimation in Unstructured Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renaud</forename><surname>Marlet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Geometric deep learning: Going beyond euclidean data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="42" />
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Estimating differential quantities using polynomial fitting of osculating jets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cazals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pouget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2003 Eurographics/ACM SIGGRAPH Symposium on Geometry Processing</title>
		<meeting>the 2003 Eurographics/ACM SIGGRAPH Symposium on Geometry Processing</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="177" to="187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Ppf-foldnet: Unsupervised learning of rotation invariant 3d local descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haowen</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Birdal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference of Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="620" to="638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ppfnet: Global context aware local features for robust 3d point matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haowen</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Birdal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slobodan</forename><surname>Ilic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="195" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the 2015 IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2650" to="2658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Fast graph representation learning with PyTorch Geometric. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">E</forename><surname>Lenssen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Splinecnn: Fast geometric deep learning with continuous b-spline kernels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Eric</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Weichert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="869" to="877" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Datadriven 3D primitives for single image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">F</forename><surname>Fouhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Collected matrix derivative results for forward and reverse mode algorithmic differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><forename type="middle">B</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Automatic Differentiation</title>
		<editor>Christian H. Bischof, H. Martin B?cker, Paul Hovland, Uwe Naumann, and Jean Utke</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A review of point clouds segmentation and classification algorithms. ISPRS -International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleonora</forename><surname>Grilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Menna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Remondino</surname></persName>
		</author>
		<idno>XLII- 2/W3</idno>
		<imprint>
			<date type="published" when="2017-02" />
			<biblScope unit="page" from="339" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Algebraic point set surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ga?l</forename><surname>Guennebaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Pcpnet learning local shape properties from raw point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Guerrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanir</forename><surname>Kleiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niloy</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="75" to="85" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Representation learning on graphs: Methods and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="52" to="74" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Multiple View Geometry in Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>2 edition</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Robust regression using iteratively reweighted least-squares</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><forename type="middle">E</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics -Theory and Methods</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="813" to="827" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Surface reconstruction from unorganized points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Derose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Duchamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Stuetzle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH &apos;92</title>
		<meeting>the 19th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH &apos;92</meeting>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="71" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Edge-aware point set resampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minglun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Ascher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao (richard)</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2013-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Learning transformation synchronization. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangru</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenxiao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Spatial transformer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Neural Information Processing Systems (NeurIPS)</title>
		<meeting>the 28th International Conference on Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2017" to="2025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Poisson surface reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kazhdan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Bolitho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Eurographics Symposium on Geometry Processing, SGP &apos;06</title>
		<meeting>the Fourth Eurographics Symposium on Geometry Processing, SGP &apos;06</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="61" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Comparison of surface normal estimation methods for range sensing applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Klasing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Althoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wollherr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Buss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<biblScope unit="page" from="3206" to="3211" />
			<date type="published" when="2009-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Discriminatively trained dense surface normal estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubor</forename><surname>Ladicky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Zeisl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The approximation power of moving leastsquares</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Comput</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">224</biblScope>
			<biblScope unit="page" from="1517" to="1531" />
			<date type="published" when="1998-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A. van den Hengel, and Mingyi He. Depth and surface normal estimation from monocular images using regression on deep features and hierarchical crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchao</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1119" to="1127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Geodesic convolutional neural networks on riemannian manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE International Conference on Computer Vision Workshop (ICCVW)</title>
		<meeting>the 2015 IEEE International Conference on Computer Vision Workshop (ICCVW)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="832" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Voronoi-based curvature and feature estimation from point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Merigot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="743" to="756" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Estimating surface normals in noisy point cloud data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In special issue of International Journal of Computational Geometry and Applications</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="261" to="276" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Rodol?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5425" to="5434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Weisfeiler and leman go neural: Higher-order graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ritzert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Eric</forename><surname>Lenssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav</forename><surname>Rattan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Grohe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Signing the unsigned: Robust surface reconstruction from raw pointsets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Mullen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>De Goes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Desbrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Cohen-Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Alliez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1733" to="1741" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Derek Hoiem and Rob Fergus. Indoor segmentation and support inference from rgbd images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet Kohli Nathan</forename><surname>Silberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A review of point cloud registration algorithms for mobile robotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Pomerleau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Colas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Siegwart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Robot</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="104" />
			<date type="published" when="2015-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Pointnet++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles Ruizhongtai Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5099" to="5108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Geonet: Geometric neural network for joint depth and surface normal estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengzhe</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="283" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">POINTCLEAN-NET: learning to denoise and remove outliers from dense point clouds. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Julie</forename><surname>Rakotosaona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">La</forename><surname>Vittorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barbera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niloy</forename><forename type="middle">J</forename><surname>Guerrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maks</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ovsjanikov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep fundamental matrix estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rene</forename><surname>Ranftl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Discovery of latent 3d keypoints via end-to-end geometric reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Supasorn</forename><surname>Suwajanakorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2063" to="2074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Designing deep networks for surface normal estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">F</forename><surname>Fouhey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="539" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep closest point: Learning representations for point cloud registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep points consolidation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minglun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Zwicker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transaction on Graphics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="176" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
