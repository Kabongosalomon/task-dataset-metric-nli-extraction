<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Published as a conference paper at ICLR 2020 CONTINUAL LEARNING WITH HYPERNETWORKS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Von Oswald</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Equal contribution Institute of Neuroinformatics</orgName>
								<orgName type="institution" key="instit1">University of Z?rich</orgName>
								<orgName type="institution" key="instit2">ETH Z?rich Z?rich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Henning</surname></persName>
							<email>henningc@ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Equal contribution Institute of Neuroinformatics</orgName>
								<orgName type="institution" key="instit1">University of Z?rich</orgName>
								<orgName type="institution" key="instit2">ETH Z?rich Z?rich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">F</forename><surname>Grewe</surname></persName>
							<email>bgrewe@ethz.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Equal contribution Institute of Neuroinformatics</orgName>
								<orgName type="institution" key="instit1">University of Z?rich</orgName>
								<orgName type="institution" key="instit2">ETH Z?rich Z?rich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><surname>Sacramento</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Equal contribution Institute of Neuroinformatics</orgName>
								<orgName type="institution" key="instit1">University of Z?rich</orgName>
								<orgName type="institution" key="instit2">ETH Z?rich Z?rich</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Published as a conference paper at ICLR 2020 CONTINUAL LEARNING WITH HYPERNETWORKS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Artificial neural networks suffer from catastrophic forgetting when they are sequentially trained on multiple tasks. To overcome this problem, we present a novel approach based on task-conditioned hypernetworks, i.e., networks that generate the weights of a target model based on task identity. Continual learning (CL) is less difficult for this class of models thanks to a simple key feature: instead of recalling the input-output relations of all previously seen data, task-conditioned hypernetworks only require rehearsing task-specific weight realizations, which can be maintained in memory using a simple regularizer. Besides achieving state-ofthe-art performance on standard CL benchmarks, additional experiments on long task sequences reveal that task-conditioned hypernetworks display a very large capacity to retain previous memories. Notably, such long memory lifetimes are achieved in a compressive regime, when the number of trainable hypernetwork weights is comparable or smaller than target network size. We provide insight into the structure of low-dimensional task embedding spaces (the input space of the hypernetwork) and show that task-conditioned hypernetworks demonstrate transfer learning. Finally, forward information transfer is further supported by empirical results on a challenging CL benchmark based on the CIFAR-10/100 image datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:1906.00695v4 [cs.LG] 11 Apr 2022</head><p>Published as a conference paper at ICLR 2020 simultaneously, can be seen as a CL upper-bound. The strategy described above has been termed rehearsal <ref type="bibr" target="#b46">(Robins, 1995)</ref>. However, storing previous task data violates our CL desiderata. Therefore, we introduce a change in perspective and move from the challenge of maintaining individual input-output data points to the problem of maintaining sets of parameters {? (t) }, without explicitly storing them. To achieve this, we train the metamodel parameters ? h analogous to the above outlined learning scheme, where synthetic targets now correspond to weight configurations that are suitable for previous tasks. This exchanges the storage of an entire dataset by a single low-dimensional task descriptor, yielding a massive memory saving in all but the simplest of tasks. Despite relying on regularization, our approach is a conceptual departure from previous algorithms based on regularization in weight (e.g., <ref type="bibr" target="#b25">Kirkpatrick et al., 2017;</ref><ref type="bibr" target="#b58">Zenke et al., 2017)</ref> or activation space (e.g., He &amp; Jaeger, 2018).</p><p>Our experimental results show that task-conditioned hypernetworks do not suffer from catastrophic forgetting on a set of standard CL benchmarks. Remarkably, they are capable of retaining memories with practically no decrease in performance, when presented with very long sequences of tasks. Thanks to the expressive power of neural networks, task-conditioned hypernetworks exploit task-totask similarities and transfer information forward in time to future tasks. Finally, the task-conditional metamodelling perspective that we put forth is generic, as it does not depend on the specifics of the target network architecture. We exploit this key principle and show that the very same metamodelling framework extends to, and can improve, an important class of CL methods known as generative replay methods, which are current state-of-the-art performers in many practical problems <ref type="bibr" target="#b52">(Shin et al., 2017;</ref><ref type="bibr" target="#b57">Wu et al., 2018;</ref><ref type="bibr" target="#b55">van de Ven &amp; Tolias, 2018</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">MODEL 2.1 TASK-CONDITIONED HYPERNETWORKS</head><p>Hypernetworks parameterize target models. The centerpiece of our approach to continual learning is the hypernetwork, <ref type="figure">Fig. 1a</ref>. Instead of learning the parameters ? trgt of a particular function f trgt directly (the target model), we learn the parameters ? h of a metamodel. The output of such metamodel, the hypernetwork, is ? trgt . Hypernetworks can therefore be thought of as weight generators, which were originally introduced to dynamically parameterize models in a compressed form <ref type="bibr" target="#b49">Schmidhuber, 1992;</ref><ref type="bibr" target="#b1">Bertinetto et al., 2016;</ref><ref type="bibr" target="#b21">Jia et al., 2016</ref>). a ... f h f trgt x y regularized hypernetwork target network t ? trgt e (1)</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>We assume that a neural network f (x, ?) with trainable weights ? is given data from a set of tasks {(X (1) , Y (1) ), . . . , (X (T ) , Y (T ) )}, with input samples X (t) = {x (t,i) } nt i=1 and output samples Y (t) = {y (t,i) } nt i=1 , where n t ? |X (t) |. A standard training approach learns the model using data from all tasks at once. However, this is not always possible in real-world problems, nor desirable in an online learning setting. Continual learning (CL) refers to an online learning setup in which tasks are presented sequentially (see <ref type="bibr" target="#b56">van de Ven &amp; Tolias, 2019</ref>, for a recent review on CL). In CL, when learning a new task t, starting with weights ? (t?1) and observing only (X (t) , Y (t) ), the goal is to find a new set of parameters ? (t) that (1) retains (no catastrophic forgetting) or (2) improves (positive backward transfer) performance on previous tasks compared to ? (t?1) and (3) solves the new task t potentially utilizing previously acquired knowledge (positive forward transfer). Achieving these goals is non-trivial, and a longstanding issue in neural networks research.</p><p>Here, we propose addressing catastrophic forgetting at the meta level: instead of directly attempting to retain f (x, ?) for previous tasks, we fix the outputs of a metamodel f h (e, ? h ) termed task-conditioned hypernetwork which maps a task embedding e to weights ?. Now, a single point has to be memorized per task. To motivate such approach, we perform a thought experiment: we assume that we are allowed to store all inputs {X (1) , . . . , X (T ) } seen so far, and to use these data to compute model outputs corresponding to ? (T ?1) . In this idealized setting, one can avoid forgetting by simply mixing data from the current task with data from the past, {(X (1) ,? (1) ), . . . , (X (T ?1) ,? (T ?1) ), (X (T ) , Y (T ) )}, where? (t) refers to a set of synthetic targets generated using the model itself f ( ? , ? (t?1) ). Hence, by training to retain previously acquired input-output mappings, one can obtain a sequential algorithm in principle as powerful as multi-task learning. Multi-task learning, where all tasks are learned y <ref type="bibr">(2)</ref> y <ref type="bibr">(3)</ref> f trgt f trgt y <ref type="bibr">(T)</ref> f trgt (1) ? trgt</p><p>(2) (1)</p><p>x <ref type="bibr">(2)</ref> ? trgt</p><p>(3)</p><p>x (3) ? trgt <ref type="bibr">(T)</ref> x <ref type="bibr">(T)</ref>   <ref type="figure">Figure 1</ref>: Task-conditioned hypernetworks for continual learning. (a) Commonly, the parameters of a neural network are directly adjusted from data to solve a task. Here, a weight generator termed hypernetwork is learned instead. Hypernetworks map embedding vectors to weights, which parameterize a target neural network. In a continual learning scenario, a set of task-specific embeddings is learned via backpropagation. Embedding vectors provide task-dependent context and bias the hypernetwork to particular solutions. (b) A smaller, chunked hypernetwork can be used iteratively, producing a chunk of target network weights at a time (e.g., one layer at a time). Chunked hypernetworks can achieve model compression: the effective number of trainable parameters can be smaller than the number of target network weights.</p><formula xml:id="formula_0">f h f h f h f h</formula><p>Continual learning with hypernetwork output regularization. One approach to avoid catastrophic forgetting is to store data from previous tasks and corresponding model outputs, and then fix such outputs. This can be achieved using an output regularizer of the following form, where past outputs play the role of pseudo-targets <ref type="bibr" target="#b46">(Robins, 1995;</ref><ref type="bibr" target="#b29">Li &amp; Hoiem, 2018;</ref>:</p><formula xml:id="formula_1">L output = T ?1 t=1 |X (t) | i=1 f (x (t,i) , ? * ) ? f (x (t,i) , ?) 2 ,<label>(1)</label></formula><p>In the equation above, ? * is the set of parameters before attempting to learn task T , and f is the learner. This approach, however, requires storing and iterating over previous data, a process that is known as rehearsing. This is potentially expensive memory-wise and not strictly online learning. A possible workaround is to generate the pseudo-targets by evaluating f on random patterns <ref type="bibr" target="#b46">(Robins, 1995)</ref> or on the current task dataset <ref type="bibr" target="#b29">(Li &amp; Hoiem, 2018)</ref>. However, this does not necessarily fix the behavior of the function f in the regions of interest.</p><p>Hypernetworks sidestep this problem naturally. In target network weight space, a single point (i.e., one set of weights) has to be fixed per task. This can be efficiently achieved with task-conditioned hypernetworks, by fixing the hypernetwork output on the appropriate task embedding.</p><p>Similar to , we use a two-step optimization procedure to introduce memorypreserving hypernetwork output constraints. First, we compute a candidate change ?? h which minimizes the current task loss L (T ) task = L task (? h , e (T ) , X (T ) , Y (T ) ) with respect to ?. The candidate ?? h is obtained with an optimizer of choice (we use Adam throughout; <ref type="bibr" target="#b23">Kingma &amp; Ba, 2015)</ref>. The actual parameter change is then computed by minimizing the following total loss:</p><formula xml:id="formula_2">L total = L task (? h , e (T ) , X (T ) , Y (T ) ) + L output (? * h , ? h , ?? h , {e (t) }) = L task (? h , e (T ) , X (T ) , Y (T ) ) + ? output T ? 1 T ?1 t=1 f h (e (t) , ? * h ) ? f h (e (t) , ? h + ?? h )) 2 ,<label>(2)</label></formula><p>where ? * h is the set of hypernetwork parameters before attempting to learn task T , ?? h is considered fixed and ? output is a hyperparameter that controls the strength of the regularizer. On Appendix D, we run a sensitivity analysis on ? output and experiment with a more efficient stochastic regularizer where the averaging is performed over a random subset of past tasks.</p><p>More computationally-intensive algorithms that involve a full inner-loop refinement, or use secondorder gradient information by backpropagating through ?? h could be applied. However, we found empirically that our one-step correction worked well. Exploratory hyperparameter scans revealed that the inclusion of the lookahead ?? h in (2) brought a minor increase in performance, even when computed with a cheap one-step procedure. Note that unlike in Eq. 1, the memory-preserving term L output does not depend on past data. Memory of previous tasks enters only through the collection of task embeddings {e (t) } T ?1 t=1 .</p><p>Learned task embeddings. Task embeddings are differentiable deterministic parameters that can be learned, just like ? h . At every learning step of our algorithm, we also update the current task embedding e (T ) to minimize the task loss L (T ) task . After learning the task, the final embedding is saved and added to the collection {e (t) }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MODEL COMPRESSION WITH CHUNKED HYPERNETWORKS</head><p>Chunking. In a straightforward implementation, a hypernetwork produces the entire set of weights of a target neural network. For modern deep neural networks, this is a very high-dimensional output. However, hypernetworks can be invoked iteratively, filling in only part of the target model at each step, in chunks <ref type="bibr" target="#b42">Pawlowski et al., 2017)</ref>. This strategy allows applying smaller hypernetworks that are reusable. Interestingly, with chunked hypernetworks it is possible to solve tasks in a compressive regime, where the number of learned parameters (those of the hypernetwork) is effectively smaller than the number of target network parameters.</p><p>Chunk embeddings and network partitioning. Reapplying the same hypernetwork multiple times introduces weight sharing across partitions of the target network, which is usually not desirable.</p><p>To allow for a flexible parameterization of the target network, we introduce a set C = {c i } NC i=1 of chunk embeddings, which are used as an additional input to the hypernetwork, <ref type="figure">Fig. 1b</ref>. Thus, the full set of target network parameters ? trgt = [f h (e, c 1 ), . . . , f h (e, c NC )] is produced by iteration over C, keeping the task embedding e fixed. This way, the hypernetwork can produce distinct weights for each chunk. Furthermore, chunk embeddings, just like task embeddings, are ordinary deterministic parameters that we learn via backpropagation. For simplicity, we use a shared set of chunk embeddings for all tasks and we do not explore special target network partitioning strategies.</p><p>How flexible is our approach? Chunked neural networks can in principle approximate any target weight configuration arbitrarily well. For completeness, we state this formally in Appendix E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">CONTEXT-FREE INFERENCE: UNKNOWN TASK IDENTITY</head><p>Determining which task to solve from input data. Our hypernetwork requires a task embedding input to generate target model weights. In certain CL applications, an appropriate embedding can be immediately selected as task identity is unambiguous, or can be readily inferred from contextual clues. In other cases, knowledge of the task at hand is not explicitly available during inference. In the following, we show that our metamodelling framework generalizes to such situations. In particular, we consider the problem of inferring which task to solve from a given input pattern, a noted benchmark challenge <ref type="bibr" target="#b6">(Farquhar &amp; Gal, 2018;</ref><ref type="bibr" target="#b56">van de Ven &amp; Tolias, 2019)</ref>. Below, we explore two different strategies that leverage task-conditioned hypernetworks in this CL setting.</p><p>Task-dependent predictive uncertainty. Neural network models are increasingly reliable in signalling novelty and appropriately handling out-of-distribution data. For categorical target distributions, the network ideally produces a flat, high entropy output for unseen data and, conversely, a peaked, low-entropy response for in-distribution data <ref type="bibr" target="#b16">(Hendrycks &amp; Gimpel, 2016;</ref><ref type="bibr" target="#b30">Liang et al., 2017)</ref>. This suggests a first, simple method for task inference (HNET+ENT). Given an input pattern for which task identity is unknown, we pick the task embedding which yields lowest predictive uncertainty, as quantified by output distribution entropy. While this method relies on accurate novelty detection, which is in itself a far from solved research problem, it is otherwise straightforward to implement and no additional learning or model is required to infer task identity.</p><p>Hypernetwork-protected synthetic replay. When a generative model is available, catastrophic forgetting can be circumvented by mixing current task data with replayed past synthetic data (for recent work see <ref type="bibr" target="#b52">Shin et al., 2017;</ref><ref type="bibr" target="#b57">Wu et al., 2018)</ref>. Besides protecting the generative model itself, synthetic data can protect another model of interest, for example, another discriminative model. This conceptually simple strategy is in practice often the state-of-the-art solution to CL (van de <ref type="bibr" target="#b56">Ven &amp; Tolias, 2019)</ref>. Inspired by these successes, we explore augmenting our system with a replay network, here a standard variational autoencoder (VAE; Kingma &amp; Welling, 2014) (but see Appendix F for experiments with a generative adversarial network, <ref type="bibr" target="#b9">Goodfellow et al., 2014)</ref>.</p><p>Synthetic replay is a strong, but not perfect, CL mechanism as the generative model is subject to drift, and errors tend to accumulate and amplify with time. Here, we build upon the following key observation: just like the target network, the generator of the replay model can be specified by a hypernetwork. This allows protecting it with the output regularizer, Eq. 2, rather than with the model's own replay data, as done in related work. Thus, in this combined approach, both synthetic replay and task-conditional metamodelling act in tandem to reduce forgetting.</p><p>We explore hypernetwork-protected replay in two distinct setups. First, we consider a minimalist architecture (HNET+R), where only the replay model, and not the target classifier, is parameterized by a hypernetwork. Here, forgetting in the target network is obviated by mixing current data with synthetic data. Synthetic target output values for previous tasks are generated using a soft targets method, i.e., by simply evaluating the target function before learning the new task on synthetic input data. Second (HNET+TIR), we introduce an auxiliary task inference classifier, protected using synthetic replay data and trained to predict task identity from input patterns. This architecture requires additional modelling, but it is likely to work well when tasks are strongly dissimilar. Furthermore, the task inference subsystem can be readily applied to process more general forms of contextual information, beyond the current input pattern. We provide additional details, including network architectures and the loss functions that are optimized, in Appendices B and C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>We evaluate our method on a set of standard image classification benchmarks on the MNIST, CIFAR-10 and CIFAR-100 public datasets 1 . Our main aims are to (1) study the memory retention capabilities of task-conditioned hypernetworks across three continual learning settings, and (2) investigate information transfer across tasks that are learned sequentially.</p><p>Continual learning scenarios. In our experiments we consider three different CL scenarios <ref type="bibr" target="#b56">(van de Ven &amp; Tolias, 2019)</ref>. In CL1, the task identity is given to the system. This is arguably the standard sequential learning scenario, and the one we consider unless noted otherwise. In CL2, task identity is unknown to the system, but it does not need to be explicitly determined. A target network with a fixed head is required to solve multiple tasks. In CL3, task identity has to be explicitly inferred. It has been argued that this scenario is the most natural, and the one that tends to be harder for neural networks <ref type="bibr" target="#b6">(Farquhar &amp; Gal, 2018;</ref><ref type="bibr" target="#b56">van de Ven &amp; Tolias, 2019)</ref>.</p><p>Experimental details. Aiming at comparability, for the experiments on the MNIST dataset we model the target network as a fully-connected network and set all hyperparameters after van de Ven &amp; Tolias (2019), who recently reviewed and compared a large set of CL algorithms. For our CIFAR experiments, we opt for a ResNet-32 target neural network <ref type="bibr" target="#b13">(He et al., 2016)</ref> to assess the scalability of our method. A summary description of the architectures and particular hyperparameter choices, as well as additional experimental details, is provided in Appendix C. We emphasize that, on all our experiments, the number of hypernetwork parameters is always smaller or equal than the number of parameters of the models we compare with. Nonlinear regression toy problem. To illustrate our approach, we first consider a simple nonlinear regression problem, where the function to be approximated is scalar-valued, <ref type="figure" target="#fig_0">Fig. 2</ref>. Here, a sequence of polynomial functions of increasing degree has to be inferred from noisy data. This motivates the continual learning problem: when learning each task in succession by modifying ? h with the memory-preserving regularizer turned off (? output = 0, see Eq. 2) the network learns the last task but forgets previous ones, <ref type="figure" target="#fig_0">Fig. 2c</ref>. The regularizer protects old solutions, <ref type="figure" target="#fig_0">Fig. 2a</ref>, and performance is comparable to an offline non-continual learner, <ref type="figure" target="#fig_0">Fig. 2b</ref>.</p><p>Permuted MNIST benchmark. Next, we study the permuted MNIST benchmark. This problem is set as follows. First, the learner is presented with the full MNIST dataset. Subsequently, novel tasks are obtained by applying a random permutation to the input image pixels. This process can be repeated to yield a long task sequence, with a typical length of T = 10 tasks. Given the low similarity of the generated tasks, permuted MNIST is well suited to study the memory capacity of a continual learner. For T = 10, we find that task-conditioned hypernetworks are state-of-the-art on CL1, <ref type="table">Table 1</ref>. Interestingly, inferring tasks through the predictive distribution entropy (HNET+ENT) works well on the permuted MNIST benchmark. Despite the simplicity of the method, both synaptic intelligence (SI; <ref type="bibr" target="#b58">Zenke et al., 2017)</ref> and online elastic weight consolidation (EWC;   versus task-averaged test set accuracy after learning all tasks (labelled 'final', in red) and immediately after learning a task (labelled 'during', in purple) for the PermutedMNIST-10 benchmark. Hypernetworks allow for model compression and perform well even when the number of target model parameters exceeds their own. Performance decays nonlinearly: accuracies stay approximately constant for a wide range of compression ratios below unity. Hyperparameters were tuned once for compression ratio ? 1 and were then used for all compression ratios. Shaded areas denote STD (a) resp. SEM (b) across 5 random seeds. methods, task-conditioned hypernetworks (HNET+TIR and HNET+R) are the best performers on all three CL scenarios.</p><p>Performance differences become larger in the long sequence limit, <ref type="figure">Fig. 3a</ref>. For longer task sequences (T = 100), SI and DGR+distill <ref type="bibr" target="#b52">(Shin et al., 2017;</ref><ref type="bibr" target="#b55">van de Ven &amp; Tolias, 2018)</ref> degrade gracefully, while the regularization strength of online EWC prevents the method from achieving high accuracy (see <ref type="figure" target="#fig_6">Fig. A6</ref> for a hyperparameter search on related work). Notably, task-conditioned hypernetworks show minimal memory decay and find high performance solutions. Because the hypernetwork operates in a compressive regime (see <ref type="figure">Fig. 3b</ref> and <ref type="figure" target="#fig_7">Fig. A7</ref> for an exploration of compression ratios), our results do not naively rely on an increase in the number of parameters. Rather, they suggest that previous methods are not yet capable of making full use of target model capacity in a CL setting. We report a set of extended results on this benchmark on Appendix D, including a study of CL2/3 (T = 100), where HNET+TIR strongly outperforms the related work.</p><p>Split MNIST benchmark. Split MNIST is another popular CL benchmark, designed to introduce task overlap. In this problem, the various digits are sequentially paired and used to form five binary classification tasks. Here, we find that task-conditioned hypernetworks are the best overall performers. In particular, HNET+R improves the previous state-of-the-art method DGR+distill on both CL2 and CL3, almost saturating the CL2 upper bound for replay models (Appendix D). Since HNET+R is essentially hypernetwork-protected DGR, these results demonstrate the generality of task-conditioned hypernetworks as effective memory protectors. To further support this, in Appendix F we show that our replay models (we experiment with both a VAE and a GAN) can learn in a class-incremental manner the full MNIST dataset. Finally, HNET+ENT again outperforms both EWC and SI, without any generative modelling.</p><p>On the split MNIST problem, tasks overlap and therefore continual learners can transfer information across tasks. To analyze such effects, we study task-conditioned hypernetworks with two-dimensional task embedding spaces, which can be easily visualized. Despite learning happening continually, we <ref type="table">Table 1</ref>: Task-averaged test accuracy (? SEM, n = 20) on the permuted ('P10') and split ('S') MNIST experiments. In the table, EWC refers to online EWC and DGR refers to DGR+distill (results reproduced from van de Ven &amp; Tolias, 2019). We tested three hypernetwork-based models: for HNET+ENT (HNET alone for CL1), we inferred task identity based on the entropy of the predictive distribution; for HNET+TIR, we trained a hypernetwork-protected recognition-replay network (based on a VAE, cf. <ref type="figure" target="#fig_2">Fig. A1</ref>) to infer the task from input patterns; for HNET+R the main classifier was trained by mixing current task data with synthetic data generated from a hypernetwork-protected VAE.  Colorcoded test set classification accuracies after learning the five splits, shown as the embedding vector components are varied. Markers denote the position of final task embeddings. (a) High classification performance with virtually no forgetting is achieved even when e-space is low-dimensional. The model shows information transfer in embedding space: the first task is solved in a large volume that includes embeddings for subsequently learned tasks. (b) Competition in embedding space: the last task occupies a finite high performance region, with graceful degradation away from the embedding vector. Previously learned task embeddings still lead to moderate, above-chance performance.</p><p>find that the algorithm converges to a hypernetwork configuration that can produce target model parameters that simultaneously solve old and new tasks, <ref type="figure" target="#fig_1">Fig. 4</ref>, given the appropriate task embedding.</p><p>Split CIFAR-10/100 benchmark. Finally, we study a more challenging benchmark, where the learner is first asked to solve the full CIFAR-10 classification task and is then presented with sets of ten classes from the CIFAR-100 dataset. We perform experiments both with a high-performance ResNet-32 target network architecture ( <ref type="figure">Fig. 5)</ref> and with a shallower model ( <ref type="figure">Fig. A3</ref>) that we exactly reproduced from previous work <ref type="bibr" target="#b58">(Zenke et al., 2017)</ref>. Remarkably, on the ResNet-32 model, we find that task-conditioned hypernetworks essentially eliminate altogether forgetting. Furthermore, forward information transfer takes place; knowledge from previous tasks allows the network to find better solutions than when learning each task individually from initial conditions. Interestingly, forward transfer is stronger on the shallow model experiments ( <ref type="figure">Fig. A3)</ref>, where we otherwise find that our method performs comparably to SI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>Bayesian accounts of continual learning. According to the standard Bayesian CL perspective, a posterior parameter distribution is recursively updated using Bayes' rule as tasks arrive  <ref type="figure">Figure 5</ref>: Split CIFAR-10/100 CL benchmark. Test set accuracies (mean ? STD, n = 5) on the entire CIFAR-10 dataset and subsequent CIFAR-100 splits of ten classes. Our hypernetworkprotected ResNet-32 displays virtually no forgetting; final averaged performance (hnet, in red) matches the immediate one (hnet-during, in blue). Furthermore, information is transferred across tasks, as performance is higher than when training each task from scratch (purple). Disabling our regularizer leads to strong forgetting (in yellow). <ref type="bibr" target="#b25">(Kirkpatrick et al., 2017;</ref><ref type="bibr" target="#b19">Husz?r, 2018;</ref>. While this approach is theoretically sound, in practice, the approximate inference methods that are typically preferred can lead to stiff models, as a compromise solution that suits all tasks has to be found within the mode determined by the first task. Such restriction does not apply to hypernetworks, which can in principle model complex multimodal distributions <ref type="bibr" target="#b31">(Louizos &amp; Welling, 2017;</ref><ref type="bibr" target="#b42">Pawlowski et al., 2017;</ref><ref type="bibr" target="#b17">Henning et al., 2018)</ref>. Thus, rich, hypernetwork-modelled priors are one avenue of improvement for Bayesian CL methods. Interestingly, task-conditioning offers an alternative possibility: instead of consolidating every task onto a single distribution, a shared task-conditioned hypernetwork could be leveraged to model a set of parameter posterior distributions. This conditional metamodel naturally extends our framework to the Bayesian learning setting. Such approach will likely benefit from additional flexibility, compared to conventional recursive Bayesian updating.</p><p>Related approaches that rely on task-conditioning. Our model fits within, and in certain ways generalizes, previous CL methods that condition network computation on task descriptors. Taskconditioning is commonly implemented using multiplicative masks at the level of modules <ref type="bibr" target="#b48">(Rusu et al., 2016;</ref><ref type="bibr" target="#b7">Fernando et al., 2017)</ref>, neurons <ref type="bibr" target="#b51">(Serra et al., 2018;</ref><ref type="bibr" target="#b37">Masse et al., 2018)</ref> or weights <ref type="bibr" target="#b33">(Mallya &amp; Lazebnik, 2018)</ref>. Such methods work best with large networks and come with a significant storage overhead, which typically scales with the number of tasks. Our approach differs by explicitly modelling the full parameter space using a metamodel, the hypernetwork. Thanks to this metamodel, generalization in parameter and task space is possible, and task-to-task dependencies can be exploited to efficiently represent solutions and transfer present knowledge to future problems. Interestingly, similar arguments have been drawn in work developed concurrently to ours <ref type="bibr" target="#b27">(Lampinen &amp; McClelland, 2019)</ref>, where task embedding spaces are further explored in the context of few-shot learning. In the same vein, and like the approach developed here, recent work in CL generates last-layer network parameters as part of a pipeline to avoid catastrophic forgetting <ref type="bibr" target="#b18">(Hu et al., 2019)</ref> or distills parameters onto a contractive auto-encoding model <ref type="bibr" target="#b4">(Camp et al., 2018)</ref>.</p><p>Positive backwards transfer. In its current form, the hypernetwork output regularizer protects previously learned solutions from changing, such that only weak backwards transfer of information can occur. Given the role of selective forgetting and refinement of past memories in achieving intelligent behavior <ref type="bibr" target="#b2">(Brea et al., 2014;</ref><ref type="bibr" target="#b44">Richards &amp; Frankland, 2017)</ref>, investigating and improving backwards transfer stands as an important direction for future research.</p><p>Relevance to systems neuroscience. Uncovering the mechanisms that support continual learning in both brains and artificial neural networks is a long-standing question <ref type="bibr" target="#b38">(McCloskey &amp; Cohen, 1989;</ref><ref type="bibr" target="#b8">French, 1999;</ref><ref type="bibr" target="#b41">Parisi et al., 2019)</ref>. We close with a speculative systems interpretation <ref type="bibr" target="#b26">(Kumaran et al., 2016;</ref><ref type="bibr" target="#b12">Hassabis et al., 2017)</ref> of our work as a model for modulatory top-down signals in cortex. Task embeddings can be seen as low-dimensional context switches, which determine the behavior of a modulatory system, the hypernetwork in our case. According to our model, the hypernetwork would in turn regulate the activity of a target cortical network.</p><p>As it stands, implementing a hypernetwork would entail dynamically changing the entire connectivity of a target network, or cortical area. Such a process seems difficult to conceive in the brain. However, this strict literal interpretation can be relaxed. For example, a hypernetwork can output lowerdimensional modulatory signals <ref type="bibr" target="#b36">(Marder, 2012)</ref>, instead of a full set of weights. This interpretation is consistent with a growing body of work which suggests the involvement of modulatory inputs in implementing context-or task-dependent network mode-switching <ref type="bibr" target="#b34">(Mante et al., 2013;</ref><ref type="bibr" target="#b20">Jaeger, 2014;</ref><ref type="bibr" target="#b53">Stroud et al., 2018;</ref><ref type="bibr" target="#b37">Masse et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We introduced a novel neural network model, the task-conditioned hypernetwork, that is well-suited for CL problems. A task-conditioned hypernetwork is a metamodel that learns to parameterize target functions, that are specified and identified in a compressed form using a task embedding vector. Past tasks are kept in memory using a hypernetwork output regularizer, which penalizes changes in previously found target weight configurations. This approach is scalable and generic, being applicable as a standalone CL method or in combination with generative replay. Our results are state-of-the-art on standard benchmarks and suggest that task-conditioned hypernetworks can achieve long memory lifetimes, as well as transfer information to future tasks, two essential properties of a continual learner.</p><p>A TASK-CONDITIONED HYPERNETWORKS: MODEL SUMMARY In our model, a task-conditioned hypernetwork produces the parameters ? trgt = f h (e, ? h ) of a target neural network. Given one such parameterization, the target model then computes prediction? y = f trgt (x, ? trgt ) based on input data. Learning amounts to adapting the parameters ? h of the hypernetwork, including a set of task embeddings {e (t) } T t=1 , as well as a set of chunk embeddings</p><formula xml:id="formula_3">{c i } NC i=1</formula><p>in case compression is sought or if the full hypernetwork is too large to be handled directly. To avoid castastrophic forgetting, we introduce an output regularizer which fixes the behavior of the hypernetwork by penalizing changes in target model parameters that are produced for previously learned tasks.</p><p>Variables that need to be stored while learning new tasks. What are the storage requirements of our model, when learning continually?</p><p>1. Memory retention relies on saving one embedding per task. This collection {e (t) } T t=1 therefore grows linearly with T . Such linear scaling is undesirable asymptotically, but it turns out to be essentially negligible in practice, as each embedding is a single lowdimensional vector (e.g., see <ref type="figure" target="#fig_1">Fig. 4</ref> for a run with 2D embeddings).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>A frozen snapshot of the hypernetwork parameters ? * h , taken before learning a new task, needs to be kept, to evaluate the output regularizer in Eq. 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B ADDITIONAL DETAILS ON HYPERNETWORK-PROTECTED REPLAY MODELS</head><p>Variational autoencoders. For all HNET+TIR and HNET+R experiments reported on the main text we use VAEs as our replay models ( <ref type="figure" target="#fig_2">Fig. A1a</ref>, <ref type="bibr" target="#b24">Kingma &amp; Welling, 2014)</ref>. Briefly, a VAE consists of an encoder-decoder network pair, where the encoder network processes some input pattern x and its outputs f enc (x) = (?, ? 2 ) comprise the parameters ? and ? 2 (encoded in log domain, to enforce nonnegativity) of a diagonal multivariate Gaussian p Z (z; ?, ? 2 ), which governs the distribution of latent samples z. On the other side of the circuit, the decoder network processes a latent sample z and a one-hot-encoded task identity vector and returns an input pattern reconstruction, f dec (z, 1 t ) =x.</p><p>VAEs can preserve memories using a technique called generative replay: when training task T , input samples are generated from the current replay network for old tasks t &lt; T , by varying 1 t and drawing latent space samples z. Generated data can be mixed with the current dataset, yielding an augmented datasetX used to relearn model parameters. When protecting a discriminative model, synthetic 'soft' targets can be generated by evaluating the network onX . We use this strategy to protect an auxiliary task inference classifier in HNET+TIR, and to protect the main target model in HNET+R.</p><p>Hypernetwork-protected replay. In our HNET+TIR and HNET+R experiments, we parameterize the decoder network through a task-conditioned hypernetwork, f h,dec (e, ? h,dec ). In combination with our output regularizer, this allows us to take advantage of the memory retention capacity of hypernetworks, now on a generative model.</p><p>The replay model (encoder, decoder and decoder hypernetwork) is a separate subsystem that is optimized independently from the target network. Its parameters ? enc and ? h,dec are learned by minimizing our regularized loss function, Eq. 2, here with the task-specific term set to the standard VAE objective function,</p><formula xml:id="formula_4">L VAE X, ? enc , ? h,dec = L rec (X, ? enc , ? dec ) + L prior (X, ? enc , ? dec ),<label>(3)</label></formula><p>with ? dec = f h,dec (e, ? h,dec ) introducing the dependence on ? h,dec . L VAE balances a reconstruction L rec and a prior-matching L prior penalties. For our MNIST experiments, we choose binary crossentropy (in pixel space) as the reconstruction loss, that we write below for a single example x</p><formula xml:id="formula_5">L rec (x, ? enc , ? dec ) = L xent x, f dec z, 1 t(x) , ? dec ,<label>(4)</label></formula><p>where L xent (t, y) = ? k t k log y k is the cross entropy. For a diagonal Gaussian p Z , the priormatching term can be evaluated analytically,</p><formula xml:id="formula_6">L prior = ? 1 2 |z| i=1 1 + log ? 2 i ? ? 2 i ? ? 2 i .<label>(5)</label></formula><p>Above, z is a sample from p Z (z; ?(x), ? 2 (x)) obtained via the reparameterization trick <ref type="bibr" target="#b24">(Kingma &amp; Welling, 2014;</ref><ref type="bibr" target="#b43">Rezende et al., 2014)</ref>. This introduces the dependency of L rec on ? enc .</p><p>Task inference network (HNET+TIR). In the HNET+TIR setup, we extend our system to include a task inference neural network classifier ?(x) parameterized by ? TI , where tasks are encoded with a T -dimensional softmax output layer. In both CL2 and CL3 scenarios we use a growing single-head setup for ?, and increase the dimensionality of the softmax layer as tasks arrive.</p><p>This network is prone to catastrophic forgetting when tasks are learned continually. To prevent this from happening we resort to replay data generated from a hypernetwork-protected VAE, described above. More specifically, we introduce a task inference loss,</p><formula xml:id="formula_7">L TI (x, ? TI ) = L xent (1 t(x) , ?(x, ? enc )),<label>(6)</label></formula><p>where t(x) denotes the correct task identity for a samplex from the augmented datasetX = {X (1) , . . .X (T ?1) ,X (T ) } withX <ref type="bibr">(t)</ref> being synthetic data f dec (z, 1 t , ? dec ) for t = 1 . . . T ? 1 and X (T ) = X (T ) is the current task data. Importantly, synthetic data is essential to obtain a well defined objective function for task inference; the cross-entropy loss L TI requires at least two groundtruth classes to be optimized. Note that replayed data can be generated online by drawing samples z from the prior. Hypernetwork-protected GANs. Generative adversarial networks <ref type="bibr" target="#b9">(Goodfellow et al., 2014)</ref> have become an established method for generative modelling and tend to produce higher quality images compared to VAEs, even at the scale of datasets as complex as ImageNet <ref type="bibr" target="#b3">(Brock et al., 2019;</ref><ref type="bibr" target="#b32">Lu?i? et al., 2019;</ref>. This makes GANs perfect candidates for powerful replay models. A suitable GAN instantiation for CL is the conditional GAN <ref type="bibr" target="#b39">(Mirza &amp; Osindero, 2014)</ref> as studied by <ref type="bibr" target="#b57">Wu et al. (2018)</ref>. Recent developments in the GAN literature already allude towards the potential of using hypernetwork-like structures, e.g., when injecting the latent noise <ref type="bibr" target="#b22">(Karras et al., 2019)</ref> or when using class-conditional batch-normalization as in <ref type="bibr" target="#b3">(Brock et al., 2019)</ref>. We propose to go one step further and use a hypernetwork that maps the condition to the full set of generator parameters ? * gen . Our framework allows training a conditional GAN one condition at the time. This is potentially of general interest, and goes beyond the scope of replay models, since conditional GANs trained in a mutli-task fashion as in <ref type="bibr" target="#b3">Brock et al. (2019)</ref> require very large computational resources.</p><formula xml:id="formula_8">a f dec f enc z task id x x (t) f h,dec (t) ? dec b f gen f disc x (t) f h,</formula><p>For our showcase experiment on class-incremental MNIST learning, <ref type="figure" target="#fig_8">Fig. A8</ref>, we did not aim to compare to related work and therefore did not tune to have less weights in the hypernetwork than on the target network (for the VAE experiments, we use the same compressive setup as in the main text, see Appendix C). The GAN hypernetwork is a fully-connected chunked hypernetwork with 2 hidden layers of size 25 and 25 followed by an output size of 75,000. We used learning rates for both discriminator and the generator hypernetwork of 0.0001, as well as dropout of 0.4 in the discriminator and the system is trained for 10000 iterations per task. We use the Pearson Chi 2 Least-Squares GAN loss from <ref type="bibr" target="#b35">Mao et al. (2017)</ref> in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C ADDITIONAL EXPERIMENTAL DETAILS</head><p>All experiments are conducted using 16 NVIDIA GeForce RTX 2080 TI graphics cards.</p><p>For simplicity, we decided to always keep the previous task embeddings e (t) , t = 1, . . . , T ? 1, fixed and only learn the current task embedding e <ref type="bibr">(T )</ref> . In general, performance should be improved if the regularizer in Eq. 2 has a separate copy of the task embeddings e (t, * ) from before learning the current task, such that e (t) can be adapted. Hence, the targets become f h (e (t, * ) , ? * h ) and remain constant while learning task T . This would give the hypernetwork the flexibility to adjust the embeddings i.e. the preimage of the targets and therefore represent any function that includes all desired targets in its image.</p><p>Nonlinear regression toy problem. The nonlinear toy regression from <ref type="figure" target="#fig_0">Fig. 2</ref> is an illustrative example for a continual learning problem where a set of ground-truth functions {g (1) , . . . , g (T ) } is given from which we collect 100 noisy training samples per task {(x, y) | y = g (t) (x) + with ? N (0, ? 2 I), x ? U(X (t) )}, where X (t) denotes the input domain of task t. We set ? = 0.05 in this experiment.</p><p>We perform 1D regression and choose the following set of tasks:</p><formula xml:id="formula_9">g (1) (x) = x + 3 X (1) = [?4, ?2] (7) g (2) (x) = 2x 2 ? 1 X (2) = [?1, 1] (8) g (3) (x) = (x ? 3) 3 X (3) = [2, 4]<label>(9)</label></formula><p>The target network f trgt consists of two fully-connected hidden layers using 10 neurons each. For illustrative purposes we use a full hypernetwork f h that generates all 141 weights of f trgt at once, also being a fully-connected network with two hidden-layers of size 10. Hence, this is the only setup where we did not explore the possibility of a chunked hypernetwork. We use sigmoid activation functions in both networks. The task embedding dimension was set to 2.</p><p>We train each task for 4000 iterations using the Adam optimizer with a learning rate of 0.01 (and otherwise default PyTorch options) and a batch size of 32.</p><p>To test our regularizer in <ref type="figure" target="#fig_0">Fig. 2a</ref> we set ? output to 0.005, while it is set to 0 for the fine-tuning experiment in <ref type="figure" target="#fig_0">Fig. 2c</ref>.</p><p>For the multi-task learner in <ref type="figure" target="#fig_0">Fig. 2b</ref> we trained only the target network (no hypernetwork) for 12000 iterations with a learning rate of 0.05. Comparable performance could be obtained when training the task-conditioned hypernetwork in this multi-task regime (data not shown).</p><p>It is worth noting that the multi-task learner from <ref type="figure" target="#fig_0">Fig. 2b</ref> that uses no hypernetwork is only able to learn the task since we choose the input domains to be non-overlapping.</p><p>Permuted MNIST benchmark. For our experiments conducted on MNIST we replicated the experimental setup proposed by van de Ven &amp; Tolias (2019) whenever applicable. We therefore use the same number of training iterations, the same or a lower number of weights in the hypernetwork than in the target network, the same learning rates and the same optimizer. For the replay model, i.e., the hypernetwork-empowered VAE, as well as for the standard classifier we used 5000 training iterations per task and learning rate is set to 0.0001 for the Adam optimizer (otherwise PyTorch default values). The batchsize is set to 128 for the VAE whereas the classifier is simultaneously trained on a batch of 128 samples of replayed data (evenly distributed over all past tasks) and a batch of 128 images from the currently available dataset. MNIST images are padded with zeros, which results in network inputs of size 32 ? 32, again strictly following the implementation of the compared work. We experienced better performance when we condition our replay model on a specific task input. We therefore construct for every task a specific input namely a sample from a standard multivariate normal of dimension 100. In practice we found the dimension to be not important. This input stays constant throughout the experiment and is not learned. Note that we use the same hyperparameters for all learning scenarios, which is not true for the reported related work since they have tuned special hyperparameters for all scenarios and all methods.</p><p>? Details of hypernetwork for the VAE. We use one hypernetwork configuration to generate weights for all variational autoencoders used for our PermutedMNIST-10 experiments namely a fully-connected chunked hypernetwork with 2 hidden layers of size 25 and 25 followed by an output size of 85,000. We use ELU nonlinearities in the hidden layers PermutedMNIST-100 during final <ref type="figure" target="#fig_0">Figure A2</ref>: Additional experiments on the PermutedMNIST-100 benchmark. (a) Final test set classification accuracy on the t-th task after learning one hundred permutations (PermutedMNIST-100). All runs use exactly the same hyperparameter configuration except for varying values of ? output . The final accuracies are robust for a wide range of regularization strengths. If ? output is too weak, forgetting will occur. However, there is no severe disadvantage of choosing ? output too high (cmp. (c)). A too high ? output simply shifts the attention of the optimizer away from the current task, leading to lower baseline accuracies when the training time is not increased. (b) Due to an increased number of output neurons, the target network for PermutedMNIST-100 has more weights than for PermutedMNIST-10 (this is only the case for CL1 and CL3). This plot shows that the performance drop is minor when choosing a hypernetwork with a comparable number of weights as the target network in CL2 (orange) compared to one that has a similar number of weights as the target network for CL1 in PermutedMNIST-100 (red). (c) Task-averaged test set accuracy after learning all tasks (labelled 'final', in red) and immediately after learning a task (labelled 'during', in purple) for the runs depicted in (a). For low values of ? output final accuracies are worse than immediate once (forgetting occurs). If ? output is too high, baseline accuracies decrease since the optimizer puts less emphasis on the current task (note that the training time per task is not increased). Shaded areas in (a) and (b) denote STD, whereas error bars in (c) denote SEM (always across 5 random seeds).</p><p>of the hypernetwork. The size of task embeddings e has been set to 24 and the size of chunk embeddings c to 8. The parameter ? output is 0.05 . The number of weights in this hypernetwork is 2,211,907 (2,211,691 network weights + 216 task embedding weights). The corresponding target network (and therefore output of the chunked hypernetwork), as taken from related work, has 2,227,024 weights.</p><p>? Details of the VAE for HNET+TIR. For this variational autoencoder, we use two fullyconnected neural networks with layers of size 1000, 1000 for the encoder and 1000, 1000 for the decoder and a latent space of 100. This setup is again copied from work we compare against.</p><p>? Details of the VAE for HNET+R. For this variational autoencoder, we use two fullyconnected neural networks with layers of size 400, 400 for the encoder and 400, 400 for the decoder (both 1000, 1000 in the related work) and a latent space of dimension 100. Here, we departure from related work by choosing a smaller architecture for the autoencoder. Note that we still use a hypernetwork with less trainable parameters than the target network (in this case the decoder) that is used in related work.</p><p>? Details of the hypernetwork for the target classifier in PermutedMNIST-10 (HNET+TIR &amp; HNET+ENT). We use the same setup for the hypernetwork as used for the VAEs above, but since the target network is smaller we reduce the output of the hypernetwork to 78,000. We also adjust the parameter ? output to 0.01, consistent with our PermutedMNIST-100 experiments. The number of weights in this hypernetwork is therefore 2,029,931 parameters (2,029,691 network weights + 240 task embedding weights). The corresponding target network (from related work) would have 2,126,100 weights for CL1 and CL3 and 2,036,010 for CL2 (only one output head).</p><p>? Details of the hypernetwork for the target classifier for PermutedMNIST-100. For these experiments we chose an architecture that worked well on the PermutedMNIST-10 benchmark and did not conduct any more search for new architectures. For PermutedMNIST-100, the reported results were obtained by using a chunked hypernetwork with 3 hidden layers of size 200, 250 and 350 (300 for CL2) and an output size of 7500 (6000 for CL2) (such that we approximately match the corresponding target network size for CL1/CL2/CL3). Interestingly, <ref type="figure" target="#fig_0">Fig. A2b</ref> shows that even if we don't adjust the number of hypernetwork weights to the increased number of target network weights, the superiority of our method is evident. Aside from this, the plots in <ref type="figure">Fig. 3</ref> have been generated using the PermutedMNIST-10 HNET+TIR setup (note that this includes the conditions set by related work for PermutedMNIST-10, e.g., target network sizes, the number of training iterations, learning rates, etc.).</p><p>? Details of the VAE and the hypernetwork for the VAE in PermutedMNIST-100 for CL2/CL3. We use a very similar setup for the VAE and it's hypernetwork used in HNET+TIR for PermutedMNIST-10 as described above. We only applied the following changes: Fully-connected hypernetwork with one hidden layer of size 100; chunk embedding sizes are set to 12; task embedding sizes are set two 128 and the hidden layer sizes of the VAE its generator are 400, 600. Also we increased the regularisation strength ? output = 0.1 for the VAE its generator hypernetwork.</p><p>? Details of the target classifier for HNET+TIR &amp; HNET+ENT. For this classifier, we use the same setup as in the study we compare to (van de Ven &amp; Tolias, 2019), i.e., a fully-connected network with layers of size 1000, 1000. Note that if the classifier is used as a task inference model, it is trained on replay data and the corresponding hard targets, i.e., the argmax of the soft targets.</p><p>Below, we report the specifications for our automatic hyperparameter search (if not noted otherwise, these specifications apply for the split MNIST and split CIFAR experiments as well):</p><p>? Hidden layer sizes of the hypernetwork: (no hidden layer), "5,5" "10,10", "25,25", "50,50", "100,100", "10", "50", "100"</p><p>? Output size of the hypernetwork: fitted such that we obtain less parameters then the target network which we compare against</p><p>? Embedding sizes (for e and c): <ref type="bibr">8,</ref><ref type="bibr">12,</ref><ref type="bibr">24,</ref><ref type="bibr">36,</ref><ref type="bibr">62,</ref><ref type="bibr">96,</ref><ref type="bibr">128</ref> ? ? output : 0.0005, 0.001, 0.005, 0.01, 0.005, 0.1, 0.5, 1.0</p><p>? Hypernetwork transfer functions: linear, ReLU, ELU, Leaky-ReLU Note that only a random subset of all possible combinations of hyperparameters has been explored.</p><p>After we found a configuration with promising accuracies and a similar number of weights compared to the original target network, we manually fine-tuned the architecture to increase/decrease the number of hypernetwork weights to approximately match the number of target network weights.</p><p>The choice of hypernetwork architecture seems to have a strong influence on the performance. It might be worth exploring alternatives, e.g., an architecture inspired by those used in typical generative models. We note that in addition to the above specifications we explored manually some hyperparameter configurations to gain a better understanding of our method.</p><p>Split MNIST benchmark. Again, whenever applicable we reproduce the setup from van de <ref type="bibr" target="#b56">Ven &amp; Tolias (2019)</ref>. Differences to the PermutedMNIST-10 experiments are just the learning rate (0.001) and the number of training iterations (set to 2000).</p><p>? Details of hypernetwork for the VAE. We use one hypernetwork configuration to generate weights for all variational autoencoders used for our split MNIST experiments, namely a fully-connected chunked hypernetwork with 2 hidden layers of size 10, 10 followed by an output size of 50,000. We use ELU nonlinearities in the hidden layers of the hypernetwork. The size of task embeddings e has been set to 96 and the size of chunk embeddings c to 96. The parameter ? output is 0.01 for HNET+R and 0.05 for HNET+TIR . The number of weights in this hypernetwork is 553,576 (553,192 network weights + 384 task embedding weights). The corresponding target network (and therefore output of the chunked hypernetwork), as taken from related work, has 555,184 weights. For a qualitative analyses of the replay data of this VAE (class incrementally learned), see A8.</p><p>? Details of the VAE for HNET+TIR. For this variational autoencoder, we use two fullyconnected neural networks with layers of size 400, 400 for the encoder and 50, 150 for the decoder (both 400, 400 in the related work) and a latent space of dimension 100.</p><p>? Details of the VAE for HNET+R. For this variational autoencoder, we use two fullyconnected neural networks with layers of size 400, 400 for the encoder and 250, 350 for the decoder (both 400, 400 in the related work) and a latent space of dimension 100.</p><p>? Details of the hypernetwork for the target classifier in split MNIST (HNET+TIR &amp; HNET+ENT). We use the same setup for the hypernetwork as used for the VAE above, but since the target network is smaller we reduce the output of the hypernetwork to 42,000. We also adjust the ? output to 0.01 although this parameter seems to not have a strong effect on the performance. The number of weights in this hypernetwork is therefore 465,672 parameters (465,192 network weights + 480 task embedding weights). The corresponding target network (from related work) would have 478,410 weights for CL1 and CL3 and 475,202 for CL2 (only one output head).</p><p>? Details of the target classifier for HNET+TIR &amp; HNET+ENT. For this classifier, we again use the same setup as in the study we compare to (van de Ven &amp; Tolias, 2019), i.e., a fully-connected neural networks with layers of size 400, 400. Note that if the classifier is used as a task inference model, it is trained on replay data and the corresponding hard targets, i.e., the argmax the soft targets.</p><p>Split CIFAR-10/100 benchmark. For these experiments, we used as a target network a ResNet-32 network <ref type="bibr" target="#b13">(He et al. (2016)</ref>) and again produce the weights of this target network by a hypernetwork in a compressive manner. The hypernetwork in this experiment directly maps from the joint task and chunk embedding space (both dimension 32) to the output space of the hypernetwork, which is of dimension 7,000. This hypernetwork has 457,336 parameters (457,144 network weights + 192 task embedding weights). The corresponding target network, the ResNet-32, has 468.540 weights (including batch-norm weights). We train for 200 epochs per task using the Adam optimizer with an initial learning rate of 0.001 (and otherwise default PyTorch values) and a batch size of 32. In addition, we apply the two learning rate schedules suggested in the Keras CIFAR-10 example 2 .</p><p>Due to the use of batch normalization, we have to find an appropriate way to handle the running statistics which are estimated during training. Note, these are not parameters which are trained through backpropagation. There are different ways how the running statistics could be treated:</p><p>1. One could ignore the running statistics altogether and simply compute statistics based on the current batch during evaluation.</p><p>2. The statistics could be part of the hypernetwork output. Therefore, one would have to manipulate the target hypernetwork output of the previous task, such that the estimated running statistics of the previous task will be distilled into the hypernetwork.</p><p>3. The running statistics can simply be checkpointed and stored after every task. Note, this method would lead to a linear memory growth in the number of tasks that scales with the number of units in the target network.</p><p>For simplicity, we chose the last option and simply checkpointed the running statistics after every task.</p><p>For the fine-tuning results in <ref type="figure">Fig. 5</ref> we just continually updated the running statistics (thus, we applied no checkpointing).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D ADDITIONAL EXPERIMENTS AND NOTES</head><p>Split CIFAR-10/100 benchmark using the model of <ref type="bibr" target="#b58">Zenke et al. (2017)</ref>. We re-run the split CIFAR-10/100 experiment reported on the main text while reproducing the setup from <ref type="bibr" target="#b58">Zenke et al. (2017)</ref>. Our overall classification performance is comparable to synaptic intelligence, which achieves 73.85% task-averaged test set accuracy, while our method reaches 71.29% ? 0.32%, with initial baseline performance being slightly worse in our approach, <ref type="figure">Fig. A3</ref>.  <ref type="figure">Figure A3</ref>: Replication of the split CIFAR-10/100 experiment of <ref type="bibr" target="#b58">Zenke et al. (2017)</ref>. Test set accuracies on the entire CIFAR-10 dataset and subsequent CIFAR-100 splits. Both task-conditioned hypernetworks (hnet, in red) and synaptic intelligence (SI, in green) transfer information forward and are protected from catastrophic forgetting. The performance of the two methods is comparable. For completeness, we report our test set accuracies achieved immediately after training (hnet-during, in blue), when training from scratch (purple), and with our regularizer turned off (fine-tuning, yellow).</p><p>To obtain our results, we use a hypernetwork with 3 hidden-layers of sizes 100, 150, 200 and output size 5500. The size of task embeddings e has been set to 48 and the size of chunk embeddings c to 80. The parameter ? output is 0.01 and the learning rate is set to 0.0001.</p><p>The number of weights in this hypernetwork is 1,182,678 (1,182,390 network weights + 288 task embedding weights). The corresponding target network would have 1,276,508 weights.</p><p>In addition to the above specified hyperparameter search configuration we also included the following learning rates: 0.0001, 0.0005, 0.001 and manually tuned some architectural parameters. PermutedMNIST-100 -CL3 HNET+TIR SI DGR+distill Online EWC <ref type="figure" target="#fig_1">Figure A4</ref>: Context-free inference using hypernetwork-protected replay (HNET+TIR) on long task sequences. Final test set classification accuracy on the t-th task after learning one hundred permutations of the MNIST dataset (PermutedMNIST-100) for the CL2 (a) and CL3 (b) scenarios, where task identity is not explicitly provided to the system. As before, the number of hypernetwork parameters is not larger than that of the related work we compare to. (a) HNET+TIR displays almost perfect memory retention. We used a stochastic regularizer (cf. Appendix D note below) which evaluates the output regularizer in Eq. 2 only for a random subset of previous tasks (here, twenty).</p><p>(b) HNET+TIR is the only method that is capable of learning PermutedMNIST-100 in this learning scenario. For this benchmark, the input data domains are easily separable and the task inference system achieves virtually perfect (~100%) task inference accuracy throughout, even for this long experiment. HNET+TIR uses a divide-and-conquer strategy: if task inference is done right, CL3 becomes just CL1. Furthermore, once task identity is predicted, the final softmax computation only needs to consider the corresponding task outputs in isolation (here, of size 10). Curiously, for HNET+TIR, CL2 can be harder than CL3 as the single output layer (of size 10, shared by all tasks) introduces a capacity bottleneck. The related methods, on the other hand, have to consider the entire output layer (here, of size 10*100) at once, which is known to be harder to train sequentially. This leads to overwhelming error rates on long problems such as PermutedMNIST-100. Shaded areas in (a) and (b) denote STD (n = 5).</p><p>Upper bound for replay models. We obtain an upper bound for the replay-based experiments <ref type="table" target="#tab_5">(Table 2)</ref> by sequentially training a classifier, in the same way as for HNET+R and DGR, now using true input data from past tasks and a synthetic, self-generated target. This corresponds to the rehearsal thought experiment delineated in Sect. 1. Quantification of forgetting in our continual learning experiments. In order to quantify forgetting of our approach, we compare test set accuracies of every single task directly after training with it's test set accuracy after training on all tasks.</p><p>Only CL1 is shown since other scenarios i.e. CL2 and CL3 depend on task inference which only is measurable after training on all tasks.   Robustness of ? output -choice. In <ref type="figure" target="#fig_0">Fig. A2a</ref> and <ref type="figure" target="#fig_0">Fig. A2c</ref> we provide additional experiments for our method on PermutedMNIST-100. We show that our method performs comparable for a wide range of ? output -values (including the one depicted in <ref type="figure">Fig. 3a)</ref>. PermutedMNIST-100 during final <ref type="figure">Figure A5</ref>: Additional experiments with online EWC and fine-tuning on the PermutedMNIST-100 benchmark. (a) Final test set classification accuracy on the t-th task after learning one hundred permutations (PermutedMNIST-100) using the online EWC algorithm  to prevent forgetting. All runs use exactly the same hyperparameter configuration except for varying values of the regularization strength ?. Our method (hnet, in red) and the online EWC run (? = 100, in orange) from <ref type="figure">Fig. 3a</ref> are shown for comparison. It can be seen that even when tuning the regularization strength one cannot attain similar performance as with our approach (cmp. <ref type="figure" target="#fig_0">Fig. A2a</ref>). Too strong regularization prevents the learning of new tasks whereas too weak regularization doesn't prevent forgetting. However, a middle ground (e.g., using ? = 100) does not reach acceptable per-task performances. (b) Task-averaged test set accuracy after learning all tasks (labelled 'final', in red) and immediately after learning a task (labelled 'during', in purple) for a range of regularization strengths ? when using the online EWC algorithm. Results are complementary to those shown in (a). (c) Final test set classification accuracy on the t-th task after learning one hundred permutations (PermutedMNIST-100) when applying fine-tuning to the hypernetwork (labelled 'hnet fine-tuning', in blue) or target network (labelled 'fine-tuning', in green). Our method (hnet, in red) from <ref type="figure">Fig. 3a</ref> is shown for comparison. It can be seen that without protection the hypernetwork suffers much more severely from catastrophic forgetting as when training a target network only. Varying the regularization strength for online EWC. The performance of online EWC in <ref type="figure">Fig. 3a</ref> is closest to our method (labelled hnet, in red) compared to the other methods. Therefore, we take a closer look at this method and show that further adjustments of the regularization strength ? do not lead to better performance. Results for a wide range of regularization strengths can be seen in <ref type="figure">Fig. A5a and Fig. A5b</ref>. As shown, online EWC cannot attain a performance comparable to our method when tuning the regularization strength only.</p><p>The impact of catastrophic forgetting on the hypernetwork and target network. We have successfully shown that by shifting the continual learning problem from the target network to the hypernetwork we can successfully overcome forgetting due to the introduction of our regularizer in Eq. 2. We motivated this success by claiming that it is an inherently simpler task to remember a few input-output mappings in the hypernetwork (namely the weight realizations of each task) rather than the massive number of input-output mappings {(x (t,i) , y (t,i) )} nt i=1 associated with the remembering of each task t by the target network.</p><p>Further evidence of this claim is provided by fine-tuning experiments in <ref type="figure">Fig. A5c and Fig. A5d</ref>. Fine-tuning refers to sequentially learning a neural network on a set of tasks without any mechanism in place to prevent forgetting. It is shown that fine-tuning a target network (no hypernetwork in this setup) has no catastrophic influence on the performance of previous tasks. Instead there is a graceful decline in performance. On the contrary, catastrophic forgetting has an almost immediate affect when training a hypernetwork without protection (i.e., training our method with ? output = 0. The performance quickly drops to chance level, suggesting that if we weren't solving a simpler task then preventing forgetting in the hypernetwork rather than in the target network might not be beneficial.</p><p>Chunking and hypernetwork architecture sensitivity. In this note we investigate the performance sensitivity for different (fully-connected) hypernetwork architectures on split MNIST and PermutedMNIST-10, <ref type="figure" target="#fig_7">Fig. A7</ref>. We trained thousands of randomly drawn architectures from the following grid (the same training hyperparameters as reported for for CL1, see Appendix C, were used throughout): possible number of hidden layers 1, 2, possible layer size 5, 10, 20, . . . , 90, 100, possible chunk embedding size 8, 12, 24, 56, 96 and hypernetwork output size in <ref type="bibr">{10, 50, 100, 200, 300, 400, 500, 750, 1k, 2k, . . . , 9k, 10k, 20k, 30k, 40k}</ref>. Since we realize compression through chunking, we sort our hypernetwork architectures by compression ratio, and consider only architectures with small compression ratios.</p><p>Performance of split MNIST stays in the high 90 percentages even when reaching compression ratios close to 1% whereas for PermutedMNIST-10 accuracies decline in a non-linear fashion. For both experiments, the choice of the chunked hypernetwork archicture is robust and high performing even in  the compressive regime. Note that the discussed compression ratio compares the amount of trainable parameters in the hypernetwork to its output size, i.e. the parameters of the target network.</p><p>Small capacity target networks for the permuted MNIST benchmark. <ref type="bibr" target="#b54">Swaroop et al. (2018)</ref> argue for using only small capacity target networks for this benchmark. Specifically, they propose to use hidden layer sizes [100, 100]. Again, we replicated the setup of van de Ven &amp; Tolias (2019) wherever applicable, except for the now smaller hidden layer sizes of [100, 100] in the target network. We use a fully-connected chunked hypernetwork with chunk embeddings c having size 12, hidden layers having size 100, 75, 50 and an output size of 2000, resulting in a total number of hypernetwork weights of 122,459 (including 10 ? 64 task embedding weights) compared to 122,700 weights that are generated for the target network. ? output is set to 0.05. The experiments performed here correspond to CL1.</p><p>We achieve an average accuracy of 93.91 ? 0.04 for PermutedMNIST-10 after having trained on all tasks. In general, we saw that the hypernetwork training can benefit from noise injection. For instance, when training with soft-targets (i.e., we modified the 1-hot target to be 0.95 for the correct class and 1?0.95 # classes?1 for the remaining classes), we could improve the average accuracy to 94.24 ? 0.03.</p><p>We also checked the challenging PermutedMNIST-50 benchmark with this small target network as previously investigated by <ref type="bibr" target="#b45">Ritter et al. (2018)</ref>. Therefore, we slightly adapted the above setup by using a hypernetwork with hidden layer sizes [100, 100] and a regularization strength of ? output = 0.1. This hypernetwork is slightly bigger than the corresponding target network |?h?{e (t) }| |?trgt| = 1.37. With this configuration, we obtain an average accuracy of 90.91 ? 0.07.</p><p>Comparison to HAT. <ref type="bibr" target="#b51">Serra et al. (2018)</ref> proposed the hard attention to the task (HAT) algorithm, a strong CL1 method which relies on learning a per-task, per-neuron mask. Since the masks are pushed to become binary, HAT can be viewed as an algorithm for allocating subnetworks (or modules) within the target network, which become specialized to solve a given task. Thus, the method is similar to ours in the sense that the computation of the target network is task-dependent, but different in spirit, as it relies on network modularity.</p><p>In HAT, task identity is assumed to be provided, so that the appropriate mask can be picked during inference (scenario CL1). HAT requires explicitly storing a neural mask for each task, whose size scales with the number of neurons in the target network. In contrast, our method allows solving tasks in a compressive regime. Thanks to the hypernetwork, whose input dimension can be freely chosen, only a low-dimensional embedding needs to be stored per task (cf. <ref type="figure" target="#fig_1">Fig. 4)</ref>, and through chunking it is possible to learn to parameterize large target models with a small number of plastic weights (cf. <ref type="figure">Fig. 3b</ref>).</p><p>Here, we compare our task-conditioned hypernetworks to HAT on the permuted MNIST benchmarks (T = 10 and T = 100), cf. <ref type="table" target="#tab_10">Table 6</ref>. For large target networks, both methods perform strongly, reaching comparable final task-averaged accuracies. For small target network sizes, task-conditioned hypernetworks perform better, the difference becoming more apparent on PermutedMNIST-100.</p><p>We note that the two algorithms use different training setups. In particular, HAT uses 200 epochs (batch size set to 64) and applies a learning rate scheduler that acts on a held out validation set. Furthermore, HAT uses differently tuned forgetting hyperparameters when target network sizes change. This is important to control for the target network capacity used per task and assumes knowledge of the (number of) tasks at hand. Using the code freely made available by the authors, we were able to rerun HAT for our target network size and longer task sequences. Here, we used the setup provided by the author's code for HAT-Large for PermutedMNIST-10 and PermutedMNIST-100. To draw a fairer comparison, when changing our usual target network size to match the ones reported in <ref type="bibr" target="#b51">Serra et al. (2018)</ref>, we trained for 50 epochs per task (no training loss improvements afterwards observed) and also changed the batch size to 64 but did not changed our training scheme otherwise; in particular, we did not use a learning rate scheduler.  <ref type="bibr" target="#b51">Serra et al. (2018)</ref>. Task-averaged test accuracy on the PermutedMNIST experiment with T = 10 and T = 100 tasks ('P10', 'P100') with three different target network sizes, i.e., three fully connected neural networks with hidden layer sizes of (100, 100) or (500, 500) or <ref type="bibr">(2000,</ref><ref type="bibr">2000)</ref> are shown. For these architectures, a single accuracy was reported by <ref type="bibr" target="#b51">Serra et al. (2018)</ref> without statistics provided. We reran HAT for PermutedMNIST-100 with code provided at https://github.com/joansj/hat, and for PermutedMNIST-10 with hidden layer size (1000, 1000) to match our setup. HAT and HNET perform similarly on large target networks for PermutedMNIST-10, while HNET is able to achieve larger performances with smaller target networks as well as for long task sequences. Efficient PermutedMNIST-250 experiments with a stochastic regularizer on subsets of previous tasks. An apparent drawback of Eq. 2 is that the runtime complexity of the regularizer grows linearly with the number of tasks. To overcome this obstacle, we show here that it is sufficient to consider a small random subset of previous tasks.</p><p>In particular, we consider the PermutedMNIST-250 benchmark (250 tasks) on CL1 using the hyperparameter setup from our PermutedMNIST-100 experiments except for a hypernetwork output size of 12000 (to adjust to the bigger multi-head target network) and a regularization strength ? output = 0.1. Per training iteration, we choose maximally 32 random previous tasks to estimate the regularizer from Eq. 2. With this setup, we achieve a final average accuracy of 94.19 ? 0.16 (compared to an average during accuracy (i.e., the accuracies achieved right after training on the corresponding task) of 95.54 ? 0.05). All results are across 5 random seeds. These results indicate that a full evaluation of the regularizer at every training iteration is not necessary such that the linear runtime complexity can be cropped to a constant one.</p><p>Combining hypernetwork output regularizers with weight importance. Our hypernetwork regularizer pulls uniformly in every direction, but it is possible to introduce anisotropy using an EWC-like approach <ref type="bibr" target="#b25">(Kirkpatrick et al., 2017)</ref>. Instead of weighting parameters, hypernetwork outputs can be weighted. This would allow for a more flexible regularizer, at the expense of additional storage.</p><p>of the UAT again: Given the compact K ? R n , the discrete set C = {c 1 , . . . , c NC } and any 2NC &gt; 0, there exists a neural network function f c h : R m ? R s ? R r such that</p><formula xml:id="formula_10">|f c h (x, c) ?f h (x, c)| &lt; 2N C , ?x ? K, ?c ? C.<label>(13)</label></formula><p>It follows that</p><formula xml:id="formula_11">i |f c h (x, c i ) ?f h (x, c i )| &lt; i 2N C = 2 , ?x ? K,<label>(14)</label></formula><p>which is equivalent to</p><formula xml:id="formula_12">| ? ? ? f c h (x, c 1 ) . . . f c h (x, c NC ) ? ? ? ? ? ? ?f h (x, c 1 ) . . . f h (x, c NC ) ? ? ? | = |f c h (x) ? f h (x)| &lt; 2 , ?x ? K.<label>(15)</label></formula><p>We have shown (11) which concludes the proof.</p><p>Note that we did not specify the number of chunks N C , r or the dimension s of the embeddings c i . Despite this theoretical result, we emphasize that we are not aware of a constructive procedure to define a chunked hypernetwork that comes with a useful bound on the achievable performance and/or compression rate. We evaluate such aspects empirically in our experimental section. In both cases the weights of the generative part, i.e., the decoder or the generator, are produced and protected by a hypernetwork.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>1D nonlinear regression. (a) Task-conditioned hypernetworks with output regularization can easily model a sequence of polynomials of increasing degree, while learning in a continual fashion. (b) The solution found by a target network which is trained directly on all tasks simultaneously is similar. (c) Fine-tuning, i.e., learning sequentially, leads to forgetting of past tasks. Dashed lines depict ground truth, markers show model predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Two-dimensional task embedding space for the split MNIST benchmark.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure A1 :</head><label>A1</label><figDesc>Hypernetwork-protected replay model setups. (a) A hypernetwork-protected VAE, that we used for HNET+R and HNET+TIR main text experiments. (b) A hypernetwork-protected GAN, that we used for our class-incremental learning Appendix F experiments. (c) A task inference classifier protected with synthetic replay data, used on HNET+TIR experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>128) ? 200 ? 250 ? 350 ? 7500, ? output = 0.01 (12 + 128) ? 200 ? 250 ? 300 ? 6000, ? output = 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure A6 :</head><label>A6</label><figDesc>(d)  This plot is complementary to(c). See description of (b) for an explanation of the labels. Shaded areas in (a) and (c) denote STD, whereas error bars in (b) and (d) denote SEM (always across 5 random seeds). Hyperparameter search for online EWC and SI on the PermutedMNIST-100 benchmark. We conduct the same hyperparameter search as performed in van de Ven &amp; Tolias (2018). We did not compute different random seeds for this search. (a) Hyperparameter search on the regularisation strength c for the SI algorithm. Accuracies during and after the experiment are shown. (b) Hyperparameter search for parameters ? and ? of the online EWC algorithm. Only accuracies after the experiment are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure A7 :</head><label>A7</label><figDesc>Robustness to hypernetwork architecture choice for a large range of compression ratios. Performance vs. compression for random hypernetwork architecture choices, for split MNIST and PermutedMNIST-10 (mean ? STD, n = 500 architectures per bin</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>FFigure A8 :</head><label>A8</label><figDesc>Image samples from hypernetwork-protected replay models. The left column of both of the subfigures display images directly after training the replay model on the corresponding class, compared to the right column(s) where samples are obtained after training on eights and nines i.e. all classes. (a) Image samples from a class-incrementally trained VAE. Here the exact same training configuration to obtain results for split MNIST with the HNET+R setup are used, see Appendix C. (b) Image samples from a class-incrementally trained GAN. For the training configurations, see Appendix B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>are overperformed on CL3 by a large margin. When complemented with generative replay</figDesc><table><row><cell>a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>b</cell></row><row><cell></cell><cell>100</cell><cell></cell><cell cols="2">PermutedMNIST-100</cell><cell></cell><cell>100</cell><cell>Compression-performance trade-off</cell></row><row><cell>Accuracy [%]</cell><cell>25 50 75</cell><cell>96.78%</cell><cell></cell><cell>95.66%</cell><cell>Accuracy [%]</cell><cell>40 60 80</cell></row><row><cell></cell><cell></cell><cell>1</cell><cell>50</cell><cell>100</cell><cell></cell><cell>0.0</cell><cell>0.5</cell><cell>1.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Task t</cell><cell></cell><cell></cell><cell>Compression ratio</cell></row><row><cell></cell><cell>hnet</cell><cell>SI</cell><cell>DGR+distill</cell><cell>Online EWC</cell><cell></cell><cell>during</cell><cell>final</cell></row><row><cell cols="7">Figure 3: Experiments on the permuted MNIST benchmark. (a) Final test set classification</cell></row><row><cell cols="7">accuracy on the t-th task after learning one hundred permutations (PermutedMNIST-100). Task-</cell></row><row><cell cols="7">conditioned hypernetworks (hnet, in red) achieve very large memory lifetimes on the permuted</cell></row><row><cell cols="7">MNIST benchmark. Synaptic intelligence (SI, in blue; Zenke et al., 2017), online EWC (in orange;</cell></row><row><cell cols="7">Schwarz et al., 2018) and deep generative replay (DGR+distill, in green; Shin et al., 2017) methods are</cell></row><row><cell cols="7">shown for comparison. Memory retention in SI and DGR+distill degrade gracefully, whereas EWC</cell></row><row><cell cols="7">suffers from rigidity and can never reach very high accuracy, even though memories persist for the</cell></row><row><cell cols="7">entire experiment duration. (b) Compression ratio |?h?{e (t) }| |?trgt|</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>CL1 95.96 ? 0.06 94.75 ? 0.14 97.51 ? 0.01 97.57 ? 0.02 97.57 ? 0.02 97.87 ? 0.01 P10-CL2 94.42 ? 0.13 95.33 ? 0.11 97.35 ? 0.02 92.80 ? 0.15 97.58 ? 0.02 97.60 ? 0.01 P10-CL3 33.88 ? 0.49 29.31 ? 0.62 96.38 ? 0.03 91.75 ? 0.21 97.59 ? 0.01 97.76 ? 0.01 S-CL1 99.12 ? 0.11 99.09 ? 0.15 99.61 ? 0.02 99.79 ? 0.01 99.79 ? 0.01 99.83 ? 0.01 S-CL2 64.32 ? 1.90 65.36 ? 1.57 96.83 ? 0.20 87.01 ? 0.47 94.43 ? 0.28 98.00 ? 0.03 S-CL3 19.96 ? 0.07 19.99 ? 0.06 91.79 ? 0.32 69.48 ? 0.80 89.59 ? 0.59 95.30 ? 0.13</figDesc><table><row><cell>EWC</cell><cell>SI</cell><cell>DGR</cell><cell>HNET+ENT HNET+TIR HNET+R</cell></row><row><cell>P10-</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Task-averaged test accuracy (? SEM, n = 20) on the permuted ('P10') and split ('S') MNIST experiments. For HNET+R and DGR+distill (van de Ven &amp; Tolias, 2019) the classification network is trained sequentially on data from the current task and replayed data from all previous tasks. Our HNET+R comes close to saturating the corresponding replay upper bound RPL-UB.</figDesc><table><row><cell></cell><cell>DGR</cell><cell>HNET+R</cell><cell>RPL-UB</cell></row><row><cell cols="4">P10-CL1 97.51 ? 0.01 97.85 ? 0.02 97.89 ? 0.02</cell></row><row><cell cols="4">P10-CL2 97.35 ? 0.02 97.60 ? 0.02 97.72 ? 0.01</cell></row><row><cell cols="4">P10-CL3 96.38 ? 0.03 97.71 ? 0.06 97.91 ? 0.01</cell></row><row><cell>S-CL1</cell><cell cols="3">99.61 ? 0.02 99.81 ? 0.01 99.83 ? 0.01</cell></row><row><cell>S-CL2</cell><cell cols="3">96.83 ? 0.20 97.88 ? 0.05 98.96 ? 0.03</cell></row><row><cell>S-CL3</cell><cell cols="3">91.79 ? 0.32 94.97 ? 0.18 98.38 ? 0.02</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="5">: Task-averaged test accuracy (? SEM, n = 20) on the permutedMNIST-10 ('P10') and</cell></row><row><cell cols="3">splitMNIST ('S') experiments during and after training.</cell><cell></cell></row><row><cell></cell><cell>HNET+TIR</cell><cell>HNET+TIR</cell><cell>HNET+R</cell><cell>HNET+R</cell></row><row><cell></cell><cell>during</cell><cell>after</cell><cell>during</cell><cell>after</cell></row><row><cell>S-CL1</cell><cell cols="4">99.79 ? 0.01 99.79 ? 0.01 99.82 ? 0.01 99.83 ? 0.01</cell></row><row><cell cols="5">P10-CL1 97.58 ? 0.02 97.57 ? 0.02 98.03 ? 0.01 97.87 ? 0.01</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="3">: Task-averaged test accuracy (? SEM, n = 5) on the permutedMNIST-100 ('P100')</cell></row><row><cell>experiments during and after training.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>HNET+TIR</cell><cell>HNET+TIR</cell></row><row><cell></cell><cell>during</cell><cell>after</cell></row><row><cell cols="3">P100-CL1 96.12 ? 0.08 96.18 ? 0.09</cell></row><row><cell>P100-CL2</cell><cell>-</cell><cell>95.97 ? 0.05</cell></row><row><cell>P100-CL3</cell><cell>-</cell><cell>96.00 ? 0.03</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Task-averaged test accuracy (? SEM, n = 5) on split CIFAR-10/100 on CL1 on two different target network architectures.</figDesc><table><row><cell>during</cell><cell>after</cell></row><row><cell cols="2">ZenkeNet 74.75 ? 0.09 71.29 ? 0.32</cell></row><row><cell cols="2">ResNet-32 82.36 ? 0.44 82.34 ? 0.44</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>). Every model was trained with the same setup (including all hyperparameters) used to obtain results reported in Table 1 (CL1). We considered architectures yielding compression ratios |? h ? {e (t) }|/|? trgt | ? [0.01, 2.0] (a) split MNIST performance for CL1 stays high even for compression ratios ? 1%. (b) PermutedMNIST-10 accuracies degrade gracefully when compression ratios decline to 1%. Notably, for both benchmarks, performance remained stable across a large pool of hypernetwork configurations.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Comparison of HNET and HAT,</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>,1000 97.67 ? 0.02 97.56 ? 0.02 P100-1000,1000 86.04 ? 0.26 94.98 ? 0.07</figDesc><table><row><cell></cell><cell>HAT</cell><cell>HNET</cell></row><row><cell>P10-100,100</cell><cell>91.6</cell><cell>95.92 ? 0.02</cell></row><row><cell>P10-500,500</cell><cell>97.4</cell><cell>97.35 ? 0.02</cell></row><row><cell cols="2">P10-2000,2000 98.6</cell><cell>98.06 ? 0.02</cell></row><row><cell>P10-1000</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Source code is available under https://github.com/chrhenning/hypercl.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">See https://keras.io/examples/cifar10_resnet/.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Task inference through predictive entropy <ref type="bibr">(HNET+ENT)</ref>. In this setup, we rely on the capability of neural networks to separate in-from out-of-distribution data. Although this is a difficult research problem on its own, for continual learning, we face a potentially simpler problem, namely to detect and distinguish between the tasks our network was trained on. We here take the first minimal step exploiting this insight and compare the predictive uncertainty, as quantified by output distribution entropy, of the different models given an input. Hence, during test time we iterate over all embeddings and therefore the models our metamodel can generate and compare the predictive entropies which results in making a prediction with the model of lowest entropy. For future work, we wish to explore the possibility of improving our predictive uncertainty by taking parameter uncertainty into account through the generation of approximate, task-specific weight posterior distributions.</p><p>Learning without task boundaries with hypernetworks. An interesting problem we did not address in this paper is that of learning without task boundaries. For most CL methods, it is crucial to know when learning one task ends and training of a new tasks begins. This is no exception for the methods introduced in this paper. However, this is not necessarily a realistic or desirable assumption; often, one desires to learn in an online fashion without task boundary supervision, which is particularly relevant for reinforcement learning scenarios where incoming data distributions are frequently subject to change . At least for discrete changes, with our hypernetwork setup, this boils down to a detection mechanism that activates the saving of the current model, i.e., the embedding e (T ) , and its storage to the collection of embeddings {e (t) }. We leave the integration of our model with such a hypernetwork-specific switching detection mechanism for future work. Interestingly, our task-conditioned hypernetworks would fit very well with methods that rely on fast remembering (a recently proposed approach which appeared in parallel to our paper, <ref type="bibr" target="#b15">He et al., 2019</ref>). For the following proof, we assume the existence of one form of the universal approximation theorem (UAT) for neural networks <ref type="bibr" target="#b28">(Leshno &amp; Schocken, 1993;</ref><ref type="bibr" target="#b11">Hanin, 2017)</ref>. Note that we will not restrict ourselves to a specific architecture, nonlinearity, input or output dimension. Any neural network that is proven to be a universal function approximator is sufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E UNIVERSAL FUNCTION APPROXIMATION WITH CHUNKED NEURAL</head><p>Proof. Given any &gt; 0, we assume the existence of a neural network f h : R m ? R n that approximates function f on K:</p><p>We will in the following show that we can always find a chunked neural network f c h : R m ? C ? R r approximating the neural network f h on K and conclude with the triangle inequality</p><p>Indeed, given the neural network f h such that (10) holds true, we construct Note thatf h is continuous on R m ? C with the product topology composed of the topology on R m induced by the metric | ? ? ? | : R m ? R m ? R and the discrete topology on C. Now we can make use</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Measuring and regularizing networks in function space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><forename type="middle">S</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rolnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konrad</forename><surname>Kording</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08289</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning feedforward one-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Valmadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="523" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Normative Theory of Forgetting: Lessons from the Fruit Fly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johanni</forename><surname>Brea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Urbanczik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Senn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1003640</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Large scale GAN training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Self-net: Lifelong learning via continual self-modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Blake</forename><surname>Camp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><surname>Jaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rolando</forename><surname>Mandivarapu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Estrada</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10354</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Large scale adversarial representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02544</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Farquhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.09733</idno>
		<title level="m">Towards robust evaluations of continual learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisantha</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Banarse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yori</forename><surname>Zwols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pathnet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.08734</idno>
		<title level="m">Evolution channels gradient descent in super neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Catastrophic forgetting in connectionist networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">M</forename><surname>French</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="128" to="135" />
			<date type="published" when="1999-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hypernetworks</surname></persName>
		</author>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Universal Function Approximation by Deep Neural Nets with Bounded Width and ReLU Activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Hanin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02691</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Demis</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dharshan</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Summerfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience-Inspired Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="258" />
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
	<note>Neuron</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic interference using conceptor-aided backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Task agnostic continual learning via meta learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Xu He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Galashov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pascanu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05201</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">A baseline for detecting misclassified and out-of-distribution examples in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02136</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Approximating the predictive distribution via adversarially-trained hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Henning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><surname>Johannes Von Oswald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Carlo</forename><surname>Sacramento</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Pascal</forename><surname>Surace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Benjamin F Grewe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Bayesian Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting for continual learning via model adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongyang</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengwei</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwen</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Note on the quadratic penalties in elastic weight consolidation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Husz?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2496" to="2497" />
			<date type="published" when="2018-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Jaeger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1403.3369</idno>
		<title level="m">Controlling Recurrent Neural Networks by Conceptors</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dynamic Filter Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><forename type="middle">De</forename><surname>Brabandere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="667" to="675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4401" to="4410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations</title>
		<meeting><address><addrLine>Banff, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04-14" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kieran</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="3521" to="3526" />
			<date type="published" when="2017-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">What Learning Systems do Intelligent Agents Need? Complementary Learning Systems Theory Updated</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dharshan</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Demis</forename><surname>Hassabis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="512" to="534" />
			<date type="published" when="2016-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Embedded meta-learning: Toward more flexible deep-learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James L</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcclelland</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.09950</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multilayer feedforward networks with a nonpolynomial activation function can approximate any function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moshe</forename><surname>Leshno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimon</forename><surname>Schocken</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="861" to="867" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning without Forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2935" to="2947" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Enhancing the reliability of out-of-distribution image detection in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02690</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Multiplicative Normalizing Flows for Variational Bayesian Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Louizos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="2218" to="2227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">High-fidelity image generation with fewer labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lu?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4183" to="4192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Packnet: Adding multiple tasks to a single network by iterative pruning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Mallya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svetlana</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7765" to="7773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Context-dependent computation by recurrent dynamics in prefrontal cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Valerio Mante</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishna</forename><forename type="middle">V</forename><surname>Sussillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">T</forename><surname>Shenoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Newsome</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">503</biblScope>
			<biblScope unit="issue">7474</biblScope>
			<biblScope unit="page" from="78" to="84" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Least squares generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><forename type="middle">Paul</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smolley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2813" to="2821" />
		</imprint>
	</monogr>
	<note>Computer Vision (ICCV</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Neuromodulation of Neuronal Circuits: Back to the Future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eve</forename><surname>Marder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2012-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nicolas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">D</forename><surname>Masse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David J</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">44</biblScope>
			<biblScope unit="page" from="10467" to="10475" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neal</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Academic Press</publisher>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="109" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.1784</idno>
		<title level="m">Conditional generative adversarial nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cuong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingzhen</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><forename type="middle">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turner</surname></persName>
		</author>
		<title level="m">Variational continual learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Continual lifelong learning with neural networks: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">German</forename><forename type="middle">I</forename><surname>Parisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Kemker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">L</forename><surname>Part</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Kanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Wermter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="54" to="71" />
			<date type="published" when="2019-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Pawlowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Rajchl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Glocker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.01297</idno>
		<title level="m">Implicit Weight Uncertainty in Neural Networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Stochastic Backpropagation and Approximate Inference in Deep Generative Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<ptr target="II-1278-II-1286.JMLR.org" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on International Conference on Machine Learning</title>
		<meeting>the 31st International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The Persistence and Transience of Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">W</forename><surname>Richards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frankland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1071" to="1084" />
			<date type="published" when="2017-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Online structured laplace approximations for overcoming catastrophic forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hippolyt</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Botev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Barber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="3738" to="3748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Catastrophic Forgetting, Rehearsal and Pseudorehearsal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Robins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Connection Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="146" />
			<date type="published" when="1995-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rolnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.11682</idno>
		<title level="m">Experience replay for continual learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><forename type="middle">C</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04671</idno>
	</analytic>
	<monogr>
		<title level="j">Progressive Neural Networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning to control fast-weight memories: An alternative to dynamic recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="139" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Progress &amp; compress: A scalable framework for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jelena</forename><surname>Luketina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>Jennifer Dy and Andreas Krause</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsm?ssan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting with hard attention to the task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Serra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Didac</forename><surname>Suris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Miron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Karatzoglou</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>Jennifer Dy and Andreas Krause</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsm?ssan, Stockholm Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Continual Learning with Deep Generative Replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanul</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehong</forename><surname>Jung Kwon Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="2990" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Motor primitives in space and time via targeted gain modulation in cortical networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><forename type="middle">P</forename><surname>Stroud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mason</forename><forename type="middle">A</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Hennequin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><forename type="middle">P</forename><surname>Vogels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1774</biblScope>
			<date type="published" when="2018-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Improving and understanding variational continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Swaroop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cuong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Thang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Continual Learning Workshop at NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Generative replay with feedback connections as a general strategy for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">S</forename><surname>Van De Ven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tolias</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.10635</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Three scenarios for continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><forename type="middle">S</forename><surname>Van De Ven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tolias</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07734</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Memory Replay GANs: Learning to Generate New Categories without Forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenshen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Herranz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xialei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joost</forename><surname>Van De Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Raducanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="5962" to="5972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Continual Learning Through Synaptic Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Friedemann</forename><surname>Zenke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="3987" to="3995" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
