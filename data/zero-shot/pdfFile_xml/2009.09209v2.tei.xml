<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MSR-DARTS: Minimum Stable Rank of Differentiable Architecture Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kengo</forename><surname>Machida</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Tokyo Institute of Technology</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuniaki</forename><surname>Uto</surname></persName>
							<email>uto@ks.c.titech.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Tokyo Institute of Technology</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koichi</forename><surname>Shinoda</surname></persName>
							<email>shinoda@titech.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Tokyo Institute of Technology</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taiji</forename><surname>Suzuki</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Graduate School of Information Science and Technology</orgName>
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Center for Advanced Intelligence Project</orgName>
								<orgName type="institution">RIKEN</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MSR-DARTS: Minimum Stable Rank of Differentiable Architecture Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In neural architecture search (NAS), differentiable architecture search (DARTS) has recently attracted much attention due to its high efficiency. It defines an overparameterized network with mixed edges, each of which represents all operator candidates, and jointly optimizes the weights of the network and its architecture in an alternating manner. However, this method finds a model with the weights converging faster than the others, and such a model with fastest convergence often leads to overfitting. Accordingly, the resulting model cannot always be well-generalized. To overcome this problem, we propose a method called minimum stable rank DARTS (MSR-DARTS), for finding a model with the best generalization error by replacing architecture optimization with the selection process using the minimum stable rank criterion. Specifically, a convolution operator is represented by a matrix, and MSR-DARTS selects the one with the smallest stable rank. We evaluated MSR-DARTS on CIFAR-10 and Ima-geNet datasets. It achieves an error rate of 2.54% with 4.0M parameters within 0.3 GPU-days on CIFAR-10, and a top-1 error rate of 23.9% on ImageNet. The official code is available at https://github.com/mtaecchhi/ msrdarts.git.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Neural architecture search (NAS) seeks to design neural network structures automatically and has been successful in many tasks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b26">27]</ref>. In NAS, all possible architectures are defined by a search space, which consists of network topologies and operator sets, and a search strategy is used to efficiently obtain a better architecture on the defined search space. A recent trend in the search space is a small component in a network called a cell, which is defined as an optimization target to reduce search cost. Reinforcement learning (RL) <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b26">27]</ref> and evolutionary algorithms (EAs) <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b34">35]</ref> are widely used for the search strategy.</p><p>Recently, DARTS <ref type="bibr" target="#b22">[23]</ref> and DARTS-based methods <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b18">19]</ref> have been proposed, which are differentiable methods that relax the search spaces to be continuous, enabling direct application of gradient-based optimization. These methods are effective regarding search cost since they skip the evaluation of each sampled architecture, which is required in RL and EAs. The cell defined in the above studies is a direct acyclic graph (DAG) with multiple nodes, each of which is a latent representation (e.g., a feature map in convolutional networks), and each directed edge is associated with an operator. While these studies explicitly introduce architecture parameters as learnable parameters in addition to the weight parameters of over-parameterized networks in the architecture search, each edge in a DAG is a mixed edge that includes all candidate operators in the operator set, and each operator is weighted by an architecture parameter. An architecture parameter indicates how suitable its operator is in a mixed edge. Architecture parameters are jointly trained with the weight parameters in an alternating manner. However, this optimization process tends to produce a fast-converging architecture, which is not always the optimal solution in terms of accuracy <ref type="bibr" target="#b30">[31]</ref>.</p><p>We propose a new method called minimum stable rank differentiable architecture search (MSR-DARTS) to solve this problem. With this method, the optimization of the learnable architecture parameters is replaced with the selection process using a stable rank criterion; thus, only weight parameters of neural networks are trained during the architecture search, which enables us to avoid selecting a fastconverging architecture but appropriately find one with a better generalization error. Our operation set includes only limited convolutional operators (e.g., separable convolution and dilated convolution with different kernel sizes), in which each convolutional operator is regarded as a matrix. We use the stable rank (numerical rank) of each convolution to derive a discrete architecture. Specifically, in each mixed edge, the operator that has the lowest stable rank is selected. This architecture search based on stable rank is reasonable since the low-rankness of a matrix indicates the high gener-alization ability of neural networks. Several studies <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b31">32]</ref> reported that a neural network with lower stable rank operators has higher generalization ability, where a stable rank is often used instead of a rank because the former properly captures the statistical degrees of freedom by ignoring negligibly tiny singular values. More precisely, when an input is noisy, a low stable rank convolution conveys the input information only and attenuates noise. Thus, a network with low stable rank has better generalization ability and is robust against noisy input. In summary, we train an over-parameterized network with fixed uniform architecture parameters; thus, only the weights of the network are optimized. The discrete architecture is then derived using the stable rank of each operator by treating a convolution as a matrix with MSR-DARTS to yield a well generalized architecture.</p><p>We conducted experiments to evaluate MSR-DARTS that involved the CIFAR-10 and ImageNet datasets. MSR-DARTS achieved an error rate of 2.54% with 4.0M parameters, which is a lower test error rate than with another DARTS-based method, e.g., PC-DARTS <ref type="bibr" target="#b37">[38]</ref>, and is competitive with Fair DARTS <ref type="bibr" target="#b7">[8]</ref>. MSR-DARTS achieved a top-1 error rate of 23.9% on ImageNet. To the best of our knowledge, it is a state-of-the-art DARTS-based method that uses CIFAR-10 dataset for architecture search. The search process takes only 0.3 GPU-days. The code is available at https://github.com/mtaecchhi/ msrdarts.git.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Neural Architecture Search</head><p>There has been growing interest in NAS since Zoph and Quoc <ref type="bibr" target="#b40">[41]</ref> proposed its algorithm. In the early years, EAs and RL were used to optimize network architectures. The algorithm using RL trains a recurrent neural network metacontroller to guide the search process and gradually sample a better architecture. Zoph et al. and Pham et al. <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b26">27]</ref> first optimized the structure of a small component in an entire network, namely a cell, instead of the entire network structure, then constructed the entire network by stacking the optimized cells. This two-step process reduces search cost. Liu et al., <ref type="bibr">Tang et al. and Real et al. [22,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b27">28]</ref> used EAs, which mutate the architecture topologies and evolve towards better performances. DARTS introduces a differentiable NAS pipeline, which relaxes the search space to be continuous and directly uses gradient-based optimization. Many studies <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b18">19]</ref> followed this approach and achieved remarkable performance with improved efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">DARTS</head><p>In this study, similar to previous ones <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b37">38]</ref>, we used DARTS as a baseline framework. DARTS stacks L cells, each of which is represented as a DAG of an ordered sequence of N nodes, {x 0 , x 1 , . . . , x N ?1 }, where each node x i is a feature map and each edge (i, j) (i &lt; j) denotes an information flow from node i to node j. A set of K candidate operators is denoted as</p><formula xml:id="formula_0">O = {o 0 , o 1 , . . . , o K?1 }, in which an element o v that includes a learnable parame- ter w (i,j) v</formula><p>is the v-th candidate operator defined in advance (e.g., separable convolution and dilated convolution). </p><formula xml:id="formula_1">(i,j) v , which indicates how suitable o v is for mixed edge (i, j), is introduced as a weight for o v . The goal is to op- timize ? (i,j) v</formula><p>(v = 0, . . . , K ? 1). For each i &lt; j, the information flow from node i to node j, illustrated in the upper middle of <ref type="figure" target="#fig_1">Figure 1</ref>, is computed as</p><formula xml:id="formula_2">f i,j (x i ) = K?1 v=0 exp(? (i,j) v ) K?1 v =0 exp(? (i,j) v ) ? o v (x i ),<label>(1)</label></formula><p>where o v (x i ) is the result of applying the input x i to o v . An output of node j is a sum over all information flows from its predecessors, that is, x j = i&lt;j f i,j (x i ). The first two nodes, x 0 and x 1 , are input nodes to a cell. The output of all the cells equals that of the final node x N ?1 , which is defined as the concatenation of all the intermediate cells, i.e., concat(x 2 , x 3 , . . . , x N ?2 ). There are two types of cells introduced in DARTS. One is a normal cell, which maintains spatial resolution, and the other is a reduction cell, which reduces the spatial resolution of feature maps. Note that while DARTS shares the architecture topology among all normal cells, the same is true for reduction cells because it optimizes architecture parameters ? normal and ? reduce , where ? normal is shared by all the normal cells and ? reduce is shared by all the reduction cells.</p><p>DARTS has two stages. The first is the search stage, which trains the over-parameterized network consisting of mixed edges in each of which all possible operators are included, and derives a promising discrete architecture in accordance with the architecture parameter ? (i,j) v (see Subsec. 3.4 for more details). The second stage is an evaluation stage in which the derived architecture from full-scratch is trained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Generalization Error Analysis</head><p>A deep network generalizes well even when it has a larger amount of parameters than the sample size. Generalization bounds represent the upper bound of the generalization error. We can guarantee that a model with small training error can have a high generalization performance if the generalization error (difference between training error and expected error) can be evaluated properly and has a small upper bound. There are several metrics to represent generalization error bounds such as VC-dimension <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b13">14]</ref>, PAC-Bayes theory <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b10">11]</ref>, norm based analysis <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b11">12]</ref>, and the compression based approach <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b31">32]</ref>. The compression based approach has recently attracted much attention because it gives tighter generalization error bounds for deep neural networks. For example, Arora et al. <ref type="bibr" target="#b1">[2]</ref> used the low rank property of weight matrices to compress neural networks based on the fact that a matrix with a lower stable rank is more robust to noise thus generalizes well. Suzuki et al. <ref type="bibr" target="#b31">[32]</ref> experimentally confirmed that most networks have near low rank weight matrices after training, where a near low rank matrix is defined as a matrix in which a small number of singular values are significantly large while the other singular values are close to zero. This near low rank property is used to derive generalization bounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">MSR-DARTS</head><p>While DARTS and many related methods <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b37">38]</ref> search for architectures by jointly training the architecture parameters ? and weights of neural networks w (e.g., the parameters of the convolutional operator) in an alternating manner (?</p><formula xml:id="formula_3">(i,j) v is denoted as ? and w (i,j) v</formula><p>is denoted as w for simplicity), Shu et al. <ref type="bibr" target="#b30">[31]</ref> reported that these methods tend to lead to a fast converged architecture during the search stage rather than well generalized models. This is because ? is updated on the basis of w, which is not fully converged rather than well trained w, which is harmful especially in the early epochs. This means that there is room to search for a model with lower error rate in the search space. MSR-DARTS addresses this issue. It fixes ? to 1, hence optimizes only w. In the search stage, instead of Eq. (1), the information flow from node i to node j with MSR-DARTS illustrated in <ref type="figure" target="#fig_1">Figure 1</ref> middle bottom, is defined as</p><formula xml:id="formula_4">f i,j (x i ) = o?O o(x i ).<label>(2)</label></formula><p>The other process is the same as those defined in Subsec.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.2.</head><p>With MSR-DARTS, we assume that each candidate operator o v ? O consists of several convolutional layers. Let c v p and c v fin be the p-th and last convolutional layers in o v , respectively. Note that the notation of node (i, j) is omitted for simplicity in c v p and c v fin . Regarding convolutional computation as matrix calculation <ref type="bibr" target="#b29">[30]</ref>, the stable rank of convolution c is then denoted as</p><formula xml:id="formula_5">R(c) = c 2 F c 2 2</formula><p>, where ? F denotes the Frobenius norm and ? 2 denotes the spectral norm. A stable rank is often used as a surrogate for a rank <ref type="bibr" target="#b1">[2]</ref>.</p><p>Then we select the best operator from O for each edge after training of an over-parameterized network in the search stage. We use the relation between network generalization ability and singular values proposed by Arora et al. <ref type="bibr" target="#b1">[2]</ref>. They reported that a well-generalized network consists of noise-robust convolutions that have low stable ranks.</p><formula xml:id="formula_6">Noise sensitivity ? N (c, x) is defined as ? N (c, x) = E ??N c(x + ? x ) ? c(x) 2 c(x) 2 ,<label>(3)</label></formula><p>where c is a mapping from real-valued vectors to realvalued vectors (e.g., convolutional computation represented by a matrix), x is a vector to be multiplied (i.e., input for a convolutional layer), N is a noise distribution, E is an expectation value, and ? is the Euclidean norm. Low noise sensitivity indicates that the convolution matrix has a near low rank property (i.e., a low stable rank) because the signal x is correctly carried whereas noise ? is attenuated. Note that ? N (c, x) is at least its stable rank when noise is generated from standard normal distribution, i.e., ? ? N (0, I).</p><p>For more details, refer to the paper by Arora et al. <ref type="bibr" target="#b1">[2]</ref>.</p><p>We assume that an operator that generalizes better has lower noise sensitivity, i.e., a lower stable rank (experimentally shown in Appendix B). We further assume that the last convolution c v fin is the most relevant to the output of o v , thus use the stable rank of c v fin (i.e., R(c v fin )) only. The operator that has the lowest R(c v fin ) is selected to yield the discrete architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Search Space</head><p>DARTS defines an operator set with eight operators. That is, 3?3 and 5?5 separable convolutions, 3?3 and 5?5 dilated separable convolutions, 3?3 max pooling, 3?3 average pooling, identity, and zero. Our operator set is the subset of the search space of DARTS, i.e., 3?3 and 5?5 separable convolutions and 3?3 and 5?5 dilated separable convolutions. As described in Subsec. 3.1, we assume that all candidate operators o v ? O consist of limited convolutional layers, where 3?3 max pooling, 3?3 average pooling, identity, and zero, which are not convolutional calculations, are excluded. As with DARTS, we use the ReLU-Conv-BN order for convolutional operators, in which each separable convolution is always applied twice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Setting Spectral Norm of Convolution in Search Stage</head><p>We assume that with MSR-DARTS, all operators in a search space are trained correctly in the search stage. However, previous studies <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17]</ref> reported that deep learning tends to produce a simpler model than its full expression ability when we use regularization such as L 1 regularization. More precisely, it has been experimentally shown that a trained network tends to have near low rank weight matrices, in which only a few singular values are large and others are close to zero. Therefore, in each mixed edge of an over-parameterized network with MSR-DARTS, some operators can be redundant because their singular values can be all close to zero. To train each operator stably, we apply the spectral norm adjustment technique introduced by Behrmann et al. <ref type="bibr" target="#b4">[5]</ref> to all convolutional operators in candidate operators, that is,</p><formula xml:id="formula_7">?v, p; c v p 2 = C<label>(4)</label></formula><p>where C is a constant value to be set <ref type="figure" target="#fig_1">(Figure 1 right)</ref>. We estimate the spectral norm of c v p by carrying out poweriteration (see Appendix A for more details), which yields an under-estimate? <ref type="bibr" target="#b0">1</ref> </p><formula xml:id="formula_8">(c v p ) ? c v p 2 , where ? q (c v p )</formula><p>denotes the q-th largest singular value of c v p . Similar to the above study, using this estimate, each convolution in candidate operator</p><formula xml:id="formula_9">c v p is normalized asc v p = c v p ? C ? 1 (c v p )</formula><p>.</p><p>Note that spectral norm adjustment of each convolution is conducted before forward propagation. We used C = 1 in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Deriving Discrete Architecture</head><p>After training of the over-parameterized network, a discrete architecture is derived by selecting the topology and operator for each intermediate node. With DARTS and its derivations, the topology is selected by retaining two of the strongest precedent edges for each intermediate node, where the strength of an edge from node i to node j, denoted as S i,j , is defined as</p><formula xml:id="formula_11">S i,j = max o?O,o =zero exp(? (i,j) o ) o ?O exp(? (i,j) o ) .<label>(6)</label></formula><p>In each edge, the operator with the largest ? v is selected. However, as described in Subsec. 3.1, MSR-DARTS uses a fixed value for ? v . We use the stable rank of the last convolution R(c v fin ) in each o v to determine the topology. First, for normal and reduction cells, the mixed edge between node i and node j is replaced with the best operator</p><formula xml:id="formula_12">(o * T ) i,j , defined by (o * T ) i,j = arg min ov?O R T (c (i,j)v fin</formula><p>).</p><p>We explicitly notate the edge indices i, j in convolution c, T = {normal, reduce} denotes the type of cells and R T (?) denotes the average R(?) of all the cells belonging to cell type T . Similar to Eq. <ref type="formula" target="#formula_13">(7)</ref>, the strength of an edge from node i to node j of cell type T with MSR-DARTS is defined by</p><formula xml:id="formula_14">(S T ) i,j = max ov?O ?R T (c (i,j)v fin )<label>(8)</label></formula><p>We use Eq. (8) instead of Eq. (6) to derive topology. Note that the operator o v ? O, which has lower R(c v fin ) is considered a better operator in terms of generalization ability (see Subsec. 3.1).</p><p>As with DARTS, each intermediate node retains the connections from the two strongest precedent nodes, denoted as i * 1 and i * 2 , with Eq. (8), that is,</p><formula xml:id="formula_15">i * 1 = arg max i S i,j i * 2 = arg max i =i * 1 S i,j .<label>(9)</label></formula><p>Note that the cell-type notation T is omitted from Eq. (9) for simplicity. In summary, a discrete architecture is derived from the over-parameterized network after training, where each mixed edge is replaced with the best operator (o * T ) i,j in accordance with Eq. <ref type="bibr" target="#b6">(7)</ref>. The two strongest precedent connections from node i * 1 and i * 2 are then preserved in each node in accordance with Eq. (8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>Similar to several previous studies <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b37">38]</ref>, we conducted experiments on the well-known image classification datasets CIFAR-10 <ref type="bibr" target="#b17">[18]</ref> and ImageNet <ref type="bibr" target="#b8">[9]</ref>. CIFAR-10 consists of 50K training images and 10K testing images. All images have a fixed size of 32?32 and equally distributed over ten classes. ImageNet was obtained from the Imagenet Large Scale Visual Recognition Challenge 2012 <ref type="bibr" target="#b28">[29]</ref> and contains 1K object classes, 1.28M training images, and 50K validation images. We follow the general setting in which the input image size is 224 ? 224.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">CIFAR-10 Toy Experiment</head><p>First, we confirmed the effectiveness of the proposed method using MSR through a simple toy experiment using CIFAR-10. In this experiment, MSR-DARTS and DARTS <ref type="bibr" target="#b22">[23]</ref> were compared, both under the same experimental conditions. The results indicate that MSR-DARTS is superior to DARTS.</p><p>In the search stage, following DARTS, the architecture was conducted on a network with L = 8 cells. Each convolutional cell consists of N = 7 nodes. The input nodes x 0 and x 1 were equal to the output of the last two preceding cells, respectively. The output node was x 6 , which is the concatenation of all the intermediate nodes. Reduction cells were inserted at 1/3 and 2/3 the total depth of the network to reduce the spatial resolution of feature maps. All other cells were normal cells that maintain spatial resolution. Note that while DARTS and related methods <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref> share the architecture topology among all normal cells, the same is true for reduction cells, because they optimize architecture parameters (? normal , ? reduce ), where ? normal is shared by all the normal cells and ? reduce is shared by all the reduction cells (see Subsec. 2.2). MSR-DARTS also optimizes two types of cell structures, i.e., normal and reduction cell, but each cell is optimized using MSR (see Subsec. 3.1) because learnable architecture parameters are not optimized with MSR-DARTS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Experimental Settings</head><p>We split the CIFAR-10 training data in a ratio of four to one. The former was used to train the over-parameterized network weights while the latter was used to calculate the loss. The over-parameterized network was trained for 50 epochs, where the batch size was determined to fit into a single GPU. The initial number of channels was set to 16. We used momentum stochastic gradient descent (SGD) to optimize the weights, with an initial learning rate of 0.025 (annealed down following a cosine schedule), momentum of 0.9, and weight decay of 3 ? 10 ?4 . We used search space O MSR ? <ref type="figure">Figure 2</ref>. Validation-loss transition of over-parameterized network in search stage. 50,000 training images were split into ratio of 4:1, former was used to optimize network parameters, latter was used to validate network. {"3x3 separable conv", "5x5 separable conv", "3x3 dilated conv", "5x5 dilated conv"}. Note that we used search space O MSR because with MSR-DARTS assumed that each candidate operator in the search space is composed of several convolutional layers (see Subsec 3.1); therefore, we omitted the operators that do not meet this assumption, i.e., "zero", "identity", "3x3 max pooling", "3x3 average pooling" from the search space. We used single the TITAN RTX GPU, and the architecture search took less than 0.3 days.</p><p>In the evaluation stage of the toy experiment, the network was composed of 8 cells (6 normal cells and 2 reduction cells) instead of 20 cells (18 normal cells and 2 reduction cells), the number of which is widely used to compare the performance of DARTS-based methods. The other settings follow those of DARTS. The network was trained for 600 epochs, with a batch size 96. The initial number of channels was 36, the SGD optimizer with an initial learning rate of 0.025 (annealed down to zero following a cosine schedule), a momentum of 0.9, a weight decay of 3?10 ?4 and gradient clipping at 5. Cutout <ref type="bibr" target="#b9">[10]</ref>, path dropout of probability 0.3, and auxiliary towers with weight 0.4 were used to enhance accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Results</head><p>The validation loss of the over-parameterized network in the search stage is illustrated in <ref type="figure">Figure 2</ref>. In the search stage, the validation loss decreased from the beginning of training and took a minimum value around 35 epochs. However, it began to increase little by little after 35 epochs. Since MSR-DARTS aims to determine a model structure with high generalization performance, the architecture generated before the increase in the validation loss was used for architecture evaluation. Specifically, we used the architecture generated in epoch 38. <ref type="figure" target="#fig_2">Figure 3</ref> left and right indicate the test accuracy and test loss, respectively. Each value is plotted after 300 epochs where the difference can be observed. The architecture generated with MSR-DARTS exhibited lower test error and higher test accuracy than those with DARTS, which indicates MSR-DARTS outperforms DARTS when the layer depth in the search stage is the same as that in the evaluation stage. <ref type="table" target="#tab_0">Table 1</ref> summarizes the results of the toy experiment. MSR-DARTS achieved a test error rate of 2.84%, which is 0.46% higher than that of DARTS. MSR-DARTS only requires 0.3 days with a GPU to search for the optimal architecture, which is 3 times faster than with DARTS. In terms of comparing the number of parameters of each architecture, there was almost no difference between the models since the same search space was used. Strictly speaking, the number of parameters of MSR-DARTS is 1.63M, which is smaller than that of DARTS.</p><p>To conclude the toy experiment, we set the same experimental settings such as search space and hyper-parameters for both methods and confirmed that MSR-DARTS yields better results than DARTS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results on CIFAR-10</head><p>We evaluated the MSR-DARTS with 20 cells (18 normal cells and 2 reduction cells) in the evaluation stage to compare other state-of-the-art methods. We used the same cell structure optimized in the toy experiment. The rest of the experimental settings were exactly the same as with DARTS. <ref type="table" target="#tab_1">Table 2</ref> compares the image-classification performance of MSR-DARTS with those of the other methods. MSR-DARTS achieved 2.54% test error, which is better than 2nd order DARTS. It outperformed PC-DARTS <ref type="bibr" target="#b37">[38]</ref> and was competitive with Fair DARTS <ref type="bibr" target="#b7">[8]</ref> in terms of testerror rate. Our architecture search finished in 0.3 GPUdays, which is faster than 2nd order DARTS (1.0 GPUday) and Fair DARTS (0.4 GPU-days). Note that MSR-DARTS generated the optimal model with 4.0M parameters, which is a slightly larger number of parameters compared with the models of the other methods. This is because of search space O MSR , which includes the convolutional operator only. This means that the operator with few parameters, such as pooling or identity (skip connection), is not selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Results on ImageNet</head><p>Following DARTS and its derivations, we evaluated the architecture with L = 14 cells in the architecture evaluation stage. We used the normal and reduction cells, which were optimized with CIFAR-10 (see Subsec. 4.2). The experimental settings mostly followed those of DARTS. The network was trained 250 epochs with a batch size 128. The initial number of channels was set to be 48. We used momentum SGD to optimize the weights, with an initial learning rate 0.1 (annealed down following a cosine schedule), momentum of 0.9, and weight decay of 3 ? 10 ?4 . For additional enhancements, label smoothing and an auxiliary loss tower were used during the training. We used 32 TI-TAN V100 GPUs, applied learning warm-up for the first 10 epochs (increase linearly with each batch), and used Horovod for distributed training.</p><p>The results are summarized in <ref type="table" target="#tab_2">Table 3</ref>. The architecture found with MSR-DARTS using CIFAR-10 reported a top-1 error rate of 23.9% and top-5 error rate of 7.3%, which outperforms the top-1 error rate of 26.7% and top-5 error rate of 8.7% reported with DARTS. In the comparison with other DARTS-based methods using CIFAR-10 for architecture search, MSR-DARTS had 0.5% higher top-1 accuracy than P-DARTS, 1.2% higher than PC-DARTS, 1.0% higher than Fair DARTS, and 0.2% higher than PR-DARTS. It was also competitive with 23.9% of DARTS+, which searches for an optimal architecture with CIFAR-100. Regarding search cost, MSR-DARTS required only 0.3 GPUdays, which is 3 times faster than the 2nd order DARTS and slightly faster or competitive with Fair DARTS and P-DARTS. Due to the fact that the search space includes only limited types of convolutional operators (see Subsec. 3.2), MSR-DARTS had a relatively large number of parameters and multiply-add operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Qualitative Evaluation</head><p>In this subsection, we compare the optimized architectures between DARTS and MSR-DARTS qualitatively.   As described in a previous paper <ref type="bibr" target="#b30">[31]</ref>, the depth of a cell structure is defined as the number of connections along the longest path from input node to output node. The width of a cell structure is defined as the total width of intermediate nodes that are connected to the input nodes. In particu-lar, the normal cell found with DARTS <ref type="figure" target="#fig_5">(Figure 4 (a)</ref>) had a depth of 3 and width of 3.5.</p><p>The normal cell found by MSR-DARTS, however, had a depth of 4 and width of 2.5, a deeper and narrower structure. As discussed in the above paper <ref type="bibr" target="#b30">[31]</ref>, DARTS tends to select shallow and wide cells because is optimizes two  parameter sets (weight w and architecture parameter ?) in an alternating manner. Each candidate architecture is not evaluated based on the generalization performance at convergence during architecture search; thus architectures with faster convergence rates tend to be selected. In contrast, the architecture parameters are fixed and only w are optimized with MSR-DARTS. Thus, MSR-DARTS can evaluate each architecture more correctly at convergence and yield deeper and narrower cells, which is a well generalized architecture. Note that the scheme that penalizes shallower cells is used with PR-DARTS <ref type="bibr" target="#b39">[40]</ref>. However, PR-DARTS has many more hyper-parameters than the original DARTS, which are difficult to adjust. On the other hand, MSR-DARTS does not require any hyper-parameters to deepen a cell structure, making it easy to optimize. All the intermediate nodes, except the first intermediate node (illustrated as 0 in <ref type="figure" target="#fig_5">Figure 4</ref>) in the normal cell found with MSR-DARTS had both a connection from an input node and a connection from another intermediate node. Each intermediate node can handle both the input features of the cell and well-processed features inside the cell. This structure may improve of the accuracy.</p><p>The reduction cell found with MSR-DARTS had a shallow and wide cell structure in contrast to the normal cell. The reason MSR-DARTS finds these structures may be that the reduction cell should summarize the information to reduce the spatial dimension, thus requiring more information from the input features than the normal cell. In addition, it seems that the reduction cell found with MSR-DARTS has small receptive fields (e.g., "3x3 separable convolution" and "5x5 separable convolution") for the output of the before last cell and relatively large receptive fields (e.g., "5x5 separable convolution" and "3x3 dilated convolution") for the output of the before cell. This enables the efficient aggregation of information by applying a large receptive field to the latest information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We proposed MSR-DARTS, which optimizes only the weight parameters of an over-parameterized network. The discrete-architecture-selection process using the optimized architecture parameters with DARTS is replaced with the process using a stable rank of each convolution. By using the relation between the generalization ability of a neural network and low-rankness of an operator, MSR-DARTS searches for an architecture that is expected to have low test error by selecting the lowest stable rank operator. In our evaluation, MSR-DARTS achieved 2.54% test error on CIFAR-10 and 23.9% test error on ImageNet. The architecture-search process can be done within 0.3 GPUdays.</p><p>Algorithm 1 Power-iteration algorithm for calculating the spectral norm ? 1 of convolution c Randomly initialize input a 0 for i = 1 to Z do b i ? c(a i?1 ) Normalize b i a i ? c T (b i ) Normalize a i end for ? 1 (c) ? c(a i ) 2 <ref type="figure">Figure 5</ref>. Test-error transition (left) and test-loss transition (right) of the networks generated with MSR-DARTS and the architecture with the highest stable rank operators (after 300 epochs are plotted). Orange solid lines represent MSR-DARTS and purple dotted lines represent the architecture with the highest stable rank operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Estimation of spectral norm of a convolution</head><p>As described in Subsec. 3.3, we constrain the spectral norms of all the convolutions c v p contained in the overparameterized network. We use a power-iteration algorithm <ref type="bibr" target="#b9">[10]</ref> described in Algorithm 1 to estimate the spectral norm of each convolution. Note that the index v and p of c v p are omitted for simplicity. The spectral norm of convolution c is denoted by ? 1 (c). c(a) is a convolutional calculation that takes input a. c T is transposed convolution of c. The Algorithm 1 yields an under-estimate, i.e.,? 1 (c) ? c 2 . In the experiment, we confirmed all the spectral norms of the convolutions in the over-parameterized network are estimated correctly. We set the number of iteration Z to 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison with the maximum stable rank architecture</head><p>We hypothesize the network with lower rank convolutions has higher generalization ability (see Subsec. 3.1). In our pipeline, we select the operators that have lowest stable rank in the mixed edges after training of the overparameterized network. We examined the low rank convolution brings better generalization performance by comparing MSR-DARTS with the architecture constructed by selecting the operators that have the maximum stable rank in the mixed edges. <ref type="figure">Figure 5</ref> shows the results of the training of the both ar-chitectures. We observed the proposed method, i.e., the architecture with the lowest stable rank operators yields better performance than the architecture with the highest stable rank operators.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1 left illustrates an example of a DAG with 4 nodes. An information flow between nodes is a mixed edge, which includes all candidate operators. An architecture parameter ?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Left: example of DAG with 4 nodes. Nodes and information flows are denoted with circles and arrows, respectively. Middle: difference in information flow between nodes between DARTS (top) and MSR-DARTS (bottom). Each figure indicates that number of candidate operators is 3. Right: setting spectral norm of each convolution to constant value in search stage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Test-error transition (left) and test-loss transition (right) of networks generated with MSR-DARTS and DARTS in evaluation stage of toy experiment (after 300 epochs were plotted). Test loss is average of cross entropy loss over all test sets. Orange solid lines represent MSR-DARTS and green dotted lines represent DARTS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 4 illustrates the cell structures found with DARTS((a) normal cell, (b) reduction cell) and with MSR-DARTS ((c)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(a) Normal cell found with DARTS.(b) Reduction cell found with DARTS. (c) Normal cell found with MSR-DARTS. (d) Reduction cell found with MSR-DARTS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Optimized cells found with DARTS and MSR-DARTS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison with DARTS in toy experiment. Search space OMSR was used. Each architecture was searched with 8 cells in search stage and evaluated 8 cells in evaluation stage. Note that column S.C is search cost (GPU-days).</figDesc><table><row><cell>Architecture</cell><cell>Test Err. (%)</cell><cell>S.C.</cell><cell>Params (M)</cell></row><row><cell>DARTS</cell><cell>3.30</cell><cell>1.0</cell><cell>1.65</cell></row><row><cell>MSR-DARTS</cell><cell>2.84</cell><cell>0.3</cell><cell>1.63</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Comparison with state-of-the-art image classifiers on CIFAR-10. Cutout is denoted as c/o.</figDesc><table><row><cell>Architecture</cell><cell>Test Err. (%)</cell><cell>Params (M)</cell><cell>Search Cost (GPU-days)</cell><cell>Search Method</cell></row><row><cell>DenseNet-BC [16]</cell><cell>3.46</cell><cell>25.6</cell><cell></cell><cell>-manual</cell></row><row><cell>NASNet-A + c/o [42]</cell><cell>2.65</cell><cell>3.3</cell><cell cols="2">1800 RL</cell></row><row><cell>AmoebaNet-B + c/o [28]</cell><cell>2.55</cell><cell>2.8</cell><cell cols="2">3150 evolution</cell></row><row><cell>Hierarchical Evo [22]</cell><cell>3.75</cell><cell>15.7</cell><cell cols="2">300 evolution</cell></row><row><cell>PNAS [21]</cell><cell>3.41</cell><cell>3.2</cell><cell cols="2">225 SMBO</cell></row><row><cell>ENAS + c/o [27]</cell><cell>2.89</cell><cell>4.6</cell><cell cols="2">0.5 RL</cell></row><row><cell>DARTS (1st order) + c/o [23]</cell><cell>3.00</cell><cell>3.3</cell><cell cols="2">0.4 gradient-based</cell></row><row><cell>DARTS (2nd order) + c/o [23]</cell><cell>2.76</cell><cell>3.3</cell><cell cols="2">1.0 gradient-based</cell></row><row><cell>SNAS (moderate) + c/o [37]</cell><cell>2.85</cell><cell>2.8</cell><cell cols="2">1.5 gradient-based</cell></row><row><cell>ProxylessNAS + c/o [6]</cell><cell>2.08</cell><cell>-</cell><cell cols="2">4.0 gradient-based</cell></row><row><cell>DARTS+ + c/o [19]</cell><cell>2.20</cell><cell>4.3</cell><cell cols="2">0.6 gradient-based</cell></row><row><cell>P-DARTS + c/o [7]</cell><cell>2.50</cell><cell>3.4</cell><cell cols="2">0.3 gradient-based</cell></row><row><cell>PC-DARTS + c/o [38]</cell><cell>2.57</cell><cell>3.6</cell><cell cols="2">0.1 gradient-based</cell></row><row><cell>Fair DARTS + c/o [8]</cell><cell>2.54</cell><cell>2.8</cell><cell cols="2">0.4 gradient-based</cell></row><row><cell>PR-DARTS + c/o [40]</cell><cell>2.32</cell><cell>3.4</cell><cell cols="2">0.17 gradient-based</cell></row><row><cell>MSR-DARTS + c/o (ours)</cell><cell>2.54</cell><cell>4.0</cell><cell cols="2">0.3 Stable Rank</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Comparison with state-of-the-art image classifiers on ImageNet. ? denotes architecture was searched for on ImageNet directly.</figDesc><table><row><cell>Architecture</cell><cell cols="3">Test Err.(%) Params</cell><cell cols="2">?+ Search Cost Search Method</cell></row><row><cell></cell><cell cols="2">top-1 top-5</cell><cell>(M)</cell><cell>(M)</cell><cell>GPU-days</cell></row><row><cell>Inception-v1 [33]</cell><cell>30.2</cell><cell>10.1</cell><cell cols="2">6.6 1448</cell><cell>-manual</cell></row><row><cell>MobileNet [15]</cell><cell>29.4</cell><cell>10.5</cell><cell>4.2</cell><cell>569</cell><cell>-manual</cell></row><row><cell>ShuffleNet 2? (v1) [39]</cell><cell>26.4</cell><cell>10.2</cell><cell>5</cell><cell>524</cell><cell>-manual</cell></row><row><cell>ShuffleNet 2? (v2) [24]</cell><cell>25.1</cell><cell>-</cell><cell>5</cell><cell>591</cell><cell>-manual</cell></row><row><cell>NASNet-A [42]</cell><cell>26.0</cell><cell>8.4</cell><cell>5.3</cell><cell>564</cell><cell>1800 RL</cell></row><row><cell>AmoebaNet-C [28]</cell><cell>24.3</cell><cell>7.6</cell><cell>6.4</cell><cell>570</cell><cell>3150 evolution</cell></row><row><cell>PNAS [21]</cell><cell>25.8</cell><cell>8.1</cell><cell>5.1</cell><cell>588</cell><cell>225 SMBO</cell></row><row><cell>MnasNet-92 [34]</cell><cell>25.2</cell><cell>8.0</cell><cell>4.4</cell><cell>388</cell><cell>-RL</cell></row><row><cell>DARTS (2nd order) [23]</cell><cell>26.7</cell><cell>8.7</cell><cell>4.7</cell><cell>574</cell><cell>4.0 gradient-based</cell></row><row><cell>SNAS (mild) [37]</cell><cell>27.3</cell><cell>9.2</cell><cell>4.3</cell><cell>522</cell><cell>1.5 gradient-based</cell></row><row><cell>ProxylessNAS(GPU)  ? [6]</cell><cell>24.9</cell><cell>7.5</cell><cell>7.1</cell><cell>465</cell><cell>8.3 gradient-based</cell></row><row><cell>DARTS+(CIFAR-100)[19]</cell><cell>23.7</cell><cell>7.2</cell><cell>5.1</cell><cell>591</cell><cell>0.2 gradient-based</cell></row><row><cell>DARTS+(ImageNet)  ? [19]</cell><cell>23.9</cell><cell>7.4</cell><cell>5.1</cell><cell>582</cell><cell>6.8 gradient-based</cell></row><row><cell>P-DARTS(CIFAR-10) [7]</cell><cell>24.4</cell><cell>7.4</cell><cell>4.9</cell><cell>557</cell><cell>0.3 gradient-based</cell></row><row><cell>P-DARTS(CIFAR-100) [7]</cell><cell>24.7</cell><cell>7.5</cell><cell>5.1</cell><cell>577</cell><cell>0.3 gradient-based</cell></row><row><cell>PC-DARTS(CIFAR-10) [38]</cell><cell>25.1</cell><cell>7.8</cell><cell>5.3</cell><cell>586</cell><cell>0.1 gradient-based</cell></row><row><cell>PC-DARTS(ImageNet)  ? [38]</cell><cell>24.2</cell><cell>7.3</cell><cell>5.3</cell><cell>597</cell><cell>3.8 gradient-based</cell></row><row><cell>Fair DARTS [8]</cell><cell>24.9</cell><cell>7.5</cell><cell>4.8</cell><cell>541</cell><cell>0.4 gradient-based</cell></row><row><cell>PR-DARTS [40]</cell><cell>24.1</cell><cell>7.3</cell><cell>4.98</cell><cell>541</cell><cell>0.17 gradient-based</cell></row><row><cell>MSR-DARTS(CIFAR-10) (ours)</cell><cell>23.9</cell><cell>7.3</cell><cell>5.6</cell><cell>632</cell><cell>0.3 Stable Rank</cell></row><row><cell>normal cell, (d) reduction cell).</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by JST CREST JPMJCR1687 and NEDO JPNP18002. TS was partially supported by MEXT Kakenhi (15H05707, 18K19793 and 18H03201), and Japan Digital Design.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fast, accurate, and lightweight super-resolution with cascading residual network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namhyuk</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byungkon</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyung-Ah</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="252" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Stronger generalization bounds for deep nets via a compression approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnam</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>Jennifer G. Dy and Andreas Krause</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsm?ssan, Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-07-10" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rademacher and gaussian complexities: Risk bounds and structural results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shahar</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mendelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="463" to="482" />
			<date type="published" when="2002-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Data-dependent coresets for compressing neural networks with applications to generalization bounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cenk</forename><surname>Baykal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Liebenwein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Gilitschenski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniela</forename><surname>Rus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Invertible residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricky</forename><forename type="middle">T Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rn-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<idno>PMLR, 2019. 4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
		<editor>Kamalika Chaudhuri and Ruslan Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-15" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="573" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1294" to="1303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Fair DARTS: eliminating unfair advantages in differentiable architecture search. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jixiang</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1911" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">09</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Gintare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel M</forename><surname>Dziugaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.11008</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sizeindependent sample complexity of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Golowich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rakhlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ohad</forename><surname>Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference On Learning Theory</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="297" to="299" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Implicit bias of gradient descent on linear convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suriya</forename><surname>Gunasekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Soudry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nati</forename><surname>Srebro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing</title>
		<meeting><address><addrLine>Nicol? Cesa-Bianchi, and Roman Garnett; NeurIPS; Montr?al, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12-08" />
			<biblScope unit="page" from="9482" to="9491" />
		</imprint>
	</monogr>
	<note>Samy Bengio,</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Nearly-tight VC-dimension bounds for piecewise linear neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Harvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abbas</forename><surname>Mehrabian</surname></persName>
		</author>
		<idno>PMLR. 3</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Learning Theory</title>
		<editor>Satyen Kale and Ohad Shamir</editor>
		<meeting>the 2017 Conference on Learning Theory<address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07" />
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="7" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<idno>abs/1704.04861</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Gradient descent aligns the layers of deep linear networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matus</forename><surname>Telgarsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019, New Orleans</title>
		<meeting><address><addrLine>LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shifeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingqiu</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kechen</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.06035</idno>
		<title level="m">Darts+: Improved differentiable architecture search with early stopping</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Autodeeplab: Hierarchical neural architecture search for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="82" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Progressive neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hierarchical representations for efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisantha</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR 2018</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Shufflenet v2: Practical guidelines for efficient cnn architecture design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningning</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai-Tao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A pac-bayesian approach to spectrally-normalized margin bounds for neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinadh</forename><surname>Behnam Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Srebro</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.09564</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Path-sgd: Path-normalized optimization in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnam</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Russ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nati</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Srebro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameter sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melody</forename><forename type="middle">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>Jennifer G. Dy and Andreas Krause</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsm?ssan, Stockholm</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="4092" to="4101" />
		</imprint>
	</monogr>
	<note>Sweden</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>Honolulu, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page" from="4780" to="4789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The singular values of convolutional layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanie</forename><surname>Sedghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">M</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Understanding architectures learnt by cell-based neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaofeng</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net, 2020. 1, 3</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Compression based bound for non-compressed network: unified generalization error analysis of large compressible deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taiji</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Abe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoaki</forename><surname>Nishimura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net, 2020. 2, 3, 4</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Gradient projection iterative sketch for large-scale constrained least-squares</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqi</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Golbabaee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><forename type="middle">E</forename><surname>Davies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>Doina Precup and Yee Whye Teh</editor>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06-11" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="3377" to="3386" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">SNAS: stochastic neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirui</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hehui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Pc-darts: Partial channel connections for memory-efficient differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.05737</idno>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Shufflenet: An extremely efficient convolutional neural network for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengxiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2018-06-18" />
			<biblScope unit="page" from="6848" to="6856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16537</idno>
		<title level="m">Theory-inspired path-regularized differential network architecture search</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="8697" to="8710" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
