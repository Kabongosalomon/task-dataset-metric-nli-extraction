<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Vision-Language Navigation with Random Environmental Mixup</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Liu</surname></persName>
							<email>liuchong@ios.ac.cnfengda.zhu@monash.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Software</orgName>
								<orgName type="laboratory">State Key Laboratory of Computer Science</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
								<address>
									<postCode>100049</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengda</forename><surname>Zhu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
							<email>xiaojun.chang@rmit.edu.au</email>
							<affiliation key="aff3">
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
							<email>xdliang328@gmail.com</email>
							<affiliation key="aff4">
								<orgName type="institution">Sun Yat-sen University</orgName>
								<address>
									<settlement>Guangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongyuan</forename><surname>Ge</surname></persName>
							<email>zongyuan.ge@monash.eduydshen@ios.ac.cn</email>
							<affiliation key="aff2">
								<orgName type="institution">Monash University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Dong</forename><surname>Shen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute of Software</orgName>
								<orgName type="laboratory">State Key Laboratory of Computer Science</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Vision-Language Navigation with Random Environmental Mixup</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Vision-language Navigation (VLN) tasks require an agent to navigate step-by-step while perceiving the visual observations and comprehending a natural language instruction. Large data bias, which is caused by the disparity ratio between the small data scale and large navigation space, makes the VLN task challenging. Previous works have proposed various data augmentation methods to reduce data bias. However, these works do not explicitly reduce the data bias across different house scenes. Therefore, the agent would overfit to the seen scenes and achieve poor navigation performance in the unseen scenes. To tackle this problem, we propose the Random Environmental Mixup (REM) method, which generates crossconnected house scenes as augmented data via mixuping environment. Specifically, we first select key viewpoints according to the room connection graph for each scene. Then, we cross-connect the key views of different scenes to construct augmented scenes. Finally, we generate augmented instruction-path pairs in the cross-connected scenes. The experimental results on benchmark datasets demonstrate that our augmentation data via REM help the agent reduce its performance gap between the seen and unseen environment and improve the overall performance, making our model the best existing approach on the standard VLN benchmark. The code have released: https://github.com/LCFractal/VLNREM.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recently, there is a surge of research interests in Vision-Language Navigation (VLN) <ref type="bibr" target="#b3">[4]</ref> tasks, in which an agent <ref type="bibr">Figure 1</ref>. REM mixes up two scenes and generates data triplets (environment, path, instruction). We divide the two scenes and recombine them to construct a new cross-connected scene, and reconstruct the corresponding paths and instructions. learns to navigate by following a natural language instruction. The agent begins at a random point and goes towards a goal via actively exploring the environments. Before the navigation starts, the agent receives a language instruction. At every step, the agent can get the surrounding visual information. The key to this task is to perceive the visual scene and comprehend natural language instructions sequentially and make actions step-by-step.</p><p>Recent advances made by deep learning works in the domains of feature extraction <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">43]</ref>, attention <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b34">35]</ref> and multi-modal grounding <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b49">50]</ref> facilitate the agent to understand the environment. Moreover, many reinforcement learning works <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b47">48]</ref> help the agent to obtain a robust navigation policy. Benefited from these works, previous attempts in the field of Vision-Language Navigation have made great progress in improving the ability to perceive the vision and language inputs <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b54">55]</ref>, and learning a robust navigation policy <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b22">23]</ref>. How-ever, the VLN task still contains large bias due to the disparity ratio between small data scale and large navigation space, which impacts the generalization ability of navigation. Although the mostly widely used dataset, Room-toroom dataset <ref type="bibr" target="#b3">[4]</ref>, contains only 22K instruction-path pairs, the actual possible navigation path space increases exponentially along with the path length. Thus, the learned navigation policy can easily overfit to the seen scenes and is hard to generalize to the unseen scenes.</p><p>Previous works have proposed various data augmentation methods in an attempt to reduce data bias. Fried et al. propose a speaker-follower framework <ref type="bibr" target="#b15">[16]</ref> to generate more data pairs in order to reduce the data bias of the data samples. Tan et al. <ref type="bibr" target="#b50">[51]</ref> propose an environmental dropout method to augment the vision features in environments; thereby reducing the vision bias inside a house scene. However, these methods focus on intra-scene data augmentation and fail to explicitly reduce the data bias across different house scenes. Accordingly, in this paper, we propose to reduce the domain gap across different house scenes by means of scenewise data augmentation. If an agent sees different house scenes during a navigation process, it will be less likely to overfit to a part of the scene textures or room structures. Inspired by this motivation, we propose our method, named Random Environmental Mixup (REM), to improve the generalization ability of a navigation agent. REM breaks up two scenes and the corresponding paths, followed by recombining them to obtain a cross-connected scene between the two scenes. The REM method provides more generalized data, which helps reduce the generalization error, so that the agent's navigation ability in the seen and unseen scenes can be improved.</p><p>The REM method comprises three steps. First, REM selects the key vertexes in the room connection graph according to the betweenness centrality <ref type="bibr" target="#b7">[8]</ref>. Second, REM splits the scenes by the key vertexes and cross-connect them to generate new augmented scenes. We propose an orientation alignment approach to solve the feature mismatch problem. Third, REM splits trajectories and instructions into sub-trajectories and sub-instructions by their context, then cross-connects them to generate augmented training data. An overview of the REM method is presented in <ref type="figure" target="#fig_5">Fig. 1</ref>.</p><p>The experimental results on benchmark datasets demonstrate that REM can significantly reduce the performance gap between seen and unseen environments, which dramatically improves the overall navigation performance. Our ablation study shows that the proposed augmentation method outperforms other augmentation methods at the same augmentation data scales. Our final model obtains 59.1% in Success weighted by Path Length (SPL) <ref type="bibr" target="#b1">[2]</ref>, which is 2.4% higher than the previous state-of-the-art result; accordingly, our method becomes the new state-of-the-art method on the standard VLN benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Embodied Navigation Environments are attracting rising attention in artificial intelligence. House3D <ref type="bibr" target="#b57">[58]</ref> is a manually created large-scale environment. AI2-THOR <ref type="bibr" target="#b29">[30]</ref> is an interactable indoor environment. Agents can interact with certain interactable objects, such as opening a drawer or picking up a statue. Recent works have tended to focus on simulated environments based on real imagery. The Active Vision dataset <ref type="bibr" target="#b0">[1]</ref> consists of dense scans of 16 different houses. Moreover, Matterport3D <ref type="bibr" target="#b3">[4]</ref>, Gibson <ref type="bibr" target="#b58">[59]</ref> and Habitat <ref type="bibr" target="#b46">[47]</ref> propose high-resolution photo-realistic panoramic view to simulate more realistic environment. Vision-Language Navigation has attracted widespread attention, since it is both widely applicable and a challenging task. Anderson et al. <ref type="bibr" target="#b3">[4]</ref> propose the Room-to-Room (R2R) dataset, which is the first Vision-Language Navigation (VLN) benchmark to combine real imagery <ref type="bibr" target="#b8">[9]</ref> and natural language navigation instructions. In addition, the TOUCHDOWN dataset <ref type="bibr" target="#b10">[11]</ref> with natural language instructions is proposed for street navigation. To address the VLN task, Fried et al. propose a speaker-follower framework <ref type="bibr" target="#b15">[16]</ref> for data augmentation and reasoning in a supervised learning context, along with a concept named "panoramic action space" that is proposed to facilitate optimization. Wang et al. <ref type="bibr" target="#b54">[55]</ref> demonstrate the benefit of combining imitation learning <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b19">20]</ref> and reinforcement learning <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b47">48]</ref>. Other methods <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b23">24]</ref> have been proposed to solve the VLN tasks from various perspectives. Due to the success of BERT <ref type="bibr" target="#b14">[15]</ref>, researchers have extended it to learn vision-language representations in VLN. PRESS <ref type="bibr" target="#b32">[33]</ref> applies the pre-trained BERT to process instructions. PREVALENT <ref type="bibr" target="#b17">[18]</ref> pre-trains an encoder with image-text-action triplets to align the language and visual states, while VLN-BERT <ref type="bibr" target="#b38">[39]</ref> fine-tunes ViLBERT <ref type="bibr" target="#b33">[34]</ref> with trajectory-instruction pairs. Hong et al. <ref type="bibr" target="#b22">[23]</ref> implements a recurrent function to leverage the history-dependent state representations based on previous models. Data Augmentation is widely adopted in diverse deep learning methods. Early data augmentation methods in the field of computer vision were manually designed; these include distortions, scaling, translation, rotation and color shifting <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b45">46]</ref>. The traditional approach to text augmentation tends to involve a primary focus on wordlevel cases <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b56">57]</ref>. Some works have achieved success in using GAN to generate augmentation data <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b44">45]</ref>. Zhang et al. <ref type="bibr" target="#b59">[60]</ref> propose mixup, which is a linear interpolation augmentation method used to regularize the training of neural networks. Data augmentation has also been investigated in RL, including domain randomization <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b43">44]</ref>, cutout <ref type="bibr" target="#b12">[13]</ref> and random convolution <ref type="bibr" target="#b31">[32]</ref>. In the vision-language navigation context, Fried et al. propose to use a generation method <ref type="bibr" target="#b15">[16]</ref> to generate data pairs, while Tan et al. <ref type="bibr" target="#b50">[51]</ref> propose an environmental dropout method to augment the vision features in various environments. In a departure from these augmentation methods, our REM method cross-connects the scenes and the instruction-trajectory pairs, thereby improving the model's generalization ability among different scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Vision-language Navigation</head><p>Given a series of triples (environment E, path P , instruction I), the VLN task requires the agent to understand the instruction in order to find a matching path in the corresponding environment. The environment E contains a large number of seen and unseen scenes, the path P = {p 0 , . . . , p n } is composed of a list of viewpoints with a length of n; morever, instruction I = {w 0 , . . . , w m } consists of m words, and a certain correspondence exists between path P and instruction I. At time step t, the agent observes panoramic views O t = {o t,i } 36 i=1 and navigable viewpoints (at most k). The picture O t is divided into 12 views in the horizontal direction and 3 views in the vertical direction, for a total of 36 views. At the t-th step, the agent predicts an action a ? ? ? (I, O t ), where ? ? is the policy function defined by the parameter ?. The actions include 'turn left', 'turn right' and 'move forward' as defined in the Matterpot environment <ref type="bibr" target="#b3">[4]</ref>. In the Matterport dataset <ref type="bibr" target="#b8">[9]</ref>, each scene is discretisized by a navigation graph consists of viewpoints. We model each scene as a graph G = (V, E), where the vertexes set V is a set of scene viewpoints, while E is the connection between viewpoints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Reduce Generalization Error in VLN</head><p>The learning problem can be formulated as the search of the function f ? F, which minimizes the expectation of a given loss ?(f (x), y). However, the distribution P of sample (x, y) is generally unknown. We can often obtain a set T ? P and use it as a training set. The approximate functionf can then be implemented by Empirical Risk Minimization (ERM) <ref type="bibr" target="#b52">[53]</ref>. However, a gap still exists betweenf and f . This error describes the generalization ability off . The generalization error can be expressed as follows:</p><formula xml:id="formula_0">R ge (f ) = R(f ) ? R(f ) = (?(f (x), y) ? ?(f (x), y))dP(x, y).<label>(1)</label></formula><p>In order to enhance the generalization ability off , it is necessary to reduce R ge . According to the Vicinal Risk Minimization (VRM) <ref type="bibr" target="#b9">[10]</ref>:</p><formula xml:id="formula_1">R v (f ) = 1 m n i=1 ?(f (x),?),<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generalization Error</head><p>Training set " for I SA " for NSA " for REM ! " where (x,?) ? (T ?T ),T ? P,T ? T . This means that more samples are needed to lower R ge . When the number of samples is certain, the farther the distance d((x,?), T ) from the sample (x,?) to the training set T , the better the generalization ability.</p><formula xml:id="formula_2">$ !," $ !,! $ ","</formula><p>In the VLN task, the training set consists of N scenes:</p><formula xml:id="formula_3">T = (S 1 ? S 2 ? ? ? ? ? S N ).<label>(3)</label></formula><p>We define a data augmentation function aug(S i , S j ). The generated augmentation data follows the distribution P:</p><formula xml:id="formula_4">S i,i = aug(S i , S i ) ? P, S i,j = aug(S i , S j ) ? P,<label>(4)</label></formula><p>whereS i,i is the intra-scene augmentation data set, and S i,j is the inter-scene augmentation data set. According to Eqs. 1 and 2, we have the following assumption: compared withS i,i , the distance fromS i,j to S i is farther, denoted as</p><formula xml:id="formula_5">d(S i,i , S i ) &lt; d(S i,j , S i )</formula><p>. Therefore, the model learned on the inter-scene augmentation data has a smaller generalization error than which learned on the intra-scene augmentation data. Previous methods have proposed two kinds of data augmentation methods in VLN: the intra-scene augmentation (ISA) method, as in <ref type="bibr" target="#b15">[16]</ref>, only constructs new paths and instructions in the scene; the near-scene augmentation (NSA) method, as in <ref type="bibr" target="#b50">[51]</ref>, breaks through the limitations of the scene to a certain extent by adding Gaussian noise to the scene, but only expands the scene to a small neighborhood. For our part, we propose a inter-scene data augmentation method: Random Environmental Mixup (REM). REM method mixes up two scenes constructs a cross-connected scene between the two scenes. In contrast to the other meth- Get vertexes v s , v t of the edge e; ods, it exceeds the limitation of the scene itself and constructs augmentation data under a broader data distribution. <ref type="figure" target="#fig_0">Fig. 2</ref> illustrates the difference between three methods. The inter-scene method provides more generalized data; this helps to reduce the generalization error, meaning that the agent's navigation ability in the seen scene and the unseen scene can be improved. Subsequent experiments have verified this assumption.</p><formula xml:id="formula_6">9 n e = |P | i=1 (1 {e?pi} + 0 {e / ?pi} ); 10 if v s , v t ? V</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Random Environmental Mixup</head><p>We propose an inter-scene data augmentation method to construct new environments, paths, and instructions with the aid of training sets. In the training set of the VLN task, there are a large number of different scenes. We randomly select two scenes from the set of training scenes and mix them up to generate cross-connected scenes. Adopting this approach enables us to construct the corresponding paths and instructions. When mixing of scenes, we have the following problems: 1) how to choose key vertexes in the scene for mixup? 2) how to mix up two scenes to obtain cross-connected scenes? 3) how to construct new paths and instructions in cross-connected scenes? Solutions to these problems are presented below construct a large number of cross-connected scenes, that are unseen relative to the original training set.  The green edges are often the entrances and exits of rooms or corridors, we choose the two vertexes of the green edge that contains the most paths as the key vertexes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Select Key Vertexes</head><p>Key vertexes are crucial to mixing between scenes. Their characteristics can be summarized as follows: 1) the entrance or corridor that connects two rooms; 2) the vertex has many paths through it. In order to match the above characteristics, key vertexes can be selected with reference to the betweenness centrality <ref type="bibr" target="#b7">[8]</ref> of the graph:</p><formula xml:id="formula_7">V C B (v) = s? =v? =t?V ? st (v) ? st , EC B (e) = s? =t?V ;e?E ? st (e) ? st ,<label>(5)</label></formula><p>where V C B (v) is the betweenness centrality of the vertex v, EC B (e) is the betweenness centrality of the edge e; ? st (v) is the number of shortest paths from s to t, passes through the vertex v; ? st (e) is the number of shortest paths from s to t through edge e; ? st is the number of all shortest paths from s to t. Betweenness centrality describes the importance of vertex by the number of shortest paths passing through vertexes or edges. Once the vertex is removed from the graph, the points on both sides will be disconnected. As shown in <ref type="figure" target="#fig_3">Fig. 3</ref>, we select the top 10 vertexes and edges of betweenness centrality to obtain the corresponding sets V V C B and E EC B ; subsequently, by excluding edges in E EC B whose vertexes are not in V V C B , we obtain the final key subgraph G C B . In order to ensure that more paths are subsequently generated, we select the edge e key that contains the most supervised paths from G C B , along with its corresponding vertexes v key s , v key t . We observe from    that the entrances and exits of rooms or corridors often have the highest betweenness. The process of selecting key vertexes is summarized in Algo. 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Construct Augmented Triplets</head><p>Construct Cross-Connected Scenes We randomly select two scenes (Scene1 G 1 and Scene2 G 2 ) in the training set. We construct the cross-connected scene G C for G 1 and G 2 in three stages <ref type="figure" target="#fig_6">(Fig. 4</ref>). In stage 1: according to Algo.1, we obtain the key vertexes (v ). In this way, we obtain a cross-connected scene G C . In stage 3: we align the orientation of G C ; ensure the matching of the cross path and the instruction by adjusting the vertex position in G C . Construct Cross Viewpoints G C is a graph containing the connection relationship information without visual observation. Therefore, we build a cross viewpoint on the basis of G C to obtain a new cross-connected environment. The process of building a new cross-connected environment is illustrated in <ref type="figure" target="#fig_7">Fig. 5</ref>. Taking the v key1 s in Scene 1+2 as an example, as described in Sec. 3.1, each viewpoint panoramic view is divided into 12 views in the horizontal direction (indicated by the numbers 0-11). By mixing the views of View 1 and View 2, we can obtain a panoramic view of View 1+2. More specifically, the view is based on the direction of the next viewpoint. We replace three views around the original angle of View 2 with View 1 to get Cross-connected view(red 0-3 7-11 from View 1, blue 2-4 from View 2). The hyperparameter settings for replacing 3 views will be discussed in the experimental part.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Construct Cross Paths and Instructions</head><p>Crossconnecting the instructions and paths requires the instructions and paths to be fine-grained. In order to obtain the fine-grained data, we use Fine-Grained R2R <ref type="bibr" target="#b21">[22]</ref> to split the instructions and paths, as well as to align the subinstructions and the sub-paths. As shown in <ref type="figure" target="#fig_3">Fig. 4 (stage 3)</ref>, we obtain the path and instructions in the cross-connected scene by combining the sub-paths before and after the key vertex, along with the corresponding sub-instructions. Orientation Alignment Following <ref type="figure" target="#fig_0">Fig. 4 (stages 1 and 2)</ref>, we construct the cross-connected scenes and corresponding cross viewpoints. Simply connecting v key1 s and v key2 t leads to a mismatch of the related orientations of the ver- texes in the cross-connected scenes.; it is therefore necessary to align the orientation of the vertexes. More specifically, after the scenes and views are mixed, the direction of '?' changes ( <ref type="figure" target="#fig_7">Fig. 5</ref> from 90 ? to 150 ? ). Correspondingly, to enable it to go to the next viewpoint, the agent's action also changes (from '?' to '?'). However the instruction is still 'turn left'. To solve this problem of mismatch between action and instruction, we need to fix the position on the cross-connected scenes. To achieve this, as shown in <ref type="figure" target="#fig_3">Fig. 4  (stage 3)</ref>, we move the vertexes v key1 t , v key2 t and their associated vertexes, exchanging the position of the two vertexes, meaning that that the relative positions of the key vertexes remain unchanged. Through fixing the vertexes' position, the orientation of '?' is aligned (see <ref type="figure" target="#fig_7">Fig. 5</ref> final view). The agent's action and instructions accordingly match again.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Augmentation in Vision Language Navigation</head><p>At this point, we have constructed augmented triplets for training: (environment, path, instruction). Our method is able to mix up any two scenes into a new cross-connected scene. We can accordingly generate a large number of new scenes and their corresponding paths and instructions.</p><p>For VLN tasks, we need to export cross-connected scenes for training, including the viewpoints, connection relations and vertex positions. The augmented triplets will be merged directly with the original training set, namely T aug =T ? T ; we use T aug in place of T in training. The observation features in different directions for the cross viewpoint are derived from different scenes.  <ref type="table">Table 3</ref>. Model performance before and after orientation alignment. Before OA means before orientation alignment; After OA means after orientation alignment; CCV means replacement visual observation in construct cross viewpoints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Dataset and Evaluation Setup</head><p>Dataset and Simulator We evaluate our agent on the Room-to-Room (R2R) <ref type="bibr" target="#b3">[4]</ref> and R4R <ref type="bibr" target="#b26">[27]</ref> based on Matter-port3D simulator <ref type="bibr" target="#b8">[9]</ref>. This is a powerful navigation simulator. R4R builds upon R2R and aims to provide an even more challenging setting for embodied navigation agents. In a scene, the agent will jump between pre-defined viewpoints on the connectivity graph of the environment.</p><p>Evaluation Metrics There are already many recognized indicators used to evaluate models in VLN: Trajectory Length (TL), trajectory length in meters; Navigation Error (NE), error from the target point in meters; Success Rate (SR), the proportion of times that the agent successfully arrived within 3 meters of the target; and the success rate weighted by the path length (SPL) <ref type="bibr" target="#b1">[2]</ref>. In R4R, CLS <ref type="bibr" target="#b26">[27]</ref>, nDTW and SDTW <ref type="bibr" target="#b24">[25]</ref> take into account the agent's steps and are sensitive to intermediate errors in the navigation path. Implementation Details We use EnvDrop <ref type="bibr" target="#b50">[51]</ref> and VLN?Bert <ref type="bibr" target="#b22">[23]</ref> as the baselines to evaluate our method.</p><p>In the interests of fairness, we use the same experimental settings as the original method. On the basis of not changing the hyperparameter settings, augmented triplets are added for training. We randomly paired and mixed up the 61 scenes in the training set, finally obtaining 116 crossconnected scenes, 5916 paths and 7022 instructions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results on VLN Standard Benchmark</head><p>In this section, our method is compared with several other representative methods. We apply the proposed REM to three baseline methods and compare them with other methods. Tab. 1 shows the results on R2R. REM achieves excellent performance on the three baseline methods. In the state-of-the-art method, REM can further improve performance.  <ref type="table">Table 4</ref>. The impact of replacing the number of different views on the model performance. "0 View" means that visual observation is not replaced three baseline methods have been significantly improved. In addition to the success rate and SPL, REM can also significantly improve CLS and nDTW, which shows that the proposed method can make the agent follow the instructions and make the navigation path more matched.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Method Analysis</head><p>Orientation Alignment In Sec. 4.2, we propose the orientation alignment operation. Tab. 3 shows the performance difference between no orientation alignment (Before OA) and orientation alignment (After OA). Orientation alignment increases the success rate of the baseline by 1%. If the orientation is not aligned, the performance of the model will decrease instead. This is because the agent's actions and instructions do not match, and the agent cannot correctly learn the relationship between instructions and action. In addition, we tested the effect of replacing visual observation (CCV) on the results, and After OA achieved the highest improvement. Replace Visual Observation In the process of constructing the cross viewpoint, we performed the operation of replacing the visual observation in the specified direction. There are a total of 12 view directions in the horizontal direction. We experimented to determine how many views should be replaced to achieve the best results for the model. Tab.4 outlines the effect of replacing different numbers of views on model performance. As the table shows, three views is the optimal choice. Excessive replacement of visual observation information is thus suboptimal. Through experiments, we choose each cross viewpoint in REM to replace views in three horizontal directions. <ref type="figure" target="#fig_9">Fig. 6</ref> shows a schematic diagram of cross viewpoints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Ablation Analysis</head><p>In order to compare the impact of the number of mixup environments on REM performance, we limited the amount of training data (a data ratio of 1 means 7022 instructions),  and compared four different settings: 1) as the amount of data increases, the environments number available for mixup also increases in the same proportion; 2) mixup is always used for all environments, but the instructions number generated; 3) NSA is used to generate the same instructions number; 4) ISA is used to generate the same instructions number. The success rate can indicate the generalization ability of different methods. The higher the success rate of the method, the stronger its generalization ability. The results are shown in <ref type="figure" target="#fig_10">Fig. 7</ref>. With the increase of sampled data, all methods achieve improvements in model performance to a certain extent. When the data ratio is 1, the red and blue dots have the same setting, the red dot reaches the peak of performance; this means that when the number of mixed scenes is fixed, continuing to increase the sam-ple data cannot further reduce the generalization error. For the blue line, there is no performance degradation trend observed when the data ratio is 1, which shows that increasing the number of mixed scenes can continue to reduce the generalization error. The difference between the red-blue and orange-green lines indicates that, when the sample number is the same, the inter-scene data augmentation is significantly better than the intra-scene data augmentation. This verifies the assumption presented in Sec. 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we analyze the factors that affect generalization ability and put forward the assumption that interscene data augmentation can more effectively reduce generalization errors. We accordingly propose the Random Environmental Mixup (REM) method, which generates crossconnected house scenes as augmented data via mixuping environment. The experimental results on benchmark datasets demonstrate that REM can significantly reduce the performance gap between seen and unseen environments. Moreover, REM dramatically improves the overall navigation performance. Finally, the ablation analysis verifies our assumption pertaining to the reduction of generalization errors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>The generalization error of the original training set and different augmentation training sets. With Original (Red) ? ISA (Orange) ? NSA (Green) ? REM (Blue), the distance between T andT is getting farther and farther, and the generalization error decreases accordingly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>then 11 if m &lt; n e then 12 m</head><label>1112</label><figDesc>= n e ;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Selecting key vertexes through betweenness centrality.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Fig. 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>1+2 1 2</head><label>1</label><figDesc>Walk past the table and turn right. Turn left and walk up the stairs. Make a right to exit the screened enclosure. Wait near the open screen door. Walk past the table and turn right. Turn left and walk up the stairs. Make a right to exit the screened enclosure. Wait near the open screen door. Walk past the table and turn right. Turn left and walk up the stairs. Make a right to exit the screened enclosure. Wait near the open screen door.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Three stages of mixup scenes. Stage 1: select key vertexes (v key1 s Stage 3: fix the position of the vertexes, align the orientation of (The instructions are fine-grained, and the sub-paths of different colors are matched with the subinstructions of the corresponding colors. As the scene is mixed up, paths and instructions are also broken up and reconstructed. The constructed scenes, paths and instructions are combined into triples, which become augmentation data for VLN tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>The process of mixing up viewpoints. View 1 is the visual observation of v key1 s in Scene 1, while View 2 is the visual observation of v key2 sin Scene 2. The solid arrow is the current direction of the agent. The dotted arrow is the direction of the agent after taking the action. '?' represents the direction to the next viewpoint. 'turn left' is the instruction received by the agent. '?,?' are the 'turn left' and 'forward' actions taken by the agent in order to arrive at the next viewpoint.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>)</head><label></label><figDesc>for G 2 . In stage 2: we mix up G 1 ,G 2 into graph G C , disconnect the two key edges e key1 ,e key2 , and link (v key1 s</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 6 .</head><label>6</label><figDesc>Schematic diagram of cross viewpoints. After the key viewpoints of the two scenes are mixed; the upper and lower two viewpoints' divided views exchange each other; the two viewpoints on the left and right are connected to each other, and the agent can go to each other through '?'.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 .</head><label>7</label><figDesc>Success rates of agents trained with different amounts of data. The same data ratio in the figure indicates that the same amount of data is used. The blue line indicates that the results are increased by gradually adding new environments to the supervised training method. The red line only gradually increases the amount of data and randomly selects data from all training environments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1 :</head><label>1</label><figDesc>Selecting key vertexes Input: Scene graph G; Paths list P = {p 1 , ..., p |P | } Output: Key vertexes v key s , v key t 1 Get vertexes set V of G; 2 Get edges set E of G; 3? = {v | top 10 v in V ordered by V C B (v)}; 4? = {e | top 10 e in E ordered by EC B (e)}; 5 m = 0; 6 // Select the vertex passed by the most paths.</figDesc><table /><note>7 for e in E do 8</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>VLN?Bert+REM 10.88 2.48 75.4 71.8 12.44 3.89 63.6 57.9 13.11 3.87 65.2 59.1 Comparison of agent performance on R2R in single-run setting. * reproduced results in my environment. Comparison of agent performance on R4R in single-run setting. * reproduced results in my environment.</figDesc><table><row><cell>Method</cell><cell cols="5">R2R Validation Seen TL NE? SR? SPL?</cell><cell cols="4">R2R Validation Unseen TL NE? SR? SPL?</cell><cell cols="2">TL</cell><cell cols="2">R2R Test Unseen NE? SR? SPL?</cell></row><row><cell>Random</cell><cell cols="2">9.58 9.45</cell><cell>16</cell><cell>-</cell><cell cols="3">9.77 9.23</cell><cell>16</cell><cell>-</cell><cell cols="4">9.89 9.79</cell><cell>13</cell><cell>12</cell></row><row><cell>Human</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="4">11.85 1.61</cell><cell>86</cell><cell>76</cell></row><row><cell>Seq2Seq-SF [4]</cell><cell cols="2">11.33 6.01</cell><cell>39</cell><cell>-</cell><cell cols="3">8.39 7.81</cell><cell>22</cell><cell>-</cell><cell cols="4">8.13 7.85</cell><cell>20</cell><cell>18</cell></row><row><cell>Speaker-Follower [16]</cell><cell>-</cell><cell>3.36</cell><cell>66</cell><cell>-</cell><cell></cell><cell>-</cell><cell>6.62</cell><cell>35</cell><cell>-</cell><cell cols="4">14.82 6.62</cell><cell>35</cell><cell>28</cell></row><row><cell>SMNA [37]</cell><cell>-</cell><cell>3.22</cell><cell>67</cell><cell>58</cell><cell></cell><cell>-</cell><cell>5.52</cell><cell>45</cell><cell>32</cell><cell cols="4">18.04 5.67</cell><cell>48</cell><cell>35</cell></row><row><cell>RCM+SIL [55]</cell><cell cols="2">10.65 3.53</cell><cell>67</cell><cell>-</cell><cell cols="3">11.46 6.09</cell><cell>43</cell><cell>-</cell><cell cols="4">11.97 6.12</cell><cell>43</cell><cell>38</cell></row><row><cell>PRESS [33]</cell><cell cols="2">10.57 4.39</cell><cell>58</cell><cell>55</cell><cell cols="3">10.36 5.28</cell><cell>49</cell><cell>45</cell><cell cols="4">10.77 5.49</cell><cell>49</cell><cell>45</cell></row><row><cell>FAST-Short [28]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell cols="3">21.17 4.97</cell><cell>56</cell><cell>43</cell><cell cols="4">22.08 5.14</cell><cell>54</cell><cell>41</cell></row><row><cell>EnvDrop [51]</cell><cell cols="2">11.00 3.99</cell><cell>62</cell><cell>59</cell><cell cols="3">10.70 5.22</cell><cell>52</cell><cell>48</cell><cell cols="4">11.66 5.23</cell><cell>51</cell><cell>47</cell></row><row><cell>AuxRN [62]</cell><cell>-</cell><cell>3.33</cell><cell>70</cell><cell>67</cell><cell></cell><cell>-</cell><cell>5.28</cell><cell>55</cell><cell>50</cell><cell>-</cell><cell></cell><cell></cell><cell>5.15</cell><cell>55</cell><cell>51</cell></row><row><cell>PREVALENT [18]</cell><cell cols="2">10.32 3.67</cell><cell>69</cell><cell>65</cell><cell cols="3">10.19 4.71</cell><cell>58</cell><cell>53</cell><cell cols="4">10.51 5.30</cell><cell>54</cell><cell>51</cell></row><row><cell>RelGraph [21]</cell><cell cols="2">10.13 3.47</cell><cell>67</cell><cell>65</cell><cell cols="3">9.99 4.73</cell><cell>57</cell><cell>53</cell><cell cols="4">10.29 4.75</cell><cell>55</cell><cell>52</cell></row><row><cell>VLN?Bert [23]</cell><cell cols="2">11.13 2.90</cell><cell>72</cell><cell>68</cell><cell cols="3">12.01 3.93</cell><cell>63</cell><cell>57</cell><cell cols="4">12.35 4.09</cell><cell>63</cell><cell>57</cell></row><row><cell>IL+RL* [51]</cell><cell cols="4">10.25 4.91 53.8 50.7</cell><cell cols="5">9.38 5.89 46.2 42.5</cell><cell cols="4">9.58 5.88 46.4 43.3</cell></row><row><cell>IL+RL+REM</cell><cell cols="4">10.18 4.61 58.2 55.3</cell><cell cols="5">9.40 5.59 48.6 44.8</cell><cell cols="4">9.81 5.67 48.7 45.1</cell></row><row><cell>EnvDrop* [51]</cell><cell cols="4">10.46 3.78 64.4 62.0</cell><cell cols="9">9.50 5.52 51.1 47.3 11.32 5.84 50.5 46.5</cell></row><row><cell>EnvDrop+REM</cell><cell cols="13">11.13 3.14 70.1 66.7 14.84 4.99 53.8 48.8 10.73 5.40 54.1 50.4</cell></row><row><cell>VLN?Bert* [23]</cell><cell cols="13">12.09 2.99 70.7 65.9 12.58 4.02 61.4 55.6 11.68 4.35 61.4 56.7</cell></row><row><cell>Method</cell><cell cols="13">R4R Validation Seen NE? SR? SPL? CLS? nDTW? SDTW? NE? SR? SPL? CLS? nDTW? SDTW? R4R Validation Unseen</cell></row><row><cell cols="5">Speaker-Follower [27] 5.35 51.9 37.3 46.4</cell><cell>-</cell><cell></cell><cell>-</cell><cell cols="5">8.47 23.8 12.2 29.6</cell><cell>-</cell><cell>-</cell></row><row><cell>RCM [27]</cell><cell cols="4">5.37 52.6 30.6 55.3</cell><cell>-</cell><cell></cell><cell>-</cell><cell cols="3">8.08 26.1 7.7</cell><cell cols="2">34.6</cell><cell>-</cell><cell>-</cell></row><row><cell>PTA [31]</cell><cell cols="4">4.53 58.0 39.0 60.0</cell><cell>58.0</cell><cell></cell><cell>41.0</cell><cell cols="5">8.25 24.0 10.0 37.0</cell><cell>32.0</cell><cell>10.0</cell></row><row><cell>EGP [14]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell cols="2">8.00 30.2</cell><cell>-</cell><cell cols="2">44.4</cell><cell>37.4</cell><cell>17.5</cell></row><row><cell>BabyWalk [63]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell cols="5">8.2 27.3 14.7 49.4</cell><cell>39.6</cell><cell>17.3</cell></row><row><cell>IL+RL* [51]</cell><cell cols="4">5.94 35.3 32.5 37.1</cell><cell>38.7</cell><cell></cell><cell>26.5</cell><cell cols="5">8.88 31.9 18.7 32.3</cell><cell>31.7</cell><cell>12.2</cell></row><row><cell>IL+RL+REM</cell><cell cols="4">6.72 39.9 36.5 42.4</cell><cell>47.3</cell><cell></cell><cell>31.2</cell><cell cols="5">8.83 33.1 20.1 38.6</cell><cell>37.6</cell><cell>15.7</cell></row><row><cell>EnvDrop* [51]</cell><cell cols="4">5.94 42.7 39.5 40.2</cell><cell>41.8</cell><cell></cell><cell>29.6</cell><cell cols="5">9.18 34.7 21.0 37.3</cell><cell>34.7</cell><cell>12.1</cell></row><row><cell>EnvDrop+REM</cell><cell cols="4">5.83 46.3 43.5 45.1</cell><cell>49.7</cell><cell></cell><cell>33.4</cell><cell cols="5">8.21 37.9 25.0 42.3</cell><cell>39.7</cell><cell>18.5</cell></row><row><cell>VLN?Bert* [23]</cell><cell cols="4">4.84 55.7 46.0 47.8</cell><cell>55.8</cell><cell></cell><cell>37.9</cell><cell cols="5">6.48 42.5 32.4 41.4</cell><cell>41.8</cell><cell>20.9</cell></row><row><cell>VLN?Bert+REM</cell><cell cols="4">3.77 66.8 57.4 56.8</cell><cell>61.5</cell><cell></cell><cell>41.5</cell><cell cols="5">6.21 46.0 38.1 44.9</cell><cell>46.3</cell><cell>22.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Tab. 2 shows the results on R4R. Through REM, all Method NE? OR? SR? SPL? Views 4.64 65.1 57.2 54.9 3 Views 4.61 65.6 58.2 55.3 4 Views 4.67 64.0 57.6 55.0 Views 5.63 56.2 48.1 44.1 3 Views 5.59 56.0 48.6 44.8 4 Views 5.66 55.3 47.9 44.3</figDesc><table><row><cell>0 View</cell><cell>4.78 63.7 55.6 53.8</cell></row><row><cell>1 View 0 View 1 View 2 Val Unseen Val Seen 2</cell><cell>4.70 64.5 56.8 54.6 5.73 55.2 47.2 43.2 5.68 55.9 47.5 43.4</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A dataset for developing and benchmarking active vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Ammirato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Poirson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunbyung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Kosecka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1378" to="1385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devendra</forename><surname>Singh Chaplot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Kosecka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roozbeh</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir Roshan</forename><surname>Zamir</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.06757</idno>
		<title level="m">On evaluation of embodied navigation agents</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bottom-up and top-down attention for image captioning and visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Buehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Teney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6077" to="6086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">and Anton Van Den Hengel. Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Teney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>S?nderhauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Vqa: Visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2425" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">End to end learning for self-driving cars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariusz</forename><surname>Bojarski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><forename type="middle">Del</forename><surname>Testa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dworakowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Firner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beat</forename><surname>Flepp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasoon</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">D</forename><surname>Jackel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathew</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urs</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiakai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Zieba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.07316</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Gan augmentation: Augmenting training data using generative adversarial networks. arXiv: Computer Vision and Pattern Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Bowles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Guerrero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bentley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><forename type="middle">N</forename><surname>Gunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hammers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">Alexander</forename><surname>Dickie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Del</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vald?s Hern?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanna</forename><forename type="middle">M</forename><surname>Wardlaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Rueckert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ulrik Brandes. A faster algorithm for betweenness centrality</title>
	</analytic>
	<monogr>
		<title level="j">Journal of mathematical sociology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Matterport3d: Learning from rgb-d data in indoor environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Niebner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3DV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Vicinal risk minimization. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="416" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Touchdown: Natural language navigation and spatial reasoning in visual street environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Howard</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alane</forename><surname>Suhr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dipendra</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multicolumn deep neural networks for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Cire?an</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ueli</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3642" to="3649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Quantifying generalization in reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Cobbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taehoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1282" to="1289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Evolving graphical planner: Contextual global planning for vision-and-language navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.05655</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><forename type="middle">Toutanova</forename><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Speaker-follower models for vision-and-language navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Fried</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronghang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volkan</forename><surname>Cirik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taylor</forename><surname>Berg-Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Cognitive mapping and planning for visual navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Tolani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Davidson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.03920</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Towards learning a generic agent for visionand-language navigation via pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weituo</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Generative adversarial imitation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03476</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Language and visual entity relationship graph for agent navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yicong</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuankai</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Sub-instruction aware vision-and-language navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yicong</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Rodriguez-Opazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.02707</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A recurrent vision-and-language bert for navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yicong</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuankai</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Rodriguez-Opazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.13922</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Transferable representation learning in vision-and-language navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoshuo</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihan</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harsh</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Magalhaes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Ie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">General evaluation for instruction conditioned navigation using dynamic time warping. ViGIL@NeurIPS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihan</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Ie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reinforcement learning with unsupervised auxiliary tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><forename type="middle">Marian</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR 2017 : International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Stay on the path: Instruction fidelity in vision-and-language navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihan</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Magalhaes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Ie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Baldridge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Tactical rewind: Self-correction via backtracking in vision-and-language navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyiming</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Srinivasa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Contextual augmentation: Data augmentation by words with paradigmatic relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sosuke</forename><surname>Kobayashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="452" to="457" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Ai2-thor: An interactive 3d environment for visual ai</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Kolve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roozbeh</forename><surname>Mottaghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuke</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.05474</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Perceive, transform, and act: Multi-modal attention networks for vision-and-language navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Landi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Baraldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcella</forename><surname>Cornia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Corsini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rita</forename><surname>Cucchiara</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.12377</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Network randomization: A simple technique for generalization in deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eighth International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Robust navigation with language pretraining and stochastic sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaolin</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bisk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Hierarchical question-image co-attention for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="289" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Selfmonitoring navigation agent via auxiliary progress estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghassan</forename><surname>Alregib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Selfmonitoring navigation agent via auxiliary progress estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghassan</forename><surname>Alregib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The regretful agent: Heuristic-aided navigation through progress estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Yao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuxuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghassan</forename><surname>Alregib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Improving visionand-language navigation with image-text pairs from the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayush</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.14973</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Asynchronous methods for deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volodymyr</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adri?</forename><forename type="middle">Puigdom?nech</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Asymmetric actor critic for image-based robot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lerrel</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems XIV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
	<note>Wojciech Zaremba, and Pieter Abbeel</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.01497</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Cad2rl: Real singleimage flight without a single real image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fereshteh</forename><surname>Sadeghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Data augmentation using generative adversarial networks (cyclegan) to improve generalizability in ct segmentation tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veit</forename><surname>Sandfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald M</forename><surname>Pickhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikuro</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Nishimura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kensuke</forename><surname>Yokoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Apac</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.03229</idno>
		<title level="m">Augmented pattern classification with neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Habitat: A platform for embodied ai research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kadian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Maksymets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yili</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Wijmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhavana</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Straub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Best practices for convolutional neural networks applied to visual document analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Steinkraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh International Conference on Document Analysis and Recognition</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="958" to="963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Lxmert: Learning crossmodality encoder representations from transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning to navigate unseen environments: Back translation with environmental dropout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Licheng</forename><surname>Hao Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Domain randomization for transferring deep neural networks from simulation to the real world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tobin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Statistical learning theory 156-160</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Regularization of neural networks using dropconnect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sixin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Le Cun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 30th International Conference on Machine Learning</title>
		<meeting>The 30th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1058" to="1066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Reinforced cross-modal matching and selfsupervised imitation learning for vision-language navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuyuan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asli</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinghan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan-Fang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Look before you leap: Bridging model-free and model-based reinforcement learning for planned-ahead vision-and-language navigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07729</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Eda: Easy data augmentation techniques for boosting performance on text classification tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">W</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6381" to="6387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Building generalizable agents with a realistic and rich 3d environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Gibson env: Real-world perception for embodied agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyang</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Sax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Character-level convolutional networks for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1509.01626</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Vision-language navigation with self-supervised auxiliary reasoning tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengda</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Babywalk: Going farther in vision-and-language navigation by taking baby steps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hexiang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihan</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Ie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04625</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
