<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lepard: Learning partial point cloud matching in rigid and deformable scenes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Li</surname></persName>
							<email>liyang@mi.t.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<country>2 RIKEN</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
							<email>harada@mi.t.u-tokyo.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Tokyo</orgName>
								<address>
									<country>2 RIKEN</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Lepard: Learning partial point cloud matching in rigid and deformable scenes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Figure 1</ref><p>. We propose a feature matching method for rigid (left) and deformable (right) point clouds that are captured by range sensors. Results shown are the initial alignment, the predicted matches (blue/red lines indicate inliers/outliers), and the registration results. Registration is done by RANSAC for rigid and non-rigid ICP for deformable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>We present Lepard, a Learning based approach for partial point cloud matching in rigid and deformable scenes. The key characteristics are the following techniques that exploit 3D positional knowledge for point cloud matching: 1) An architecture that disentangles point cloud representation into feature space and 3D position space. 2) A position encoding method that explicitly reveals 3D relative distance information through the dot product of vectors. 3) A repositioning technique that modifies the crosspoint-cloud relative positions. Ablation studies demonstrate the effectiveness of the above techniques. In rigid cases, Lepard combined with RANSAC and ICP demonstrates state-of-the-art registration recall of 93.9% / 71.3% on the 3DMatch / 3DLoMatch. In deformable cases, Lepard achieves +27.1% / +34.8% higher non-rigid feature matching recall than the prior art on our newly constructed 4DMatch / 4DLoMatch benchmark. Code and data are available at https://github.com/rabbityl/lepard.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Matching partial point clouds from range sensors lies at the core of many 3D computer vision applications including SLAM and dynamic tracking and reconstruction. The former assumes rigid scenes, e.g. <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b46">47]</ref>, while the latter focuses on scenes that are non-rigidly deforming, e.g. <ref type="bibr" target="#b45">[46]</ref>. This work aims at developing a robust point clouds match-ing method for both rigid and deformable scenes.</p><p>Point cloud matching methods often consist of two phases: point cloud feature extraction followed by nearest neighbor search in feature space. Recent learning-based works have made substantial progress for representation learning in 3D data. State-of-the-art point clouds matching approaches <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b25">26]</ref> employ the geometry features extracted by 3D convolutional networks, such as the KPConvbased <ref type="bibr" target="#b62">[63]</ref> or the Minkowski Engine <ref type="bibr" target="#b12">[13]</ref>. These 3D feature extractors are strictly translation invariant, and, to a certain extent, also invariant to rotation transformations given the commonly adopted max-pooling layers in the networks and random rotation-based data augmentation during training.</p><p>Transformation invariance is well suited for local geometry feature representation. However, it may cause ambiguity in scenes that have repetitive geometry patterns. For instance, the same kind of chairs scattered in different locations of a floor, or left and right hands of a human could yield similar geometry features. We argue that such ambiguity can be resolved by enhancing geometry features with the 3D positional knowledge. Intuitively, humans associate things across observations by referring to not only things' appearance but also their relative locations.</p><p>Motivated by the above observations, we design Lepard, a novel partial point clouds matching method that exploits 3D positional knowledge. We first build our baseline using the fully convolutional feature extractor KPFCN <ref type="bibr" target="#b62">[63]</ref>, the concept of Transformer <ref type="bibr" target="#b64">[65]</ref> with self and cross attention, and the idea of differentiable matching <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b61">62]</ref>. Then, to leverage 3D position information, we introduce the fol-lowing techniques: 1) A framework that fully disentangles the point cloud representations into a features space and a position space. 2) A position encoding method that explicitly reveals 3D relative distance information through the dot product of vectors. 3) A repositioning module that adjusts the cross-point-cloud relative positions which benefits cross attention and differentiable matching. Ablation studies demonstrate the effectiveness of the above techniques.</p><p>In addition, we propose a partial point cloud matching benchmark called 4DMatch, and its low overlap version 4DLoMatch. 4DMatch contains point clouds that are non-rigidly deforming across the time axis. Compared to the rigid situations, the time-varying geometry in 4DMatch poses more challenges for both matching and registration.</p><p>We apply Lepard for both rigid and deformable point cloud matching. In rigid cases, Lepard combined with RANSAC and ICP demonstrates state-of-the-art registration recall of 93.9% / 71.3% on the 3DMatch / 3DLoMatch. On the newly proposed 4DMatch and 4DLoMatch benchmarks, Lepard achieves +27.1% and +34.8% higher nonrigid matching recall than the prior art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work 2.1. Rigid Point Cloud Matching and Registration</head><p>Local descriptors prediction followed by the robust RANSAC-based <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b56">57]</ref> optimization is a long-studied approach. Early works employ hand engineered descriptors <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b63">64]</ref>. Recent learning-based approaches have made significant progresses for point feature representation <ref type="bibr">[1, 6, 14-16, 18, 19, 21, 26, 30, 32, 39, 66, 71, 74, 76]</ref>. 3DMatch <ref type="bibr" target="#b75">[76]</ref> made the first attempt to extract descriptors using the siamese network. FCGF <ref type="bibr" target="#b13">[14]</ref> leverages the fully convolutional network <ref type="bibr" target="#b40">[41]</ref> structure for dense feature extraction. D3feat <ref type="bibr" target="#b5">[6]</ref> jointly learns feature description with point saliency detection. Predator <ref type="bibr" target="#b25">[26]</ref> adopts the attention mechanism to predict overlapping regions for feature sampling. CoFiNet <ref type="bibr" target="#b73">[74]</ref> learns feature descriptors in a coarseto-fine manner.</p><p>Another line of research focuses on direct registration. ICP <ref type="bibr" target="#b7">[8]</ref> and FGR <ref type="bibr" target="#b76">[77]</ref> optimize the pose using secondorder gradients. Go-ICP <ref type="bibr" target="#b71">[72]</ref> achieves global registration with a SE(3) space searching schema. Recent works incorporate learned models into end-to-end pose optimization <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b72">73]</ref>. PointNetLK <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b33">34]</ref> formulate point cloud registration as a Lucas Kanade-based [7] optimization task; Wang et al. <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b67">68]</ref> learn registration through graph neural networks. DGR <ref type="bibr" target="#b11">[12]</ref> and 3DRegNet <ref type="bibr" target="#b48">[49]</ref> learn correspondence weighting networks to reject outliers. This paper is about enhancing the point cloud feature descriptors with 3D positional knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Non-Rigid Correspondence</head><p>Estimating non-rigid correspondence from real-world sensor data is a key task for online non-rigid reconstruction <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b45">46]</ref>. DynamicFusion <ref type="bibr" target="#b45">[46]</ref> employs the simple projective correspondence for real-time efficiency. VolumeDeform <ref type="bibr" target="#b26">[27]</ref> incorperates SIFT <ref type="bibr" target="#b41">[42]</ref> descriptor-based correspondence for robust non-rigid tracking. Schmidt et al. <ref type="bibr" target="#b55">[56]</ref> uses DynamicFusion to supervise a siamese network for dense correspondence learning. DeepDeform <ref type="bibr" target="#b9">[10]</ref> learns sparse global correspondence for patches in non-rigid deforming RGB-D sequences. Li et al. <ref type="bibr" target="#b34">[35]</ref> learns non-rigid features through a differentiable non-rigid alignment optimization. NNRT <ref type="bibr" target="#b8">[9]</ref> focuses on end-to-end robust correspondence estimation with an outlier rejection network. Scene flow estimation, e.g. <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b68">69]</ref>, is a closely related technique which usually delivers inter-frame level correspondence.</p><p>Non-Rigid correspondence is also a major topic in geometry processing where the input data are usually manifold surfaces. Huang et al. <ref type="bibr" target="#b24">[25]</ref> filters outliers using isometric deformation assumption. 3DCODED <ref type="bibr" target="#b21">[22]</ref> achieve shape correspondence through latent code optimization. Functional map <ref type="bibr" target="#b47">[48]</ref> have been proposed to produce shape correspondence in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b51">52]</ref>.</p><p>This paper is about developing a general non-rigid feature matching method for partial point cloud scans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem Definition</head><p>Given a source point clouds S ? R n?3 and a target point cloud T ? R m?3 , where n, m are the number of points, our goal is to find a set of matches K, which can be used to recover the warp function W : R 3 ? R 3 that aligns S to T. In this paper, we focus on both rigid and deformable point clouds. In rigid cases, the warp function W is parameterized by a SE(3) transformation. In deformable cases, W is generalized to the dense per-point warp field. Given the ground truth warp function W gt , an inlier match</p><formula xml:id="formula_0">(S i ? R 3 , T j ? R 3 ) ? K should satisfies ||W gt (S i ) ? T j || 2 &lt; ?,</formula><p>where || ? || 2 is the Euclidean norm, and ? is the tolerance radius for a match.</p><p>Partial Overlap. In real-world range sensor data, due to object motion or viewpoint change, a point in S does not necessarily have a corresponding point in T. This is referred to as a non-overlapping point. We define the set of overlapping points O T S for the source point cloud by:</p><formula xml:id="formula_1">O T S = {S i |S i ? S ? ||W gt (S i ) ? NN(W(S i ), T)|| 2 &lt; ?}</formula><p>where NN(?, ?) is the nearest neighbor search operator. Then the overlap ratio can be calculated by |O T S |/|S|.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Local geometry feature extraction</head><p>Given the input source and target point clouds S and T, We use the function ? to extract multi-level geometry features. ? does the following two mappings:</p><formula xml:id="formula_2">(?, x?) = ?(S), (T, xT) = ?(T)</formula><p>Where? ? Rn ?3 andT ? Rm ?3 are the output point clouds, x? ? Rn ?d and xT ? Rm ?d are the extracted features with dimension d = 528.</p><p>We build ? based on the KPFCN backbone <ref type="bibr" target="#b62">[63]</ref>. KPFCN possesses the inductive bias of translation equivariance and locality, which are well suited for local geometry feature extraction. The default KPFCN has an UNet-like structure with the same number of pooling/un-pooling layers in the encoder/decoder. We remove the decoder units after the 2nd to the last un-pooling layer from the KPFCN backbone. Thus the output? andT are the down-sampled </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Relative 3D Positional Encoding</head><p>The KPFCN backbone learns strict translation invariant features. Translation invariant could cause ambiguity in scenes that have symmetric structures or globally repetitive geometry patches. To resolve such ambiguity, we enhance features with the transformation sensitive 3D positional information.</p><p>We use the Rotary positional encoding proposed in <ref type="bibr" target="#b59">[60]</ref> and extend it to the 3D case. Given a 3D point S i = (x, y, z) ? R 3 , and the it's feature x S i ? R d . The position encoding function PE :</p><formula xml:id="formula_3">R 3 ? R d ? R d is defined by PE(S i , x S i ) = ?(S i )x S i = ? ? ? ? ? M1 M2 . . . M d/6 ? ? ? ? ? x S i where ?(S i ) is a block diagonal matrix. Each diagonal block with size 6 ? 6 is defined by M k = ? ? ? ? ? ? ? ? cos x? k ? sin x? k 0 0 0 0 sin x? k cos x? k 0 0 0 0 0 0 cos y? k ? sin y? k 0 0 0 0 sin y? k cos y? k 0 0 0 0 0 0 cos z? k ? sin z? k 0 0 0 0 sin z? k cos z? k ? ? ? ? ? ? ? ? where ? k = 1 10000 6(k?1)/d , k ? [1, 2, .</formula><p>., d/6] encodes the index in the feature channel.</p><p>Compared to the Sinusoidal encoding <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b64">65]</ref>, it has two advantages: 1) ?(?) is an orthogonal function, the encoding only changes the feature's direction but not the fea- ture's length, which could potentially stabilize the learning process. 2) The dot product of two encoded features</p><formula xml:id="formula_4">PE(S i , x S i ), PE(S j , x S j ) can be derived to: [?(S i )x S i ] T ?(S j )x S j = (x S i ) T ?(S j ? S i )x S j<label>(1)</label></formula><p>which means the relative 3D distance information can be explicitly revealed by the dot product. We adopt this positional encoding in both the transformer (Sec. 4.3) and matching (Sec. 4.4) layers. The comparison with Sinusoidal encoding can be found in Sec. 6.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Transformer</head><p>After the local geometry extraction, x? and xT are passed through the transformer block with a self attention layer to aggregate the global context, followed by a cross attention layer to exchange information between two point clouds. Following <ref type="bibr" target="#b64">[65]</ref>, the attention operation selects the relevant information by measuring the similarity between the query vector q, and the key vector k. The output vector is the sum of the value vector v weighted by the similarity scores.</p><p>Self Attention Layer. In self attention layer, q and (k, v) are obtained from the same point clouds (either from source or the target). Below shows the example of self attention for the source?. The vectors q, k, v are first computed by</p><formula xml:id="formula_5">q i = ?(? i )W q x? i k j = ?(? j )W k x? j v j = W v x? j (2) where W q , W k , W v ? R d?d are learnable projection matri- ces. The feature x? i is finally updated by x? i ? x? i + MLP(cat[q i , j a ij v j ])<label>(3)</label></formula><p>where</p><formula xml:id="formula_6">a ij = softmax(q i k T j / ? d)</formula><p>is the attention weight, MLP(?) denotes a 3-layer fully connected network, and cat[?, ?] is the concatenation operator.</p><p>Cross-Attention Layer. In cross-attention layer, the input vectors q and (k, v) are obtained from different point clouds depending on the direction of cross-attention (? ?T or T ?? ). After replacing the contents for q, k, and v, the formations are the same with self attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Position Aware Feature Matching</head><p>After the transformer layer, we compute the scoring matrix S between two point clouds as</p><formula xml:id="formula_7">S(i, j) = 1 ? d ?(? i )W?x? i , ?(T j )WTxT j<label>(4)</label></formula><p>where W?, WT ? R d?d are learnable projection matrices. The features are position-encoded such that the matching algorithm could take the spatial distance into account. We apply softmax on both dimensions (kown as the dual-softmax operation <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b61">62]</ref>) to convert the scroing matrix to confidence matrix C.</p><formula xml:id="formula_8">C(i, j) = Softmax(S(i, ?)) ? Softmax(S(?, j))</formula><p>Another option for matching is the sinkhorn optimal transport algorthm as in <ref type="bibr" target="#b54">[55]</ref>. The comparison can be seen in Sec. 6.1.</p><p>Match Prediction. Based on the confidence matrix C, we select matches with confidence higher than a threshold of ? c , and further enforce with mutual nearest neighbor (MNN) criteria. The influence of ? c can be found in the supplemental ablation study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Disentanglement between Position and Feature.</head><p>As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, we hold the position code and geometry features in separated data streams. They are combined only when a similarity matrix needs to be computed. In the transformer layers (c.f. Eqn. 2 and 3), position code ?(?) is only multiplied to query q and key k but not to the value v, i.e. ?(?) can influence the attention weights but can not be a part of the feature. This technique leads to the Disentanglement between position and feature. Opposed to this is regarded as Entangled, which does not hold separate data streams for position and feature, i.e. they are mixed at the very beginning of the transformer. The comparison is seen in Sec. 6.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Rigid Fitting With Soft Prucrustes</head><p>Given the the confidence matrix C, we select the matches set K sof t with topn matching scores, and then fit them with a rigid rotation R ? SO3 and translation t ? R 3 . Heren is the number of points in the source cloud?. Following <ref type="bibr" target="#b2">[3]</ref>, the rotation is computed from the SVD decomposition of</p><formula xml:id="formula_9">the matrix H = U ?V T . H ? R 3?3 is obtained with: H = (i,j)?K sof tC (i, j)? iT T j whereC(i, j)</formula><p>is the normalized confidence score. Then the rotation and is computed by</p><formula xml:id="formula_10">R = U diag(1, 1, det(U V T ))V</formula><p>Then the translation is obtained with</p><formula xml:id="formula_11">t = 1 |K sof t | ( (i,?)?K sof t? i ? R (?,j)?K sof tT j )</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Repositioning</head><p>The position encoding in Eqn. 1 can reveal 3D relative distance information between a pair of points. However, this distance knowledge is often incorrect for point pairs from two unaligned point clouds. In other words, this position encoding benefits self-attention but may become irrelevant or noisy signals for cross-attention and matching. To this end, we adjust the position code ?(? i ) of? with the rigid fitting R, t from the soft Procrustes layer by</p><formula xml:id="formula_12">?(? i ) ? ?(R? i + t)</formula><p>We call it as repositioning. An example is shown in <ref type="figure" target="#fig_4">Fig. 3</ref>. Intuitively, repositioning pushs corresponding points closer in the position space such that it better informs cross attention and also facilitates position aware matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.">Supervision</head><p>Matching Loss. We minimize the focal loss over the confidence matrix C returned by the matching layer. It is defined as:</p><formula xml:id="formula_13">L m = ? 1 |K gt | (i,j)?Kgt ?(1 ? C(i, j)) ? log C(i, j)</formula><p>where ? = 0.25 and ? = 2 are empirically decided focal loss parameters as in <ref type="bibr" target="#b37">[38]</ref>, and K gt is the set of ground-truth matches. During training, we warp? toT using the groundtruth wrap function W gt , and then collect the set of mutual nearest neighbors of the two-point clouds that are below a distance threshold as K gt .</p><p>Warping Loss. We minimize the L 1 loss for the point clouds that is warped by the R,t from the Procrustes layer. It is defined as</p><formula xml:id="formula_14">L w = 1 |OT S | i?OT S |W gt (? i ) ? R? i ? t|</formula><p>where OT S is the set of overlapping points in?, and W gt (?) is the ground truth warp function. Intuitively, in rigid cases, L w regularizes the optimization by suppressing falsepositives in K sof t and also encourages sub-point accuracy for soft correspondences; in deformable cases, L w tries to approximate a "root" pose that aligns the principal part of the overlapping region, e.g. the deer in <ref type="figure" target="#fig_4">Fig. 3</ref>.</p><p>Total Loss. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, the Transform-Matching-Procrustes (TMP) block repeats two times. The total loss combines the matching loss and warpping loss from the 1st and 2nd TMP blocks:</p><formula xml:id="formula_15">L = (L 1 m + L 2 m ) + ? w (L 1 w + L 2 w )</formula><p>where ? w is the weighting factor of warpping loss. We show ablation study for ? w and the number of TMP blocks (2, 3, and 4) in supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">4DMatch</head><p>We propose 4DMatch, a benchmark for matching and registration of partial point clouds with time-varying geometry. 4DMatch is constructed using the sequence from DeformingThings4D <ref type="bibr" target="#b35">[36]</ref> which contains 1,972 animation sequences with ground truth dense correspondence. We randomly select 1761 animations and generate partial point cloud scans by synthesizing depth images.     shows examples of point cloud pairs with different overlap ratios. <ref type="figure" target="#fig_7">Fig. 5</ref> is the histogram of overlap ratio. The following shows the evaluation metrics for 4DMatch. Inlier ratio (IR). IR measures the fraction of correct matches in the predicted correspondences set K pred . A match is correct if it lies within a threshold ? = 0.04m after the transformation using the ground truth warp function W gt . It is defined as</p><formula xml:id="formula_16">IR = 1 |K pred | (p,q)?K pred ||W gt (p) ? q|| 2 &lt; ?<label>(5)</label></formula><p>where || ? || 2 is the Euclidean norm and [?] is the Iverson bracket.</p><p>Non-rigid Feature Matching Recall (NFMR). NFMR measures the fraction of ground-truth matches (u ? R 3 , v ? R 3 ) ? K gt that can be successfully recovered by the predicted correspondences (p ? R 3 , q ? R 3 ) ? K pred . Based on K pred , a sparse 3D scene flow filed F = {q ? p|(p, q) ? K pred } for the set of anchor points A = {p|(p, q) ? K pred } are constructed. Then the flow field F is propagated from A to a source point u in K gt using the inverse distance interpolation</p><formula xml:id="formula_17">?(u, A, F) = Ai?knn(u,A) F i ||p ? A i || ?1 2 Ai?knn(u,A) ||u ? A i || ?1 2<label>(6)</label></formula><p>where knn(?, ?) denotes the k-nearest neighbors search with k = 3. Finally, we define NFMR as</p><formula xml:id="formula_18">NFMR = 1 |K gt | (u,v)?Kgt ||?(u, A, F) ? v|| 2 &lt; ?</formula><p>Note that NFMR directly measures the fraction of groundtruth correspondences that are "recalled". It is a different concept from the Feature Matching Recall (FMR) in the rigid case <ref type="bibr" target="#b75">[76]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experimental Results</head><p>3DMatch and 3DLoMatch. 3DMatch <ref type="bibr" target="#b75">[76]</ref> and 3DLo-Match <ref type="bibr" target="#b25">[26]</ref> are a benchmark of indoor rigid scan matching and registration. 3DMatch contains scan pairs with overlap ratios greater than 30%, while 3DLoMatch contains scan pairs with overlap ratios between 10% and 30%. Following previous works <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b73">74]</ref>, we report the following metrics: Inlier Ratio (IR), Feature Matching Recall (FMR), rigid Registration Recall (RR), Relative Rotation Error (RTE), and Relative Translation Error (RTE). RR is widely recognized as the ultimate metric because it measures the fraction of successfully registered scan pairs. Impementation details. Our method is implemented using Pytorch and trained using SGD on Nvidia A100 (80G) GPU. We use a batch size of 8 and apply padding and masking to handle different point clouds sizes. On 3DMatch, we follow the train/validation split as Predator <ref type="bibr" target="#b25">[26]</ref>. The training on 3DMatch and 4DMatch both converge around the 15th epoch. We save the model with the best validation loss. More implementation details are seen in the supplementary. -Positional encoding: absolute vs relative. Our relative 3D positional encoding yields +3.8% higher NFMR on 4DLoMatch and +1.5% / +2.3% higher RR on 3DMatch / 3DLoMatch than the absolute sinusoidal encoding <ref type="bibr" target="#b64">[65]</ref> (c.f. <ref type="figure" target="#fig_4">Tab. 1, 3</ref>).</p><p>-Does Repositioning make sense? Repositioning gains +2.9% / +3.3% NFMR on 4DMatch / 4DLoMatch and +0.9% / +1.0% RR on 3DMatch / 3DLoMatch (c.f. <ref type="figure" target="#fig_4">Tab. 1, 3)</ref>. Note that the performances drop significantly with the Random rotation-based positioning. The Oracle deformation in Tab. 1 and Oracle rigid fitting in Tab. 3 achieve near perfect results. These results demonstrate the importance of positional knowledge for point cloud registration. In Tab. 1, the Oracle rigid fitting refers to the best rigid fitting for the ground truth deformation. We consider it as the upper bound of the rigid fitting-based repositioning approach.</p><p>-Matching algorithm: Sinkhorn vs dual softmax. The dual softmax operator achieves higher scores on all benchmarks than the Sinkhorn approach.  <ref type="figure" target="#fig_9">Fig. 7</ref> shows the qualitative point cloud matching results on 4DMatch. We also report results from probabilistic registration <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b44">45]</ref>, functional map-based <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b42">43]</ref>, and scene flow methods <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b68">69]</ref>. Overall, feature matching methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26]</ref> show superior performance than other categories. Existing scene flow methods, can not handle large global motion. Functional map methods fail because they need connected shapes to obtain reliable Laplacian matrices, while the shapes in 4DMatch are usually disconnected due to occlusion (c.f. examples in <ref type="figure" target="#fig_6">Fig. 4</ref>). The Coherent Point Drift (CPD) models <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b44">45]</ref> do not work well on the partial scan data.</p><p>3DMatch &amp; 3DLoMatch. Compared to Predator <ref type="bibr" target="#b25">[26]</ref>, our method acheives +1.7% / +6.6% higher RR on 3DMatch / 3DLoMatch (c.f. Tab. 3). <ref type="figure" target="#fig_8">Fig. 6</ref> shows the qualitative results for a low overlap case. As shown in Tab. 4, Our method also produces better RRE and RTE than Predator; the point-to-point ICP-based postprocessing can further improve the registrations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Integrating to non-rigid registration.</head><p>We further integrate the predicted matches to non-rigid point cloud registration. For registration, we adopt the nonrigid iterative closest point (N-ICP) <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b77">78]</ref> method which iteratively minimizes the typical energy function:</p><formula xml:id="formula_19">E total (G) = ? c E corr (G) + ? r E reg (G)</formula><p>where E corr is the correspondence term, E reg is the regularization term as in <ref type="bibr" target="#b58">[59]</ref>, and G is the latent deformation graph model. The correspondence term E corr is defined by the L2 distance between corresponding points. See the supplementary for formal definitions.  3DMatch <ref type="bibr" target="#b75">[76]</ref> 3DLoMatch <ref type="bibr">[</ref>   baseline adopts the simple Euclidean space nearest neighbor search-based correspondence. Predator + N-ICP and Ours + N-ICP replace the correspondence term by the predicted matches during the beginning 20 iterations and then run 45 N-ICP iterations for refinements. Our method better informs non-rigid registration than Predator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>By leveraging the positional knowledge, Lepard demonstrates state-of-the-art feature matching results for both rigid and deformable point clouds. A promising direction is extending it to end-to-end registration. A few limita-tions are yet to be addressed: 1) Lepard is a coarse matching approach. Fine-grained correspondence could be obtained with learning-based refinement, e.g. <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b73">74]</ref>. 2) In deformable cases, Lepard does not explicitly handle topological changes. A potential solution is to jointly learn matching with motion segmentation. 3) Finally, matching and registration in the low overlapping cases is particularly challenging due to data incompleteness. <ref type="figure" target="#fig_13">Fig. 9</ref> shows such failure cases. A potential solution for low-overlap scenarios is to expand the mutual information via data completion <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b74">75]</ref>. Learning outlier rejection as <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b48">49]</ref> could also benefit registration.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Acknowledgement</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material: Lepard: Learning partial point cloud matching in rigid and deformable scenes</head><p>Supplementary material includes: ablation study (Sec. I); implementation details (Sec. II, III, IV, and V); formal definition of non-rigid registration (Sec. VI); and more results on 3DMatch and 4DMatch (Sec. VII).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Ablation study</head><p>-Influence of Warping Loss Weight. Applying warping loss in general yields higher NFMR and IR 4DMatch and 4DLoMatch. In particular, in the low overlap situations, the performance grows steadily with the increasing of the motion loss weight (c.f. Tab. 1). In 3DMatch and 3DLo-Match, warping loss significantly increases the Inlier Rate (IR). However, it leads to a decrease in Registration Recall (c.f. Tab. 2). We assume that this is because the warping loss might suppress some border cases correspondences which could have benefited the RANSAC. In deformable cases, a high inlier rate is desired for successful non-rigid registration. However, in rigid cases, the inlier rate is less important since RANSAC is very robust to noise. Therefore, we set ? w = 0.1 for 4DMatch and ? w = 0.0 for 3DMatch.  <ref type="table" target="#tab_3">Table 4</ref>. Influence of confidence thresholds on 4DMatch and 4DLoMatch. D3Feat <ref type="bibr" target="#b5">[6]</ref> and Predator <ref type="bibr" target="#b25">[26]</ref> probabilistically sample points either from a saliency heat map or from a machability?overlap heat map (numbers in brackets are the numbers of sampled points). Ours uses the confidence threshold ?c to get matches from the confidence matrix (c.f. Sec. 4.4). All methods apply the mutual nearest neighbor criteria to filter matches. |K pred | indicates the average number of final predicted correspondences.</p><p>(c.f. Tab. 4). We found ? c =0.1 a good trade-off between precision and recall.</p><p>-Adding more TMP blocks. We tested 3 and 4 TMP layers. The corresponding number of the Repositioning layer is 2 and 3 because it is placed between every two consecutive TMP layers. As shown in Tab. 5, in 3DMatch, additional layers do not improve the results; in 4DMatch, 3 TMP layers achieve the best results. Adding layers inevitably increase the training time.  <ref type="table">Table 5</ref>. Ablation study of number of TMP layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Sparse ?(?) Multiplication</head><p>Taking the advantage of the sparsity of ?(?), given a position p = (x, y, z) ? R 3 and a feature x ? R d , the multiplication ?(p)x can be efficiently realized by <ref type="bibr" target="#b4">(5)</ref> . . .</p><formula xml:id="formula_20">? ? ? ? ? ? ? ? ? ? ? ? ? ? ? x(0) x(1) x(2) x(3) x(4) x</formula><formula xml:id="formula_21">x(d/6 ? 1) x(d/6 ? 1) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?</formula><p>cos x? 0 cos x? 0 cos y? 0 cos y? 0 cos z? 0 cos z? 0 . . .     </p><formula xml:id="formula_22">cos z? d/6?1 cos z? d/6?1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? + ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?x(1) x(0) ?x(3) x(2) ?x(5) x(4) . . . ?x(d/6 ? 1) x(d/6 ? 1) ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? sin x? 0 sin x? 0 sin y? 0 sin y? 0 sin z? 0 sin z? 0 . . . sin z? d/6?1 sin z? d/6?1 ? ? ? ? ? ? ? ? ? ? ? ? ? ?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. KPFCN backbone architecture</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. Non-Rigid Registration</head><p>This section introduce the non-rigid registration technique used in this paper.</p><p>Deformation Model. To represent the dense motion from a source to a target, we adapt the embedded deformation model of Sumner et al. <ref type="bibr" target="#b60">[61]</ref>. The non-rigid deformation is parameterized by the deformation graph G = {V, E}, where V is the set of node and E is the set of edge. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, we evenly sample graph nodes V over the source point cloud surface. Each point in the scene has a 3D location: g i ? R 3 . The motion of a node i ? V is parameterized by a translation vector: t i ? R 3 and a rotation matrix: R i ? SO3. In addition, we represent rotations by R i = exp(? ? i )R i , where ? i = [0, 0, 0] represents the delta of the rotation in axis-angle form. (?) ? operator convert a 3-dimensional vector to a 3 ? 3 skew-symmetric matrix. exp : so3 ? SO3 map the skew-symmetric matrix to 3 ? 3 rotation matrix using the Rodrigues formula. Finally, all unkowns in the graph are G = ? 1 , ? ? ? , ? |V| |t 1 , ? ? ? , t |V| Non-rigid Warping Function Given a point p ? R 3 , the non-rigid warping function W is defined as</p><formula xml:id="formula_23">W(p) = i?V w p,i (R i (p ? g i ) + g i + t i )</formula><p>where w p,i ? R is the "skinning weight" that measure the influence of node i. They are computed as w p,i = Ce To compute geodesic distance, we construct the surface triangle mesh by connecting the nearby pixels' 3D locations. We filter the triangles with an edge larger than 4cm. During registration, for numerically stable optimization, we ignore point cloud clusters with fewer than 40 deformation nodes.</p><p>where ? is the coverage radius of a node, for which we set to 0.9 cm for 4DMatch examples, C denotes the normalization constant, ensuring that skinning weights add up to one Vi?V w p,i = 1 Energy Function. The energy function of non-rigid iterative closest point (N-ICP) consists of two terms: the correspondence term and the regularization term. Given a set of matches K, and the confidence of the correspondences c (ps,pt) where (p s , p t ) ? K. Correspondence term is defined as E corr (G) = (ps,pt)?K where each block is a 3 ? 1 vector. The total length is (|K| + |E|) ? 3.</p><p>Non-rigid Optimization. We use Gauss-Newton algorithm and minimizes the total energy function E total . The Gauss-Newton method is an iterative scheme. In every iteration n, we re-compute the Jacobian matrix J and the residual vector r , and get a solution increment ?G by solving the update equations:</p><formula xml:id="formula_24">J T J?G = J T r</formula><p>The above linear system is solved using LU decomposition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. Qualitative Results</head><p>Tab. 9 shows the scores for the elephant and dragon examples from the main paper. <ref type="figure" target="#fig_4">Fig. 3</ref> shows the qualitative matching and registration results on 4DMatch. Tab. 10 shows the corresponding scores for results in <ref type="figure" target="#fig_4">Fig. 3. Fig. 4</ref> shows the qualitative matching and registration results on 3DLoMatch.   <ref type="table">Table 10</ref>. Quantitative non-rigid registration results. The metrics are 3D end point error (EPE) and motion estimation accuracy (Acc) (&lt;0.05m or 5%, &lt;0.1m or 10%).  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Fig. 4shows examples of non-rigid point clouds pairs with different overlap ratio.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Overview of the proposed method. (The symbols are : Positional encoding function ?(?); : Rigid 3D transformation; : Matrix-vector multiplication; : Source and target). Given the input point cloud S and T, the KPFCN backbone grid-subsample them t? S andT, and extract geometry features x? and xT (Sec. 4.1). The positions informations are encoded as ?(?) and ?(T) using the 3D relative positional encoding function (Sec. 4.2). The position codes and geometry features are then processed by the first TMP layer which includes a Transformer block with self and cross attentions (Sec. 4.3), a differentiable Matching layer (Sec. 4.4), and a soft Procurestes layer to estimate the rigid fitting R, t (Sec. 4.6). Based on the rigid fitting estimation, the Repositioning layer adjusts source's position code ?(?) (Sec. 4.7). Given the updated positions and transformed features, the second TMP layer predicts the final matches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2</head><label>2</label><figDesc>shows the overview of the proposed method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>point clouds. See supplementary for details. This downsampling is crucial for efficient computation in the following transformer (Sec. 4.3) and matching ((Sec. 4.4) layers, where the time complexity are both O(n 2 ) of the number of points.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Visualization of self/cross attention heat maps and the rigid fitting based repositioning. In the 2nd TMP layer, self-attention expands to cover larger context, and cross attention converges to the corresponding region.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>The selected 1761 sequences are divided into 1232/176/353 as train/valid/test sets. Point cloud pairs in the 353 testing sequence are eventually split into either 4DMatch or 4DLo-Match based on an overlap ratio threshold of 45%.Fig. 4</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>Examples in 4DMatch/4DLoMatch with different overlap ratio. Overlap ratio is computed relative to the source (Blue). Partial overlap is the joint effect of scene deformation and camera viewpoint change.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Histogram of the 4DMatch and 4DLoMatch benchmark. The overlap ratio threshold is set to 45%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .</head><label>6</label><figDesc>Qualitative rigid point cloud registration results in 3DLoMatch benchmark. We use T-SNE to reduce the feature dimension to 3 and then normalize it to [0, 255] as RGB values. We propagate our output feature ?(?i)W?x? i and ?(Tj)WTxT j as in Eqn. 4 to the raw point clouds via interpolation as Eqn. 6. The feature visualization shows that our approach learns a position-aware feature representation and also accurately reflects the inter-fragment relative position.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>Qualitative deformable point cloud matching results in 4DMatch benchmark. Blue/red lines indicate inliers/outliers. In this example, the "Flying Dragon" has a bilateral symmetric shape. T-SNE feature visualization shows that Predator<ref type="bibr" target="#b25">[26]</ref> learns similar features for the two wings of the dragon, while our method can discriminate between the left and right wings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>6. 1 .</head><label>1</label><figDesc>Ablation Study -Does disentangling position and feature help? For nonrigid cases, disentangling position and feature achieve similar results to the entangled version on 4DMatch and achieve significantly better results on 4DLoMatch (c.f. Tab. 1). Fea. &amp; Pos. disentanglement also gain +1.1% / +2.5% RR on 3DMatch / 3DLoMatch (c.f. Tab. 3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 8</head><label>8</label><figDesc>shows the qualitative results of non-rigid registration on the dragon and elephant examples. The N-ICP</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 .</head><label>8</label><figDesc>Qualitative non-rigid registration results. As shown on the left end, scene deformation is approximated by the deformation graph. Results shown are the final alignment and the transformed source.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 9 .</head><label>9</label><figDesc>Failure cases in rigid (top) and non-rigid (bottom) matching. The low overlapping cases are still challenging, in particular, if the point clouds have similar patterns in the nonoverlapping region. Given the similar table and chairs (top), and a similar half-body (bottom), our method fails to treat them as different features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head></head><label></label><figDesc>This work was partially supported by JST AIP Acceleration Research JPMJCR20U3, Moonshot R&amp;D Grant Number JPMJPS2011, CREST Grant Number JPMJCR2015, and Basic Research Grant (Super AI) of Institute for AI and Beyond of the University of Tokyo.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 1 .</head><label>1</label><figDesc>Details of the KPFCN backbone architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>1 2? 2 2 Figure 2 .</head><label>1222</label><figDesc>||Vi?p|| 2 Deformation model. Nodes V (red dot) are evenly sampled over the source surface. Edges E (green lines) are computed between nodes based on geodesic connectivity. The point cloud examples in 4DMatch are obtained from depth images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 3 .</head><label>3</label><figDesc>Qualitative point cloud matching and registration results on 4DMatch. The inlier threshold is set to 4cm. The N-ICP-based refinement can remedy outliers to a certain extent if the outlier matches are not too far away from the ground truth (see the results of Predator + N-ICP in the Moose example). The N-ICP-based refinement can not handle outliers that connects distant parts. E.g. in the Mutant example, left and right legs are registered together by both methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 4 .</head><label>4</label><figDesc>Qualitative point cloud matching and registration results on 3DLoMatch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Ablation study on 4DMatch. * indicates the default configuration of our method. Quantitative Results on 4DMatch. S ? denotes supvervised methods. ? Point cloud Laplacian is obtained via<ref type="bibr" target="#b57">[58]</ref>.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">4DMatch</cell><cell cols="2">4DLoMatch</cell></row><row><cell cols="2">Ablation Target</cell><cell cols="4">NFMR? IR? NFMR? IR?</cell></row><row><cell>Fea. &amp; Pos.</cell><cell>Entangled Disentangled*</cell><cell>84.1 83.7</cell><cell>83.5 82.7</cell><cell>63.3 66.9</cell><cell>51.4 55.7</cell></row><row><cell>PE type</cell><cell>Absolute Relative*</cell><cell>83.7 83.7</cell><cell>82.2 82.7</cell><cell>63.1 66.9</cell><cell>51.8 55.7</cell></row><row><cell></cell><cell>Random rotation</cell><cell>79.2</cell><cell>78.2</cell><cell>58.4</cell><cell>46.7</cell></row><row><cell></cell><cell>w/o Repositioning</cell><cell>80.8</cell><cell>80.5</cell><cell>63.6</cell><cell>53.7</cell></row><row><cell>Positioning</cell><cell>Repositioning*</cell><cell>83.7</cell><cell>82.7</cell><cell>66.9</cell><cell>55.7</cell></row><row><cell></cell><cell>Oracle rigid fitting</cell><cell>91.5</cell><cell>89.7</cell><cell>80.2</cell><cell>67.2</cell></row><row><cell></cell><cell>Oracle deformation</cell><cell>100.0</cell><cell>99.8</cell><cell>100.0</cell><cell>97.6</cell></row><row><cell>Matching</cell><cell>Sinkhorn Dual-Softmax*</cell><cell>81.7 83.7</cell><cell>77.4 82.7</cell><cell>59.6 66.9</cell><cell>46.1 55.7</cell></row></table><note>4DMatch &amp; 4DLoMatch. As shown in Tab. 2, our method acheive +27.1% / +34.8% higher NFMR and +22.3% / +28.2% higher IR than Predator.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Feature matching and RANSAC registration results on 3DMatch. Refer to Tab. 1 for the configs of Ours (Default). Note that, in this paper, RR is averaged on all scan pairs to reflect the true percentage of successful registrations. RTE ? RR ? RRE ? RTE ? RR ?</figDesc><table><row><cell></cell><cell></cell><cell>3DMatch</cell><cell></cell><cell></cell><cell>3DLoMatch</cell><cell></cell></row><row><cell cols="2">RRE ? Predator 2.72 RANSAC Ours 2.48</cell><cell>7.8 7.2</cell><cell>91.8 93.5</cell><cell>4.44 4.10</cell><cell>11.6 10.8</cell><cell>62.4 69.0</cell></row><row><cell>Predator RANSAC+ICP Ours</cell><cell>2.06 1.96</cell><cell>6.2 6.0</cell><cell>92.3 93.9</cell><cell>3.46 3.17</cell><cell>9.8 8.9</cell><cell>65.2 71.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>RRE (?), RTE (cm) and RR (%) on 3DMatch. Pointto-point ICP can further refine the transformations.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 .</head><label>6</label><figDesc>The hyper parameters for metric evaluation, match prediction, KPFCN backbone, and training loss IV. Time and memory expense</figDesc><table><row><cell></cell><cell cols="2">Predator [26] Lepard (Ours)</cell></row><row><cell>Average time (s)</cell><cell>0.18</cell><cell>0.10</cell></row><row><cell>Cuda memory (MB)</cell><cell>13,361</cell><cell>6,595</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 .</head><label>7</label><figDesc>Time and Cuda memory usage of inference on an Nvidia A100 (80G) GPU. Time is averaged on 2193 testing samples in 4DLoMatch. Lepard is about twice as efficient as Predator on both time and memory.</figDesc><table><row><cell cols="5">KPFCN Self Att. (?2) Cross Att. (?2) Matching (?2) Procrustes (?2)</cell></row><row><cell>0.0109</cell><cell>0.0016 (?2)</cell><cell>0.0014 (?2)</cell><cell>0.0023 (?2)</cell><cell>0.0191 (?2)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 .</head><label>8</label><figDesc></figDesc><table /><note>Average time (s) of Lepard function inference on an Nvidia A100 (80G) GPU. Time is averaged on 2193 testing sam- ples in 4DLoMatch.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 9 .</head><label>9</label><figDesc>Quantitative non-rigid registration results. The metrics are 3D end point error (EPE) and motion estimation accuracy (Acc) (&lt;0.05m or 5%, &lt;0.1m or 10%).</figDesc><table><row><cell></cell><cell></cell><cell>moose</cell><cell></cell><cell></cell><cell>mutant</cell><cell></cell></row><row><cell></cell><cell cols="6">EPE? Acc5? Acc10? EPE? Acc5? Acc10?</cell></row><row><cell>N-ICP</cell><cell>0.728</cell><cell>0.1</cell><cell>0.7</cell><cell>0.52</cell><cell>0.0</cell><cell>0.6</cell></row><row><cell cols="2">Predator [26] + N-ICP 0.0283</cell><cell>86.9</cell><cell>99.4</cell><cell>0.217</cell><cell>44.6</cell><cell>60.1</cell></row><row><cell>Ours + N-ICP</cell><cell>0.0263</cell><cell>88.5</cell><cell>99.9</cell><cell>0.119</cell><cell>62.6</cell><cell>71.4</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Residual and Partial Derivatives. The followings show the residuals and partial derivatives for optimization. Derivative of the wrapping function W </p><p>The full Jacobian matrix J ? R (3|K|+3|E|)?6|V| is shown as where |V| is the number of graph node. |K| is number of correspondence. |E| is the number of graph edge. Each block in J is a 3 ? 3 matrix. For the sparse nature of this problem, most blocks are zeros. The full residual vector r ? R 3|K|+3|E| is shown as  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Spinnet: Learning a general surface descriptor for 3d point cloud registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Markham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="11753" to="11762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pointnetlk: Robust &amp; efficient point cloud registration using pointnet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Aoki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Goforth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Srivatsan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7163" to="7172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Least-squares fitting of two 3-d point sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Arun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Blostein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="698" to="700" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Attaiki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.09994</idno>
		<title level="m">Dpfm: Deep partial functional maps</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Pointdsc: Robust point cloud registration using deep spatial consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15859" to="15869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">D3feat: Joint learning of dense detection and description of 3d local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="6359" to="6367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Lucas-kanade 20 years on: A unifying framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="255" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Method for registration of 3-d shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Besl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Mckay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sensor fusion IV: control paradigms and data structures</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">1611</biblScope>
			<biblScope unit="page" from="586" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bo?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Palafox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zollh?fer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Thies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie?ner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.13240</idno>
		<title level="m">Neural non-rigid tracking</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deepdeform: Learning non-rigid rgb-d reconstruction with semisupervised data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bo?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zollh?fer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7002" to="7012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">End-to-end object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="213" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep global registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="2514" to="2523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">4d spatio-temporal convnets: Minkowski convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3075" to="3084" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fully convolutional geometric features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="8958" to="8966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Ppf-foldnet: Unsupervised learning of rotation invariant 3d local descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Birdal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ilic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="602" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Ppfnet: Global context aware local features for robust 3d point matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Birdal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ilic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="195" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep geometric functional maps: Robust feature learning for shape correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Donati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">UnsupervisedR&amp;R: Unsupervised Pointcloud Registration via Differentiable Rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">El</forename><surname>Banani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bootstrap Your Own Correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">El</forename><surname>Banani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV, 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tedrake</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.13073</idno>
		<title level="m">Surfelwarp: Efficient nonvolumetric single view dynamic reconstruction</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The perfect match: 3d point cloud matching with smoothed densities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gojcic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Wegner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wieser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="5545" to="5554" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">3d-coded: 3d correspondences by deep deformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Groueix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aubry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="230" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A bayesian formulation of coherent point drift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hirose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="2269" to="2286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Registration with the point cloud library: A modular framework for aligning in 3-d</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Holz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Ichim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics &amp; Automation Magazine</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="110" to="124" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Nonrigid registration under isometric deformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wicke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1449" to="1457" />
		</imprint>
		<respStmt>
			<orgName>Wiley Online Library</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Predator: Registration of 3d point clouds with low overlap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gojcic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Usvyatsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="4267" to="4276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Volumedeform: Real-time volumetric nonrigid reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Innmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zollh?fer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stamminger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="362" to="379" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Kinectfusion: real-time 3d reconstruction and interaction using a moving depth camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Molyneaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th annual ACM symposium on User interface software and technology</title>
		<meeting>the 24th annual ACM symposium on User interface software and technology</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="559" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Using spin images for efficient object recognition in cluttered 3d scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="433" to="449" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning compact geometric features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khoury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="153" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Global correspondence optimization for non-rigid registration of depth scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Sumner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer graphics forum</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1421" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">End-to-end learning local multi-view descriptors for 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Tai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Neural scene flow prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pontes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Pointnetlk revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Pontes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="12763" to="12772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to optimize non-rigid tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bozic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4910" to="4918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Takehara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Taketomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie?ner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.01905</idno>
		<title level="m">Non-rigid motion estimation beyond the observable surface</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02108</idno>
		<title level="m">Splitfusion: Simultaneous tracking and mapping for non-rigid scenes</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Neighborhood normalization for robust geometric feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ishii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Unberath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13049" to="13058" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Flownet3d: Learning scene flow in 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="529" to="537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Distinctive image features from scaleinvariant keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Melzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wonka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zoomout</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07865</idno>
		<title level="m">Spectral upsampling for efficient shape correspondence</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Distinctiveness oriented positional equilibrium for point cloud registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="5490" to="5498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Point set registration: Coherent point drift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Myronenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="2262" to="2275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dynamicfusion: Reconstruction and tracking of non-rigid scenes in real-time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="343" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Kinectfusion: Real-time dense surface mapping and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Molyneaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kohi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th IEEE International Symposium on Mixed and Augmented Reality</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="127" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Functional maps: a flexible representation of maps between shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ben-Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Butscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">3dregnet: A deep neural network for 3d point registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Pais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramalingam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Govindu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Nascimento</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Miraldo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="7193" to="7203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Flot: Scene flow on point clouds guided by optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Puy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Marlet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings, Part XXVIII 16</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Rocco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arandjelovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.10510</idno>
		<title level="m">Neighbourhood consensus networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Partial functional correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodol?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cosmo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torsello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Graphics Forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="222" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Fast point feature histograms (fpfh) for 3d registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Blodow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE international conference on robotics and automation</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="3212" to="3217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Aligning point cloud views using persistent feature histograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Blodow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ international conference on intelligent robots and systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3384" to="3391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Superglue: Learning feature matching with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-E</forename><surname>Sarlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Detone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Self-supervised visual descriptor learning for dense correspondence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="420" to="427" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Efficient ransac for point-cloud shape detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schnabel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer graphics forum</title>
		<imprint>
			<publisher>Wiley Online Library</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="214" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A Laplacian for Nonmanifold Triangle Meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sharp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crane</surname></persName>
		</author>
		<idno>2020. 7</idno>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum (SGP)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">As-rigid-as-possible surface modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sorkine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alexa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Symposium on Geometry Processing</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Roformer: Enhanced transformer with rotary position embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.09864</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Embedded deformation for shape manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Sumner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pauly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">80</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Loftr: Detector-free local feature matching with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="8922" to="8931" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Kpconv: Flexible and deformable convolution for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-E</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Unique shape context for 3d data description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tombari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Salti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Di</forename><surname>Stefano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM workshop on 3D object retrieval</title>
		<meeting>the ACM workshop on 3D object retrieval</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="57" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">You only hypothesize once: Point cloud registration with rotationequivariant descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.00182</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Deep closest point: Learning representations for point cloud registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3523" to="3532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Prnet: Self-supervised learning for partial-to-partial registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.12240</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Pointpwc-net: A coarse-to-fine network for supervised and self-supervised scene flow estimation on 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fuxin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.12408</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Omnet: Learning overlapping mask for partial-to-partial point cloud registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.00937</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Selfsupervised geometric perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Carlone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Go-icp: A globally optimal solution to 3d icp point-set registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="2241" to="2254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Rpm-net: Robust point matching using learned features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">J</forename><surname>Yew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11824" to="11833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Cofinet: Reliable coarse-to-fine correspondences for robust point cloud registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Busam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ilic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.14076</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Pointr: Diverse point cloud completion with geometry-aware transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Learning local geometric descriptors from rgb-d reconstructions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Fast global registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q.-Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="766" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Real-time non-rigid reconstruction using an rgb-d camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zollh?fer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Izadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Loop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (ToG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">156</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
