<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NEURAL PROCESSES WITH STOCHASTIC ATTENTION: PAYING MORE ATTENTION TO THE CONTEXT DATASET</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyu</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">KAIST AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyeongryeol</forename><surname>Go</surname></persName>
							<email>kyeongryeol.go@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution">KAIST AI</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Se-Young</forename><surname>Yun</surname></persName>
							<email>yunseyoung@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution">KAIST AI</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">NEURAL PROCESSES WITH STOCHASTIC ATTENTION: PAYING MORE ATTENTION TO THE CONTEXT DATASET</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural processes (NPs) aim to stochastically complete unseen data points based on a given context dataset. NPs essentially leverage a given dataset as a context representation to derive a suitable identifier for a novel task. To improve the prediction accuracy, many variants of NPs have investigated context embedding approaches that generally design novel network architectures and aggregation functions satisfying permutation invariant. In this work, we propose a stochastic attention mechanism for NPs to capture appropriate context information. From the perspective of information theory, we demonstrate that the proposed method encourages context embedding to be differentiated from a target dataset, allowing NPs to consider features in a target dataset and context embedding independently. We observe that the proposed method can appropriately capture context embedding even under noisy data sets and restricted task distributions, where typical NPs suffer from a lack of context embeddings. We empirically show that our approach substantially outperforms conventional NPs in various domains through 1D regression, predator-prey model, and image completion. Moreover, the proposed method is also validated by MovieLens-10k dataset, a real-world problem.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Neural processes <ref type="bibr">(NPs)</ref> have been in the spotlight as they stochastically complete unseen target points considering a given context dataset without huge inference computation <ref type="bibr" target="#b10">(Garnelo et al., 2018a;</ref><ref type="bibr" target="#b4">b;</ref>. NPs leverage neural networks to derive an identifier suitable for a novel task using context representation, which contains information about given context data points. These methods enable us to handle considerable amounts of data points, such as in image-based applications, that the Gaussian process cannot naively deal with. Many studies have revealed that the prediction performance relies on the way of context representation <ref type="bibr" target="#b26">Volpp et al., 2021)</ref>. The variants of NPs have mainly investigated on context embedding approaches that generally design novel network architectures and aggregation functions that are permutation invariant. For example, <ref type="bibr" target="#b10">Garnelo et al. (2018a;</ref><ref type="bibr" target="#b4">b)</ref> developed NPs using MLP layers to embed context set via mean aggregation. Bayesian aggregation satisfying permutation invariance enhanced the prediction accuracy by varying weights for individual context data points <ref type="bibr" target="#b26">(Volpp et al., 2021)</ref>. From the prospective of network architectures to increase model capacity,  suggested the way of local representation to consider relations between context dataset and target dataset using deterministic attention mechanism <ref type="bibr" target="#b25">(Vaswani et al., 2017)</ref>. For robustness under noisy situations, bootstrapping method was proposed to orthogonally apply to variants of NPs <ref type="bibr" target="#b18">(Lee et al., 2020)</ref>.</p><p>Despite many appealing approaches, one significant drawback of previous NPs is that they still underfit when confronted with noisy situations like real-world problems. This manifests as inaccurate predictions at the locations of the context set as seen in <ref type="figure">Figure 1a</ref>. Additionally, in <ref type="figure">Figure 1b</ref>, the attentive neural process  fails to capture contextual embeddings because the attention weights of all target points highlight on the lowest value or the maximum value in the context dataset. In the case of the Bootstrapping ANP <ref type="bibr" target="#b18">(Lee et al., 2020)</ref> and ANP with information dropout, the quality of heat-map is slightly improved, but it still falls short of ours. This indicates that the present NPs are unable to properly exploit context embeddings because the noisy situations impair the learning of the context embeddings during meta-training. 1 arXiv:2204.05449v1 <ref type="bibr">[cs.</ref>LG] 11 Apr 2022</p><p>Published as a conference paper at ICLR 2022 (a) 1D regression predcitions (b) Heatmaps of asscociated attention weights <ref type="figure">Figure 1</ref>: Comparison of 1D regression predictions and asscociated attention weights as specified by ANP , ANP with Information dropout, Bootstrapping ANP <ref type="bibr" target="#b18">(Lee et al., 2020)</ref> and ours. The training data for 1D regression is fairly noisy. (a) Ours more accurately captures the context datasets and significantly better predicts than baselines. (b) The horizontal axis indicates the value of features in the context dataset, while the vertical axis indicates the value of features in the target dataset in these heatmaps. The best pattern for this heat-map is diagonal because all feature values are arranged in ascending order. Among all models, ours comes closet to the ideal. The detailed analysis is shown in Appendix G To address this issue, we propose a newly designed neural process to fundamentally improve performance by paying more attention to the context dataset. The proposed method expedites a stochastic attention to adequately capture the dependency of the context and target datasets by adjusting stochasticity. It results in improving prediction performance due to maintained context information. We observe that our proposed algorithm works well by utilizing contextual information in an intended manner as seen in <ref type="figure">Figure 1</ref>. This method outperforms current NPs and their regularization methods in all experiment settings. Thus, this paper clarifies the proposed method as regularized NPs in terms of information theory, explaining that the stochastic attention encourages the context embedding to be differentiated from the target dataset. This differentiated information induces NPs to become appropriate identifiers for target dataset by paying more attention to context representation. To summarize, we make the following contributions:</p><p>? We propose the novel neural process that pay more attention to the context dataset. We claims for the first time, using the information theory framework, that critical conditions for contextual embeddings in NPs are independent of target features and close to contextual datasets.</p><p>? Through comprehensive analyses, we illustrate how stochastic local embeddings are crucial for NPs to focus on capturing the dependencies of context and target datasets. Even when context dataset contains noise or is somewhat different from target dataset, as shown in <ref type="bibr" target="#b18">Lee et al. (2020)</ref>, the proposed method is capable of adapting a novel task while preserving predictive performance. Particularly, this method significantly enhances performance without additional architectures and data augmentation compared to the attentive neural process .</p><p>? The experimental results show that the proposed model substantially outperforms conventional NPs in typical meta-regression problems. For instance, the proposed method achieves to obtain the state of the art score in the image completion task with the CelebA dataset. Especially, the proposed model maintains performance in the limited task distribution regimes such as the MovieLenz-10k dataset with a small number of users.</p><p>This paper is organized as follows. We introduce background knowledge in section 2. section 3 presents a neural process with stochastic attention and related works illustrated in section 5. Experimental results are shown in section 4, concluding with section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND</head><p>2.1 NEURAL PROCESSES Suppose that we have an observation set X = {x i } n i=1 and a label set Y = {y i } n i=1 . NPs <ref type="bibr" target="#b10">(Garnelo et al., 2018a;</ref><ref type="bibr" target="#b4">b;</ref> are designed to obtain the probabilistic mapping from the observation set to the label set p(Y |X, X c , Y c ) given a small subset (X c , Y c ) = (x j , y j ) m j=1 . Basically, it is built upon the neural network with an encoder-decoder architecture where the encoder f ? outputs a task representation by feed-forwarding (X c , Y c ) through permutation-invariant set encoding <ref type="bibr" target="#b30">(Zaheer et al., 2017;</ref><ref type="bibr" target="#b6">Edwards &amp; Storkey, 2017)</ref> and the decoder f ? models the distribution of Y (e.g Gaussian case : estimating ?, ?) using X along with the encoder outputs. Its objective is to maximize the log likelihood over the (unknown) task distribution p(T ). All tasks provided by the data generating process are considered as Monte Carlo samples, respectively:</p><formula xml:id="formula_0">T k ?p(T ) log p(Y |X, X c , Y c ) = T k ?p(T ) n i=1 log N (y i |? i , ? i ) where (? i , ? i ) = f ? (x i , r), r = f ? ({x j , y j } m j=1 )<label>(1)</label></formula><p>The set encoding architecture differentiates the type of NPs. In Conditional neural process(CNP) <ref type="bibr" target="#b10">(Garnelo et al., 2018a)</ref>, the representation r is a deterministic variable such that, by using mean aggregation, the encoder maps the context set into a single deterministic representation r = 1 /m m j=1 f ? (x j , y j ). Neural process (NP) <ref type="bibr" target="#b11">(Garnelo et al., 2018b)</ref> introduces a probabilistic latent variable z to model functional uncertainty as a stochastic process such that the parameters of output distribution may change according to the sampled value of z. Due to the intractable log-likelihood, a training objective is derived based on variational inference which can be decomposed into two terms, reconstruction term and regularization term:</p><formula xml:id="formula_1">log p(Y |X, X c , Y c ) ? E q ? (z|X,Y ) log p ? (Y |X, r, z)p ? (z|X c , Y c ) q ? (z|X, Y ) = E q ? (z|X,Y ) [log p ? (Y |X, r, z)] ? KL(q ? (z|X, Y )||p ? (z|X c , Y c ))<label>(2)</label></formula><p>For simplicity, the prior distribution p ? (z|X c , Y c ) is approximated by q ? (z|X c , Y c ). However, as pointed out in , the mean aggregation over the context set is too restrictive to describe the dependencies of the set elements. To enhance the expressiveness of the task representation, Attentive neural process(ANP) accommodates an attention mechanism <ref type="bibr" target="#b25">(Vaswani et al., 2017)</ref> into the encoder, which generates the local deterministic representation r i corresponding to a target data point x i , and addresses the underfitting issue in NP. Although additional set encoding methods such as the kernel method and the bayesian aggregation considering task information have been suggested <ref type="bibr" target="#b28">(Xu et al., 2020;</ref><ref type="bibr" target="#b26">Volpp et al., 2021)</ref>, the attentive neural process is mainly considered as the baseline in terms of model versatility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">BAYESIAN ATTENTION MODULE</head><p>Consider m key-value pairs, packed into a key matrix K ? R m?d k and a value matrix V ? R m?dv and n queries packed into Q ? R n?d k , where the dimensions of the queries and keys are the same. Attention mechanisms aim to create the appropriate values O ? R n?dv corresponding to Q based on the similarity metric to K, which are typically computed via an alignment score function g such that ? = g(Q, K). Then, a softmax function is applied to allow the attention weight W ? R n?m to satisfy the simplex constraint so that the output features can be obtained by O i,j = W i ? V j :</p><formula xml:id="formula_2">W i,j = exp(? i,j ) m j=1 exp(? i,j )<label>(3)</label></formula><p>Note that there are many options for the alignment score function g where a scaled dot-product or a neural network are widely used. Bayesian attention module <ref type="bibr" target="#b7">(Fan et al., 2020)</ref> considers a stochastic attention weight W . Compared to other stochastic attention methods <ref type="bibr" target="#b22">(Shankar &amp; Sarawagi, 2018;</ref><ref type="bibr" target="#b17">Lawson et al., 2018;</ref><ref type="bibr" target="#b1">Bahuleyan et al., 2018;</ref><ref type="bibr" target="#b5">Deng et al., 2018)</ref>, it requires minimal modification to the deterministic attention mechanism described above so that it is compatible with the existing frameworks, which can be adopted in a straightforward manner. Specifically, un-normalized attention weights? such that W i,j =? i,j / m j=1? i,j are sampled via the variational distribution q ? (? |Q, K), which can be trained via amortized variational inference:</p><formula xml:id="formula_3">log p(O|Q, K, V ) ? E q ? (? |Q,K) log p ? (O|V,? ) ? KL(q ? (? |Q, K)||p ? (? ))<label>(4)</label></formula><p>Considering the random variable? to be non-negative such that it can satisfy the simplex constraint by normalization, the variational distribution q ? (? |Q, K) is set to Weibull(k, ?) and the prior distribution p ? (? ) is set to <ref type="bibr">Gamma(?, ?)</ref>. This ? can be obtained by the standard attention mechanism, on the other hands, ? can be either a learnable parameter or a hyper-parameter depending on that the model follows key-based contextual prior described in the following paragraph. The remaining variables k and ? are regarded as user-defined hyper-parameters. By introducing Euler-Mascheroni constant ? <ref type="bibr" target="#b31">(Zhang et al., 2018;</ref><ref type="bibr" target="#b2">Bauckhage, 2014)</ref>, the KL divergence in Equation 4 can be computed in an analytical expression. The detailed derivation is shown in Appendix A.</p><formula xml:id="formula_4">KL(Weibull(k, ?)||Gamma(?, ?)) = ?? k ? ? log k + ???(1 + 1 k ) ? ? ? 1 ? ? log ? + log?(?) (5)</formula><p>Samples from Weibull distribution can be obtained using a reparameterization trick exploiting an inverse CDF method: ?(? log(1 ? )) 1 k , ? Uniform(0, 1). Note that mean and variance of Weibull(k, ?) are computed as ??(1 + 1 /k) and ? 2 ?(1 + 2 /k) ? (?(1 + 1 /k)) 2 . It can be observed that the variance of obtained samples decreases as k increases.</p><p>Key-based contextual prior To model the prior distribution of attention weights, key-based contextual prior was proposed. This method allows the neural network to calculate the shape parameter ? of the gamma distribution as a prior distribution. This leads to the stabilization of KL divergence between standard attention weights and sampled attention weights, and it prevents overfitting of the attention weights <ref type="bibr" target="#b7">(Fan et al., 2020)</ref>. In this paper, we explain the reason why the key-based context prior is important for capturing an appropriate representation focusing on a context dataset from the prosepective of information theory. We expect NPs to appropriately represent the context dataset to predict target data points in a novel task. However, if the context dataset has a limited task distribution and noise like real-world problems, conventional NPs tend to sensitively react to this noise and maximize the objective function including irreducible noise. These irreducible noises do not completely correlate with context information, so that this phenomenon derives meaningless set encoding of the context dataset in training phase and hinders adaptation to new tasks. In other words, the output of NPs p ? (y i |x i , z, r i ) does not depend on (z, r i ). To preserve the quality of context representation, we propose a method that better utilizes the context dataset by exploiting stochastic attention with the key-based contextual prior to NPs. We show that the proposed method enables to create more precise context encoding by adjusting stochasticity, even in very restricted task distribution regimes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">NEURAL PROCESSES WITH STOCHASTIC ATTENTION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">GENERATIVE PROCESS</head><p>As with the Attentive neural process , the proposed method consists of the two types of encoders and a single decoder architecture. The first encoder embeds (X c , Y c ) to a global representation z and the second encoder makes a local representation r i by (x i , X c , Y c ). The global representation z serves to represent entire context data points (X c , Y c ), whereas the local representation r i is in charge of finegrained information between target data x i and context (X c , Y c ) for predicting the output distribution p(y i |x i , (z, r i )). Unlike the ANP, the proposed model considers all intermediate representations (z, r i ) as stochastic variables. We exploit the Bayesian attention module to create a local representation r i by the stochastic attention weights w i with the key-based contextual prior <ref type="bibr" target="#b7">(Fan et al., 2020)</ref>. To use the reparameterization trick for sampling stochastic variables, we draw random noise samples 1 ? Unif(0, 1), 2 ? N (0, 1). First, as mentioned in section 2, the stochastic attention weights {w i } N i=1 are obtained via the inverse CDF of the Weibull distribution with random noise 1 . For amortized variational inference, the prior distribution q ? ({w} N i=1 |K(X c )) is also derived with context dataset X c for implementing key-based contextual prior. Meanwhile, 2 is used to obtain the global representation z sampled from normal distribution. The entire scheme is shown in <ref type="figure">Figure D</ref>.2c. As shown in section 2, we can calculate all the KL divergences of z and {w} n i=1 as closed-form solutions. The decoder follows the standard neural processes p(y i |x i , z, r i ) = N (y i |? ? (x i , z, r i ), ? 2 ? (x i , z, r i )). See Appendix D for implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">LEARNING AND INFERENCE</head><p>Unlike the Attentive neural process , the proposed method regards all representations z and W = {w i } n i=1 as stochastic variables, so that we clearly drive the objective function according to amortized variational inference. Based on the objective function of Neural process <ref type="bibr" target="#b11">(Garnelo et al., 2018b)</ref>, the proposed method adds KL divergence of stochastic attention weight</p><formula xml:id="formula_5">W = {w i } n i=1 .</formula><p>Assuming the independence between z and {w i } n i such that individual w i is only dependent on x i and (X c , Y c ) as seen in <ref type="figure" target="#fig_0">Figure 2</ref>, the objective function for each task T k is presented as follows:</p><formula xml:id="formula_6">L T k (?, ?) = N i=1 log p ? (y i |x i , z, r i ) ? KL q ? (w i |x i , X c )|q ? (w i |X c ) ? KL q ? (z|X, Y )|q ? (z|X c , Y c )<label>(6)</label></formula><p>Note that (X, Y ) follows a task T k and each task T k is drawn from task distribution p(T ). The final objective function is</p><formula xml:id="formula_7">L(?, ?) = E T k [L T k (?, ?)].</formula><p>From the perspective of amortized variational inference, the prior distributions of p(z) and p({w i }) n i=1 should be defined. With regard to z, we follow the standard neural processes wherein p(z) is defined as q ? (z|{X c , Y c } <ref type="bibr" target="#b11">(Garnelo et al., 2018b)</ref>. In the case of {w i } N i=1 , we introduce the strategy of Bayesian attention modules <ref type="bibr" target="#b7">(Fan et al., 2020)</ref>. The prior distribution of {w i } N i=1 defined as a key-based contextual prior, q ? (w i |X c ), not only stabilizes the KL divergence but also activates the representation w i to pay more attention to the context dataset. In the next section, this objective function can be described in terms of information theory as role of regularization to pursue the original goal of NPs, which is deriving appropriate identifiers for target datasets in novel tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">DISCUSSION OF OBJECTIVE FUNCTION FROM VIEWS OF INFORMATION THEORY</head><p>A novel part of the proposed method is the use of the stochastic attention mechanism to more leverage context information, thereby stably capturing the dependency of context and target datasets in noisy and very limited task distributions. In this subsection, based on information theory, we elaborate the goal of NPs and our novel stochastic attention mechanism explained as the regularization of latent variables to pay more attention to context datasets. This enables us to understand latent variables and their requirements semantically. According to subsection 3.2, the objective function is categorized into two terms: a reconstruction log p ? (y i |x i , z, r i ) and regularization as two KL Divergences. Suppose that {x i , y i } is a data point in a target dataset, D is a given context dataset, latent variables z and r i are considered as Z, which is defined as the information bottleneck for D, we suggest that maximizing a reconstruction term corresponds to increase I(y i , D|x i ) and minimizing two KL Divergence means to decrease I(Z, x i |D).</p><p>First, the mutual information of the target value y i and the context dataset D given the input feature x i , I(y i , D|x i ), is the metric to identify that NPs is adapted to a novel task. Suppose p(y i |x i , D) is output value of NPs and p(y i |x i ) = E D p(y i |x i , D) is output value not conditioned on context dataset D. If NPs completely fail to adapt new tasks using the context dataset D, the suggested metric I(y i , D|x i ) goes to 0.</p><formula xml:id="formula_8">I(y i , D|x i ) = E yi,D log p ? (y i |x i , D) p ? (y i |x i )<label>(7)</label></formula><p>Assumed that target data point {x i , y i } is sampled from T k , which is uncontrollable data generating process, the reconstruction term {xi,yi} log p(y i |x i , Z) can be regarded to I(y i ; Z|x i ) based on information bottleneck theorem; I(y i ; D|x i ) ? I(y i ; Z|x i ) holds. The detailed explanation is given in Appendix C. The objective function should be designed to increase I(y i , D|x i ) by an appropriate identifier for a novel task considering a context dataset D. However, as mentioned in the previous sections, NPs suffer from irreducible noises and limited task distribution in meta training. This phenomena means that NPs increase the objective function by learning the way to directly map from x i to y i including noises and some features only in meta-training, instead of taking into consideration of the context D. To make latent variables Z capture proper dependencies, we define the regularization accounting for latent variables to pay more attention to the context dataset.</p><p>This regularization is the mutual information of latent variable Z and input x i given context dataset D to indicates how similar information latent variable Z and target x i contain. We regard p(Z|x i , D) as the distribution of latent variables that considers both context dataset D and target x i , meanwhile p(Z|D) = E xi p(Z|x i , D) as the distribution of latent variables only depending on the context dataset D. If latent variables Z have totally different information against the target x i given the context dataset D, It can be I(Z, x i |D) = 0</p><formula xml:id="formula_9">I(Z, x i |D) = E Z,xi log p(Z|x i , D) p(Z|D)<label>(8)</label></formula><p>We bring I(y i ; D|x i ) ? I(Z, x i |D) to be maximized instead of I(y i , D|x i ) so as to model adequately dependency between context and the target dataset. By decreasing I(Z, x i |D) and increasing I(y i , D|x i ) in meta-training, we expect that the model learns the way to differentiate Z and x i and construct an identifier which can further consider Z and x i together. Note that ? is the parameter of the function to transform D to the information bottleneck Z and ? is the parameter of the identifier for target data point y i , we show that I(y i ;</p><formula xml:id="formula_10">D|x i ) ? I(Z, x i |D) ? I ?,? (y i ; Z|x i ) ? I ? (Z, x i |D) if ?, ?</formula><p>is perfectly able to leverage all information about Z and x i . We assume that neural network architectures can perform an intended manners. Theorem 1. Let Z be the representation of the context dataset D and it follows an information bottleneck. The following equation holds when the latent variable Z can be split into {z, w i } and z is only dependent on D, but w i is dependent on D and x i ,</p><formula xml:id="formula_11">L T k (?, ?) ? I(y i ; D|x i ) ? I(Z, x i |D)<label>(9)</label></formula><p>where w i is obtained by the Bayesian attention modules <ref type="bibr" target="#b7">(Fan et al., 2020)</ref>, and L T k is defined in <ref type="figure" target="#fig_5">Equation 6</ref> and its probabilistic graphical model follows <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>As mentioned, if the neural network architectures ?, ? are able to completely represent to Z and y i given D and</p><formula xml:id="formula_12">x i , L T k (?, ?) = I ?,? (y i ; Z|x i ) ? I ? (Z; x i |D) ideally holds.</formula><p>In this subsection, we reveal that stochastic attention mechanism satisfy on this regularization as mentioned. p(Z|x i , D) is regarded as q ? (w i |x i , {X c , Y c }) and p(Z|D) is the key-based contextual prior q ? (w i |K(X c )). Therefore, the stochastic attention mechanism with key-prior that requires D and x i as well as being able to this regularization for latent variables to pay more attention to the context dataset in Equation 8 is considered. By Theorem 1, the network parameters ? and ? are updated by the gradient of the objective function in Equation 6 semantically improves I(y i ; D|x i ) ? I(Z, x i |D). Therefore, we present the experimental results in the next section. They indicate that we can implement a model that can complete unseen data points in novel tasks by fully considering the context representations. The detailed analysis is presented in Appendix G and Appendix H.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT</head><p>In this section, we describe our experiments to answer three key questions: 1) Are existing regularization methods such as weight decay, importance-weighted ELBO as well as recent methods(Information dropout, Bootstrapping, and Bayesian aggregation) effective to properly create context representations ?; 2) Can the proposed method reliably capture dependencies between target and context datasets even under noisy situations and limited task distributions ?; 3) Is it possible to improve performance via the appropriate representation of the dataset ?</p><p>To demonstrate the need for neural process with stochastic attention, we choose CNP, NP <ref type="bibr" target="#b10">(Garnelo et al., 2018a;</ref><ref type="bibr" target="#b4">b)</ref>, and ANP  as baselines, which are commonly used. For all baselines, we employ weight decay and importance-weighted ELBO that requires several samples against one  <ref type="bibr" target="#b26">(Volpp et al., 2021)</ref> and Bootstrapping <ref type="bibr" target="#b18">(Lee et al., 2020)</ref> are chosen. Bayesian aggregation is used for CNP and NP according to the original paper, meanwhile Information dropout and Bootstrapping are used for the ANP to verify regularization of local representations. When training, all methods follow their own learninig policy; however, for fair comparison, all methods perform one Monte-Carlo sampling across a test data point during testing. We respectively conduct 5 trials for each experiment and report average scores. As a metric to evaluate the model's predictive performance, we use the likelihood of the target dataset, while the likelihood of the context dataset is considered as a metric to measure the extent to which models can represent a context dataset. Since these metrics are proportional to model performance, a higher value indicates a better performance. In these experiments, we show that the proposed method substantially outperforms various NPs and their regularization methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">1D REGRESSION UNDER NOISY SITUATIONS</head><p>We conduct synthetic 1D regression experiments to test whether our model adequately captures the dependency of a dataset under noisy situation. We trained all models with samples from the RBF GP functions. We tested them with samples from various kernel functions (Matern, Periodic inclduing RBF) to identify that models is capable of adaptatation to new tasks. To consider noisy environments, we artificially generate noises into the training dataset. Our model maintains outstanding performance compared to other baselines. In particular, when the test data comes from periodic kernel GP, which is the most different from the RBF GP, the proposed model utilizes context datasets appropriately regardless of the test data sources, whereas other models do not properly use the context data. When comparing the likelihood values of context datasets, the proposed method preserves equivalent scores in all cases, but the others do not. As shown in <ref type="figure">Figure 1a</ref>, the proposed method captures context points better than other methods, as only it method correctly captures the relationship even under noisy situations. These results support our claim, the proposed method utilizes context datasets in prediction. We report graphical explanation and the additional experimental result of 1D regression without noises in Appendix E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">PREDATOR-PREY MODEL AND IMAGE COMPLETION</head><p>We apply NPs to a domain shift problem called the predator-prey model, proposed in the Con-vCNP <ref type="bibr" target="#b12">(Gordon et al., 2019)</ref>. In this experiment, we train models with the simulated data and applied models to predict the real-world data set, Hudson's bay the hare-lynx. Note that the hare-lynx dataset is very noisy, unlike the simulated data. The detailed explanation of datasets is written in Appendix F.</p><p>Recent regularization methods such as Bayesian aggregation, Information dropout, and Bootstrapping are effective to improve performance. In particular, Bootstrapping method significantly influences predictive performance compared of other ANPs as mentioned in the original paper <ref type="bibr" target="#b18">(Lee et al., 2020)</ref>. However, we observe that the proposed method is superior to the other models in both simulated test set and real-world dataset. In particular, all baselines drastically decrease the likelihood values due to noises during the test, while the proposed model preserves the performance because it is robust to noises. See the left side of <ref type="table" target="#tab_1">Table 2</ref>. We report the additional experimental result with periodic noises and the graphical explanation is presented in Appendix F.</p><p>Second, we conduct the image completion task in which the models generate images under some given pixels. The experiment setting follows the previous experiments <ref type="bibr" target="#b10">(Garnelo et al., 2018a;</ref><ref type="bibr" target="#b4">b;</ref><ref type="bibr" target="#b18">Lee et al., 2020)</ref>. To conduct fair comparison, all models employ only MLP encoders and decoders and the multi-head cross attention is used for local representations; the variant of ANPs. We indicate that the proposed method records the best score as seen in the right side of <ref type="table" target="#tab_1">Table 2</ref>. The best baseline records 3.53 with 500 context pixels in <ref type="table" target="#tab_1">Table 2</ref>, whereas our method attains 2.653 of likelihood even with 50 context pixels and grows to 3.948 with 500 context pixels. Referred to <ref type="bibr" target="#b18">Lee et al. (2020)</ref>'s paper, the previous highest score is 4.150 of likelihood for context pixels and 3.129 of likelihood for target pixels. As  mentioned that the more complex architecture like the self-attention mechanism enhances the completion quality than the MLP encoders, these scores were obtained by ANP with self-attention encoders and employing bootstrapping. However, we achieves to obtain comparable results for context points and exceed the previous highest score for target points by a significant margins without exhausted computations and complicated architectures. The completed images by ours and baselines are shown in Appendix J.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MOVIELENS-100K DATA</head><p>We demonstrate the robustness and effectiveness of our method using a real-world dataset, the Movie-Lenz dataset, which is commonly used in recommendation systems. This setting has an expensive data collection process that restricts the number of users. In this section, we report how well the proposed method can be generalized to novel tasks using limited tasks during the meta-training. To train NPs, we decide to split this dataset according to user ID and regard the rating samples made by one user as a task. The purpose of this experiment is that NP provides an identifier to serve for new visitor using very few rating samples. We follow the setting used in the existing work <ref type="bibr" target="#b9">(Galashov et al., 2019)</ref>. The proposed model performs better than the other methods. As mentioned in subsection 4.2, it captures the information from the context dataset, while other methods suffer from noise in the data and lack of users in meta-training. The experiment result of comaprison with baselines is reported in Appendix I. To validate use of real applications, we compare with existing studies. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORKS</head><p>The stochastic attention mechanism enables the capturing of complicated dependencies and regularizing weights based on the user's prior knowledge. However, such methods cannot utilize back-propagation because they do not consider the reparameterization trick to draw samples <ref type="bibr" target="#b22">(Shankar &amp; Sarawagi, 2018;</ref><ref type="bibr" target="#b17">Lawson et al., 2018;</ref><ref type="bibr" target="#b1">Bahuleyan et al., 2018;</ref><ref type="bibr" target="#b5">Deng et al., 2018)</ref>. Even if these methods employ a normal distribution as a posterior distribution of latent variables, satisfying the simplex constraints, which sum to one <ref type="bibr" target="#b1">(Bahuleyan et al., 2018)</ref>, is impossible. Recently, the Bayesian attention module suggests that the attention weights are samples from the Weibull distribution whose parameters can be reparameterized, so this method can be stable for training and maintaining good scalability <ref type="bibr" target="#b7">(Fan et al., 2020)</ref>.</p><p>Since the Conditional neural process have been proposed <ref type="bibr" target="#b10">(Garnelo et al., 2018a;</ref><ref type="bibr" target="#b4">b)</ref>, several studies have been conducted to improve the neural processes in various aspects. The Attentive neural process modify the set encoder as an cross-attention mechanism to increase the performance of the predictability and interpretability . Some studies investigate NPs for sequential data <ref type="bibr" target="#b29">(Yoon et al., 2020;</ref><ref type="bibr" target="#b23">Singh et al., 2019)</ref>. Trials have been combined with optimization-based metalearning to increase the performance of NPs for the image classification task with a pre-trained image encoder <ref type="bibr" target="#b21">(Rusu et al., 2018;</ref><ref type="bibr" target="#b28">Xu et al., 2020)</ref>. The convolutional network can be used for set encoding to obtain translation-invariant predictions with the assistance of supplementary data points <ref type="bibr" target="#b12">(Gordon et al., 2019;</ref><ref type="bibr" target="#b8">Foong et al., 2020)</ref>. Similar to this study, the Bayesian context aggregation suggests the importance of context information over tasks <ref type="bibr" target="#b26">(Volpp et al., 2021)</ref> and the Bootstrapping NPs orthogonally improves the predictive performance under the model-data mismatch. <ref type="bibr" target="#b18">(Lee et al., 2020)</ref>. Unfortunately, there is no clear explanation of how stochasticity has helped improve performance and does not show a fundamental approach to enhancing dependency between the context and the target dataset in terms of set encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this work, we propose an algorithm, neural processes with stochastic attention that effectively leverages context datasets and adequately completes unseen data points. We utilize a stochastic attention mechanism to capture the relationship between the context and target dataset and adjust stochasticity during the training phase for making the model insensitive to noises. We demonstrate that the proposed method can be explained based on information theory. The proposedregularization leads representations paying attention to the context dataset. We conducted various experiments to validate consistent enhancement of the proposed model. We identify that the proposed method substantially outperforms the conventional NPs and their recent regularization methods by substantial margins. This evidence from this study suggests that the proposed method can provides a better identifier to the novel tasks that the model has not experienced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A CLOSED FORM SOLUTION FOR THE KL DIVERGENCE BETWEEN WEIBULL AND GAMMA DISTRIBUTION</head><p>The generalized gamma distribution contains both Weibull and gamma distribution as special cases.</p><p>We are concerned with the three-parameter version of generalized gamma distribution introduced in Stacy ( <ref type="bibr" target="#b24">Stacy et al., 1962)</ref>. Its parameters can be categorized into one scale parameter a and two shape parameters d and p. Its probability density function is defined for x ? [0, ?) and given by</p><formula xml:id="formula_13">f (x|a, d, p) = p a d x d?1 ?( d /p) exp ?( x a ) p (A.1)</formula><p>where ?(?) is the gamma function, and parameters a, d, p &gt; 0. For d = p, it corresponds to the Weibull distribution, and if p = 1, it becomes the gamma distribution. Bauckhage <ref type="bibr" target="#b2">(Bauckhage, 2014)</ref> derives a closed form solution for the kullback-leibler divergence between two generalized gamma distribution as follow.</p><formula xml:id="formula_14">KL(f 1 |f 2 ) := ? 0 f 1 (x|a 1 , d 1 , p 1 ) log f 1 (x|a 1 , d 1 , p 1 ) f 2 (x|a 2 , d 2 , p 2 ) dx = log p 1 a p2 2 ?( d2 /p2) p 2 a p1 1 ?( d1 /p1) + ?( d1 /p1) p 1 + log a 1 (d 1 ? d 2 ) + ?( d1+p2 p1 ) ?( d1 p1 ) a 1 a 2 p2 ? d 1 p 1 (A.2)</formula><p>where f 1 , f 2 are the generalized gamma distributions, and ?(?) is digamma function. The Weiull distribution with scale parameter ? and shape parameter K coincides with the generalized gamma distribution a = ? and d, p = K. For gamma distribution with scale parameter ? and shape parameter ?, it becomes the generalized gamma distribution a = 1 /?, d = ? and p = 1. The KL divergence between the Weibull distribution (?, k) and the gamma distribution (?, ?) amounts to</p><formula xml:id="formula_15">KL(f 1 |f 2 ) = log k ? ? log ? + log ?(?) + ?(1) ? ? ks ?(1) ? ? log ? + ???(1 + 1 /K) ? 1 (A.3)</formula><p>We introduce ?(1) = ?? ? 0.5772 as Euler constant. Finally, we obtain Equation 5</p><formula xml:id="formula_16">KL(Weibull(k, ?)||Gamma(?, ?)) = ?? k ? ? log ? + log k + ??? 1 + 1 k ? ? ? 1 ? ? log ? + log ?(?) (A.4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B ELBO DERIVATIONS</head><p>In this section, we derive the objective function in the manuscript of this paper. Without loss of generality, target dataset {X,</p><formula xml:id="formula_17">Y } = {x i , y i } N i=1 and context dataset D = (X c , Y c ) = {x i , y i } M j=1</formula><p>such that N M . Let the log-likelihood of target data points in a task T k be log p(Y |X, D). We begin to maximizing the log-likelihood of target data points based on context dataset and representations. We suppose that it follows the graphical model in <ref type="figure">Figure D</ref></p><formula xml:id="formula_18">.2c logp(Y |X, D) = log p(Y, Z|X, D)dz (B.5) = log p(Y, Z|X, D) q(Z|X, D) q(Z|X, D) dz (B.6) = log p(Y, Z|X, D) q(Z|X, D) q(Z|X, D)dz (B.7) = log i=1 p(y i |x i , Z i ) q(Z i |x i , D) p(z i |x i , D)q(z i |x i , D)dz (B.8) = log E q(z) i=1 p(y i |x i , Z i ) q(Z i |x i , D) p(z i |x i , D) (B.9)</formula><p>Applying Jensen's inequality to <ref type="figure">Figure D</ref>.2c, we define z is dependent on context dataset D and w i is dependent on target x i and context dataset D</p><formula xml:id="formula_19">log p(Y |X, D) ? E q(z) log i=1 p(y i |x i , Z i )p(Z i |x i , D) q(z i |x i , D) (B.10) ? E q(z) i=1 log p ? (y i |x i , Z i ) ? log q(Z i |x i , D) p(Z i |x i , D) (B.11) From Z i = {z, w i } in</formula><formula xml:id="formula_20">log p(Y |X, D) ? E q(z) i=1 log p ? (y i |x i , Z i ) ? log q(w i |x i , D) p(w i |x i , D) ? log q(z|D) p(z|D) (B.12)</formula><p>We assume that p(w i |x i , D) ? q ?1 2 (w i |K(X c )) by regularization of latent variables to pay attention on context dataset. It also follows the strategy of the standard neural processes : posterior distribution of z is q ?2 (w i |{X t , Y t }) and prior distribution of z is q ?2 (w i |{X c , Y c }). Thereby, we show that ELBO become the objective function of the proposed method in Equation 6.</p><formula xml:id="formula_21">log p(Y |X, D) ? E q(z) i=1 log p ? (y i |x i , Z i ) ? log q ?1 1 (w i |x i , D) q 12 (w i |, K(X c )) ? log q ?2 (z|{X t , Y t }) q ?2 (z|{X c , Y c }) = L Tk (B.13) C PROOF OF THEOREM 1</formula><p>We present that I(y i ; D|x i ) has relation to the objective function of the proposed method. Suppose that Z is information bottleneck for D and all variables follow the graphical models <ref type="figure" target="#fig_0">Figure 2</ref>. As described in Equation 7, the mutual information I(y i , D|x i ) is to measure dependency of y i and context dataset D. We should maximize this information to generalize the novel task. For simplicity, we set all latent variables as information bottleneck Z for the context dataset D. Note that Z = ({w i } n i=1 , z) is information bottleneck corresponding to context representations in NPs, where W = {w i , . . . , w n } is an attention weights and X, Y = {(x 1 , y 1 ), . . . , (x n , y n )} is respectively data points in the target data set. ? is regarded as the parameter of the function to transform D to the information bottleneck Z and ? is the parameter of the identifier for target data point y i . By information bottleneck theorem, Equation C.14 holds.</p><formula xml:id="formula_22">I(y i ; D|x i ) ? I ?,? (y i ; Z|x i ) = ?H ?,? (y|x i , Z) + H(y|x i ) (C.14)</formula><p>The target data point {x i , y i } is drawn by the data generating process T k ? p(T ), so that H(y|x i ) can be regarded as a constant value due to uncontrollable factors. As a result, ?H ?,? (y|x i , Z) is written as</p><formula xml:id="formula_23">?H ?,? (y i |x i , Z) = E (x,y) ? log p ? (y i |x i , Z) (C.15) We employ {xi,yi} log p ? (y i |x i , Z ? ), which is unbiased estimate for ?H ?,? (y i |x i , Z) based on</formula><p>Monte Carlo sampling. Given that the concrete information bottleneck Z is given, we expect that the Z allows us to generalize a novel task {x i , y i } by enhancing {xi,yi} log p ? (y i |x i , Z ? ). However, in practice, Z induced by neural networks is more likely to memorize the training dataset including irreducible noises when the number of tasks is insufficient. The conventional methods accomplished maximizing {xi,yi} log p ? (y i |x i , Z ? ) by simply finding the relation between y i and x i only in the training dataset. It means that the information in representation Z becomes increasingly identical to the information in x i in the meta training dataset. It does not satisfy the condition of information bottleneck for the context dataset D.</p><p>To avoid this issue, we introduce I(Z, x i |D) as a regularization. By reducing dependencies of Z and x i , we can make the information bottleneck Z focus on D. It means that as p(Z|x i , D) and P (Z|D) get closer, the target input x i less influences Z, but D has a high correlation with Z. In other words, minimizing I(Z, x i |D) is to make Z and target x i more independent given context dataset D. It encourages latent variables Z = (w i , z) to pay more attention to context dataset D</p><formula xml:id="formula_24">I(Z, x i |D) = E xi [E Zi [KL(q(Z i |x i , D)||q(Z i ||D))]] = E xi E wi [KL(q(w i |x i , D)||q(w i |D))] + E z [KL(q(z|x i , D)||q(z|D))] (C.16)</formula><p>where, the q(w i |x i , D) follows the Weibull distribution and q(w i |D) follows the gamma distribution. In this study, q(w i |x i , D) can be modeled as the stochastic attention weights and q(w i |D) can be modeled as the key-based contextual prior q ? (w i |K). We can factorize all latent variables because the attention weight w i does not have a dependency on data points except for the specific data point {x i , y i }. We denote that w i has conditional independence over {w j } i =j given x i . For the global representation; z, to follow objective function of neural processes, we assume q(z|x i , D) = q ? (z|X, Y ) and q ? (z|D) = q(z|D). As mentioned in section 3, we suppose that the global representation z follows normal distribution. Therefore, we derive the regularization term I(Z, x t |D) have relation to KL Divergence terms in our loss function. From this fact, we recognize KL Divergence terms in our objective function helps latent variables give attention on context dataset.</p><p>To summarize the mutual information between y i and D, and the newly designed regularization, we found that</p><formula xml:id="formula_25">I(y i ; D|x i ) ? I ?,? (y i ; Z|x i ) ? I(Z, x i |D) ? ?H ?,? (y|x i , Z) ? I(Z, x i |D) + Constant (C.17)</formula><p>Based on the graphical models in <ref type="figure" target="#fig_0">Figure 2</ref> and assumptions of representations z and w i , we identify that this equation has relation to our objective function L T k</p><formula xml:id="formula_26">I ?,? (y i ; Z|x i ) ? I(Z, x i |D) = {xi,yi} log p ? (y i |x i , Z ? ) ? E z [KL(q ? (z|X, Y )|q ? (z|X c , Y c ))] ? E W [KL(q ? (W |X, D)|q ? (W |K(X c )] + Constant = L T k + Constant (C.18)</formula><p>Finally, we can derive Theorem 1 as below</p><formula xml:id="formula_27">L T k (?, ?) ? I(y i ; D|x i ) ? I(Z, x i |D) (C.19)</formula><p>From Equation C.19, the gradients of ? and ? with respect to L T k can be regarded as the direction of increasing I(y i ; D|x i )?I(Z, x i |D), where, L T k is defined as the target likelihood and KL divergence of z and {w i } n i=1 in a single task.</p><formula xml:id="formula_28">L T k (?, ?) = N i=1 log p ? (y i |x i , z, r i ) ? KL q ? (w i |x i , D)|q ? (w i |X D ) ? KL q ? (z|X, Y )|q ? (z|D) (C.20)</formula><p>where X D is input features in the context dataset and q ? (w i |X D ) follows key-based contextual prior as described in section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D IMPLEMENT DETAILS</head><p>We referred to most of the architectures from the paper  and their released source code 1 . The information dropout and importance weighted ELBO were respectively borrowed from these papers <ref type="bibr" target="#b4">Burda et al., 2016)</ref>  <ref type="bibr">23</ref> . The stochastic attention can be implemented based on Bayesian attention modules <ref type="bibr">(Fan et al., 2020) 4</ref> . We migrated and revised all codes to meet our purpose. In this chapter, we follow the notation of this paper <ref type="bibr" target="#b18">(Lee et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 (ATTENTIVE) NEURAL PROCESS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MLP Encoder</head><p>We suppose that multi-layers modules(MLP) have the structure as Equation D.21, where l is the number of layers, d in is the dimension of input features, d hidden is the dimension of hidden units and d out is the dimension of outputs.</p><formula xml:id="formula_29">MLP(l, d in , d hidden , d out ) = Linear(d hidden , d out ) = ? (ReLU ? Linear(d hidden , d hidden ) ? ? ? ) l?2 ? (ReLU ? Linear(d in , d hidden )) (D.21)</formula><p>The variants of neural processes have two types of MLP encoders: The deterministic path is used in the conditional neural process <ref type="bibr" target="#b10">(Garnelo et al., 2018a)</ref>, and the stochastic path is employed in the neural process <ref type="bibr" target="#b11">(Garnelo et al., 2018b)</ref>, attentive neural process  and ours. The deterministic path is to aggregate all hidden units by the MLP encoder.</p><formula xml:id="formula_30">h = 1 |c| j?c MLP(l pre , d x + d y , d h , d h )([x j , y j ]) r = MLP(l post , d h , d h )(h) (D.22)</formula><p>Instead, the stochastic path is to aggregate all hidden units and then feed-forward a single network to generate ? ?1 and ? ?1 . We obtain the stochastic path r via the reparameterization trick.</p><formula xml:id="formula_31">h = 1 |c| j?c MLP(l pre , d x + d y , d h , d h )([x j , y j ]) ? ?1 , ? ?1 = MLP(l post , d h , d h )(h) r = ? ?1 + 2 * ? ?1 (D.23)</formula><p>Attention encoder We introduce cross-attention to describe the dependency of context and target dataset. Let MHA be a multi-head attention <ref type="bibr" target="#b25">(Vaswani et al., 2017</ref>) computed as follows :</p><formula xml:id="formula_32">Q = {Linear(d q , d h )(q)} q?Q K = {Linear(d k , d h )(k)} k?K V = {Linear(d v , d h )(v)} v?V H = softmax( Q K / ? d h )V MHA(Q, K, V ) = LayerNorm(H) (D.24)</formula><p>Where, {d q , d k , d v } are respectively the dimensions of query, key and value components. The LayerNorm is the layer normalization in terms of heads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MLP Decoder</head><p>The architecture of MLP decoder is similar to the stochastic encoder. In case of CNP <ref type="bibr" target="#b10">(Garnelo et al., 2018a)</ref> and NP <ref type="bibr" target="#b11">(Garnelo et al., 2018b)</ref>, this decoder transforms all representation z and the input feature {x i } i?T to target distribution, the normal distribution,</p><formula xml:id="formula_33">{? i , ? i } i?T . (? y , ? y ) = MLP(l dec , d x + d h , d h , 2d y )([z, r i , x i ]) (D.25)</formula><p>Meanwhile, in case of attentive neural process  and ours, the inputs of this decoder are the global representation z, local representation {r i } i?T and the input feature {x i } i?T .</p><formula xml:id="formula_34">(? y , ? y ) = MLP(l dec , d x + d h + d h , d h , 2d y )([z, r i , x i ]) (D.26)</formula><p>The detailed information of each architecture is described in <ref type="table" target="#tab_3">Table D</ref>.1. </p><formula xml:id="formula_35">CNP 3?128 - 3?128 0.001 (for CNP_WD) 5 (IWAE) - - - NP 3?128 - 3?128 0.001 (for NP_WD) 5 (IWAE) - - - CNP_BA 3?128 - 3?128 - 5 - - - NP_BA 3?128 - 3?128 - 5 - - - ConvCNP (U_NET) : 12 layers - 1?16 - - RBF kernel - - ConvNP (U_NET) : 12 layers - 1?16 - 5 (For Sim2Real : 2) * RBF kernel - - ANP 3?128 Multi-heads : 8 3?128 0.001 (for ANP_WD) 5 (IWAE) - - - ANP (dropout) 3?128 Multi-heads : 8 3?128 - - - - Bootstrapping ANP 3?128 Multi-heads : 8 3?128 - 5 - - - Ours 3?128 Multi-heads : 8 3?128 - - - - * :</formula><p>In the case of ConvNP, we proceeded with 2 samples due to lack of memory.  In this paper, we set the dimension of all latent variables as 128, namely d h = 128. The number of heads in multi-head attention is 8, which is the same as the original paper of attentive neural processes . For all models and all experiments, we use the Adam optimizer <ref type="bibr" target="#b15">(Kingma &amp; Ba, 2015)</ref> with the learning rate 0.001, and we set the number of update steps as 200000.</p><p>For training and evalation, we used AMD Ryzen 2950X(16-cores), RAM 64GB and RTX2080Ti. The 1D regressions has a batch size of 1 and a total of 160 batches. The Sim2Real configures the batch size to be 10 and the total number of batches to be 16. The MovieLenz-100k has a batch size of 1 and the number of batches to be 459. The image completion task consists of 227 batches and its size is 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 MODEL ARCHITECTURE</head><p>We graphically show the architecture of the proposed method in <ref type="figure">Figure D</ref>.1. This model has two types of encoder as attentive neural process . The encoder parameters ? consists of ? 1 , ? 2 . The ? 1 is responsible for the local representation r i and the ? 2 is responsible for global representation z. The encoder of global representation is same as neural process <ref type="bibr" target="#b11">(Garnelo et al., 2018b)</ref>, however, the encoder of local representation is different from the standard cross attention <ref type="bibr" target="#b25">(Vaswani et al., 2017)</ref>. After obtaining standard attention weight w standard , we introduce reparameterization trick for w i , which follows the Weiubll distribution <ref type="bibr" target="#b7">(Fan et al., 2020)</ref>. The important thing is that the key conceptual prior can be made by MLP ?1 3 ({x j } j?C ). The decoder is the same as the attentive neural process . The proposed method requires hyper-parameters k and ? for reparameterization of the Weibull distribution and KL divergence between the Weibull and the gamma distribution. We conduct the grid searches for k to find the best value. We identify that the proposed method with k = 300 adequately captures the dependency and generates noises to avoid memorization for all experiments. In the case of ?, we follow the setting of the Bayesian attention module <ref type="bibr" target="#b7">(Fan et al., 2020)</ref>. We suggest the entire procedure of our algorithm as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.4 COMPARISON OF PROBABILISTIC GRAPHICAL MODELS FOR VARIANTS OF NPS</head><p>We describe NPs with probabilistic graphical models to differentiate the variants of NPs. The Neural process employs mean aggregate function and reparameterization trick to obtain a global context representation z <ref type="bibr" target="#b11">(Garnelo et al., 2018b)</ref>. This model follows <ref type="figure">Figure D.</ref>2a. The Attentive neural process expedites the multi-head cross attention to obtain local representation r i with global context representation z. We show that the graphical model for ANP is the middle of <ref type="figure">Figure D.</ref>2, all variables in the attention mechanism are regarded as the determinstic variable.</p><p>In this work, we design that all latent variables contain stochasticity and achieves by the reparameterization trick. By Bayesian attention module, we present our graphical model as shown in <ref type="figure" target="#fig_0">Figure 2</ref> Algorithm 1: Neural Process with stochastic attention Input: Task distribution p(T ), the shape parameters of weibull distribution and gamma distribution : k = 300(Image completion task : k = 100), ? = 1, Stepsize : ? output: encoder parameters : ? = {? 1 , ? 2 }, decoder parameters : ? Initialization : ? and ? randomly;</p><formula xml:id="formula_36">while not converged do Sample tasks {T k } K k=1 from p(T ) for all T k {T } do Sample context dataset (X c , Y c ) = {x j , y j } M j=1 and target dataset (X t , Y t ) = {x i , y i } N i=1</formula><p>from the task T k Sample random noises 1 ? Unif(0, 1) and 2 ? N (0, 1) For the synthetic 1D regression experiment, we set d x = 1, d y = 1. The number of layers in encoder and decoder in all baselines is respectively l enc = {l pre = 3, l post = 1} = 4 and l dec = 3. We set the dimension of latent variable as d h = 128.</p><formula xml:id="formula_37">1 Local representation {r i } N i=1 : Q, K, V ? f ?1 (X t , (X c , Y c )) w standard ? Softmax( QK T / ? d k ) (Reprameterization sampling of weibull distribution for W ) ? ? w standard * ?(1 + 1 /k) W = {w 1 , ? ? ? , w n } ? ?(? log(1 ? 1 )) 1 /k W = {w 1 , ? ? ? , w n } ? { wi Wi , ? ? ? , wn Wi } (Parameters of the prior distribution for W ) ? ? f ?1 (K) {r i } N i=1 ? {w i V, ? ? ? , w n V } 2 Global representation z : ? ?1 , ? ?1 ? Aggregator(f ?2 ({x j , y j } M j=1 )) (Reprameterization sampling of normal distribution for z) z = ? ?2 + 2 * ? ?2 3 Decode p(Y t |X t , z, {r i } N i=1 ) : ? y , ? y ? (f ? (X t , z, {r i } N i=1 )) 4 Evaluation loss : L ?,? T k = N i=1 log p ? (y i |? y,i , ? y,i ) ? KL q ?2 (z| {X t , Y t })|q ?2 (z| {X c , Y c }) ? KL q ?1 (w i |x i , X c )|q ?1 (w i |X c ) end Update ? ? ? + ?? ? 1 |T | T k L T k Update ? ? ? + ?? ? 1 |T | T k L T k end</formula><p>When it comes to data generation process, the training data is generated from the Gaussian process with RBF kernel. For each task, we randomly generate x ? U nif (?2, 2) and then y is the function value by the Gaussian process with RBF kernel, k(x, x ) = s 2 ? exp(? x?x 2 /2l 2 ). To validate our model, we establish two types of datasets in the this 1D regression experiment.</p><p>First, we set the parameters of the RBF kernel as s = 3 and l = 3. Hence, as shown in <ref type="figure">Figure E</ref>.3a, all datasets are drawn from continuous and smooth functions. Second, we consider the noisy situations in the first scheme. We intend that the suggested scheme represents the actual real-world situation. Unlike the existing studies <ref type="bibr" target="#b10">(Garnelo et al., 2018a;</ref><ref type="bibr" target="#b18">Lee et al., 2020)</ref>, we modify the RBF kernel function adding a high frequency periodic kernel function k(y, y ) = s 2 ? exp(?2 sin 2 (? x ? x 2 /p)l 2 ). <ref type="bibr" target="#b18">Lee et al. (2020)</ref> proposed a noisy situation by using random noises sampled by t-distribution; however, these noises often have exaggerated values so that the generated function does not have any tendency and seems to be entire noises. On the other hand, the function generated by Gaussian processes with a high frequent periodic kernel is smooth but is satisfied with a random function every trial. Thus, this function does not interfere with the smoothness of the RBF GP function and maintains the smoothness of all support ranges. Therefore, we decide to use the dataset generated by the RBF GP function with periodic noises to synthetically test all baselines and the proposed method for the robustness of noises. The sampled dataset is graphically presented in <ref type="figure">Figure E</ref> To generate function values of the Gaussian process, the GPy library 5 provides various functions compatible for PyTorch 6 . In the GPy, x ? x 2 can be regarded as the pre-defined vector {1, . . . , freq} T {1, . . . , freq}. We set the parameters of the periodic kernel as freq = 30, p = 2?, s = 1. The generated functions for training datasets are shown in <ref type="figure">Figure E</ref>.3.</p><p>To test generalization to a novel task, we introduce other functions such as the Matern32 kernel GP and the periodic kernel GP as shown in <ref type="bibr" target="#b18">Lee et al. (2020)</ref>. In this experiment, we expect the trained models to capture context points despite different functions. Naturally, all models perform well on the RBF GP function because the meta-training set is generated from RBF GP functions; instead, we test all baselines on other types of functions such as the Matern32 kernel GP and the Periodic kernel GP as well as the RBF kernel GP. For the Matern32 kernel k(x, x ) = s 2 (1+ ? 3 x?x ) exp(? ? 3 x?x ) and the periodic kernel is same as mentioned earlier. The shared parameters of these three GPs are same as s = 3, l = 3. The periodic kernel requires another parameter freq = 10, which is the default value in the GPy.</p><p>To elaborate the meta-training framework, the minimum number of context points is 3, and the minimum number of target points is 6, including the context data points. The maximum number of context points and target points is respectively 97 and 100. In the following subsection, we report experimental results, including clean and noisy situations. We train all baselines on the RBF GP functions without noises. We demonstrate experimental results in terms of predictability and context set encoding.</p><p>As shown in <ref type="table" target="#tab_6">Table E</ref>.4, all models are capable of fitting the RBF GP function; meanwhile, all models are degraded in cases of Matern kernel GP and Periodic GP. Unlike all baseline models, of which performances drop substantially, the proposed method has relatively small degradation. Particularly, the proposed method records that the likelihood value of context points at Matern kernel GP and Periodic GP is respectively 1.170 and 0.680. Meanwhile, the best performance among baselines is 1.077 and 0.379 by ANP with weight decay. This result shows that the proposed method performs better than all baselines. The graphical results are described in <ref type="figure">Figure E</ref>.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 EXPERIMENT RESULT ON RBF GP FUNCTIONS WITH NOISES</head><p>As mentioned early in the current section, we train all models on the RBF GP functions adding the random periodic noise. Looking at the column of RBF kernel GP in <ref type="table" target="#tab_0">Table 1</ref>, most of the baselines are degraded due to noisy situations. However, the performances of all baselines are improved in Matern GP and Periodic GP. We guess that this phenomenon can be explained as mitigating memorization issues by injecting random noise to the target value <ref type="bibr" target="#b19">(Rajendran et al., 2020)</ref>. We present how effectively random noises improve generalization performances for all baselines and our method in this experiment. However, we can recognize that injecting random noises cannot be a fundamental solution. As seen in Appendix G, we emphasize that capturing and appropriately utilizing context information when predicting target values is a fundamental solution to avoid memorization in a given situation. The experimental result is described in <ref type="table" target="#tab_0">Table 1</ref> on manuscript and the detailed graphical explanation is suggested in <ref type="figure">Figure E</ref>.5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F PREDATOR PREY MODEL</head><p>We follow the experimental detail in this paper <ref type="bibr" target="#b18">(Lee et al., 2020;</ref><ref type="bibr" target="#b12">Gordon et al., 2019)</ref>. This experiment is designed to evaluate all baselines capable of adapting new tasks, which have slightly different task distributions. It is called "Sim2Real". We assume that, in this situation, we easily obtain simulation data, but it requires a high expense to collect real-world data points. We try to train all baselines on the dataset generated by simulations and test them on real data sets that are relatively small compared to the simulation data.</p><p>The way of simulated data is generated from the Lotka-Volterra model(LV model) <ref type="bibr" target="#b27">(Wilkinson, 2018)</ref>.</p><p>Note that X is the number of predators, and Y is the number of prey at any time step in our simulation. According to the explanation, one of the following four events should occur. The following events require the parameter ? 1 = 0.01, ? 2 = 0.5, ? 3 = 1, ? 4 = 0.01 1. A single predator is born according to rate ? 1 ? X ? Y , increasing X by one.</p><p>2. A single predator dies according to rate ? 2 ? X, decreasing X by one.</p><p>3. A single prey is born according to rate ? 3 ? Y , decreasing Y by one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>A single prey dies(or is eaten) according to rate ? 4 ? X ? Y , decreasing Y by one.</p><p>The initial X and Y are randomly chosen. On the other hand, Hudson's bay lynx-hare dataset follows a similar tendency to the LV model; however, it is oscillating time series because it has been collected in real-world records. There were unexpected outliers, unexplained events, and noise. For the detailed explanation, refer <ref type="bibr" target="#b12">Gordon et al. (2019)</ref>'s work. All simulation codes are available on this URL 7 . The generated simulation data can be graphically shown as the left side of <ref type="figure">Figure F</ref>.6.</p><p>In this experiment, we set d x = 1, d y = 2, and all remaining settings are the same as the 1D regression experiment except that the number of context points is at least 15 and the extra target points is also at least 15. When training models, we use the dataset generated by the LV model and test on the lynx-hare dataset. The experimental result is shown in <ref type="table" target="#tab_1">Table 2</ref>, and the prediction performance can be graphically shown in <ref type="figure">Figure F</ref>.6.</p><p>We conduct additional experiments to validate whether the random periodic noise positively influences the performance. As conducted in the 1D regression experiment, we utilize the periodic kernel GP function, which has very high frequency freq = 100 to add noises to the training dataset. As shown in <ref type="table" target="#tab_6">Table F</ref>.5 compared to <ref type="table" target="#tab_1">Table 2</ref>, We recognize that adding random periodic noise empirically improves all baselines and our method. Among models, our models perform best due to the full representation of context and target datasets. The prediction results can be graphically shown in <ref type="figure">Figure F</ref>.6b 7 https://github.com/juho-lee/bnp 25 Published as a conference paper at ICLR 2022  The attention mechanism can explicitly display the distance between context and target data points via attention weights. Especially, when the dimension of features is one, x ? R 1 , the distance between features is simply calculated and sorted, so allowing for straightforward comprehension when the attention weights are shown in heat-maps. As a result, we present several heatmaps to compare ours with baselines in both clean and noisy 1D regression datasets. The horizontal axis in these graphs represents the value of features in the context dataset, while the vertical axis represents the value of features in the target dataset. The best pattern for this heat-map is diagonal because all feature values are arranged in ascending order. Additionally, we will provide the simplified heat-map that take into account only target points with same value in the context dataset. Due to the fact that the original version has one-hundred target points, labels and ticks are necessarily small. We guess that readers may be unable to decipher the detailed information such as labels and attention scores. This simplified version allows the readers to instantly grasp what we attempt to convey by exhibiting a more distinct diagonal pattern. From <ref type="figure">Figure G</ref>.7 to <ref type="figure">Figure G</ref>.9, on the left side, we show a simplified version of the attention score; on the right side, we show the result for the entire target dataset. Plus, we provide Sim2Real's attention heat-maps in both clean and noisy environments. As a result, our discovery appears to be consistent.</p><p>First, the heatmaps of the 1D regression problem without perioidc noises are shown in <ref type="figure">Figure G</ref>.7. In this graph, all models including ours can accurately depict the similarity between the context and targete dataset. Although the attention scores for each model vary, it is clear that the majority pattern of all models is diagonal. Therefore, all models are trained using the clean dataset in the intended manner. However, other phenomena are found in the noisy data. We identify that the attentive neural process  fails to capture contextual embeddings because the attention weights of all target points highlight on the lowest value or the maximum value in the context dataset. In the case of the Bootstrapping ANP <ref type="bibr" target="#b18">Lee et al. (2020)</ref> and ANP with information dropout, the quality of heat-map is slightly improved, but it still falls short of ours. This indicates that the present NPs are unable to properly exploit context embeddings because the noisy situations impair the learning of the context embeddings during meta-training. On the other hands, even in the noisy situation, the attention score in ours still appear clearly. Second, we include heatmaps for the Sim2Real problem. As seen in <ref type="figure">Figure F</ref>.6, the context and target datapoints are much too many for the label information and ticks to be recognized. Hence, we recommend that readers verify the presence of diagonal patterns rather than examining detailed numerical values. As seen in <ref type="figure">Figure G</ref>.9a, all models are capable of capturing properly similarity between the context and target datasets. However, as with 1D regression, the diagonal pattern of the baselines is disrupted as seen in the left graph of <ref type="figure">Figure G</ref>.9b; nevertheless, ours retains the ideal pattern in both clean and noisy situations.</p><p>When comparing our model's heat-map pattern in clean and noisy environments, there is a noteworthy point. Our model is capable of learning adaptively how to focus on certain context datapoints depending on the extent of dirty data in the meta-train dataset. The model is trained on the clean dataset to take into consideration nearby points as well as the corresponding point in the context dataset, hence, the heat-map gradually changes. This is because the clean dataset has smooth values, y i,j , near a certain feature x i,j . Meanwhile, in the noisy dataset, the model is trained to focus exclusively on corresponding points to the context dataset. Hence, the heat-map in <ref type="figure">Fig E.5 (b)</ref> indicates that attention score of target datapoints that includes the context dataset has a high value, whilst the remainder points treat all context datapoints uniformly. This phenomena occurs because there is less correlation between adjacent features x i,j and its labels y i,j in the noisy situation during the meta-training.  This section discusses the effect of suggested regularization, paying more attention to the context dataset on attention scores. We demonstrated how the proposed regularization term results in an increase in learning stability and embedding quality. Prior to conducting a thorough comparison of stochastic attention with and without regularization, we analyze learning curves between baselines, such as CNP, ConvCNP and ANPs in 1D regression under a noisy situation. Because the proposed regularization naturally incorporates the attention mechanism, we begin by comparing the proposed model to NPs that do not employ the attention mechanism. We choose CNP with Bayesian Aggregation, NP with Bayesian Aggregation <ref type="bibr" target="#b26">(Volpp et al., 2021)</ref> and ConvCNP <ref type="bibr" target="#b12">(Gordon et al., 2019)</ref> as baselines, taking into account prediction performance as demonstraed in <ref type="table" target="#tab_0">Table 1</ref>. As shown in <ref type="figure">Figure H</ref>.10a, the negative loglikelihood of CNP_BA and NP_BA have converged to about ?10.0 and 0.0 However, the ConvCNP and ours record values around ?30.0. In the case on ConvCNP, this method optimally computes similarity between context and augmented data points (called grid) that include target points with a high probability using the thereotically well-defined functional representation by RBF kernel function. On the other hand, the proposed regularization approaches the ideal loglikelihood value without the assistance of extra data points. The proposed can train how to establish similarity between context and target points and predict labels of target points during meta-training. Second, we compare training curves between ANP, ANP(dropout) , Bootstrapping ANP <ref type="bibr" target="#b18">(Lee et al., 2020)</ref> and ours. This comparison indicates that while all methods make use of the attention mechanism, the chosen baselines exclude stochastic attention and regularization; I(Z, x i |D). When we look at <ref type="figure">Figure H.10b</ref>, we observe the same results as shown the quality of context embeddings in Appendix G. While the Bootstrapping ANP had superior training curves to ANP and ANP(dropout), but it was unable to be match ours. We examine the general effect of the proposed regularization to the stochastic attention by altering hyper-parameter K. We conduct experiments in which all models use same generative process for stochastic attentions, as desribed in <ref type="figure" target="#fig_0">Figure 2</ref>, but with varied hyper parameter, <ref type="bibr">K ? {1, 10, 20, 30, 40, 50, 60, 70, 80, 100, 300, 500} and the presence</ref> </p><formula xml:id="formula_38">of KL[q ? (w i |x i , X c )|q ? (w i |X c )].</formula><p>To begin, when we analyze <ref type="table" target="#tab_6">Table H</ref>.6, we observe that variation of the hyper-parameter K has little influence on the prediction performance of 1D regressions. If the models properly converge, the prediction outcomes should be statistically indistinguishable. However, the proposed regularization has an effect on model's learnability. While all experiments cases that employ the proposed regularization converge, a few models with the hyper-parameter K ? {10, 50, 70} that do not use the proposed regularization, do not. Additionally, we demonstrate this fact via negative log likelihood values in the meta-training, as seen in <ref type="figure">Figure H</ref>.11. As <ref type="table" target="#tab_6">Table H</ref>.6 indicates, all models that use the proposed regularization have converged, whereas some models that do not use the proposed regularization and use the hyper-parameter K ? {10, 50, 70}, have significantly different training curves when compared of converged models. Therefore, we anticipate that the proposed method will ensure learnability and convergence regardless of a hyper-parameter value.  We study the learned attention scores in detail to verify the proposed regularization's efficiency. To conduct fair comparison, we fix the number of context points and choose target points that have same value as the context dataset. The ideal scenario is that all scores in the diagonal components have identical values and little variation regardless of the placement of target points as the attention mechanism should focus exclusively on context and target dataset.</p><p>As seen in the case of no regularization in <ref type="figure">Figure H</ref>.12, despite somewhat varied scores, all converged models exhibit the same diagonal pattern. As a result, these models present similar prediction performance. We argue that 1D regressions do not need precise context embeddings. However, when we compare the attention scores with and without regularization, we discover findings regarding the quality of context embeddings. In the absence of regularization, the values of attention weights changes according to the hyper-parameter K. Certain models place a less emphasis on the diagonal components than others, while others excessively place a greater emphasis on them. Without the regularization, the attention scores of diagonal components range from 0.3 to 0.64. We instantly notice that without regularization, the attention heat-map of stochastic attention has an inconsistent degree of brightness in relation to the hyper parameter K. In particular, the heatmaps of K = 60, 100 is too bright in comparison to other heat-maps, whilst the heatmaps of K = 40 is too dark. While the diagoanl pattern is presented, there is no consistency in the brightness of any heat-maps.</p><p>On the other hand, the attention scores of regularized models exhibit little fluctuation. Regardless of the hyper parameter K, these scores are closed to 0.5. properly emphasize on the context dataset according to property of context and target dataset. The regularization cases in <ref type="figure">Figure H</ref>.12 illustrate this fact graphically. All heatmaps of stochastic attention that employ the proposed method regularization have very a comparable brightness. We identify that the proposed regularization ensures learning stability by ensuring the quality of context embeddings remains consistent indepedent of the hyper-parameter K. As a consequence, we declare that the proposed method increases model's insensitivity to hyper-parameters K by preserving the context embeddings consistently.   tion is 0.001. As a result of the consistent scores across all target points ranges, we realize that the regularized model improves context embeddings.</p><p>The detailed analysis is shown in <ref type="figure">Figure H</ref>.14. While the mean values of attention scores vary between individuals, the proposed regularization assures that attention scores are constantly near 0.5 value. From the perspective of NP's aim, the proposed regularization enbales models to achieve those objectives. The attention scores of all target points must not be influenced by feature magnitudes and their regions. Consequently, this method has to concentrate only on the similarity between features. The regularization aims to derive an appropriate attention mechanism that evenly weights across important regions and eliminates biases during the meta-training. It leads to achieving task adaptation, as it equally prioritizes context data points regardless of features magnitude. Whenever the novel arises, the regularization ensures that the models retain the quality of their context embeddings.</p><p>We investigate more research into the cases of not converged models. As seen in <ref type="figure">Figure H</ref>.15, there are completely distinct phenomena from what we have observed so far. When models are not converged, all attention scores remains constently uniform across all region. As a result, the prediction performance degrades. However, when the models use the proposed regularization, the attention scores are comparable to the others. This means that the regularization is crucial for preventing models from trapped in the local optima. Additionally, as seen in <ref type="figure">Figure H</ref>.11, this regularization enables models can approach to maximize log likelihood values. By examining these phenomenon, it is clear that the approach proposed in this study performed as a regularization role. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I MOVIELENZ-100K DATA</head><p>We follow the experimental detail in the paper <ref type="bibr" target="#b9">(Galashov et al., 2019)</ref>. The way to split into train, test, validation dataset is described in this work 8 . Briefly, all ratings are first divided into two datasets, which respectively have user IDs and are not duplicated each other. We define that one is the meta-training dataset and the other is the meta-test dataset. In this experiment, we evaluate baselines that generalize to a new customer with small history data points. To explain a training regime, the number of context is at least three and the objective function is computed with the remaining data points. All users do not have the same amount of ratings so that the number of data points is varying during meta-training. When testing baselines, we sample a few ratings from unobserved users and then evaluate the likelihood values for the remaining points. To exclude users' unique information, we drop the User ID from the set of features and only use general features such as age, occupation. Lastly, in this experiment, we set d x = 44, d y = 1, and all remaining settings are the same as the 1D regression experiment. The detailed explanation is in <ref type="bibr" target="#b9">Galashov et al. (2019)</ref>'s work. The likelihood values on the MovieLens-10k is reported in <ref type="table" target="#tab_6">Table I</ref>.8. To compare RMSE scores with existing methods for Movielens-100k data, we suggest evaluating NPs using u1.base and u1.test. As mentioned, the prediction by NPs is based on given context data points. First, we randomly choose a customer in the u1.test. Second, we randomly sample a small number of ratings from u1.base, which is used as the meta-training data. In this experiment, we decided to draw ten samples from u1.base and employ these points as the context data set. The ten ratings is relatively a short history compared to the size of the u1.base. Third, we perform predictions for the data points in the u1.test based on the context data points. The important thing is that context and target data points are sampled from the same user but the different data set. Plus, we do not touch in information in the test set, at least. Based on the relationship between sampled context points and target points, the performance of NPs is somewhat variable, so we report five runs and average these results. The experimental result is in <ref type="table" target="#tab_2">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J IMAGE COMPLETION</head><p>In the image completion task, we follow the training regime suggested by NPs <ref type="bibr" target="#b10">(Garnelo et al., 2018a;</ref><ref type="bibr" target="#b4">b)</ref>. In this regime, d x means the pixel location and d y means the color RGB data. Namely, we set d x = 2 and d y = 3. For high capacity representation, the dimension of all hidden units is determined as d h = 512. All remaining settings, including layer sizes, are the same as the 1D regression experiments.</p><p>When it comes to image completion tasks, according to these papers, NPs are known to complete facial images given partial pixels. Although a few pixels are provided, NPs are capable of understanding the common appearance of a human face. These models generate eye, mouth, and nose even if only a small number of local information is given, which is generally hard to recognize. The Conditional neural process properly performs; however, it often loses its context representations. The Attentive neural process tackles this issue to employ an attention mechanism. Instead of the encoders consisting of MLP layers, the self-attention can improve the quality of pixels generated at the context data points. However, as mentioned on subsection 4.2, scores of generated pixels in unseen regions are still problems. Even though many pixels are provided, the quality of completed images is not improved. In this work, the proposed method concentrates on given contextual pixels and complete images based on that information. Hence, the proposed method completes an image with high uncertainty when few pixels are given. Plus, it can be seen that the higher the pixels information, the higher the quality of generated images. The numerical result is presented in <ref type="table" target="#tab_1">Table 2,</ref>  The proposed method allows for completion of images using only partially provided pixels, so it enables to complete larget images than the image size in the training dataset. We produce images of various sizes using the proposed method, which is trained on the CelebA dataset with size of 32 ? 32. The completed images are presented in <ref type="figure">Figure J</ref>.20. When we qualitatively evaluate the completion results, the proposed method properly perform for generating large images without sacrificing performance. All completed images are quite close to the ground truth. As a result, we conclude that the proposed method can be used for task adaptation since it can complete images that the model have never encountered during meta-training and whose sizes differ from the training dataset. In particular, while the percentage of contributed pixels to the total number of pixels remains constant, the quality of completed images are enhanced according to the amount of provided pixels. We understand that the number of pixels is more significant than the ratio of context points. This is because the model has a sufficient pixel counts to work with when images are large. For instance, employing only 300 pixels as a context dataset is insufficient to complete the images. Nonetheless, the completed images with 300 pixels are comparable to those with higher pixel counts and is of higher quality than the baselines in <ref type="figure">Figure J.</ref>18.</p><p>There is an interesting discovery of uncertainty values in the image completion task. Basically, we expect that many pixels reduce the uncertainty of generated images. However, the existing methods stably generate facial images, but uncertainty values do not decrease even if available pixels increase. The proposed method makes high variance for a completed image under the small number of context points. As shown in <ref type="figure">Figure J</ref>.21, it can decrease the uncertainty of completed images when the number of context points is large. From this fact, we identify that the proposed method performs in an intended manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>38</head><p>Published as a conference paper at ICLR 2022 </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Probabilistic graphical models for the proposed method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure</head><label></label><figDesc>Figure D.1: Model Architectures of the proposed method</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>2: Comparison of graphical models; (a) Neural process<ref type="bibr" target="#b11">(Garnelo et al., 2018b)</ref>, (b) Attentive neural process and (c) Proposed method E 1D REGRESSIONS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>.3b. (a) The RBF kernel GP (b) The RBF kernel GP with periodic noises Figure E.3: Comaprison of RBF GP functions in 1D regression problems</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure E. 4 :</head><label>4</label><figDesc>1D regression results by NPs trained on the RBF kernel function without periodic noises. All baselines and ours fit the RBF GP function, but degrade their performances in cases of Matern and Periodic kernel GP. 23 Figure E.5: 1D regression results by NPs trained on the RBF kernel function with periodic noises. All models improve performance in Matern and Periodic GP than Figure E.4. The proposed method outperforms baselines and regularization methods. Even this model achieves better performance than the result on RBF GP without noises. 24</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure F. 6 :</head><label>6</label><figDesc>Prediction results on the hare-lynx data. (left) All models are trained on the clean dataset. (right) All models are trained on the noisy dataset. G ANLAYSIS OF CONTEXT EMBEDDINGS VIA ATTENTION WEIGHTS IN 1D REGRESSIONS AND THE LYNX-HARE DATASET</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure G. 7 :</head><label>7</label><figDesc>Heatmaps of asscociated attention weights in 1D regression problems when test datasets are sampled from RBF and Periodic kernel functions. All models are trained on the clean dataset. (Left) A simplified heat-map that takes into account only target datapoints with same value in the context dataset. (Right) A heat-map that takes into account entire target datapoints.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure G. 8 :</head><label>8</label><figDesc>Heatmaps of asscociated attention weights in 1D regression problems when test datasets are sampled from RBF and Periodic kernel functions. All models are trained on the data with periodic noises. (Left) A simplified heat-map that takes into account only target datapoints with same value in the context dataset. (Right) A heat-map that takes into account entire target datapoints. of asscociated attention weights in the hare-lynx dataset. (Left) A simplified heat-map that takes into account only target datapoints with same value in the context dataset. (Right) A heat-map that takes into account entire target datapoints. (a) All models are trained on the clean dataset by the lotka-volterra simulation (b) All models are trained on the lotka-volterra simulation with periodic noises.H ABLATION STUDY: RELATIONSHIP BETWEEN REGULARIZATION OF PAYING MORE ATTENTION TO THE CONTEXT DATASET AND CONTEXT EMBEDDINGS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>10: Comparison of training curves with their respective baselines. (a) The baselines that do not employ the attention mechanism. (b) The baselines that employ the attention mechanism.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure H. 11 :</head><label>11</label><figDesc>Comparison of training curves varying the hyper parameter K. All models employ the generative process of stocahstic attentions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure H. 12 :</head><label>12</label><figDesc>Comparison of attention scores varying the hyper-parameter, k and the presense of regularization, in 1D regressions drawn from the RBF kernel GP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>13: Mean and variance for attention scores of diagonal components varying the hypereparameter K and regularization. (a) No regularization. (b) Regularization Figure H.14: Mean and variance for attention scores of off diagonal components varying the hypereparameter K and regularization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure H. 15 :</head><label>15</label><figDesc>Comparison of attention scores when the models without regularization are not properly trained, K ? {10, 50, 70}, in 1D regressions drawn from the RBF kernel GP. (left) All methods do not utilize the suggested regularization. They employ the reparameterization trick exclusively for attention scores. (right) All methods employ the suggested regularization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>the graphical evidences are shown in from Figure J.16 to Figure J.19.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure J. 16 :</head><label>16</label><figDesc>Completed images using 50 pixels Figure J.17: Completed images using 100 pixels 39 Published as a conference paper at ICLR 2022 Figure J.18: Completed images using 300 pixels Figure J.19: Completed images using 500 pixels (20: Our completed images in a variety of sizes. The training dataset consists of the CelebA images with a size of 32 ? 32. The completed images range in size from 32 ? 32 to 80 ? 80. Each image is completed with 0.3 of the overall pixels. As the image size increases, the following values are used as the number of context points;{300, 690, 1230, 1920}. Both the context dataset and its completed image are displayed. Additionally the most right column has the ground truth image. Each image is shown in proportion to its image size.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Results of likelihood values on the synthetic 1D regression experiment. The test samples are drawn from GPs with various kernel functions; All methods are trained on the samples from the RBF GP function. To consider noisy setting, we artificially generate a periodic noise in the training step. Bold entries indicates the best results. 151?0.012 -0.690?0.059 0.107?0.018 -0.177?0.024 -0.235?0.032 -0.918?0.029 -0.400?0.046 -1.321?0.047 ANP 0.228?0.021 -0.603?0.036 0.405?0.0010 -0.097?0.024 0.254?0.006 -0.488?0.014 0.111?0.034 -0.951?0.070</figDesc><table><row><cell></cell><cell cols="2">RBF kernel GP(noises)</cell><cell cols="2">RBF kernel GP</cell><cell cols="2">Matern kernel GP</cell><cell cols="2">Periodic kernel GP</cell></row><row><cell></cell><cell>context</cell><cell>target</cell><cell>context</cell><cell>target</cell><cell>context</cell><cell>target</cell><cell>context</cell><cell>target</cell></row><row><cell>CNP</cell><cell cols="3">0.233?0.036 -0.478?0.034 0.440?0.013</cell><cell>0.026?0.014</cell><cell cols="4">0.246?0.021 -0.544?0.024 0.176?0.022 -0.978?0.033</cell></row><row><cell cols="2">NP -0.(Weight decay; ? = 0.001)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNP</cell><cell cols="3">0.240?0.041 -0.471?0.037 0.460?0.016</cell><cell>0.045?0.020</cell><cell cols="4">0.278?0.035 -0.472?0.041 0.185?0.012 -0.970?0.037</cell></row><row><cell>NP</cell><cell cols="8">-0.153?0.033 -0.709?0.070 0.122?0.026 -0.178?0.036 -0.228?0.034 -0.936?0.026 -0.401?0.047 -1.315?0.072</cell></row><row><cell>ANP</cell><cell cols="3">0.957?0.015 -0.442?0.030 1.050?0.011</cell><cell>0.053?0.034</cell><cell cols="4">1.014?0.009 -0.209?0.036 0.926?0.007 -0.644?0.027</cell></row><row><cell cols="2">(Importance Weighted ELBO; s = 5)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNP</cell><cell cols="3">0.271?0.024 -0.442?0.041 0.478?0.012</cell><cell>0.059?0.029</cell><cell cols="4">0.321?0.019 -0.460?0.036 0.231?0.017 -0.957?0.041</cell></row><row><cell>NP</cell><cell cols="8">-0.155?0.014 -0.633?0.026 0.067?0.016 -0.213?0.030 -0.238?0.015 -0.779?0.018 -0.330?0.008 -1.094?0.088</cell></row><row><cell>ANP</cell><cell cols="8">0.771?0.012 -0.470?0.034 0.895?0.016 -0.031?0.026 0.800?0.031 -0.324?0.027 0.704?0.026 -0.687?0.039</cell></row><row><cell cols="2">(Bayesian Aggregation)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNP</cell><cell cols="3">0.351?0.049 -0.508?0.084 0.575?0.016</cell><cell>0.112?0.025</cell><cell cols="4">0.349?0.018 -0.569?0.097 0.278?0.018 -1.026?0.051</cell></row><row><cell>NP</cell><cell cols="8">-0.406?0.035 -0.723?0.067 -0.201?0.024 -0.389?0.024 -0.450?0.014 -0.837?0.036 -0.537?0.011 -0.877?0.021</cell></row><row><cell cols="2">(Functional representation)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ConvCNP</cell><cell cols="3">1.314?0.007 -0.428?0.033 1.326?0.010</cell><cell>0.084?0.020</cell><cell cols="4">1.319?0.007 -0.119?0.023 1.358?0.003 -0.502?0.022</cell></row><row><cell>ConvNP</cell><cell cols="3">0.873?0.154 -0.469?0.041 0.729?0.131</cell><cell>0.053?0.017</cell><cell cols="4">0.832?0.005 -0.163?0.025 0.953?0.077 -0.522?0.025</cell></row><row><cell cols="2">(Regularization for local representation)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ANP (dropout)</cell><cell cols="8">0.158?0.019 -0.593?0.035 0.372?0.026 -0.163?0.025 0.136?0.020 -0.575? 0.014 0.014?0.017 -0.877?0.036</cell></row><row><cell cols="4">Bootstrapping ANP 0.754?0.018 -0.407?0.036 0.872?0.009</cell><cell>0.043?0.023</cell><cell cols="4">0.788?0.010 -0.303? 0.032 0.711?0.025 -0.717?0.033</cell></row><row><cell>Ours</cell><cell cols="3">1.374?0.004 -0.337?0.027 1.363?0.010</cell><cell>0.244?0.026</cell><cell>1.</cell><cell></cell><cell></cell></row></table><note>365?0.009 -0.175?0.031 1.372?0.005 -0.612?0.029 data point and aggregated by log i exp L k . Recent regularization methods can be also considered. Information dropout(Kingma et al., 2015; Achille &amp; Soatto, 2018), Bayesian aggregation</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results of likelihood values on the Sim2Real experiment using predator-prey simulation and image completion with the CelebA dataset. In the image completion, there are several experimental cases; The number of context points is in {50, 100, 300, 500}. We report that likelihood of context points is averaged over all experiment cases and elaborate individual likelihood values of target points. Bold entries indicates the best results. 078?0.006 2.501 2.801 3.005 3.043Bootstrapping ANP 2.537?0.001 2.166? 0.001 2.451?0.019 -3.382?1.288 3.172?0.009 2.453 2.837 3.095 3.145 Ours 2.711?0.000 2.297?0.000</figDesc><table><row><cell></cell><cell></cell><cell cols="2">Sim2Real : Predator-Prey</cell><cell></cell><cell cols="4">Image Completion : CelebA</cell></row><row><cell></cell><cell cols="2">Simulation</cell><cell>Real</cell><cell></cell><cell>context</cell><cell></cell><cell cols="2">Target</cell></row><row><cell></cell><cell>context</cell><cell>target</cell><cell>context</cell><cell>target</cell><cell></cell><cell>50</cell><cell>100</cell><cell>300</cell><cell>500</cell></row><row><cell>CNP</cell><cell>0.395?0.000</cell><cell cols="8">0.274?0.000 -2.645?0.085 -3.120?0.245 3.452?0.002 2.662 3.077 3.359 3.414</cell></row><row><cell>NP</cell><cell cols="9">-0.259?0.004 -0.369?0.002 -2.526?0.030 -2.816?0.088 3.072?0.003 2.483 2.786 2.999 3.042</cell></row><row><cell>ANP</cell><cell>1.211?0.001</cell><cell cols="7">0.961?0.001 -1.756?0.187 -3.742?0.448 3.100?0.012 2.492 2.806 3.02</cell><cell>3.06</cell></row><row><cell cols="2">(Weight decay; ? = 0.001)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNP</cell><cell>0.393?0.000</cell><cell cols="5">0.265?0.000 -2.661?0.023 -3.049?0.096 2.969?0.014 2.21</cell><cell>2.6</cell><cell cols="2">2.866 2.918</cell></row><row><cell>NP</cell><cell cols="9">-0.069?0.003 -0.185?0.001 -2.571?0.054 -2.914?0.108 2.429?0.008 1.878 2.17 2.368 2.406</cell></row><row><cell>ANP</cell><cell>1.520?0.001</cell><cell>1.180?0.002</cell><cell cols="7">0.212?0.129 -2.807?0.665 2.832?0.025 2.339 2.611 2.795 2.829</cell></row><row><cell cols="2">(Importance Weighted ELBO; s = 5)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNP</cell><cell>0.476?0.000</cell><cell cols="8">0.337?0.000 -2.596?0.048 -3.038?0.183 3.474?0.002 2.67 3.091 3.379 3.436</cell></row><row><cell>NP</cell><cell cols="9">0.055?0.002 -0.067?0.002 -2.514?0.048 -2.760?0.107 3.179?0.023 2.49 2.856 3.112 3.163</cell></row><row><cell>ANP</cell><cell>1.004?0.001</cell><cell cols="8">0.775?0.001 -1.800?0.203 -3.728?0.486 3.131?0.002 2.477 2.826 3.057 3.101</cell></row><row><cell cols="2">(Bayesian Aggregation)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNP</cell><cell>0.551?0.000</cell><cell cols="8">0.429?0.000 -2.654?0.156 -2.952?0.112 3.583?0.013 2.733 3.18 3.474 3.53</cell></row><row><cell>NP</cell><cell>0.332?0.003</cell><cell cols="6">0.192?0.005 -2.489?0.065 -3.009?0.315 3.483?0.032 2.529 3.072</cell><cell>3.4</cell><cell>3.46</cell></row><row><cell cols="2">(Functional representation)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ConvCNP</cell><cell>2.509?0.000</cell><cell>2.139?0.000</cell><cell cols="2">1.758?0.089 -0.431?0.457</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>ConvNP</cell><cell>2.467?0.000</cell><cell>2.124?0.000</cell><cell cols="2">1.652?0.089 -1.180?0.439</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table><note>(Regularization for local representation) ANP (dropout) 1.492?0.003 1.134? 0.004 1.068?0.039 -6.215?1.577 3.2.429?0.031 -1.766?0.885 4.119?0.010 2.653 3.21 3.787 3.948</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparison of RMSE scores on u.test in MoveLens-100k<ref type="bibr" target="#b20">Rashed et al., 2019)</ref>. For fair comparison, we train and test the proposed method on the same setting, named as U1 splits. When evaluate baselines on the u1.test dataset, we randomly draw samples of corresponding users from the u1.base used in the meta-training and regard as context data points. Although we do not use graph structures, as seen inTable 3, The ANP points the comparable result of 0.909, meanwhile the proposed model attains a promising result, 0.895 of the RMSE value. This experiment indicates that the proposed method can reliably adapt to new tasks even if it provides small histories, and we identify again that our model can properly work on noisy situations.</figDesc><table><row><cell>RMSE</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table D</head><label>D</label><figDesc></figDesc><table><row><cell></cell><cell cols="5">.1: Architecture details and hyperparameters for the neural processes. Attention indicates</cell></row><row><cell cols="6">variants of attentive neural processes used. Encoder and decoder indicate the MLP network sizes</cell></row><row><cell>used.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Models</cell><cell>MLP Encoder</cell><cell>Attention Encoder MLP Decoder</cell><cell>Weight decay</cell><cell>MC samples</cell><cell>Rep. by functions Information dropout Stochastic attention</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table D</head><label>D</label><figDesc></figDesc><table><row><cell>Models</cell><cell cols="4">1D regression Sim2Real MovieLenz-100k Image Completion</cell></row><row><cell>CNP</cell><cell>99,842</cell><cell>100,228</cell><cell>110,850</cell><cell>1,583,110</cell></row><row><cell>NP</cell><cell>116,354</cell><cell>116,740</cell><cell>127,362</cell><cell>1,845,766</cell></row><row><cell>CNP_BA</cell><cell>116,354</cell><cell>116,740</cell><cell>127,362</cell><cell>1,845,766</cell></row><row><cell>NP_BA</cell><cell>116,354</cell><cell>116,740</cell><cell>127,362</cell><cell>1,845,766</cell></row><row><cell>ConvCNP</cell><cell>50,612</cell><cell>50,655</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>ConvNP</cell><cell>51,156</cell><cell>51,199</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>ANP</cell><cell>595,714</cell><cell>596,228</cell><cell>617,730</cell><cell>9,466,886</cell></row><row><cell>ANP (dropout)</cell><cell>628,610</cell><cell>629,124</cell><cell>650,626</cell><cell>9,991,686</cell></row><row><cell>Bootstrapping ANP</cell><cell>628,610</cell><cell>629,124</cell><cell>650,626</cell><cell>9,991,686</cell></row><row><cell>Ours</cell><cell>597,015</cell><cell>597,529</cell><cell>619,031</cell><cell>9,472,027</cell></row></table><note>.2: The number of network parameters required for all experimental cases.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table D .</head><label>D</label><figDesc></figDesc><table><row><cell>Models</cell><cell cols="3">1D regression Sim2Real MovieLenz-10k</cell><cell cols="4">Image Completion : CelebA</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>50</cell><cell>100</cell><cell>300</cell><cell>500</cell></row><row><cell>CNP</cell><cell>0.860</cell><cell>0.896</cell><cell>0.829</cell><cell>1.274</cell><cell>1.321</cell><cell>1.390</cell><cell>1.390</cell></row><row><cell>NP</cell><cell>1.411</cell><cell>1.422</cell><cell>1.356</cell><cell>1.975</cell><cell>1.990</cell><cell>1.959</cell><cell>2.081</cell></row><row><cell>CNP_BA</cell><cell>1.143</cell><cell>1.215</cell><cell>2.149</cell><cell>1.629</cell><cell>1.644</cell><cell>2.091</cell><cell>2.221</cell></row><row><cell>NP_BA</cell><cell>1.930</cell><cell>2.003</cell><cell>3.198</cell><cell>3.074</cell><cell>3.106</cell><cell>3.709</cell><cell>4.017</cell></row><row><cell>ConvCNP</cell><cell>2.788</cell><cell>4.128</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>ConvNP</cell><cell>2.907</cell><cell>4.289</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>ANP</cell><cell>2.442</cell><cell>2.500</cell><cell>2.222</cell><cell>5.294</cell><cell>5.710</cell><cell cols="2">9.010 11.740</cell></row><row><cell>ANP (dropout)</cell><cell>3.283</cell><cell>3.328</cell><cell>2.967</cell><cell>5.961</cell><cell>6.376</cell><cell cols="2">9.926 12.710</cell></row><row><cell>Bootstrapping ANP</cell><cell>6.474</cell><cell>6.968</cell><cell>6.250</cell><cell cols="4">26.186 30.012 60.619 88.332</cell></row><row><cell>Ours</cell><cell>3.152</cell><cell>5.848</cell><cell>3.121</cell><cell cols="4">11.350 19.217 57.898 95.031</cell></row><row><cell>Unit : second</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>3: Time required for inference in all experiment cases. (1 epoch).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table E .</head><label>E</label><figDesc>4: Results of likelihood values on the synthetic 1D regression without noises. Bold entries indicates the best results.</figDesc><table><row><cell></cell><cell cols="2">RBF kernel GP</cell><cell cols="2">Matern kernel GP</cell><cell cols="2">Periodic kernel GP</cell></row><row><cell></cell><cell>context</cell><cell>target</cell><cell>context</cell><cell>target</cell><cell>context</cell><cell>target</cell></row><row><cell>CNP</cell><cell cols="3">1.136?0.044 0.762?0.090 -0.465?0.106</cell><cell>-3.684?0.222</cell><cell cols="2">-2.354?0.218 -9.612?0.0287</cell></row><row><cell>NP</cell><cell cols="3">0.687?0.030 0.312?0.127 -1.222?0.055</cell><cell>-3.546?0.268</cell><cell cols="2">-2.252?0.115 -6.038?0.195</cell></row><row><cell>ANP</cell><cell cols="3">1.326?0.004 0.819?0.023 0.963?0.039</cell><cell>-1.538?0.083</cell><cell cols="2">-0.193?0.219 -7.447?0.278</cell></row><row><cell cols="2">(Weight decay; ? = 1.0e ? 3)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNP</cell><cell cols="3">1.167?0.025 0.827?0.051 -0.310?0.067</cell><cell>-3.135?0.178</cell><cell cols="2">-2.278?0.170 -8.840?0.259</cell></row><row><cell>NP</cell><cell cols="3">0.695?0.031 0.297?0.051 -1.297?0.201</cell><cell>-3.583?0.536</cell><cell cols="2">-2.577?0.223 -6.489?0.268</cell></row><row><cell>ANP</cell><cell cols="3">1.355?0.002 0.924?0.035 1.077?0.023</cell><cell>-1.753?0.089</cell><cell>0.379?0.080</cell><cell>-7.663?0.325</cell></row><row><cell cols="2">(Importance Weighted ELBO; k = 5)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNP</cell><cell cols="3">1.170?0.023 0.803?0.083 -0.443?0.130</cell><cell>-3.704?0.296</cell><cell cols="2">-2.422?0.151 -9.639?0.330</cell></row><row><cell>NP</cell><cell cols="3">0.728?0.028 0.255?0.156 -1.476?0.054</cell><cell>-4.208?0.175</cell><cell cols="2">-3.042?0.399 -7.463?0.624</cell></row><row><cell>ANP</cell><cell cols="3">1.344?0.004 0.889?0.037 0.854?0.050</cell><cell>-1.854?0.114</cell><cell cols="2">-0.483?0.198 -7.900?0.201</cell></row><row><cell cols="2">(Bayesian Aggregation)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNP</cell><cell cols="3">1.282?0.014 0.978?0.019 -0.141?0.140</cell><cell>-3.443?0.294</cell><cell cols="2">-2.016?0.168 -9.703?0.221</cell></row><row><cell>NP</cell><cell cols="6">0.379?0.023 0.069?0.051 -0.751?0.074 -1.811?0.0.066 -1.465?0.092 -3.308?0.177</cell></row><row><cell cols="2">(Functional representation)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ConvCNP</cell><cell cols="3">1.351?0.002 0.891?0.024 1.336?0.008</cell><cell>-1.941?0.066</cell><cell>1.020?0.062</cell><cell>-9.634?0.249</cell></row><row><cell>ConvNP</cell><cell cols="3">1.318?0.012 0.905?0.029 1.287?0.015</cell><cell>-1.806?0.169</cell><cell>0.953?0.057</cell><cell>-9.580?0.306</cell></row><row><cell cols="2">(Regularization for local representation)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ANP (dropout)</cell><cell cols="3">1.348?0.001 0.866?0.029 0.902?0.051</cell><cell>-1.753?0.084</cell><cell cols="2">-0.520?0.211 -8.052? 0.324</cell></row><row><cell cols="4">Bootstrapping ANP 1.347?0.005 0.895?0.026 0.790?0.044</cell><cell>-1.834?0.084</cell><cell cols="2">-0.983?0.309 -8.463? 0.343</cell></row><row><cell>Proposed Method</cell><cell cols="3">1.343?0.006 0.937?0.040 1.170?0.013</cell><cell>-1.708?0.043</cell><cell>0.681?0.052</cell><cell>-7.807?0.399</cell></row></table><note>E.1 EXPERIMENT RESULT ON RBF GP FUNCTIONS</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table F .</head><label>F</label><figDesc>5: Predator-prey model results. All models are trained on data with periodic noises.</figDesc><table><row><cell></cell><cell cols="2">Simulation</cell><cell cols="2">Real data</cell></row><row><cell></cell><cell>context</cell><cell cols="3">target context target</cell></row><row><cell>CNP</cell><cell>-0.181</cell><cell cols="3">-0.308 -2.420 -2.789</cell></row><row><cell>NP</cell><cell>-0.641</cell><cell cols="3">-0.739 -2.464 -2.710</cell></row><row><cell>ANP</cell><cell>0.645</cell><cell>0.290</cell><cell cols="2">-0.634 -1.962</cell></row><row><cell cols="2">(Importance weighted ELBO (s = 5))</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNP</cell><cell>-0.284</cell><cell cols="3">-0.390 -2.484 -2.864</cell></row><row><cell>NP</cell><cell>-0.527</cell><cell cols="3">-0.628 -2.335 -2.641</cell></row><row><cell>(Bayesian Aggregation)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CNP</cell><cell>-0.060</cell><cell cols="3">-0.171 -2.393 -2.776</cell></row><row><cell>NP</cell><cell>-0.357</cell><cell cols="3">-0.458 -2.260 -2.618</cell></row><row><cell>(Functional representation)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ConvCNP</cell><cell>2.395</cell><cell>1.679</cell><cell>1.879</cell><cell>-0.205</cell></row><row><cell>ConvNP</cell><cell>2.368</cell><cell>1.687</cell><cell>1.691</cell><cell>-0.521</cell></row><row><cell cols="2">(Regularization for local representation)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ANP (information dropout)</cell><cell>-0.749</cell><cell cols="3">-0.990 -1.766 -2.458</cell></row><row><cell>Bootstrapping ANP</cell><cell>0.326</cell><cell cols="3">-0.008 -1.183 -2.008</cell></row><row><cell>Ours</cell><cell>2.745</cell><cell>1.819</cell><cell>2.699</cell><cell>-0.076</cell></row><row><cell>(a) On the clean data</cell><cell></cell><cell></cell><cell cols="2">(b) On the noisy dataset.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table H</head><label>H</label><figDesc>.6: Prediction performance of ours varying the hyper-parameter K and regularization. All models employ the generative process of stocahstic attentions. The hyphen means a model converges.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">No Regularization</cell><cell></cell><cell></cell><cell></cell><cell cols="2">Regularization</cell><cell></cell></row><row><cell></cell><cell></cell><cell>RBF</cell><cell></cell><cell>Periodic</cell><cell></cell><cell></cell><cell>RBF</cell><cell></cell><cell>Periodic</cell></row><row><cell cols="2">Models Trainable</cell><cell>context</cell><cell>target</cell><cell>context</cell><cell>target</cell><cell>Trainable</cell><cell>context</cell><cell>target</cell><cell>context</cell><cell>target</cell></row><row><cell>K=1</cell><cell>-</cell><cell cols="4">1.383?0.000 0.421?0.008 1.382?0.000 -0.322?0.028</cell><cell>-</cell><cell cols="4">1.376?0.001 0.405?0.007 1.376?0.001 -0.347?0.030</cell></row><row><cell>K=10</cell><cell></cell><cell cols="4">0.543?0.007 0.199?0.009 0.301?0.015 -0.645?0.030</cell><cell>-</cell><cell cols="4">1.383?0.000 0.417?0.008 1.369?0.002 -0.402?0.025</cell></row><row><cell>K=20</cell><cell>-</cell><cell cols="4">1.380?0.001 0.431?0.008 1.380?0.000 -0.355?0.029</cell><cell>-</cell><cell cols="4">1.377?0.003 0.408?0.011 1.381?0.001 -0.366?0.017</cell></row><row><cell>K=30</cell><cell>-</cell><cell cols="4">1.381?0.001 0.356?0.011 1.380?0.000 -0.370?0.027</cell><cell>-</cell><cell cols="4">1.382?0.000 0.452?0.007 1.381?0.000 -0.423?0.026</cell></row><row><cell>K=40</cell><cell>-</cell><cell cols="4">1.380?0.001 0.395?0.009 1.381?0.000 -0.313?0.031</cell><cell>-</cell><cell cols="4">1.379?0.002 0.446?0.008 1.380?0.001 -0.399?0.021</cell></row><row><cell>K=50</cell><cell></cell><cell cols="4">0.730?0.012 0.267?0.022 0.520?0.012 -0.642?0.043</cell><cell>-</cell><cell cols="4">1.379?0.002 0.353?0.004 1.380?0.001 -0.501?0.028</cell></row><row><cell>K=60</cell><cell>-</cell><cell cols="4">1.378?0.003 0.433?0.007 1.381?0.001 -0.460?0.029</cell><cell>-</cell><cell cols="4">1.380?0.001 0.349?0.004 1.380?0.001 -0.338?0.025</cell></row><row><cell>K=70</cell><cell></cell><cell cols="4">0.642?0.005 0.235?0.010 0.401?0.017 -0.644?0.029</cell><cell>-</cell><cell cols="4">1.373?0.001 0.429?0.008 1.377?0.000 -0.370?0.024</cell></row><row><cell>K=80</cell><cell>-</cell><cell cols="4">1.379?0.002 0.423?0.011 1.381?0.001 -0.374?0.034</cell><cell>-</cell><cell cols="4">1.375?0.002 0.443?0.009 1.379?0.002 -0.353?0.030</cell></row><row><cell>K=100</cell><cell>-</cell><cell cols="4">1.375?0.002 0.373?0.007 1.378?0.001 -0.436?0.030</cell><cell>-</cell><cell cols="4">1.377?0.001 0.457?0.009 1.378?0.001 -0.391?0.034</cell></row><row><cell>K=300</cell><cell>-</cell><cell cols="4">1.380?0.002 0.393?0.006 1.382?0.000 -0.369?0.026</cell><cell>-</cell><cell cols="4">1.379?0.002 0.417?0.006 1.382?0.001 -0.346?0.024</cell></row><row><cell>K=500</cell><cell>-</cell><cell cols="4">1.383?0.000 0.359?0.008 1.383?0.000 -0.316?0.030</cell><cell>-</cell><cell cols="4">1.381?0.001 0.402?0.009 1.380?0.001 -0.352?0.032</cell></row><row><cell></cell><cell></cell><cell cols="3">(a) No regularization.</cell><cell></cell><cell></cell><cell cols="2">(b) Regularization</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Table H.7 contains the quantitative result. In the regularized model, the variance of attention scores for diagonal components is 0.003 and the mean value of attention scores is 0.469. Nonetheless, the mean of the model without the regularization is 0.367 and the variance is 0.026. This demonstrate that regularized models consistently</figDesc><table><row><cell></cell><cell cols="2">Diagonal</cell><cell cols="2">Off-Diagonal</cell></row><row><cell></cell><cell cols="4">Mean Variance Mean Variance</cell></row><row><cell cols="2">No Regularization 0.367</cell><cell>0.026</cell><cell>0.059</cell><cell>0.001</cell></row><row><cell>Regularization</cell><cell>0.469</cell><cell>0.003</cell><cell>0.070</cell><cell>0.002</cell></row><row><cell cols="5">Table H.7: Descriptive statistics of attention scores between diagonal and off-diagonal compoenents</cell></row><row><cell cols="3">in cases of regularization, I(Z, x i |D) and no-regularization</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>The intriguing fact is that the difference in attention scores for the diagonal component is rather significant within the same models. Since the values of target points are same as the context dataset, the attention scores should be constant. For instance, when K = 40 and no regularization is used, the attention scores are as {0.64, 0.64, 0.54, 0.47, 0.64, 0.54, 0.57, 0.62, 0.64, 0.64}. The attention scores for the same model with regularization are {0.51, 0.52, 0.44, 0.43, 0.45, 0.43, 0.45, 0.46, 0.5, 0.52}. The variance in absence of regularization is 0.003, whereas the variance in the presence of regulariza-</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table I .</head><label>I</label><figDesc>8: Results of likelihood values on the MovieLens-10k. Bold entries indicates the best results.</figDesc><table><row><cell></cell><cell cols="2">context Target</cell></row><row><cell>CNP</cell><cell cols="2">-24.718 -23.908</cell></row><row><cell>NP</cell><cell cols="2">-23.096 -22.135</cell></row><row><cell>ANP</cell><cell>-1.456</cell><cell>-2.042</cell></row><row><cell cols="2">(Weight decay; ? = 0.001)</cell><cell></cell></row><row><cell>CNP</cell><cell cols="2">-23.524 -23.098</cell></row><row><cell>NP</cell><cell cols="2">-15.876 -16.109</cell></row><row><cell>ANP</cell><cell>-0.891</cell><cell>-1.865</cell></row><row><cell cols="3">(Importance Weighted ELBO; s = 5)</cell></row><row><cell>CNP</cell><cell cols="2">-17.276 -17.799</cell></row><row><cell>NP</cell><cell cols="2">-25.322 -25.233</cell></row><row><cell>ANP</cell><cell cols="2">-17.205 -16.427</cell></row><row><cell cols="2">(Bayesian Aggregation)</cell><cell></cell></row><row><cell>CNP</cell><cell cols="2">-12.472 -12.141</cell></row><row><cell>NP</cell><cell cols="2">-11.911 -11.859</cell></row><row><cell cols="3">(Regularization for local representation)</cell></row><row><cell>ANP (dropout)</cell><cell>-1.742</cell><cell>-2.434</cell></row><row><cell cols="3">Bootstrapping ANP -16.267 -16.191</cell></row><row><cell>Ours</cell><cell>-0.349</cell><cell>-1.617</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/deepmind/neural-processes 2 https://github.com/kefirski/variational_dropout 3 https://github.com/JohanYe/IWAE-pytorch 4 https://github.com/zhougroup/BAM</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://github.com/SheffieldML/GPy 6 https://pytorch.org</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">https://tinyurl.com/yyfzlg2x</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REPRODUCIBILITY STATEMENT</head><p>Our code is available at https://github.com/MingyuKim87/NPwSA. For convenience reproducibility, both training and evaluation codes are included.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Information dropout: Learning optimal representations through noisy computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2897" to="2905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Variational attention for sequence-to-sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hareesh</forename><surname>Bahuleyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Vechtomova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Poupart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1672" to="1682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Computing the kullback-leibler divergence between two generalized gamma distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bauckhage</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1401.6853</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rianne</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">N</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02263</idno>
		<title level="m">Graph convolutional matrix completion</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Importance weighted autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Burda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Roger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR (Poster)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Latent alignment and variational attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Demi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2018/file/b691334ccf10d4ab144d672f7783c8a3-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Towards a neural statistician</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Bayesian attention modules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinjie</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyuan</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/bcff3f632fd16ff099a49c2f0932b47a-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="16362" to="16376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Meta-learning stationary stochastic process prediction with convolutional neural processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Foong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wessel</forename><surname>Bruinsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Requeima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Turner</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/5df0385cba256a135be596dbe28fa7aa-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8284" to="8295" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Meta-learning surrogate models for sequential decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Galashov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Saxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Sm Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.11907</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Saxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Eslami</surname></persName>
		</author>
		<title level="m">Conditional neural processes. In International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1704" to="1713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Danilo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.01622</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">Neural processes. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Convolutional conditional neural processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bruinsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Foong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Requeima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">E</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Glocal-k: Global and local kernels for recommender systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taejun</forename><surname>Soyeon Caren Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqu</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josiah</forename><surname>Burgstaller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Poon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.12184</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Oriol Vinyals, and Yee Whye Teh. Attentive neural processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Garnelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Rosenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Variational dropout and the local reparameterization trick</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Durk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2575" to="2583" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning hard alignments with variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieterich</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Cheng</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5799" to="5803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bootstrapping neural processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoonho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungtaek</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunho</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung</forename><forename type="middle">Ju</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Meta-learning requires meta-augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janarthanan</forename><surname>Rajendran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Irpan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Jang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Attribute-aware non-linear coembeddings of graph features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Rashed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josif</forename><surname>Grabocka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Schmidt-Thieme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th ACM Conference on Recommender Systems</title>
		<meeting>the 13th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="314" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Andrei A Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Posterior attention models for sequence to sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sequential neural processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautam</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesik</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngsung</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Ahn</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/110209d8fae7417509ba71ad97c17639-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A generalization of the gamma distribution. The Annals of mathematical statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Edney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stacy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1962" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1187" to="1192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bayesian context aggregation for neural processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Volpp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Fl?renbrock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Grossberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Stochastic modelling for systems biology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Darren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wilkinson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Chapman and Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Metafun: Metalearning with iterative functional updates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Francois</forename><surname>Ton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Kosiorek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10617" to="10627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Robustifying sequential neural processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaesik</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautam</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjin</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10861" to="10870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satwik</forename><surname>Kottur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siamak</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barnab?s</forename><surname>P?czos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Whai: Weibull hybrid autoencoding inference for deep topic modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyuan</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
