<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large-scale Robust Deep AUC Maximization: A New Surrogate Loss and Empirical Studies on Medical Image Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoning</forename><surname>Yuan</surname></persName>
							<email>zhuoning-yuan@uiowa.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Electrical Engineering&amp; Computer Science</orgName>
								<orgName type="institution">Washington State University</orgName>
								<address>
									<postCode>99163</postCode>
									<region>WA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Sonka</surname></persName>
							<email>milan-sonka@uiowa.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
							<email>tianbao-yang@uiowa.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">?Department of Computer Science</orgName>
								<orgName type="institution">The University of Iowa</orgName>
								<address>
									<postCode>52242</postCode>
									<region>IA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Large-scale Robust Deep AUC Maximization: A New Surrogate Loss and Empirical Studies on Medical Image Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep AUC Maximization (DAM) is a new paradigm for learning a deep neural network by maximizing the AUC score of the model on a dataset. Most previous works of AUC maximization focus on the perspective of optimization by designing efficient stochastic algorithms, and studies on generalization performance of large-scale DAM on difficult tasks are missing. In this work, we aim to make DAM more practical for interesting real-world applications (e.g., medical image classification). First, we propose a new margin-based min-max surrogate loss function for the AUC score (named as the AUC min-maxmargin loss or simply AUC margin loss for short). It is more robust than the commonly used AUC square loss, while enjoying the same advantage in terms of large-scale stochastic optimization. Second, we conduct extensive empirical studies of our DAM method on four difficult medical image classification tasks, namely (i) classification of chest x-ray images for identifying many threatening diseases, (ii) classification of images of skin lesions for identifying melanoma, (iii) classification of mammogram for breast cancer screening, and (iv) classification of microscopic images for identifying tumor tissue. Our studies demonstrate that the proposed DAM method improves the performance of optimizing crossentropy loss by a large margin, and also achieves better performance than optimizing the existing AUC square loss on these medical image classification tasks. Specifically, our DAM method has achieved the 1st place on Stanford CheXpert competition on Aug. 31, 2020. To the best of our knowledge, this is the first work that makes DAM succeed on large-scale medical image datasets. We also conduct extensive ablation studies to demonstrate the advantages of the new AUC margin loss over the AUC square loss on benchmark datasets. The proposed method is implemented in our open-sourced library LibAUC (www.libauc. org) whose github address is https://github.com/Optimization-AI/LibAUC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the last decade, we have seen great progress in deep learning (DL) techniques for medical image classification driven by large-scale medical datasets. For example, Stanford machine learning group led by Andrew Ng has collected and released a high-quality largescale Chest X-Ray dataset for detecting chest and lung diseases, which contains 224,316 high-quality X-rays images from 65,240 patients <ref type="bibr" target="#b20">[22]</ref>. Various deep learning methods have been designed and evaluated on this dataset by participating the CheXpert competition organized by Stanford ML group <ref type="bibr" target="#b20">[22]</ref>, and many of them have achieved radiologist-level performance on detecting certain related diseases. Esteva et al. <ref type="bibr" target="#b8">[10]</ref> have trained a CNN <ref type="figure">Figure 1</ref>: An illustrative example for optimizing different AUC losses on a toy data for learning a two-layer neural network with ELU activation. The top row is optimizing the AUC square loss and the bottom row is optimizing the new AUC margin loss. The first column depicts the initial decision boundary (dashed line) pre-trained on a set of examples. In the middle column, we add some easy examples to the training set and retrain the model by optimizing the AUC loss. In the last column, we add some noisily labeled data (blue circled data) to the training set and retrain the model by optimizing the AUC loss. The results demonstrate the new AUC margin loss is more robust than the AUC square loss.</p><p>using a dataset of 129,450 clinical images consisting of 2,032 different diseases, and achieved dermatologist-level performance for classification of skin lesions. Wu et al. <ref type="bibr" target="#b37">[39]</ref> have trained a deep neural network for breast cancer screening on a large-scale medical dataset, which includes 229,426 digital screening mammography exams (1,001,093 images) from 141,473 patients. Their model is as accurate as an experienced radiologist. Despite these great efforts, an important question remains: "Can we design a generic method that can further improve the performance of DL on these medical datasets without relying on domain knowledge"?</p><p>In this paper, we provide an affirmative answer to this question. Our solution is to optimize a novel loss for DL instead of optimizing the standard cross-entropy loss in the previous works. In particular, we choose to maximize the AUC score (a.k.a the area under the ROC curve) for DL. There are several benefits of maximizing AUC score over minimizing the cross-entropy loss. First, in medical classification tasks the AUC score is the default metric for evaluating and comparing different methods. Directly maximizing AUC score can potentially lead to the largest improvement in the model's performance. Second, the datasets in medical image classification tasks are usually imbalanced (e.g., the number of malignant cases is usually much less than benign cases). AUC is more suitable for handling imbalanced data distribution since maximizing AUC aims to rank the predication score of any positive data higher than any negative data. However, AUC maximization is much more challenging than minimizing mis-classifcation error since AUC is much more sensitive to model change. A simple example in Appendix F shows that by changing the prediction scores of a few examples, the mis-classification error rate keep unchanged but the AUC score drops significantly.</p><p>AUC maximization has been studied in the community of machine learning <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b39">41,</ref><ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b21">23,</ref><ref type="bibr" target="#b10">12]</ref>. However, existing methods for AUC maximization are still not satisfactory for practical use. The foremost challenge for AUC maximization is to determine a surrogate loss for the AUC score. A naive way is to use a pairwise surrogate loss based on the definition of the AUC score. However, optimizing a generic pairwise loss on training data suffers from a severe scalability issue, which makes it not practical for DL on large-scale datasets. Several studies have made attempts to address the scalability issue <ref type="bibr" target="#b21">[23,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b39">41,</ref><ref type="bibr" target="#b26">28]</ref>. One promising solution is to maximize the pairwise square loss for AUC by utilizing its special form <ref type="bibr" target="#b39">[41,</ref><ref type="bibr" target="#b26">28]</ref>. However, our study reveals that the AUC square loss has adverse effect when trained with easy data and is sensitive to the noisy data.</p><p>To address these issues, we propose a new margin-based surrogate loss in the minmax form for AUC (referred to as the AUC min-max-margin loss and the AUC margin loss for short), which is inspired by addressing the two issues of the AUC square loss. In particular, the AUC margin loss has two features that can alleviate the two issues, making it more robust to noisy data and not adversely affected by easy data. We will explain it with more details in the technical section and use a toy example in <ref type="figure">Figure 1</ref> to illustrate the robustness of AUC margin loss over AUC square loss. Moreover, the min-max form of the AUC margin loss make it enjoy the same benefit as the AUC square loss in terms of scalability, making it more attractive than conventional pairwise margin-based surrogate loss for AUC maximization. In particular, we are able to directly employ existing large-scale optimization algorithms <ref type="bibr" target="#b13">[15]</ref> designed for maximizing the AUC square loss to maximize our AUC margin loss with one line change of the code.</p><p>To demonstrate the effectiveness of our deep AUC maximization method, we conduct empirical studies on four difficult medical image classification tasks, namely classification of X-ray images for detecting chest diseases, classification of images of skin lesions, classification of mammograms for breast cancer screening and classification of microscopic images of tumor tissue. Our deep AUC maximization method has achieved great success on these difficult tasks. Specifically, we achieved the 1st place on Stanford CheXpert competition on Aug. 31, 2020, and Top 1% rank on Kaggle 2020 Melanoma classification competition. In CheXpert competition, our method is ranked 1 out of 150+ submissions, with a 2%+ improvement over Stanford baseline on a private testing data. In Kaggle competition, our ensembled model is ranked 33 out of 3314 teams. However, our best single model is better than the winning team's best model by more than 2%. Besides these medical tasks, we also conduct extensive ablation studies on benchmark datasets to compare the proposed AUC margin loss with the AUC square loss and traditional classification losses including cross-entropy and focal loss. Before ending this section, we summarize our contributions below:</p><p>? We proposed a new robust surrogate loss for AUC maximization, which is more robust than the AUC square loss but enjoys the same benefit of large-scale optimization.</p><p>? We conducted extensive empirical studies of the DAM method on a broad range of medical image classification data, and demonstrated its superb performance compared with standard DL methods.</p><p>To the best of our knowledge, this is the first comprehensive study of DAM on large-scale medical image classification datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Optimizing Pairwise Surrogate loss. Based on the definition of AUC, many studies consider to optimize a pairwise surrogate loss for AUC <ref type="bibr" target="#b9">[11,</ref><ref type="bibr" target="#b39">41,</ref><ref type="bibr" target="#b26">28]</ref>. Joachims et al <ref type="bibr" target="#b21">[23]</ref> proposed a SVM method for optimizing the AUC measure, which has a complexity of O(n 2 ) for a dataset with n examples. Many later studies tried to improve the efficiency of optimizing a pairwise surrogate loss of AUC. Herschtal et al. <ref type="bibr" target="#b18">[20]</ref> proposed an approximate objective for empirical pairwise loss of AUC by using partial pairs. In particular, for each negative data they only constructed a pairwise loss with only one positive data. However, the quality of such approximation highly depends on the properties of the dataset. When the examples have large intra-variance, their objective could yield poor performance. Zhao et al. <ref type="bibr" target="#b41">[43]</ref> proposed an online method for AUC maximization by maintaining a data buffer for storing some historical positive and negative data, and constructed an approximate AUC score by pairing a newly received data with all data in the buffer. However, analysis shows that such data buffer needs to be very large in order to make the algorithm has a small regret.</p><p>Optimizing Pairwise Square loss. Pairwise square loss is an exception, which has a unique property to enable one to design efficient stochastic algorithms for large-scale data <ref type="bibr" target="#b10">[12,</ref><ref type="bibr" target="#b39">41,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b28">30]</ref>. In particular, Ying et al. <ref type="bibr" target="#b39">[41]</ref> formulated the minimization of the pairwise square loss into an equivalent min-max optimization problem, which allows them to develop efficient stochastic algorithms without explicitly constructing and handling pairs of positive and negative data. Several papers tried to improve the convergence rate for solving the min-max optimization problems <ref type="bibr" target="#b25">[27,</ref><ref type="bibr" target="#b28">30]</ref>.</p><p>Deep AUC Maximization (DAM). Most of the studies mentioned above are for learning a linear model. Recently, there are some emerging studies on DAM. In <ref type="bibr" target="#b33">[35]</ref>, the authors considered DAM for learning a deep neural network based on an online buffered gradient method proposed by <ref type="bibr" target="#b41">[43]</ref>, and applied it to classification of breast cancer based on imbalanced mammogram images. Nevertheless, the issue of this approach is that it cannot scale to large datasets as it requires a large buffer to store positive and negative samples at each iteration for computing an approximate AUC score. Hence, they only consider datasets with few thousand medical images. Recently, <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b13">15]</ref> proposed efficient stochastic non-convex min-max optimization algorithms for DAM by solving the corresponding min-max objective of the AUC square loss. Their algorithms can scale up to hundreds of thousands of training examples. <ref type="bibr" target="#b12">[14,</ref><ref type="bibr" target="#b40">42]</ref> proposed federated learning algorithms for distributed DAM. However, all of these studies have neglected the deficiencies of the square loss for AUC maximization.</p><p>To the best of our knowledge, this is the first work that analyzes the deficiencies of AUC square loss and proposes a better solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>Notations. Let I(?) be an indicator function of a predicate, [s] + = max(s, 0). Let S = {(x 1 , y 1 ), . . . , (x n , y n )} denote a set of training data, where x i represents an input training example (e.g., an image), and y i ? {1, ?1} denotes its corresponding label (e.g., the indicator of a certain disease). For notational simplicity, we use z = (x, y). Let w ? R d denote the parameters of the deep neural network to be learned, and let h w (x) = h(w, x) denote the prediction of the neural network on an input data x. The standard approach of deep learning is to define a loss function on individual data by L(w; x, y) = (h w (x), y), where (?, y) is a surrogate loss function of the misclassification error (e.g., cross-entropy loss), and to minimize the empirical loss min w?R d 1 n n i=1 L(w; x i , y i ). However, this standard approach is easily misled by the imbalanced distribution of training images in medical datasets. In medical applications, a more favorable metric for comparing and evaluating different classifiers is AUC. It has been shown that the algorithms designed to minimize the misclassification error rate may not lead to maximization of AUC <ref type="bibr" target="#b5">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Background on Scalable AUC Maximization</head><p>Existing works of AUC maximization consider the following definition of AUC that is equivalent to the Wilcoxon-Mann-Whitney statistic <ref type="bibr" target="#b15">[17,</ref><ref type="bibr" target="#b3">5]</ref>:</p><formula xml:id="formula_0">AUC(w) = Pr(h w (x) ? h w (x )|y = 1, y = ?1) (1) = E I(h w (x) ? h w (x ) ? 0) y = 1, y = ?1 .</formula><p>It is interpreted that the AUC score is the probability of a positive sample ranking higher than a negative sample.</p><p>For optimization purpose, the indicator function in the above definition of AUC is usually replaced by a convex surrogate loss :</p><formula xml:id="formula_1">R ? R + which satisfies I(h w (x) ? h w (x ) &lt; 0) ? (h w (x) ? h w (x ))</formula><p>. As a result, many existing works formulate the AUC maximization on a training data S as</p><formula xml:id="formula_2">min w?R d 1 N + N ? x?S + x ?S ? (h w (x) ? h w (x )),<label>(2)</label></formula><p>where S + , S ? denote the set of positive and negative examples, and N + , N ? denote their size, respectively. Nonetheless, directly optimizing the above formulation is not scalable to large datasets as the complexity could be as worse as O(n 2 ) due to there are O(n 2 ) pairs, where n is the total number of examples.</p><p>To address the scalability issue, existing studies have proposed some promising solutions. One solution that attracts great attention is to optimize the square loss due to its algorithmic simplicity. With a square loss (h w (x)?h w (x )) = (1?h w (x)+h w (x )) 2 as the surrogate loss of AUC, it was shown that the objective is equivalent to the following min-max problem <ref type="bibr" target="#b39">[41]</ref>: min</p><formula xml:id="formula_3">w?R d (a,b)?R 2 max ??R f (w, a, b, ?) := E z [F (w, a, b, ?; z)] ,<label>(3)</label></formula><p>where z = (x, y) ? S is a random sample, and</p><formula xml:id="formula_4">F (w, a, b, ?; z) = (1 ? p) (h w (x) ? a) 2 I [y=1] (4) + p(h w (x) ? b) 2 I [y=?1] ? p(1 ? p)? 2 + 2? p(1 ? p) + ph w (x)I [y=?1] ? (1 ? p)h w (x)I [y=1]</formula><p>, and p = Pr(y = 1). Since the objective function in the above formulation is decomposable over individual examples, hence it enables one to develop efficient primal-dual stochastic algorithms for updating the model parameter w without explicitly constructing positivenegative pairs. Several studies have developed efficient stochastic algorithms for solving the above min-max formulation, which are able to scale to hundreds of thousands of examples <ref type="bibr" target="#b39">[41,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b26">28]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Drawbacks of the AUC Square Loss</head><p>Although the AUC square loss makes AUC maximization scalable, it has two issues that have been ignored by existing studies. In particular, it has adverse effect when trained with well-classified data (i.e., easy data), and is sensitive to noisily labeled data (i.e., noisy data). Below, we will elaborate these two issues by considering a linear model h w (x) = w x for illustration and understand these issues from the viewpoint of stochastic gradient update. We give a one-dimensional data in Appendix E.2 to support our arguments. When we use the min-max formulation (3) to explain these issues, we will make some simplification. In particular, we will use the optimal value of a, b, ? given w, i.e., a = a(w)</p><formula xml:id="formula_5">:= E[h w (x)|y = 1], b = b(w) := E[h w (x)|y = ?1], ? = 1 + b ? a,</formula><p>where a, b can be interpreted as the mean prediction score on positive data and negative data, respectively (please refer to Appendix A for a derivation). The same trick will be used to illustrate the benefit of the AUC Margin loss. Adverse Effect on Easy Data. To illustrate this, let us consider a scenario: the current model parameter is given by w and there comes a positive and negative data pair (x, y = 1), (x , y = ?1). Suppose these data are easy examples meaning that the prediction h w (x) is large and h w (x ) is small such that h w (x)?h w (x ) &gt; 1. By taking the stochastic gradient descent update of the square loss (h w (x) ? h w (x )) = (1 ? h w (x) + h w (x )) 2 , we have the updated model given by</p><formula xml:id="formula_6">w + = w ? ?2(1 ? h w (x) + h w (x ))(?x + x ), where ? &gt; 0 is a step size. Since 1 ? h w (x) + h w (x )</formula><p>&lt; 0, the model parameter w will move towards the negative direction of the positive data x and the positive direction of the negative data x . As a result, the new model w + tends to push the score h w + (x) on the positive data smaller and the score h w + (x ) on the negative data larger, which makes its classification capability worse. A similar effect happens when we use the min-max objective (3) to conduct the update. We include the analysis in Appendix D. Sensitivity to Noisy Data. Next, we elaborate the issue of sensitivity to noisily labeled examples. To this end, we consider a scenario: the current model parameter is given by w and there comes a positive and negative data pair (x, y = 1,? = ?1), (x , y = ?1,? = 1), where y, y denote the true labels of x, x that are not revealed, respectively, and? = ?1,? = 1 denote the noisy labels. Again, assume the prediction h w (x) is large and h w (x ) is small. The SGD update of the model parameter w based on the min-max objective is given by</p><formula xml:id="formula_7">w + = w ? 2?{(1 ? p)(h w (x ) ? a ? ?)x + p(h w (x) ? b + ?)x}.</formula><p>By plugging the optimal values of a, b, ? given w, i.e.,</p><formula xml:id="formula_8">? = 1 + b ? a and a = E[h w (x)|y = 1], b = E[h w (x )|y = ?1], we can see that the term in the update of w that involves x is ?2?p(h w (x)+1?E[h w (x)|y = 1])x, and that involves x is ?2?p(h w (x )?1?E[h w (x )|y = 1])x . Then it is clear to see that when h w (x) is large enough such that h w (x) + 1 ? E[h w (x)|y = 1]</formula><p>&gt; 0, the update of w will move to the negative direction of the truly positive data x, and similarly it will move to the positive direction of the truly negative data x when h w (x ) is small enough.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Proposed AUC Margin Loss</head><p>To alleviate the two issues of the AUC square loss, we propose a new margin-based surrogate loss. The new surrogate loss is a direct modification of the square loss to alleviate the two issues. To motivate the new AUC margin loss, we reformulate the AUC square loss as following (please refer to Appendix B for a derivation):</p><formula xml:id="formula_9">A S (w) = E[(1 ? h w (x) + h w (x )) 2 |y = 1, y = ?1] = E[(h w (x) ? a(w)) 2 |y = 1] A 1 (w) (5) + E[(h w (x ) ? b(w)) 2 |y = 1] A 2 (w) + (1 ? a(w) + b(w)) 2 A 3 (w) = A 1 (w) + A 2 (w) + max ? {2?(1 ? a(w) + b(w)) ? ? 2 }, where a(w) = E[h w (x)|y = 1], b(w) = E[h w (x )|y = 1]</formula><p>, and in the second equality we use the fact s 2 = max ? 2?s ? ? 2 . The three terms A 1 (w), A 2 (w), A 3 (w) have meaningful interpretations. In particular, minimizing A 1 (w), A 2 (w) aim to minimize the variance of prediction scores on positive data and negative data, respectively; minimizing the A 3 (w) aims to push the mean prediction scores of positive and negative examples to be far away. However, the square function in the last term makes it suffer from the two aforementioned issues. Our solution is to use a squared hinge function to replace A 3 (w), which is widely used in margin-based SVM classifiers. In particular, we replace</p><formula xml:id="formula_10">A 3 (w) by max ??0 {2?(m ? a(w) + b(w)) ? ? 2 } = (m ? a(w) + b(w)) 2 + ,</formula><p>where m is a hyper-parameter that specifies desired margin between a(w) and b(w). Hence, our new AUC margin loss is defined by</p><formula xml:id="formula_11">A M (w) = A 1 (w) + A 2 (w)<label>(6)</label></formula><formula xml:id="formula_12">+ max ??0 2?(m ? a(w) + b(w)) ? ? 2 .</formula><p>Without the non-negative constraint on ?, the loss becomes the square loss with a tunable margin parameter m.</p><p>Benefits of the AUC Margin Loss. We first show that the above objective is equivalent to a min-max objective.</p><p>Theorem 1 Minimizing the AUC margin loss (6) is equivalent to the following min-max optimization: min</p><formula xml:id="formula_13">w?R d (a,b)?R 2 max ??0 E z [F M (w, a, b, ?; z)] , where<label>(7)</label></formula><formula xml:id="formula_14">F M (w, a, b, ?; z) = (1 ? p) (h w (x) ? a) 2 I [y=1] (8) + p(h w (x) ? b) 2 I [y=?1] ? p(1 ? p)? 2 + 2? p(1 ? p)m + ph w (x)I [y=?1] ? (1 ? p)h w (x)I [y=1] . We highlight that min a,b max ??0 E z [F M (w, a, b, ?; z)] = p(1 ? p)A M (w). Please see proof in Appendix C.</formula><p>Robust to Easy Data. Based on the above min-max formulation, let us first elaborate the benefits of the new loss that alleviate the two issues of the AUC square loss. First, let us consider how the non-negative constraint ? ? 0 helps alleviate the adverse effect when trained with easy data. Following the same logic as before, we compute the gradient of</p><formula xml:id="formula_15">F M (w, a, b, ?) by ? w F M (w, a, b, ?; z) =2(1 ? p)xI [y=1] ? (h w (x) ? a ? ?) + 2pxI [y=?1] ? (h w (x) ? b + ?). Different from the square loss, the optimal ? given w is ? = m + b(w) ? a(w) if m + b(w) ? a(w) ? 0, and ? = 0 if m + b(w) ? a(w) &lt; 0, where a(w) = E[h w (x)|y = 1], b(w) = E[h w (x)|y = ?1].</formula><p>When the model is good enough, i.e., m + b(w) ? a(w) &lt; 0 meaning that the mean prediction scores of positive data is larger than the mean prediction scores of negative data by a margin m &gt; 0, then the gradient becomes</p><formula xml:id="formula_16">? w F M (w, a, b, ?; z) = 2(1 ? p)xI [y=1] ? (h w (x) ? a) + 2pxI [y=?1] ? (h w (x) ? b)</formula><p>. Taking a stochastic gradient decent update for w will only push the prediction score of the sampled data to be close to their mean score. When the model is poor</p><formula xml:id="formula_17">, i.e., m + b(w) ? a(w) &gt; 0, the gradient becomes ? w F M (w, a, b, ?; z) = 2(1 ? p)xI [y=1] ? (h w (x) ? m ? b(w)) + 2pxI [y=?1] ? (h w (x) + m ? a(w)).</formula><p>Since the model is poor in this case, it is likely that h w (x) ? m ? b(w) &lt; 0 for a positive data x, and h w (x) + m ? a(w) &gt; 0 for a negative data x. As a result, taking a stochastic gradient decent update for w + = w ? ?? w F M (w, a, b, ?; z) will likely move the model in the right direction pushing the prediction score of positive data larger, and that of negative data smaller. Robust to Noisy Data. Next, let us elaborate how adding a tunable margin parameter m can help alleviate the sensitivity to noisy data. Similar to the AUC square loss, the update in the noisy data case is given by</p><formula xml:id="formula_18">w + = w ? 2?{(1 ? p)(h w (x ) ? a ? ?)x + p(h w (x) ? b + ?)x}, where</formula><p>x is a true negative data but labeled as positive and x is a true positive data but labeled as negative. Let us consider the case that model is not good enough such that the optimal value of ? = m + b(w) ? a(w). Then the term in the update of w that involves the true positive data</p><formula xml:id="formula_19">x is ?2?p(h w (x) + m ? E[h w (x)|y = 1])x, and that involves the true negative data x is 2?p(m + E[h w (x )|y = 1] ? h w (x ))x .</formula><p>Note that even when h w (x) is large and h w (x ) is small such that the model w + is moving in the wrong direction, by tuning m to a smaller value, we can ensure that the movement into the wrong direction is much reduced. Hence, adding the tunable margin parameter m can alleviate the sensitivity to the noisy data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">DAM with the AUC Margin Loss</head><p>As seen from Theorem 1, the AUC margin loss is equivalent to a min-max optimization problem, that is similar to that of the AUC square loss. Hence, any stochastic algorithms Algorithm 1 PESG for optimizing the AUC margin loss Require: ?, ?, ?, T</p><formula xml:id="formula_20">1: Initialize v 1 , ? 1 ? 0 2: for t = 1, . . . , T do 3: Compute ? v F M (v t , ? t ; z t ) and ? ? F M (v t , ? t ; z t ). 4: Update primal variables v t+1 = v t ? ?(? v F M (v t , ? t ; z t ) + ?(v t ? v ref )) ? ??v t 5: Update ? t+1 = [? t + ?? ? F M (v t , ? t ; z t )] + .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Decrease ? by a factor and update v ref periodically 7: end for proposed for solving the min-max objective of the AUC square loss can be easily adapted to solving the min-max objective of the AUC margin loss. In particular, for any update on the dual variable ?, we follow by a projection step that projects ? into non-negative orthant. In this paper, we employ the proximal epoch stochastic method (named PESG) proposed in <ref type="bibr" target="#b13">[15]</ref> to update variables w, a, b, ?. To present the algorithm, we use a notation v = (w, a, b) to denote all primal variables. The key steps are presented in Algorithm 1. In the algorithm, ? denotes the standard regularization parameter (i.e, weight decay parameter), ? &gt; 0 is an algorithmic regularization parameter that can help improve the generalization, v ref is a reference solution that is updated periodically by using the accumulated average of v t in the previous stage (before decaying learning rate). We refer the readers to <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b13">15]</ref> for more discussion and convergence analysis of this algorithm.</p><p>A Two-stage Framework for DAM. From our preliminary studies on deep AUC maximization, we observe that directly optimizing the AUC margin loss can easily handle the recognition tasks on simple datasets, e.g., CIFAR. However, it shows some difficulties on complex tasks, e.g., CheXpert, Melanoma. We conjecture that the feature extraction layers learned by directly optimizing AUC from scratch are not as good as optimizing the standard cross-entropy loss on these difficult data. Inspired by recent works on two-stage methods, e.g., <ref type="bibr" target="#b22">[24]</ref>, we also employ a two-stage framework on difficult medical image classification tasks that includes a pre-training step that minimizes the standard cross-entropy loss, and an AUC maximization step that maximizes an AUC surrogate loss of the pre-trained CNN for learning all layers with the last classifier layer randomly initialized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Empirical Studies</head><p>In this section, we present extensive empirical studies on the proposed robust DAM method with the AUC margin loss. First, we present results on some benchmark datasets and then we present the results on four medical image classification tasks. The code for reproducing the results of our method in this paper can be found here [1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Performance on Benchmark datasets</head><p>For benchmark datasets, we construct imbalanced Cat&amp;Dog (C2), CIFAR-10 (C10), CIFAR-100 (C100), STL-10 (S10) <ref type="bibr" target="#b7">[9,</ref><ref type="bibr" target="#b23">25,</ref><ref type="bibr" target="#b4">6]</ref> following instructions by <ref type="bibr" target="#b26">[28]</ref>. Specifically, we first randomly split the training data by class ID into two even portions as the positive and negative classes, and then we randomly remove some samples from the positive class to make it imbalanced. We keep the testing set untouched. We refer to imbalance ratio (imratio) as the ratio of # of positive examples to # of all examples. Statistics of these datasets are presented in Appendix G.</p><p>We experiment with two network structures, i.e., DenseNet121 (D) ( <ref type="bibr" target="#b19">[21]</ref>) and ResNet20 (R) ( <ref type="bibr" target="#b16">[18]</ref>) with ELU activation functions. We explore the imbalance ratio = 1%, 10%, and use a 9:1 train/val split to conduct cross-valuation for tuning parameters. We compare DAM using our AUC margin loss (AUC-M) with three baselines, DAM using AUC square loss (AUC-S), and DL with two other popular loss functions i.e., cross-entropy loss (CE) and focal loss (Focal) trained by SGD. We use the?-balanced Focal loss ??(1?p t )? log(p t ), and tune its parameter?,? from [0.25, 0.5, 0.75] and [1,2,5] on the validation set, respectively. For DAM, we tune ? in [1/100, 1/300, 1/500, 1/700, 1/1000]. For AUC-M loss, we tune margin parameter m in [0.1, 0.3, 0.5, 0.7, 1.0]. For optimization, we run 100 epochs with a stagewise learning rate: initial value of 0.1 and decaying at 50% and 75% of the total number of training epochs for all experiments. We use a weight decay, i.e., ?, as 1e-4 for all methods. The batch size is set to 128 on all datasets except for S10, which is set to 32 due to smaller data size. For each method, we run the experiment with five different random training sets (by randomly removing some positive examples with different random seeds), and evaluate on the same testing set by comparing the averaged testing AUC scores. We also found that using a L2 normalization of the predication scores in a mini-batch is helpful. We refer to this normalization as Batch Score Normalization (BSN). Hence, in the following experiments we use the BSN before computing both the AUC-S and AUC-M losses. Please refer to section 5.1 for an ablation study on comparing with and without BSN.</p><p>The results for DenseNet121/ResNet20 with imratio=1% are reported in <ref type="table" target="#tab_0">Table 1</ref>. We include the results for imratio=10% to the Appendix H. Overall, we observe that the AUC-M and AUC-S perform much better than non-AUC-based losses in most cases. Comparing AUC-M with AUC-S, we can see that AUC-M performs better in most cases, especially in the extremely imbalanced setting with imratio=1%.</p><p>We also conduct some ablation studies on the benchmark datasets to demonstrate the robustness of the proposed AUC-M loss in comparison with AUC-S loss for DAM with added easy and noisy data, and the effectiveness of non-negative constraint on ?. The results are included in Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Medical Image Classification Tasks</head><p>Below, we present results on four difficult medical image classification tasks, namely classification of X-ray images for detecting chest diseases, classification of images of skin lesions for detecting melanoma, classification of mammograms for breast cancer screening, and classification of microscopic images for identifying tumor tissue. A summary of these tasks and their data is reported in <ref type="table" target="#tab_1">Table 2</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">CheXpert Competition</head><p>CheXpert competition is a medical AI competition organized by Stanford ML group <ref type="bibr" target="#b20">[22]</ref>, which released a large-scale Chest X-Ray dataset for detecting chest and lung diseases <ref type="bibr" target="#b20">[22]</ref>. The training data consists of 224,316 high-quality X-ray images from 65,240 patients. The validation dataset consists of 234 images from 200 patients. The testing data has images for 500 patients, which is not released to the public and is maintained by the organizer for final evaluation. The training images were annotated by a labeler to automatically detect the presence of 14 observations in radiology reports, capturing uncertainties inherent in radiography interpretation. The validation images were manually annotated by 3 boardcertified radiologists. The testing images were annotated by a consensus of 5 board-certified radiologists. The average resolution of CheXpert images is 2828x2320 pixels, which is about 6 times larger than ImageNet. The competition requires participants to submit the trained models for evaluation of the AUC score on predicting 5 selected diseases, i.e., Cardiomegaly, Edema, Consolidation, Atelectasis, Pleural Effusion. These tasks have an average imratio of 20.21%. They also reported another metric that compares the model's performance with 3 radiologists' predictions for reference.</p><p>Model Pre-training. To tackle the uncertain data in CheXpert, we adopt a label smoothing method similar to that in works <ref type="bibr" target="#b29">[31]</ref>. We choose five networks: DenseNet121, DenseNet161, DensNet169, DensNet201 and Inception-renset-v2 <ref type="bibr" target="#b19">[21,</ref><ref type="bibr" target="#b34">36]</ref>. With limited resources, we scale the resolution of all raw images to 320x320. For data augmentation, we use random rotation, random translation and random scaling. For pre-training step, we optimize CE loss by Adam on the 5 classification tasks with weight decay parameter of 1e-5. The total training time is 2 epochs with a batch size of 32 and initial learning rate of 1e-5. In the second step of AUC maximization, we replace the last classifier layer trained in the first step by random weights and use our DAM method to optimize the last classifier layer and all previous layers. We tune ? in {1/300, 1/500, 1/800}, set weight decay ? to 0, Competition Results. Our final submission is the ensemble of five models trained by DAM with the AUC-M loss for each disease. On Aug 31, 2020, we submitted our models to CheXpert and we achieved a mean testing AUC score of 0.9305, which is currently ranked at 1st place over all submissions. The leaderboard is shown in <ref type="bibr" target="#b11">[13]</ref>, where our submission is named as DeepAUC-v1 (ensemble). We also compare our results with other methods in <ref type="table" target="#tab_2">Table 3</ref>, where Hierarchical Learning <ref type="bibr" target="#b29">[31]</ref> utilizes domain knowledge to pre-define a disease hierarchy used for conditional training, YWW <ref type="bibr" target="#b38">[40]</ref> utilizes weakly-supervised lesion localization technique through a novel Probabilistic-CAM (PCAM) pooling operator to improve the model training. All these solutions are trained by CE loss. Our AUC-based solution surpasses these solutions and it is also better than 2.8 out of 3 radiologists (NRBC) for 5 selected diseases on average as in <ref type="table" target="#tab_2">Table 3</ref>. Finally, we noticed that a recent work that optimizes AUC square loss for DAM on CheXpert only achieves a mean testing AUC score of 0.922 <ref type="bibr" target="#b13">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Melanoma Classification</head><p>Melanoma is a skin cancer, which is the major cause for skin cancer death <ref type="bibr" target="#b27">[29]</ref>. We conduct empirical studies on the Kaggle Melanoma dataset <ref type="bibr" target="#b30">[32]</ref>, which is released through a Kaggle competition. The data is split into 33,126 training images with 584 malignant melanoma images (imbalance ratio=1.76%) and 10,892 testing images with an unknown number of melanoma images. Further, the testing set is split into public testing set and private testing set at 30%/70% ratio by patient ID. The public testing set (noting that their ground-truth labels are not revealed) is used to rank participating teams at the early stage. The private testing set is used to evaluate the participating teams for the final ranking. The public AUC score is updated daily but private AUC score is released after the end of competition.</p><p>Data preparations. The raw dataset has various sizes of images, e.g., 6000x4000, 1920x1080. We resize all images to lower resolutions due to limited computational resources. To evaluate the model locally, we follow <ref type="bibr" target="#b6">[8]</ref> to construct a 5-fold Stratified Leak-Free version cross-validation by 8:2 train/valid split. The data split follows two rules: 1) images from same patients are either put in train set or in validation set. 2) train and validation set have same imbalance ratio 1.76%. In addition, we also utilize two external data sources to complement the provided data in train set: 1) 12,859 images from previous competitions, e.g., ISIC2017 and ISIC2018, and 2) 580 malignant melanoma images parsed from the website of The International Skin Imaging Collaboration <ref type="bibr" target="#b0">[2]</ref>. We merge all data sources and finally obtain a training set of 46,131 images with an imbalance ratio of 7.1%. Comparison with Baselines. We first compare with three baselines as above, i.e., optimizing CE, Focal and AUC-S losses. We choose the family of EfficientNet <ref type="bibr" target="#b35">[37]</ref> as the main network. Data augmentation is very crucial in this competition, and we use a set of augmentations, e.g., horizontal flipping, rotating, scaling, shearing, coarse dropout following a public notebook <ref type="bibr" target="#b6">[8]</ref>. In addition, we use the cyclical learning rate with a base learning rate <ref type="bibr" target="#b32">[34]</ref> of 3e-5 and a maximum learning rate of 2.4e-4 and with 8 epochs for a full cycle. We use a weight decay of 1e-5. For focal loss <ref type="bibr" target="#b24">[26]</ref>, we tune?={1,2,5},?={0.25,0.5,0.75} and report the best result. For non-AUC losses, we train a total of 16 epochs with batch size of 256. For DAM, we start optimization from the pretrained backbone trained by optimizing the CE loss. For AUC losses, we set ? to 1/500 which is tuned by cross validation. For AUC Margin loss, we also tune m = {0.3, 0.5, 0.7, 1.0}. For experiments, we train 35 epochs in total with same batch size and initial learning rate of 0.01 decreasing by 2 times every 10 epochs using Algorithm 1. In addition, we find patient-level information (metadata) useful, e.g., age, sex, and location of imaged site. To utilize metadata, after training EfficientNet, we merge it with a 2-layer neural network (256x128) with a 0.5:0.5 weighted ratio, which is trained independently. The network structure is illustrated in <ref type="figure">Figure 9</ref> in Appendix K.</p><p>The comparison between different methods for learning EfficientNet-B5 on resized images with a fixed resolution of 384?384 is given in <ref type="table" target="#tab_3">Table 4</ref>. For each method, we report four numbers that represent performance on the public testing data (in early stage of competition) and private testing data (for final ranking) with/without test-time data augmentation (TTA) <ref type="bibr" target="#b31">[33]</ref>. We can see that DAM methods improve over the standard DL methods for minimizing CE and Focal losses. In addition, the AUC Margin loss is better than AUC Square loss. We also plot the histogram of predictions on training data of our best DAM method (AUC-M+Meta) compared with standard DL method with CE loss in <ref type="figure" target="#fig_1">Figure 2</ref>. We can see that the predictions by the DAM method have two well-separated patterns corresponding to positive and negative data. In contrast, the predictions by optimizing the CE loss is more mixed together.</p><p>Competition Results. For final submission towards this competition, we use an ensemble method. We train different nets including EfficientNet (B3, B5, B6) and different resolutions , i.e., 256 ? 256, 384 ? 384, 512 ? 512, 768 ? 768. Our final result is averaged over 10 models, which is also reported in <ref type="table" target="#tab_3">Table 4</ref>. Our method achieves AUC scores of The winning team has an AUC score of 0.9490 on the private testing set <ref type="bibr" target="#b14">[16]</ref>. We would like to emphasize that the winning team has used several useful tricks to improve the final result. In particular, they used an ensemble of 18 models and also used images at higher resolution of 896 * 896. We expect these tricks can be also used for improving our results. In terms of learning a single model, our DAM method has a higher AUC score of 0.9423 than their single model's AUC score of 0.9167 (e.g., model 7 under similar configurations, e.g., EfficientNetB5, 384x384, metadata <ref type="bibr" target="#b14">[16]</ref>). After the competition, we find the ensemble of EffecientNetB5(384 * 384, AUC-M loss, metadata) and EffecientNetB6(512 * 512, CE loss) achieves highest private AUC of 0.9505.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Other Two Medical Classification Tasks</head><p>Finally, we present results on two more medical classification tasks, i.e., classification of mammogram for breast cancer screening on DDSM+ data, and classification of microscopic images for identifying tumor tissue on PathCamelyon Data. The DDSM+ data is a combination of two datasets namely DDSM and CBIS-DDSM <ref type="bibr" target="#b2">[4,</ref><ref type="bibr" target="#b17">19]</ref>, which consists of 55,000 mammographic images (224?224) taken at lower doses than usual X-rays for training with imratio of 13% and 13,900 images for testing with imratio of 4%. The PathCamelyon dataset consists of 294,912 color images (96?96) extracted from histopathologic scans of lymph node section for training and 32,768 images for testing with balanced class ratio <ref type="bibr" target="#b36">[38,</ref><ref type="bibr" target="#b1">3]</ref>. For second task, we manually construct an imbalanced dataset with imratio of 1% following section 4.1. For experiments, we train DenseNet121 and use batch size of 32 for DDSM+ and 64 for PatchCamelyon. For non-AUC losses, we train models using Adam with weight decay of 1e-5 for 5 epochs. We tune learning rate {1e-1 ? 1e-5} on validation set sampled from 10% training data. For focal loss, we tune?={1,2,5},?={0.25,0.5,0.75}. For AUC losses, we start from pretrained model of last iteration by CE loss and train a total of 1 epoch. We tune learning rate {1e-1, 1e-2, 1e-3}, ?={1/300, 1/500, 1/800} and set ? = 0. For AUC-M, we tune m={0.3, 0.5, 0.7, 1.0}. We report the best results for each method in table 5. The results indicate that AUC-M performs consistently better than baseline methods on these two datasets. We run experiments with DenseNet121 on four benchmark datasets with two imbalance ratio, e.g., 1%, 10% with and without applying batch score normalization. The results are shown in <ref type="figure" target="#fig_2">Figure 3</ref>. We can see that applying the BSN can improve the performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">AUC-Margin Loss</head><p>Robustness to Noisy Data and Easy Data. We conduct ablation studies on the C2-IB data. To verify the robustness of our AUC-M loss to noisy data, we manually create some data with noisy labels. We construct the noisy dataset by modifying the C2 (imratio=1%).</p><p>To this end, we sample 1% and 5% from negative class to flip their labels to positive, and also randomly sample 1% and 5% positive data from the deleted positive examples and flip their labels and add them to the training data. This gives us two datasets with 1% and 5% noisy ratio. To verify the robustness of our AUC loss to easy data, we first pre-train a model by minimizing CE loss on C2 (imratio=1%) and then we make predictions on the removed positive samples and sort all prediction scores in descending order. Finally, we choose top 10%, 20% of sorted samples and add them to training data. We train DenseNet121 using batch size of 128 and initial learning rate of 0.1. Other parameter settings are the same as in Section 4.1. We run experiments 5 times and plot the average testing AUC curve in <ref type="figure" target="#fig_3">Figure 4</ref> for the setting with 1% noisy data and 10% easy data. In <ref type="figure" target="#fig_4">Figure 5</ref>, we report results on other settings. All results clearly show that AUC-M outperforms AUC-S by a large margin.</p><p>Effect of Alpha Constraint. To verify the effectiveness of non-negative constraint on ?, we design an experiment to compare the performance of AUC-M with and without ? ? 0 constraint. We start with C2-IB with imbalance ratio of 1% and add 40% easy (positive) samples and 1% noisy samples to the training set similar to that is done above. We fix margin m = 0.1. The curve of testing AUC and the curve of ? v.s. # of epochs are plotted in <ref type="figure" target="#fig_3">Figure 4 (bottom panel)</ref>. We observe that the performance with enforcing ? ? 0  is better than that without enforcing it. The bottom right plot in <ref type="figure" target="#fig_3">Figure 4</ref> gives us a better illustration about the change of ? during training. The plot inside it reveals the change of ? in the first 2 epochs. It shows that the constraint prevents the value of ? from dropping to a bad region and hence yields a faster convergence and better result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we have considered large-scale robust deep AUC maximization. We have proposed a new margin-based surrogate loss for AUC to address the two major issues of square loss, and demonstrated its robustness to noisy and easy data. We thoroughly evaluate our methods on four benchmark datasets and four real-world medical datasets. The results not only demonstrate the effectiveness of the new margin loss and also the success of our deep AUC maximization methods on medical image classification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Optimal Values of a, b, ? in AUC Square Loss</head><p>In Section 3.2, we use the optimal values of a, b, ?. In this section, we show how to derive these values. We first re-present the min-max problem in (3) as follows min</p><formula xml:id="formula_21">w?R d (a,b)?R 2 max ??R f (w, a, b, ?) := E z [F (w, a, b, ?; z)] , where F (w, a, b, ?; z) = (1 ? p) (h w (x) ? a) 2 I [y=1] + p(p(1 ? p) + h w (x) ? b) 2 I [y=?1] ? p(1 ? p)? 2 + 2? ph w (x)I [y=?1] ? (1 ? p)h w (x)I [y=1]</formula><p>. Given a fixed w,the variable a is only involved in the first term in F , so we have the a-subproblem as min</p><formula xml:id="formula_22">a E z [(1 ? p)(h w (x) ? a) 2 I [y=1] ] =(1 ? p)E z [(h w (x) ? a) 2 ] ? E z [I [y=1] ] =(1 ? p)E z [(h w (x) ? a) 2 |y = 1] ? p.</formula><p>As can be seen, E z [(h w (x) ? a) 2 |y = 1] achieves minimum value when a = E[h w (x)|y = 1], which becomes the variance of h w (x). The optimal value of b = E[h w (x)|y = ?1] can be achieved in the same way as a. The subproblem of ? is max</p><formula xml:id="formula_23">? E z [2?(p(1 ? p) + ph w (x)I [y=?1] ? (1 ? p)h w (x)I [y=1] )] ? p(1 ? p)? 2 =2?(p(1 ? p) + pE z [h w (x)I [y=?1] ] ? (1 ? p)E z [h w (x)]I [y=1] ) ? p(1 ? p)? 2 =2?(p(1 ? p) + p(1 ? p)E z [h w (x)|y = ?1] ? p(1 ? p)E z [h w (x)|y = ?1]) ? p(1 ? p)? 2 =p(1 ? p) ? (1 + 2?(E z [h w (x)|y = ?1] ? E z [h w (x)|y = ?1]) ? ? 2 )</formula><p>where we can derive its optimal value simply setting its gradient as zero. This leads to</p><formula xml:id="formula_24">? * =1 + E z [h w (x)|y = ?1] ? E z [h w (x)|y = ?1] =1 + b(w) ? a(w).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Reformulation of AUC Square Loss</head><p>In this section, we reformulate AUC square loss as follows Appendix C. Proof of Theorem 1</p><formula xml:id="formula_25">A S (w) =E[(1 ? h w (x) + h w (x )) 2 |y = 1, y = ?1] =E[(1 ? a(w) + a(w) ? h(w; x) + h(w; x ) ? b(w) + b(w)) 2 |y = 1, y = ?1] =E[ (a(w) ? h(w; x) + h(w; x ) ? b(w)) + (1 + b(w) ? a(w)) 2 |x = 1, y = ?1] =E[(a(w) ? h(w; x) + h(w; x ) ? b(w)) 2 + (1 + b(w) ? a(w)) 2 + 2 a(w) ? h(w; x) + h(w; x ) ? b(w) ? (1 + b(w) ? a(w))|y = 1, y = ?1] (e1) = E[(h(w; x) ? a(w)) 2 + (h(w; x ) ? b(w)) 2 ? 2(h(w; x) ? a(w)) ? (h(w; x ) ? b(w)) + (1 + b(w) ?</formula><p>Below, we start from the min-max problem and prove it is equivalent to the AUC margin loss in <ref type="bibr" target="#b4">(6)</ref>. min</p><formula xml:id="formula_26">a,b max ??0 E z [F M (w, a, b, ?; z)] = min a,b max ??0 E z (1 ? p) (h w (x) ? a) 2 I [y=1] + p(h w (x) ? b) 2 I [y=?1] ? p(1 ? p)? 2 + 2? p(1 ? p)m + ph w (x)I [y=?1] ? (1 ? p)h w (x)I [y=1] = min a,b max ??0 (1 ? p)E z [(h w (x) ? a) 2 I [y=1] ] + pE z [(h w (x) ? b) 2 I [y=?1] ] ? p(1 ? p)? 2 + 2? p(1 ? p)m + pE z [h w (x)I [y=?1] ] ? (1 ? p)E z [h w (x)I [y=1] ] = max ??0 p(1 ? p) E z [(h w (x) ? a(w)) 2 |y = 1] + E z [(h w (x) ? b(w)) 2 |y = ?1] ? ? 2 + 2? (m + b(w) ? a(w)) = p(1 ? p)A M (w) (9) = p(1 ? p) E z [(h w (x) ? a(w)) 2 |y = 1] + E z [(h w (x) ? b(w)) 2 |y = ?1] + (m + b(w) ? a(w)) 2 +</formula><p>where <ref type="bibr" target="#b7">(9)</ref> shows the equivalence between minimizing A M (w) in <ref type="bibr" target="#b4">(6)</ref> and min</p><formula xml:id="formula_27">w,a,b max ??0 E z [F M (w, a, b, ?; z)],</formula><p>i.e., min</p><formula xml:id="formula_28">w,a,b max ??0 E z [F M (w, a, b, ?; z)] = p(1 ? p)A M (w).</formula><p>The last equality is to explicitly show the squared hinge loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D. Analysis of Adverse Effect on Easy Data of Square loss based on the min-max formulation</head><p>In particular, the gradient of F (w, a, b, ?; z) is given by</p><formula xml:id="formula_29">? w F (w, a, b, ?; z) = 2(1?p)xI [y=1] ? (h w (x) ? a ? ?) + 2pxI [y=?1] ? (h w (x) ? b + ?).</formula><p>When z is positive, the first term above is active, by plugging the optimal value of a, b, ? given w, the stochastic gradient descent update will yields an updated model as</p><formula xml:id="formula_30">w + = w ? ?2(1 ? p)xI [y=1] ? (h w (x) ? 1 ? b),</formula><p>where b is the mean prediction score on negative data. When x is an easy positive data such that h w (x) ? 1 ? b &gt; 0, then w + will move towards the negative direction of the positive data x, as a result it will push the score h w + (x) on the positive data smaller than h w (x), which is harmful for AUC maximization. Similarly, we have the same phenomenon when the sampled data z is negative. </p><formula xml:id="formula_31">? w F (w, a, b, ?; z) =2(1 ? p)(h w (x) ? b) ? ? w h w (x)I [y=1] + 2p(h w (x) ? b) ? ? w h w (x)I [y=?1] + 2?(p? w h w (x)I [y=?1] ? (1 ? p)? w h w (x)I [y=1] ) =2(1 ? p)? w h w (x)I [y=1] ? (h w (x) ? a ? ?) =B +2p? w h w (x)I [y=?1] ? (h w (x) ? b + ?) =C ,</formula><p>where our study focuses on the two terms B and C, which determines the direction of ? w F for y = 1 and y = ?1, respectively. ? is the key difference between AUC square loss in (3) and AUC margin loss in <ref type="bibr" target="#b4">(6)</ref>. To simplify the explanation, we let a = a(w) and b = b(w) achieve their optimal values. In AUC square loss (3), ? is not constrained, and the optimal value is ? = 1 + b ? a. In AUC margin loss <ref type="bibr" target="#b4">(6)</ref>, it has a non-negative constraint on ?, so the optimal value is ? = max{0, 1 + b ? a}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Easy Data for AUC Square Loss</head><p>At the t-th iteration, let w t = 1 and we have two easy data (x 1 = 1, y 1 = 1) and (x 2 = ?1, y 2 = ?1). We assume that a = 0.5 and b = ?0.5.</p><p>For (x 1 , y 1 = 1)</p><formula xml:id="formula_32">B = h w (x 1 ) ? a ? ? = h w (x 1 ) ? 1 ? b = 1 ? 1 ? 1 ? (?0.5) = 0.</formula><p>5, which indicates that ? w F ? ? w h w (x 1 ) (they are in the same direction). By assuming all the constants and the step size can be merged into a constant value 0.1, the stochastic gradient descent can be</p><formula xml:id="formula_33">w t+1 = w t ? 0.1 ? ? w h wt (x 1 ) = 1 ? 0.1 ? x 1 = 1 ? 0.1 ? 1 = 0.9.</formula><p>Then we re-evaluate the prediction score by w t+1 : h w t+1 (x 1 ) = 0.9 ? 1 = 0.9 &lt; h wt (x 1 ) = 1. In this case, the prediction score for a positive sample decreases, which is an undesirable update.</p><p>For (x 2 , y 2 = ?1) C = h w (x 1 ) ? b + ? = h w (x 1 ) + 1 ? a = ?1 + 1 ? 0.5 = ?0.5, which indicates that ? w F ? ?? w h w (x 1 ) (they are in the negative direction of each other). By assuming all the constants and the step size can be merged into a constant value 0.1, the stochastic gradient descent can be w t+1 = w t ? 0.1 ? (?1) ? ? w h wt (x 1 ) = 1 + 0.1 ? x 2 = 1 + 0.1 ? (?1) = 0.9.</p><p>Then we re-evaluate the prediction score by w t+1 : h w t+1 (x 2 ) = 0.9 ? (?1) = ?0.9 &gt; h wt (x 2 ) = ?1. In this case, the prediction score for a negative sample increases, which is an undesirable update.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Easy Data for AUC Margin Loss</head><p>Since the optimal ? = max{0, m + b ? a}, we consider the two cases, respectively.</p><p>Case 1: ? = 0. This case indicates that m + b ? a ? 0 or m + b ? a, which is a good situation, because a (the mean prediction of positive data) and b (the mean prediction of negative data) are sufficiently far away from each other by a margin of m. Here for simplicity, we assume that at the t-th iteration, w = 1, m = 1, a = 1 and b = ?0.5.</p><p>For (x 1 = 0.75, y = 1):</p><formula xml:id="formula_34">B = h w (x 1 ) ? a ? ? = h w (x 1 ) ? a = 0.75 ? 1 = ?0.25 (negative direction)</formula><p>, where h w (x 1 ) &gt; m + b = 0.5 means that x 1 is well classified, but F M still suffers a penalty on it and push it to be closer to a = 1.</p><p>For (x 1 = 1.25, y = 1):</p><formula xml:id="formula_35">B = h w (x 1 ) ? a ? ? = h w (x 1 ) ? a = 1.25 ? 1 = 0.25 (negative direction), where h w (x 1 ) &gt; m + b = 0.5</formula><p>means that x 1 is well classified, but F M still suffers a penalty on it and push it to be closer to a = 1. To sum up, when the model is good enough, i.g., m + b &lt; a, F M only push positive data towards a and negative data towards b.</p><formula xml:id="formula_36">Case 2: ? = m + b ? a.</formula><p>This case indicates that m + b ? a &gt; 0 or m + b &gt; a, which is a undesirable situation, because a (the mean prediction of positive data) and b (the mean prediction of negative data) are within a margin of m. Here for simplicity, we assume that at the t-th iteration, w = 1, m = 1, a = 0, b = ?0.5.</p><p>For (x 1 = 0.25, y 1 = 1):</p><formula xml:id="formula_37">B = h w (x 1 ) ? a ? ? = h w (x 1 ) ? m ? b = 0.25 ? 1 + 0.5 = ?0.25</formula><p>(negative direction), where h w (x 1 ) &lt; m + b = 0.5 means that x 1 is not well classified. Thus, the stochastic gradient descent for updating w t can be w t+1 = w t ? 0.1 ? (?1) ? ? w h wt (x 1 ) = 1 + 0.1 ? x 1 = 1 + 0.1 ? 0.25 = 1.025, which makes the prediction of x 1 larger: h w t+1 (x 1 ) = 1.025 ? 0.25 = 0.2562 &gt; h wt (x 1 ) = 0.25.</p><p>Examples for negative data can be derived in a similar way, so we omit those presentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 Noisy Data for AUC Square Loss</head><p>Assuming w = 1, consider the case where m + b &gt; a, i.e., the model is not good, e.g., a = 0.25, b = ?0.5. For (x 1 = 0.25, y 1 = ?1, y true 1 = 1), since only y 1 is revealed, we will use term C to determine ? w F . On the other hand, since y true 1 = 1, we know that h w (x) can be large. Then we can compute its term C C = h w (x 1 ) ? b + ? = h w (x 1 ) + 1 ? a = 0.25 ? 1 + 1 ? 0.25 = 1 (positive direction), which means that ? w F is in the same direction of ? w h w (x 1 ). It is exactly the same case in Section E.1 when B &gt; 0, so it will give an undesirable update.</p><p>Negative sample (x 2 = ?1, y 1 = 1, y true 1 = ?1) can be developed in the same way, which also gives an undesirable update.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.4 Noisy Data for AUC Margin Loss</head><p>Assuming w = 1, consider the case where m + b &gt; a, i.e., the model is not good, and ? = m + b ? a. We assume a = 0.25, b = ?0.5. For (x 1 = 0.25, y 1 = ?1, y true 1 = 1): C = h w (x 1 ) ? b + ? = h w (x 1 ) ? b + (m + b ? a) = h w (x 1 ) + m ? a = 0.25 ? 1 + m ? 0.25 = m. m is positive by dentition. However, unlike the previous AUC square loss where m = 1, in AUC margin loss m is a hyper-parameter. Even though we cannot completely resolve the noisy data issue by using AUC margin loss, we can still reduce the magnitude of update along with the wrong direction by changing m to a smaller value from constant 1.</p><p>The same situation happens for noisy negative data on the not-so-good model. <ref type="table">Table 6</ref>: Illustrations of sensitivity of Accuracy and AUC on an imbalanced dataset of 25 samples with a positive ratio of 3/25. The accuracy threshold is 0.5. Example 1 shows that all positive instances rank higher than negative instances and two negative instances are misclassified to positive class. Example 2 shows that 1 positive instance ranks lower than 7 negative instances and 1 positive and 1 negative instances are missclassifed. Example 3 shows that 2 positive instances rank lower than 7 negative instances, and 2 positive instances are also missclassifed as negative class. Overall, we can observe that AUC drops dramatically as the ranks of positive instances drop but meanwhile Accuracy remains unchanged. Appendix G. Descriptions of Imbalanced Datasets <ref type="table">Table 7</ref>: Description of of Datasets. Note that "size of training set" refers to the number of samples for the original training set. Datasets with suffix "-IB" denote that we manually construct the imbalanced datasets by randomly removing some positive samples. Appendix H. More Experiments on Benchmark Datasets <ref type="figure">Figure 6</ref>: Testing AUC vs epochs on Benchmark Datasets for DenseNet121. <ref type="figure">Figure 7</ref>: Testing AUC vs epochs on Benchmark Datasets for ResNet20. <ref type="table">Table 8</ref>: Testing AUC of benchmark datasets with DenseNet121(D) and ResNet20(R) for imratio=10%. Note that when the imbalance ratio increases e.g., from 1% to 10%, data becomes less imbalanced and the classification becomes easier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix F. An Example of Sensitivity of AUC</head><p>Dataset imratio CE Focal AUC-S AUC-M C2 (D) 10% 0.893?0.004 0.879?0.005 0.901?0.002 0.902?0.001 C10 (D) 10% 0.898?0.005 0.879?0.005 0.889?0.002 0.887?0.005 S10 (D) 10% 0.820?0.015 0.819?0.010 0.825?0.013 0.846?0.015 C100 (D) 10% 0.710?0.007 0.705?0.007 0.720?0.003 0.723?0.006 C2 (R) 10% 0.920?0.004 0.881?0.008 0.897?0.007 0.920?0.006 C10 (R) 10% 0.898?0.004 0.851?0.018 0.872?0.007 0.898?0.005 S10 (R) 10% 0.825?0.013 0.813?0.009 0.819?0.013 0.821?0.011 C100(R) 10% 0.669?0.006 0.666?0.012 0.686?0.005 0.695?0.003</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>.018 0.713?0.009 0.803?0.018 0.809?0.016 C10 (D) 0.698?0.017 0.700?0.007 0.745?0.010 0.760?0.006 S10 (D) 0.641?0.032 0.660?0.027 0.669?0.070 0.703?0.030 C100 (D) 0.588?0.011 0.591?0.017 0.607?0.010 0.614?0.016 C2 (R) 0.730?0.028 0.724?0.020 0.748?0.007 0.756?0.017 C10 (R) 0.690?0.011 0.681?0.011 0.702?0.015 0.715?0.008 S10 (R) 0.641?0.021 0.634?0.024 0.645?0.029 0.659?0.020 C100 (R) 0.563?0.015 0.565?0.022 0.587?0.017 0.596?0.016</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Prediction histogram of positive (blue) and negative (red) samples for the models trained by AUC-M loss and CE loss on Melanoma training dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Ablation Study on Batch Score Normalization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>First two plots: comparison when adding noisy and easy samples. Last two plots: comparison between with/without ? ? 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Comparison when adding extra 20% easy samples and 5% noisy samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>a(w)) 2 |y = 1, y = ?1](e2) = E[(h(w; x) ? a(w)) 2 |y = 1] + E[(h(w; x ) ? b(w)) 2 |y = ?1] + (1 + b(w) ? a(w)) 2 (e3) = E[(h(w; x) ? a(w)) 2 |y = 1] + E[(h(w; x ) ? b(w)) 2 |y = ?1] + max ? 2?(1 + b(w) ? a(w)) ? ? 2 ,where equality (e1) is due to the definitions a(w) = E[h(w; x)|y = 1] and b(w) = E[h(w; x )|y = ?1], E[a(w)] = a(w) and E[b(w)] = b(w) (a(w) and b(w) are expectations, so they are constants).Equality (e2) is due to the independence of the positive and negative samples. Equality (e3) is due to the convex conjugate of the square function: x 2 = max y 2y ? x ? y 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Testing AUC on benchmark datasets with imratio=1%.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Summary of Medical Classification Tasks.</figDesc><table><row><cell>Dataset</cell><cell cols="3">Image Domain Imratio # Training</cell></row><row><cell>CheXpert</cell><cell>Chest X-ray</cell><cell>20.21%</cell><cell>224,316</cell></row><row><cell>Melanoma</cell><cell>Skin Lesion</cell><cell>7.1%</cell><cell>46,131</cell></row><row><cell>DDSM+</cell><cell>Mammogram</cell><cell>13%</cell><cell>55,000</cell></row><row><cell>PatchCamelyon</cell><cell>Microscopic</cell><cell>1%</cell><cell>148,960</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Averaged Testing AUC Scores on CheXpert. NBRC means the # of radiologists out of 3 are beaten by AI algorithms.</figDesc><table><row><cell>Model</cell><cell>AUC</cell><cell cols="2">NRBC Rank</cell></row><row><cell>Stanford Baseline [22]</cell><cell>0.9065</cell><cell>1.8</cell><cell>85</cell></row><row><cell>YWW [40]</cell><cell>0.9289</cell><cell>2.8</cell><cell>5</cell></row><row><cell cols="2">Hierarchical Learning [31] 0.9299</cell><cell>2.6</cell><cell>2</cell></row><row><cell>DAM (Ours)</cell><cell cols="2">0.9305 2.8</cell><cell>1</cell></row><row><cell cols="4">set the initial learning rate to 0.1 and decrease the learning rate at 2000, 8000 iterations by</cell></row><row><cell>3 times, run a total of 2 epochs for Algorithm 1.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Comparison of Testing AUC on Melanoma dataset for Optimizing EfficientNetB5. TTA (30) means that predictions are averaged over 30 augmented copies of each image in test set.</figDesc><table><row><cell></cell><cell cols="2">wo/ TTA</cell><cell cols="2">w/ TTA(30)</cell></row><row><cell>Loss</cell><cell cols="4">Public Private Public Private</cell></row><row><cell>CE</cell><cell>0.9391</cell><cell>0.9285</cell><cell>0.9447</cell><cell>0.9345</cell></row><row><cell>Focal</cell><cell>0.9412</cell><cell>0.9266</cell><cell>0.9424</cell><cell>0.9303</cell></row><row><cell>AUC-S</cell><cell>0.9482</cell><cell>0.9332</cell><cell>0.9502</cell><cell>0.9364</cell></row><row><cell>AUC-M</cell><cell cols="3">0.9497 0.9357 0.9503</cell><cell>0.9393</cell></row><row><cell>AUC-S (Meta)</cell><cell>0.9495</cell><cell>0.9358</cell><cell>0.9501</cell><cell>0.9409</cell></row><row><cell cols="4">AUC-M (Meta) 0.9522 0.9380 0.9520</cell><cell>0.9423</cell></row><row><cell>Our Submission</cell><cell>-</cell><cell>-</cell><cell>0.9685</cell><cell>0.9438</cell></row></table><note>0.9685/0.9438 on public/private sets, which rank at 42nd/33rd out of 3314 teams. To our best knowledge, this is also the first solution to optimize AUC in the competition.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Testing AUC of two medical datasets on DenseNet121.</figDesc><table><row><cell>Data (imratio)</cell><cell>CE</cell><cell cols="2">Focal AUC-S AUC-M</cell></row><row><cell>DDSM+ (13%)</cell><cell cols="2">0.9392 0.9495 0.9469</cell><cell>0.9544</cell></row><row><cell cols="3">PatchCamelyon (1%) 0.8394 0.8556 0.8703</cell><cell>0.8896</cell></row><row><cell>5. Ablation Studies</cell><cell></cell><cell></cell></row><row><cell cols="2">5.1 Batch Score Normalization (BSN)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Appendix E. A 1-Dim Example of Easy/Noisy Data for AUC Square andMargin Loss -dimensional model w, i.e., h w (x) = w ? x, so that ? w h w (x) = x. Recall the definition of F in (3), we have its gradient w.r.t. w as follows</figDesc><table><row><cell>Suppose we have a 1-dimensional AUC maximization problem with a linear model parame-</cell></row><row><cell>terized by a 1</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We are grateful to the anonymous reviewers for their constructive comments and suggestions. This work is partially supported by TY's NSF CAREER Award 1844403.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head><p>[1] Deep auc maximization code. https://github.com/Optimization-AI/ICCV2021_</p><p>DeepAUC.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix I. The Choice of Margin m for AUC-M Loss</head><p>Margin m is an important parameter for AUC-M loss. As illustrated in Section 3.3, when the model is not good enough, noisy data may produce a stochastic gradient that indicates a wrong direction. In this case, a smaller m can alleviate such sensitivity to noisy data. Tuning m parameter can trade off the margin benefit and the robustness to noisy data. That is the reason why tuning m is important in AUC-M. On benchmark datasets, the average values of m over different random trials are 0.7,0.8,0.7,0.5 on C2, C10, S10, C100, respectively. On Melanoma, the best m is 0.8. On CheXpert, the best m is 0.8 in average over 5 classes. On DDSM, the best m is 0.5. On PatchCamelyon, the best m is 0.7. For the results of ablation studies, we use m = 0.3 for AUC-M loss. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix J. A Two-stage Training Framework for DAM</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The international skin imaging collaboration (isic)</title>
		<ptr target="https://www.isic-archive.com" />
		<imprint>
			<biblScope unit="page" from="2020" to="2028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitko</forename><surname>Babak Ehteshami Bejnordi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">Johannes</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bram</forename><surname>Van Diest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nico</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geert</forename><surname>Karssemeijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Awm</forename><surname>Jeroen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meyke</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hermsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Quirine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maschenka</forename><surname>Manson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Balkenhol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jama</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="2199" to="2210" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The digital database for screening mammography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kopans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kegelmeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sallam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Woods</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third international workshop on digital mammography</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Ranking and empirical minimization of u-statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Clemencon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><surname>Lugosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Vayatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="844" to="874" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics</title>
		<meeting>the fourteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Auc optimization vs. error rate minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehryar</forename><surname>Mohri</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/2518-auc-optimization-vs-error-rate-minimization.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 16</title>
		<editor>S. Thrun, L. K. Saul, and B. Sch?lkopf</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="313" to="320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Triple stratified kfold with tfrecords</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Deotte</surname></persName>
		</author>
		<editor>Kaggle</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Asirra: a captcha that exploits interest-aligned manual image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Elson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>John R Douceur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Howell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Conference on Computer and Communications Security</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="366" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Dermatologist-level classification of skin cancer with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Esteva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brett</forename><surname>Kuprel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roberto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Novoa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Susan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><forename type="middle">M</forename><surname>Swetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Blau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thrun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">542</biblScope>
			<biblScope unit="issue">7639</biblScope>
			<biblScope unit="page" from="115" to="118" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the consistency of auc pairwise optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="939" to="945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">One-pass auc optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghuo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="906" to="914" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Chexpert: A large chest x-ray dataset and competition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Stanford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Group</surname></persName>
		</author>
		<ptr target="https://stanfordmlgroup.github.io/competitions/chexpert/" />
		<imprint>
			<date type="published" when="2019-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Communication-efficient distributed stochastic AUC maximization with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhishuai</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingrui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoning</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Fast objective and duality gap convergence for non-convex strongly-concave min-max problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhishuai</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoning</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.06889</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Identifying melanoma images using efficientnet ensemble: Winning solution to the siim-isic melanoma classification challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qishen</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuxu</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.05351</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The meaning and use of the area under a receiver operating characteristic (roc) curve</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><forename type="middle">J</forename><surname>Hanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcneil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="36" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Current status of the digital database for screening mammography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kopans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kegelmeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Munishkumaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Digital mammography</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1998" />
			<biblScope unit="page" from="457" to="460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Optimising area under the roc curve using gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Herschtal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhavani</forename><surname>Raskutti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-first international conference on Machine learning</title>
		<meeting>the twenty-first international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">49</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Irvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silviana</forename><surname>Ciurea-Ilcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Chute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Marklund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behzad</forename><surname>Haghgoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robyn</forename><surname>Ball</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katie</forename><surname>Shpanskaya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="590" to="597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A support vector method for multivariate performance measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on Machine learning</title>
		<meeting>the 22nd international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="377" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=r1gRTCVFvB" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fast stochastic auc maximization with o(1/n)-convergence rate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingrui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zaiyi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3189" to="3197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Stochastic auc maximization with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingrui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoning</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10831</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Arlo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martin C Mihm</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Melanoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">355</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="65" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Stochastic proximal algorithms for auc maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Natole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3710" to="3719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Interpreting chest x-rays via cnns that exploit hierarchical disease dependencies and uncertainty labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tung</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><forename type="middle">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dat</forename><forename type="middle">Q</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ha</forename><forename type="middle">Q</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=4awO8EwEKe" />
	</analytic>
	<monogr>
		<title level="m">Medical Imaging with Deep Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">A patient-centric dataset of images and metadata for identifying melanomas using clinical context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronica</forename><surname>Rotemberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Kurtansky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brigid</forename><surname>Betz-Stablein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Caffery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanouil</forename><surname>Chousakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Combalia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Dusza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascale</forename><surname>Guitera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gutman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.07360</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for largescale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cyclical learning rates for training neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="464" to="472" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Maximizing auc with deep learning for classification of imbalanced mammogram datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremias</forename><surname>Sulam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Ben-Ari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kisilev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VCBM</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="131" to="135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Alemi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.07261</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11946</idno>
		<title level="m">Rethinking model scaling for convolutional neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rotation equivariant cnns for digital pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bastiaan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Veeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Linmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taco</forename><surname>Winkens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="210" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deep neural networks improve radiologists&apos; performance in breast cancer screening</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Phang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungkyu</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqiu</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masha</forename><surname>Zorin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>Stanis Law Jastrzkebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>F?vry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Katsnelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1184" to="1194" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Weakly supervised lesion localization with probabilistic-cam pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenwu</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Stochastic online auc maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longyin</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siwei</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="451" to="459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Federated deep auc maximization for hetergeneous data with a constant communication complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoning</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhishuai</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Yang</surname></persName>
		</author>
		<idno>PMLR</idno>
		<ptr target="https://proceedings.mlr.press/v139/yuan21a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th International Conference on Machine Learning</title>
		<editor>Marina Meila and Tong Zhang</editor>
		<meeting>the 38th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2021-07" />
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="18" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Online auc maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peilin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
