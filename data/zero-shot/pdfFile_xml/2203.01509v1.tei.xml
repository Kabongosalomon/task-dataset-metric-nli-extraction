<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SoftGroup for 3D Instance Segmentation on Point Clouds</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Vu</surname></persName>
							<email>thangvubk@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kookhoi</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tung</forename><forename type="middle">M</forename><surname>Luu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><forename type="middle">Thanh</forename><surname>Nguyen</surname></persName>
							<email>thanhnguyen@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><forename type="middle">D</forename><surname>Yoo</surname></persName>
							<email>cdyoo@kaist.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution">Korea Advanced Institute of Science and Technology (KAIST)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SoftGroup for 3D Instance Segmentation on Point Clouds</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing state-of-the-art 3D instance segmentation methods perform semantic segmentation followed by grouping. The hard predictions are made when performing semantic segmentation such that each point is associated with a single class. However, the errors stemming from hard decision propagate into grouping that results in (1) low overlaps between the predicted instance with the ground truth and (2) substantial false positives. To address the aforementioned problems, this paper proposes a 3D instance segmentation method referred to as SoftGroup by performing bottom-up soft grouping followed by top-down refinement. SoftGroup allows each point to be associated with multiple classes to mitigate the problems stemming from semantic prediction errors and suppresses false positive instances by learning to categorize them as background. Experimental results on different datasets and multiple evaluation metrics demonstrate the efficacy of SoftGroup. Its performance surpasses the strongest prior method by a significant margin of +6.2% on the ScanNet v2 hidden test set and +6.8% on S3DIS Area 5 in terms of AP 50 . Soft-Group is also fast, running at 345ms per scan with a single Titan X on ScanNet v2 dataset. The source code and trained models for both datasets are available at https: //github.com/thangvubk/SoftGroup.git.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Scene understanding on 3D data has received increasing attention for the rapid development of 3D sensors and availability of large-scale 3D datasets. Instance segmentation on point clouds is a 3D perception task, serving as the foundation for a wide range of applications such as autonomous driving, virtual reality, and robot navigation. Instance segmentation processes the point clouds to output a category and an instance mask for each detected object.</p><p>State-of-the-art methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref> consider 3D instance segmentation as a bottom-up pipeline. They learn the point-wise semantic labels and center offset vectors and then group points of the same labels with small geomet-  <ref type="figure">Figure 1</ref>. Instance segmentation with and without SoftGroup from the same semantic prediction results. The last row shows the palette for semantic predictions only. Instance predictions are illustrated by different random colors for different objects. In the semantic prediction results, some regions of cabinet are wrongly predicted as other furniture. Without SoftGroup, these errors are propagated to instance prediction. SoftGroup addresses this problem and produces more accurate instance masks.</p><p>ric distances into instances. These grouping algorithms are performed on the hard semantic prediction, where a point is associated with a single class. In many cases, objects are locally ambiguous, the output semantic predictions show different categories for different parts, and thus using hard semantic predictions for instance grouping leads to two problems: <ref type="bibr" target="#b0">(1)</ref> low overlap between predicted instance and the ground-truth and (2) extra false-positive instances from wrong semantic regions. <ref type="figure">Figure 1</ref> shows a visualization example. Here, in the semantic prediction results, some parts of cabinet is wrongly predicted as other furniture. When hard semantic predictions are used to perform grouping, the semantic prediction error is propagated to instance prediction. As a result, the predicted cabinet instance has low overlap with the ground truth, and the other furniture instance is a false positive. This paper proposes SoftGroup to address these prob-lems by considering soft semantic scores to perform grouping instead of hard one-hot semantic predictions. The intuition of SoftGroup is illustrated in <ref type="figure">Figure 2</ref>. Our finding is that the object parts with wrong semantic predictions still have reasonable scores for the true semantic class. Soft-Group relies on a score threshold to determine which category the object belongs instead of the argument max values. Grouping on the soft semantic scores produces for accurate instance on true semantic class. The instance with wrong semantic prediction will be suppressed by learning to categorize it as background. To this end, we treat an instance proposal as either a positive or negative sample depending on the maximum Intersection over Union (IoU) with the ground truth, then construct a top-down refinement stage to refine the positive sample and suppress the negative one. As shown in <ref type="figure">Figure 1</ref>, SoftGroup is able to produce accurate instance masks from imperfect semantic prediction. SoftGroup is conceptually simple and easy to implement. Experiments on the ScanNet v2 <ref type="bibr" target="#b5">[6]</ref> and S3DIS <ref type="bibr" target="#b0">[1]</ref> benchmark datasets show the efficacy of our method. Notably, SoftGroup outperforms the previous state-of-the-art method by a significant margin of +6.2% on the ScanNet hidden test set and +6.8% on S3DIS Area 5 in terms of AP 50 . SoftGroup is fast, requiring 345ms to process a Scan-Net scene. In summary, our contribution is threefold.</p><p>? We propose SoftGroup that performs grouping on soft semantic scores to address the problem of the hard semantic predictions that propagates the errors to instance predictions.</p><p>? We propose a top-down refinement stage to correct, refine the positive samples and suppress false positives introduced by wrong semantic predictions.</p><p>? We report extensive experiments on multiple datasets with different evaluation metrics, showing significant improvements over existing state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Deep Learning on 3D Point Clouds. Point cloud representation is a common data format for 3D scene understanding since it is simple while preserving original geometric information. To process point clouds, early methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref> extract hand-crafted features based on statistical properties of points. Recent deep learning methods learn to extract features from points. Pointwise methods, such as PointNet <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>, directly process points through shared Multi-Layer Perceptron (MLP) and then aggregate regional and global features from symmetric function, such as max-pooling. Voxel-based methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b29">30]</ref> transform the unordered point sets into ordered sparse volumetric grids and then perform 3D sparse convolutions on the grids, showing the effectiveness in performance and speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Soft Grouping</head><p>Background Classification Classification Cabinet <ref type="figure">Figure 2</ref>. The cabinet in <ref type="figure">Figure 1</ref> is extracted to illustrate the high-level pipeline of our method. The soft grouping module based on soft semantic scores to output more accurate instance (the upper one). The classifier processes each instance and suppress the instance from wrong semantic prediction (the lower one).</p><p>Proposal-based Instance Segmentation. Proposalbased methods consider a top-down strategy that generates region proposals and then segments the object within each proposal. Existing proposal-based methods for 3D point clouds are highly influenced by the success of Mask-R CNN for 2D images. To handle data irregularity of point clouds, Li et al. <ref type="bibr" target="#b36">[37]</ref> propose GSPN, which takes an analysis-by-synthesis strategy to generate high-objectness 3D proposals, which are refined by a region-based PointNet.</p><p>Hou et al. <ref type="bibr" target="#b11">[12]</ref> present 3DSIS that combines multi-view RGB input with 3D geometry to predict bounding boxes and instance masks. Yang et al. <ref type="bibr" target="#b35">[36]</ref> propose 3D-BoNet which directly outputs a set of bounding boxes without anchor generation and non-maximum suppression, then segments the object by a pointwise binary classifier. Liu et al. <ref type="bibr" target="#b18">[19]</ref> present GICN to approximate the instance center of each object as a Gaussian distribution, which is sampled to get object candidates then produce corresponding bounding boxes and instance masks.</p><p>Grouping-based Instance Segmentation. Groupingbased methods rely on a bottom-up pipeline that produces per-point predictions (such as semantic maps, and geometric shifts, or latent features) then groups points into instances. Wang et al. <ref type="bibr" target="#b33">[34]</ref> propose SGPN to construct a feature similarity matrix for all points and then group points of similar features into instances. Pham et al. <ref type="bibr" target="#b24">[25]</ref> present JSIS3D that incorporates the semantic and instance labels by a multi-value conditional random field model and jointly optimizes the labels to obtain object instances. Lahoud et al. <ref type="bibr" target="#b15">[16]</ref> propose MTML to learn feature and directional embedding, then perform mean-shift clustering on the feature embedding to generate object segments which are scored according to their direction feature consistency. Han et al. <ref type="bibr" target="#b8">[9]</ref> introduce OccuSeg that performs graph-based  clustering guided by object occupancy signal for more accurate segmentation outputs. Zhang et al. <ref type="bibr" target="#b37">[38]</ref> consider a probabilistic approach that represents each point as a tri-variate normal distribution followed by a clustering step to obtain object instances. Jiang et al. <ref type="bibr" target="#b13">[14]</ref> propose Point-Group to segment objects on original and offset-shifted point sets, relying on a simple yet effective algorithm that groups nearby points of the same label and expands the group progressively. Chen et al. <ref type="bibr" target="#b3">[4]</ref> extend PointGroup and propose HAIS that further absorbs surrounding fragments of instances and then refines the instances based on intrainstance prediction. Liang et al. <ref type="bibr" target="#b16">[17]</ref> SSTNet to construct a tree network from pre-computed superpoints then traverse the tree and split nodes to get object instances.</p><p>The common proposal-based and grouping-based methods have their advantages and drawbacks. Proposal-based methods process each object proposal independently that is not interfered with by other instances. Grouping-based methods process the whole scene without proposal generation, enabling fast inference. However, proposal-based methods have difficulties in generating high-quality proposals since the point only exists on the object surface. Grouping-based methods highly depend on semantic segmentation such that the errors in semantic predictions are propagated to instance predictions. The proposed method leverages the advantages and address the limitations of both approaches. Our method is constructed as a two-stage pipeline, where the bottom-up stage generates high-quality object proposals by grouping on soft semantic scores, and then the top-down stage process each proposal to refine positive samples and suppress negative ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>The overall architecture of SoftGroup is depicted in <ref type="figure">Figure</ref> 3, which is divided into two stages. In the bottomup grouping stage, the point-wise prediction network (Sec.</p><p>3.1) takes point clouds the input and produces point-wise semantic labels and offset vectors. The soft grouping module (Sec. 3.2) processes these outputs to produce preliminary instance proposals. In the top-down refinement stage, based on the proposals, the corresponding features from the backbone are extracted and used to predict classes, instance masks, and mask scores as the final results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Point-wise Prediction Network</head><p>The input of the point-wise prediction network is a set of N points, each of which is represented by its coordinate and color. The point set is voxelized to convert unordered points to ordered volumetric grids, which are fed into a U-Net style backbone <ref type="bibr" target="#b30">[31]</ref> to obtain point features. The Submanifold Sparse Convolution <ref type="bibr" target="#b7">[8]</ref> is adopted to implement the U-Net for 3D point clouds. From the point features, two branches are constructed to output the point-wise semantic scores and offset vectors.</p><p>Semantic Branch. A semantic branch is constructed from a two-layer MLP and learns to output semantic scores S = {s 1 , ..., s N } ? R N ?Nclass for N points over N class classes. Different from existing methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14]</ref>, we directly perform grouping on semantic scores without converting the semantic scores to one-hot semantic predictions.</p><p>Offset Branch. In parallel with the semantic branch, we apply a two-layer MLP to learn the offset vectors O = {o 1 , ..., o N } ? R N ?3 , which represents the vector from each point to the geometric center of the instance the point belongs. Based on the learned offset vectors, we shift the points to the center of the corresponding instance to perform grouping more effectively.</p><p>The cross-entropy loss and 1 regression loss are used to train the semantic and offset branches, respectively.</p><formula xml:id="formula_0">L semantic = 1 N N i=1 CE(s i , s * i ),<label>(1)</label></formula><formula xml:id="formula_1">L offset = 1 N i=1 1 {p i } N i=1 1 {p i } o i ? o * i 1 ,<label>(2)</label></formula><p>where s * is the semantic label, o * is offset label representing the vector from a point to the geometric center of the instance that the point belongs to (analogous to <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b16">17]</ref>), and 1 {p i } is the indicator function indicating whether the point p i belongs to any instance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Soft Grouping</head><p>The soft grouping module receives the semantic scores and offset vectors as the input and produces instance proposals. First, the offset vectors are used to shift points toward the corresponding instance centers. To perform grouping using the semantic scores, we define a score threshold ? to determine which semantic classes a point belongs to, allowing the point to be associated with multiple classes. Given semantic scores S ? R N ?Nclass , we iterate through N class classes, and at each class index we slice a point subset of the whole scene that has the score (w.r.t. the class index) higher than the threshold ? . We follow <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14]</ref> to perform grouping on each point subset. Since all points in each subset belong to the same class, we simply traverse all the points in the subset and create the links between points having a geometric distance smaller than a grouping bandwidth b to get the instance proposals. For each iteration, the grouping is performed on a point subset of the whole scan, ensuring fast inference. The overall instance proposals are the union of the proposals from all subsets.</p><p>We note that existing proposal-based methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b35">36</ref>] commonly consider bounding boxes as object proposals then perform segmentation within each proposal. Intuitively, the bounding box with high overlap with the instance should have the center close to the object center. However, generating high-quality bounding box proposals in 3D point clouds is challenging since the point only exists on object surfaces. Instead, SoftGroup relies on point-level proposals which are more accurate and naturally inherit the scattered property of point clouds.</p><p>Since the quality of instance proposals from grouping highly depend on the quality of semantic segmentation, we quantitatively analyze the impact of ? on the recall and precision of semantic predictions. The recall and precision for class j is defined as follows.  <ref type="figure">Figure 4</ref>. The recall and precision of semantic prediction with varying score threshold ? . The dashed lines denote the recall and precision with hard semantic prediction. <ref type="figure">Figure 4</ref> shows the recall and precision (averaged over classes) with the varying score thresholds ? compared with those of hard semantic prediction. With hard semantic prediction, the recall is 79.1%, indicating more than 20% amount of points over classes are not covered by the predictions. When using the score threshold, the recall increases as the score threshold decreases. However, the small score threshold also leads to low precision. We propose a topdown refinement stage mitigate the low precision problems. The precision can be interpreted as the relation between foreground and background points of object instances. We set the threshold to 0.2 with precision near 50%, leading to the ratio between foreground and background points for ensuring stage is balanced.</p><formula xml:id="formula_2">recall j = N i=1 (s ij &gt; ? ) ? (s * i = j) s * i = j , precision j = N i=1 (s ij &gt; ? ) ? (s * i = j) s ij &gt; ? .<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Top-Down Refinement</head><p>The top-down refinement stage classifies and refines the instance proposals from the bottom-up grouping stage. A feature extractor layer processes each proposal to extract its corresponding backbone features. The extracted features are fed into a tiny U-Net network (a U-Net style network with a small number of layers) before predicting classification scores, instance masks, and mask scores at the ensuing branches.</p><p>Classification Branch. The classification branch starts with a global average pooling layer to aggregate the feature of all points in the instance, followed by a MLP to predict the classification scores C = {c 1 , ..., c K } ? R K?(Nclass+1) , where K is the number of instances. We directly derive the object category and classification confidence score from the output of the classification branch.</p><p>We note that existing grouping-based methods typically derive the object category from semantic predictions. However, instances may come from objects with noisy semantic predictions. The proposed method directly uses the output of the classification branch as the instance class. The classification branch aggregates all point features of the instance and classifies the instance with a single label, leading to more reliable predictions.</p><p>Segmentation Branch. As shown in Section 3.2, the instance proposals contain both foreground and background points, we construct a segmentation branch to predict an instance mask within each proposal. The segmentation branch is a point-wise MLP of two layers that output an instance mask m k for each instance k.</p><p>Mask Scoring Branch. The mask scoring branch shares the same structure as the classification branch. This branch outputs the mask scores E = {e 1 , ..., e K } ? R K?Nclass , which estimate the IoU of a predicted mask with the ground truth. The mask score is combined with the classification score by multiplication to get the final confidence score.</p><p>Learning Targets. Training the top-down refinement branches requires the target labels for each branch. To this end, we follow the logic in existing 2D object detection and segmentation methods. We treat all instance proposals having IoU with a ground-truth instance higher than 50% as the positive samples and the rest as negatives. Every positive sample is assigned to a ground-truth instance with the highest IoU. The classification target of a positive sample is the category of the corresponding ground-truth instance. The total number of classes is N class + 1 (N class foreground classes and one background class). The segmentation and mask scoring branches are trained on positive samples only. The mask target of a positive sample is the mask of the assigned ground-truth instance. The mask score target is the IoU between the predicted mask and the ground truth. The training loss of these branches is the combination of crossentropy, binary cross-entropy, and 2 regression losses, following <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13]</ref>.</p><formula xml:id="formula_3">L class = 1 K K k=1 CE(c k , c * k ),<label>(4)</label></formula><formula xml:id="formula_4">L mask = 1 K k=1 1 {m k } K k=1 1 {m k } BCE(m k , m * k ),<label>(5)</label></formula><formula xml:id="formula_5">L mask score = 1 K k=1 1 {r k } K k=1 1 {r k } r k ? r * k 2 . (6)</formula><p>Here, c * , m * , r * are the classification, segmentation, and mask scoring targets, respectively. K is the total number of proposals and 1 {.} indicates whether the proposal is a positive sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Multi-task Learning</head><p>The whole network can be trained in an end-to-end manner using a multi-task loss. L = L semantic + L offset + L class + L mask + L mask score , <ref type="bibr" target="#b6">(7)</ref> where L semantic and L offset are the semantic and offset losses defined at subsection Section 3.1 while L class , L mask and L mask score are the classification, segmentation and mask score losses defined at Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Settings</head><p>Datasets. The experiments are conducted on standard benchmarked ScanNet v2 <ref type="bibr" target="#b5">[6]</ref> and S3DIS <ref type="bibr" target="#b0">[1]</ref> dataset. The ScanNet dataset contains 1613 scans which is divided into training, validation, and testing sets of 1201, 312, 100 scans, respectively. Instance segmentation is evaluated on 18 object classes. Following existing methods, the benchmarked results are reported on the hidden test split. The ablation study is conducted on the validation set.</p><p>The S3DIS dataset contains 3D scans of 6 areas with 271 scenes in total. The dataset consists of 13 classes for instance segmentation evaluation. Following existing methods, two settings are used to evaluate the instance segmentation results: testing on Area 5 and 6-fold cross-validation.</p><p>Evaluation Metrics. The evaluation metric is the standard average precision. Here, AP 50 and AP 25 denote the scores with IoU thresholds of 50% and 25%, respectively. Likewise, AP denotes the averaged scores with IoU threshold from 50% to 95% with a step size of 5%. Additionally, the S3DIS is also evaluated using mean coverage (mCov), mean weighed coverage (mWCov), mean precision (mPrec), and mean recall (mRec). Implementation Details. The implementation details follow those of existing methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14]</ref>. The model is implemented using PyTorch deep learning framework <ref type="bibr" target="#b23">[24]</ref> and trained on 120k iterations with Adam optimizer <ref type="bibr" target="#b14">[15]</ref>. The batch size is set to 4. The learning rate is initialized to 0.001 and scheduled by a cosine annealing <ref type="bibr" target="#b19">[20]</ref>. The voxel size and grouping bandwidth b are set to 0.02m and 0.04m, respectively. The score threshold for soft grouping ? is set to 0.2. At training time, the scenes are randomly cropped at a maximum number of points of 250k. At inference, the whole scene is fed into the network without cropping. For the S3DIS with high point density, scenes are randomly downsampled at a ratio of 1/4 before cropping. At inference, the scene is divided into four parts before feeding into the model, and then the outputs from the four parts are merged to get the final results.</p><p>We note that the source code and trained models for existing high-performing methods are publicly available on ScanNet v2 only. In this work, the source code and trained models on both ScanNet v2 and S3DIS will be released to support result reproducibility.  <ref type="figure" target="#fig_3">Figure 5</ref>. Qualitative results on ScanNet v2 validation set. Instance prediction without SoftGroup output low-quality instance mask at the region of wrong semantic prediction (highlighted by dashed boxes). The prediction with SoftGroup shows more accurate instance masks at these regions. Zoom in for best view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Benchmarking Results</head><p>ScanNet v2. <ref type="table" target="#tab_1">Table 1</ref> shows the results of SoftGroup and recent state-of-the-art methods on the hidden test set of ScanNet v2 benchmark. We submit our model and report the results from the server. The proposed SoftGroup achieves the highest average AP 50 of 76.1%, surpassing the previous strongest methods a significant margin of 6.2%. Regarding class-wise scores, our method achieves the best performance in 12 out of 18 classes. Segmentation and Detection Results. We further report the instance segmentation and object detection results on ScanNet v2 validation set. To obtain object detection results, we follow the approach in <ref type="bibr" target="#b6">[7]</ref> to extract a tight axisaligned bounding box from the predicted point mask. <ref type="table">Table 3</ref> reports the instance segmentation and object detection results. Our method achieves significant improvement compared to the second-best by 3.2, 3.3, 6.3, and 7.3(%) of AP 50 , AP 25 , box AP 50 , and box AP 25 , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3DIS.</head><p>Runtime Analysis.    <ref type="table">Table 6</ref>. Ablation experiments on varying score threshold ? for soft grouping. "None" denotes the threshold is not used, and the hard semantic prediction is used for grouping instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Qualitative Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>Component-wise Analysis. We provide experimental results of SoftGroup when different components are omitted. The considered baseline is a model with hard grouping and the confidence scores of output instances are ranked by a ScoreNet branch <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b16">17]</ref>. <ref type="table" target="#tab_4">Table 5</ref> shows the ablation results. The baseline achieves 39.5/61.1/75.5(%) in terms of AP/AP 50 /AP 25 . Significant improvement is obtained by either applying soft grouping or top-down refinement. Combining these two components achieves the best overall performance AP/AP 50 /AP 25 of 46.0/67.6/78.9(%), which is significantly higher than the baseline by 6.5/6.5/3.4(%).</p><p>Score Threshold for Soft Grouping. <ref type="table">Table 6</ref> shows the experimental results with varying score thresholds for soft grouping. The baseline is with ? being "None", indicating the threshold is deactivated and the hard predicted label is used for grouping. The baseline achieves AP/AP 50 /AP 25 of 44.3/65.4/78.1(%). When ? is too high or too low the performance is even worse than the baseline. The best performance is obtained at ? of 0.2, which confirms our analysis at the Section 3.2, where the number of positive and negative samples are balanced.</p><p>Top-Down Refinement. We further provide the ablation results on the top-down refinement, on  <ref type="table">Table 8</ref>. Ablation study on instance category. "N" indicates that the instance category is taken from majority vote of semantic prediction. "Y" indicates that the instance category is taken from classification branch AP/AP 50 /AP 25 of 41.1/64.6/79.7(%). When mask branch and mask scoring branch are in turn applied, the performance tends to improve on the higher IoU threshold regions. Combining all branches yields the performance AP/AP 50 /AP 25 of 46.0/67.6/78.9(%).</p><p>Instance Category from Classification Branch. <ref type="table">Table 8</ref> reports the results of different schemes to obtain object categories. The results show that deriving the object category from semantic prediction yields the AP/AP 50 /AP 25 of 45.0/65.6/76.2(%). The proposed method directly uses the output of the classification branch as the instance class. The classification branch aggregates all point features of the instance and classifies the instance with a single label, leading to more reliable prediction. The results show that directly using classification output as object category improves the AP/AP 50 /AP 25 to 46.0/67.6/78.9(%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have presented SoftGroup, a simple yet effective method for instance segmentation on 3D point clouds. Soft-Group performs grouping on soft semantic scores to address the problem stemming from hard grouping on locally ambiguous objects. The instance proposals obtained from the grouping stage are assigned to either positive or negative samples. Then a top-down refinement stage is constructed to refine the positives and suppress the negatives. Extensive experiments on different datasets show that our method outperforms the existing state-of-the-art method by a significant margin of +6.2% on the hidden ScanNet v2 test set and +6.8% on S3DIS Area 5 in terms of AP 50 . SoftGroup is also fast, requiring 345ms to process a ScanNet scene.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>The architecture of the proposed method consists of bottom-up grouping and top-down refinement stages. From the input point clouds, the U-Net backbone extracts the point features. Then semantic and offset branches predict the semantic scores and offset vectors, followed by a soft grouping module to generate instance proposal. The feature extractor layer extracts backbone features from instance proposals. The features for each proposal are fed into a tiny U-Net followed by the classification, segmentation, and mask scoring branches to get the final instances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5</head><label>5</label><figDesc>shows the visualization examples from Scan-Net v2 dataset. Without SoftGroup, the semantic prediction errors are propagated to instance segmentation predictions (highlighted by dashed boxes). In contrast, SoftGroup effectively corrects the semantic prediction errors and thus generates more accurate instance masks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>20.8 39.0 16.9 6.5 27.5 2.9 6.9 0.0 8.<ref type="bibr" target="#b6">7</ref> 4.3 1.4 2.7 0.0 11.2 35.1 16.8 43.8 13.8 GSPN [37] 30.6 50.0 40.5 31.1 34.8 58.9 5.4 6.8 12.6 28.3 29.0 2.8 21.9 21.4 33.1 39.6 27.5 82.1 24.SoftGroup (Ours) 76.1 100.0 80.8 84.5 71.6 86.2 24.3 82.4 65.5 62.0 73.4 69.9 79.1 98.1 71.6 84.4 76.9 100.0 59.4 3D instance segmentation results on ScanNet v2 hidden test set in terms of AP50 scores. The proposed SoftGroup achieves the highest average AP50, outperforming the previous strongest method by a significant margin. Reported results are from the ScanNet benchmark on 13/11/2021.</figDesc><table><row><cell>Method</cell><cell>AP50</cell><cell>bathtub</cell><cell>bed</cell><cell>bookshe.</cell><cell>cabinet</cell><cell>chair</cell><cell>counter</cell><cell>curtain</cell><cell>desk</cell><cell>door</cell><cell>other</cell><cell>picture</cell><cell>fridge</cell><cell>s. curtain</cell><cell>sink</cell><cell>sofa</cell><cell>table</cell><cell>toilet</cell><cell>window</cell></row><row><cell>SGPN [34]</cell><cell cols="19">14.3 5</cell></row><row><cell>3D-SIS [12]</cell><cell cols="19">38.2 100.0 43.2 24.5 19.0 57.7 1.3 26.3 3.3 32.0 24.0 7.5 42.2 85.7 11.7 69.9 27.1 88.3 23.5</cell></row><row><cell>MASC [18]</cell><cell cols="19">44.7 52.8 55.5 38.1 38.2 63.3 0.2 50.9 26.0 36.1 43.2 32.7 45.1 57.1 36.7 63.9 38.6 98.0 27.6</cell></row><row><cell cols="20">PanopticFusion [23] 47.8 66.7 71.2 59.5 25.9 55.0 0.0 61.3 17.5 25.0 43.4 43.7 41.1 85.7 48.5 59.1 26.7 94.4 35.9</cell></row><row><cell>3D-Bonet [36]</cell><cell cols="19">48.8 100.0 67.2 59.0 30.1 48.4 9.8 62.0 30.6 34.1 25.9 12.5 43.4 79.6 40.2 49.9 51.3 90.9 43.9</cell></row><row><cell>MTML [16]</cell><cell cols="19">54.9 100.0 80.7 58.8 32.7 64.7 0.4 81.5 18.0 41.8 36.4 18.2 44.5 100.0 44.2 68.8 57.1 100.0 39.6</cell></row><row><cell>3D-MPA [7]</cell><cell cols="19">61.1 100.0 83.3 76.5 52.6 75.6 13.6 58.8 47.0 43.8 43.2 35.8 65.0 85.7 42.9 76.5 55.7 100.0 43.0</cell></row><row><cell>Dyco3D [11]</cell><cell cols="19">64.1 100.0 84.1 89.3 53.1 80.2 11.5 58.8 44.8 43.8 53.7 43.0 55.0 85.7 53.4 76.4 65.7 98.7 56.8</cell></row><row><cell>PE [39]</cell><cell cols="19">64.5 100.0 77.3 79.8 53.8 78.6 8.8 79.9 35.0 43.5 54.7 54.5 64.6 93.3 56.2 76.1 55.6 99.7 50.1</cell></row><row><cell>PointGroup [14]</cell><cell cols="19">63.6 100.0 76.5 62.4 50.5 79.7 11.6 69.6 38.4 44.1 55.9 47.6 59.6 100.0 66.6 75.6 55.6 99.7 51.3</cell></row><row><cell>GICN [19]</cell><cell cols="19">63.8 100.0 89.5 80.0 48.0 67.6 14.4 73.7 35.4 44.7 40.0 36.5 70.0 100.0 56.9 83.6 59.9 100.0 47.3</cell></row><row><cell>OccuSeg [9]</cell><cell cols="19">67.2 100.0 75.8 68.2 57.6 84.2 47.7 50.4 52.4 56.7 58.5 45.1 55.7 100.0 75.1 79.7 56.3 100.0 46.7</cell></row><row><cell>SSTNet [17]</cell><cell cols="19">69.8 100.0 69.7 88.8 55.6 80.3 38.7 62.6 41.7 55.6 58.5 70.2 60.0 100.0 82.4 72.0 69.2 100.0 50.9</cell></row><row><cell>HAIS [4]</cell><cell cols="19">69.9 100.0 84.9 82.0 67.5 80.8 27.9 75.7 46.5 51.7 59.6 55.9 60.0 100.0 65.4 76.7 67.6 99.4 56.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>AP 25 Box AP 50 Box AP 25</figDesc><table><row><cell>summaries the results on Area 5 and 6-</cell></row><row><cell>fold cross-validation of S3DIS dataset. On both Area 5</cell></row><row><cell>and cross-validation evaluations, the proposed SoftGroup</cell></row><row><cell>achieves higher overall performance compared to existing</cell></row><row><cell>method. Notably, on Area 5 evaluation, SoftGroup achieves</cell></row><row><cell>AP/AP 50 of 51.6/66.1(%), which is 8.9/6.8(%) improve-</cell></row><row><cell>ment compared to the second-best. The state-of-the-art per-</cell></row><row><cell>formance on both ScanNet v2 and S3DIS datasets shows the</cell></row><row><cell>generalization advantage of our method.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Table 4report the runtime per scan of different methods on ScanNet v2 validation set. For a fair comparison, the reported runtime is measured on the same Titan X GPU model. The inference time of our method is 345ms per scan, which is extra 6ms over the fastest model. Inference time per scan of different methods on ScanNet v2 validation set. For a fair comparison, the runtime is measured on the same Titan X GPU model.Regarding our component-time, the point-wise prediction network, soft grouping algorithm, and top-down refinement latencies are 152ms, 132ms, and 70ms, respectively. The results show that our method achieves high accuracy while remaining computationally efficient.</figDesc><table><row><cell>Method</cell><cell>Component time (ms)</cell><cell>Total (ms)</cell></row><row><cell></cell><cell>Backbone (GPU): 2080</cell><cell></cell></row><row><cell>SGPN [34]</cell><cell>Group merging (CPU): 149000</cell><cell>158439</cell></row><row><cell></cell><cell>Block merging (CPU): 7119</cell><cell></cell></row><row><cell></cell><cell>Backbone (GPU): 2083</cell><cell></cell></row><row><cell>ASIS [35]</cell><cell>Mean shift (CPU): 172711</cell><cell>181913</cell></row><row><cell></cell><cell>Block merging (CPU): 7119</cell><cell></cell></row><row><cell></cell><cell>Backbone (GPU): 1612</cell><cell></cell></row><row><cell>GSPN [37]</cell><cell>Point sampling (GPU): 9559</cell><cell>12702</cell></row><row><cell></cell><cell>Neighbour search (CPU): 1500</cell><cell></cell></row><row><cell></cell><cell>Backbone (GPU): 2083</cell><cell></cell></row><row><cell cols="2">3D-BoNet [36] SCN (GPU): 667</cell><cell>9202</cell></row><row><cell></cell><cell>Block merging (CPU): 7119</cell><cell></cell></row><row><cell></cell><cell>Backbone (GPU): 1497</cell><cell></cell></row><row><cell>GICN [19]</cell><cell>SCN (GPU): 667</cell><cell>8615</cell></row><row><cell></cell><cell>Block merging(CPU): 7119</cell><cell></cell></row><row><cell></cell><cell>Backbone GPU): 189</cell><cell></cell></row><row><cell>OccuSeg [9]</cell><cell>Supervoxel (CPU): 1202</cell><cell>1904</cell></row><row><cell></cell><cell>Clustering (GPU+CPU): 513</cell><cell></cell></row><row><cell></cell><cell>Backbone (GPU): 128</cell><cell></cell></row><row><cell cols="2">PointGroup [14] Clustering (GPU+CPU):221</cell><cell>452</cell></row><row><cell></cell><cell>ScoreNet (GPU): 103</cell><cell></cell></row><row><cell></cell><cell>Backbone (GPU) 125</cell><cell></cell></row><row><cell>SSTNet [17]</cell><cell>Tree network (GPU+CPU): 229</cell><cell>428</cell></row><row><cell></cell><cell>ScoreNet (GPU): 74</cell><cell></cell></row><row><cell></cell><cell>Pointwise prediction (GPU): 154</cell><cell></cell></row><row><cell>HAIS [4]</cell><cell>Hier. aggr. (GPU+CPU): 118</cell><cell>339</cell></row><row><cell></cell><cell>Intra-inst. prediction (GPU): 67</cell><cell></cell></row><row><cell>SoftGroup (Ours)</cell><cell>Pointwise prediction (GPU): 152 Soft grouping (GPU+CPU): 123 Top-down refinement (GPU): 70</cell><cell>345</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Baseline Soft grouping Top-down refinement AP AP50 AP25 39.5 61.1 75.5 41.6 63.8 79.2 44.3 65.4 78.1 46.0 67.6 78.9 Component-wise analysis on ScanNet v2 validation set. Our model achieves significant improvement over the baseline.</figDesc><table><row><cell>Overall improvement</cell><cell></cell><cell></cell><cell>+6.5 +6.5 +3.4</cell></row><row><cell>?</cell><cell>AP</cell><cell>AP 50</cell><cell>AP 25</cell></row><row><cell>None</cell><cell>44.3</cell><cell>65.4</cell><cell>78.1</cell></row><row><cell>0.01</cell><cell>40.1</cell><cell>58.5</cell><cell>69.2</cell></row><row><cell>0.1</cell><cell>45.3</cell><cell>66.5</cell><cell>78.5</cell></row><row><cell>0.2</cell><cell>46.0</cell><cell>67.6</cell><cell>78.9</cell></row><row><cell>0.3</cell><cell>45.2</cell><cell>66.8</cell><cell>78.5</cell></row><row><cell>0.4</cell><cell>44.7</cell><cell>46.1</cell><cell>78.3</cell></row><row><cell>0.5</cell><cell>43.9</cell><cell>64.8</cell><cell>77.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7 .Table 7 .</head><label>77</label><figDesc>With only the classification branch, our method achieves Class Mask Mask score AP AP 50 AP 25 41.1 64.6 79.7 45.7 68.4 79.5 46.0 67.6 78.9 The impact of each branch in top-down refinement on ScanNet v2 validation set.Category from class branch? AP AP 50 AP 25</figDesc><table><row><cell>N</cell><cell>45.0 65.6</cell><cell>76.2</cell></row><row><cell>Y</cell><cell>46.0 67.6</cell><cell>78.9</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Ioannis Brilakis, Martin Fischer, and Silvio Savarese. 3d semantic parsing of large-scale indoor spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Amir R Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The wave kernel signature: A quantum mechanical approach to shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Aubry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Schlickewei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV workshops</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scale-invariant heat kernel signatures for non-rigid shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hierarchical aggregation for 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiemin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">4d spatio-temporal convnets: Minkowski convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Scannet: Richly-annotated 3d reconstructions of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Alireza Fathi, Bastian Leibe, and Matthias Nie?ner. 3d-mpa: Multi-proposal aggregation for 3d semantic instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Bokeloh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">3d semantic segmentation with submanifold sparse convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Engelcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Occuseg: Occupancy-aware 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR, 2020</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Piotr Doll?r, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dyco3d: Robust instance segmentation of 3d point clouds through dynamic convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Tong He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">3d-sis: 3d semantic instance segmentation of rgb-d scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mask scoring r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaojin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongchao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Pointgroup: Dual-set point grouping for 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICVLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Marc Pollefeys, and Martin R Oswald. 3d instance segmentation via multi-task metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Lahoud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Instance segmentation in 3d scenes using semantic superpoint tree networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songcen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Masc: Multi-scale affinity with sparse convolution for 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasutaka</forename><surname>Furukawa</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.04478</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning gaussian instance segmentation in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Hung</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shang-Yi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shao-Chi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwann-Tzong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyng-Luh</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.09860</idno>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICVLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Voxnet: A 3d convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Partnet: A largescale benchmark for fine-grained and hierarchical part-level 3d object understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shilin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subarna</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Panopticfusion: Online volumetric semantic mapping at the level of stuff and things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaku</forename><surname>Narita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Seno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoya</forename><surname>Ishikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohsuke</forename><surname>Kaji</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.01177</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Jsis3d: joint semantic-instance segmentation of 3d point clouds with multi-task pointwise networks and multi-value conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quang-Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Binh-Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai-Kit</forename><surname>Roig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep hough voting for 3d object detection in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Litany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Frustum pointnets for 3d object detection from rgb-d data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Point-net++: Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Charles R Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guibas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02413</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Octnet: Learning deep 3d representations at high resolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gernot</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Osman Ulusoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unet: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fast point feature histograms (fpfh) for 3d registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nico</forename><surname>Radu Bogdan Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Blodow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICVRA</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Aligning point cloud views using persistent feature histograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nico</forename><surname>Radu Bogdan Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blodow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zoltan Csaba Marton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Beetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sgpn: Similarity group proposal network for 3d point cloud instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiangui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Associatively segmenting instances and semantics in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning object bounding boxes for 3d instance segmentation on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Markham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Trigoni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Gspn: Generative shape proposal network for 3d instance segmentation in point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minhyuk</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Point cloud instance segmentation using probabilistic embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Wonka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page" from="2021" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Point cloud instance segmentation using probabilistic embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Wonka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
