<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Unreasonable Effectiveness of the Baseline: Discussing SVMs in Legal Text Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Clavi?</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Jus Mundi</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Alphonsus</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Jus Mundi</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">The Unreasonable Effectiveness of the Baseline: Discussing SVMs in Legal Text Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>arXiv:2109.07234v2 [cs.CL] 22 Oct 2021 B. Clavi? and M. Alphonsus / Discussing SVMs in Legal Text Classification</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:54+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Natural Language Processing</term>
					<term>Text Classification</term>
					<term>Machine Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We aim to highlight an interesting trend to contribute to the ongoing debate around advances within legal Natural Language Processing. Recently, the focus for most legal text classification tasks has shifted towards large pre-trained deep learning models such as BERT. In this paper, we show that a more traditional approach based on Support Vector Machine classifiers reaches surprisingly competitive performance with BERT-based models on the classification tasks in the LexGLUE benchmark. We also highlight that error reduction obtained by using specialised BERT-based models over baselines is noticeably smaller in the legal domain when compared to general language tasks. We present and discuss three hypotheses as potential explanations for these results to support future discussions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recently, the state-of-the-art in many Natural Language Processing (NLP) tasks has been achieved by large pre-trained models such as BERT and its variants <ref type="bibr" target="#b0">[1]</ref>. Specialised BERT-based models have been developed for many fields, establishing the state-of-theart in domain specific tasks, as evidenced in the biomedical domain <ref type="bibr" target="#b1">[2]</ref>.</p><p>In legal NLP, recent work has focused on exploring the applications of BERT-based approaches on a variety of existing tasks and how to best adapt BERT to the legal domain <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. These efforts, while successful at establishing state-of-the-art on a variety of tasks, also reveal an interesting trend: the performance gain between a general language BERT and a specifically legal-language trained BERT appears to be smaller than in other specialised domains <ref type="bibr" target="#b3">[4]</ref>.</p><p>A common application of legal NLP is text classification. Text classification tasks target various kinds of legal insight, such as predicting the outcome of a ruling from a decision's body <ref type="bibr" target="#b4">[5]</ref>, whether a given clause is likely to be unfair to a customer <ref type="bibr" target="#b5">[6]</ref> or identifying the topic of a contract close <ref type="bibr" target="#b6">[7]</ref>. Recently, the LexGLUE benchmark has been released to allow for easier, more transparent benchmarking in legal NLP <ref type="bibr" target="#b7">[8]</ref>.</p><p>Little attention has been given to comparing these new BERT-based approaches to well-optimised baselines, such as Support Vector Machine (SVM)-based classifiers, which historically perform well on text classification tasks, opting instead for comparisons with other deep learning-based baselines.</p><p>In this short paper, we aim to (A) highlight the very strong performance of optimised baseline classifiers on multiple legal text classification tasks compared to deep learning classifiers, (B) show that the gains from BERT-based approaches is noticeably smaller on legal-domain tasks than on general tasks and (C) discuss three hypotheses to explain the previous two phenomena.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">General Domain</head><p>For all general domain tasks, we use results from BERT-ITPT-FiT <ref type="bibr" target="#b8">[9]</ref>, which optimises BERT for text classification, on four common benchmarks. For SVM results, we report the score of the best performing variant from a large scale comparison <ref type="bibr" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Legal Domain Experiments &amp; Baselines</head><p>For ease of comparison and reproducibility, we benchmark SVM classifiers on LexGLUE <ref type="bibr" target="#b7">[8]</ref>. LexGLUE, is a benchmark suite comprising of commonly studied legal NLP tasks. For the purpose of this paper, we evaluate our models on all six classification tasks and leave the QA task aside and focus on the six text classification tasks:</p><p>ECtHR A and B <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b10">11]</ref> are multi-label tasks which use facts part of European Court of Human Rights (ECtHR) rulings and the goal is to predict which article(s) were found by the court to have been violated (A) and which article(s) were considered by the court as allegedly violated (B).</p><p>SCOTUS <ref type="bibr" target="#b7">[8]</ref> is a multi-class task on opinions from the Supreme Court of the United States which need to be classified into one of 14 issue areas.</p><p>EUR-LEX <ref type="bibr" target="#b11">[12]</ref> is a multi-label task on EU law documents. The labels are comprised of 100 common EuroVoc legal concepts. The aim of this task is to identify all relevant EuroVoc label linked with a document.</p><p>LEDGAR <ref type="bibr" target="#b6">[7]</ref> is a multi-class task on contract provisions (paragraph) from the US Securities and Exchange Commission (SEC) where the goal is to detect the main topic of a given provision.</p><p>Unfair Terms of Service (ToS) <ref type="bibr" target="#b5">[6]</ref> is a multi-label task with clauses from the Terms of Services of 50 online plateforms. The aim of this task is to detect if a clause is likely to violate consumer rights and exactly which right is at risk of being violated.</p><p>Further information about the LexGLUE tasks is provided by Chalkidis et al. <ref type="bibr" target="#b7">[8]</ref>.</p><p>On each of the legal tasks, we train and evaluate SVM classifiers with modest optimisation. Results are reported as the average of ten runs. We also experiment with NBSVM, an SVM classifier using Na?ve Bayes features to represent words <ref type="bibr" target="#b12">[13]</ref>. We release the code used to train all models. <ref type="bibr" target="#b1">2</ref> .</p><p>For BERT-based models, we report the benchmark results from the LexGLUE paper <ref type="bibr" target="#b7">[8]</ref>.</p><p>Following their nomenclature, we refer to the legal Legal-BERT model from Chalkidis et al. <ref type="bibr" target="#b2">[3]</ref> as Legal-BERT and the Legal-BERT model from Zheng et al. <ref type="bibr" target="#b3">[4]</ref>, trained on US case law documents, as CaseLaw-BERT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Metrics and Evaluation</head><p>In line with the nature of this paper, all metrics reported follow the existing literature. For all General Domain tasks, the metric used is accuracy over the test set. As these tasks can be multi-class but not multi-label classification tasks, accuracy is identical to micro-averaged F1 score. <ref type="bibr" target="#b13">[14]</ref> For all legal tasks, we report both micro-averaged (?F1) and macro-averaged (mF1) F1 score for all tasks to allow for easier comparison with both other models evaluated on LexGLUE and results from general domain tasks.</p><p>In all cases, we report the error reduction between the best performing BERT-based model and SVMs as the percentage decrease in error rate between models to simplify evaluating the impact of using a different model over multiple tasks. The error rate is calculated as 100 ? Score. <ref type="table">Table 1</ref> gives an overview of the various classification results on General Domain tasks and presents the error reduction obtained by using the a fine-tuned BERT model over the best SVM classifier in the literature. <ref type="table">Table 2</ref> presents the classification results on the 6 LexGLUE classification tasks. We report the results for our best performing SVM as well as the results from BERT-Base, Legal-BERT and CaseLaw-BERT from the existing LexGLUE benchmark. We also compute the error reduction between the SVM classifier and the best performing BERT-based model for each task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Classification Results</head><p>The error reduction between SVM and BERT models in the general domain is high, at 85.1% on average over the four tasks, with the lowest reduction being 77.2%.</p><p>The difference is much less stark within the legal domain. BERT-based models do obtain the best results on all six takss, with Legal BERT models reaching the best performance on five out of the six tasks and a general domain BERT slightly outperforming them on ECtHR (A). However, in all cases, the performance increase is much less pronounced than in other domains, with an average micro-F1 error reduction across all six tasks of just 18.1%.</p><p>The average reduction in macro-F1 is overall similar, with an average reduction of 18.3%. However, is noticeable that this reduction in is considerably more pronounced on both ECtHR tasks. The ECtHR dataset is rather imbalanced, with all both tasks containing labels with very few examples and others covering a large proportion of the data <ref type="bibr" target="#b7">[8]</ref>. This seems to point towards the BERT models' ability t oget better performance with lower quantities of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Discussion</head><p>The results highlight an interesting phenomenon: while the average micro-F1 error reduction on general domain benchmarks is 85.1%, it is only 18.1% on legal text classification tasks. It is worth noting that the performance increases for BERT-based models is larger on the LexGLUE tasks with more pronounced label imbalance, with just a few labels representing the vast majority of a dataset and certain classes having very few examples. This is also noticeable with a much larger increase in macro-F1 score when compared to the increase in micro-F1 score on the same tasks. This highlights the increased robustness of the BERT-based models, whose use of pre-training and transfer learning techniques allow them to reach certain levels of performance performance with much fewer examples than traditional methods such as SVM. As training in the legal domain can be difficult to acquire and label, this is an important step towards democratising legal NLP.</p><p>Despite this and their impressive performance in both the general domain and other specialised domains, it is still apparent that in the legal domain, BERT-based models, even with specific domain pre-training, produce only a modest improvement on the 6 evaluated LexGLUE tasks.</p><p>There is no clear explanation for this phenomenon, but we discuss multiple hypotheses (a, b, c). The first (a), initially proposed by Zheng et al. <ref type="bibr" target="#b3">[4]</ref> to explain the mild improvements from Legal-BERT, is that the tasks on which we evaluate legal NLP algorithms are not suitable, either due to them being too simple or their language not being sufficiently domain-specific to take advantage of the models' pretraining. However, this does not provide a clear explanation for the overall weak improvement from deep learning over SVM classifiers.</p><p>A similar potential explanation (b) could be that simple mono-lingual text classification is not enough to truly take advantage of the possibilities offered by more powerful BERT-based models. This would indicate that the powerful language representation of Legal-BERT models could be key to tackling more complex tasks. Such tasks have now started being explored, such as legal rationale extraction <ref type="bibr" target="#b10">[11]</ref> or textual entailment in the form of a multiple choice QA task <ref type="bibr" target="#b3">[4]</ref>. This QA task, CaseHold, is the final task of the LexGLUE benchmark, and shows a noticeably better increase in performance of Legal BERT models over General Domain BERT models, which supports the interest of further studies towards validating this hypothesis.</p><p>However, this explanation does not fully address the weak performance gains on text classification. A final hypothesis (c) we propose is that large language models, even when trained on legal language, still lack the ability to capture the depth of legal language and its specific vocabulary. These models could also fail to properly weigh the meaning of multiple legal concepts being mentioned together. This hypothesis would suggest the need to develop a way to integrate sources of legal information, such as knowledge-bases or ontologies, within deep learning models to truly take advantage of their potential.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion and Future Work</head><p>We experimentally confirm the intuition that SVM classifiers perform remarkably well on multiple legal text classification benchmarks. We notably highlight that the relative performance improvement between BERT-based models and SVM models is considerably smaller within the legal domain than on general domain classification tasks, even with BERT models specifically trained for the legal domain.</p><p>We propose and discuss three potential explanations for these results. Future work will focus on exploring the limits of BERT models within the legal field, both by exploring more complex tasks and integrating existing knowledge bases with them.</p><p>We believe our results do not indicate the unsuitability of BERT-based approaches, but rather show that they have shortcomings and that they are perhaps better suited to more complex tasks. We also show that in the case of imbalanced datasets with very few examples for some of their classes, BERT-based models result in bigger increases in macro F1-score than in micro-F1 score, showcasing their ability to reach better results in low-data downstream tasks.</p><p>Future work will focus on exploring and pushing the limits of BERT models (and variants) within the legal domain, both by exploring more complex tasks and attempting to integrate external knowledge bases within them to improve performance on tasks such as text classification.</p><p>We hope our work will help support future work on Legal NLP focusing on exploring the specificities of legal text and better taking them into account. We make our experiments' code available to support future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Results for the best performing model of each kind on a variety of General Domain (GD). Error reduction is calculated between the Best SVM and the best BERT variant. Results for the various models on the 6 LexGLUE classification tasks. ?F1 refers to micro-averaged F1-score and mF1 to macro-averaged F1 score.Error reduction is calculated between the Best SVM and the best BERT variant.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Model</cell><cell></cell><cell>AGNews</cell><cell cols="2">IMDB</cell><cell>Yelp!</cell><cell cols="2">DBPedia</cell><cell>Average</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Best SVM</cell><cell></cell><cell>75.3</cell><cell></cell><cell>80.7</cell><cell>84.0</cell><cell>87.1</cell><cell></cell><cell>81.78</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>BERT</cell><cell></cell><cell>95.2</cell><cell></cell><cell>95.6</cell><cell>98.1</cell><cell>99.3</cell><cell></cell><cell>97.0</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Error Reduction</cell><cell>80.6%</cell><cell cols="2">77.2%</cell><cell>88.1%</cell><cell>94.6%</cell><cell></cell><cell>85.1%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell></cell><cell cols="2">ECtHR</cell><cell></cell><cell cols="2">SCOTUS</cell><cell cols="2">EUR-LEX</cell><cell cols="2">LEDGAR</cell><cell cols="2">Unfair</cell><cell cols="2">Average</cell></row><row><cell></cell><cell>A</cell><cell></cell><cell>B</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Tos</cell><cell></cell><cell></cell></row><row><cell></cell><cell>?F1</cell><cell>mF1</cell><cell>?F1</cell><cell>mF1</cell><cell>?F1</cell><cell>mF1</cell><cell>?F1</cell><cell>mF1</cell><cell>?F1</cell><cell>mF1</cell><cell>?F1</cell><cell>mF1</cell><cell>?F1</cell><cell>mF1</cell></row><row><cell>SVM</cell><cell>66.3</cell><cell>55.0</cell><cell>76.0</cell><cell>65.4</cell><cell>74.4</cell><cell>64.5</cell><cell>65.7</cell><cell>49.0</cell><cell>88</cell><cell>82.6</cell><cell>95.1</cell><cell>75.9</cell><cell>77.6</cell><cell>65.4</cell></row><row><cell>BERT</cell><cell>71.4</cell><cell>64</cell><cell>79.6</cell><cell>78.3</cell><cell>70.5</cell><cell>60.9</cell><cell>71.6</cell><cell>55.6</cell><cell>87.7</cell><cell>82.2</cell><cell>97.3</cell><cell>80.4</cell><cell>79.7</cell><cell>70.2</cell></row><row><cell>Legal BERT</cell><cell>71.2</cell><cell>64.9</cell><cell>80.6</cell><cell>77.2</cell><cell>76.2</cell><cell>65.8</cell><cell>72.2</cell><cell>56.2</cell><cell>88.1</cell><cell>82.7</cell><cell>97.4</cell><cell>83.4</cell><cell>81.0</cell><cell>71.7</cell></row><row><cell>CaseLaw BERT</cell><cell>71.2</cell><cell>64.2</cell><cell>79.7</cell><cell>76.8</cell><cell>76.4</cell><cell>66.2</cell><cell>71</cell><cell>55.9</cell><cell>88</cell><cell>82.3</cell><cell>97.4</cell><cell>82.4</cell><cell>80.6</cell><cell>71.3</cell></row><row><cell>Error Red. %</cell><cell>15.1</cell><cell>22</cell><cell>19.2</cell><cell>37.3</cell><cell>7.8</cell><cell>4.8</cell><cell>19.0</cell><cell>14.1</cell><cell>0.8</cell><cell>0.6</cell><cell>46.9</cell><cell>31.1</cell><cell>18.1</cell><cell>18.3</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Contact: Benjamin Clavi?, Jus Mundi, 30 Rue de Lisbonne, 75008 Paris, France; b.clavie@jusmundi.com.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Code available at https://gitlab.com/jusmundi-group/public/Legal-svm-baselines</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Acknowledgements</head><p>This work was granted access to the HPC resources of IDRIS under the allocation AD011012667 made by GENCI.</p><p>Many thanks to Paul Briton, Rym Laabiyad, Akshita Gheewala and Francesco Piccoli for their advice on this paper.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toutanova</forename><forename type="middle">K</forename><surname>Bert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL</title>
		<meeting>NAACL</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">BioBERT: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">LEGAL-BERT: The Muppets straight out of Law School</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fergadiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Aletras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Findings of EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">When Does Pretraining Help? Assessing Self-Supervised Learning for Law and the CaseHOLD Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICAIL2021. ACM</title>
		<meeting>ICAIL2021. ACM</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural Legal Judgment Prediction in English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Aletras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4317" to="4340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">CLAUDETTE: an automated detector of potentially unfair clauses in online terms of service</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pa?ka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Contissa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lagioia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Micklitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sartor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artif Intell Law</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="156" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">LEDGAR: A Large-Scale Multi-label Corpus for Text Classification of Legal Provisions in Contracts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuggener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Von D?niken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Peetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cieliebak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">LexGLUE: A Benchmark Dataset for Legal Language Understanding in English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><forename type="middle">A</forename><surname>Hartung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bommarito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename></persName>
		</author>
		<idno>arXiv cs.CL 2110.00976</idno>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">How to fine-tune bert for text classification?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">China National Conference on Chinese Computational Linguistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="194" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Simple Baseline Machine Learning Text Classifiers for Small Datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riekert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riekert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SN Computer Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Paragraphlevel Rationale Extraction through Regularization: A case study on European Court of Human Rights Cases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fergadiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsarapatsanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Aletras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL 2021</title>
		<meeting>NAACL 2021</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">MultiEURLEX-A multi-lingual and multi-label legal document classification dataset for zero-shot cross-lingual transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fergadiotis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2021</title>
		<meeting>ACL 2021</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Metrics for Multi-Class Classification: an Overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grandini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bagli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Visani</surname></persName>
		</author>
		<idno>stat.ML 2008.05756</idno>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
