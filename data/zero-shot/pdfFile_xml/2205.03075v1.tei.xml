<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">QLEVR: A Diagnostic Dataset for Quantificational Language and Elementary Visual Reasoning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zechen</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Northeastern University</orgName>
								<address>
									<region>US</region>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>S?gaard</surname></persName>
							<email>soegaard@di.ku.dk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Copenhagen</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">QLEVR: A Diagnostic Dataset for Quantificational Language and Elementary Visual Reasoning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Synthetic datasets have successfully been used to probe visual question-answering datasets for their reasoning abilities. CLEVR (Johnson et al., 2017), for example, tests a range of visual reasoning abilities. The questions in CLEVR focus on comparisons of shapes, colors, and sizes, numerical reasoning, and existence claims. This paper introduces a minimally biased, diagnostic visual questionanswering dataset, QLEVR, that goes beyond existential and numerical quantification and focus on more complex quantifiers and their combinations, e.g., asking whether there are more than two red balls that are smaller than at least three blue balls in an image. We describe how the dataset was created and present a first evaluation of state-of-the-art visual question-answering models, showing that QLEVR presents a formidable challenge to our current models. Code and Dataset are available at https://github.com/ zechenli03/QLEVR</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Visual question answering is at the locus of computer vision and natural language processing, and its objective is developing computer vision systems that can answer arbitrary natural language questions about images <ref type="bibr">(Lu et al., 2016;</ref><ref type="bibr">Schwartz et al., 2017;</ref><ref type="bibr">Ramakrishnan et al., 2018;</ref><ref type="bibr">Gat et al., 2020)</ref>. This is useful across a range of applications, including medical image analysis, accessibility for visually impaired, video surveillance, art and advertisement <ref type="bibr">(Barra et al., 2021)</ref>.</p><p>The complexity of visual question answering naturally depends on the complexity of the images and the complexity of the natural language questions. The task reduces to object recognition for very simple questions of the form:</p><p>(1) Is there a triangle in this image?</p><p>Question: Are all the cyan metallic triangular prisms on the brown plane? Answer: True Question: On the non-white planes on the left rear side of the black wood rectangular plane, all the cyan metallic cubes but at least 2 are larger than at most 7 cubes; is it right? Answer: False <ref type="figure">Figure 1</ref>: A sample image and questions from QLEVR. Tasks involve attribute recognition, counting, comparing numbers, spatial relationships, and understanding of quantifiers.</p><p>Object recognition can of course be a very complex task on its own, depending on the types of objects, the number of possible objects to be recognized, the amount of supervision for inducing a good model, general image quality, etc. However, more complex queries such as (2) make visual question answering much harder:</p><p>(2) Is there a triangle inside a circle in this image?</p><p>Answering such a question in the presence of an image requires a computer vision system that not only recognizes objects, but also relations between them. CLEVR <ref type="bibr">(Johnson et al., 2017)</ref> probes computer vision systems's ability to answer even more complex queries, such as, for instance:</p><p>(3) Is there a cyan cube to the right of the yellow sphere?</p><p>Question <ref type="formula">(3)</ref> involves reasoning about the relation between two objects, as well as the compositional semantics of color adjectives. In addition to shapes and colors, CLEVR also includes questions about sizes and quantities.</p><p>In this paper, we present a novel visual questionanswering dataset that goes beyond CLEVR in focusing specifically on quantificational language, e.g.:</p><p>(4) Are most of the cyan cubes to the right of the yellow sphere?</p><p>Given the complexity of quantificational language, the rich typology of expressions of quantification across different languages, and the interest from philosophy, it is perhaps surprising that quantificational language has received relatively little attention in the NLP community (see ?2), but we believe it is a crucial step in pushing the research horizons in (visual) question-answering.</p><p>Contributions Based on a comprehensive typology of English quantifiers, we build a dataset of 100,000 synthetic images and 999,446 unique questions to these images. This is roughly the same size as or a little bigger than CLEVR <ref type="bibr">(Johnson et al., 2017)</ref>. Our questions are on average longer than previous datasets. We evaluate three baselines from <ref type="bibr">Johnson et al. (2017)</ref>, a text-only baseline based on <ref type="bibr">BERT (Devlin et al., 2019)</ref>, and MAC (Hudson and Manning, 2018) on QLEVR and analyze performance across quantifier types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Visual Question Answering Challenge Datasets Several synthetic challenge datasets for visual question answering exist: <ref type="bibr">Andreas et al. (2016)</ref> presents SHAPES, a predecessor to CLEVR and QLEVR, relying also on synthetic constellations of colored geometric shapes and template-driven question generation. Pezzelle and Fern?ndez (2019) create a similar dataset to probe visual question answering models for knowledge of adjectival semantics. A portion of the visual question answering dataset <ref type="bibr">(Agrawal et al., 2017)</ref> contains synthetic cartoon imagery. <ref type="bibr">Sampat et al. (2021)</ref> present an extension of CLEVR that probes for hypothetical reasoning of the form: If someone removed three triangles from this image, how many would be left? <ref type="bibr">Malinowski and Fritz (2014)</ref> combined natural images with synthetic, template-driven question generation.</p><p>Finally, <ref type="bibr">Parfenova et al. (2021)</ref> recently created a dataset of three-image scenes to probe two-step reasoning.</p><p>Synthetic visual question answering datasets have several advantages over ones based on real images and questions that tend to suffer from selection biases <ref type="bibr">(Liu et al., 2021)</ref>, but of course they are limited in what can be induced from them. They are therefore mostly useful for probing the limitations of visual question answering architectures and off-the-shelf models. Showing results only on synthetic data is often seen as a weakness in the literature <ref type="bibr">(Hassantabar, 2018)</ref>, but synthetic data is useful for diagnosing the errors of visual question answering systems, in our case highlighting the challenges posed by quantifiers.</p><p>Quantifiers Quantifiers have been largely ignored in the NLP community. Question-answering datasets have been developed for numerical reasoning in English <ref type="bibr">(Dua et al., 2019)</ref>, and some have identified quantifier words as important sources of errors for textual entailment systems <ref type="bibr">(Joshi et al., 2020)</ref>. <ref type="bibr">Fang and Lou (2021)</ref> recently focused on the two quantifier words part and whole in an error analysis for named entity recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">QLEVR</head><p>We design a challenge dataset called QLEVR (for Quantificational Language and Elementary Visual Reasoning) that requires more complex reasoning than previous visual question-answering datasets. QLEVR is designed to probe the visual reasoning capabilities of visual question-answering systems with respect to quantificational language, including detecting members of sets, quantifying sets, and reasoning about the relationships between sets. To this end, we automatically construct scene graphs <ref type="bibr">(Johnson et al., 2015)</ref> and use these to generate synthetic images with ground-truth locations, attributes, and relationships for planes and objects. Each scene graph can be queried in a number of way, and we design query templates to render natural language questions involving complex reasoning about sets of such planes and objects. We describe each of these steps in detail:</p><p>Image Generation All images in QLEVR are images of objects organized in a particular way on a desk-like surface. <ref type="figure" target="#fig_0">Figure 2</ref> shows how the images are generated. We construct a scene graph for a two-dimensional image containing areas and ob- jects of different sizes and shapes. Scene graphs determine the ground-truth locations, bounding boxes, attributes and relationships for the planes and objects in the form of a graph or tree structure. Nodes are planes or objects annotated with attributes, each of which is connected to its spatially related nodes.</p><p>Each image contains one to five areas or geometric planes. These can be either triangular, rectangular or circular. The rest of the desk area we refer to as the white non-geometric plane. Geometric planes come in two materials (marble and wood), three colors (black, gray, and brown), and random sizes.</p><p>Each geometric plane contains one to ten (1-10) objects, with different sizes and shapes, and the non-geometric plane contains one to twelve (1-12) objects, with different sizes and shapes. Object come in seven shapes (cone, cube, cylinder, pentahedron, sphere, triangular prism, and tetrahedron), two absolute sizes (small and large), five materials (metal, rubber, leather, marble, and wood), and eight colors <ref type="bibr">(blue, brown, cyan, gray, green, purple, red and yellow)</ref>. The spatial relationships between planes and objects include front, back, left and right, as well as right front, right rear, left front and left rear.</p><p>We render three-dimensional images of the scene graphs with Blender (Community, 2018). Light settings and three preset camera positions were chosen at random, after validating that all objects were at least partially visible. Since the depth of the scene can affect the judgment of the spatial relationship in the three-dimensional image, the desk boundary is always visible as a reference for determining the depth of the scene. Minimum distances between objects and planes were kept to reduce the ambiguity of spatial relationships. See Appendix B for more details. Question Generation Quantifiers are often said to be among the most important and complex constructs of natural languages <ref type="bibr">(Hintikka, 1977;</ref><ref type="bibr">Barwise and Cooper, 1981)</ref>. As pointed out by by <ref type="bibr">Bernardi and Pezzelle (2021)</ref>, visual questionanswering models need to master a wide range of linguistic phenomena, including negation, entailment, mutual exclusivity and so on. We add (generalized) quantifiers to this list and design a dataset to probe the ability of visual question-answering systems to handle quantifiers in combination with other linguistic phenomena. See <ref type="table" target="#tab_0">Table 1</ref> for the quantifiers included in QLEVR.</p><formula xml:id="formula_0">allP (A, B) ? A ? B someP (A, B) ? A ? B = ? noP (A, B) ? A ? B = ? some but not allP (A, B) ? A ? B = ? = A ? B mostP (A, B) ? |A ? B| &gt; |A ? B| moreP (A, B) ? |A| &gt; |B| f ewerP (A, B) ? |A| &lt; |B| equalP (A, B) ? |A| = |B| exactly nP (A, B) ? |A| = n &amp; A ? B between n1 and n2 P (A, B) ? n1 ? |A ? B| ? n2 at most nP (A, B) ? |A ? B| ? n more than nP (A, B) ? |A ? B| &gt; n all but at least nP (A, B) ? |A ? B| ? n at least n d of theP (A, B) ? |A ? B| |A| ? n d f ewer than n d of theP (A, B) ? |A ? B| |A| &lt; n d no objects except CP (A, B) ? A ? B = {c} every object except CP (A, B) ? A ? B = {c}</formula><p>See <ref type="figure" target="#fig_0">Figure 2</ref> for how questions are formed from scene graphs. In brief, we think of the scene graph as a model and evaluate various combinations of logical operators, including quantifiers, on the scene graph, i.e., performing a model checking <ref type="bibr">(Clarke et al., 2009)</ref> procedure.</p><p>We introduce the notion of a question family, defined by a set of operators and a scene graph. Each question family is associated with 2-6 text templates and a set of synonyms (for shapes, colors, materials, and spatial relationships). The templates were written by hand. Each question template can thus generate multiple questions. For example, the where upper-cased variables refer to words, and lower-cased variables to suffixes, can generate the question (6) Are there exactly 2 small red rubber objects on the black wooden triangular plane?</p><p>We construct a total of 671 different templates, which are randomly constructed from 11 plane templates and 61 object templates. Our questions involve attribute recognition, counting, comparing numbers or attributes, spatial relationships, and understanding of quantifiers. <ref type="figure" target="#fig_0">Figure 2</ref> shows the operators built in the given question family, such as filter, relate, and at least. Note that many (generalized) quantifiers are related by entailment. The question (7) Are all the red cubes on the marble planes?</p><p>is, assuming an image with red cubes, semantically equivalent to (8) Are no red cubes not on the marble planes?</p><p>The semantics of combinations of quantifiers can be derived using squares of opposition <ref type="bibr">(Westerst?hl, 2012)</ref>. We exploit these entailment relations in creating QLEVR.  Some combinations of key values may generate unreasonable questions. We therefore define restrictions for each question family to avoid the generation of pragmatically odd, ill-posed or trivial questions. For example, the phrase on the marble plane where there are at least 5 red objects would be pragmatically odd if there was only one marble plane in the scene. The sentence (9) On the marble plane, do between 2 and 4 cubes have the same size as most of the cylinders?</p><p>is ill-posed if there are no cubes on the marble plane. Finally, questions like Are there more red cubes than cubes? are trivial, because they can be answered in the absence of the image. The assertion is always true. The opposite would, for example, be true of (10) On the plane with 8 balls, are there exactly 3 balls?</p><p>We present many examples of images and questions in the Appendix, but see also <ref type="figure" target="#fig_1">Figure 3</ref> for a complex question with embedded quantifiers.</p><p>Dataset Characteristics QLEVR has 1,000,000 questions for 100,000 images, with each image having 10 questions generated from different question families. The dataset is balanced, preventing answering in the absence of the images. In addition, the answer distribution across question families is constrained by acceptance-rejection sampling. The data is randomly split, with 70% for training data, 15% for validation and 15% for heldout evaluation data (the test set). As shown in figure 4, QLEVR includes 27 different quantifiers. Questions contain 1-4 quantifiers. <ref type="table" target="#tab_2">Table 2</ref> shows the diversity and complexity of the QLEVR questions. Almost all the questions are unique. Very few questions appear in several splits, and always in conjunction with new scene graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we evaluate the performance of baselines and near-state-of-the-art models on the QLEVR dataset and perform detailed error analysis. We ran each each method three times with different random seeds and report the test set performance for the model that achieved the best performance on the validation data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Models</head><p>We first present three purely text-based models, Q-type <ref type="bibr">(Antol et al., 2015)</ref>, LSTM (Hochreiter and Schmidhuber, 1997) and <ref type="bibr">BERT (Devlin et al., 2019)</ref>, to evaluate the level of visual reasoning needed for QLEVR. If these perform at random (0.5), we have successfully constructed a dataset in which questions cannot be answered in the absence of images. It is important to include text-only models as baselines in visual question answering to control for spurious correlations <ref type="bibr">(Gat et al., 2020)</ref>. We shall see in ?4.2 that while Q-type performs at chance level, the BERT and LSTM baselines are able to pick up on some spurious correlations. We also evaluate two standard visual question answering architectures, one based on a combination of convolutional and recurrent neural networks (CNN+LSTM), and one attention-   <ref type="table" target="#tab_5">Table 3</ref> shows the results of the five methods described in ?4.1 on the test set of QLEVR. We make the following observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Analysis by Quantifier Type</head><p>1. Q-type exhibits performance levels around 50% for every quantifier type, showing that the answer distribution of QLEVR is uniform.</p><p>2. Text-only LSTM and BERT achieve an average accuracies of 64.6% and 65.8%, respectively. These results suggest that even if the answers of each question family are distributed uniformly, there may still be spurious correlations: Objects with more detailed attribute descriptions may be more likely to get a false answer. For example, the question "Are there more than 3 small blue cubes on the black planes?" is more likely to get a false answer than "Are there more than 3 blue objects on the black planes?").   <ref type="figure">Figure 4</ref> for the number distribution of quantifiers. <ref type="figure">Figure 5</ref>: The effect of different number of quantifiers in questions on the accuracy of the answers. <ref type="figure">Figure 4</ref> shows the distribution of the number of quantifiers in each QLEVR question.</p><p>higher than for quantifiers that require a number of objects to match exact values (e.g., exactly N).</p><p>5. Quantifiers without numerals (e.g., all, most, not all, some and some but not all) lead to lower accuracies than other quantifiers, showing that reasoning with these quantifiers is harder. This highlights the need for including such quantifiers in challenge datasets to push advancements in visual question answering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis</head><p>Number of Quantifiers in Questions <ref type="figure">Figure 5</ref> shows how accuracy varies as the number of quantifiers in the questions increases. The more quantifiers in a question, the more complex its semantics will be.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Planes</head><p>We also test the visual reasoning abilities of these models by examining error across the number of planes involved in answering the question. Appendix A introduces all the plane templates in our question families. We use the plane template "on the &lt;PC&gt; &lt;PM&gt; &lt;PS&gt; plane&lt;ps&gt;" for our analysis, because this template has no influence of quantifiers or spatial relationships in targeting planes. QLEVR test set has 13,612 questions with this plane template. The left graph in <ref type="figure">Figure 6</ref> shows how the accuracy varies with the increase in the number of target planes that need to be reasoned with. Among the 13,612 questions, 10,288 of them involve a single plane and 3,324 of them involve multiple planes.</p><p>We can see that for language-only models Q-type, BERT and LSTM, the number of target planes does not significantly affect the accuracy. However, for CNN+LSTM and MAC, questions involving just a single plane are harder to answer than those involving multiple planes. This is because for visual models, planes enable disambiguation and thereby reduce the required reasoning. The right graph in <ref type="figure">Figure 6</ref> compares accuracy on questions that do not refer to specific planes (no attribute), to questions that refer to specific planes (with attributes). Among the 13,612 questions, 1,340 questions do not refer to specific planes, whereas 12,272 do. This distinction has little impact on the perfor- <ref type="figure">Figure 6</ref>: The results of questions contains "on the &lt;PC&gt; &lt;PM&gt; &lt;PS&gt; plane&lt;ps&gt;". Left: The effect of different number of target planes on the accuracy of the answers; single means that the reasoning process basically only needs to consider one plane in the image, while multiple means that multiple planes need to be considered. Right:</p><p>The effect of whether the plane has attribute description on the accuracy of the answer; no attribute ("on the planes") means that the reasoning process does not need to consider planes in the image and see the image as a whole, while with attributes ("e.g., on the wooden plane") means that specific plane(s) needs to be considered.</p><p>mance of our text-only models. For CNN+LSTM and MAC, however, examples in the no attribute class exhibit higher accuracies than those in with attributes. This, again, shows performance is better when less visual reasoning is required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>In this paper, we proposed a dataset, which we call QLEVR -for Quantificational Language and Elementary Visual Reasoning. QLEVR probes the ability of visual question-answering systems to reason with quantificational language, including 27 different quantifiers and combinations thereof. It requires complex visual reasoning to locate the specific planes and understand various relationships between objects. We increase the semantic diversity of the questions by negating quantifiers and by using different templates for semantically equivalent questions. Our analysis highlights how challenging such examples are to visual question-answering systems, and we hope that QLEVR will help guide push research horizons in visual question-answering by zooming in on the challenges posed by quantificational language. One fundamental limitation is that QLEVR only considers English questions, and we plan to extent it to other, typologically unrelated languages. Besides, QLEVR can easily be extended by adding new question families, and questions whose answers are not limited to true or false, e.g., with numbers or attributes as answer types. In addition to the three-dimensional images, we also provide two-dimensional images and scene graphs recording the ground-truth information (see <ref type="figure" target="#fig_0">Figure 2)</ref>. It is also possible to generate questions about 2D im-ages by simply modifying our question families. We hope these two datasets can be used for transfer learning for visual question answering in the future. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material A Question Templates</head><p>As described in Section 3, QLEVR question templates are composed of 11 plane templates and 61 object templates randomly paired. In this section we detail the difference between these templates.</p><p>Plane Templates. The role of the plane templates is to raise our question for specific planes (regions) in the image through some restrictions (attributes, spatial relations and explicitly restricted quantifier phrases). Basically, the plane templates can generate questions with following types:</p><p>? On the white non-geometric planes.</p><p>? On the geometric plane with a different shape (color/material) from other planes. ? On the black planes to the left rear of the circular plane. ? On the planes where there are at least 3 red cubes on each plane. ? On the quadrilateral plane where there are at most 5 blue balls. ? On the brown planes where there are between 1 and 4 triangular prisms on each plane. ? On the triangular plane where there is exactly 1 leathery object. ? On the plane where there are not 2 to 4 triangular prisms. ? On the gray planes where there are not exactly 3 items on each plane. ? On the marble plane where there are not any wooden cones. ? On the wooden plane where there is a total of 7 small rubber objects.</p><p>To avoid pragmatically odd questions, we ensure that the number of planes obtained by the plane templates with restrictions of spatial relations and explicitly restricted quantifier phrases (e.g. On the brown planes behind the gray plane, or On the brown plane where there are exactly 3 balls) is less than the number of planes obtained by the templates without these restrictions (e.g. On the brown planes) for the same scene graph.</p><p>Object Templates. We can use the operators representation of the questions templates to analyze model performance on the following forms of reasoning: <ref type="figure">Figure 7</ref>: Accuracy per question type on the QLEVR dataset.</p><p>? Existence type 1: Questions ask whether a certain type of quantifier-restricted object exists on one or some specific planes (e.g., "Whether all the cyan cubes [Plane Template]?").</p><p>? Existence type 2: Questions ask whether a certain type of quantifier-restricted object exists in a certain direction of a unique object (e.g., "[Plane Template], are there fewer than 3 balls behind the cyan cube?").</p><p>? Comparing attributes: Questions ask whether two types of quantifier-restricted objects have the same value for some attributes (e.g., "[Plane Template], is there any small cylinders that has the same color as most leathery tetrahedrons?").</p><p>? Quantity comparison: Questions compare the size of two sets of objects (e.g., "[Plane Template], are there more big blocks than rubber balls?").</p><p>? Size comparison: Questions ask which of two quantifier-restricted objects has a larger size (e.g., "[Plane Template], some red cones are larger than some but not all of the metal cones; is it right?").</p><p>? Spatial relations: Questions involves the spatial relationship between objects (e.g., "[Plane Template], are there more big blocks in front of the yellow cylinder than rubber balls to the left rear of the small block?"). <ref type="figure">Figure 7</ref> shows the performance on above question types. As can be seen, MAC outperforms other models on most question types. The only exception is: on quantity comparison task, BERT performs slightly better than MAC, showing that MAC has better reasoning ability in complex scenes. Questions of Existence type 1 obtain better results than Existence type 2 for vision-language model CNN+LSTM and MAC, suggesting that the position relationship between object and plane is easier to be inferred by the models than the spatial relationship between the objects. For questions of Quantity comparison, MAC and CNN+LSTM performs on par with LSTM, suggesting that the image features extracted by ResNet-101 may contain little information related to counting in complex scenes. <ref type="figure">Figure 8</ref> shows the materials and object models made through Blender (Community, 2018), as well as the performance of different colors on these materials. Two different materials of leather, marble, and wood were made respectively to further enrich the diversity of objects in the dataset. The images of the plane materials were made by modifying the images under CC0 1.0 Universal. 1 Note that after the overall scene rendering, objects of certain materials will produce different effects according to the color and material of the plane in contact with them, as well as the position of the camera and lights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B 3D Modeling and Design</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Example Images and Questions</head><p>The remaining pages show some images and questions generated by the combination of our different plane templates and object templates. Each question is annotated with its answer and contained quantifiers, where N stands for Number, F stands for Fraction and O stands for Object.  <ref type="figure">Figure 8</ref>: From left to right, the object shapes in (a) are cone, cube, cylinder, pentahedron, sphere, triangular prism, and tetrahedron; the plane attributes in (b) are black marble, black wood, brown marble, brown wood, gray marble and gray wood; the colors in (c)~(g) are blue, brown, cyan, gray, green, purple, red and yellow.</p><p>Question: Whether all the large brown objects are on the white plane? Answer: False Quantifiers: all Question: Some large rubber tetrahedron is not on the gray marble plane; is it right? Answer: True Quantifiers: not all (some ?) Question: It is not the case that all the big blue rubbery spheres are not on the gray rectangular plane; is it right? Answer: False Quantifiers: some (? all ?) Question: It's not the case that some large purple metallic triangular prism is on the planes where there are 9 items in total; is it right? Answer: True Quantifiers: total, no (? some) Question: Whether some but not all of the large purple rubber objects are on the marble planes where there are 4 blue objects in total? Answer: False Quantifiers: total, some but not all Question: Are there at most 3 small blue objects on the dappled planes where there are 5 big triangular prisms in total? Answer: True Quantifiers: total, at most N Question: All the big wooden blocks but at least 2 are not on the planes where there are exactly 2 cylinders on each plane; is it right? Answer: True Quantifiers: each, exactly N, at least N (all but at least N ?) Question: It is not the case that at most 2 wood cylinders are on the quadrilateral plane where there are exactly 2 purple wood cylinders; is it right? Answer: False Quantifiers: each, exactly N, more than N (? at most N) Question: Are there fewer than 2 small purple dappled cylinders on the planes where there is exactly 1 purple block on each plane? Answer: True Quantifiers: each, exactly N, fewer than N Question: All the tiny red wood objects but 1 are not on the non-white plane where the shape of the plane is different from that of other planes; is it right? Answer: True Quantifiers: exactly N (all but N ?) Question: Are there between 1 and 3 small red leathery cubes on the circular plane to the left rear of the brown quadrilateral plane? Answer: True Quantifiers: between Question: All the red leather objects but at most 3 are on the geometric plane where the material of the plane is different from that of other planes; is it right? Answer: False Quantifiers: all but at most N Question: More than two thirds of the green objects are on the brown marble plane to the left front of the black wood plane; is it right? Answer: False Quantifiers: more than F Question: Are most brown metallic objects on the geometric plane on the right side of the brown wooden round plane? Answer: False Quantifiers: most Question: It is not the case that fewer than 4 brown metallic triangular prisms are not on the non-white plane where the color of the plane is different from that of other planes; is it right? Answer: True Quantifiers: all but at least N (? fewer than N ?) Question: Fewer than three-quarters of the small yellow objects are on the wood three-sided plane where there are not any large metallic square-based pyramids; is it right? Answer: True Quantifiers: no (? any), fewer than F Question: It is not the case that fewer than 11/15 of the metallic items are on the planes where there are 0 tiny rubbery tetrahedrons on each plane; is it right? Answer: True Quantifiers: each, no (0), at least F (? fewer than F) Question: At most 7/8 of the yellow rubber triangular pyramids are on the planes where there is no big yellow wooden cone on each plane; is it right? Answer: False Quantifiers: each, no, at most F Question: On the gray marble plane where there are between 3 and 5 tiny cyan objects, is there any wooden triangular prism that has the same size as most metallic objects? Answer: False Quantifiers: between, some (any), most Question: On the gray plane where there are between 1 and 4 cyan triangular prisms, 2 to 5 cyan items are the same material as most small items; is it right? Answer: True Quantifiers: between, between, most Question: On the planes where there are between 3 and 6 cyan items on each plane, are there exactly 3 small triangular prisms that have the same color as most small metallic spheres? Answer: True Quantifiers: each, between, exactly N, most Question: On the gray quadrilateral plane where there are not between 1 and 3 small gray items, are all the large items but at most 1 the same color as most leather items? Answer: True Quantifiers: not between, all but at most N, most Question: On the plane where there are not between 2 and 4 green leather objects, fewer than a half of the gray cylinders are the same size as most gray rubbery objects; is it right? Answer: False Quantifiers: not between, fewer than F, most Question: On the planes where there are not between 0 and 3 big objects on each plane, more than five twelfths of the big gray objects have the same shape as most gray rubber objects; is it right? Answer: False Quantifiers: each, not between, more than F, most Question: On the planes where there are not exactly 2 spheres on each plane, at most 4 red leather objects are the same shape as most objects; is it right? Answer: True Quantifiers: each, not exactly N, at most N, most Question: On the triangular plane where there is not exactly 1 small marbled square-based pyramid, at least 2 red marbled items have the same size as most red items; is it right? Answer: False Quantifiers: not exactly N, at least N, most Question: On the marbled planes where there is at least 1 large marbled item on each plane, at least 2 large items are not the same material as most gray items; is it right? Answer: True Quantifiers: each, at least N, all but at least N (at least N ?), most Question: On the planes where there are more than or equal to 2 cylinders on each plane, are there more brown metallic cones than brown leathery cylinders? Answer: False Quantifiers: each, at least N, more O1 than O2 Question: On the wood plane where there is not exactly 1 small yellow leathery object, is the number of small objects less than the number of brown leathery cones? Answer: False Quantifiers: not exactly N, fewer O1 than O2</p><p>Question: On the planes where there are no fewer than 2 big cones on each plane, is the number of circular cylinders the same as the number of big circular cylinders? Answer: True Quantifiers: each, at least N, equal O1 and O2 Question: On the dappled planes, is there the same number of tiny objects on the left side of the big sphere and tiny red spheres right of the red leathery triangular prism? Answer: False Quantifiers: equal O1 and O2 Question: On the white non-geometric plane, are there fewer big objects to the right rear of the big red dappled object than tiny spheres in front of the big red dappled object? Answer: True Quantifiers: fewer O1 than O2 Question: On the planes, is the number of triangular prisms to the right front of the red leathery tetrahedron greater than the number of leathery tetrahedrons on the left side of the large marble sphere? Answer: True Quantifiers: more O1 than O2</p><p>Question: On the planes where there are no more than 3 tiny marbled objects on each plane, all the tiny marbled objects are in front of the red metallic triangular prism; is it right? Answer: True Quantifiers: each, at most N, all Question: On the plane where there are at most 4 marble items, is there any tiny ball in front of the tiny red metal three-sided prism? Answer: False Quantifiers: at most N, some Question: On the wood plane where there are fewer than or equal to 3 small marble objects, it is not the case that no large marble triangular prism is not on the left side of the green sphere; is it right? Answer: True Quantifiers: at most N, not all (? no ?)</p><p>Question: On the planes where there is exactly 1 small blue marbled object on each plane, every green metal object is not behind the green rubber cylinder; is it right? Answer: False Quantifiers: each, exactly N, no (every ?)</p><p>Question: On the plane where there is not exactly 1 big green metal tetrahedron, some but not all of the marble objects are to the right of the blue tetrahedron; is it right? Answer: True Quantifiers: not exactly N, some but not all Question: On the planes where there is a total of 5 big green items, all the tiny green blocks but at most 1 are not right rear of the big green marble block; is it right? Answer: False Quantifiers: total, at most N (all but at most N ?)</p><p>Question: On the planes where there are at least 2 cyan items on each plane, all the tiny cones but at least 4 are not right rear of the tiny red rubbery pentahedron; is it right? Answer: False Quantifiers: each, at least N, at least N (all but at least N ?) Question: On the quadrilateral plane where there is at most 1 yellow circular cylinder, it is not the case that at most 1 red rubber object is left rear of the leather object; is it right? Answer: False Quantifiers: at most N, more than N (? at most N)</p><p>Question: On the geometric plane whose material is different from that of other planes, it is not the case that all the red items but at least 2 are not right front of the tiny yellow cylinder; is it right? Answer: True Quantifiers: fewer than N (? all but at least N ?)</p><p>Question: On the planes where there are not any small red rubber objects on each plane, there are exactly 2 small gray pentahedrons left rear of the large cyan pentahedron; is it right? Answer: False Quantifiers: each, no (? any), exactly N Question: On the planes where there is not exactly 1 wood ball on each plane, are there 1 to 3 wood objects to the left front of the gray marbled square-based pyramid? Answer: False Quantifiers: each, not exactly N, between Question: On the wooden planes where there are not between 1 and 3 red rubber items on each plane, at most 3 small items are not on the right front side of the big red sphere; is it right? Answer: True Quantifiers: each, not between, all but at most N (at most N ?)</p><p>Question: On the planes where there are between 1 and 3 tiny gray items on each plane, are all the tiny items but at least 5 right of the large gray metal circular cylinder? Answer: False Quantifiers: each, between, all but at least N Question: On the round plane to the left of the brown dappled three-cornered plane, most items are behind the small yellow dappled block; is it right? Answer: True Quantifiers: most Question: On the marble planes where there is a total of 7 tiny triangular prisms, it is not the case that fewer than 2/3 of the big items are to the left of the tiny gray cube; is it right? Answer: False Quantifiers: total, at least F (? fewer than F) Question: On the gray marble plane, it is not the case that more than 5/8 of the pentahedrons are to the right of the tiny metallic pentahedron; is it right? Answer: True Quantifiers: at most F (? more than F) Question: On the rectangular plane, all the blue wood square pyramids are larger than some rubber square pyramid; is it right? Answer: True Quantifiers: all, some Question: On the non-geometric plane, are all the green square-based pyramids smaller than some but not all of the square-based pyramids? Answer: True Quantifiers: all, some but not all Question: On the planes where there are 0 large metal balls on each plane, it is not the case that no blue cone is larger than some but not all of the yellow cones; is it right? Answer: False Quantifiers: each, no (0), some (? no), some but not all Question: On the planes where there are not exactly 3 tiny blue objects on each plane, exactly 3 blue cones are larger than at least 2 blue wood cones; is it right? Answer: False Quantifiers: each, not exactly N, exactly N, at least N Question: On the planes where there are not between 1 and 4 tiny marbled spheres on each plane, all the spheres but at least 2 are larger than at most 1 yellow sphere; is it right? Answer: True Quantifiers: each, not between, at least N (all but at least N ?), more than N (? at most) Question: On the circular planes where there are exactly 2 big objects on each plane, 1 to 3 marbled cones are smaller than more than 3/7 of the red marbled cones; is it right? Answer: True Quantifiers: each, exactly N, between, more than F Question: On the brown plane where there are between 1 and 3 red marbled objects, at least one-ninth of the marbled cones are larger than at least 2 cones; is it right? Answer: True Quantifiers: between, at least N, at least F Question: On the marble planes where there is a total of 5 marble items, all the cones but at least 2 are smaller than fewer than 3/4 of the gray cones; is it right? Answer: False Quantifiers: total, at least N (all but at least N ?), at least F (? fewer than F) Question: On the geometric plane whose color is different from that of other planes, all yellow spheres but 1 are smaller than fewer than 1 or more than 3 spheres; is it right? Answer: True Quantifiers: exactly N (all but N ?), between (? between) Question: On the wooden planes where there are no fewer than 2 tiny balls on each plane, every item except the marble ball is not a tiny item; is it right? Answer: False Quantifiers: each, at least N, no _ except (every _ except ?) Question: On the brown plane where there is no more than 1 dappled square pyramid, no objects except the metal ones are not square pyramids; is it right? Answer: True Quantifiers: at most N, every _ except (no _ except ?)</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>An overview of our dataset. Top: Image generation process and bounding box information. The top twodimensional image records the scene graph, and the bottom gray-scale color map records roughness of each plane. Center: Examples of questions and their associated operators. Bottom: Ideal visual attention as the operator proceeds.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Example image-question pair template (5) Are there exactly &lt;OC&gt; &lt;Z&gt; &lt;C&gt; &lt;M&gt; &lt;S&gt;&lt;os&gt; on the &lt;PC&gt; &lt;PM&gt; &lt;PS&gt; plane&lt;ps&gt;?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>based architecture (Hudson and Manning, 2018). The latter performs best on the counting and number comparison tasks in the CLEVR dataset (Johnson et al., 2017) compared with other approaches, such as Bottom-Up-Attention and Top-Down (UpDn) (Anderson et al., 2018), Question-Conditioned Graph (QCG) (Norcliffe-Brown et al., 2018), Bilinear Attention Network (BAN) (Kim et al., 2018), Relation Network (RN) (Santoro et al., 2017) and Recurrent Aggregation of Multimodal Embeddings Network (RAMEN) (Shrestha et al., 2019). We describe each system in detail:? Q-type(Antol et al., 2015): Similar to the "per Q-type prior" method in(Antol et al., 2015), this baseline predicts the most popular answer for each question type.? LSTM (Hochreiter and Schmidhuber, 1997): Question words are embedded as 300-dimensional vector sand fed into an LSTM network. The last hidden state representation is passed into a multi-layer perceptron (MLP) to predict the final answer. All experiments use</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Quantifiers included in QLEVR. P denotes the set of all the objects on the target plane(s). A or B denotes a subset of P with the same attributes. |A| is the cardinality of the set A.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Statistics for our dataset. In each Overlap column, the number on the right represents the number of overlapping questions with the same answer.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Figure 4: Statistics for our dataset. Left: Question length distribution for different popular VQA datasets; most of the QLEVR questions have 30 to 40 words, which is longer than other datasets. Middle: Distribution of the number of quantifiers in QLEVR questions. Right: Frequency distribution of quantifiers in QLEVR, where N stands for Number and F stands for Fraction; each, total, no, at most N, at least N, exactly N, between, not between, and not exactly N are also used in the plane templates, so they appear more frequently. For the quantifiers in the texts of the same question family, we consider each quantifier in square of opposition {Q, Q?, ?Q, Q d } as quantifier Q.</figDesc><table><row><cell>a bi-directional LSTM with 512 units in the</cell></row><row><cell>hidden layer per direction.</cell></row><row><cell>? BERT (Devlin et al., 2019): We fine-tune BERT</cell></row><row><cell>(Devlin et al., 2019) augmented with a sentence-</cell></row><row><cell>level classification head: The special classifica-</cell></row><row><cell>tion token [CLS] is passed to a feed-forward</cell></row><row><cell>layer and used for sentence class prediction.</cell></row><row><cell>? CNN+LSTM: The images are encoded using a</cell></row><row><cell>convolutional neural network and questions as</cell></row><row><cell>the last hidden state produced by an LSTM net-</cell></row><row><cell>work. The convolutional network uses spatial fea-</cell></row><row><cell>tures produced by ResNet-101 (He et al., 2015)</cell></row><row><cell>pre-trained on ImageNet (Deng et al., 2009). We</cell></row><row><cell>resize all images to 448x448, and use the final</cell></row><row><cell>average pooling layer to extracts features of the</cell></row><row><cell>shape (1, 14, 14, 2048). The question and image</cell></row><row><cell>features are concatenated and passed to a multi-</cell></row><row><cell>layered perceptron to predict the final answer.</cell></row><row><cell>? MAC (Hudson and Manning, 2018): The</cell></row><row><cell>MAC network is a recurrent attention network,</cell></row><row><cell>which uses a Memory, Attention, and Composi-</cell></row><row><cell>tion (MAC) cell in each attention-based reason-</cell></row><row><cell>ing step to learn to perform iterative reasoning</cell></row><row><cell>processes. MAC learns compositional reasoning</cell></row><row><cell>directly from the questions and the images in an</cell></row><row><cell>end-to-end approach. The word vectors have a</cell></row><row><cell>dimension of 300 and are initialized randomly us-</cell></row><row><cell>ing a standard uniform distribution. The images</cell></row><row><cell>are resized to 448x448, and 2048-dimensional</cell></row><row><cell>features are produced by ResNet-101. The model</cell></row><row><cell>uses a hidden state size of 512 and a length of 12</cell></row><row><cell>MAC cells.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Test set results of baselines and state-of-the-art models on the QLEVR dataset. Models are evaluated for both overall accuracy and accuracy per quantifier type. In quantifier type, N stands for Number and F stands for Fraction. Refer to</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Justin Johnson, Ranjay Krishna, Michael Stark, Li-Jia Li, David Shamma, Michael Bernstein, and Li Fei-Fei. 2015. Image retrieval using scene graphs. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3668-3678. Keyur Sampat, Akshay Kumar, Yezhou Yang, and Chitta Baral. 2021. CLEVR_HYP: A challenge dataset and baselines for visual question answering with hypothetical actions over images. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational</figDesc><table><row><cell cols="2">Edmund M. Clarke, E. Allen Emerson, and Joseph Sifakis. 2009. Model checking: Algorithmic verification and debugging. Commun. ACM, 52(11):74-84. Blender Online Community. 2018. Blender -a 3D modelling and rendering package. Blender Founda-Shailaja Linguistics: Human Language Technologies, pages</cell><cell>Pratik Joshi, Somak Aditya, Aalok Sathe, and Mono-</cell></row><row><cell cols="2">tion, Stichting Blender Foundation, Amsterdam. 3692-3709, Online. Association for Computational</cell><cell>jit Choudhury. 2020. TaxiNLI: Taking a ride up the</cell></row><row><cell cols="2">Linguistics. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hier-Adam Santoro, David Raposo, David G. T. Barrett, archical image database. In 2009 IEEE Conference Mateusz Malinowski, Razvan Pascanu, Peter W. on Computer Vision and Pattern Recognition, pages Battaglia, and Timothy P. Lillicrap. 2017. A sim-</cell><cell>NLU hill. In Proceedings of the 24th Conference on Computational Natural Language Learning, pages 41-55, Online. Association for Computational Lin-guistics.</cell></row><row><cell cols="2">248-255. ple neural network module for relational reasoning.</cell><cell>Jin-Hwa Kim, Jaehyun Jun, and Byoung-Tak Zhang.</cell></row><row><cell cols="2">In NIPS. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep Idan Schwartz, Alexander Schwing, and Tamir Hazan. bidirectional transformers for language understand-2017. High-order attention models for visual ques-</cell><cell>2018. Bilinear Attention Networks. In Advances in Neural Information Processing Systems 31, pages 1571-1581.</cell></row><row><cell cols="2">ing. NAACL-HLT. tion answering. In Advances in Neural Information</cell><cell>Fangyu Liu, Emanuele Bugliarello, Edoardo Maria</cell></row><row><cell cols="2">Processing Systems, volume 30. Curran Associates, Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Inc. Stanovsky, Sameer Singh, and Matt Gardner. 2019. DROP: A reading comprehension benchmark requir-Robik Shrestha, Kushal Kafle, and Christopher Kanan. ing discrete reasoning over paragraphs. In Proceed-2019. Answer them all! toward universal visual ings of the 2019 Conference of the North American guistics: Human Language Technologies, Volume 1 Chapter of the Association for Computational Lin-question answering models. In CVPR.</cell><cell>Ponti, Siva Reddy, Nigel Collier, and Desmond El-liott. 2021. Visually grounded reasoning across lan-guages and cultures. In Proceedings of the 2021 Conference on Empirical Methods in Natural Lan-guage Processing, pages 10467-10485, Online and Computational Linguistics. Punta Cana, Dominican Republic. Association for</cell></row><row><cell cols="2">(Long and Short Papers), pages 2368-2378, Min-</cell><cell>Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh.</cell></row><row><cell cols="2">neapolis, Minnesota. Association for Computational</cell><cell>2016. Hierarchical question-image co-attention for</cell></row><row><cell>Linguistics.</cell><cell></cell><cell>visual question answering. In Advances in Neural</cell></row><row><cell cols="2">Lei Fang and Jian-Guang Lou. 2021. Part &amp; whole extraction: Towards a deep understanding of quan-</cell><cell>Information Processing Systems, volume 29. Curran Associates, Inc.</cell></row><row><cell>titative facts for percentages in text. abs/2110.13505.</cell><cell>ArXiv,</cell><cell>Mateusz Malinowski and Mario Fritz. 2014. A multi-world approach to question answering about real-</cell></row><row><cell cols="2">Itai Gat, Idan Schwartz, Alexander Schwing, and Tamir Hazan. 2020. Removing bias in multi-modal classi-</cell><cell>world scenes based on uncertain input. In NeurIPS, pages 1682-1690.</cell></row><row><cell cols="2">fiers: Regularization by maximizing functional en-tropies. In Advances in Neural Information Process-ing Systems, volume 33, pages 3197-3208. Curran Associates, Inc.</cell><cell>Will Norcliffe-Brown, Efstathios Vafeias, and Sarah Parisot. 2018. Learning conditioned graph struc-tures for interpretable visual question answering. arXiv preprint arXiv:1806.07243.</cell></row><row><cell cols="2">Shayan Hassantabar. 2018. Visual question answering : Datasets , methods , challenges and oppurtunities.</cell><cell>Iuliia Parfenova, Desmond Elliott, Raquel Fern?ndez, and Sandro Pezzelle. 2021. Probing cross-modal</cell></row><row><cell cols="2">Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep residual learning for image recog-nition.</cell><cell>representations in multi-step relational reasoning. In Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021), pages 152-162, Online. Association for Computational Linguis-</cell></row><row><cell cols="2">Jaakko Hintikka. 1977. Quantifiers in natural lan-</cell><cell>tics.</cell></row><row><cell cols="2">guages: Some logical problems ii. Linguistics and Philosophy, 1(2):153-172.</cell><cell>Sandro Pezzelle and Raquel Fern?ndez. 2019. Is the red square big? MALeViC: Modeling adjectives</cell></row><row><cell cols="2">Sepp Hochreiter and J?rgen Schmidhuber. 1997. Long short-term memory. Neural computation.</cell><cell>leveraging visual contexts. In Proceedings of the 2019 Conference on Empirical Methods in Natu-ral Language Processing and the 9th International</cell></row><row><cell cols="2">Drew A Hudson and Christopher D Manning. 2018.</cell><cell>Joint Conference on Natural Language Processing</cell></row><row><cell cols="2">Compositional attention networks for machine rea-</cell><cell>(EMNLP-IJCNLP), pages 2865-2876, Hong Kong,</cell></row><row><cell>soning.</cell><cell></cell><cell>China. Association for Computational Linguistics.</cell></row></table><note>Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C Lawrence Zitnick, and Ross Girshick. 2017. Clevr: A diagnostic dataset for com- positional language and elementary visual reasoning. In CVPR.Sainandan Ramakrishnan, Aishwarya Agrawal, and Stefan Lee. 2018. Overcoming language priors in visual question answering with adversarial regular- ization. In Advances in Neural Information Process- ing Systems, volume 31. Curran Associates, Inc.Dag Westerst?hl. 2012. Classical vs. modern squares of opposition, and beyond.</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
