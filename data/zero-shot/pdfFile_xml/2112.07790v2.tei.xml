<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Maximum Bayes Smatch Ensemble Distillation for AMR Parsing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-05-02">2 May 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Suk</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research AI ?</orgName>
								<orgName type="institution" key="instit2">IBM Research -Ireland ?</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ram?n</forename><surname>Fernandez Astudillo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research AI ?</orgName>
								<orgName type="institution" key="instit2">IBM Research -Ireland ?</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><surname>Lam Hoang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research AI ?</orgName>
								<orgName type="institution" key="instit2">IBM Research -Ireland ?</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
							<email>tanseem@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research AI ?</orgName>
								<orgName type="institution" key="instit2">IBM Research -Ireland ?</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
							<email>raduf@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research AI ?</orgName>
								<orgName type="institution" key="instit2">IBM Research -Ireland ?</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
							<email>roukos@us.ibm.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research AI ?</orgName>
								<orgName type="institution" key="instit2">IBM Research -Ireland ?</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Maximum Bayes Smatch Ensemble Distillation for AMR Parsing</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-05-02">2 May 2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>AMR parsing has experienced an unprecendented increase in performance in the last three years, due to a mixture of effects including architecture improvements and transfer learning. Self-learning techniques have also played a role in pushing performance forward. However, for most recent high performant parsers, the effect of self-learning and silver data augmentation seems to be fading. In this paper we propose to overcome this diminishing returns of silver data by combining Smatch-based ensembling techniques with ensemble distillation. In an extensive experimental setup, we push single model English parser performance to a new state-of-the-art, 85.9 (AMR2.0) and 84.3 (AMR3.0), and return to substantial gains from silver data augmentation. We also attain a new state-of-the-art for cross-lingual AMR parsing for Chinese, German, Italian and Spanish. Finally we explore the impact of the proposed technique on domain adaptation, and show that it can produce gains rivaling those of human annotated data for QALD-9 and achieve a new state-of-the-art for BioAMR.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Adoption of the Transformer architecture <ref type="bibr" target="#b44">(Vaswani et al., 2017)</ref> for Abstract Meaning Representation (AMR) parsing <ref type="bibr" target="#b5">(Cai and Lam, 2020;</ref> as well as pretrained language models <ref type="bibr" target="#b3">(Bevilacqua et al., 2021;</ref><ref type="bibr" target="#b56">Zhou et al., 2021b;</ref><ref type="bibr" target="#b0">Bai et al., 2022)</ref> have enabled an improvement of above 10 Smatch points , the standard metric, in the last two years.</p><p>Data augmentation techniques have also shown great success in pushing the state-of-the-art of AMR parsing forward. These include generating silver AMR annotations with a trained parser <ref type="bibr" target="#b21">(Konstas et al., 2017;</ref><ref type="bibr" target="#b43">van Noord and Bos, 2017)</ref>, with multitask pre-training and fine-tuning <ref type="bibr" target="#b49">(Xu et al., 2020)</ref> as well as combining AMR to source text and silver AMR generation  and stacked pre-training of silver data from different models -from low performance to high performance silver data <ref type="bibr" target="#b48">(Xia et al., 2021)</ref>. However, the latest BART-based state-of-the-art parsers, have shown diminishing returns for data augmentation. Both SPRING <ref type="bibr" target="#b3">(Bevilacqua et al., 2021)</ref> and Structured-BART <ref type="bibr" target="#b56">(Zhou et al., 2021b</ref>) gain a mere 0.5 Smatch from self-learning, compared with over 1 point gains of the previous, less performant, models. Since performance scores are already above where inter annotator agreement (IAA) is assumed to be, i.e. 83 for newswire and 79 for web text reported in <ref type="bibr" target="#b1">(Banarescu et al., 2013)</ref>, one possible explanation is that we are reaching some unavoidable performance plateau.</p><p>In this work we show that we can achieve significant performance gains close to 2 Smatch point with the newly proposed data augmentation technique, contrary to the results from the previous state-of-the-art systems. The main contributions of this paper are as follows:</p><p>? We propose to combine Smatch-based model ensembling <ref type="bibr" target="#b2">(Barzdins and Gosko, 2016;</ref><ref type="bibr" target="#b16">Hoang et al., 2021)</ref> and ensemble distillation <ref type="bibr" target="#b15">(Hinton et al., 2015)</ref> of heterogeneous parsers to produce high quality silver data.</p><p>? We offer a Bayesian ensemble interpretation of this technique as alternative to views such as Minimum Bayes Risk decoding <ref type="bibr" target="#b14">(Goel and Byrne, 2000)</ref> and name the technique Maximum Bayes Smatch Ensemble (MBSE).</p><p>? Applied to English monolingual parsing, MBSE distillation yields a new single system state-of-the-art (SoTA) on AMR2.0 (85.9) and AMR3.0 (84.3) test sets.</p><p>? Trained with Structured-mBART 1 , it yields new SoTA for Chinese (63.0), German (73.7), Italian (76.1) and Spanish (77.1) crosslingual parsing.</p><p>? Applied to domain adaptation, MBSE distillation achieves the performance comparable to human annotations of QALD-9 training data and achieves new SoTA on BioAMR test set.</p><p>? We release QALD-9-AMR treebank 2 at, which comprises 408 training and 150 test sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Maximum Bayes Smatch Ensemble</head><p>Ensemble distillation <ref type="bibr" target="#b15">(Hinton et al., 2015)</ref> integrates knowledge of different teacher models into a student model. For sequence to sequence models, e.g. machine translation, it is possible to ensemble models by combining probabilities of words given context at each time step <ref type="bibr" target="#b20">(Kim and Rush, 2016;</ref><ref type="bibr" target="#b13">Freitag et al., 2017)</ref>. Syntactic and semantic parsers model a distribution over graphs that is harder to integrate across teacher models in an optimal way. For particular cases like dependency parsing, it is possible to ensemble teachers based on the notion of edge attachment <ref type="bibr" target="#b24">(Kuncoro et al., 2016)</ref>, which is related to the usual evaluation metric, Label Attachment Score (LAS). However, AMR graphs are quite complex and not explicitly aligned to words. The standard Smatch  metric approximates the NP-Complete problem of aligning nodes across graphs with a hill climbing algorithm. This illustrates the difficulty of achieving consensus across teachers for AMR ensembling. Prior work ensembling AMR graphs has leveraged Smatch directly or its hill climbing strategy for ensembling. The ensemble in <ref type="bibr" target="#b2">(Barzdins and Gosko, 2016)</ref> selects, among a number of candidate AMRs, the one that has the largest average Smatch with respect to all sampled AMRs. The ensemble in <ref type="bibr" target="#b16">(Hoang et al., 2021)</ref>, modifies the candidate AMRs to increase consensus as measured by coverage. Then it selects from the union of original and modified graphs for the one with highest coverage or largest average Smatch. One possible intepretation of both techniques is that of Minimum Bayes Risk (MBR) decoding, a well established method in Automatic Speech Recognition (ASR) <ref type="bibr" target="#b14">(Goel and Byrne, 2000)</ref> and Machine Translation (MT) <ref type="bibr" target="#b23">(Kumar and Byrne, 2004)</ref>. Assuming 2 https://github.com/IBM/AMR-annotations that we have a model predicting a graph from an input sentence p(g | w), normal decoding entails searching among model outputs g for the one that has the highest likelihood according to the model p(g | w). MBR searches instead for the model output that minimizes the risk with respect to the distribution of possible human (gold) outputs for a given input</p><formula xml:id="formula_0">g = arg min g {E p(g h |w) {R(g, g h )}}</formula><p>where p(g h | w) is the distribution of correct human outputs, e.g. given by multiple annotators, and R is a risk function that measures how severe deviations from g h are. In this case risk would be minus Smatch. Since in practice p(g h | w) is not available, MBR takes often the strong assumption of replacing p(g h | w) by the model distribution itself p(g | w).</p><p>Here we suggest another Bayesian interpretation, that requires less strong assumptions than MBR, a Bayesian model ensemble <ref type="table">(Wilson and Iz</ref> <ref type="bibr">mailov, 2020)</ref>. Indeed techniques above can be seen as solvin?</p><formula xml:id="formula_1">g = arg max g?G {E p(M|D) {Smatch(g,g M )}}</formula><p>where p(M | D) is the distribution of models M given training data D, approximated by a sample average of models of different architectures or different random seeds, and</p><formula xml:id="formula_2">g M = post ? ? arg max y ? ? ? |y| t=1 p M (y t | y &lt;t , w) ? ? ? ? ?</formula><p>is the output of a conventional decoding process for each parser prediction distribution p M , including post-processing post(). This process differs across models indexed by M, for example y can be transition actions or linearized graphs and post() running the state-machine or linearized graph post-processing 3 . G is the space of candidate graphs, which in <ref type="bibr" target="#b2">Barzdins and Gosko (2016)</ref> are the AMRs resulting from decoding each sample from p(M | D) and in <ref type="bibr" target="#b16">Hoang et al. (2021)</ref> are those same graphs plus the modified pivot graphs. There is in principle no restriction on how to build the set G. Decoding a graph g ? G means here selecting the member of that set maximizing the expected Smatch and is different from each parser's decoding process.  <ref type="figure">Figure 1</ref>: Data augmentation framework: Given a labeled example in English (e 1 , g 1 ), we use an AMR-to-text generation system to generate an alternative input text? 2 for g 1 following . Given a sentence e 3 , and various state-of-the-art off-the-shelf parser outputs (A, B, C), Maximum Bayes Smatch Ensemble (MBSE) produces a single annotation for each input sentence by selecting from existing AMRs or their modified versions. MBSE is only applied to unlabeled English sentences to produce? 3 . Following <ref type="bibr" target="#b11">(Damonte and Cohen, 2018)</ref>, we translate the English sentences to e.g. Spanish, to yield new training samples (? 1 , g 1 ), (? 2 , g 1 ), (? 3 ,? 3 ) to train a Spanish cross-lingual parser. We use the English pairs (e 1 , g 1 ), (? 2 , g 1 ), (e 3 ,? 3 ) to train an English parser.</p><p>If we replace Smatch() by an indicator function on the decoding outputs 1 g=g M , then</p><formula xml:id="formula_3">g = arg max g?G {E p(M|D) {1 g=g M }}</formula><p>recovers majority voting of AMR graphs. Since the space of graphs is exponentially large on the input size, this would be too sparse to attain meaningful vote counts. The propagation of the uncertainty in p(M | D) through the Smatch() transformation both solves the sparsity problem, and allows optimization on a space that is better related to the target metric. The method will be henceforth described here as Maximum Bayes Smatch Ensemble distillation (MBSE distillation).</p><p>In what follows, we will consider three versions for ensembling, the Smatch version of <ref type="bibr" target="#b16">Hoang et al. (2021)</ref> (graphene-Smatch), the average-Smatch selection of <ref type="bibr" target="#b2">Barzdins and Gosko (2016)</ref>, and a greedy version of <ref type="bibr" target="#b2">Barzdins and Gosko (2016)</ref> where we select the two highest Smatch AMRs and from that pair, keep the graph with the highest Smatch with respect to the remaining graphs (greedy-select). The greedy-select algorithm is given in Algorithm 1 of Appendix A and performs similarly to the average-Smatch of <ref type="bibr" target="#b2">Barzdins and Gosko (2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Silver Training Strategy</head><p>We now describe the AMR silver training strategy proposed in this work. This strategy creates high quality English and cross-lingual AMR annotations for unlabeled data with MBSE and alternative input sentences of gold AMRs via AMR-totext.</p><p>As depicted in <ref type="figure">Fig. 1</ref>, we start with 1) a set of gold-labeled (English sentence, AMR) pairs, 2) a set of unlabeled English sentences and 3) pre-trained English-to-foreign language Machine Translation systems. Assuming N off-the-shelf AMR parsers, we train each of the N parsers using the gold data with their respective training procedure. More than one random seed may be trained for some parsers, leading to more than N AMR parses for each input sentence.</p><p>After the parsers have been trained, we use them to parse the unlabeled English text as in <ref type="bibr" target="#b21">Konstas et al. (2017)</ref>. Interpreting the set of trained models as samples of the model distribution, we apply the MBSE distillation methods described in Section. 2. We apply all variations of the MBSE algorithms including graphene-Smatch, greedy-select and average-Smatch algorithms.</p><p>For English parsers, the MBSE distilled AMR annotations are added to the human-annotated gold treebanks for enhanced model training. For cross-lingual parsers, we translate all English input sentences to the target foreign languages and train respective cross-lingual parsers with pairs of (Foreign language input sentences, AMR graphs in English), following <ref type="bibr" target="#b11">(Damonte and Cohen, 2018)</ref>.</p><p>Following , we also apply an AMR-to-text model <ref type="bibr" target="#b29">(Mager et al., 2020;</ref><ref type="bibr" target="#b36">Ribeiro et al., 2021;</ref><ref type="bibr" target="#b3">Bevilacqua et al., 2021)</ref> to generate additional sentences for human-annotated AMR. We filter out the generated texts if they are too similar (BLEU &gt; 0.9) or too dissimilar (BLEU &lt; 0.1) to the original input texts, as measured by BLEU <ref type="bibr" target="#b34">(Papineni et al., 2002)</ref>. AMR-to-text generation 4 is used for cross-lingual AMR parser training only.</p><p>4 Experimental Setup 4.1 Corpus Statistics and QALD-9-AMR <ref type="table" target="#tab_2">Table 1</ref> details the corpora considered for the standard benchmark experiments on AMR2.0 and AMR3.0 test sets (lef) and out-of-domain data used for domain adaptation experiments (right). Silver indicates the unlabeled data for silver AMR acquisition. SQuAD2.0-Q(uestions) are for QALD-9 (silver q ) and PubMed, BioNLP-2011 <ref type="bibr" target="#b19">(Kim et al., 2011)</ref> and CRAFT <ref type="bibr" target="#b10">(Cohen et al., 2017)</ref> for BioAMR (silver b ).</p><p>Since there were no human annotations of QALD-9 corpus, we created QALD-9-AMR treebank. QALD-9 training/test data have been annotated by 3 skilled resident human annotators with experience in AMR annotations over a year. Each of the annotators annotated both the train and test data sets, followed by cross validation by each other. The final annotations were adjudicated by the most experienced annotator. Inter-annotator agreement (IAA) rate on a subset of 158 training sentences is over 95% in Smatch. The data is made publicly available under an Apache2 license.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Parsing Models</head><p>We use 4 off-the-shelf AMR parsers to parse unannotated raw texts. We train the parsers following their standard configurations.</p><p>APT <ref type="bibr" target="#b55">(Zhou et al., 2021a</ref>) 5 is a transition-based parser that combines hard attention over sentences with a target side action pointer mechanism to decouple source tokens from node representations and address alignments. Cross-attention of all decoder layers is used for action-source alignment.</p><p>SPRING Bevilacqua et al. (2021) 6 fine-tunes BART  to predict linearized AMR graphs, avoiding complex pipelines.</p><p>Structured-BART Zhou et al. (2021b) 7 models the transition-based parser state within a pre-trained BART architecture, outperforming SPRING. This is the main parser for our work.</p><p>AMRBART <ref type="bibr" target="#b0">Bai et al. (2022)</ref>  <ref type="bibr">8</ref> improves the structure awareness of pre-trained BART over AMR graphs by introducing node/edge denoising and sub-graph denoising tasks, for graph-tograph pre-training, achieving significant improvement over previous BART-based systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Structured-mBART</head><p>For cross-lingual AMR parsing, we adapt Structured-BART by replacing the pretrained BART with mBART of , henceforth Structured-mBART. The codebase is made publicly available under an Apache2 license. Structured-mBART diverges from Structured-BART mainly in input processing and vocabulary:</p><p>? For task vocabulary, Structured-mBART in-cludes~250K sentencepiece tokens of <ref type="bibr" target="#b22">(Kudo, 2018)</ref> including 25 language tags, e.g. es_XX, whereas Structured-BART includes 50K BPE tokens of <ref type="bibr" target="#b37">(Sennrich et al., 2016)</ref>.</p><p>? We append the source language tag to the end of each input sentence without specifying the target language tag for Structured-mBART.</p><p>? For Structured-mBART, we set the learning rate to 3e?5, cf. 1e?4 of Structured-BART, and move the layer normalization to the beginning of each transformer block.</p><p>We obtain contextualized embeddings from the pre-trained mBART for multilingual input sentence representations. For target action sequences, we map the sentencepiece tokens to the corresponding target token, by averaging all values from the sentencepiece tokens corresponding to the target token. For German, Italian and Spanish input texts, we apply the tokenizer from JAMR parser 9 before sentencepiece tokenization. For Chinese, we directly apply the sentencepiece tokenizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>To explore the effect of the proposed MBSE distillation and training strategy, we consider an extensive experimental setup including standard English benchmarks (Section 5.1), cross-lingual benchmarks (Section 5.2) and out of domain data   We first provide the performance evaluation of each ensembling technique used in MBSE in Table 2 to demonstrate the effectiveness of the ensemble techniques by themselves. We test the algorithm on the standard test data sets from AMR2.0 and AMR3.0 and three out-of-domain data sets, Q9AMR (QALD-9-AMR), LP (Little Prince) and BioAMR in <ref type="table" target="#tab_2">Table 1</ref>. We consider here only standard English AMR parsing. As expected, all MBSE algorithms, average-Smatch, graphene-Smatch and greedy-select, improve individual models by large margins. Note that while the ensembles outperform single model state-ofthe-art by a large margin, the use of heterogeneous ensembles of models is computationally prohibitive in practice, both due to the cost of run- <ref type="bibr">10</ref> We also applied the technique to APT, observing similar performance gains when using MBSE distillation.</p><formula xml:id="formula_4">20K 386K SQuAD2.0-Q silver q 135K 1.5M SQuAD2.0-C silver 1 70K 2M BioNLP-ST-2011 silver b 15K 460K Ontonotes5.0 silver 2 59K 1.1M CRAFT silver b 27K 740K WikiText-103 silver 3 70K 2M</formula><p>ning different models but also the ensembling techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">English AMR Parsing</head><p>As displayed in <ref type="table" target="#tab_2">Table 1</ref>, we consider the standard AMR2.0 (LDC2017T10) and AMR3.0 (LDC2020T02) treebank as gold data. For ensemble distillation, we use the data sets denoted by silver 1 for comparison with previous work, and silver 2 and silver 3 to investigate the impact of unlabeled corpus size on model performance. For silver 1 , we use all sentence examples in PropBank (LDC2004T14). From SQuAD2.0-C(ontexts) 11 we filter out the~92K sentences, removing bad utf8 encoding (~7K) and ill-formed disconnected graphs produced by APT (~15K). Silver 2 comprises Ontonotes5.0 (LDC2013T19) and silver 3 WikiText-103.</p><p>The results are shown in  To isolate the effect of ensembling, we provide two additional baselines: 1) silver obtained from SPRING, which is expected to have complementary information to self-trained silver, and 2) an equal mixture of SPRING and Structured-BART (random 50:50), which tests if the MBSE selection strategy bears any effect. MBSE distillation outperforms these two baselines by between 0.2 and 0.5 Smatch point, depending on the scenario, proving that MBSE selection has a clear positive effect.</p><p>We also investigate the impact of unlabeled corpus size on model performance by adding silver 2 and silver 3 to silver 1 , i.e. silver 1+2 and silver 1+2+3 . We observe additional 0.3-0.4 improvement, complementary to the one obtainable with conventional ensemble decoding. This pushes the numbers to 85.7 and 84.2, setting a new SoTA for single system with 4 model ensemble (Ensemble-4) distillation. Note that using 5 model ensemble (Ensemble-5) distillation moves the Smatch scores even higher to 85.9 for AMR2.0 and 84.3 for AMR3.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Cross-lingual AMR Parsing</head><p>For cross-lingual AMR parsing, we consider the well known cross-lingual extension of AMR2.0 <ref type="bibr" target="#b11">(Damonte and Cohen, 2018)</ref>. Our cross-lingual parsers are trained with Structured-mBART, always using separate vocabulary (sep-voc). Input sentences of the English training data are machine translated into the target languages with WLT 12 to generate cross-lingual parser training data. <ref type="table">Table 4</ref> shows the results on the human translated AMR2.0 test set, following standard practices.</p><p>We provide results for recently published cross-lingual AMR parsers and different silver training versions of Structured-mBART. Structured-mBART with 4 model ensemble (Ensemble-4) distillation with just silver 1 improves the Smatch score by 2.1 to 2.6 over the Structured-mBART baselines, out-performing very strong previous SoTA from <ref type="bibr" target="#b6">(Cai et al., 2021a)</ref> on Chinese and Spanish and tied on Italian. Increasing the input sentence diversity via AMRto-text generation and ensemble decoding further improve the system performances, attaining new cross-lingual SoTA on all four languages. Increasing the silver training data size to silver 1+2+3 and using 5 model ensemble (Ensemble-5) push the numbers higher by 0.2-0.5 Smatch points. <ref type="bibr" target="#b40">(Uhrig et al., 2021)</ref> report that translateand-parse pipelines outperform the conventional cross-lingual parsers, we thus include translateand-parse from the combination of WLT and Structured-BART + MBSE distillation. This out-performs the cross-lingual parsers by 0.6-1.0 Smatch on all languages except for Spanish, when trained with the same MBSE avg.-Smatch silver 1+2+3 data.</p><p>Comparing the fine-grained F1 scores for crosslingual parsers with those for English, as shown in <ref type="table" target="#tab_9">Table 5</ref>, we observe that cross-lingual parsers are particularly worse than English for negation. For instance, German negations are often realized as a compound, as in nichttarif?re (non -tariff), which is aligned to the non-negated stem portion of the concept tariff, losing its negation meaning. We observe similar issues in English with prefixed negations such as unhappy, inadequate, atypical. 12 https://www.ibm.com/cloud/watson-language-translator</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Domain Adaptation</head><p>We use the AMR2.0 version of BioAMR (medical domain) as this has clearly defined partitions 13 and was used in <ref type="bibr" target="#b3">Bevilacqua et al. (2021)</ref>. We also use QALD-9-AMR, constructed from QALD-9 data 14 <ref type="bibr" target="#b41">(Usbeck et al., 2018)</ref>, a corpus of natural language questions for executable semantic parsing <ref type="bibr">(Kapanipathi et al., 2021)</ref>. Corpus statistics of the domain adaptation data is summarized in <ref type="table" target="#tab_2">Table 1</ref>. <ref type="table" target="#tab_11">Table 6</ref> shows the experimental results. Results for SPRING are taken from <ref type="bibr" target="#b3">Bevilacqua et al. (2021)</ref>. For each test set, we report the results under three different training conditions, all of which include either AMR2.0 or AMR3.0 treebank in the training data: (1) use only silver data with MBSE distillation, (2) use only domain gold sentences, (3) use both silver data and domain gold sentences. Since BioAMR is annotated in AMR2.0 style and QALD-9-AMR in AMR3.0 style, we use the corresponding Structured-BART models as indicated in the table.</p><p>As for BioAMR data, MBSE distillation (with both graphene-Smatch and greedy-select) on silver b -comprising PubMed (LDC2008T20, LDC2008T21), BioNLP-ST-2011 and CRAFTimproves over the Structured-BART baseline by 6.5 Smatch point (60.4 vs. 66.9). However, adding just 201 domain gold sentences to AMR2.0 treebank results in 11.9 Smatch point improvement over the baseline <ref type="bibr">(60.4 vs. 72.3)</ref>. A close inspection shows that this is largely due to the NER score improvement, as shown in the column under NER, i.e. NER score 27.0 in Structured-BART (AMR2.0) vs. 68.0 after adding 201 domain gold sentences. The dramatic impact of NE coverage no longer holds when we double the domain gold sentences from 201 to 403. In fact, MBSE greedyselect silver b + 201 domain gold sentences (75.8) is more effective than doubling the domain gold sentences (74.3). Finally, by combining MBSE distillation on silver b with 5K domain gold sentences, the system achieves 81.3 Smatch, outperforming the previous SoTA by 1.4.</p><p>Regarding QALD-9-AMR data, MBSE distillation on silver q , i.e. SQuAD-Q(uestion) sentences, is almost as effective as 408 domain gold sentences <ref type="formula">(</ref>   domain gold sentences with MBSE greedy-select silver q adds less than 1 Smatch point to 90.1. Since MBSE distillation on silver b lags behind the performance of 201 human annotated AMR for BioAMR, mostly due to low NER scores, we further analyze the target vocabulary coverage of named entity (NE) types occurring in the test sets. The analysis is shown in <ref type="table" target="#tab_12">Table 7</ref>. NE types are equally well covered in all models for Q9AMR (QALD-9-AMR). 0.7% out-of-vocabulary (OOV) ratio is caused by a typo in human annotation of the test set, i.e. country misspelled as countrty. For BioAMR, however, NE type OOV ratio of MBSE silver model is 3.7%, e.g. proteinsegment, macro-molecular-complex, substantially higher than 0.6% of the model trained with 201 domain gold sentences. When the NE type is OOV, there is no chance for the system to produce the missing NE type, let alone predicting it correctly, underscoring the challenges posed by domain specific concepts unavailable elsewhere.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Work</head><p>There have been numerous works applying ensemble/knowledge distillation <ref type="bibr" target="#b15">(Hinton et al., 2015)</ref> to machine translation <ref type="bibr" target="#b20">(Kim and Rush, 2016;</ref><ref type="bibr" target="#b13">Freitag et al., 2017;</ref><ref type="bibr" target="#b32">Nguyen et al., 2020;</ref><ref type="bibr" target="#b46">Wang et al., 2020</ref>, dependency parsing <ref type="bibr" target="#b24">(Kuncoro et al., 2016)</ref> and question answering <ref type="bibr" target="#b30">(Mun et al., 2018;</ref><ref type="bibr" target="#b52">Ze et al., 2020;</ref><ref type="bibr" target="#b51">You et al., 2021;</ref><ref type="bibr" target="#b9">Chen et al., 2012)</ref>. Regarding ensembling AMR graphs, <ref type="bibr" target="#b2">Barzdins and Gosko (2016)</ref> propose choosing the AMR with highest average sentence Smatch to all other AMRs. <ref type="bibr" target="#b16">Hoang et al. (2021)</ref> proposed a more complex technique capable of building new AMRs by exploiting Smatch's hill climbing algorithm. Our work brings together ensemble distillation and Smatchbased ensembling and shows that it can provide substantial gains over the standard self-training. <ref type="bibr" target="#b11">Damonte and Cohen (2018)</ref> show that it may be possible to use the original AMR annotations devised for English as representations of equivalent sentences in other languages. <ref type="bibr" target="#b11">Damonte and Cohen (2018)</ref>; <ref type="bibr" target="#b38">Sheth et al. (2021)</ref> propose annotation projection of English AMR graphs to target languages to train cross-lingual parsers, using word alignments. <ref type="bibr" target="#b4">Blloshmi et al. (2020)</ref> show that one may not need alignment-based parsers for crosslingual AMR, and model concept identification as a seq2seq problem. <ref type="bibr" target="#b35">Procopio et al. (2021)</ref>   fine-tuned on pretrained-mBART with an MNMT objective. <ref type="bibr" target="#b8">Cai et al. (2021b)</ref> propose to use bilingual input to enable a model to predict more ac-   curate AMR concepts. <ref type="bibr" target="#b50">Xu et al. (2021)</ref> propose a cross-lingual pretraining approach via multitask learning for AMR parsing. <ref type="bibr" target="#b6">Cai et al. (2021a)</ref> propose to use noisy knowledge distillation for multilingual AMR parsing. We introduce Structured-mBART and attain new SoTA in Chinese, German, Italian and Spanish cross-lingual parsing by applying MBSE distillation and AMR-to-text. We subsume domain adaptation under data augmentation with MBSE distillation, where the only difference between the two lies in the properties of the unlabeled data. The unlabeled data is drawn from the target domain for the purpose of domain adaptation rather than those similar to the source training data for data augmentation in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We proposed a technique called Maximum Bayes Smatch Ensemble (MBSE) distillation, which brings together Smatch-based model ensembling <ref type="bibr" target="#b2">Barzdins and Gosko (2016);</ref><ref type="bibr" target="#b16">Hoang et al. (2021)</ref> and ensemble distillation <ref type="bibr" target="#b15">Hinton et al. (2015)</ref> of heterogeneous parsers, to significantly improve AMR parsing. The technique generalizes well across various tasks and is highly effective, leading to a new single system SoTA in English and cross-lingual AMR parsing and achieving the performance comparable to human annotated training data in domain adaptation of QALD-9-AMR corpus. Remaining technical challenges include tokenization and alignment of an input token corresponding to more than one concept for AMR parsing and identification of unknown named entities and their types for domain adaptation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Greedy-Select Ensemble Algorithm</head><p>Algorithm 1: Greedy-Select MBSE Algorithm and Corpus Selection Input: AMR 1 ...AMR n parses from n AMR parsing models, where n ? 3 Optionally Require: Smatch score threshold = ? Output: One-best AMR parse 1: Let bestAMR = N U LL 2: for ? i,j in 1 ? i, j ? n and i = j do 3:</p><p>Compute sentence Smatch score smatch(AMR i , AMR j ), total n(n ? 1)/2 scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Pick the highest smatch(AMR i , AMR j ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>for Each AMR a , where a = i or a = j do end for 17: end for 18: return bestAMR We start with n parses from n heterogeneous parsing models, where the minimum number of parses is 3. For each input sentence, we compute sentence-level Smatch scores between any two parses across all n parses, for a total of n(n ? 1)/2 Smatch scores (lines 2-3). Subsequently, we pick the two parses AMR i and AMR j with the highest Smatch score, where AMR i denotes the AMR parse from the system i (line 4) For each of the two parses, AMR i and AMR j , we choose the parse with the higher Smatch score against the rest of the parses as the best parse (lines 5-11). When the scores are tied, we select the first parse output (equivalent to a random choice of fixed seed).</p><p>We incorporate an optional parse selection criterion into Algorithm 1, indicated as Optionally Require and specified in lines 12-15. The bestAMR for input sentence is selected for data augmentation if the Smatch score smatch(AMR a , AMR b ) is greater than or equal to the pre-specified value   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Model Structures and Parameter Size</head><p>Pre-trained BART and mBART share the same model configurations except for the vocabulary size. There are 12 encoder/decoder layers, 16 heads per layer, 1024 model dimension and 4096 feed forward network (FFN) size. BART includes 50K and mBART,~250K task vocabulary. When using separate vocabulary (sep-voc), Structured-BART and Structured-mBART use the same vocabulary as BART and mBART, respectively, for the source. For the target, they create embedding vectors for action symbols and the target vocabulary size vary according to the training data. When using joint vocabulary (joint-voc), Structured-BART shares the same vocabulary between the source and the target, a combination of BART vocabulary and the additional embedding vectors for some action symbols.</p><p>Vocabulary and parameter sizes for Structured-BART and Structured-mBART trained with MBSE distillation are shown in <ref type="table" target="#tab_15">Table 9</ref> and Table 10, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Implementation Details</head><p>Our models are implemented with FAIRSEQ toolkit <ref type="bibr" target="#b33">(Ott et al., 2019)</ref>, trained and tested on a single NVIDIA Tesla A100/V100 GPU with 40-80GB memory. We use fp16 mixed precision training and all models are trained on 1 GPU.   For all English AMR parsing models with silver data, we use the Adam optimizer with ? 1 = 0.9 and ? 2 = 0.98. Batch size is set to 1024 maximum number of tokens with gradient accumulation over 8 steps. Learning rate schedule is the same as <ref type="bibr" target="#b44">Vaswani et al. (2017)</ref> with 4000 warm-up steps and 1e?7 warm-up initial learning rate and the maximum learning rate 1e?4. Dropout rate is 0.2 and label smoothing rate is 0.01. These hyper parameters are fixed and not tuned for different models and datasets. All models are trained for 10 epochs and the best 5 checkpoints are selected based on the development set Smatch from greedy decoding. Model parameters are averaged over the top 3 and top 5 models. The model that produces the highest development set score, after beam search decoding with beam size = 1, 5 and 10, is selected as the final model. Training with MBSE greedy-select silver 1+2+3 takes 48-72 hours, and all other models with less silver data take less time to train.</p><p>For cross-lingual AMR parsing, maximum learning rate is always set to 3e?5. Baseline models trained only on AMR2.0 corpus are trained up to 80 epochs whereas models with silver 1 (and AMR-to-text) is trained up to 30 epochs and models with silver 1+2+3 , up to 15 epochs. Model parameters are updated after gradient is accumulated for 8192 tokens. Dropout rate, label smooth-ing rate and model selection criteria are the same as the English parsers. Training baseline models takes about 10 hours. Training with silver 1 takes about 24 hours. Training with silver 1+2+3 takes about 96-120 hours. In order to reduce the vocabulary size, which subsequently reduces the model parameter size and memory requirement, we prune out singleton target vocabulary for training with silver data.</p><p>Inference time for AMR2.0 benchmark test set is shown in <ref type="table" target="#tab_2">Table 11</ref>, where beam size=10 and batch size=64 for all languages. EN is decoded</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>4: Cross-lingual parser Smatch scores on AMR2.0 human translated test sets. mBART mt of Procopio et al. (2021) indicates the mBART model fine-tuned on both semantic parsing tasks and the MT data. mBARTmmt of Cai et al. (2021a) indicates an NMT model by (Tang et al., 2020), trained from mBART covering 50 languages. Shortnames: MBSE-G (greedy-selection), MBSE-A (average-Smatch) 'ens. dec.', ensemble decoding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>smatch(AMR a , AMR b )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Corpus statistics for the standard benchmark experiments on AMR2.0 and AMR3.0 test sets (left) and domain adaptation experiments (right). Silver indicates the unlabeled data for silver training.</figDesc><table><row><cell>Models</cell><cell cols="5">AMR2.0 AMR3.0 Q9AMR LP BioAMR</cell></row><row><cell>APT (Zhou et al., 2021a)</cell><cell>83.0</cell><cell>81.1</cell><cell>83.7</cell><cell>79.0</cell><cell>55.2</cell></row><row><cell>Structured-BART (Zhou et al., 2021b)</cell><cell>84.6</cell><cell>83.1</cell><cell>87.7</cell><cell>81.0</cell><cell>62.4</cell></row><row><cell>SPRING 1 (Bevilacqua et al., 2021)</cell><cell>84.2</cell><cell>83.2</cell><cell>87.7</cell><cell>81.3</cell><cell>61.6</cell></row><row><cell>SPRING 2 (Bevilacqua et al., 2021)</cell><cell>83.8</cell><cell>82.9</cell><cell>86.4</cell><cell>81.0</cell><cell>60.5</cell></row><row><cell>AMRBART (Bai et al., 2022)</cell><cell>85.4</cell><cell>84.2</cell><cell>88.0</cell><cell>82.3</cell><cell>63.4</cell></row><row><cell>aver.-Smatch (A) (Barzdins and Gosko, 2016)</cell><cell>86.2</cell><cell>84.9</cell><cell>89.0</cell><cell>82.9</cell><cell>64.1</cell></row><row><cell>graphene-Smatch (P) (Hoang et al., 2021)</cell><cell>86.7</cell><cell>85.4</cell><cell>89.3</cell><cell>83.1</cell><cell>65.8</cell></row><row><cell>greedy-select (G)</cell><cell>85.9</cell><cell>84.8</cell><cell>88.8</cell><cell>82.8</cell><cell>63.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>English parsing performance in Smatch in general domain and domain adaptation for recent state-of-theart systems (top). Performance in Smatch for the ensemble of all systems using different Smatch-based ensembling techniques (bottom). SPRING 1 and SPRING 2 are 2 random seeds of the same model. Highest scores are boldfaced.</figDesc><table /><note>sets (Section 5.3). 10 For model training and selec- tion details, see Appendix B and Appendix C.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>The lower</figDesc><table><row><cell>Models</cell><cell>silver</cell><cell cols="2">AMR2.0</cell><cell>AMR3.0</cell><cell></cell></row><row><cell>Naseem et al. (2019)</cell><cell></cell><cell cols="2">75.5</cell><cell>-</cell><cell></cell></row><row><cell>Zhang et al. (2019a)</cell><cell></cell><cell cols="2">76.3?0.1</cell><cell>-</cell><cell></cell></row><row><cell>Zhang et al. (2019b)</cell><cell></cell><cell cols="2">77.0?0.1</cell><cell>-</cell><cell></cell></row><row><cell>Cai and Lam (2020)</cell><cell></cell><cell cols="2">80.2</cell><cell>-</cell><cell></cell></row><row><cell>Fernandez Astudillo et al. (2020)</cell><cell></cell><cell cols="2">80.2?0.0</cell><cell>-</cell><cell></cell></row><row><cell>Lyu et al. (2020)</cell><cell></cell><cell>-</cell><cell></cell><cell>75.8</cell><cell></cell></row><row><cell>Lee et al. (2020)</cell><cell>85K</cell><cell cols="2">81.3?0.0</cell><cell>-</cell><cell></cell></row><row><cell>Xu et al. (2020)</cell><cell>14M</cell><cell cols="2">81.4</cell><cell>-</cell><cell></cell></row><row><cell>Bevilacqua et al. (2021)</cell><cell>200K</cell><cell cols="2">84.5</cell><cell>83.0</cell><cell></cell></row><row><cell>Zhou et al. (2021a)</cell><cell>70K</cell><cell cols="2">82.6?0.1</cell><cell>80.3</cell><cell></cell></row><row><cell>Xia et al. (2021)</cell><cell>1.8M</cell><cell cols="2">84.2</cell><cell>-</cell><cell></cell></row><row><cell>Bai et al. (2022)</cell><cell>200K</cell><cell cols="2">85.4</cell><cell>84.2</cell><cell></cell></row><row><cell>Zhou et al. (2021b)</cell><cell></cell><cell cols="2">sep-voc joint-voc</cell><cell>sep-voc</cell><cell>joint-voc</cell></row><row><cell>Structured-BART-baseline</cell><cell></cell><cell cols="2">84.0?0.1 84.2?0.1</cell><cell>82.3?0.0</cell><cell>82.0?0.0</cell></row><row><cell>+ self-trained silver 1</cell><cell>90K</cell><cell>-</cell><cell>84.7?0.1</cell><cell>82.7?0.1</cell><cell>82.6?0.0</cell></row><row><cell>+ self-trained silver 1 + ensemble dec.</cell><cell>90K</cell><cell>-</cell><cell>84.9</cell><cell>83.1</cell><cell>-</cell></row><row><cell>Ours below (Struct-BART)</cell><cell></cell><cell cols="2">sep-voc joint-voc</cell><cell>sep-voc</cell><cell>joint-voc</cell></row><row><cell>+ SPRING silver 1</cell><cell cols="3">90K 84.8?0.1 84.8?0.0</cell><cell>83.0?0.0</cell><cell>83.2?0.1</cell></row><row><cell cols="4">+ SPRING + self-trained silver 1 (50:50) 90K 84.8?0.1 84.7?0.0</cell><cell>83.0?0.0</cell><cell>83.2?0.1</cell></row><row><cell cols="4">Ensemble-4 distillation (APT + Structured-BART + SPRING 1 + SPRING 2 )</cell><cell></cell><cell></cell></row><row><cell>+ MBSE-P silver 1</cell><cell cols="3">90K 85.1?0.1 85.1?0.1</cell><cell>83.2?0.1</cell><cell>83.5?0.1</cell></row><row><cell>+ MBSE-G silver 1</cell><cell cols="3">90K 85.0?0.0 85.2?0.1</cell><cell>83.4?0.0</cell><cell>83.5?0.0</cell></row><row><cell>+ MBSE-G silver 1+2</cell><cell cols="3">149K 85.3?0.1 85.4?0.1</cell><cell>83.6?0.1</cell><cell>83.7?0.1</cell></row><row><cell>+ MBSE-G siver 1+2+3</cell><cell cols="3">219K 85.3?0.1 85.5?0.1</cell><cell>83.7?0.0</cell><cell>83.9?0.0</cell></row><row><cell cols="2">+ MBSE-G silver 1+2+3 + ensemble dec. 219K</cell><cell>85.6</cell><cell>85.7</cell><cell>84.0</cell><cell>84.2</cell></row><row><cell cols="5">Ensemble-5 distillation (APT + Structured-BART + SPRING 1 + SPRING 2 + AMRBART)</cell><cell></cell></row><row><cell>+ MBSE-A silver 1</cell><cell>90K</cell><cell></cell><cell>85.3?0.1</cell><cell></cell><cell>83.6?0.1</cell></row><row><cell>+ MBSE-A silver 1+2</cell><cell>149K</cell><cell></cell><cell>85.5?0.0</cell><cell></cell><cell>84.0?0.0</cell></row><row><cell>+ MBSE-A silver 1+2+3</cell><cell>219K</cell><cell></cell><cell>85.7?0.0</cell><cell></cell><cell>84.1?0.0</cell></row><row><cell cols="2">+ MBSE-A silver 1+2+3 + ensemble dec. 219K</cell><cell></cell><cell>85.9</cell><cell></cell><cell>84.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell>sil-</cell></row></table><note>Smatch scores on AMR2.0 and AMR3.0 test data. Lower rows show Structured-BART performances with various silver data augmentations. sep-voc denotes separate vocabulary and joint-voc, joint vocabulary. The numbers prefixed by ? indicate the standard deviation of Smatch scores across 3 seeds.part of the table (denoted by Ours) compares the performances of Structured-BART in various</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>: Fine-grained F1 scores on the AMR2.0 test set for EN (English), DE (German), ES (Spanish), IT (Italian)</cell></row><row><cell>and ZH (Chinese). EN-mono denotes English mono-lingual parser, {DE,ES,IT,ZH}-cross, cross-lingual parsers</cell></row><row><cell>and {DE,ES,IT,ZH}-pipeline, translate-and-parse pipeline.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>: Smatch scores on BioAMR and QALD-9</cell></row><row><cell>test sets with varying sizes of human annotated (gold)</cell></row><row><cell>domain sentences and silver data. MBSE-G (greedy-</cell></row><row><cell>select) and MBSE-P (Graphene-Smatch respectively).</cell></row><row><cell>MBSE distillations are all with Ensemble-4 (APT +</cell></row><row><cell>Structured-BART + SPRING 1 + SPRING 2 ).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell>: Named entity (NE) type out-of-vocabulary</cell></row><row><cell>ratio w.r.t the target vocabulary of various models.</cell></row><row><cell>BioAMR and QALD-9 test sets include 1691 and 150</cell></row><row><cell>occurrences of named entities, respectively.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell cols="4">: Distribution of individual model parses from</cell></row><row><cell cols="4">MBSE greedy-select distillation with silver 1 dataset in</cell></row><row><cell>Table 1</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell>Param</cell><cell>AMR2.0</cell><cell>AMR3.0</cell></row><row><cell></cell><cell>src voc size</cell><cell>50,265</cell><cell>50,265</cell></row><row><cell>sep-voc</cell><cell>tgt voc size</cell><cell>42,344</cell><cell>42,784</cell></row><row><cell></cell><cell># param</cell><cell cols="2">493,011,968 493,913,088</cell></row><row><cell cols="2">joint-voc joint voc size</cell><cell>57,912</cell><cell>58,673</cell></row><row><cell></cell><cell># param</cell><cell cols="2">414,121,984 414,901,248</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 9</head><label>9</label><figDesc></figDesc><table><row><cell>: Vocabulary and parameter sizes of Structured-</cell></row><row><cell>BART with MBSE distillation on silver 1+2+3 dataset</cell></row><row><cell>from Table 1</cell></row><row><cell>?.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 10 :</head><label>10</label><figDesc>Target vocabulary (sep-voc) and parameter sizes of Structured-mBART with MBSE distillation on silver 1+2+3 dataset from Table 1. Source vocabulary size is 250,027 across all languages.</figDesc><table><row><cell>Lgs.</cell><cell>vocab</cell><cell cols="2">base model ens. model</cell></row><row><cell>EN</cell><cell>joint-voc</cell><cell>60min</cell><cell>60min</cell></row><row><cell>DE</cell><cell>sep-voc</cell><cell>23min</cell><cell>42min</cell></row><row><cell>ES</cell><cell>sep-voc</cell><cell>24min</cell><cell>44min</cell></row><row><cell>IT</cell><cell>sep-voc</cell><cell>22min</cell><cell>40min</cell></row><row><cell>ZH</cell><cell>sep-voc</cell><cell>30min</cell><cell>60min</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 11 :</head><label>11</label><figDesc>Inference time for AMR2.0 test set. Base models are trained on AMR2.0 treebank only and ens. models are trained on AMR2.0 treebank plus silver 1+2+3 .</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/IBM/transition-amr-parser/tree/structured-mbart</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We consider only auto-regressive models in this work but this approach could also encompass e.g. graph-based parsers.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We use https://github.com/SapienzaNLP/spring. 5 github.com/IBM/transition-amr-parser/tree/action-pointer, Apache2 License 6 github.com/SapienzaNLP/spring, CC BY-NC-SA 4.0 7 github.com/IBM/transition-amr-parser, Apache2 License</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">https://github.com/muyeby/AMRBART, MIT License 9 https://github.com/jflanigan/jamr</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">https://rajpurkar.github.io/SQuAD-explorer/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">amr.isi.edu/download/2016-03-14/amr-release-trainingbio.txt, amr-release-dev-bio.txt, amr-release-test-bio.txt 14 https://github.com/ag-sc/QALD</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Graph pre-training for AMR parsing and generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuefeng</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2022" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Abstract Meaning Representation for sembanking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Banarescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Bonial</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madalina</forename><surname>Georgescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename><surname>Griffitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Hermjakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse</title>
		<meeting>the 7th Linguistic Annotation Workshop and Interoperability with Discourse<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="178" to="186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Riga at semeval-2016 task 8: Impact of smatch extensions and character-level neural machine translation on amr parsing accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guntis</forename><surname>Barzdins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Didzis</forename><surname>Gosko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of SemEval-2016</title>
		<meeting>SemEval-2016</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1143" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">One spring to rule them both: Symmetric amr semantic parsing and generation without a complex pipeline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Bevilacqua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rexhina</forename><surname>Blloshmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Technical Track on Speech and Natural Language Processing I</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="12564" to="12573" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">XL-AMR: Enabling cross-lingual AMR parsing with transfer learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rexhina</forename><surname>Blloshmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rocco</forename><surname>Tripodi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2487" to="2500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Amr parsing via graph sequence iterative inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1290" to="1301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multilingual amr parsing with noisy knowledge distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jackie</forename><surname>Chun-Sing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidong</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2778" to="2789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Smatch: an evaluation metric for semantic feature structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="748" to="752" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Making better use of bilingual information for cross-lingual amr parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yitao</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1537" to="1547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Cross-domain knowledge distillation for retrieval-based question answering systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghui</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehong</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linbo</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the World Wide Web Conference</title>
		<meeting>the World Wide Web Conference</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The colorado richly annotated full text (craft) corpus: multi-model annotation in the biomedical domain. Handbook of Linguistic Annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Funk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Hunter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1379" to="1394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cross-lingual Abstract Meaning Representation parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Damonte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1146" to="1155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Transition-based parsing with stacktransformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramon</forename><surname>Fernandez Astudillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Blodgett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Associtation for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1001" to="1007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Ensemble distillation for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Al-Onaizan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baskaran</forename><surname>Sankaran</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01802</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Minimum bayes-risk automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaibhava</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="135" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Ensembling graph prediction for amr parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thanh</forename><forename type="middle">Lam</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Picco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufang</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Suk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzung</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vanessa</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramon</forename><forename type="middle">Fernandez</forename><surname>L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Astudillo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.09131</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><surname>Kapanipathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ibrahim</forename><surname>Abdelaziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><surname>Ravishankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ram?n</forename><surname>Fernandez Astudillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristina</forename><surname>Cornelio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saswati</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Achille</forename><surname>Fokoue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinesh</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfio</forename><surname>Gliozzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sairam</forename><surname>Gurajada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hima</forename><surname>Karanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naweed</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinesh</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Suk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Luus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ndivhuwo</forename><surname>Makondo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nandana</forename><surname>Mihindukulasooriya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Neelam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucian</forename><surname>Popa</surname></persName>
		</author>
		<imprint>
			<pubPlace>Ryan Riegel</pubPlace>
		</imprint>
	</monogr>
	<note>Revanth Gangi Reddy</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Leveraging Abstract Meaning Representation for knowledge base question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaetano</forename><surname>Rossiello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Udit</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G P Shrivatsa</forename><surname>Bhargav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.339</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3884" to="3894" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Overview of bionlp shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Dong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bossy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngan</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of BioNLP Shared Task 2011 Workshop</title>
		<meeting>BioNLP Shared Task 2011 Workshop</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sequencelevel knowledge distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1317" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural AMR: Sequence-to-sequence models for parsing and generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Konstas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivasan</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1014</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="146" to="157" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Subword regularization: Improving neural network translation models with multiple subword candidates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics (Long Papers)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="66" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Minimum bayes-risk decoding for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shankar</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">; Johns Hopkins Univ Baltimore Md</forename><surname>Center For</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Speech Processing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>CLSP</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distilling an ensemble of greedy dependency parsers into one mst parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adhiguna</forename><surname>Kuncoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1744" to="1753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pushing the limits of amr parsing with self-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Suk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramon</forename><surname>Fernandez Astudillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Revanth</forename><surname>Gangi Reddy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the EMNLP2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3208" to="3214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bart: Denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceesings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>eesings of the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7871" to="7880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Multilingual denoising pre-training for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marjan</forename><surname>Ghazvininejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.08210</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A differentiable relaxation of graph segmentation and alignment for amr parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunchuan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Titov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12676</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">GPT-too: A language-model-first approach for AMR-to-text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Mager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ram?n</forename><surname>Fernandez Astudillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arafat</forename><surname>Md</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Suk</forename><surname>Sultan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roukos</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.167</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1846" to="1852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning to specialize with knowledge distillation for visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghwan</forename><surname>Mun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kimin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32nd Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Rewarding smatch: Transition-based amr parsing with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4586" to="4592" />
		</imprint>
	</monogr>
	<note>Radu Florian, Salim Roukos, and Miguel Ballesteros</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Data diversification: A simple strategy for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan-Phi</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shafiq</forename><surname>Joty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename><surname>Kui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ai</forename><forename type="middle">Ti</forename><surname>Aw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">34th Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fairseq: A fast, extensible toolkit for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2019: Demonstrations</title>
		<meeting>NAACL-HLT 2019: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="48" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bleu: a method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sgl: Speaking the graph languages of semantic parsing via multilingual translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><surname>Procopio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rocco</forename><surname>Tripodi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="325" to="337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Investigating pretrained language models for graph-to-text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Leonardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Sch?tze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Workshop on Natural Language Processing for Conversational AI</title>
		<meeting>the Third Workshop on Natural Language Processing for Conversational AI</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="211" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bootstrapping multilingual amr with contextual word alignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janaki</forename><surname>Sheth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Suk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramon</forename><surname>Fernandez Astudillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="394" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chau</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng-Jen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishrav</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.00401</idno>
		<title level="m">Multilingual translation with extensible multilingual pretraining and finetuning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Translate, then parse! a strong baseline for cross-lingual amr parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Uhrig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Yoalli Rezepka Gar?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anette</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th International Conference on Parsing Technologies (IWPT 2021)</title>
		<meeting>the 17th International Conference on Parsing Technologies (IWPT 2021)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="58" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Usbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ria</forename><forename type="middle">Hari</forename><surname>Gusmita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhamad</forename><surname>Saleem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel-Cyrille Ngonga</forename><surname>Ngomo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>9th challenge on question answering over linked data (qald-</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<title level="m">Joint proceedings of the 4th Workshop on Semantic Deep Learning (SemDeep-4) and NLIWoD4</title>
		<imprint>
			<biblScope unit="volume">2241</biblScope>
			<biblScope unit="page" from="58" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Neural semantic parsing by character-based translation: Experiments with abstract meaning representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Van Noord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Bos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.09980</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Selective knowledge distillation for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fusheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhao</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6456" to="6466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Transductive ensemble learning for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiren</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6291" to="6298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Bayesian deep learning and a probabilistic perspective of generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08791</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Stacked amr parsing with silver data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingrong</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="4729" to="4738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Improving amr parsing with sequence-to-sequence pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongqin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhua</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2501" to="2511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Xlpt-amr: Cross-lingual pretraining via multi-task learning for zero-shot amr parsing and text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongqin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhua</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="896" to="907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Knowledge distillation for improved accuracy in spoken question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyu</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuexian</forename><surname>Zou</surname></persName>
		</author>
		<idno>ICASSP 2021</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Model compression with twostage multi-teacher knowledge distillation for web question answering system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Ze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjun</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wutao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirteenth ACM International Conference on Web Search and Data Mining</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Amr parsing as sequence-tograph transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xutai</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="80" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Broad-coverage semantic parsing as transduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xutai</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLPIJC-NLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLPIJC-NLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3784" to="3796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Amr parsing with action-pointer transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramon</forename><surname>Fernandez Astudillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="5585" to="5598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Structure-aware fine-tuning of sequence-to-sequence transformers for transitionbased amr parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tahira</forename><surname>Naseem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramon</forename><forename type="middle">Fernandez</forename><surname>Astudillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young-Suk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6279" to="6290" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
