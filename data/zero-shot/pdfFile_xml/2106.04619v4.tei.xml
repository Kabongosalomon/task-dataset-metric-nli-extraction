<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julius</forename><surname>Von K?gelgen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems T?bingen</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Sharma</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">T?bingen AI Center</orgName>
								<orgName type="institution">University of T?bingen</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">IMPRS for Intelligent Systems 5 Amazon</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><surname>Gresele</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems T?bingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">T?bingen AI Center</orgName>
								<orgName type="institution">University of T?bingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems T?bingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Besserve</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Max Planck Institute for Intelligent Systems T?bingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
						</author>
						<title level="a" type="main">Self-Supervised Learning with Data Augmentations Provably Isolates Content from Style</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Self-supervised representation learning has shown remarkable success in a number of domains. A common practice is to perform data augmentation via hand-crafted transformations intended to leave the semantics of the data invariant. We seek to understand the empirical success of this approach from a theoretical perspective. We formulate the augmentation process as a latent variable model by postulating a partition of the latent representation into a content component, which is assumed invariant to augmentation, and a style component, which is allowed to change. Unlike prior work on disentanglement and independent component analysis, we allow for both nontrivial statistical and causal dependencies in the latent space. We study the identifiability of the latent representation based on pairs of views of the observations and prove sufficient conditions that allow us to identify the invariant content partition up to an invertible mapping in both generative and discriminative settings. We find numerical simulations with dependent latent variables are consistent with our theory. Lastly, we introduce Causal3DIdent, a dataset of high-dimensional, visually complex images with rich causal dependencies, which we use to study the effect of data augmentations performed in practice.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Learning good representations of high-dimensional observations from large amounts of unlabelled data is widely recognised as an important step for more capable and data-efficient learning systems <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b71">72]</ref>. Over the last decade, self-supervised learning (SSL) has emerged as the dominant paradigm for such unsupervised representation learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b89">90,</ref><ref type="bibr" target="#b90">91,</ref><ref type="bibr">115,</ref><ref type="bibr">122,</ref><ref type="bibr">125,</ref><ref type="bibr">126]</ref>. The main idea behind SSL is to extract a supervisory signal from unlabelled observations by leveraging known structure of the data, which allows for the application of supervised learning techniques. A common approach is to directly predict some part of the observation from another part (e.g., future from past, or original from corruption), thus forcing the model to learn a meaningful representation in the process. While this technique has shown remarkable success in natural language processing <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b83">84,</ref><ref type="bibr" target="#b85">86,</ref><ref type="bibr" target="#b94">95,</ref><ref type="bibr" target="#b98">99]</ref> and speech recognition <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b99">100,</ref><ref type="bibr" target="#b103">104]</ref>, where a finite dictionary allows one to output a distribution over the missing part, such predictive SSL methods are not easily applied to continuous or high-dimensional domains such as vision. Here, a common approach is to learn a joint embedding of similar observations or views such that their representation is close <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b43">44]</ref>. Different views can come, for example, from different modalities (text &amp; speech; video &amp; audio) or time points. As still images lack such multi-modality or temporal structure, recent advances in representation learning have relied on generating similar views by means of data augmentation.</p><p>In order to be useful, data augmentation is thought to require the transformations applied to generate additional views to be generally chosen to preserve the semantic characteristics of an observation, while changing other "nuisance" aspects. While this intuitively makes sense and has shown remarkable empirical results, the success of data augmentation techniques in practice is still not very well understood from a theoretical perspective-despite some efforts <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b27">28]</ref>. In the present work, we seek to better understand the empirical success of SSL with data augmentation by formulating the generative process as a latent variable model (LVM) and studying identifiability of the representation, i.e., under which conditions the ground truth latent factors can provably be inferred from the data <ref type="bibr" target="#b76">[77]</ref>.</p><p>Related work and its relation to the current. Prior work on unsupervised representation learning from an LVM perspective often postulates mutually independent latent factors: this independence assumption is, for example, at the heart of independent component analysis (ICA) <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b55">56]</ref> and disentanglement <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b70">71]</ref>. Since it is impossible to identify the true latent factors without any supervisory signal in the general nonlinear case <ref type="bibr" target="#b56">[57,</ref><ref type="bibr" target="#b81">82]</ref>, recent work has turned to weakly-or self-supervised approaches which leverage additional information in the form of multiple views <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr">108,</ref><ref type="bibr">129]</ref>, auxiliary variables <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b62">63]</ref>, or temporal structure <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b68">69]</ref>. To identify or disentangle the individual independent latent factors, it is typically assumed that there is a chance that each factor changes across views, environments, or time points.  <ref type="figure">Figure 1</ref>: Overview of our problem formulation. We partition the latent variable z into content c and style s, and allow for statistical and causal dependence of style on content. We assume that only style changes between the original view x and the augmented viewx, i.e., they are obtained by applying the same deterministic function f to z = (c, s) andz = (c,s).</p><p>Our work-being directly motivated by common practices in SSL with data augmentation-differs from these works in the following two key aspects (see <ref type="figure">Fig. 1</ref> for an overview). First, we do not assume independence and instead allow for both nontrivial statistical and causal relations between latent variables. This is in line with a recently proposed <ref type="bibr" target="#b104">[105]</ref> shift towards causal representation learning <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b86">87,</ref><ref type="bibr" target="#b105">106,</ref><ref type="bibr" target="#b106">107,</ref><ref type="bibr">112,</ref><ref type="bibr">123,</ref><ref type="bibr">127]</ref>, motivated by the fact that many underlying variables of interest may not be independent but causally related to each other. <ref type="bibr" target="#b0">1</ref> Second, instead of a scenario wherein all latent factors may change as a result of augmentation, we assume a partition of the latent space into two blocks: a content block which is shared or invariant across different augmented views, and a style block that may change. This is aligned with the notion that augmentations leave certain semantic aspects (i.e., content) intact and only affect style, and is thus a more appropriate assumption for studying SSL. In line with earlier work <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr">129]</ref>, we focus on the setting of continuous ground-truth latents, though we believe our results to hold more broadly.</p><p>Structure and contributions. Following a review of SSL with data augmentation and identifiability theory ( ? 2), we formalise the process of data generation and augmentation as an LVM with content and style variables ( ? 3). We then establish identifiability results of the invariant content partition ( ? 4), validate our theoretical insights experimentally ( ? 5), and discuss our findings and their limitations in the broader context of SSL with data augmentation ( ? 6). We highlight the following contributions:</p><p>? we prove that SSL with data augmentations identifies the invariant content partition of the representation in generative (Thm. 4.2) and discriminative learning with invertible (Thm. 4.3) and non-invertible encoders with entropy regularisation (Thm. 4.4); in particular, Thm. 4.4 provides a theoretical justification for the empirically observed effectiveness of contrastive SSL methods that use data augmentation and InfoNCE <ref type="bibr" target="#b90">[91]</ref> as an objective, such as SimCLR <ref type="bibr" target="#b19">[20]</ref>;</p><p>? we show that our theory is consistent with results in simulating statistical dependencies within blocks of content and style variables, as well as with style causally dependent on content ( ? 5.1);</p><p>? we introduce Causal3DIdent, a dataset of 3D objects which allows for the study of identifiability in a causal representation learning setting, and use it to perform a systematic study of data augmentations used in practice, yielding novel insights on what particular data augmentations are truly isolating as invariant content and discarding as varying style when applied ( ? 5.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preliminaries and background</head><p>Self-supervised representation learning with data augmentation. Given an unlabelled dataset of observations (e.g., images) x, data augmentation techniques proceed as follows. First, a set of observation-level transformations t ? T are specified together with a distribution p t over T . Both T and p t are typically designed using human intelligence and domain knowledge with the intention of not changing the semantic characteristics of the data (which arguably constitutes a form of weak supervision). <ref type="bibr" target="#b1">2</ref> For images, for example, a common choice for T are combinations of random crops <ref type="bibr">[113]</ref>, horizontal or vertical flips, blurring, colour distortion <ref type="bibr" target="#b51">[52,</ref><ref type="bibr">113]</ref>, or cutouts <ref type="bibr" target="#b30">[31]</ref>; and p t is a distribution over the parameterisation of these transformations, e.g., the centre and size of a crop <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b30">31]</ref>. For each observation x, a pair of transformations t, t ? p t is sampled and applied separately to x to generate a pair of augmented views (x,x ) = (t(x), t (x)).</p><p>The joint-embedding approach to SSL then uses a pair of encoder functions (g, g ), i.e. deep nets, to map the pair (x,x ) to a typically lower-dimensional representation (z,z ) = (g(x), g (x )).</p><p>Often, the two encoders are either identical, g = g , or directly related (e.g., via shared parameters or asynchronous updates). Then, the encoder(s) (g, g ) are trained such that the representations (z,z ) are "close", i.e., such that sim(z,z ) is large for some similarity metric sim(?), e.g., the cosine similarity <ref type="bibr" target="#b19">[20,</ref><ref type="bibr">129]</ref>, or negative L2 norm <ref type="bibr">[129]</ref>. The advantage of directly optimising for similarity in representation space over generative alternatives is that reconstruction can be very challenging for high-dimensional data. The disadvantage is the problem of collapsed representations. <ref type="bibr" target="#b2">3</ref> To avoid collapsed representations and force the encoder(s) to learn a meaningful representation, two main families of approaches have been used: (i) contrastive learning (CL) <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b90">91,</ref><ref type="bibr">115,</ref><ref type="bibr">126]</ref>; and (ii) regularisation-based SSL <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr">128]</ref>.</p><p>The idea behind CL is to not only learn similar representations for augmented views (x i ,x i ) of the same x i , or positive pairs, but to also use other observations x j (j = i) to contrast with, i.e., to enforce a dissimilar representation across negative pairs (x i ,x j ). In other words, CL pulls representations of positive pairs together, and pushes those of negative pairs apart. Since both aims cannot be achieved simultaneously with a constant representation, collapse is avoided. A popular CL objective function (used, e.g., in SimCLR <ref type="bibr" target="#b19">[20]</ref>) is InfoNCE <ref type="bibr" target="#b90">[91]</ref> (based on noise-contrastive estimation <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref>):</p><formula xml:id="formula_0">L InfoNCE (g; ?, K) = E {xi} K i=1 ?px ? K i=1 log exp{sim(zi,z i )/? } K j=1 exp{sim(zi,z j )/? }<label>(1)</label></formula><p>wherez = E t?pt [g(t(x))], ? is a temperature, and K ?1 is the number of negative pairs. InfoNCE <ref type="bibr" target="#b0">(1)</ref> has an interpretation as multi-class logistic regression, and lower bounds the mutual information across similar views (z,z )-a common representation learning objective <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b74">75,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b96">97,</ref><ref type="bibr">120]</ref>. Moreover, (1) can be interpreted as alignment (numerator) and uniformity (denominator) terms, the latter constituting a nonparametric entropy estimator of the representation as K ? ? [124]. CL with InfoNCE can thus be seen as alignment of positive pairs with (approximate) entropy regularisation.</p><p>Instead of using negative pairs, as in CL, a set of recent SSL methods only optimise for alignment and avoid collapsed representations through different forms of regularisation. For example, BYOL <ref type="bibr" target="#b40">[41]</ref> and SimSiam <ref type="bibr" target="#b20">[21]</ref> rely on "architectural regularisation" in the form of moving-average updates for a separate "target" net g (BYOL only) or a stop-gradient operation (both). BarlowTwins [128], on the other hand, optimises the cross correlation between (z,z ) to be close to the identity matrix, thus enforcing redundancy reduction (zero off-diagonals) in addition to alignment (ones on the diagonal).</p><p>Identifiability of learned representations. In this work, we address the question of whether SSL with data augmentation can reveal or uncover properties of the underlying data generating process. Whether a representation learned from observations can be expected to match the true underlying latent factors-up to acceptable ambiguities and subject to suitable assumptions on the generative process and inference model-is captured by the notion of identifiability <ref type="bibr" target="#b76">[77]</ref>.</p><p>Within representation learning, identifiability has mainly been studied in the framework of (nonlinear) ICA which assumes a model of the form x = f (z) and aims to recover the independent latents, or sources, z, typically up to permutation or element-wise transformation. A crucial negative result states that, with i.i.d. data and without further assumptions, this is fundamentally impossible <ref type="bibr" target="#b56">[57]</ref>. However, recent breakthroughs have shown that identifiability can be achieved if an auxiliary variable (e.g., a time stamp or environment index) renders the sources conditionally independent <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b57">58]</ref>. These methods rely on constructing positive and negative pairs using the auxiliary variable and learning a representation with CL. This development has sparked a renewed interest in identifiability in the context of deep representation learning <ref type="bibr" target="#b62">[63,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b101">102,</ref><ref type="bibr">108,</ref><ref type="bibr">109,</ref><ref type="bibr">129]</ref>.</p><p>Most closely related to SSL with data augmentation are works which study identifiability when given a second viewx of an observation x, resulting from a modified versionz of the underlying latents or sources z <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr" target="#b100">101,</ref><ref type="bibr">108,</ref><ref type="bibr">129]</ref>. Here,z is either an element-wise corruption of z <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b100">101,</ref><ref type="bibr">129]</ref> or may share a random subset of its components <ref type="bibr" target="#b82">[83,</ref><ref type="bibr">108]</ref>. Crucially, all previously mentioned works assume that any of the independent latents (are allowed to) change, and aim to identify the individual factors. However, in the context of SSL with data augmentation, where the semantic (content) part of the representation is intended to be shared between views, this assumption does not hold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem formulation</head><p>We specify our problem setting by formalising the processes of data generation and augmentation. We take a latent-variable model perspective and assume that observations x (e.g., images) are generated by a mixing function f which takes a latent code z as input. Importantly, we describe the augmentation process through changes in this latent space as captured by a conditional distribution pz |z , as opposed to traditionally describing the transformations t as acting directly at the observation level.</p><p>Formally, let z be a continuous r.v. taking values in an open, simply-connected n-dim. representation space Z ? R n with associated probability density p z . Moreover, let f : Z ? X be a smooth and invertible mapping to an observation space X ? R d and let x be the continuous r.v. defined as x = f (z). <ref type="bibr" target="#b3">4</ref> The generative process for the dataset of original observations of x is thus given by:</p><formula xml:id="formula_1">z ? p z , x = f (z).</formula><p>(2) Next, we formalise the data augmentation process. As stated above, we take a representation-centric view, i.e., we assume that an augmentationx of the original x is obtained by applying the same mixing or rendering function f to a modified representationz which is (stochastically) related to the original representation z of x. Specifying the effect of data augmentation thus corresponds to specifying a conditional distribution pz |z which captures the relation between z andz.</p><p>In terms of the transformation-centric view presented in ? 2, we can view the modified representatio? z ? Z as obtained by applying f ?1 to a transformed observationx = t(x) ? X where t ? p t , i.e., z = f ?1 (x). The conditional distribution pz |z in the representation space can thus be viewed as being induced by the distribution p t over transformations applied at the observation level. <ref type="bibr" target="#b4">5</ref> We now encode the notion that the set of transformations T used for augmentation is typically chosen such that any transformation t ? T leaves certain aspects of the data invariant. To this end, we assume that the representation z can be uniquely partitioned into two disjoint parts:</p><p>(i) an invariant part c which will always be shared across (z,z), and which we refer to as content;</p><p>(ii) a varying part s which may change across (z,z), and which we refer to as style. We assume that c and s take values in content and style subspaces C ? R nc and S ? R ns , respectively, i.e., n = n c + n s and Z = C ? S. W.l.o.g., we let c corresponds to the first n c dimensions of z: z = (c, s), c := z 1:nc , s := z (nc+1):n , We formalise the process of data augmentation with content-preserving transformations by defining the conditional pz |z such that only a (random) subset of the style variables change at a time. for some continuous density ps |s on S ? S, where ?(?) is the Dirac delta function, i.e.,c = c a.e. Assumption 3.2 (Style changes). Let A be the set of subsets of style variables A ? {1, ..., n s } and let p A be a distribution on A. Then, the style conditional ps |s is obtained via</p><formula xml:id="formula_2">A ? p A , ps |s,A (s|s, A) = ?(s A c ? s A c )ps A |s A (s A |s A )</formula><p>, where ps A |s A is a continuous density on S A ? S A , S A ? S denotes the subspace of changing style variables specified by A, and A c = {1, ..., n s } \ A denotes the complement of A. <ref type="bibr" target="#b3">4</ref> While x may be high-dimensional n d, invertibility of f implies that X is an n-dim. sub-manifold of R d . <ref type="bibr" target="#b4">5</ref> We investigate this correspondence between changes in observation and latent space empirically in ? 5.</p><p>Note that Assumption 3.2 is less restrictive than assuming that all style variables need to change, since it also allows for only a (possibly different) subset of style variables to change for any given observation. This is in line with the intuition that not all transformations affect all changeable (i.e., style) properties of the data: e.g., a colour distortion should not affect positional information, and, in the same vein, a (horizontal or vertical) flip should not affect the colour spectrum.</p><p>The generative process of an augmentation or transformed observationx is thus given by</p><formula xml:id="formula_3">A ? p A ,z|z, A ? pz |z,A ,x = f (z).</formula><p>(3) Our setting for modelling data augmentation differs from that commonly assumed in (multi-view) disentanglement and ICA in that we do not assume that the latent factors z = (c, s) are mutually (or conditionally) independent, i.e., we allow for arbitrary (non-factorised) marginals p z in (2). <ref type="bibr" target="#b5">6</ref> Causal interpretation: data augmentation as counterfactuals under soft style intervention. We now provide a causal account of the above data generating process by describing the (allowed) causal dependencies among latent variables using a structural causal model (SCM) <ref type="bibr" target="#b93">[94]</ref>. As we will see, this leads to an interpretation of data augmentations as counterfactuals in the underlying latent SCM. The assumption that c stays invariant as s changes is consistent with the view that content may causally influence style, c ? s, but not vice versa, see <ref type="figure">Fig. 1</ref>. We therefore formalise their relation as:</p><formula xml:id="formula_4">c := f c (u c ), s := f s (c, u s ), (u c , u s ) ? p uc ? p us</formula><p>where u c , u s are independent exogenous variables, and f c , f s are deterministic functions. The latent causal variables (c, s) are subsequently decoded into observations x = f (c, s). Given a factual observation</p><formula xml:id="formula_5">x F = f (c F , s F ) which resulted from (u F c , u F s )</formula><p>, we may ask the counterfactual question: "what would have happened if the style variables had been (randomly) perturbed, all else being equal?". Consider, e.g., a soft intervention <ref type="bibr" target="#b34">[35]</ref> on s, i.e., an intervention that changes the mechanism f s to</p><formula xml:id="formula_6">do(s :=f s (c, u s , u A )),</formula><p>where u A is an additional source of stochasticity accounting for the randomness of the augmentation process (p A ? ps |s,A ). The resulting distribution over counterfactual observations x CF = f (c F , s CF ) can be computed from the modified SCM by fixing the exogenous variables to their factual values and performing the soft intervention:</p><formula xml:id="formula_7">c CF := c F , s CF :=f s (c F , u F s , u A ), u A ? p u A .</formula><p>This aligns with our intuition and assumed problem setting of data augmentations as style corruptions. We note that the notion of augmentation as (hard) style interventions is also at the heart of ReLIC <ref type="bibr" target="#b86">[87]</ref>, a recently proposed, causally-inspired SSL regularisation term for instance-discrimination <ref type="bibr" target="#b43">[44,</ref><ref type="bibr">126]</ref>. However, ReLIC assumes independence between content and style and does not address identifiability. For another causal perspective on data augmentation in the context of domain generalisation, c.f. <ref type="bibr" target="#b58">[59]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Theory: block-identifiability of the invariant content partition</head><p>Our goal is to prove that we can identify the invariant content partition c under a distinct, weaker set of assumptions, compared to existing results in disentanglement and nonlinear ICA <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr">108,</ref><ref type="bibr">129]</ref>. We stress again that our primary interest is not to identify or disentangle individual (and independent) latent factors z j , but instead to separate content from style, such that the content variables can be subsequently used for downstream tasks. We first define this distinct notion of block-identifiability. Defn. 4.1 is related to independent subspace analysis <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr">114]</ref>, which also aims to identify blocks of random variables as opposed to individual factors, though under an independence assumption across blocks, and typically not within a multi-view setting as studied in the present work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Generative self-supervised representation learning</head><p>First, we consider generative SSL, i.e., fitting a generative model to pairs (x,x) of original and augmented views. <ref type="bibr" target="#b6">7</ref> We show that under our specified data generation and augmentation process ( ? 3), <ref type="bibr" target="#b5">6</ref> The recently proposed Independently Modulated Component Analysis (IMCA) <ref type="bibr" target="#b63">[64]</ref> extension of ICA is a notable exception, but only allows for trivial dependencies across z in the form of a shared base measure. <ref type="bibr" target="#b6">7</ref> For notational simplicity, we present our theory for pairs (x,x) rather than for two augmented views (x,x ), as typically used in practice but it also holds for the latter, see ? 6 for further discussion.</p><p>as well as suitable additional assumptions (stated and discussed in more detail below), it is possible to isolate (i.e., block-identify) the invariant content partition. Full proofs are included in Appendix A. Theorem 4.2 (Identifying content with a generative model). Consider the data generating process described in ? 3, i.e., the pairs (x,x) of original and augmented views are generated according to <ref type="bibr" target="#b1">(2)</ref> and (3) with pz |z as defined in Assumptions 3.1 and 3.2. Assume further that (i) f : Z ? X is smooth and invertible with smooth inverse (i.e., a diffeomorphism);</p><p>(ii) p z is a smooth, continuous density on Z with p z (z) &gt; 0 almost everywhere;</p><p>(iii) for any l ? {1, ..., n s }, ?A ? {1, ..., n s } s.t. l ? A; p A (A) &gt; 0; ps A |s A is smooth w.r.t. both s A ands A ; and for any s A , ps A |s A (?|s A ) &gt; 0 in some open, non-empty subset containing s A .</p><p>If, for a given n s (1 ? n s &lt; n), a generative model (p z ,p A ,ps |s,A ,f ) assumes the same generative process ( ? 3), satisfies the above assumptions (i)-(iii), and matches the data likelihood,</p><formula xml:id="formula_8">p x,x (x,x) =p x,x (x,x) ?(x,x) ? X ? X ,</formula><p>then it block-identifies the true content variables via g =f ?1 in the sense of Defn. 4.1.</p><p>Proof sketch. First, show (using (i) and the matching likelihoods) that the representation? = g(x) extracted by g is related to the true z by a smooth invertible mapping h = g?f such that? = h(z) 1:nc is invariant across (z,z) almost surely w.r.t. p z,z . <ref type="bibr" target="#b7">8</ref> Second, show by contradiction (using (ii), (iii)) that h(?) 1:nc can, in fact, only depend on the true content c and not on style s, for otherwise the invariance from step 1 would be violated in a region of the style (sub)space of measure greater than zero.</p><p>Intuition. Thm. 4.2 assumes that the number of content (n c ) and style (n s ) variables is known, and that there is a positive probability that each style variable may change, though not necessarily on its own, according to (iii). In this case, training a generative model of the form specified in ? 3 (i.e., with an invariant content partition and subsets of changing style variables) by maximum likelihood on pairs (x,x) will asymptotically (in the limit of infinite data) recover the true invariant content partition up to an invertible function, i.e., it isolates, or unmixes, content from style.</p><p>Discussion. The identifiability result of Thm. 4.2 for generative SSL is of potential relevance for existing variational autoencoder (VAE) <ref type="bibr" target="#b67">[68]</ref> variants such as the GroupVAE [51], 9 or its adaptive version AdaGVAE <ref type="bibr" target="#b82">[83]</ref>. Since, contrary to existing results, Thm. 4.2 does not assume independent latents, it may also provide a principled basis for generative causal representation learning algorithms <ref type="bibr" target="#b75">[76,</ref><ref type="bibr" target="#b106">107,</ref><ref type="bibr">127]</ref>. However, an important limitation to its practical applicability is that generative modelling does not tend to scale very well to complex high-dimensional observations, such as images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Discriminative self-supervised representation learning</head><p>We therefore next turn to a discriminative approach, i.e., directly learning an encoder function g which leads to a similar embedding across (x,x). As discussed in ? 2, this is much more common for SSL with data augmentations. First, we show that if an invertible encoder g is used, then learning a representation which is aligned in the first n c dimensions is sufficient to block-identify content. Theorem 4.3 (Identifying content with an invertible encoder). Assume the same data generating process ( ? 3) and conditions (i)-(iv) as in Thm. 4.2. Let g : X ? Z be any smooth and invertible function which minimises the following functional:</p><formula xml:id="formula_9">L Align (g) := E (x,x)?p x,x g(x) 1:nc ? g(x) 1:nc 2 2<label>(4)</label></formula><p>Then g block-identifies the true content variables in the sense of Definition 4.1.</p><p>Proof sketch. First, we show that the global minimum of (4) is reached by the smooth invertible function f ?1 . Thus, any other minimiser g must satisfy the same invariance across (x,x) used in step 1 of the proof of Thm. 4.2. The second step uses the same argument by contradiction as in Thm. 4.2.</p><p>Intuition. Thm. 4.3 states that if-under the same assumptions on the generative process as in Thm. 4.2-we directly learn a representation with an invertible encoder, then enforcing alignment between the first n c latents is sufficient to isolate the invariant content partition. Intuitively, invertibility guarantees that all information is preserved, thus avoiding a collapsed representation.</p><p>Discussion. According to Thm. 4.3, content can be isolated if, e.g., a flow-based architecture <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b91">92,</ref><ref type="bibr" target="#b92">93]</ref> is used, or invertibility is enforced otherwise during training <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b59">60]</ref>. However, the applicability of this approach is limited as it places strong constraints on the encoder architecture which makes it hard to scale these methods up to high-dimensional settings. As discussed in ? 2, state-of-the-art SSL methods such as SimCLR <ref type="bibr" target="#b19">[20]</ref>, BYOL <ref type="bibr" target="#b40">[41]</ref>, SimSiam <ref type="bibr" target="#b20">[21]</ref>, or BarlowTwins [128] do not use invertible encoders, but instead avoid collapsed representations-which would result from naively optimising (4) for arbitrary, non-invertible g-using different forms of regularisation.</p><p>To close this gap between theory and practice, finally, we investigate how to block-identify content without assuming an invertible encoder. We show that, if we add a regularisation term to (4) that encourages maximum entropy of the learnt representation, the invertibility assumption can be dropped. Theorem 4.4 (Identifying content with discriminative learning and a non-invertible encoder). Assume the same data generating process ( ? 3) and conditions (i)-(iv) as in Thm. 4.2. Let g : X ? (0, 1) nc be any smooth function which minimises the following functional:</p><formula xml:id="formula_10">L AlignMaxEnt (g) := E (x,x)?p x,x g(x) ? g(x) 2 2 ? H (g(x))<label>(5)</label></formula><p>where H(?) denotes the differential entropy of the random variable g(x) taking values in (0, 1) nc . Then g block-identifies the true content variables in the sense of Defn. 4.1.</p><p>Proof sketch. First, use the Darmois construction <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b56">57]</ref> to build a function d : C ? (0, 1) nc mapping c = f ?1 (x) 1:nc to a uniform random variable. Then g = d ? f ?1 1:nc attains the global minimum of (5) because c is invariant across (x,x) and the uniform distribution is the maximum entropy distribution on (0, 1) nc . Thus, any other minimiser g of (5) must satisfy invariance across (x,x) and map to a uniform r.v. Then, use the same step 2 as in Thms. 4.2 and 4.3 to show that h = g ? f : Z ? (0, 1) nc cannot depend on style, i.e., it is a function from C to (0, 1) nc . Finally, we show that h must be invertible since it maps p c to a uniform distribution, using a result from [129].</p><p>Intuition. Thm. 4.4 states that if we do not explicitly enforce invertibility of g as in Thm. 4.3, additionally maximising the entropy of the learnt representation (i.e., optimising alignment and uniformity [124]) avoids a collapsed representation and recovers the invariant content block. Intuitively, this is because any function that only depends on c will be invariant across (x,x), so it is beneficial to preserve all content information to maximise entropy.</p><p>Discussion. Of our theoretical results, Thm. 4.4 requires the weakest set of assumptions, and is most closely aligned with common SSL practice. As discussed in ? 2, contrastive SSL with negative samples using InfoNCE (1) as an objective can asymptotically be understood as alignment with entropy regularisation [124], i.e., objective <ref type="bibr" target="#b4">(5)</ref>. Thm. 4.4 thus provides a theoretical justification for the empirically observed effectiveness of CL with InfoNCE: subject to our assumptions, CL with InfoNCE asymptotically isolates content, i.e., the part of the representation that is always left invariant by augmentation. For example, the strong image classification performance based on representations learned by SimCLR <ref type="bibr" target="#b19">[20]</ref>, which uses color distortion and random crops as augmentations, can be explained in that object class is a content variable in this case. We extensively evaluate the effect of various augmentation techniques on different ground-truth latent factors in our experiments in ? 5. There is also an interesting connection between Thm. 4.4 and BarlowTwins [128], which only uses positive pairs and combines alignment with a redundancy reduction regulariser that enforces decorrelation between the inferred latents. Intuitively, redundancy reduction is related to increased entropy: g constructed in the proof of Thm. 4.4-and thus also any other minimiser of (5)-attains the global optimum of the BarlowTwins objective, though the reverse implication may not hold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We perform two main experiments. First, we numerically test our main result, Thm. 4.4, in a fullycontrolled, finite sample setting ( ? 5.1), using CL to estimate the entropy term in <ref type="bibr" target="#b4">(5)</ref>. Second, we seek to better understand the effect of data augmentations used in practice ( ? 5.2). To this end, we introduce a new dataset of 3D objects with dependencies between a number of known ground-truth factors, and use it to evaluate the effect of different augmentation techniques on what is identified as content. Additional experiments are summarised in ? 5.3 and described in more detail in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Numerical data</head><p>Experimental setup. We generate synthetic data as described in ? 3. We consider n c = n s = 5, with content and style latents distributed as c ? N (0, ? c ) and s|c ? N (a + Bc, ? s ), thus allowing for statistical dependence within the two blocks (via ? c and ? s ) and causal dependence between content and style (via B). For f , we use a 3-layer MLP with LeakyReLU activation functions. <ref type="bibr" target="#b9">10</ref> The distribution p A over subsets of changing style variables is obtained by independently flipping the same biased coin for each s i . The conditional style distribution is taken as ps A |s A = N (s A , ? A ). We train an encoder g on pairs (x,x) with InfoNCE using the negative L2 loss as the similarity measure, i.e., we approximate (5) using empirical averages and negative samples. For evaluation, we use kernel ridge regression <ref type="bibr" target="#b87">[88]</ref> to predict the ground truth c and s from the learnt representation? = g(x) and report the R 2 coefficient of determination. For a more detailed account, we refer to Appendix D.</p><p>Generative process</p><formula xml:id="formula_11">R 2 (nonlinear) p(chg.) Stat. Cau. Content c Style s 1.0 1.00 ? 0.00 0.07 ? 0.00 0.75 1.00 ? 0.00 0.06 ? 0.05 0.75 0.98 ? 0.03 0.37 ? 0.05 0.75 0.99 ? 0.01 0.80 ? 0.08</formula><p>Results. In the inset table, we report mean ? std. dev. over 3 random seeds across four generative processes of increasing complexity covered by Thm. 4.4: "p(chg.)", "Stat.", and "Cau." denote respectively the change probability for each s i , statistical dependence within blocks (? c = I = ? s ), and causal dependence of style on content (B = 0). An R 2 close to one indicates that almost all variation is explained by?, i.e., that there is a 1-1 mapping, as required by Defn. 4.1. As can be seen, across all settings, content is block-identified. Regarding style, we observe an increased score with the introduction of dependencies, which we explain in an extended discussion in Appendix C.1. Finally, we show in Appendix C.1 that a high R 2 score can be obtained even if we use linear regression to predict c from? (R 2 = 0.98 ? 0.01, for the last row).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">High-dimensional images: Causal3DIdent</head><p>Causal3DIdent  Experimental setup. For g, we train a convolutional encoder composed of a ResNet18 <ref type="bibr" target="#b45">[46]</ref> and an additional fully-connected layer, with LeakyReLU activation. As in SimCLR <ref type="bibr" target="#b19">[20]</ref>, we use InfoNCE with cosine similarity, and train on pairs of augmented examples (x,x ). As n c is unknown and variable depending on the augmentation, we fix dim(?) = 8 throughout. Note that we find the results to be, for the most part, robust to the choice of dim(?), see inset figure. We consider the following data augmentations (DA): crop, resize &amp; flip; colour distortion (jitter &amp; drop); and rotation ? {90?, 180?, 270?}. For comparison, we also consider directly imposing a content-style DA: colour distortion 0.42 ? 0.01 0.61 ? 0.10 0.17 ? 0.00 0.10 ? 0.01 0.01 ? 0.00 0.01 ? 0.00 0.33 ? 0.02 LT: change hues 1.00 ? 0.00 0.59 ? 0.33 0.91 ? 0.00 0.30 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.30 ? 0.01 DA: crop (large) 0.28 ? 0.04 0.09 ? 0.08 0.21 ? 0.13 0.87 ? 0.00 0.09 ? 0.02 1.00 ? 0.00 0.02 ? 0.02 DA: crop (small) 0.14 ? 0.00 0.00 ? 0.01 0.00 ? 0.01 0.00 ? 0.00 0.00 ? 0.00 1.00 ? 0.00 0.00 ? 0.00 LT: change positions 1.00 ? 0.00 0.16 ? 0.23 0.00 ? 0.01 0.46 ? 0.02 0.00 ? 0.00 0.97 ? 0.00 0.29 ? 0.01 DA: crop (large) + colour distortion 0.97 ? 0.00 0.59 ? 0.07 0.59 ? 0.05 0.28 ? 0.00 0.01 ? 0.01 0.01 ? 0.00 0.74 ? 0.03 DA: crop (small) + colour distortion 1.00 ? 0.00 0.69 ? 0.04 0.93 ? 0.00 0.30 ? 0.01 0.00 ? 0.00 0.02 ? 0.03 0.56 ? 0.03 LT: change positions + hues 1.00 ? 0.00 0.22 ? 0.22 0.07 ? 0.08 0.32 ? 0.02 0.00 ? 0.01 0.02 ? 0.03 0.34 ? 0.06 DA: rotation 0.33 ? 0.06 0.17 ? 0.09 0.23 ? 0.12 0.83 ? 0.01 0.30 ? 0.12 0.99 ? 0.00 0.05 ? 0.03 LT: change rotations 1.00 ? 0.00 0.53 ? 0.33 0.90 ? 0.00 0.41 ? 0.00 0.00 ? 0.00 0.97 ? 0.00 0.28 ? 0.00</p><p>DA: rotation + colour distortion 0.59 ? 0.01 0.58 ? 0.06 0.21 ? 0.01 0.12 ? 0.02 0.01 ? 0.00 0.01 ? 0.00 0.33 ? 0.04 LT: change rotations + hues 1.00 ? 0.00 0.57 ? 0.34 0.91 ? 0.00 0.30 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.28 ? 0.00 partition by performing a latent transformation (LT) to generate views. For evaluation, we use linear logistic regression to predict object class, and kernel ridge to predict the other latents from?. <ref type="bibr" target="#b12">13</ref> Results. The results are presented in Tab. 1. Overall, our main findings can be summarised as:</p><p>(i) it can be difficult to design image-level augmentations that leave specific latent factors invariant;</p><p>(ii) augmentations &amp; latent transformations generally have a similar effect on groups of latents;</p><p>(iii) augmentations that yield good classification performance induce variation in all other latents.</p><p>We observe that, similar to directly varying the hue latents, colour distortion leads to a discarding of hue information as style, and a preservation of (object) position as content. Crops, similar to varying the position latents, lead to a discarding of position as style, and a preservation of background and object hue as content, the latter assuming crops are sufficiently large. In contrast, image-level rotation affects both the object rotation and position, and thus deviates from only varying the rotation latents.</p><p>Whereas class is always preserved as content when generating views with latent transformations, when using data augmentations, we can only reliably decode class when crops &amp; colour distortion are used in conjunction-a result which mirrors evaluation on ImageNet <ref type="bibr" target="#b19">[20]</ref>. As can be seen by our evaluation of crops &amp; colour distortion in isolation, while colour distortion leads to a discarding of hues as style, crops lead to a discarding of position &amp; rotation as style. Thus, when used in conjunction, class is isolated as the sole content variable. See Appendix C.2 for additional analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Additional experiments and ablations</head><p>We also perform an ablation on dim(?) for the synthetic setting from ? 5.1, see Appendix C.1 for details. Generally, we find that if dim(?) &lt; n c , there is insufficient capacity to encode all content, so a lower-dimensional mixture of content is learnt. Conversely, if dim(?) &gt; n c , the excess capacity is used to encode some style information (as that increases entropy </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>Theory vs practice. We have made an effort to tailor our problem formulation ( ? 3) to the setting of data augmentation with content-preserving transformations. However, some of our more technical assumptions, which are necessary to prove block-identifiability of the invariant content partition, may not hold exactly in practice. This is apparent, e.g., from our second experiment ( ? 5.2), where we observe that-while class should, in principle, always be invariant across views (i.e., content)-when using only crops, colour distortion, or rotation, g appears to encode shortcuts <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b95">96]</ref>. 14 Data augmentation, unlike latent transformations, generates viewsx which are not restricted to the 11-dim. image manifold X corresponding to the generative process of Causal3DIdent, but may introduce additional variation: e.g., colour distortion leads to a rich combination of colours, typically a 3-dim. feature, whereas Causal3DIdent only contains one degree of freedom (hue). With additional factors, any introduced invariances may be encoded as content in place of class. Image-level augmentations also tend to change multiple latent factors in a correlated way, which may violate assumption (iii) of our theorems, i.e., that ps A |s A is fully-supported locally. We also assume that z is continuous, even though Causal3DIdent and most disentanglement datasets also contain discrete latents. This is a very common assumption in the related literature <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b81">82,</ref><ref type="bibr" target="#b82">83,</ref><ref type="bibr">129</ref>] that may be relaxed in future work. Moreover, our theory holds asymptotically and at the global optimum, whereas in practice we solve a non-convex optimisation problem with a finite sample and need to approximate the entropy term in (5), e.g., using a finite number of negative pairs. The resulting challenges for optimisation may be further accentuated by the higher dimensionality of X induced by image-level augmentations. Finally, we remark that while, for simplicity, we have presented our theory for pairs (x,x) of original and augmented examples, in practice, using pairs (x,x ) of two augmented views typically yields better performance. All of our assumptions (content invariance, changing style, etc) and theoretical results still apply to the latter case. We believe that using two augmented views helps because it leads to increased variability across the pair: for ifx andx differ from x in style subsets A and A , respectively, then (x,x ) differ from each other (a.s.) in the union A ? A .</p><p>Beyond entropy regularisation. We have shown a clear link between an identifiable maximum entropy approach to SSL (Thm. The choice of augmentation technique implicitly defines content and style. As we have defined content as the part of the representation which is always left invariant across views, the choice of augmentation implicitly determines the content-style partition. This is particularly important to keep in mind when applying SSL with data augmentation to safety-critical domains, such as medical imaging. We also advise caution when using data augmentation to identify specific latent properties, since, as observed in ? 5.2, image-level transformations may affect the underlying ground-truth factors in unanticipated ways. Also note that, for a given downstream task, we may not want to discard all style information since style variables may still be correlated with the task of interest and may thus help improve predictive performance. For arbitrary downstream tasks, however, where style may change in an adversarial way, it can be shown that only using content is optimal <ref type="bibr" target="#b102">[103]</ref>.</p><p>What vs how information is encoded. We focus on what information is learnt by SSL with data augmentations by specifying a generative process and studying identifiability of the latent representation. Orthogonal to this, a different line of work instead studies how information is encoded by analysing the sample complexity needed to solve a given downstream task using a linear predictor <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr">[116]</ref><ref type="bibr">[117]</ref><ref type="bibr">[118]</ref><ref type="bibr">[119]</ref>. Provided that downstream tasks only involve content, we can draw some comparisons. Whereas our results recover content only up to arbitrary invertible nonlinear functions (see Defn. 4.1), our problem setting is more general: <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b73">74]</ref> assume (approximate) independence of views (x,x) given the task (content), while [118, 119] assume (approximate) independence between one view and the task (content) given the other view, neither of which hold in our setting.</p><p>Conclusion. Existing representation learning approaches typically assume mutually independent latents, though dependencies clearly exist in nature <ref type="bibr" target="#b105">[106]</ref>. We demonstrate that in a non-i.i.d. scenario, e.g., by constructing multiple views of the same example with data augmentation, we can learn useful representations in the presence of this neglected phenomenon. More specifically, the present work contributes, to the best of our knowledge, the first: (i) identifiability result under arbitrary dependence between latents; and (ii) empirical study that evaluates the effect of data augmentations not only on classification, but also on other continuous ground-truth latents. Unlike existing identifiability results which rely on change as a learning signal, our approach aims to identify what is always shared across views, i.e., also using invariance as a learning signal. We hope that this change in perspective will be helpful for applications such as optimal style transfer or disentangling shape from pose in vision, and inspire other types of counterfactual training to recover a more fine-grained causal representation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>Overview:</p><p>? Appendix A contains the full proofs for all theoretical results from the main paper.</p><p>? Appendix B contains additional details and plots for the Causal3DIdent dataset.</p><p>? Appendix C contains additional experimental results and analysis.</p><p>? Appendix D contains additional implementation details for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Proofs</head><p>We now present the full detailed proofs of our three theorems which were briefly sketched in the main paper. We remark that these proofs build on each other, in the sense that the (main) step 2 of the proof of Thm If, for a given n s (1 ? n s &lt; n), a generative model (p z ,p A ,ps |s,A ,f ) assumes the same generative process ( ? 3), satisfies the above assumptions (i)-(iii), and matches the data likelihood,</p><formula xml:id="formula_12">p x,x (x,x) =p x,x (x,x) ?(x,x) ? X ? X ,</formula><p>then it block-identifies the true content variables via g =f ?1 in the sense of Defn. 4.1.</p><p>Proof. The proof consists of two main steps.</p><p>In the first step, we use assumption (i) and the matching likelihoods to show that the representation z = g(x) extracted by g =f ?1 is related to the true latent z by a smooth invertible mapping h, and that? must satisfy invariance across (x,x) in the first n c (content) components almost surely (a.s.) with respect to (w.r.t.) the true generative process.</p><p>In the second step, we then use assumptions (ii) and (iii) to prove (by contradiction) that? :=? 1:nc = h(z) 1:nc can, in fact, only depend on the true content c and not on the true style s, for otherwise the invariance established in the first step would have be violated with probability greater than zero.</p><p>To provide some further intuition for the second step, the assumed generative process implies that (c, s,s)|A is constrained to take values (a.s.) in a subspace R of C ?S ?S of dimension n c +n s +|A| (as opposed to dimension n c + 2n s for C ? S ? S). In this context, assumption (iii) implies that (c, s,s)|A has a density with respect to a measure on this subspace equivalent to the Lebesgue measure on R nc+ns+|A| . This equivalence implies, in particular, that this "subspace measure" is Step 1. From the assumed data generating process described in ? 3-in particular, from the form of the model conditionalpz |z described in Assumptions 3.1 and 3.2-it follows that g(x) 1:nc = g(x) 1:nc</p><p>a.s., i.e., with probability one, w.r.t. the model distributionp x,x .</p><p>Due to the assumption of matching likelihoods, the invariance in (6) must also hold (a.s.) w.r.t. the true data distribution p x,x .</p><p>Next, since f ,f : Z ? X are smooth and invertible functions by assumption (i), there exists a smooth and invertible function h = g ? f : Z ? Z such that</p><formula xml:id="formula_14">g = h ? f ?1 .<label>(7)</label></formula><p>Substituting <ref type="formula" target="#formula_14">(7)</ref> into <ref type="formula" target="#formula_13">(6)</ref>, we obtain (a.s. w.r.t. p):</p><formula xml:id="formula_15">c :=? 1:nc = g(x) 1:nc = h(f ?1 (x)) 1:nc = h(f ?1 (x)) 1:nc<label>(8)</label></formula><p>Substituting</p><formula xml:id="formula_16">z = f ?1 (x) andz = f ?1 (x) into (8), we obtain (a.s. w.r.t. p) c = h(z) 1:nc = h(z) 1:nc .<label>(9)</label></formula><p>It remains to show that h(?) 1:nc can only be a function of c, i.e., does not depend on any other (style) dimension of z = (c, s).</p><p>Step </p><p>that is, we assume that the partial derivative of h c w.r.t. some style variable s l is non-zero at some point z * = (c * , s * ) ? Z = C ? S.</p><p>Since h is smooth, so is h c . Therefore, h c has continuous (first) partial derivatives.</p><p>By continuity of the partial derivative, ?hc ?s l must be non-zero in a neighbourhood of (c * , s * ), i.e., ?? &gt; 0 </p><formula xml:id="formula_18">s.t. s l ? h c c * , (s * ?l , s l ) is strictly monotonic on (s * l ? ?, s * l + ?),<label>(11)</label></formula><p>To obtain a contradiction to the invariance condition (9) from Step 1 under assumption (10), it remains to show that ? from <ref type="formula" target="#formula_0">(12)</ref> is strictly positive with probability greater than zero (w.r.t. p).</p><p>First, the strict monotonicity from <ref type="bibr" target="#b10">(11)</ref> implies that</p><formula xml:id="formula_20">? c * , (s * ?l , s l ), (s * ?l ,s l ) &gt; 0 , ?(s l ,s l ) ? (s * l , s * l + ?) ? (s * l ? ?, s * l ) .<label>(13)</label></formula><p>Note that in order to obtain the strict inequality in <ref type="formula" target="#formula_0">(13)</ref>  in the domain of ? on which ? is strictly positive.</p><p>Moreover, due to <ref type="bibr" target="#b12">(13)</ref>:</p><formula xml:id="formula_21">{c * } ? {s * ?l } ? (s * l , s * l + ?) ? {s * ?l } ? (s * l ? ?, s * l ) ? U,<label>(15)</label></formula><p>so U is non-empty.</p><p>Next, by assumption (iii), there exists at least one subset A ? {1, ..., n s } of changing style variables such that l ? A and p A (A) &gt; 0; pick one such subset and call it A. Define the following space <ref type="bibr" target="#b15">16)</ref> and, recalling that A c = {1, ..., n s } \ A denotes the complement of A, define</p><formula xml:id="formula_22">R A := {(s A ,s A ) : s A ? S A ,s A ? O(s A )}<label>(</label></formula><formula xml:id="formula_23">R := C ? S A c ? R A<label>(17)</label></formula><p>which is a topological subspace of C ? S ? S.</p><p>By assumptions (ii) and (iii), p z is smooth and fully supported, and ps A |s A (?|s A ) is smooth and fully supported on O(s A ) for any s A ? S A . Therefore, the measure ? (c,s A c ,s A ,s A )|A has fully supported, strictly-positive density on R w.r.t. a strictly positive measure on R. In other words, p z ? ps A |s A is fully supported (i.e., strictly positive) on R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Now consider the intersection U ? R of the open set U with the topological subspace R.</head><p>Since U is open, by the definition of topological subspaces, the intersection U ? R ? R is open in R, (and thus has the same dimension as R if non-empty).</p><formula xml:id="formula_24">Moreover, since O(s * A ) is open containing s * A , there exists ? &gt; 0 such that {s * ?l } ? (s * l ? ? , s * l ) ? O(s * A ). Thus, for ? = min(?, ? ) &gt; 0, {c * } ? {s * A c } ? {s * A\{l} } ? (s * l , s * l + ?) ? {s * A\{l} } ? (s * l ? ? , s * l ) ? R.<label>(18)</label></formula><p>In particular, this implies that</p><formula xml:id="formula_25">{c * } ? {s * ?l } ? (s * l , s * l + ?) ? {s * ?l } ? (s * l ? ? , s * l ) ? R,<label>(19)</label></formula><p>Now, since ? ? ?, the LHS of (19) is also in U according to <ref type="bibr" target="#b14">(15)</ref>, so the intersection U ? R is non-empty.</p><p>In summary, the intersection U ? R ? R:</p><p>? is non-empty (since both U and R contain the LHS of (15));</p><p>? is an open subset of the topological subspace R of C ? S ? S (since it is the intersection of an open set, U, with R);</p><p>? satisfies ? &gt; 0 (since this holds for all of U);</p><p>? is fully supported w.r.t. the generative process (since this holds for all of R).</p><p>As a consequence, P (?(c, s,s) &gt; 0|A) ? P(U ? R) &gt; 0, <ref type="bibr" target="#b19">(20)</ref> where P denotes probability w.r.t. the true generative process p.</p><p>Since p A (A) &gt; 0, this is a contradiction to the invariance (9) from Step 1.</p><p>Hence, assumption <ref type="formula" target="#formula_0">(10)</ref>    </p><p>Then g block-identifies the true content variables in the sense of Definition 4.1.</p><p>Proof. As in the proof of Thm. 4.2, the proof again consists of two main steps.</p><p>In the first step, we show that the representation? = g(x) extracted by any g that minimises L Align is related to the true latent z through a smooth invertible mapping h, and that? must satisfy invariance across (x,x) in the first n c (content) components almost surely (a.s.) with respect to (w.r.t.) the true generative process.</p><p>In the second step, we use the same argument by contradiction as in Step 2 of the proof of Thm. 4.2, to show that? = h(z) 1:nc can only depend on the true content c and not on style s.</p><p>Step 1. From the form of the objective (4), it is clear that L Align ? 0 with equality if and only if g(x) 1:nc = g(x) 1:nc for all (x,x) s.t. p x,x (x,x) &gt; 0.</p><p>Moreover, it follows from the assumed generative process that the global minimum of zero is attained by the true unmixing f ?1 since</p><formula xml:id="formula_27">f ?1 (x) 1:nc = c =c = f ?1 (x) 1:nc<label>(21)</label></formula><p>holds a.s. (i.e., with probability one) w.r.t. the true generative process p.</p><p>Hence, there exists at least one smooth invertible function (f ?1 ) which attains the global minimum.</p><p>Let g be any function attaining the global minimum of L Align of zero.</p><p>As argued above, this implies that (a.s. w.r.t. p):</p><p>g(x) 1:nc = g(x) 1:nc .</p><p>Writing</p><formula xml:id="formula_29">g = h ? f ?1 , where h is the smooth, invertible function h = g ? f we obtain (a.s. w.r.t. p): c = h(z) 1:nc = h(z) 1:nc .<label>(23)</label></formula><p>Note that this is the same invariance condition as (9) derived in Step 1 of the proof of Thm. 4.2.</p><p>Step 2. It remains to show that h(z) 1:nc can only depend on the true content c and not on any of the style variables s. To show this, we use the same Step 2 as in the proof of Thm. 4.2.</p><p>A.3 Proof of Thm. 4.4</p><p>Theorem 4.4 (Identifying content with discriminative learning and a non-invertible encoder). Assume the same data generating process ( ? 3) and conditions (i)-(iv) as in Thm. 4.2. Let g : X ? (0, 1) nc be any smooth function which minimises the following functional:</p><formula xml:id="formula_30">L AlignMaxEnt (g) := E (x,x)?p x,x g(x) ? g(x) 2 2 ? H (g(x))<label>(5)</label></formula><p>where H(?) denotes the differential entropy of the random variable g(x) taking values in (0, 1) nc . Then g block-identifies the true content variables in the sense of Defn. 4.1.</p><p>Proof. The proof consists of three main steps.</p><p>In the first step, we show that the representation? = g(x) extracted by any smooth function g that minimises (5) is related to the true latent z through a smooth mapping h; that? must satisfy invariance across (x,x) almost surely (a.s.) with respect to (w.r.t.) the true generative process p; and that? must follow a uniform distribution on (0, 1) nc .</p><p>In the second step, we use the same argument by contradiction as in Step 2 of the proof of Thm. 4.2, to show that? = h(z) can only depend on the true content c and not on style s.</p><p>Finally, in the third step, we show that h must be a bijection, i.e., invertible, using a result from [129].</p><p>Step 1. The global minimum of L AlignMaxEnt is reached when the first term (alignment) is minimised (i.e., equal to zero) and the second term (entropy) is maximised.</p><p>Without additional moment constraints, the unique maximum entropy distribution on (0, 1) nc is the uniform distribution <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b60">61]</ref>.</p><p>First, we show that there exists a smooth function g * : X ? (0, 1) nc which attains the global minimum of L AlignMaxEnt .</p><p>To see this, consider the function f ?1 1:nc : X ? C, i.e., the inverse of the true mixing f , restricted to its first n c dimensions. This exists and is smooth since f is smooth and invertible by assumption (i). Further, we have f ?1 (x) 1:nc = c by definition.</p><p>We now build a function d : C ? (0, 1) nc which maps c to a uniform random variable on (0, 1) nc using a recursive construction known as the Darmois construction <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b56">57]</ref>.</p><p>Specifically, we define</p><formula xml:id="formula_31">d i (c) := F i (c i |c 1:i?1 ) = P(C i ? c i |c 1:i?1 ), i = 1, ..., n c ,<label>(24)</label></formula><p>where F i denotes the conditional cumulative distribution function (CDF) of c i given c 1:i?1 .</p><p>By construction, d(c) is uniformly distributed on (0, 1) nc <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b56">57]</ref>.</p><p>Further, d is smooth by the assumption that p z (and thus p c ) is a smooth density.</p><p>Finally, we define</p><formula xml:id="formula_32">g * := d ? f ?1 1:nc : X ? (0, 1) nc ,<label>(25)</label></formula><p>which is a smooth function since it is a composition of two smooth functions.</p><p>Claim A.1. g * as defined in <ref type="formula" target="#formula_10">(25)</ref> attains the global minimum of L AlignMaxEnt .</p><p>Proof of Claim A.1. Using f ?1 (x) 1:nc = c and f ?1 (x) 1:nc =c, we have</p><formula xml:id="formula_33">L AlignMaxEnt (g * ) = E (x,x)?p (x,x) g * (x) ? g * (x) 2 2 ? H (g * (x)) (26) = E (x,x)?p (x,x) d(c) ? d(c) 2 2 ? H (d(c))<label>(27)</label></formula><p>= 0</p><p>where in the last step we have used the fact that c =c almost surely w.r.t. to the ground truth generative process p described in ? 3, so the first term is zero; and the fact that d(c) is uniformly distributed on (0, 1) nc and the uniform distribution on the unit hypercube has zero entropy, so the second term is also zero.</p><p>Next, let g : X ? (0, 1) nc be any smooth function which attains the global minimum of (5), i.e.,</p><formula xml:id="formula_35">L AlignMaxEnt (g) = E (x,x)?p (x,x) g(x) ? g(x) 2 2 ? H (g(x)) = 0.<label>(29)</label></formula><p>Define h := g ? f : Z ? (0, 1) nc which is smooth because both g and f are smooth.</p><p>Writing x = f (z), (29) then implies in terms of h:</p><formula xml:id="formula_36">E (x,x)?p (x,x) h(z) ? h(z) 2 2 = 0 ,<label>(30)</label></formula><p>H (h(z)) = 0 .</p><p>Equation <ref type="bibr" target="#b29">(30)</ref> implies that the same invariance condition (9) used in the proofs of Thms. 4.2 and 4.3 must hold (a.s. w.r.t. p), and (31) implies that? = h(z) must be uniformly distributed on (0, 1) nc .</p><p>Step 2. Next, we show that h(z) = h(c, s) can only depend on the true content c and not on any of the style variables s. For this we use the same Step 2 as in the proofs of Thms. 4.2 and 4.3.</p><p>Step 3. Finally, we show that the mapping? = h(c) is invertible.</p><p>To this end, we make use of the following result from <ref type="bibr">[129]</ref>.</p><p>Proposition A.2 (Proposition 5 of [129]). Let M, N be simply connected and oriented C 1 manifolds without boundaries and h : M ? N be a differentiable map. Further, let the random variable z ? M be distributed according to z ? p(z) for a regular density function p, i.e., 0 &lt; p &lt; ?. If the pushforward p #h (z) of p through h is also a regular density, i.e., 0 &lt; p #h &lt; ?, then h is a bijection.</p><p>We apply this result to the simply connected and oriented C 1 manifolds without boundaries M = C and N = (0, 1) nc , and the smooth (hence, differentiable) map h : C ? (0, 1) nc which maps the random variable c to a uniform random variable? (as established in Step 1).</p><p>Since both p c (by assumption) and the uniform distribution (the pushforward of p c through h) are regular densities in the sense of Prop. A.2, we conclude that h is a bijection, i.e., invertible.</p><p>We have shown that for any smooth g : X ? (0, 1) nc which minimises L AlignMaxEnt , we have that c = g(x) = h(c) for a smooth and invertible h : C ? (0, 1) nc , i.e., c is block-identified by g.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional details on the Causal3DIdent data set</head><p>Using the Blender rendering engine <ref type="bibr" target="#b10">[11]</ref>, 3DIdent [129] is a recently proposed benchmark which contains hallmarks of natural environments (e.g. shadows, different lighting conditions, a 3D object), but allows for identifiability evaluation by exposing the underlying generative factors.</p><p>Each 224 ? 224 ? 3 image in the dataset shows a coloured 3D object which is located and rotated above a coloured ground in a 3D space. Furthermore, each scene contains a coloured spotlight which is focused on the object and located on a half-circle around the scene. The images are rendered based on a 10-dimensional latent, where: (i) three dimensions describe the XYZ position of the object, (ii) three dimensions describe the rotation of the object in Euler angles, (iii) two dimensions describe the colour (hue) of the object and the ground of the scene, respectively, and (iv) two dimensions describe the position and colour (hue) of the spotlight. For influence of the latent factors on the renderings, see <ref type="figure" target="#fig_3">Fig. 2 of [129]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Details on introduced object classes</head><p>3DIdent contained a single object class, Teapot <ref type="bibr" target="#b88">[89]</ref>. We add six additional object classes: Hare [121], Dragon [110], Cow <ref type="bibr" target="#b61">[62]</ref>, Armadillo <ref type="bibr" target="#b69">[70]</ref>, Horse <ref type="bibr" target="#b97">[98]</ref>, Head [111].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Details on latent causal graph</head><p>In 3DIdent, the latents are uniformly sampled independently. We instead impose a causal graph over the variables (see <ref type="figure" target="#fig_3">Fig. 2</ref>). While object class and all environment variables (spotlight position, spotlight hue, background hue) are sampled independently, all object variables are dependent. Specifically, for spotlight position, spotlight hue, and background hue, we sample from U <ref type="figure">(?1, 1)</ref>. We impose the dependence by varying the mean (?) of a truncated normal distribution with standard deviation ? = 0.5, truncated to the range [?1, 1].</p><p>Object rotation is dependent solely on object class, see Tab. 2 for details. Object position is dependent on both object class &amp; spotlight position, see Tab. 3. Object hue is dependent on object class, background hue, &amp; object hue, see Tab. 4. Hares blending into their environment as a form of active camouflage has been observed in Alaskan <ref type="bibr" target="#b77">[78]</ref>, Arctic <ref type="bibr" target="#b1">[2]</ref>, &amp; Snowshoe hares.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Dataset Visuals</head><p>We show 40 random samples from the marginal of each object class in Causal3DIdent in Figs. 3 to 9.           </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Numerical Data</head><p>In Tab. 5, we report mean ? std. dev. R 2 over 3 random seeds across four generative processes of increasing complexity using linear (instead of nonlinear) regression to predict c from?. The block-identification of content can clearly still be seen even if we consider a linear fit.</p><p>In <ref type="figure" target="#fig_22">Fig. 10</ref>, we perform an ablation on dim(?), visualising how varying the dimensionality of the learnt representation affects identifiability of the ground-truth content &amp; style partition. Generally, if dim(?) &lt; n c , there is insufficient capacity to encode all content, so a lower-dimensional mixture of content is learnt. Conversely, if dim(?) &gt; n c , the excess capacity is used to encode some style information, as that increases entropy.  On Dependence. As can be seen from Tab. 5, the corresponding inset table in ? 5.1, and <ref type="figure" target="#fig_22">Fig. 10</ref>, scores for identifying style increase substantially when statistical dependence within blocks and causal dependence between blocks are included. This finding can be explained as follows.</p><p>If we compare the performance for small latent dimensionalities (dim(?) &lt; n c ) between the first two (without) and the third plot (with statistical dependence) of <ref type="figure" target="#fig_22">Fig. 10</ref>, we observe a significantly higher score in identifying content for the latter (e.g., R 2 of ca. 0.4 vs 0.2 at dim(?) = 1). This suggest that the introduction of statistical dependence between content variables (as well as between style variables, and in how style variables change) in the third plot/row, reduces the effective dimensionality of the ground-truth latents and thus leads to higher content identifiability for the same dim(?) &lt; n c . Since the R 2 for content is already close to 1 for dim(?) = 3 in the third plot of <ref type="figure" target="#fig_22">Fig. 10</ref> (due to the smaller effective dimensionality induced by statistical dependence between c), when dim(?) = n c = 5 is used (as reported in Tab. 5), excess capacity is used to encode style, leading to a positive R 2 .</p><p>Regarding causal dependence (i.e., the fourth plot in <ref type="figure" target="#fig_22">Fig. 10</ref> and fourth row in Tab. 5), we note that the ground truth dependence between c and s is linear, i.e., p(s|c) is centred at a linear transformation a + Bc of c, see the data generating process in Appendix D for details. Given that our evaluation consists of predicting the ground truth c and s from the learnt representation? = g(x), if we were to block-identify c according to Defn. 4.1, we should be able to also predict some aspects of s from?, due to the linear dependence between c and s. This manifests in a relatively large R 2 for s in the last row of Tab. 5 and the corresponding table in ? 5.1.</p><p>To summarise, we highlight two main takeaways: (i) when latent dependence is present, this may reduce the effective dimensionality, so that some style is encoded in addition to content unless a smaller representation size is chosen; (ii) even though the learnt representation isolates content in the sense of Defn. 4.1, it may still be predictive of style when content and style are (causally) dependent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Causal3DIdent</head><p>Full version of Tab. 1: In Tab. 6, we a) provide the results for the individual axes of object position &amp; rotation and b) present additional rows omitted from Tab. 1 for space considerations.</p><p>Interestingly, we find that the variance across the individual axes is significantly higher for object position than object rotation. If we compare the causal dependence imposed for object position (see <ref type="table">Tab.</ref> 3) to the causal dependence imposed for object rotation (see <ref type="table">Tab.</ref> 2), we can observe that the dependence imposed over individual axes is also significantly more variable for position than rotation, i.e., for x the sine nonlinearity is used, for y the cosine nonlinearity is used, while for z, no dependence is imposed.</p><p>Regarding the additional rows, we can observe that the composition of image-level rotation &amp; crops yields results quite similar to solely using crops, a relationship which mirrors how transforming the rotation &amp; position latents yields results quite similar to solely transforming the position latents. This suggests that the rotation variables are difficult to disentangle from the position variables in Causal3DIdent, regardless of whether data augmentation or latent transforms are used.</p><p>Finally, we can observe that applying image-level rotation in conjunction with small crops &amp; colour distortion does lead to a difference in the encoding, background hue is preserved, while the scores for object position &amp; rotation appear to slightly decrease. When using three augmentations as opposed to two, the effects of the individual augmentations are lessened. While colour distortion discourages the encoding of background hue, both small crops &amp; image-level rotation encourages it, and thus it is preserved when all three augmentations are used. While colour distortion encourages the encoding of object position &amp; rotation, both small crops &amp; image-level rotation discourage it, but as a causal relationship exists between the class variable and said latents, the scores merely decrease, the latents are still for the most part preserved. In reality, where complex interactions between latent variables abound, the effect of data augmentations may be uninterpretable, however with Causal3DIdent, we are able to interpret their effects in the presence of rich visual complexity and causal dependencies, even when applying three distinct augmentations in tandem. DA: colour distortion 0.42 ? 0.01 0.58 ? 0.01 0.75 ? 0.00 0.52 ? 0.01 0.17 ? 0.00 0.10 ? 0.01 0.01 ? 0.00 0.01 ? 0.00 0.36 ? 0.01 0.33 ? 0.01 0.32 ? 0.00 LT: change hues 1.00 ? 0.00 0.81 ? 0.02 0.81 ? 0.02 0.15 ? 0.02 0.91 ? 0.00 0.30 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.30 ? 0.02 0.30 ? 0.01 0.30 ? 0.01 DA: crop (large) 0.28 ? 0.04 0.04 ? 0.02 0.03 ? 0.01 0.19 ? 0.02 0.21 ? 0.13 0.87 ? 0.00 0.09 ? 0.02 1.00 ? 0.00 0.00 ? 0.00 0.05 ? 0.00 0.02 ? 0.00 DA: crop (small) 0.14 ? 0.00 0.00 ? 0.00 0.01 ? 0.02 0.00 ? 0.00 0.00 ? 0.01 0.00 ? 0.00 0.00 ? 0.00 1.00 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 LT: change positions 1.00 ? 0.00 0.01 ? 0.00 0.47 ? 0.01 0.01 ? 0.00 0.00 ? 0.01 0.46 ? 0.02 0.00 ? 0.00 0.97 ? 0.00 0.30 ? 0.00 0.29 ? 0.00 0.28 ? 0.00 DA: crop (large) + colour distortion 0.97 ? 0.00 0.59 ? 0.03 0.52 ? 0.01 0.68 ? 0.01 0.59 ? 0.05 0.28 ? 0.00 0.01 ? 0.01 0.01 ? 0.00 0.74 ? 0.01 0.78 ? 0.00 0.72 ? 0.00 DA: crop (small) + colour distortion 1.00 ? 0.00 0.72 ? 0.02 0.65 ? 0.02 0.70 ? 0.00 0.93 ? 0.00 0.30 ? 0.01 0.00 ? 0.00 0.02 ? 0.03 0.53 ? 0.00 0.57 ? 0.01 0.58 ? 0.01 LT: change positions + hues 1.00 ? 0.00 0.10 ? 0.10 0.49 ? 0.02 0.06 ? 0.05 0.07 ? 0.08 0.32 ? 0.02 0.00 ? 0.01 0.02 ? 0.03 0.34 ? 0.09 0.34 ? 0.04 0.34 ? 0.08 DA: rotation 0.33 ? 0.06 0.29 ? 0.03 0.11 ? 0.01 0.12 ? 0.04 0.23 ? 0.12 0.83 ? 0.01 0.30 ? 0.12 0.99 ? 0.00 0.02 ? 0.01 0.06 ? 0.03 0.07 ? 0.01 LT: change rotations 1.00 ? 0.00 0.78 ? 0.01 0.72 ? 0.03 0.09 ? 0.03 0.90 ? 0.00 0.41 ? 0.00 0.00 ? 0.00 0.97 ? 0.00 0.28 ? 0.00 0.28 ? 0.00 0.28 ? 0.00 DA: rotation + colour distortion 0.59 ? 0.01 0.63 ? 0.01 0.57 ? 0.08 0.54 ? 0.02 0.21 ? 0.01 0.12 ? 0.02 0.01 ? 0.00 0.01 ? 0.00 0.36 ? 0.03 0.34 ? 0.04 0.30 ? 0.03 LT: change rotations + hues 1.00 ? 0.00 0.80 ? 0.02 0.77 ? 0.01 0.13 ? 0.02 0.91 ? 0.00 0.30 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.28 ? 0.00 0.28 ? 0.01 0.28 ? 0.00 DA: rot. + crop (lg) 0.26 ? 0.01 0.03 ? 0.02 0.03 ? 0.01 0.15 ? 0.04 0.04 ? 0.03 0.84 ? 0.06 0.10 ? 0.01 1.00 ? 0.00 0.00 ? 0.00 0.04 ? 0.02 0.02 ? 0.00 DA: rot. + crop (sm) 0.15 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 1.00 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 LT: change rot. + pos.</p><p>1.00 ? 0.00 0.   1.00 ? 0.00 0.28 ? 0.20 0.12 ? 0.05 0.31 ? 0.00 0.00 ? 0.00 0.01 ? 0.01 0.37 ? 0.06 The fact that we can recover certain content variables which appeared discarded in the output from the intermediate layer may suggest that we should be able to decode class. While scores are certainly increased, we do not see such drastic differences in R 2 scores, as was seen above. The drastic difference highlighted above was with regards to latent transformation, for which we always observed class encoded as a content variable. So, unfortunately, using an intermediate layer does not rectify the discrepancy between data augmentations and latent transformations. While latent transformations allow us to better interpret the effect of certain empirical techniques <ref type="bibr" target="#b19">[20]</ref>, as discussed in the main paper, we cannot make a one-to-one correspondence between data augmentations used in practice and latent transformations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BarlowTwins:</head><p>We repeat our analysis from ? 5.2 using BarlowTwins [128] (instead of SimCLR) which, as discussed at the end of ? 4.2, is also loosely related to Thm. 4.4. The BarlowTwins objective consists of an invariance term, which equates the diagonal elements of the cross-correlation matrix to 1, thereby making the embedding invariant to the distortions applied and a redundancy reduction term, which equates the off-diagonal elements of the cross-correlation matrix to 0, thereby decorrelating the different vector components of the embedding, reducing the redundancy between output units.</p><p>In Tab. 10 we train BarlowTwins with ? = 0.0051, the default value for the hyperparameter which weights the redundancy reduction term relative to the invariance term. To confirm the insights are robust to the value of ?,in Tab. 11, we report results with ? increased by an order of magnitude, ? = 0.051. We find that the results mirror Tab. 1, e.g. colour distortion yields a discarding of hue, crops isolate background hue where the larger the crop, the higher the identifiability of object hue, and crops &amp; colour distortion yield high accuracy in inferring the object class variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 MPI3D-real</head><p>We ran the same experimental setup as in ? 5.2 also on the MPI3D-real dataset <ref type="bibr" target="#b37">[38]</ref> containing &gt; 1 million real images with ground-truth annotations of 3D objects being moved by a robotic arm.  As MPI3D-real contains much lower resolution images (64 ? 64) compared to ImageNet &amp; Causal3DIdent (224 ? 224), we used the standard convolutional encoder from the disentanglement literature <ref type="bibr" target="#b81">[82]</ref>, and ran a sanity check experiment to verify that by training the same backbone as in our unsupervised experiment with supervised learning, we can recover the ground-truth factors from the augmented views. In Tab. 13, we observe that only five out of seven factors can be consistently inferred, object shape and size are somewhat ambiguous even when observing the original image. Note that while in the self-supervised case, we evaluate by training a nonlinear regression for each ground truth factor separately, in the supervised case, we train a network for all ground truth factors simultaneously from scratch for as many gradient steps as used for learning the self-supervised model.</p><p>In Tab. 12, we report the evaluation results in the self-supervised scenario. Subject to the aforementioned caveats, the results show a similar trend as those on Causal3DIdent, i.e. with colour distortion, color factors of variation are decoded significantly worse than positional/rotational information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Experimental details</head><p>Ground-truth generative model. The generative process used in our numerical simulations ( ? 5.1) is summarised by the following: When we do not allow for statistical dependence (Stat.) within blocks of content and style variables, we set the covariance matrices ? c , ? s , and ? to the identity. When we do not allow for causal dependence (Cau.) of style on content, we set a i , b ij = 0, ?i, j.</p><p>For f MLP , we use a 3-layer MLP with LeakyReLU (? = 0.2) activation functions, specified using the same process as used in previous work <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr">129]</ref>. For the square weight matrices, we draw (n c + n s ) ? (n c + n s ) samples from U (?1, 1), and perform l 2 column normalisation. In addition, to control for invertibility, we re-sample the weight matrices until their condition number is less than or equal to a threshold value. The threshold is pre-computed by sampling 24, 975 weight matrices, and recording the minimum condition number.</p><p>Training encoder. Recall that the result of Thm. 4.4 corresponds to minimizing the following functional (5):</p><p>L AlignMaxEnt (g) := E (x,x)?p x,x g(x) ? g(x) 2 ? H (g(x)) .</p><p>Note that InfoNCE <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b90">91]</ref> (1) can be rewritten as:</p><formula xml:id="formula_38">L InfoNCE (g; ?, K) = E {xi,xi} K i=1 ?px,x ? K i=1 sim(g(x) i , g(x) i )/? + log K j=1 exp{sim(g(x) i , g(x) j )/? } .<label>(32)</label></formula><p>Thus, if we consider ? = 1, and sim(u, v) = ?(u ? v) 2 ,</p><formula xml:id="formula_39">L InfoNCE (g; K) = E {xi,xi} K i=1 ?px,x K i=1 g(x) i ? g(x) i 2 + log K j=1 exp{?(g(x) i ? g(x) j ) 2 }<label>(33)</label></formula><p>we can approximately match the form of <ref type="bibr" target="#b4">(5)</ref>. In practice, we use K = 6, 144.</p><p>For g, as in [129], we use a 7-layer MLP with (default) LeakyReLU (? = 0.01) activation functions. As the input dimensionality is (n c + n s ), we consider the following multipliers <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b9">10]</ref> for the number of hidden units per layer. In correspondence with Thm. 4.4, we set the output dimensionality to n c .</p><p>We train our feature encoder for 300, 000 iterations, using Adam <ref type="bibr" target="#b65">[66]</ref> with a learning rate of 10 ?4 .</p><p>Causal3DIdent. We here elaborate on details specific to the experiments in ? 5.2. We train the feature encoder for 200, 000 iterations using Adam with a learning rate of 10 ?4 . For the encoder we use a ResNet18 <ref type="bibr" target="#b45">[46]</ref> architecture followed by a single hidden layer with dimensionality 100 and LeakyReLU activation function using the default (0.01) negative slope. The scores are evaluated on a test set consisting of 25, 000 samples not included in the training set.</p><p>Data augmentations. We here specify the parameters for the data augmentations we considered:</p><p>? colour distortion: see the paragraph labelled "Color distortion" in Appendix A of <ref type="bibr" target="#b19">[20]</ref> for details. We use s = 1.0, the default value. ? crop: see the paragraph labelled "Random crop and resize to 224 ? 224" in Appendix A of <ref type="bibr" target="#b19">[20]</ref> for details. For small crops, a crop of random size (uniform from 0.08 to 1.0 in area) of the original size is made, which corresponds to what was used in the experiments reported in <ref type="bibr" target="#b19">[20]</ref>. For large crops, a crop of random size (uniform from 0.8 to 1.0 in area) of the original size is made. ? rotation: as specified in the captions for <ref type="figure" target="#fig_16">Figure 4</ref> &amp; <ref type="table">Table 3</ref> in <ref type="bibr" target="#b19">[20]</ref>, we sample one of {0?, 90?, 180?, 270?} uniformly. Note that for the pair, we sample two values without replacement.</p><p>A visual overview of the effect of these image-level data augmentations is shown in <ref type="figure" target="#fig_24">Fig. 11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Latent transformations. To generate views via latent transformations (LT) in our experiments on</head><p>Causal3DIdent ( ? 5.2), we proceed as follows.</p><p>Let z refer to the latent corresponding to the original image. For all latents specified to change, we sample? from a truncated normal distribution constrained to [?1, 1], centered at z, with ? = 1.. Then, we use nearest-neighbor matching to find the latent? closest to? (in L 2 distance) for which there exists an image rendering. <ref type="bibr" target="#b14">15</ref> Evaluation. Recall that Thm. 4.4 states that g block-identifies the true content variables in the sense of Defn. 4.1, i.e., there exists an invertible function h : R nc ? R nc s.t.? = h(c).</p><p>Since this is different from typical evaluation in disentanglement or ICA in that we do not assume independence and do not aim to find a one-to-one correspondence between inferred and ground truth latents, existing metrics, such as MCC <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref> or MIG <ref type="bibr" target="#b17">[18]</ref>, do not apply.</p><p>We therefore treat identifying h as a regression task, which we solve using kernel ridge regression with a Gaussian kernel <ref type="bibr" target="#b87">[88]</ref>. Since the Gaussian kernel is universal, this constitutes a nonparametric regression technique with universal approximation capabilities, i.e., any nonlinear function can be approximated arbitrarily well given sufficient data.</p><p>We sample 4096 ? 10 datapoints from the marginal for evaluation. For kernel ridge regression, we standardize the inputs and targets, and fit the regression model on 4096 ? 5 (distinct) datapoints. We tune the regularization strength ? and kernel variance ? by 3-fold cross-validated grid search over the following parameter grids: ? ? </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Assumption 3 . 1 (</head><label>31</label><figDesc>Content-invariance). The conditional density pz |z over Z ? Z takes the form pz |z (z|z) = ?(c ? c)ps |s (s|s)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Definition 4 . 1 (</head><label>41</label><figDesc>Block-identifiability). We say that the true content partition c = f ?1 (x) 1:nc is block-identified by a function g : X ? Z if the inferred content partition? = g(x) 1:nc contains all and only information about c, i.e., if there exists an invertible function h : R nc ? R nc s.t.? = h(c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>(Left) Causal graph for the Causal3DIdent dataset. (Right) Two samples from each object class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>A. 1 2 Theorem 4 . 2 (</head><label>1242</label><figDesc>. 4.2 is also used in the proofs of Thms. 4.3 and 4.4. Proof of Thm. 4.Identifying content with a generative model). Consider the data generating process described in ? 3, i.e., the pairs (x,x) of original and augmented views are generated according to (2) and (3) with pz |z as defined in Assumptions 3.1 and 3.2. Assume further that (i) f : Z ? X is smooth and invertible with smooth inverse (i.e., a diffeomorphism); (ii) p z is a smooth, continuous density on Z with p z (z) &gt; 0 almost everywhere; (iii) for any l ? {1, ..., n s }, ?A ? {1, ..., n s } s.t. l ? A; p A (A) &gt; 0; ps A |s A is smooth w.r.t. both s A ands A ; and for any s A , ps A |s A (?|s A ) &gt; 0 in some open, non-empty subset containing s A .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>strictly positive: it takes strictly positive values on open sets of R seen as a topological subspace of C ? S ? S. These open sets are defined by the induced topology: they are the intersection of the open sets of C ? S ? S with R. An open set B of V on which p(c, s,s|A) &gt; 0 then satisfies P (B|A) &gt; 0. We look for such an open set to prove our result.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>2 .</head><label>2</label><figDesc>Suppose for a contradiction that h c (c, s) := h(c, s) 1:nc = h(z) 1:nc depends on some component of the style variable s: ?l ? {1, ..., n s }, (c * , s * ) ? C ? S, s.t. ?h c ?s l (c * , s * ) = 0,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>where s ?l ? S ?l denotes the vector of remaining style variables except s l . Next, define the auxiliary function ? : C ? S ? S ? R ?0 as follows: ?(c, s,s) := |h c (c, s) ? h c (c,s)| ? 0 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>, it is important that s l ands l take values in disjoint open subsets of the interval (s * l ? ?, s * l + ?) from (11). Since ? is a composition of continuous functions (absolute value of the difference of two continuous functions), ? is continuous. Consider the open set R &gt;0 , and recall that, under a continuous function, pre-images (or inverse images) of open sets are always open.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Applied to the continuous function ?, this pre-image corresponds to an open set U ? C ? S ? S (14)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>cannot hold, i.e., h c (c, s) does not depend on any style variable s l . It is thus only a function of c, i.e.,? = h c (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Finally, smoothness and</head><label></label><figDesc>invertibility of h c : C ? C follow from smoothness and invertibility of h, as established in Step 1. This concludes the proof that? is related to the true content c via a smooth invertible mapping. A.2 Proof of Thm. 4.3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Theorem 4 . 3 (</head><label>43</label><figDesc>Identifying content with an invertible encoder). Assume the same data generating process ( ? 3) and conditions (i)-(iv) as in Thm. 4.2. Let g : X ? Z be any smooth and invertible function which minimises the following functional: L Align (g) := E (x,x)?p x,x g(x) 1:nc ? g(x) 1:nc 2 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>3 :</head><label>3</label><figDesc>Given a certain object class &amp; spotlight position, the center of the truncated normal distribution from which we sample xy-position latents varies. Note the spotlight position pos spl is rescaled from [?1, 1] to [??/2, ?/2]. pos spl ) ? cos(pos spl ) 0 Dragon ? sin(pos spl ) ? cos(pos spl ) 0 Cow sin(pos spl ) cos(pos spl ) 0 Armadillo sin(pos spl ) cos(pos spl ) 0 Horse ? sin(pos spl ) ? cos(pos spl ) 0 Head sin(pos spl ) cos(pos spl ) 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 3 :</head><label>3</label><figDesc>40 random samples from the marginal distribution of the Teapot object class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 4 :</head><label>4</label><figDesc>40 random samples from the marginal distribution of the Hare object class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 5 :</head><label>5</label><figDesc>40 random samples from the marginal distribution of the Dragon object class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 6 :</head><label>6</label><figDesc>40 random samples from the marginal distribution of the Cow object class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 7 :</head><label>7</label><figDesc>40 random samples from the marginal distribution of the Armadillo object class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 8 :</head><label>8</label><figDesc>40 random samples from the marginal distribution of the Horse object class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 9 :</head><label>9</label><figDesc>40 random samples from the marginal distribution of the Head object class. C Additional results ? Appendix C.1 contains numerical experiments, namely linear evaluation &amp; an ablation on dim(?). ? Appendix C.2 contains experiments on Causal3DIdent, namely (i) nonlinear &amp; linear evaluation results of the output &amp; intermediate feature representation of SimCLR with results for the individual axes of object position &amp; rotation, and (ii) evaluation of BarlowTwins. ? Appendix C.3 contains experiments on the MPI3D-real dataset [38], namely SimCLR &amp; a supervised sanity check.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 10 :</head><label>10</label><figDesc>Identifiability of the content &amp; style partition in the numerical experiment as a function of the model latent dimensionality</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>c</head><label></label><figDesc>? p(c) = N (0, ? c ), with ? c ? Wishart nc (I, n c ),s|c ? p(s|c) = N (a + Bc, ? s ), with ? s ? Wishart ns (I, n s ), a i , b ij i.i.d. ? N (0, 1), s A |s A , A ? p(s A |s A ) = N (s A , ?(A)) with ? ? Wishart ns (I, n s ), (x, x) = (f MLP (z), f MLP (z)),where the set of changing style vectors A is obtained by flipping a (biased) coin with p(chg.) = 0.75 for each style dimension independently, and where ?(A) denotes the submatrix of ? defined by selecting the rows and columns corresponding to subset A.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 11 :</head><label>11</label><figDesc>Visual overview of the effect of different data augmentations (DA), applied to 10 representative samples. Rows correspond to (top to bottom): original images, small random crop (+ random flip), large random crop (+ random flip), colour distortion (jitter &amp; drop), and random rotation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head></head><label></label><figDesc>[1, 0.1, 0.001, 0.0001], ? ? [0.01, 0.22, 4.64, 100]. Compute. The experiments in ? 5.1 took on the order of 5-10 hours on a single GeForce RTX 2080 Ti GPU. The experiments in ? 5.2 on 3DIdent took 28 hours on four GeForce RTX 2080 Ti GPUs. The creation of the Causal3DIdent dataset additionally required approximately 150 hours of compute time on a GeForce RTX 2080 Ti.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>dataset. 3DIdent [129] is a benchmark for evaluating identifiability with rendered 224 ? 224 images which contains hallmarks of natural environments (e.g. shadows, different lighting conditions, a 3D object). For influence of the latent factors on the renderings, see Fig. 2 of [129]. In 3DIdent, there is a single object class (Teapot [89]), and all 10 latents are sampled independently. For Causal3DIdent, we introduce six additional classes: Hare [121], Dragon [110], Cow<ref type="bibr" target="#b61">[62]</ref>, Armadillo<ref type="bibr" target="#b69">[70]</ref>, Horse<ref type="bibr" target="#b97">[98]</ref>, and Head [111]; and impose a causal graph over the latent variables, seeFig. 2. While object class and all environment variables (spotlight position &amp; hue, background hue) are sampled independently, all object latents are dependent, 11 see Appendix B for details.<ref type="bibr" target="#b11">12</ref> </figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Causal3DIdent results: R 2 mean ? std. dev. over 3 random seeds. DA: data augmentation, LT: latent transformation, bold: R 2 ? 0.5, red: R 2 &lt; 0.25. Results for individual axes of object position &amp; rotation are aggregated, see Appendix C for the full table.</figDesc><table><row><cell>Views generated by</cell><cell>Class</cell><cell>Positions</cell><cell></cell><cell>Hues</cell><cell>Rotations</cell></row><row><cell></cell><cell>object</cell><cell>spotlight</cell><cell>object</cell><cell>spotlight</cell><cell>background</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>). Further, we repeat our analysis from ? 5.2 using BarlowTwins [128] (instead of SimCLR) which, as discussed at the end of ? 4.2, is also loosely related to Thm. 4.4. The results mostly mirror those obtained for SimCLR and presented in Tab. 1, see Appendix C.2 for details. Finally, we ran the same experimental setup as in ? 5.2 also on the MPI3D-real dataset<ref type="bibr" target="#b37">[38]</ref> containing &gt; 1 million real images with ground-truth annotations of 3D objects being moved by a robotic arm. Subject to some caveats, the results show a similar trend as those on Causal3DIdent, see Appendix C.3 for details.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>/graphics.stanford.edu/data/3Dscanrep/, 2021. /gfx.cs.princeton.edu/proj/sugcon/models/, 2021. [112] Raphael Suter, Djordje Miladinovic, Bernhard Sch?lkopf, and Stefan Bauer. Robustly disentangled causal mechanisms: Validating deep representations for interventional robustness. In International Conference on Machine Learning, pages 6056-6065. PMLR, 2019. Proceedings of the 38th International Conference on Machine Learning, volume 139, pages 12310-12320, 2021.</figDesc><table><row><cell></cell><cell>Scanning</cell><cell>Repository.</cell><cell>The</cell><cell>Stanford</cell><cell>3D</cell><cell>Scanning</cell><cell>Repository.</cell></row><row><cell>http:/[111] Suggestive</cell><cell>Contour</cell><cell>Gallery.</cell><cell></cell><cell>Suggestive</cell><cell></cell><cell>Contour</cell><cell>Gallery</cell><cell>.</cell></row><row><cell>https:/</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>[113] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Computer Vision and Pattern Recognition (CVPR), 2015.[114] Fabian Theis. Towards a general independent subspace analysis. Advances in Neural Information Processing Systems, 19:1361-1368, 2006.[115] Yonglong Tian, Dilip Krishnan, and Phillip Isola. Contrastive multiview coding. In Computer Vision - ECCV 2020, volume 12356, pages 776-794. Springer, 2020.[116] Yuandong Tian, Xinlei Chen, and Surya Ganguli. Understanding self-supervised learning dynamics without contrastive pairs. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on Machine Learning,, volume 139, pages 10268-10278, 2021.[117] Christopher Tosh, Akshay Krishnamurthy, and Daniel Hsu. Contrastive estimation reveals topic posterior information to linear models. arXiv preprint arXiv:2003.02234, 2020.[118] Christopher Tosh, Akshay Krishnamurthy, and Daniel Hsu. Contrastive learning, multi-view redundancy, and linear models. In Algorithmic Learning Theory, pages 1179-1206. PMLR, 2021.[119] Yao-Hung Hubert Tsai, Yue Wu, Ruslan Salakhutdinov, and Louis-Philippe Morency. Self-supervised learning from a multi-view perspective. In International Conference on Learning Representations, 2020.[120] Michael Tschannen, Josip Djolonga, Paul K. Rubenstein, Sylvain Gelly, and Mario Lucic. On mutual information maximization for representation learning. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020.[121] Greg Turk and Marc Levoy. Zippered polygon meshes from range images. In Dino Schweitzer, Andrew S. Glassner, and Mike Keeler, editors, Proceedings of the 21th Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH 1994, Orlando, FL, USA, July 24-29, 1994, pages 311-318. ACM, 1994.[122] Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. Extracting and compos- ing robust features with denoising autoencoders. In Proceedings of the 25th International Conference on Machine Learning, pages 1096-1103, 2008.[123] Julius von K?gelgen, Ivan Ustyuzhaninov, Peter Gehler, Matthias Bethge, and Bernhard Sch?lkopf. Towards causal generative scene models via competition of experts. In ICLR Workshop on "Causal Learning for Decision Making", 2020.[124] Tongzhou Wang and Phillip Isola. Understanding contrastive representation learning through alignment and uniformity on the hypersphere. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Proceedings of Machine Learning Research, pages 9929-9939. PMLR, 2020.[125] Xiaolong Wang and Abhinav Gupta. Unsupervised learning of visual representations using videos. In Proceedings of the IEEE International Conference on Computer Vision, pages 2794-2802, 2015.[126] Zhirong Wu, Yuanjun Xiong, Stella X. Yu, and Dahua Lin. Unsupervised feature learning via non- parametric instance discrimination. In Conference on Computer Vision and Pattern Recognition, CVPR, pages 3733-3742. IEEE Computer Society, 2018.[127] Mengyue Yang, Furui Liu, Zhitang Chen, Xinwei Shen, Jianye Hao, and Jun Wang. Causalvae: Structured causal disentanglement in variational autoencoder. arXiv preprint arXiv:2004.08697, 2020.[128] Jure Zbontar, Li Jing, Ishan Misra, Yann LeCun, and St?phane Deny. Barlow twins: Self-supervised learning via redundancy reduction. In Marina Meila and Tong Zhang, editors,[129] Roland S. Zimmermann, Yash Sharma, Steffen Schneider, Matthias Bethge, and Wieland Brendel. Contrastive learning inverts the data generating process. In Proceedings of the 38th International Conference on Machine Learning, volume 139, pages 12979-12990, 2021.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Then, also by assumption (iii), for any s A ? S A , there is an open subset O(s A ) ? S A containing s A , such that ps A |s A (?|s A ) &gt; 0 within O(s A ).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2 :</head><label>2</label><figDesc>Given a certain object class, the center of the truncated normal distribution from which we sample rotation latents varies.</figDesc><table><row><cell cols="4">object class ?(?) ?(?) ?(?)</cell></row><row><cell>Teapot</cell><cell cols="2">-0.35 0.35</cell><cell>0.35</cell></row><row><cell>Hare</cell><cell cols="3">0.35 -0.35 0.35</cell></row><row><cell>Dragon</cell><cell>0.35</cell><cell cols="2">0.35 -0.35</cell></row><row><cell>Cow</cell><cell cols="3">0.35 -0.35 -0.35</cell></row><row><cell>Armadillo</cell><cell cols="3">-0.35 0.35 -0.35</cell></row><row><cell>Horse</cell><cell cols="3">-0.35 -0.35 0.35</cell></row><row><cell>Head</cell><cell cols="3">-0.35 -0.35 -0.35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Given a certain object class, background hue, and spotlight hue, the center of the truncated normal distribution from which we sample the object hue latent varies. Note that for the Hare and Dragon classes, in particular, the object either blends in or stands out from the environment.</figDesc><table><row><cell>object class</cell><cell>?(hue)</cell></row><row><cell>Teapot</cell><cell>0</cell></row><row><cell>Hare Dragon</cell><cell>huebg+huespl 2 huebg+huespl ? 2</cell></row><row><cell>Cow</cell><cell>?0.35</cell></row><row><cell>Armadillo</cell><cell>0.7</cell></row><row><cell>Horse</cell><cell>?0.7</cell></row><row><cell>Head</cell><cell>0.35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Results using linear regression for the experiment on numerical data presented in ? 5.1</figDesc><table><row><cell>Generative process</cell><cell cols="2">R 2 (linear)</cell></row><row><cell>p(chg.) Stat. Cau.</cell><cell>Content c</cell><cell>Style s</cell></row><row><cell>1.0</cell><cell cols="2">1.00 ? 0.00 0.00 ? 0.00</cell></row><row><cell>0.75</cell><cell cols="2">0.99 ? 0.00 0.00 ? 0.00</cell></row><row><cell>0.75</cell><cell cols="2">0.97 ? 0.03 0.37 ? 0.05</cell></row><row><cell>0.75</cell><cell cols="2">0.98 ? 0.01 0.78 ? 0.07</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Full version of Tab. 1.</figDesc><table><row><cell>Views generated by</cell><cell>Class</cell><cell cols="2">Positions</cell><cell></cell><cell></cell><cell>Hues</cell><cell></cell><cell></cell><cell>Rotations</cell></row><row><cell></cell><cell>object(x)</cell><cell>object(y)</cell><cell>object(z)</cell><cell>spotlight</cell><cell>object</cell><cell>spotlight</cell><cell>background</cell><cell>object(?)</cell><cell>object(?)</cell><cell>object(?)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>02 ? 0.03 0.48 ? 0.02 0.01 ? 0.01 0.02 ? 0.03 0.49 ? 0.03 0.03 ? 0.02 0.98 ? 0.00 0.29 ? 0.01 0.28 ? 0.01 0.28 ? 0.01 DA: rot. + crop (lg) + col. dist. 0.99 ? 0.00 0.69 ? 0.03 0.60 ? 0.01 0.70 ? 0.02 0.86 ? 0.03 0.28 ? 0.00 0.01 ? 0.00 0.01 ? 0.00 0.60 ? 0.01 0.64 ? 0.02 0.61 ? 0.01 DA: rot. + crop (sm) + col. dist. 1.00 ? 0.00 0.61 ? 0.02 0.59 ? 0.01 0.64 ? 0.01 0.82 ? 0.01 0.38 ? 0.00 0.01 ? 0.01 0.78 ? 0.03 0.44 ? 0.00 0.48 ? 0.02 0.45 ? 0.01 LT: change rot. + pos. + hues 1.00 ? 0.00 0.20 ? 0.12 0.50 ? 0.04 0.14 ? 0.11 0.15 ? 0.12 0.32 ? 0.01 0.00 ? 0.00 0.02 ? 0.01 0.33 ? 0.04 0.33 ? 0.02 0.32 ? 0.03 Linear identifiability: In Tab. 7, we present results evaluating all continuous variables with linear regression. While, as expected, R 2 scores are reduced across the board, we can observe that even with a linear fit, the patterns observed in Tab. 6 persist.</figDesc><table /><note>Intermediate feature evaluation: In Tab. 8 and Tab. 9, we present evaluation based on the repre- sentation from an intermediate layer (i.e., prior to applying a projection layer [20]) with nonlinear and linear regression for the continuous variables, respectively. Note the intermediate layer has an</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>Evaluation results using a linear fit for not only class, but all continuous variables.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>BarlowTwins ? = 0.0051 results: R 2 mean ? std. dev. over 3 random seeds. DA: data augmentation, LT: latent transformation, bold: R 2 ? 0.5, red: R 2 &lt; 0.25. Results for individual axes of object position &amp; rotation are aggregated. ? 0.02 0.51 ? 0.14 0.07 ? 0.01 0.08 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.21 ? 0.04 LT: change hues 1.00 ? 0.00 0.56 ? 0.20 0.76 ? 0.07 0.30 ? 0.01 0.00 ? 0.00 0.01 ? 0.00 0.35 ? 0.01 DA: crop (large) 0.17 ? 0.02 0.10 ? 0.03 0.06 ? 0.02 0.29 ? 0.13 0.11 ? 0.05 0.99 ? 0.00 0.02 ? 0.01 DA: crop (small) 0.15 ? 0.00 0.04 ? 0.02 0.05 ? 0.02 0.02 ? 0.01 0.00 ? 0.01 1.00 ? 0.00 0.00 ? 0.01 LT: change positions 0.88 ? 0.00 0.19 ? 0.20 0.05 ? 0.00 0.50 ? 0.02 0.04 ? 0.01 0.98 ? 0.00 0.27 ? 0.03 DA: crop (large) + colour distortion 0.87 ? 0.02 0.49 ? 0.06 0.32 ? 0.03 0.25 ? 0.01 0.00 ? 0.00 0.00 ? 0.00 0.50 ? 0.02 DA: crop (small) + colour distortion 0.81 ? 0.01 0.39 ? 0.07 0.42 ? 0.06 0.47 ? 0.04 0.03 ? 0.01 0.85 ? 0.02 0.30 ? 0.02 LT: change positions + hues</figDesc><table><row><cell>Views generated by</cell><cell>Class</cell><cell>Positions</cell><cell></cell><cell>Hues</cell><cell>Rotations</cell></row><row><cell></cell><cell>object</cell><cell>spotlight</cell><cell>object</cell><cell>spotlight</cell><cell>background</cell></row><row><cell>DA: colour distortion</cell><cell>0.48</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 :</head><label>11</label><figDesc>BarlowTwins ? = 0.051 results: R 2 mean ? std. dev. over 3 random seeds. DA: data augmentation, LT: latent transformation, bold: R 2 ? 0.5, red: R 2 &lt; 0.25. Results for individual axes of object position &amp; rotation are aggregated. ? 0.07 0.43 ? 0.18 0.07 ? 0.02 0.10 ? 0.03 0.00 ? 0.00 0.00 ? 0.00 0.21 ? 0.05 LT: change hues 1.00 ? 0.00 0.55 ? 0.24 0.74 ? 0.02 0.30 ? 0.00 0.00 ? 0.00 0.01 ? 0.01 0.33 ? 0.02 DA: crop (large) 0.19 ? 0.05 0.08 ? 0.02 0.05 ? 0.01 0.39 ? 0.36 0.08 ? 0.05 0.96 ? 0.05 0.01 ? 0.02 DA: crop (small) 0.15 ? 0.00 0.05 ? 0.02 0.07 ? 0.02 0.00 ? 0.01 0.01 ? 0.01 1.00 ? 0.00 0.00 ? 0.00 LT: change positions 0.89 ? 0.01 0.19 ? 0.20 0.05 ? 0.01 0.48 ? 0.04 0.05 ? 0.02 0.98 ? 0.00 0.25 ? 0.03 DA: crop (large) + colour distortion 0.86 ? 0.03 0.40 ? 0.07 0.23 ? 0.02 0.24 ? 0.01 0.00 ? 0.00 0.00 ? 0.00 0.47 ? 0.04 DA: crop (small) + colour distortion 0.99 ? 0.01 0.63 ? 0.03 0.88 ? 0.01 0.32 ? 0.02 0.00 ? 0.00 0.16 ? 0.13 0.52 ? 0.03 LT: change positions + hues 1.00 ? 0.00 0.21 ? 0.22 0.07 ? 0.01 0.30 ? 0.00 0.00 ? 0.00 0.02 ? 0.01 0.46 ? 0.06 intermediate layer. With that being said, our theoretical result applies to the final layer, which is why said results were highlighted in the main paper. The discarding of certain content variables is an empirical phenomenon, likely a consequence of a limited number of negative samples in practice, leading to certain content variables being redundant, or unnecessary, for solving the contrastive objective.</figDesc><table><row><cell>Views generated by</cell><cell>Class</cell><cell>Positions</cell><cell></cell><cell>Hues</cell><cell>Rotations</cell></row><row><cell></cell><cell>object</cell><cell>spotlight</cell><cell>object</cell><cell>spotlight</cell><cell>background</cell></row><row><cell>DA: colour distortion</cell><cell>0.52</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 12 :</head><label>12</label><figDesc>MPI3D-real results: R 2 mean ? std. dev. over 3 random seeds for dim(?)= 5. DA: data augmentation, bold: R 2 ? 0.5, red: R 2 &lt; 0.25. ? 0.01 0.00 ? 0.00 0.16 ? 0.011.00 ? 0.00 0.09 ? 0.15 0.60 ? 0.06 0.42 ? 0.08 DA: crop (large) 0.65 ? 0.17 0.01 ? 0.02 0.31 ? 0.03 1.00 ? 0.00 1.00 ? 0.00 0.37 ? 0.06 0.08 ? 0.03</figDesc><table><row><cell>Views generated by</cell><cell>object color object shape</cell><cell>object size</cell><cell cols="4">camera height background color horizontal axis vertical axis</cell></row><row><cell cols="3">DA: colour distortion 0.39 DA: crop (small) 0.09 ? 0.02 0.03 ? 0.00 0.19 ? 0.01</cell><cell>1.00 ? 0.00</cell><cell>1.00 ? 0.00</cell><cell>0.21 ? 0.02</cell><cell>0.07 ? 0.00</cell></row><row><cell>DA: crop (large) + colour distortion</cell><cell cols="2">0.34 ? 0.00 0.00 ? 0.00 0.22 ? 0.03</cell><cell>1.00 ? 0.00</cell><cell>0.39 ? 0.02</cell><cell>0.54 ? 0.01</cell><cell>0.29 ? 0.01</cell></row><row><cell cols="3">DA: crop (small) + colour distortion 0.25 ? 0.02 0.00 ? 0.00 0.10 ? 0.01</cell><cell>1.00 ? 0.00</cell><cell>0.75 ? 0.16</cell><cell>0.54 ? 0.01</cell><cell>0.29 ? 0.03</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 13 :</head><label>13</label><figDesc>Supervised MPI3D-real results: R 2 mean ? std. dev. over 3 random seeds. DA: data augmentation. bold: R 2 ? 0.5, red: R 2 &lt; 0.25.</figDesc><table><row><cell>Views generated by</cell><cell>object color object shape</cell><cell>object size</cell><cell cols="4">camera height background color horizontal axis vertical axis</cell></row><row><cell>Original</cell><cell cols="2">0.90 ? 0.01 0.25 ? 0.02 0.61 ? 0.02</cell><cell>0.99 ? 0.00</cell><cell>0.97 ? 0.01</cell><cell>1.00 ? 0.00</cell><cell>1.00 ? 0.00</cell></row><row><cell>DA: colour distortion</cell><cell cols="2">0.61 ? 0.01 0.11 ? 0.00 0.47 ? 0.01</cell><cell>0.98 ? 0.00</cell><cell>0.93 ? 0.00</cell><cell>0.99 ? 0.00</cell><cell>1.00 ? 0.00</cell></row><row><cell>DA: crop (large)</cell><cell cols="2">0.82 ? 0.01 0.05 ? 0.01 0.42 ? 0.02</cell><cell>0.97 ? 0.01</cell><cell>0.91 ? 0.00</cell><cell>0.96 ? 0.00</cell><cell>0.97 ? 0.01</cell></row><row><cell>DA: crop (small)</cell><cell cols="2">0.71 ? 0.04 0.01 ? 0.00 0.32 ? 0.02</cell><cell>0.95 ? 0.00</cell><cell>0.85 ? 0.01</cell><cell>0.79 ? 0.02</cell><cell>0.90 ? 0.01</cell></row><row><cell>DA: crop (large) + colour distortion</cell><cell cols="2">0.45 ? 0.02 0.02 ? 0.00 0.22 ? 0.00</cell><cell>0.95 ? 0.01</cell><cell>0.67 ? 0.01</cell><cell>0.91 ? 0.00</cell><cell>0.94 ? 0.00</cell></row><row><cell cols="3">DA: crop (small) + colour distortion 0.45 ? 0.02 0.00 ? 0.00 0.17 ? 0.02</cell><cell>0.91 ? 0.02</cell><cell>0.55 ? 0.03</cell><cell>0.69 ? 0.01</cell><cell>0.79 ? 0.08</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">E.g.,<ref type="bibr" target="#b68">[69]</ref>,Fig. 11where dependence between latents was demonstrated for multiple natural video data sets.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Note that recent work has investigated automatically discovering good augmentations<ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>.<ref type="bibr" target="#b2">3</ref> If the only goal is to make representations of augmented views similar, a degenerate solution which simply maps any observation to the origin trivially achieves this goal.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">This step is partially inspired by<ref type="bibr" target="#b82">[83]</ref>; the technique used to prove the second main step is entirely novel.<ref type="bibr" target="#b8">9</ref> which also uses a fixed content-style partition for multi-view data, but assumes that all latent factors are mutually independent, and that all style variables change between views, independent of the original style;</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">chosen to lead to invertibility almost surely by following the settings used by previous work<ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref> 11 e.g., our causal graph entails hares blend into the environment (object hue centered about background &amp; spotlight hue), a form of active camouflage observed in Alaskan<ref type="bibr" target="#b77">[78]</ref>, Arctic<ref type="bibr" target="#b1">[2]</ref>, &amp; Snowshoe hares.<ref type="bibr" target="#b11">12</ref> We made the Causal3DIdent dataset publicly available at this URL.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">See Appendix C.2 for results with linear regression, as well as evaluation using a higher-dimensional intermediate layer by considering a projection head<ref type="bibr" target="#b19">[20]</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14">class is distinguished by shape, a feature commonly unused in downstream tasks on natural images<ref type="bibr" target="#b35">[36]</ref> </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">[108] Rui Shu, Yining Chen, Abhishek Kumar, Stefano Ermon, and Ben Poole. Weakly supervised disentanglement with guarantees. In 8th International Conference on Learning Representations, 2020.[109] Peter Sorrenson, Carsten Rother, and Ullrich K?the. Disentanglement by nonlinear ica with general incompressible-flow networks (gin). In International Conference on Learning Representations, 2020.15[110] Stanford</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">see [129] for further details</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank: the anonymous reviewers for several helpful suggestions that triggered improvements in theory and additional experiments; Cian Eastwood, Ilyes Khemakem, Michael Lohaus, Osama Makansi, Ricardo Pio Monti, Roland Zimmermann, Weiyang Liu, and the MPI T?bingen causality group for helpful discussions and comments; Hugo Y?che for pointing out a mistake in ?2 of an earlier version of the manuscript; github user TangTangFei for catching a bug in the implementation of the experiments from ? 5.1 (that has been corrected in this version); and the International Max Planck Research School for Intelligent Systems (IMPRS-IS) for supporting YS. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding Transparency Statement</head></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>DA: colour distortion 0.42 ? 0.01 0.37 ? 0.03 0.20 ? 0.16 0.23 ? 0.02 0.01 ? 0.01 0.03 ? 0.01 ?0.00 ? 0.00 ?0.00 ? 0.00 0.13 ? 0.01 0.04 ? 0.01 0.09 ? 0.02 LT: change hues 1.00 ? 0.00 0.72 ? 0.07 0.56 ? 0.04 ?0.00 ? 0.00 0.65 ? 0.07 0.29 ? 0.01 ?0.00 ? 0.00 ?0.00 ? 0.00 0.27 ? 0.01 0.26 ? 0.03 0.26 ? 0.01 DA: crop (large) 0.28 ? 0.04 0.00 ? 0.00 0.02 ? 0.00 0.04 ? 0.07 0.08 ? 0.13 0.51 ? 0.05 0.03 ? 0.02 0.20 ? 0.04 0.00 ? 0.00 0.02 ? 0.00 0.01 ? 0.00 DA: crop (small) 0.14 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 0.17 ? 0.05 ?0.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 LT: change positions 1.00 ? 0.00 ?0.00 ? 0.00 0.44 ? 0.02 ?0.00 ? 0.00 ?0.00 ? 0.00 0. <ref type="bibr" target="#b28">29</ref>  1.00 ? 0.00 0.68 ? 0.02 0.57 ? 0.01 ?0.00 ? 0.00 0.72 ? 0.10 0.29 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 0.28 ? 0.00 0.28 ? 0.00 0.28 ? 0.00 DA: rot. + crop (lg) 0.26 ? 0.01 ?0.00 ? 0.00 0.02 ? 0.00 0.00 ? 0.00 0.00 ? 0.00 0.59 ? 0.05 0.02 ? 0.01 0.20 ? 0.04 0.00 ? 0.00 0.01 ? 0.00 0.01 ? 0.00 DA: rot. + crop (sm) 0.15 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 0.29 ? 0.21 ?0.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 LT: change rot. + pos.</p><p>1.00 ? 0.00 ?0.00 ? 0.00 0.45 ? 0.01 ?0.00 ? 0.00 ?0.00 ? 0.00 0.32 ? 0.02 0.00 ? 0.00 0. output dimensionality of 100. While it is clear that all R 2 scores are increased across the board, we can notice that certain latents which were discarded in the final layer, were not in an intermediate layer. For example, with "LT: change hues", in the final layer the z-position was discarded (R 2 = 0.15 in Tab. 6), inexplicably we may add, as position is content regardless of axis with this latent transformation. But in the intermediate layer, z-position was not discarded (R 2 = 0.88 in Tab. 8). 0.20 ? 0.01 0.07 ? 0.03 0.09 ? 0.10 0.01 ? 0.01 0.20 ? 0.01 ?0.00 ? 0.00 ?0.00 ? 0.00 1.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 ?0.00 ? 0.00 LT: change rot. + pos.</p><p>1.00 ? 0.00 0.  In <ref type="bibr" target="#b19">[20]</ref>, the value in evaluating an intermediate layer as opposed to a final layer is discussed, where the authors demonstrated that predicting the data augmentations applied during training is significantly more accurate from an intermediate layer as opposed to the final layer, implying that the intermediate layer contains much more information about the transformation applied. Our results suggest a distinct hypothesis, the value in using an intermediate layer as a representation for downstream tasks is not due to preservation of style information, as can be seen, R 2 scores on style variables are not significantly higher in Tab. 8 relative to Tab. 6. The value is in preservation of all content variables, as we can observe certain content variables are discarded in the final layer, but are preserved in an</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to see by moving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pulkit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="37" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arctic</forename><surname>Wildlife</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Churchill Polar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bears</surname></persName>
		</author>
		<ptr target="https://churchillpolarbears.org/churchill/" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Orestis Plevrakis, and Nikunj Saunshi. A theoretical analysis of contrastive unsupervised representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrishikesh</forename><surname>Khandeparkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Khodak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">36th International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9904" to="9923" />
		</imprint>
	</monogr>
	<note>International Machine Learning Society (IMLS)</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Buchwalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="15509" to="15519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">vq-wav2vec: Self-supervised learning of discrete speech representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Abdelrahman Mohamed, and Michael Auli. wav2vec 2.0: A framework for self-supervised learning of speech representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Self-organizing neural network that discovers surfaces in random-dot stereograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanna</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">355</biblScope>
			<biblScope unit="issue">6356</biblScope>
			<biblScope unit="page" from="161" to="163" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Invertible residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Behrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Grathwohl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rn-Henrik</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jacobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="573" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An information-maximization approach to blind separation and blind deconvolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrence</forename><forename type="middle">J</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1129" to="1159" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Representation learning: A review and new perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1798" to="1828" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Blender -a 3D modelling and rendering package. Blender Foundation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blender Online Community</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2021</biblScope>
			<pubPlace>Blender Institute, Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Signature verification using a &quot;siamese&quot; time delay neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>S?ckinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roopak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="737" to="744" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ilya Sutskever, and Dario Amodei. Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arka</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loic</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Watters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lerchner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03599</idno>
		<title level="m">Understanding disentangling in ?-VAE</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Infomax and maximum likelihood for blind source separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J-F</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal processing letters</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="112" to="114" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Separation of mixed audio sources by independent subspace analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Casey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Westner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICMC</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="154" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Incorporating invariances in nonlinear SVMs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="609" to="616" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Isolating sources of disentanglement in vaes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Ricky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuechen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grosse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2615" to="2625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A group-theoretic framework for data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuxiao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgar</forename><surname>Dobriban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">245</biblScope>
			<biblScope unit="page" from="1" to="71" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Exploring simple siamese representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15750" to="15758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Kuksa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2461" to="2505" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Independent component analysis, a new concept? Signal processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Comon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="287" to="314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Elements of Information Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joy A</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="113" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="702" to="703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A kernel theory of modern data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tri</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virginia</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">De</forename><surname>Sa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>R?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1528" to="1537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Analyse des liaisons de probabilit?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Darmois</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Stat. Conferences</title>
		<meeting>Int. Stat. Conferences</meeting>
		<imprint>
			<date type="published" when="1947" />
			<biblScope unit="page">231</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<title level="m">Improved regularization of convolutional neural networks with cutout</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">NICE: Non-linear independent components estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.8516</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Density estimation using real NVP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Interventions and causal inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederick</forename><surname>Eberhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Scheines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy of science</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="981" to="995" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricia</forename><surname>Rubisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<title level="m">Imagenet-trained cnns are biased towards texture; increasing shape bias improves accuracy and robustness. International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Shortcut learning in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rn-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Michaelis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="665" to="673" />
			<date type="published" when="2020-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On the transfer of inductive bias from simulation to the real world: a new disentanglement dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Waleed</forename><surname>Gondal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Wuthrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djordje</forename><surname>Miladinovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Breidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Volchkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Akpo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="15740" to="15751" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The Incomplete Rosetta Stone problem: Identifiability results for multi-view nonlinear ICA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><surname>Gresele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">K</forename><surname>Rubenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Mehrjou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI</title>
		<meeting>the Thirty-Fifth Conference on Uncertainty in Artificial Intelligence, UAI</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Independent mechanism analysis, a new concept?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><surname>Gresele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julius</forename><surname>Von K?gelgen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Stimper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Besserve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent -A new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><surname>Bernardo ?vila Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Valko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="307" to="361" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Hidden markov nonlinear ica: Unsupervised learning from nonstationary time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermanni</forename><surname>H?lv?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="939" to="948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9726" to="9735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Data-efficient image recognition with contrastive predictive coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>H?naff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="4182" to="4192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lo?c</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arka</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Group-based learning of disentangled representations with generalizability for novel contents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haruo</forename><surname>Hosoya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2506" to="2513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Some improvements on deep convolutional neural network based image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Emergence of phase-and shift-invariant features by decomposition of natural images into independent feature subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrik</forename><surname>Hoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1705" to="1720" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Unsupervised feature extraction by time-contrastive learning and nonlinear ICA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Morioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3765" to="3773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Nonlinear ica of temporally dependent stationary sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Morioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="460" to="469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Independent component analysis: algorithms and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erkki</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="411" to="430" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Nonlinear independent component analysis: Existence and uniqueness results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petteri</forename><surname>Pajunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="429" to="439" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Nonlinear ica using auxiliary variables and generalized contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroaki</forename><surname>Sasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="859" to="868" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Selecting data augmentation for simulating interventions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Ilse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Forr?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="4555" to="4562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rn-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Oyallon. I-Revnet</surname></persName>
		</author>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Deep invertible networks</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">On the rationale of maximum-entropy methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Edwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jaynes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="939" to="952" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Keenan&apos;s 3D Model Repository. Keenan&apos;s 3D Model Repository</title>
		<ptr target="https://www.cs.cmu.edu/kmcrane/Projects/ModelRepository/" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Variational autoencoders and nonlinear ICA: A unifying framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilyes</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><forename type="middle">Pio</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 23rd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="2207" to="2217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Ice-beem: Identifiable conditional energy-based deep models based on nonlinear ICA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilyes</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><forename type="middle">Pio</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Disentangling by factorising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2649" to="2658" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Glow: generative flow with invertible 1? 1 convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhariwal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10236" to="10245" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Towards nonlinear disentanglement in natural data with temporal sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Klindt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Schott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Ustyuzhaninov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Paiton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Fitting smooth surfaces to dense polygon meshes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkat</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Levoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques</title>
		<editor>John Fujii</editor>
		<meeting>the 23rd Annual Conference on Computer Graphics and Interactive Techniques<address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996-08-04" />
			<biblScope unit="page" from="313" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Variational inference of disentangled latent concepts from unlabeled observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasanna</forename><surname>Sattigeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Balakrishnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Building machines that learn and think like people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brenden M Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tomer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and brain sciences</title>
		<imprint>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Learning hierarchical invariant spatiotemporal features for action recognition with independent subspace analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><forename type="middle">Y</forename><surname>Quoc V Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Serena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3361" to="3368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Predicting what you already know helps: Provable self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Jason D Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikunj</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhuo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.01064</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Independent component analysis using an extended infomax algorithm for mixed subgaussian and supergaussian sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Te-Won</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Girolami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrence</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="417" to="441" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Leeb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashas</forename><surname>Annadani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07796</idno>
		<title level="m">Structural autoencoders improve representations for generation and transfer</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Theory of point estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Erich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Casella</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer Science &amp; Business Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lepus</forename><surname>Othus</surname></persName>
		</author>
		<ptr target="https://animaldiversity.org/accounts/Lepus_othus/" />
	</analytic>
	<monogr>
		<title level="j">Animal Diversity Web</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Self-organization in a perceptual network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Linsker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="105" to="117" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">An application of the principle of maximum information preservation to linear systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Linsker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="186" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roberta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Challenging common assumptions in the unsupervised learning of disentangled representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>Raetsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bachem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4114" to="4124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Weakly-supervised disentanglement without compromises</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gunnar</forename><surname>R?tsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="6348" to="6359" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">An efficient framework for learning sentence representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lajanugen</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Nonlinear invariant risk minimization: A causal approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.12353</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Jo?e Miguel Hern?ndez-Lobato, and Bernhard Sch?lkopf</note>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Representation learning via invariant causal mechanisms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jovana</forename><surname>Mitrovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><forename type="middle">C</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><forename type="middle">Holger</forename><surname>Buesing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Machine learning: a probabilistic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kevin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">The Utilization of Procedure Models in Digital Image Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">Edward</forename><surname>Newell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
		<respStmt>
			<orgName>The University of Utah</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Masked autoregressive flow for density estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Theo</forename><surname>Pavlakou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2338" to="2347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Normalizing flows for probabilistic modeling and inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">57</biblScope>
			<biblScope unit="page" from="1" to="64" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Causality</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Pezeshki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>S?kou-Oumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Kaba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Precup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lajoie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.09468</idno>
		<title level="m">Gradient starvation: A learning proclivity in neural networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">On variational bounds of mutual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5171" to="5180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Lapped textures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emil</forename><surname>Praun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugues</forename><surname>Hoppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th Annual Conference on Computer Graphics and Interactive Techniques</title>
		<editor>Judith R. Brown and Kurt Akeley</editor>
		<meeting>the 27th Annual Conference on Computer Graphics and Interactive Techniques<address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000-07-23" />
			<biblScope unit="page" from="465" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>OpenAI</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Multi-task self-supervised learning for robust speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirco</forename><surname>Ravanelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Pascual</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawel</forename><surname>Swietojanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<date type="published" when="2020-01" />
			<biblScope unit="page" from="6989" to="6993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Modeling shared responses in neuroimaging studies through multiview ica</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gresele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyvarinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ablin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020-12" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="19149" to="19162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">On linear identifiability of learned representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Roeder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Durk</forename><surname>Kingma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9030" to="9039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Invariant models for causal transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateo</forename><surname>Rojas-Carulla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1309" to="1342" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">wav2vec: Unsupervised pretraining for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech 2019, 20th Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3465" to="3469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">Causality for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10500</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Anirudh Goyal, and Yoshua Bengio. Toward causal representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Bauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE<address><addrLine>Nan Rosemary Ke</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">Disentangled generative causal representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinwei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furui</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanze</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.02637</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
