<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unified Deep Supervised Domain Adaptation and Generalization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
							<email>samotiian@mix.wvu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University Morgantown</orgName>
								<address>
									<postCode>26508</postCode>
									<region>WV</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Piccirilli</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University Morgantown</orgName>
								<address>
									<postCode>26508</postCode>
									<region>WV</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
							<email>daadjeroh@mix.wvu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University Morgantown</orgName>
								<address>
									<postCode>26508</postCode>
									<region>WV</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Doretto</surname></persName>
							<email>gidoretto@mix.wvu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University Morgantown</orgName>
								<address>
									<postCode>26508</postCode>
									<region>WV</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unified Deep Supervised Domain Adaptation and Generalization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work provides a unified framework for addressing the problem of visual supervised domain adaptation and generalization with deep models. The main idea is to exploit the Siamese architecture to learn an embedding subspace that is discriminative, and where mapped visual domains are semantically aligned and yet maximally separated. The supervised setting becomes attractive especially when only few target data samples need to be labeled. In this scenario, alignment and separation of semantic probability distributions is difficult because of the lack of data. We found that by reverting to point-wise surrogates of distribution distances and similarities provides an effective solution. In addition, the approach has a high "speed" of adaptation, which requires an extremely low number of labeled target training samples, even one per category can be effective. The approach is extended to domain generalization. For both applications the experiments show very promising results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Many computer vision applications require enough labeled data (target data) for training visual classifiers to address a specific task at hand. Whenever target data is either not available, or it is expensive to collect and/or label it, the typical approach is to use available datasets (source data), representative of a closely related task. Since this practice is known for leading to suboptimal performance, techniques such as domain adaptation <ref type="bibr" target="#b6">[6]</ref> and/or domain generalization <ref type="bibr" target="#b5">[5]</ref> have been developed to address the issue. Domain adaptation methods require target data, whereas domain generalization methods do not. Domain adaptation can be either supervised <ref type="bibr" target="#b61">[60,</ref><ref type="bibr" target="#b33">33]</ref>, unsupervised <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b62">61]</ref>, or semi-supervised <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b68">67]</ref>. Unsupervised domain adaptation (UDA) is attractive because it does not require target data to be labeled. Conversely, supervised domain adaptation (SDA) requires labeled target data.</p><p>UDA expects large amounts of target data in order to be effective, and this is emphasized even more when using deep models. Moreover, given the same amount of target data, SDA typically outperforms UDA, as we will later explain. Therefore, especially when target data is scarce, it is more attractive to use SDA, also because limited amounts of target data are likely to not be very expensive to label.</p><p>In the absence of target data, domain generalization (DG) exploits several cheaply available datasets (sources), representing different specific but closely related tasks. It then attempts to learn by combining data sources in a way that produces visual classifiers that are less sensitive to the specific target data that will need to be processed.</p><p>In this work, we introduce a supervised approach for visual recognition that can be used for both SDA and DG. The SDA approach requires very few labeled target samples per category in training. Indeed, even one sample can significantly increase performance, and a few others bring it closer to a peak, showing a remarkable "speed" of adaptation. Moreover, the approach is also robust to adapting to categories that have no target labeled samples. Although domain adaptation and generalization are closely related, adaptation techniques are not directly applied to DG, and viceversa. However, we show that by making simple changes to our proposed training loss function, and by maintaining the same architecture, our SDA approach very effectively extends to DG.</p><p>Using basic principles, we analyze how visual classification is extended to handle UDA by aligning a source domain distribution to a target domain distribution to make the classifier domain invariant. This leads to observing that SDA approaches improve upon UDA by making the alignment semantic, because they can ensure the alignment of semantically equivalent distributions from different domains. However, we go one step ahead by suggesting that semantic distribution separation should further increase performance, and this leads to the introduction of a classification and contrastive semantic alignment (CCSA) loss.</p><p>We deal with the limited size of target domain samples by observing that the CCSA loss relies on computing distances and similarities between distributions (as typically done in adaptation and generalization approaches). Those are difficult to represent with limited data. Thus, we revert In training, the semantic alignment loss minimizes the distance between samples from different domains but the same class label and the separation loss maximizes the distance between samples from different domains and class labels. At the same time, the classification loss guarantees high classification accuracy.</p><p>to point-wise surrogates. The resulting approach turns out to be very effective as shown in the experimental section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>Domain adaptation. Visual recognition algorithms are trained with data from a source domain, and when they are tested on a target domain with marginal distribution that differs from the one of the sources, we experience the visual domain adaptation (DA) problem (also known as dataset bias <ref type="bibr" target="#b48">[48,</ref><ref type="bibr" target="#b60">59,</ref><ref type="bibr" target="#b59">58]</ref>, or covariate shift <ref type="bibr" target="#b54">[54]</ref>), and observe a performance decrease. Traditional DA methods attempt to directly minimize the shift between source and target distributions. We divide them in three categories. The first one includes those that try to find a mapping between source and target distributions <ref type="bibr" target="#b53">[53,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b26">26,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b58">57]</ref>. The second one seeks to find a shared latent space for source and target distributions <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b2">2,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b21">21,</ref><ref type="bibr" target="#b22">22,</ref><ref type="bibr" target="#b47">47,</ref><ref type="bibr" target="#b43">43]</ref>. The third one regularizes a classifier trained on a source distribution to work well on a target distribution <ref type="bibr" target="#b4">[4,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b67">66,</ref><ref type="bibr" target="#b15">15,</ref><ref type="bibr" target="#b3">3,</ref><ref type="bibr" target="#b12">12]</ref>. UDA approaches fall in the first and second categories, while SDA methods could fall either in the second or third category or sometimes both. Recently, <ref type="bibr" target="#b7">[7,</ref><ref type="bibr" target="#b42">42]</ref> have addressed UDA when an auxiliary data view <ref type="bibr" target="#b36">[36,</ref><ref type="bibr" target="#b43">43]</ref>, is available during training, which is beyond the scope of this work.</p><p>Here, we are interested in finding a shared subspace for source and target distributions. Among algorithms for subspace learning, Siamese networks <ref type="bibr" target="#b11">[11]</ref> work well for different tasks <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b55">55,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b64">63,</ref><ref type="bibr" target="#b9">9]</ref>. Recently, Siamese networks have been used for domain adaptation. In <ref type="bibr" target="#b61">[60]</ref>, which is an SDA approach, unlabeled and sparsely labeled target domain data are used to optimize for domain invariance to facilitate domain transfer while using a soft label distribution matching loss. In <ref type="bibr" target="#b56">[56]</ref>, which is a UDA approach, unlabeled target data is used to learn a nonlinear transformation that aligns correlations of layer activations in deep neural networks. Some approaches went beyond the Siamase weight-sharing and used couple networks for DA. <ref type="bibr" target="#b33">[33]</ref> uses two CNN streams, for source and target, fused at the classifier level. <ref type="bibr" target="#b50">[50]</ref> uses a two-streams architecture, for source and target, with related but not shared weights. Here we use a Siamese network to learn an embedding such that samples from the same class are mapped as close as possible to each other. This semantic alignment objective is similar to other deep approaches, but unlike them, we explicitly model and introduce cross-domain class separation forces. Moreover, we do so with very few training samples, which makes the problem of characterizing distributions challenging, and this is why we propose to use point-wise surrogates.</p><p>Domain generalization. Domain generalization (DG) is a less investigated problem and is addressed in two ways. In the first one, all information from the training domains or datasets is aggregated to learn a shared invariant representation. Specifically, <ref type="bibr" target="#b5">[5]</ref> pulls all of the training data together in one dataset, and learns a single SVM classifier. <ref type="bibr" target="#b44">[44]</ref> learns an invariant transformation by minimizing the dissimilarity across domains. <ref type="bibr" target="#b23">[23]</ref>, which can be used for SDA too, finds a representation that minimizes the mismatch between domains and maximizes the separability of data. <ref type="bibr" target="#b24">[24]</ref> learns features that are robust to variations across domains.</p><p>The second approach to DG is to exploit all information from the training domains to train a classifier or regulate its weights <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b66">65,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b46">46]</ref>. Specifically, <ref type="bibr" target="#b32">[32]</ref> adjusts the weights of the classifier to work well on an unseen dataset, and <ref type="bibr" target="#b66">[65]</ref> fuses the score of exemplar classifiers given any test sample. While most works use the shallow models, here we approach DG as in the first way, and extend the proposed SDA approach by training a deep Siamese network to find a shared invariant representation where semantic alignment as well as separation are explicitly accounted for. To the best of our knowledge, <ref type="bibr" target="#b24">[24]</ref> is the only DG approach using deep models, and our method is the first deep method that solves both adaptation and generalization. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Supervised DA with Scarce Target Data</head><p>In this section we describe the model we propose to address supervised domain adaptation (SDA), and in the following Section 4 we extend it to address the domain generalization problem. We are given a training dataset made of pairs</p><formula xml:id="formula_0">D s = {(x s i , y s i )} N i=1 .</formula><p>The feature x s i ? X is a realization from a random variable X s , and the label y s i ? Y is a realization from a random variable Y . In addition, we are also given the training data</p><formula xml:id="formula_1">D t = {(x t i , y t i )} M i=1 , where x t</formula><p>i ? X is a realization from a random variable X t , and the labels y t i ? Y. We assume that there is a covariate shift [54] between X s and X t , i.e., there is a difference between the probability distributions p(X s ) and p(X t ). We say that X s represents the source domain and that X t represents the target domain. Under this settings the goal is to learn a prediction function f : X ? Y that during testing is going to perform well on data from the target domain.</p><p>The problem formulated thus far is typically referred to as supervised domain adaptation. In this work we are especially concerned with the version of this problem where only very few target labeled samples per class are available. We aim at handling cases where there is only one target labeled sample, and there can even be some classes with no target samples at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Deep SDA</head><p>In the absence of covariate shift a visual classifier f is trained by minimizing a classification loss</p><formula xml:id="formula_2">L C (f ) = E[ (f (X s ), Y )] ,<label>(1)</label></formula><p>where E[?] denotes statistical expectation and could be any appropriate loss function (for example categorical crossentropy for multi-class classification). When the distributions of X s and X t are different, a deep model f s trained with D s will have reduced performance on the target domain. Increasing it would be trivial by simply training a new model f t with data D t . However, D t is small and deep models require large amounts of labeled data.</p><p>In general, f could be modeled by the composition of two functions, i.e., f = h ? g. Here g : X ? Z would be an embedding from the input space X to a feature or embedding space Z, and h : Z ? Y would be a function for predicting from the feature space. With this notation we would have f s = h s ? g s and f t = h t ? g t , and the SDA problem would be about finding the best approximation for g t and h t , given the constraints on the available data.</p><p>The unsupervised DA paradigm (UDA) assumes that D t does not have labels. In that case the typical approach assumes that g t = g s = g, and f minimizes (1), while g also minimizes L CA (g) = d(p(g(X s )), p(g(X t ))) .</p><p>(</p><p>The purpose of (2) is to align the distributions of the features in the embedding space, mapped from the source and the target domains. d is meant to be a metric between distributions that once aligned, they will no longer allow to tell whether a feature is coming from the source or the target domain. For that reason, we refer to (2) as the confusion alignment loss. A popular choice for d is the Maximum Mean Discrepancy <ref type="bibr" target="#b28">[28]</ref>. In the embedding space Z, features are assumed to be domain invariant. Therefore, UDA methods say that from the feature to the label space it is safe to assume that h t = h s = h.</p><p>Since we are interested in visual recognition, the embedding function g would be modeled by a convolutional neural network (CNN) with some initial convolutional layers, followed by some fully connected layers. In addition, the training architecture would have two streams, one for source and the other for target samples. Since g s = g t = g, the CNN parameters would be shared as in a Siamese architecture. In addition, the source stream would continue with additional fully connected layers for modeling h. See <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>From the above discussion it is clear that in order to perform well, UDA needs to align effectively. This can happen only if distributions are represented by a sufficiently large dataset. Therefore, UDA approaches are in a position of weakness because we assume D t to be small. More- over, UDA approaches have also another intrinsic limitation, which is that even with perfect confusion alignment, there is no guarantee that samples from different domains but the same class label, would map nearby in the embedding space. This lack of semantic alignment is a major source of performance reduction.</p><p>SDA approaches easily address the semantic alignment problem by replacing <ref type="formula" target="#formula_3">(2)</ref> with</p><formula xml:id="formula_4">L SA (g) = C a=1 d(p(g(X s a )), p(g(X t a ))) ,<label>(3)</label></formula><p>where C is the number of class labels, and X s a = X s |{Y = a} and X t a = X t |{Y = a} are conditional random variables. d instead is a suitable distance metric between the distributions of X s a and X t a in the embedding space. We refer to (3) as the semantic alignment loss, which clearly encourages samples from different domains but the same label, to map nearby in the embedding space.</p><p>While the analysis above clearly indicates why SDA provides superior performance than UDA, it also suggests that deep SDA approaches have not considered that greater performance could be achieved by encouraging class separation, meaning that samples from different domains and with different labels, should be mapped as far apart as possible in the embedding space. This idea means that, in principle, a semantic alignment less prone to errors should be achieved by adding to (3) the following term</p><formula xml:id="formula_5">L S (g) = a,b|a =b k(p(g(X s a )), p(g(X t b ))) ,<label>(4)</label></formula><p>where k is a suitable similarity metric between the distributions of X s a and X t b in the embedding space, which adds a penalty when the distributions p(g(X s a )) and p(g(X t b )) come close, since they would lead to lower classification accuracy. We refer to (4) as the separation loss.</p><p>Finally, we suggest that SDA could be approached by learning a deep model f = h ? g such that</p><formula xml:id="formula_6">L CCSA (f ) = L C (h ? g) + L SA (g) + L S (g) . (5)</formula><p>We refer to <ref type="bibr" target="#b5">(5)</ref> as the classification and contrastive semantic alignment loss. This would allow to set g s = g t = g. The classification network h is trained only with source data, so h s = h. In addition, to improve performance on the target domain, h t could be obtained via fine-tuning based on the few samples in D t , i.e., h t = fine-tuning(h|D t ) .</p><p>Note that the network architecture remains the one in <ref type="figure" target="#fig_0">Figure 1</ref>, only with a different loss, and training procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Handling Scarce Target Data</head><p>When the size of the labeled target training dataset D t is very small, minimizing the loss (5) becomes a challenge. The problem is that the semantic alignment loss as well as the separation loss rely on computing distances and similarities between distributions, and those are very difficult to represent with as few as one data sample.</p><p>Rather than attempting to characterize distributions with statistics that require enough data, because of the reduced size of D t , we compute the distance in the semantic alignment loss (3) by computing average pairwise distances between points in the embedding space, i.e., we compute d(p(g(X s a )), p(g(X t a ))) =</p><formula xml:id="formula_8">i,j d(g(x s i ), g(x t j )) ,<label>(7)</label></formula><p>A ?W A ?D W ?A W ?D D ?A D ?WAverage  where it is assumed y s i = y t j = a. The strength of this approach is that it allows even a single labeled target sample to be paired with all the source samples, effectively trying to semantically align the entire source data with the few target data. Similarly, we compute the similarities in the separation loss (4) by computing average pairwise similarities between points in the embedding space, i.e., we compute</p><formula xml:id="formula_9">k(p(g(X s a )), p(g(X t b ))) = i,j k(g(x s i ), g(x t j )) ,<label>(8)</label></formula><p>where it is assumed that y s i = a = y t j = b. Moreover, our implementation further assumes that</p><formula xml:id="formula_10">d(g(x s i ), g(x t j )) = 1 2 g(x s i ) ? g(x t j ) 2 ,<label>(9)</label></formula><formula xml:id="formula_11">k(g(x s i ), g(x t j )) = 1 2 max(0, m ? g(x s i ) ? g(x t j ) ) 2 (10)</formula><p>where ? denotes the Frobenius norm, and m is the margin that specifies the separability in the embedding space. Note that with the choices outlined in <ref type="formula" target="#formula_10">(9)</ref> and <ref type="formula" target="#formula_2">(10)</ref>, the loss L SA (g)+L S (g) becomes the well known contrastive loss as defined in <ref type="bibr" target="#b30">[30]</ref>. Finally, to balance the classification versus the contrastive semantic alignment portion of the loss (5), <ref type="bibr" target="#b7">(7)</ref> and <ref type="bibr" target="#b8">(8)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Extension to Domain Generalization</head><p>In visual domain generalization (DG), D labeled datasets D s1 , ? ? ? , D s D , representative of D distinct source domains are given. The goal is to learn from them a visual classifier f that during testing is going to perform well on data D t , not available during training, thus representative of an unknown target domain.</p><p>The SDA method in Section 3 treats source and target datasets D s and D t almost symmetrically. In particular, the embedding g aims at achieving semantic alignment, while favoring class separation. The only asymmetry is in the prediction function h that is trained only on the source, to be then fine-tuned on the target.</p><p>In domain generalization, we are not interested in adapting the classifier to the target domain, because it is unknown. Instead, we want to make sure that the embedding g maps to a domain invariant space. To do so we consider every distinct unordered pair of source domains (u, v), represented by D su and D sv , and, like in SDA, impose the semantic alignment loss (3) as well as the separation loss (4). Moreover, the losses are summed over every pair in order to make the map g as domain invariant as possible. Similarly, the classifier h should be as correct as possible for any of the mapped samples, to maximize performance on an unseen target. This calls for having a fully symmetric learning for h by training it on all the source domains, meaning that the classification loss (1) is summed over every domain s u . See <ref type="figure">Figure 2</ref>.</p><p>The network architecture is still the one in <ref type="figure" target="#fig_0">Figure 1</ref>, and we have implemented it with the same choices for distances and similarities as those made in Section 3.2. However, since we are summing the losses (3) and (4) over every unordered pair of source domains, there is a quadratic growth of paired training samples. So, if necessary, rather than processing every paired sample, we select them randomly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We divide the experiments into two parts, domain adaptation and domain generalization. In both sections, we use benchmark datasets and compare our domain adaptation model and our domain generalization model, both indicated as CCSA, with the state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Domain Adaptation</head><p>We present results using the Office dataset <ref type="bibr" target="#b53">[53]</ref>, the MNIST dataset <ref type="bibr" target="#b37">[37]</ref>, and the USPS dataset <ref type="bibr" target="#b31">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Office Dataset</head><p>The office dataset is a standard benchmark dataset for visual domain adaptation. It contains 31 object classes for three domains: Amazon, Webcam, and DSLR, indicated as A, W, and D, for a total of 4,652 images. We consider six domain shifts using the three domains (A ? W, A ? D, W ? A, W ? D, D ? A, and D ? W). We performed different experiments using this dataset. First experiment. We followed the setting described in <ref type="bibr" target="#b61">[60]</ref>. All classes of the office dataset and 5 train-test splits  <ref type="bibr" target="#b61">[60]</ref>. We also report the classification results of the SDA algorithm presented in <ref type="bibr" target="#b39">[39]</ref> and <ref type="bibr" target="#b33">[33]</ref>. In addition to the SDA algorithms, we report the results of some recent UDA algorithms. They follow a different experimental protocol compared to the SDA algorithms, and use all samples of the target domain in training as unlabeled data together with all samples of the source domain. For the embedding function g, we used the convolutional layers of the VGG-16 architecture <ref type="bibr" target="#b55">[55]</ref> followed by 2 fully connected layers with output size of 1024 and 128, respectively. For the prediction function h, we used a fully connected layer with softmax activation. Similar to <ref type="bibr" target="#b61">[60]</ref>, we used the weights pre-trained on the ImageNet dataset <ref type="bibr" target="#b51">[51]</ref> for the convolutional layers, and initialized the fully connected layers using all the source domain data. We then fine-tuned all the weights using the train-test splits. <ref type="table">Table 1</ref> reports the classification accuracy over 31 classes for the Office dataset and shows that CCSA has better performance compared to <ref type="bibr" target="#b61">[60]</ref>. Since the difference between W domain and D domain is not considerable, unsupervised algorithms work well on D ? W and W ? D. However, in the cases when target and source domains are very different (A ? W, W ? A, A ? D, and D ? A), CCSA shows larger margins compared to the second best. This suggests that CCSA will provide greater alignment gains when there are bigger domain shifts. <ref type="figure" target="#fig_4">Figure 4</ref>(a) instead, shows how much improvement can be obtained with respect to the base model. This is simply obtained by training g and h with only the classification loss and source training data, so no adaptation is performed. Second experiment. We followed the setting described in <ref type="bibr" target="#b61">[60]</ref> when only 10 target labeled samples of 15 classes of the Office dataset are available during training. Similar to <ref type="bibr" target="#b61">[60]</ref>, we compute the accuracy on the remaining 16 categories for which no target data was available during training. We used the same network structure as in the first experiment and the same splits generated by <ref type="bibr" target="#b61">[60]</ref>. <ref type="table">Table 2</ref> shows that CCSA is effective at transferring information from the labeled classes to the unlabeled target classes. Similar to the first experiment, CCSA works well when shifts between domains are larger. Third experiment. We used the original train-test splits of the Office dataset <ref type="bibr" target="#b53">[53]</ref>. The splits are generated in a similar manner to the first experiment but here instead, only 10 classes are considered (backpack, bike, calculator, headphones, keyboard, laptop-computer, monitor, mouse, mug, and projector). In order to compare our results with the state-of-the-art, we used DeCaF-fc6 features <ref type="bibr" target="#b14">[14]</ref> and 800dimension SURF features as input. For DeCaF-fc6 features (SURF features) we used 2 fully connected layers with output size of 1024 (512) and 128 <ref type="bibr" target="#b32">(32)</ref> with ReLU activation as the embedding function, and one fully connected layer with softmax activation as the prediction function. The features and splits are available on the Office dataset webpage 1 .</p><p>We compared our results with three UDA (GFK <ref type="bibr" target="#b26">[26]</ref>, mSDA <ref type="bibr" target="#b8">[8]</ref>, and RTML <ref type="bibr" target="#b13">[13]</ref>) and one SDA (CDML <ref type="bibr" target="#b65">[64]</ref>) algorithms under the same settings. <ref type="table">Table 3</ref> shows that CCSA provides an improved accuracy with respect to the others. Again, greater domain shifts are better compensated by CCSA . <ref type="figure" target="#fig_4">Figure 4(b)</ref> shows the improvement of CCSA over the base model using DeCaF-fc6 features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">MNIST-USPS Datasets</head><p>The MNIST (M) and USPS (U) datasets have recently been used for domain adaptation <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b50">50]</ref>. They contain images Lower Bound GFK <ref type="bibr" target="#b26">[26]</ref> mSDA <ref type="bibr" target="#b8">[8]</ref>   of digits from 0 to 9. We considered two cross-domain tasks, M ? U and U ? M, and followed the experimental setting in <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b50">50]</ref>, which involves randomly selecting 2000 images from MNIST and 1800 images from USPS. Here, we randomly selected n labeled samples per class from target domain data and used them in training. We evaluated our approach for n ranging from 1 to 8 and repeated each experiment 10 times (we only show the mean of the accuracies because the standard deviation is very small). Similar to <ref type="bibr" target="#b37">[37]</ref>, we used 2 convolutional layers with 6 and 16 filters of 5 ? 5 kernels followed by max-pooling layers and 2 fully connected layers with size 120 and 84 as the embedding function g, and one fully connected layer with softmax activation as the prediction function h. We compare our method with 2 recent UDA methods. Those methods use all target samples in their training stage, while we only use very few labeled target samples per category in training. <ref type="table">Table 4</ref> shows the average classification accuracy of the MNIST-USPS datasets. CCSA works well even when only one target sample per category (n = 1) is available in training. Also, we can see that by increasing n, the accuracy quickly converges to the top. Ablation study. We consider three baselines to compare with CCSA for M ? U task. First, we train the network with source data and then fine-tune it with available target data. Second, we train the network using the classification and semantic alignment losses (L CSA (f ) = L C (h ? g) + L SA (g)). Third, we train the network using the classification and separation losses (L CS (f ) = L C (h ? g) + L S (g)). <ref type="figure" target="#fig_4">Figure 4(d)</ref> shows the average accuracies over 10 repetitions. It shows that CSA and CS improve the accuracy over fine-tuning. Using the semantic alignment loss together with separation loss (CCSA) shows the best performance. Visualization. We show how samples lie on the embedding space using CCSA . First, we considered the row images of the MNIST and USPS datasets and plotted 2D visualization of them using t-SNE algorithm <ref type="bibr" target="#b41">[41]</ref>. As <ref type="figure" target="#fig_2">Figure 3</ref>(Left) shows the row images of the same class and different domains lie far away from each other in the 2D subspace. For example, the samples of the class zero of the USPS dataset (0 U ) are far from the class zero of the MNIST dataset (0 M ). Second, we trained our base model with no adaptation on the MNIST dataset. We then plotted the 2D visualization of the MNIST and USPS samples in the embedding space (output of g, the last fully connected layer). As <ref type="figure" target="#fig_2">Figure 3</ref>(Middle) shows, the samples from the same class and different domains still lie far away from each other in the 2D subspace. Finally, we trained our SDA model on the MNIST dataset and 3 labeled samples per class of the USPS dataset. We then plotted the 2D visualization of the MNIST and USPS samples in the embedding space (output of g). As <ref type="figure" target="#fig_2">Figure 3</ref>(Right) shows, the samples from the same class and different domains now lie very close to each other in the 2D subspace. Note however, that this is only a 2D visualization of high-dimensional data, and <ref type="figure" target="#fig_2">Figure 3</ref>(Right) may not perfectly reflect how close is the data from the same class, and how classes are separated. Weight sharing: There is no restriction whether g t and g s should share the weights or not. Not sharing weights will likely lead to overfitting, given the reduced amount of target training data, and weight-sharing can be seen as a regularizer. We repeated the experiment for M ? U task when n = 4. Not sharing weights provides the average accuracy 88.6 over 10 repetitions which is less than the average accuracy with weight-sharing (see <ref type="table">Table 4</ref>). A similar behavior can be seen for other experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Domain Generalization</head><p>We evaluate CCSA on different datasets. The goal is to show that CCSA is able to learn a domain invariant embedding subspace for visual recognition tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">VLCS Dataset</head><p>In this section, we use images of 5 shared object categories (bird, car, chair, dog, and person), of the PAS-CAL VOC2007 (V) <ref type="bibr" target="#b16">[16]</ref>, LabelMe (L) <ref type="bibr" target="#b52">[52]</ref>, Caltech-101 (C) <ref type="bibr" target="#b18">[18]</ref>, and SUN09 (S) <ref type="bibr" target="#b10">[10]</ref> datasets, which is known as VLCS dataset <ref type="bibr" target="#b17">[17]</ref>. <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b23">23]</ref> have shown that there are covariate shifts between the above 4 domains and have developed a DG method to minimize them. We followed their experimental setting, and randomly divided each domain into a training set (70%) and a test set (30%) and conducted a leave-one-domain-out evaluation (4 cross-domain cases) and a leave-two-domain-out evaluation (3 cross-domain cases). In order to compare our results with the state-of-the-art, we used DeCaF-fc6 features which are publicly available 2 , and repeated each cross-domain case 20 times and reported the average classification accuracy.</p><p>We used 2 fully connected layers with output size of 1024 and 128 with ReLU activation as the embedding function g, and one fully connected layer with softmax activation as the prediction function h. To create positive and negative pairs for training our network, for each sample of a source domain we randomly selected 5 samples from each remaining source domain, and help in this way to avoid overfitting. However, to train a deeper network together with convolutional layers, it is enough to create a large amount of positive and negative pairs. We report comparative results in <ref type="table">Table 5</ref>, where all DG methods work better than the base model, emphasizing the need for domain generalization. Our DG method has higher average performance. Also, note that in order to compare with the state-of-the-art DG methods, we only used 2 fully connected layers for our network and precomputed features as input. However, when using convolutional layers on row images, we expect our DG model to provide better performance. <ref type="figure" target="#fig_4">Figure 4</ref>(c) shows the improvement of our DG model over the base model using DeCaF-fc6 features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">MNIST Dataset</head><p>We followed the setting in <ref type="bibr" target="#b24">[24]</ref>, and randomly selected a set M of 100 images per category from the MNIST dataset (1000 in total). We then rotated each image in M five times with 15 degrees intervals, creating five new domains M 15 ? , M 30 ? , M 45 ? , M 60 ? , and M 75 ? . We conducted a leave-one-domain-out evaluation (6 cross-domain cases in total). We used the same network of Section 5.1.2, and we repeated the experiments 10 times. To create positive and negative pairs for training our network, for each sample of a source domain we randomly selected 2 samples from each remaining source domain. We report comparative average accuracies for CCSA and others in <ref type="table" target="#tab_3">Table 6</ref>, showing again a performance improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>We have introduced a deep model in combination with the classification and contrastive semantic alignment (CCSA) loss to address SDA. We have shown that the CCSA loss can be augmented to address the DG problem without the need to change the basic model architecture. However, the approach is general in the sense that the architecture sub-components can be changed. We found that addressing the semantic distribution alignments with pointwise surrogates of distribution distances and similarities for SDA and DG works very effectively, even when labeled target samples are very few. In addition, we found the SDA accuracy to converge very quickly as more labeled target samples per category are available.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Deep supervised domain adaptation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>1 Figure 2 .</head><label>12</label><figDesc>Deep domain generalization. In training, the semantic alignment loss minimizes the distance between samples from different domains but the same class label and the separation loss maximizes the distance between samples from different domains and class labels. At the same time, the classification loss guarantees high classification accuracy. In testing, the embedding function embeds samples from unseen distributions to the domain invariant space and the prediction function classifies them (right). In this figure, different colors represent different domain distributions and different shapes represent different classes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Visualization of the MNIST-USPS datasets. Left: 2D visualization of the row images of the MNIST-USPS datasets. The samples from the same class and different domains lie far from each other on the 2D subspace. Middle: 2D visualization of the embedded images using our base model (without domain adaptation). The samples from the same class and different domains still lie far from each other on the 2D subspace. Right: 2D visualization of the embedded images using our SDA model. The samples from the same class and different domains lie very close to each other on the 2D subspace.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>,S ?V V,C,S ?L V,L,S ?C L,L,C ?S C,S ?V,L C,L ?V,S V,C ?L,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>(a), (b), (c): Improvement of CCSA over the base model. (d): Average classification accuracy for M ? U task for different number of labeled target samples per category (n). It shows that our model provides significant improvement over baselines.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>are normalized and weighted by 1 ? ? and (1) by ?.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Office dataset. Classification accuracy for domain adaptation over the 31 categories of the Office dataset. A, W, and D stand for Amazon, Webcam, and DSLR domain. Lower Bound is our base model without adaptation. ? 0.4 68.5 ? 0.4 68.7 ? 0.3 82.7 ? 0.8 84.5 ? 1.7 88.2 ? 1.0 A ? D 62.3 ? 0.8 64.4 ? 0.3 67.0 ? 0.4 67.1 ? 0.3 86.1 ? 1.2 86.3 ? 0.8 89.0 ? 1.2 W ? A 51.6 ? 0.9 52.2 ? 0.4 53.1 ? 0.3 54.09 ? 0.5 65.0 ? 0.5 65.7 ? 1.7 72.1 ? 1.0 Office dataset. Classification accuracy for domain adaptation over the Office dataset when only the labeled target samples of 15 classes are available during training. Testing is done on all 31 classes. A, W, and D stand for Amazon, Webcam, and DSLR domain. Lower Bound is our base model without adaptation. For the source domain, 20 examples per category for the Amazon domain, and 8 examples per category for the DSLR and Webcam domains are randomly selected for training for each split. Also, 3 labeled examples are randomly selected for each category in the target domain for training for each split. The rest of the target samples are used for testing. Note that we used the same splits generated by</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Unsupervised</cell><cell></cell><cell></cell><cell>Supervised</cell></row><row><cell></cell><cell cols="2">Lower Bound</cell><cell>[62]</cell><cell>[39]</cell><cell>[25]</cell><cell>[60]</cell><cell>[33]</cell><cell>CCSA</cell></row><row><cell></cell><cell cols="8">A ? W 61.8 W ? D 61.2 ? 0.9 95.6 ? 0.7 98.5 ? 0.4 99.0 ? 0.2 99.0 ? 0.2 97.6 ? 0.2 97.5 ? 0.7 97.6 ? 0.4 D ? A 58.5 ? 0.8 52.1 ? 0.8 54.0 ? 0.4 56.0 ? 0.5 66.2 ? 0.3 66.5 ? 1.0 71.8 ? 0.5 D ? W 80.1 ? 0.6 95.0 ? 0.5 96.0 ? 0.3 96.4 ? 0.3 95.7 ? 0.5 95.5 ? 0.6 96.4 ? 0.8</cell></row><row><cell></cell><cell>Average</cell><cell>68.2</cell><cell>70.6</cell><cell>72.9</cell><cell>73.6</cell><cell>82.21</cell><cell>82.68</cell><cell>85.8</cell></row><row><cell></cell><cell>Lower Bound</cell><cell>[60]</cell><cell>CCSA</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>A ? W A ? D W ? A W ? D D ? A D ? W</cell><cell>52.1 ? 0.6 61.6 ? 0.8 34.5 ? 0.9 95.1 ? 0.2 40.1 ? 0.3 89.7 ? 0.8</cell><cell cols="2">59.3 ? 0.6 63.3 ? 0.9 68.0 ? 0.5 70.5 ? 0.6 40.5 ? 0.2 43.6 ? 1.0 97.5 ? 0.1 96.2 ? 0.3 43.1 ? 0.2 42.6 ? 0.6 90.0 ? 0.2 90.0 ? 0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Average</cell><cell>62.26</cell><cell>66.4</cell><cell>67.83</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>are considered.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .Table 5 .</head><label>45</label><figDesc>MNIST-USPS datasets. Classification accuracy for domain adaptation over the MNIST and USPS datasets. M and U stand for MNIST and USPS domain. Lower Bound is our base model without adaptation. CCSA -n stands for our method when we use n labeled target samples per category in training. VLCS dataset. Classification accuracy for domain generalization over the 5 categories of the VLCS dataset. LB (Lower Bound) is our base model trained without the contrastive semantic alignment loss. 1NN stands for first nearest neighbor.</figDesc><table><row><cell></cell><cell>Method</cell><cell cols="3">M ? U U ? M Average</cell><cell></cell></row><row><cell></cell><cell>ADDA [61] CoGAN [38]</cell><cell>89.4 91.2</cell><cell>90.1 89.1</cell><cell>89.7 90.1</cell><cell></cell></row><row><cell></cell><cell>Lower Bound CCSA-1 CCSA-2 CCSA-3 CCSA-4 CCSA-5 CCSA-6 CCSA-7 CCSA-8</cell><cell>65.4 85.0 89.0 90.1 91.4 92.4 93.0 92.9 92.8</cell><cell>58.6 78.4 82.0 85.8 86.1 88.8 89.6 89.4 90.0</cell><cell>62.0 81.7 85.5 87.9 88.7 90.1 91.3 91.1 91.4</cell><cell></cell></row><row><cell></cell><cell>Lower Bound</cell><cell></cell><cell cols="2">Domain Generalization</cell><cell></cell></row><row><cell></cell><cell cols="5">1NN SVM LB UML [17] LRE-SVM [65] SCA [23] CCSA</cell></row><row><cell cols="2">L, C, S ? V 57.2 58.4 59.1 V, C, S ? L 52.4 55.2 55.6 V, L, S ? C 90.5 85.1 86.1 V, L, C ? S 56.9 55.2 54.6 C, S ? V, L 55.0 55.5 55.3 C, L ? V, S 52.6 51.8 50.9 V, C ? L, S 56.6 59.9 60.1</cell><cell>56.2 58.5 91.1 58.4 56.4 57.4 55.4</cell><cell>60.5 59.7 88.1 54.8 55.0 52.8 58.8</cell><cell>64.3 59.6 88.9 59.2 59.5 55.9 60.7</cell><cell>67.1 62.1 92.3 59.1 59.3 56.5 60.2</cell></row><row><cell>Average</cell><cell>60.1 60.1 60.2</cell><cell>61.5</cell><cell>61.4</cell><cell>64.0</cell><cell>65.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 .</head><label>6</label><figDesc>MNIST dataset. Classification accuracy for domain generalization over the MNIST dataset and its rotated domains. CAE [49] MTAE [24] CCSA M 15 ? , M 30 ? , M 45 ? , M 60 ? , M 75 ? ? M 72.1 82.5 84.6 M, M 30 ? , M 45 ? , M 60 ? , M 75 ? ? M 15 ? 95.3 96.3 95.6 M, M 15 ? , M 45 ? , M 60 ? , M 75 ? ? M 30 ? 92.6 93.4 94.6 M, M 15 ? , M 30 ? , M 60 ? , M 75 ? ? M 45 ? 81.5 78.6 82.9 M, M 15 ? , M 30 ? , M 45 ? , M 75 ? ? M 60 ? 92.7 94.2 94.8 M, M 15 ? , M 30 ? , M 45 ? , M 60 ? ? M 75 ?</figDesc><table><row><cell></cell><cell>79.3</cell><cell>80.5</cell><cell>82.1</cell></row><row><cell>Average</cell><cell>85.5</cell><cell>87.5</cell><cell>89.1</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://cs.stanford.edu/?jhoffman/domainadapt/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://www.cs.dartmouth.edu/?chenfang/proj_ page/FXR_iccv13/index.php</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This material is based upon work supported by the Center for Identification Technology Research and the National Science Foundation under Grant No. 1066197.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tabula rasa: Model transfer for object category detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Aytar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<title level="m">IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2252" to="2259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by domain invariant projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baktashmotlagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Lovell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="769" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Non-linear domain adaptation with boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Christoudias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="485" to="493" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exploiting weakly-labeled web images to improve object classification: a domain adaptation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bergamo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="181" to="189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Generalizing from several related classification tasks to a new unlabeled sample</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Blanchard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2178" to="2186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Domain adaptation with structural correspondence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 conference on empirical methods in natural language processing</title>
		<meeting>the 2006 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="120" to="128" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Recognizing RGB images by learning from RGB-D data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014-06" />
			<biblScope unit="page" from="1418" to="1425" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Marginalized denoising autoencoders for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.4683</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep domain adaptation for describing people based on fine-grained clothing attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5315" to="5324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploiting hierarchical context on a large database of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer vision and pattern recognition (CVPR), 2010 IEEE conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Domain adaptation for statistical classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="101" to="126" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Robust transfer metric learning for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="660" to="670" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">DeCAF: a deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1310.1531</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Domain transfer svm for video concept detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Maybank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1375" to="1381" />
		</imprint>
	</monogr>
	<note>IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unbiased metric learning: On the utilization of multiple datasets and web images for softening bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Rockmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories. Computer vision and Image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="59" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised visual domain adaptation using subspace alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sebban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2960" to="2967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Joint crossdomain classification and subspace learning for unsupervised adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaarsc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogition Letters</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.7495</idno>
		<title level="m">Unsupervised domain adaptation by backpropagation</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Domainadversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">59</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scatter component analysis: A unified framework for domain adaptation and domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2551" to="2559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep reconstruction-classification networks for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Geodesic flow kernel for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2066" to="2073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Domain adaptation for object recognition: An unsupervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="999" to="1006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A kernel method for the two-sample-problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cross language text classification via subspace co-regularized multi-view learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Machine Learning, ICML 2012</title>
		<meeting>the 29th International Conference on Machine Learning, ICML 2012<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-07-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer vision and pattern recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A database for handwritten text recognition research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="550" to="554" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Undoing the damage of dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="158" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Domain adaptation by mixture of alignments of second-or higher-order scatter tensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">What you saw is not what you get: Domain adaptation using asymmetric kernel transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1785" to="1792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning local image descriptors with deep siamese and triplet convolutional networks by minimising global loss functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5385" to="5394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning using privileged information: SVM+ and weighted SVM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Gradientbased learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Coupled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="469" to="477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning transferable features with deep adaptation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="97" to="105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Transfer sparse coding for robust image representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="407" to="414" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Information bottleneck domain adaptation with privileged information for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Information bottleneck learning using privileged information for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1496" to="1505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML (1)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multi-view domain generalization for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4193" to="4201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">An exemplar-based multiview domain generalization framework for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Domain adaptation via transfer component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TNN</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="199" to="210" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Dataset issues in object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marszalek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Toward category-level object recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="29" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Contractive auto-encoders: Explicit invariance during feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th international conference on machine learning (ICML-11)</title>
		<meeting>the 28th international conference on machine learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="833" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Beyond sharing weights for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozantsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fua</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.06432</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ImageNet Large Scale Visual Recognition Challenge. IJCV</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Labelme: a database and web-based tool for image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="157" to="173" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Improving predictive inference under covariate shift by weighting the log-likelihood function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shimodaira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Planning and Inference</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="244" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deep coral: Correlation alignment for deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Workshops</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="443" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning the roots of visual domain shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lanzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2016 Workshops</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="475" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A deeper look at dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Patricia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="504" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Unbiased look at dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1521" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.3474</idno>
		<title level="m">Deep domain confusion: Maximizing for domain invariance</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">A siamese long short-term memory architecture for human reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Varior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="135" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Cross-domain metric learning based on information theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2099" to="2105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Exploiting low-rank structure from latent domains for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="628" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Adapting svm classifiers to data with shifted distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining Workshops, 2007. ICDM Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
	<note>Seventh IEEE International Conference on</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Semisupervised domain adaptation with subspace learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015-06" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
