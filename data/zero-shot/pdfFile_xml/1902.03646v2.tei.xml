<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Context-Aware Visual Compatibility Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
							<email>gcucurull@elementai.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Perouz</forename><surname>Taslakian</surname></persName>
							<email>perouz@elementai.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
							<email>dvazquez@elementai.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Element</forename><surname>Ai</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<address>
									<settlement>Element</settlement>
									<region>AI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<region>AI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Context-Aware Visual Compatibility Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>How do we determine whether two or more clothing items are compatible or visually appealing? Part of the answer lies in understanding of visual aesthetics, and is biased by personal preferences shaped by social attitudes, time, and place. In this work we propose a method that predicts compatibility between two items based on their visual features, as well as their context. We define context as the products that are known to be compatible with each of these item. Our model is in contrast to other metric learning approaches that rely on pairwise comparisons between item features alone. We address the compatibility prediction problem using a graph neural network that learns to generate product embeddings conditioned on their context. We present results for two prediction tasks (fill in the blank and outfit compatibility) tested on two fashion datasets Polyvore and Fashion-Gen, and on a subset of the Amazon dataset; we achieve state of the art results when using context information and show how test performance improves as more context is used.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Predicting fashion compatibility refers to the task of determining whether a set of fashion items go well together. In its ideal form, it involves understanding the visual styles of garments, being cognizant of social and cultural attitudes, and making sure that when worn together the outfit is aesthetically pleasing. The task is fundamental to a variety of industry applications such as personalized fashion design <ref type="bibr" target="#b18">[19]</ref>, outfit composition <ref type="bibr" target="#b6">[7]</ref>, wardrobe creation <ref type="bibr" target="#b15">[16]</ref>, item recommendation <ref type="bibr" target="#b30">[31]</ref> and fashion trend forecasting <ref type="bibr" target="#b0">[1]</ref>. Fashion compatibility, however, is a complex task that depends on subjective notions of style, context, and trend -all properties that may vary from one individual to another and evolve over time.</p><p>Previous work <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b35">36]</ref> on the problem of fashion compatibility prediction uses models that mainly perform pairwise comparisons between items based on item information such as image, category, description, . . . , etc. These ap- ? <ref type="figure">Figure 1</ref>: Fashion compatibility. We use context information around fashion items to improve the task of fashion compatibility prediction. (a) standard methods compare pairs of items (b) we use a graph to exploit relational information to know the context of the items.</p><p>proaches have the drawback that each pair of items considered are treated independently, making the final prediction rely on comparisons between the features of each item in isolation. In such a comparison mechanism that discards context, the model makes the same prediction for a given pair of clothing items every time. For example, if the model is trained to match a specific style of shirt with a specific style of shoes, it will consistently make this same prediction every time. However, as compatibility is a subjective measure that can change with trends and across individuals, such inflexible behaviour is not always desirable at test time. The compatibility between the aforementioned shirt and shoes is not only defined by the features of these items alone, but is also biased by the individual's preferences and sense of fashion. We thus define the context of a clothing item to be the set of items that it is compatible with, and address the limitation of inflexible predictions by introducing a model that makes compatibility decisions based on the visual features, as well as the context of each item. This consideration gives the model some background as to what we consider "compatible", in itself a subjective bias of the individual and the trend of the time.</p><p>In this paper, we propose to leverage the underlying relational information between items in a collection to make better compatibility predictions. We use fashion as our theme, and represent clothing items and their pairwise compatibility as a graph, where vertices are the fashion items and edges connect pairs of items that are compatible; we then use a graph neural network based model to learn to predict edges. Our model is based on the graph auto-encoder framework <ref type="bibr" target="#b21">[22]</ref>, which defines an encoder that computes node embeddings and a decoder that is applied on the embedding of each product. Graph auto-encoders have previously been used for related problems such as recommender systems <ref type="bibr" target="#b34">[35]</ref>, and we extend the idea to the fashion compatibility prediction task. The encoder part of the model computes item embeddings depending on their connections, while the decoder uses these embeddings to compute the compatibility between item pairs. By conditioning the embeddings of the products on the neighbours, the style information contained in the representation is more robust, and hence produces more accurate compatibility predictions. This accuracy is tested by a set of experiments we perform on three datasets: Polyvore <ref type="bibr" target="#b11">[12]</ref>, Fashion-Gen <ref type="bibr" target="#b27">[28]</ref> and Amazon <ref type="bibr" target="#b23">[24]</ref>, and through two tasks (1) outfit completion (see Section 4.1) and (2) outfit compatibility prediction (see Section 4.1). We compare our model with previous methods and obtain state of the art results. During test time, we provide our model with varying amount of context of each item being tested and empirically show, in addition, that the more context we use, the more accurate our predictions get.</p><p>This work has the following main contributions, (1) we propose the first fashion compatibility method that uses context information; <ref type="bibr" target="#b1">(2)</ref> we perform an empirical study of how the amount of neighbourhood information used during test time influences the prediction accuracy; and (3) we show that our method outperforms other baseline approaches that do not use the context around each item on the Polvvore <ref type="bibr" target="#b11">[12]</ref>, Fashion-Gen <ref type="bibr" target="#b27">[28]</ref>, and Amazon <ref type="bibr" target="#b23">[24]</ref> datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>As our proposed model uses graph neural networks to perform fashion compatibility prediction, we group previous work related to our proposed model into two categories that we discuss in this section. In what follows, an outfit is a set of clothing items that can be worn concurrently. We say that an outfit is compatible, if the clothing items composing the outfit are aesthetically pleasing when worn together; we extend an outfit when we add clothing item(s) to the set composing the outfit.</p><p>Visual Fashion Compatibility Prediction. To approach the task of visual compatibility prediction, McAuley et al. <ref type="bibr" target="#b23">[24]</ref> learn a compatibility metric on top of CNNextracted visual features, and apply their method to pairs of products such that the learned distance in the embedding space is interpreted as compatibility. Their approach is improved by Veit et al. <ref type="bibr" target="#b37">[38]</ref>, who instead of using pre-computed features for the images, use an end-to-end siamese network to predict compatibility between pairs of images. A similar end-to-end approach <ref type="bibr" target="#b18">[19]</ref> shows that jointly learning the feature extractor and the recommender system leads to better results. The evolution of fashion style has an important role in compatibility estimation, and He et al. <ref type="bibr" target="#b13">[14]</ref> study how previous methods can be adapted to model the visual evolution of fashion trends within recommender systems. Some variations of this task include predicting the compatibility of an outfit, to generate outfits from a personal closet <ref type="bibr" target="#b33">[34]</ref> for example, or determining the item that best extends a partial outfit. To approach these tasks, Han et al. <ref type="bibr" target="#b11">[12]</ref> consider a fashion outfit to be an ordered sequence of products and use a bidirectional LSTM on top of the CNN-extracted features from the images and semantic information extracted from text in the embedding space. This method was improved by adding a new style embedding for the full outfit <ref type="bibr" target="#b26">[27]</ref>. Vasileba et al. <ref type="bibr" target="#b35">[36]</ref> also use textual information to improve the product embeddings, along with using conditional similarity networks <ref type="bibr" target="#b36">[37]</ref> to produce typeconditioned embeddings and learn a metric for compatibility. This approach projects each product embedding to a new space, depending on the type of the item pairs being compared.</p><p>Graph Neural Networks. Extending neural networks to work with graph structured data was first proposed by Gori et al. <ref type="bibr" target="#b9">[10]</ref> and Scarselli et al. <ref type="bibr" target="#b28">[29]</ref>. The interest in this topic resurged recently, with the proposal of spectral graph neural networks <ref type="bibr" target="#b4">[5]</ref> and its improvements <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21]</ref>. Gilmer et al. <ref type="bibr" target="#b8">[9]</ref> showed that most of the methods that apply neural networks to graphs <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b10">11]</ref> can be seen as specific instances of a learnable message passing framework on graphs. For an indepth review of different approaches that apply neural networks to graph-structured data, we refer the reader to the work by Bronstein et al. <ref type="bibr" target="#b3">[4]</ref> and Battaglia et al. <ref type="bibr" target="#b1">[2]</ref>, which explores how relational inductive biases can be injected in deep learning architectures.</p><p>Graph neural networks have been applied to product recommendation, which is similar to product compatibility prediction. In this task, the goal is to predict compatibility between users and products (as opposed to a pair of products). Van den Berg et al. <ref type="bibr" target="#b34">[35]</ref> showed how this task can be approached as a link prediction problem in a graph. Similarly, graphs can also be used to take advantage of the structure within the rows and columns of a matrix completion problem applied to product recommendation <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b25">26]</ref>. Recently, a graph-based recommender system has been scaled to web-scale <ref type="bibr" target="#b39">[40]</ref>, operating on a graph with more than 3 billion nodes consisting of pins and boards from Pinterest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>The approach we use in this work is similar to the metric learning idea of Vasileba et al. <ref type="bibr" target="#b35">[36]</ref>, but rather than using text to improve products embeddings, we use a graph to exploit structural information and obtain better product embeddings. Our model is based on the graph auto-encoder (GAE) framework defined by Kipf et al. <ref type="bibr" target="#b21">[22]</ref>, which has been used for tasks like knowledge base completion <ref type="bibr" target="#b29">[30]</ref> and collaborative filtering <ref type="bibr" target="#b34">[35]</ref>. In this framework, the encoder gets as input an incomplete graph, and produces an embedding for each node. Then, the node embeddings are used by the decoder to predict the missing edges in the graph.</p><p>Let G = (V, E) be an undirected graph with N nodes i ? V and edges (i, j) ? E connecting pairs of nodes. Each node in the graph is represented with a vector of features x i ? R F , and X = { x 0 , x 1 , . . . , x N ?1} is a R N ?F matrix that contains the features of all nodes in the graph. Each row of X, denoted as X i,: , contains the features of one node, i.e. X i,0 , X i,1 , . . . , X i,N ?1 represent the features of the i th node. The graph is represented by an adjacency matrix A ? R N ?N , where A i,j = 1 if there exist an edge between nodes i and j and A i,j = 0 otherwise.</p><p>The objective of the model is to learn an encoding H = f enc (X, A) and a decoding A = f dec (H) function. The encoder transforms the initial features X into a new representation H ? R N ?F , depending on the structure defined by the adjacency matrix A. This new matrix follows the same structure as the initial matrix X, so the i-th row H i,: contains the new features for the i-th node. Then, the decoder uses the new representations to reconstruct the adjacency matrix. This whole process can be seen as encoding the input features to a new space, where the distance between two points can be mapped to the probability of whether or not an edge exists between them. We use a decoder to compute this probability using the features of each node: p((i, j) ? E) = f dec (H i,: , H j,: ), which for our purposes represents the compatibility between items i and j.</p><p>In this work, the encoder is a Graph Convolutional Network (Section 3.1) and the decoder (Section 3.2) learns a metric to predict the compatibility score between pairs of products (i, j). <ref type="figure">Figure 2</ref> shows a scheme of how this encoder-decoder mechanism works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Encoder</head><p>From the point of view of a single node i, the encoder will transform its initial visual features x i into a new representation h i . The initial features, which can be computed with a CNN as a feature extractor, contain information about how an item looks like, e.g., shape, color, size. However, we want the new representation produced by the encoder to capture not only the product properties but also structural information about the other products it is compatile with. In other words, we want the new representation of each node to contain information about itself, but also about its neighbours N i , where N i = {j ? V |A i,j = 1} denotes the set of nodes that are connected to node i. Therefore, the encoder is a function that aggregates the local neighbourhood around a node</p><formula xml:id="formula_0">h i = f enc ( x i , N i ) : R F ? R F to include neighbourhood information in the learned</formula><p>representations. This function is implemented as a deep Graph Convolutional Network (GCN) <ref type="bibr" target="#b20">[21]</ref> that can have several hidden layers. Thus, the final value of h i is a composition of the functions computed at each hidden layer, which produces hidden activations z (l) i . A single layer takes the following form.</p><formula xml:id="formula_1">z (l+1) i = ReLU ? ? z (l) i ? (l) 0 + j?Ni 1 |N i | z (l) j ? (l) 1 ? ? (1) Here, z (l) i</formula><p>is the input of the i-th node at layer l, and z (l+1) i is its output. In its matrix form, the function operates on all the nodes of the graph at the same time:</p><formula xml:id="formula_2">Z (l+1) = ReLU S s=0? s Z (l) ? (l) s (2)</formula><p>Here, Z (0) = X for the first layer. We denote? s as the normalized s-th step adjacency matrix, where A 0 = I N contains self-connections, and A 1 = A + I N contains first step neighbours with self-connections. We let? = D ?1 A, normalizing it row-wise using the diagonal degree matrix D ii = j A i,j . Context information is controlled by the parameter S that represents the depth of the neighbourhood that is being considered during training: the neighbourhood at depth s of node i is the set of all nodes that are at distance (number of edges traveled) at most s from i. We let S = 1 for all our experiments, meaning that we only use neighbours at depth one in each layer. ? (l) s is a R F ?F matrix, which contains the trainable parameters for layer l. We apply techniques such as batch normalization <ref type="bibr" target="#b16">[17]</ref>, dropout <ref type="bibr" target="#b32">[33]</ref> or weight regularization at each layer.</p><p>Finally, we introduce a regularization technique applied to the matrix A, which consists of randomly removing all the incident edges of some nodes with a probability p drop . The goal of this technique is two-fold: (1) it introduces some changes in the structure of the graph, making it more robust against changes in structure, and (2) it trains the model to perform well for nodes that do not have neighbours, making it more robust to scenarios with low relational information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Decoder</head><p>We want the decoder to be a function that computes the probability that two nodes are connected. This scenario is known as metric learning <ref type="bibr" target="#b2">[3]</ref>, where the goal is to learn a notion of similarity or compatibility between data samples. It is relevant to note that similarity and compatibility are not exactly the same. Similarity measures how similar two nodes are, for example two shirts might be similar because they have the same shape and color, but they are not necessarily compatible. Compatibility is a property that measures how well two items go together.</p><p>In its general form, metric learning can be defined as learning a function d(?, ?) : R N ? R N ? R + 0 that represents the distance between two N -dimensional vectors. Therefore, our decoder function takes inspiration from other metric learning approaches <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b31">32]</ref>. In our case, we want to train the decoder to model the compatibility between pairs of items, so we want the output of d(?, ?) to be bounded by the interval [0, 1].</p><p>The decoder function we use is similar to the one proposed by <ref type="bibr" target="#b7">[8]</ref>. Given the representations of two nodes h i</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Compatibility prediction between nodes</head><p>Input:</p><p>X -Feature matrix of the nodes A -Adjacency matrix of nodes relations (i, j) -Pairs of nodes for assessing compatibility Output: The compatibility score p between nodes i and j 1: L = 3</p><p>Use 3 graph convolutional layers 2: S = 1</p><p>Consider neighbours 1 step away 3: H = ENCODER(X, A) 4: p = DECODER(H, i, j) 5: function ENCODER(X, A) 6:</p><formula xml:id="formula_3">A 0 , A 1 = I L , I L + A 7:? 1 = D ?1 A 1</formula><p>Normalize the adj. matrix <ref type="bibr" target="#b7">8</ref>:</p><formula xml:id="formula_4">Z (0) = X 9:</formula><p>for each layer l = 0, ..., L ? 1 do 10: </p><formula xml:id="formula_5">Z (l+1) = ReLU S s=0? s Z (l) ? (l)<label>s 11</label></formula><formula xml:id="formula_6">return ? |H i,: ? H j,: | ? T + b 16: end function</formula><p>and h j computed with the encoder model described above, the decoder outputs the probability p that these two nodes are connected by an edge.</p><formula xml:id="formula_7">p = ? h i ? h j ? T + b<label>(3)</label></formula><p>Here |?| is absolute value, and ? ? R F and b ? R are learnable parameters. ?(?) is the sigmoid function that maps a scalar value to a valid probability ? (0, 1).</p><p>The form of the decoder described in <ref type="figure" target="#fig_2">Equation 3</ref> can be seen as a logistic regression decoder operating on the absolute difference between the two input vectors. The absolute value is used to ensure that the decoder is symmetric, i.e., the output of d( h i , h j ) and d( h j , h i ) is the same, making it invariant to the order of the nodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Training</head><p>The model is trained to predict compatibility among the products. With A being the adjacency matrix of the graph of items, we randomly remove a subset of edges to generate an incomplete adjacency matrix?. The set of edges removed is denoted by E + , as they represent positive edges, i.e., pairs of nodes (i, j) such that A i,j = 1. We then randomly sample a set of negative edges E ? , which represent pairs of nodes (i, j) that are not connected, i.e., products ?  that are not compatible. The model is trained to predict the edges E train = (E + , E ? ) that contain both positive and negative edges. Therefore, given the incomplete adjacency matrix? and the initial features for each node X, the decoder predicts the edges defined in E train , and the model is optimized by minimizing the cross entropy loss between the predicted edges and their ground truth values, which is 1 for the edges in E + and 0 for the edges in E ? . A schematic overview of the model can be seen in <ref type="figure">Figure</ref> 2, and Algorithm 1 shows how to compute the compatibility between two products using the encoder and decoder described above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental setup 4.1. Tasks</head><p>We apply our model to two tasks that can be recast as a graph edge prediction problem. In what follows, we let {o 1 , . . . , o N ?1 } denote the set of N fashion items in a given outfit, and e i,j denote the edge between nodes i and j.</p><p>Fill In The Blank (FITB). The fill-in-the-blank task consists of choosing the item that best extends an outfit from among a given set of possible item choices. We follow the setup described in Han et al. <ref type="bibr" target="#b11">[12]</ref>, where one FITB question is defined for each test outfit. Each question consists of a set of products that form a partial outfit, and a set of possible choices {c 0 , . . . , c M ?1 } that includes the correct answer and M ? 1 randomly chosen products. In our experiments we set the number of choices to 4. An example of one of these questions can be seen in <ref type="figure" target="#fig_2">Figure 3a</ref>, where the top row shows the products of a partial outfit and the bottom row shows the possible choices for extending it. FITB can be framed as an edge prediction problem where the model first generates the probability of edges between item pairs (o i , c j ) for all i = 0, . . . , N ? 1 and j = 0, . . . , M ? 1. Then, the score for each of the j choices is computed as N ?1 i=0 e i,j , and the one with the highest score is the item that is selected to be added to the partial outfit. The task itself is evaluated using the same metric defined by Han et al. <ref type="bibr" target="#b11">[12]</ref>: by measuring whether or not the correct item was selected from the list of choices.</p><p>Outfit Compatibility Prediction. In the outfit compatibility prediction task, the goal is to produce an outfit compatibility score, which represents the overall compatibility of the items forming the outfit. Scores close to 1 represent compatible outfits, and scores close to 0 represent incompatible outfits. The task can be framed as an edge prediction problem where the model predicts the probability of every edge between all possible item pairs; this means predicting the probability of N (N ?1) 2 edges for each outfit. The compatibility score of the outfit is the average over all pairwise edge probabilities</p><formula xml:id="formula_8">2 N (N ?1) N ?1 i=0 N ?1 j=i+1</formula><p>e i,j . The outfit compatibility prediction task is evaluated using the area under the ROC curve for the predicted scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Evaluation by neighbourhood size</head><p>Let the k-neighbourhood of node i in our relational graph be the set of k nodes that are visited by a breadthfirst-search process, starting from i. In order to measure the effect of the size of relational structure around each item, during testing we let each test sample contain the items and their k-neighbourhoods, and we evaluate our model by varying k. Thus, when k = 0 <ref type="figure" target="#fig_4">(Figure 4a</ref>) no relational information is used, and the embedding of each product is based only on its own features. As the value of k increases <ref type="figure" target="#fig_4">(Figures 4b and 4c</ref>), the embedding of the items compared will be conditioned on more neighbours. Note that this is applied only at evaluation time; during training, we use all available edges. For all results in the following sections we report the value of k used for each experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Datasets</head><p>We test our model on three datasets, as well as on a few of their variations that we discuss below.</p><p>The Polyvore dataset. The Polyvore dataset <ref type="bibr" target="#b11">[12]</ref> is a crowd-sourced dataset created by the users of a website of the same name; the website allowed its members to upload photos of fashion items, and collect them into outfits. It contains a total of 164,379 items that form 21,899 different outfits. The maximum number of items per outfit is 8, and the average number of items per outfit is 6.5. The graph is created by connecting each pair of nodes that appear in the same outfit with an edge. We train our model with the train set of the Polyvore dataset, and test it on a few variations obtained from this dataset, described below.</p><p>The FITB task contains 3,076 questions and the outfit compatibility task has 3,076 valid, and 4,000 invalid outfits. In the original Polyvore dataset, the wrong FITB choices and the invalid outfits are selected randomly from among all remaining products. The resampled dataset proposed by Vasileba et al. <ref type="bibr" target="#b35">[36]</ref> is more challenging: the incorrect choices in each question of the FITB task are sampled from the items having the same category as the correct choice; for outfit compatibility, outfits are sampled randomly such that each item in a given outfit is from a distinct category. We also propose a more challenging set which we call subset where we limit the outfits size to 3 randomly selected items. In this scenario the tasks become harder because less information is available to the model.</p><p>The Fashion-Gen Outfits dataset. Fashion-Gen <ref type="bibr" target="#b27">[28]</ref> is a dataset of fashion products collected from an online platform that sells luxury goods from independent designers. Each product has images, descriptions, attributes, and relational information. Fashion-Gen relations are defined by professional designers and adhere to a general theme, while Polyvore's relations are generated by users with different tastes and notions of compatibility.</p><p>We created outfits from Fahion-Gen by grouping between 3 and 5 products that are connected together. The training set consists of 60,159 different outfits from the collections 2015 ? 2017, and the validation and test sets have 2,683 and 3,104 outfits respectively, from the 2014 collection. The incorrect FITB choices and the invalid outfits for the compatibility task are randomly sampled items that satisfy gender and category restrictions, as in the case of the resampled Polyvore dataset.</p><p>Amazon products dataset. The Amazon products dataset <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b13">14]</ref> contains over 180 million relationships between almost 6 million products of different categories. In this work we focus on the clothing products, and we apply our method to the Men and Women categories. There are 4 types of relationships between items: (1) users who viewed A also viewed B; (2) users who viewed A bought B; (3) users who bought A also bought B; and (4) users bought A and B simultaneously. For the latter two cases, we make the assumption that the pair or items A and B are compatible and evaluate our model based on this assumption. We evaluate our model by predicting  the latter two, since they indicate products that might be complementary <ref type="bibr" target="#b23">[24]</ref>. We use the features they provide, which are computed with a CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Training details</head><p>Our model has 3 graph convolutional layers with S = 1, 350 units, dropout of 0.5 applied at the input and batch normalization at its output. The value of p drop applied to A is 0.15. The input to each node are 2048-dimensional feature vectors extracted with a ResNet-50 <ref type="bibr" target="#b12">[13]</ref> from the image of each product, and are normalized to zero-mean and unit variance. It is trained with Adam <ref type="bibr" target="#b19">[20]</ref>, with a learning rate of 0.001 for 4, 000 iterations with early stopping.</p><p>The Siamese Network baseline is trained with triplets of compatible and incompatible pairs of items. It consists on a ImageNet pretrained ResNet-50 at each branch and a metric learning output layer. We train it using SGD with a learning rate of 0.001 and a momentum of 0.9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Fill In The Blank</head><p>Polyvore Original. We report our results for this task in <ref type="table" target="#tab_2">Table 1</ref>. The first three rows correspond to previous work, and the following three rows show the scores obtained by our model for different values of k. As shown in the table, the scores consistently increases with k, from 62.2% of accuracy with k = 0 to 96.9% with k = 15. This behaviour is better seen in <ref type="figure" target="#fig_5">Figure 5a</ref> which shows how the accuracy in the FITB task increases as a function of k. When k = 0 the other methods perform better, because without structure our model is simpler. However, we can see how as more neighbourhood information is used, the results in the FITB task increase, which shows that using information from neighbouring nodes is a useful approach if extra relational information is available.</p><p>Polyvore Resampled. For the resampled setup, the accuracy also increases with k, going from 47.0% to 92.7%,   which is lower than its original counterpart, showing that the resampled task is indeed more difficult.</p><p>Polyvore Subset. The last rows of <ref type="table" target="#tab_2">Table 1</ref> (marked with ?) correspond to this scenario, and we can see that compared to when using the full outfit, the the FITB accuracy drops from 96.9% to 88.2% for the original version, and from 92.7% to 82.1% for the resampled version, both at k = 15.</p><p>Fashion-Gen Outfits. The results for the FITB task on the Fashion-Gen dataset are shown in <ref type="table" target="#tab_3">Table 2</ref> as a function of k. Similar to the results for variations of Polyvore, we see in <ref type="figure" target="#fig_5">Figure 5c</ref> how an increase in the value of k improves the performance of our model also for the Fashion-Gen dataset. For example, it increases by 20 points by using up to k = 15 neighbourhood nodes for each item, compared to using no neighbourhood information at all. When compared to the Siamese Network baseline, we observe how the siamese model is better than our model without structure, but with k ? 3 our method outperforms the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Outfit Compatibility Prediction</head><p>Polyvore Results. <ref type="table" target="#tab_2">Table 1</ref> shows the results obtained by our model on the compatibility prediction task for different values of k. Similarly to the previous task, results show that using more neighborhood information improves the performance on the outfit compatibility task, where the AUC increases from 0.86 with k = 0 to 0.99 with k = 15.</p><p>Polyvore Resampled. The scores on the resampled version are similar to the original version, increasing the AUC from 0.76 to 0.99 with a larger value for k.</p><p>Polyvore Subset. The results on this test data is denoted with ? in the table, and we see how in this scenario the scores decrease from 0.99 to 0.93 and 0.92 for the original and resampled tasks respectively, both with k = 15. As with the FITB task, here we observe again how using extra information in the form of relations with other products is beneficial to achieve better performance.</p><p>Fashion-Gen Outfits. The results on this task for the Fashion-Gen outfits dataset are shown in the second column of <ref type="table" target="#tab_3">Table 2</ref>, for different values of k. As can be seen, the larger the value of k, the better the performance. This trend is better shown in <ref type="figure" target="#fig_5">Figure 5d</ref>, where we can see how increasing k from 0 to 10 steadily improves the performance, and plateaus afterwards. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Context matters</head><p>With the above experiments, we have seen how increasing the amount of neighbourhood information improves the results on all tasks. To better understand the role of context, we use an example from Polyvore to demonstrate how the context of an item can influence its predicted compatibility with another product. <ref type="figure" target="#fig_6">Figure 6</ref> shows the compatibility predicted between a pair of trousers and two pairs of shoes depending on two different contexts. <ref type="figure" target="#fig_6">Figure 6a</ref> shows the original context of the trousers, and the shoes selected are the correct ones. However, if we change the context of the trousers to a different set of clothes, as in <ref type="figure" target="#fig_6">Figure 6b</ref>, the outcome of the prediction is now a different pair of shoes (more formal one) that presumably are a better match given the new context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Amazon Links</head><p>We also evaluate how our method can be applied to predict relations between products in the Amazon dataset. We train a model for each type of relationship and also evaluate how one model trained with clothes from one gender transfers to the other gender. This cross-gender setup allows us to evaluate how the model adapts to changes in context, as opposed to a baseline that ignores context altogether. In <ref type="table" target="#tab_4">Table 3</ref> we show that our model achieves state of the art results for the 'also bought' relation, and similar results for the 'bought together' relation. The 'bought together' relationship has much less connections than the 'also bought', so our model is less effective at using context to improve the results. However, since in that scenario the model has been trained with less connections, it performs better with  k = 0, because it is more similar to the training behaviour. In <ref type="table" target="#tab_5">Table 4</ref> we show the results of one model trained with men's clothing and tested with women's clothing (and vice versa). The model denoted with ? does not use relational information during training and testing, so is the baseline for not using contextual information (k = 0). As it can be seen, the more neighbourhood information a model uses, the most robust it is to the domain change. This occurs because when the model relies on context, it can adapt better to unseen styles or clothing types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this paper we have seen how context information can be used to improve the performance on compatibility prediction tasks using a graph neural network based model. We experimentally show that increasing the amount of context improves the performance of our model on all tasks. We conduct experiments on three different fashion datasets and obtain state of the art results when context is used during test time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>2 Figure 2 :</head><label>22</label><figDesc>Method. We pose fashion compatibility as an edge prediction problem. Our method consists of an encoder, which computes new embeddings for each product depending on their connections, and a decoder that predicts the compatibility score of two items. (a) Given the nodes x 1 and x 2 we want to compute their compatibility. (b) The encoder computes the embeddings of the nodes by using L graph convolutional layers that merge information from their neighbours. (c) The decoder computes the compatibility score using the embeddings computed with the encoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Tasks. We evaluate our model in two different tasks. (a) shows an example of a FITB question for the first task, and (b) shows an example of a valid outfit for the seconf task. (c) Shows how a FITB question can be posed as an edge prediction problem in a graph and (d) shows how the compatibility prediction for an outfit can be posed as an edge prediction problem.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>?</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Evaluation by k-neighbourhood. BFS expansion of k neighbours around two nodes. When (a) k = 0 no neighbourhood information is used; (c) k = 4 up to 4 neighbourhood nodes are used for compatibility prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Results. Evaluation of our models for different values of k.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Context matters. (a) and (b) show how predicted compatibility between items depends on their context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Polyvore Results. Polyvore results for both the FITB and the compatibility prediction tasks. Resampled task is more difficult than the original one. ? Using only a subset of length 3 of the original outfit.</figDesc><table><row><cell></cell><cell cols="4">FITB Accuracy Compat. AUC</cell></row><row><cell>Method</cell><cell>Orig.</cell><cell>Res.</cell><cell>Orig.</cell><cell>Res.</cell></row><row><cell cols="2">Siamese Net [36] 54.2</cell><cell>54.4</cell><cell>0.85</cell><cell>0.85</cell></row><row><cell>Bi-LSTM [12]</cell><cell>68.6</cell><cell>64.9</cell><cell>0.90</cell><cell>0.94</cell></row><row><cell>TA-CSN [36]</cell><cell>86.1</cell><cell>65.0</cell><cell>0.98</cell><cell>0.93</cell></row><row><cell>Ours (k = 0)</cell><cell>62.2</cell><cell>47.0</cell><cell>0.86</cell><cell>0.76</cell></row><row><cell>Ours (k = 3)</cell><cell>95.9</cell><cell>90.9</cell><cell>0.99</cell><cell>0.98</cell></row><row><cell>Ours (k = 15)</cell><cell>96.9</cell><cell>92.7</cell><cell>0.99</cell><cell>0.99</cell></row><row><cell>Ours (k = 0)  ?</cell><cell>59.5</cell><cell>45.3</cell><cell>0.69</cell><cell>0.64</cell></row><row><cell>Ours (k = 3)  ?</cell><cell>79.1</cell><cell>69.4</cell><cell>0.92</cell><cell>0.90</cell></row><row><cell>Ours (k = 15)  ?</cell><cell>88.2</cell><cell>82.1</cell><cell>0.93</cell><cell>0.92</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Fashion-Gen Results. Results on the Fashion-Gen dataset for the FITB and compatibility tasks.</figDesc><table><row><cell>Method</cell><cell cols="2">FITB Acc. Compatibility AUC</cell></row><row><cell>Siamese Network</cell><cell>56.3</cell><cell>0.69</cell></row><row><cell>Ours (k = 0)</cell><cell>51.9</cell><cell>0.72</cell></row><row><cell>Ours (k = 3)</cell><cell>65.0</cell><cell>0.84</cell></row><row><cell>Ours (k = 15)</cell><cell>76.1</cell><cell>0.90</cell></row><row><cell>Ours (k = 30)</cell><cell>77.1</cell><cell>0.91</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Amazon results. Results on the Amazon dataset for the link prediction task.</figDesc><table><row><cell></cell><cell cols="2">Also bought</cell><cell cols="2">Bought together</cell></row><row><cell>Method</cell><cell cols="4">Men Women Men Women</cell></row><row><cell cols="2">McAuley et al. [24] 93.3</cell><cell>91.2</cell><cell>95.1</cell><cell>94.3</cell></row><row><cell>Ours (k = 0)</cell><cell>57.9</cell><cell>53.8</cell><cell>79.5</cell><cell>71.7</cell></row><row><cell>Ours (k = 3)</cell><cell>92.6</cell><cell>92.9</cell><cell>94.5</cell><cell>94.5</cell></row><row><cell>Ours (k = 10)</cell><cell>97.1</cell><cell>95.8</cell><cell>94.0</cell><cell>94.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Amazon cross-gender results. Test the adaptability of the model by training and testing across different genders. Rows show the gender the model has been trained on, columns show the gender the model is tested with. ? Model trained also with k = 0 so it does not use context during training.</figDesc><table><row><cell></cell><cell>Men Women</cell><cell></cell><cell>Men Women</cell></row><row><cell cols="2">k=0  ? Men 95.0 58.3 Women 66.5 93.2</cell><cell cols="2">k=0  ? Men 90.7 62.5 Women 73.2 91.5</cell></row><row><cell>k=0</cell><cell>Men 57.9 52.9 Women 55.9 53.8</cell><cell>k=0</cell><cell>Men 79.5 61.8 Women 68.5 71.7</cell></row><row><cell>k=3</cell><cell>Men 92.6 79.8 Women 86.5 92.9</cell><cell>k=3</cell><cell>Men 82.7 73.9 Women 79.7 94.5</cell></row><row><cell>k=10</cell><cell>Men 97.1 86.0 Women 90.9 95.8</cell><cell>k=10</cell><cell>Men 94.0 74.3 Women 83.2 94.8</cell></row><row><cell></cell><cell>(a) Also bought.</cell><cell cols="2">(b) Bought together.</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Fashion forward: Forecasting visual style in fashion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Al-Halah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.06394</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Faulkner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01261</idno>
		<title level="m">Relational inductive biases, deep learning, and graph networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A survey on metric learning for feature vectors and structured data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bellet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Habrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sebban</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1306.6709</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Geometric deep learning: going beyond euclidean data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine (SPM)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="42" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6203</idno>
		<title level="m">Spectral networks and locally connected networks on graphs</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Interpretable partitioned embedding for customized multi-item fashion outfit composition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimedia Retrieval</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04043</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.01212</idno>
		<title level="m">Neural message passing for quantum chemistry</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning fashion compatibility with bidirectional lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM on Multimedia Conference</title>
		<imprint>
			<publisher>ACM-MM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on World Wide Web (ICWWW)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep metric learning using triplet network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ailon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Workshop on Similarity-Based Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Creating capsule wardrobes from fashion images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-L</forename><surname>Hsiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kalofolias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.1717</idno>
		<title level="m">Matrix completion on graphs</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Visuallyaware fashion recommendation and design with generative image models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-C</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Data Mining (ICDM</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Variational graph auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Bayesian Deep Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Image-based recommendations on styles and substitutes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Targett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Geometric matrix completion with recurrent multi-graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Outfit generation and style extraction via bidirectional lstm and autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03133</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Fashion-gen: The generative fashion dataset and challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rostamzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Boquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Stokowiec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jauvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.08317</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The graph neural network model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hagenbuchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks (TNN)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="80" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modeling relational data with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schlichtkrull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bloem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Titov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Semantic Web Conference (ESWC)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Compatibility family learning for item recommendation and generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Shih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence (AAAI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<idno>2017. 4</idno>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Recommending outfits from personal closet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tangseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yamaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Okatani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision Workshop</title>
		<imprint>
			<publisher>ICCVW</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02263</idno>
		<title level="m">Graph convolutional matrix completion</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Learning type-aware embeddings for fashion compatibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Vasileva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Plummer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dusad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajpal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.09196</idno>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Conditional similarity networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karaletsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning visual clothing style with heterogeneous dyadic co-occurrences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kovacs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Velickovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10903</idno>
		<title level="m">Graph attention networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eksombatchai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01973</idno>
		<title level="m">Graph convolutional neural networks for web-scale recommender systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
