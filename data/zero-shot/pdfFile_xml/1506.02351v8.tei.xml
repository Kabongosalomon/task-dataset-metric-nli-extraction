<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Workshop track -ICLR 2016 STACKED WHAT-WHERE AUTO-ENCODERS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
							<email>junbo.zhao@cs.nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
								<address>
									<addrLine>719 Broadway, 12th Floor</addrLine>
									<postCode>10003</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
							<email>mathieu@cs.nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
								<address>
									<addrLine>719 Broadway, 12th Floor</addrLine>
									<postCode>10003</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
							<email>goroshin@cs.nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
								<address>
									<addrLine>719 Broadway, 12th Floor</addrLine>
									<postCode>10003</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Courant Institute of Mathematical Sciences</orgName>
								<orgName type="institution" key="instit2">New York University</orgName>
								<address>
									<addrLine>719 Broadway, 12th Floor</addrLine>
									<postCode>10003</postCode>
									<settlement>New York</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Workshop track -ICLR 2016 STACKED WHAT-WHERE AUTO-ENCODERS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a novel architecture, the "stacked what-where auto-encoders" (SWWAE), which integrates discriminative and generative pathways and provides a unified approach to supervised, semi-supervised and unsupervised learning without relying on sampling during training. An instantiation of SWWAE uses a convolutional net (Convnet) ) to encode the input, and employs a deconvolutional net (Deconvnet) (Zeiler et al. <ref type="formula">(2010)</ref>) to produce the reconstruction. The objective function includes reconstruction terms that induce the hidden states in the Deconvnet to be similar to those of the Convnet. Each pooling layer produces two sets of variables: the "what" which are fed to the next layer, and its complementary variable "where" that are fed to the corresponding layer in the generative decoder.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A desirable property of learning models is the ability to be trained in supervised, unsupervised, or semi-supervised mode with a single architecture and a single learning procedure. Another desirable property is the ability to exploit the advantageous discriminative and generative models. A popular approach is to pre-train auto-encoders in a layer-wise fashion, and subsequently fine-tune the entire stack of encoders (the feed-forward pathway) in a supervised discriminative manner <ref type="bibr" target="#b1">(Erhan et al. (2010)</ref>; ; <ref type="bibr" target="#b5">Henaff et al. (2011)</ref>; <ref type="bibr" target="#b11">Kavukcuoglu et al. (2009;</ref>; ; ). This approach fails to provide a unified mechanism to unsupervised and supervised learning. Another approach, that provides a unified framework for all three training modalities, is the deep boltzmann machine (DBM) model <ref type="bibr" target="#b6">(Hinton et al. (2006)</ref>; <ref type="bibr" target="#b14">Larochelle &amp; Bengio (2008)</ref>). Each layer in a DBM is an restricted boltzmann machine (RBM), which can be seen as a kind of auto-encoder. Deep RBMs have all the desirable properties, however they exhibit poor convergence and mixing properties ultimately due to the reliance on sampling during training. The main issue with stacked auto-encoders is asymmetry. The mapping implemented by the feed-forward pathway is often many-to-one, for example mapping images to invariant features or to class labels. Conversely, the mapping implemented by the feed-back (generative) pathway is one-to-many, e.g. mapping class labels to image reconstructions. The common way to deal with this is to view the reconstruction mapping as probabilistic. This is the approach of RBMs and DBMs: the missing information that is required to generate an image from a category label is dreamed up by sampling. This sampling approach can lead to interesting visualizations, but is impractical for training large scale networks because it tends to produce highly noisy gradients.</p><p>If the mapping from input to output of the feed-forward pathway were one-to-one, the mappings in both directions would be well-defined functions and there would be no need for sampling while reconstructing. But if the internal representations are to possess good invariance properties, it is desirable that the mapping from one layer to the next be many-to-one. For example, in a Convnet, invariance is achieved through layers of max-pooling and subsampling.</p><p>Our model attempts to satisfy two objectives: (i)-to learn a factorized representation that encodes invariance and equivariance, (ii)-we want to leverage both labeled and unlabeled data to learn this representation in a unified framework. The main idea of the approach we propose here is very simple: whenever a layer implements a many-to-one mapping, we compute a set of complementary variables that enable reconstruction. A schematic of our model is depicted in figure 1 (b). In the max-pooling layers of Convnets, we view the position of the max-pooling "switches" as the complementary information necessary for reconstruction. The model we proposed consists of a feed-forward Convnet, coupled with a feed-back Deconvnet. Each stage in this architecture is what we call a "what-where auto-encoder". The encoder is a convolutional layer with ReLU followed by a max-pooling layer. The output of the max-pooling is the "what" variable, which is fed to the next layer. The complementary variables are the max-pooling "switch" positions, which can be seen as the "where" variables. The "what" variables inform the next layer about the content with incomplete information about position, while the "where" variables inform the corresponding feed-back decoder about where interesting (dominant) features are located. The feed-back (generative) decoder reconstructs the input by "unpooling" the "what" using the "where", and running the result through a reconstructing convolutional layer. Such "what-where" convolutional auto-encoders can be stacked and trained jointly without requiring alternate optimization <ref type="bibr" target="#b36">(Zeiler et al. (2010)</ref>). The reconstruction penalty at each layer constrains the hidden states of the feed-back pathway to be close to the hidden states of the feed-forward pathway. The system can be trained in purely supervised manner: the bottom input of the feed-forward pathway is given the input, the top layer of the feed-back pathway is given the desired output, and the weights of the decoders are updated to minimize the sum of the reconstruction costs. If only the top-level cost is used, the model reverts to purely supervised backprop. If the hidden layer reconstruction costs are used, the model can be seen as supervised with a reconstruction regularization. In unsupervised mode, the top-layer label output is left unconstrained, and simply copied from the output of the feed-forward pathway. The model becomes a stacked convolutional auto-encoder. As with boltzmann machines (BM), the underlying learning algorithm doesn't change between the supervised and unsupervised modes and we can switch between different learning modalities by clamping or unclamping certain variables. Our model is particularly suitable when one is faced with a large amount of unlabeled data and a relatively small amount of labeled data. The fact that no sampling (or contrastive divergence method) is required gives the model good scaling properties; it is essentially just backprop in a particular architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>The idea of "what" and "where" has been defined previously in different ways. One related method was proposed known as "transforming auto-encoders" <ref type="bibr" target="#b7">(Hinton et al. (2011)</ref>), in which "capsule" units were introduced. In that work, two sets of variables are trained to encapsulate "invariance" and "equivariance" respectively, by providing the parameters of particular transformation states to the network. Our work is carried out in a more unsupervised fashion in that it doesn't require the true latent state while still being able to encode similar representations within the "what" and "where". Switches information is also made use of by some visualization work such as <ref type="bibr" target="#b36">Zeiler et al. (2010)</ref>, while such work only has a generative pass and merely uses a feed-forward pass as an initialization step.</p><p>Similar definitions have been applied to learn invariant features ; <ref type="bibr" target="#b5">Henaff et al. (2011);</ref><ref type="bibr" target="#b11">Kavukcuoglu et al. (2009;</ref>; ; ; <ref type="bibr" target="#b19">Makhzani &amp; Frey (2014)</ref>; <ref type="bibr" target="#b20">Masci et al. (2011)</ref>). Among them, most works merely shed light to unsupervised feature learning and therefore failed to unify different learning modalities. Another relevant hierarchical architecture is proposed in ; ), however, because this architecture is trained in a layer-wise greedy manner, its performance is not competitive with jointly trained models.</p><p>In terms of joint loss minimization and semi-supervised learning, our work can be linked to <ref type="bibr" target="#b35">Weston et al. (2012)</ref> and <ref type="bibr" target="#b24">Ranzato &amp; Szummer (2008)</ref>, with the main advantage being the easiness to extend a Convnet with a Deconvnet and thereby enabling the utilization of unlabeled data. <ref type="bibr" target="#b21">Paine et al. (2014)</ref> has analyzed the regularization effect with similar architectures in a layer-wise fashion.</p><p>One recent work <ref type="bibr" target="#b26">(Rasmus et al. (2015b)</ref>, ) has been proposed to adopt deep auto-encoders to support supervised learning in which completely different strategy is employed to harness the lateral connection between same stage encoder-decoder pairs, however. In that work, decoders receive the entire pre-pooled activation state from the encoder, whereas decoders from SWWAE only receive the "where" state from the corresponding encoder stages. Further, due to a lack of unpooling mechanism incorporated in the Ladder networks, it is restricted to only reconstruct the top layer within generative pathway (? model), which looses the "ladder" structure. By contrast, SWWAE doesn't suffer from such necessity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MODEL ARCHITECTURE</head><p>We consider the loss function of SWWAE depicted in figure 1(b) composed of three parts:</p><formula xml:id="formula_0">L = L N LL + ? L2rec L L2rec + ? L2M L L2M ,<label>(1)</label></formula><p>where L N LL is the discriminative loss, L L2rec is the reconstruction loss at the input level and L L2M charges intermediate reconstruction terms. ?'s weight the losses against each other.</p><p>Pooling layers in the encoder split information into "what" and "where" components, depicted in figure 1(a), that "what" is essentially max and "where" carries argmax, i.e., the switches of maximally activation defined under local coordinate frame over each pooling region. The "what" component is fed upward through the encoder, while the "where" is fed through lateral connections to the same stage in the feed-back decoding pathway. The decoder uses convolution and "unpooling" operations to approximately invert the output of the encoder and reproduce the input, shown in figure 1. The unpooling layers use the "where" variables to unpool the feature maps by placing the "what" into the positions indicated the preserved switches. We use negative log-likelihood (NLL) loss for classification and L2 loss for reconstructions; e.g,</p><formula xml:id="formula_1">L L2rec = x ?x 2 , L L2M = x m ?x m 2 ,<label>(2)</label></formula><p>where L L2rec denotes the reconstruction loss at input-level and L L2M denotes the middle reconstruction loss. In our notation, x represents the input (no subscripts) and x i (with subscripts) represent the feature map activations of the Convnet, respectively. Similarly,x andx m are the input and activations of the Deconvnet, respectively. The entire model architecture is shown in figure 1(b). Notice in the following, we may use L L2 * to represent the weighted sum of L L2rec and L L2M . 3.1 SOFT VERSION "WHAT" AND "WHERE"</p><p>Recently, <ref type="bibr" target="#b2">Goroshin et al. (2015)</ref> introduces a soft version of max and argmax operators within each pooling region:</p><formula xml:id="formula_2">m k = N k z(x, y) e ?z(x,y) N k e ?z(x,y) ? max N k z(x, y)<label>(3)</label></formula><formula xml:id="formula_3">p k = N k x y e ?z(x,y) N k e ?z(x,y) ? arg max N k z(x, y),<label>(4)</label></formula><p>where z(x, y) denotes activation on the feature maps and x, y represent spatial location which take normalized values from -1 to 1. N k stands for the k th pooling region. Note that ? is a hyperparameter that is always set to be non-negative. It parametrizes soft pooling in such a way that the larger the ?, the closer the soft-pooling approaches max-pooling, while small ? approximates mean-pooling. We use interpolation in the unpooling stage to handle continuous value conveyed by "where".</p><p>The soft pooling and unpooling can be embedded seamlessly into the SWWAE model and it has the virtue such that it can backpropogate through p, in the contrast to the hard max-pooling being not differentiable w.r.t the argmax "switch" locations. Furthermore, soft-pooling operators enable location information to be more accurately represented and thus enable the features to capture fine details about the input, as evidenced in our visualization experiments (see section 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">TRAINING WITH JOINT LOSSES AND REGULARIZATION</head><p>As we mentioned, the SWWAE provides a unified framework for learning with all three learning modalities, all within a single architecture and single learning algorithm, i.e. stochastic gradient descent and backprop. Switching between these modalities can be achieved as follows:</p><p>? for supervised learning, we can mask out the entire Deconvnet pathway by setting ? L2 * to 0 and the SWWAE falls back to vanilla Convnet.</p><p>? for unsupervised learning, we can nullify the fully-connected layers on top of Convnet together with softmax classifier by setting ? N LL = 0. In this setting, the SWWAE is equivalent to a deep convolutional auto-encoder.</p><p>? for semi-supervised learning, all three terms of the loss are active. The gradient contributions from the Deconvnet can be interpreted as an information preserving regularizer.</p><p>The idea behind using reconstruction as a regularizer was studied previously in <ref type="bibr" target="#b1">Erhan et al. (2010)</ref>, although it uses unsupervised pre-training as its setup. In terms of this, SWWAE is connected to unsupervised pre-training in the sense that both paradigms attempt to provide better generalization by forcing the model to reconstruct. One argument of unsupervised learning acting as a regularizer is that supervised loss drives to model P (Y | X), while unsupervised pre-training captures the input distribution of P (X); and learning P (X) is helpful to learning P (Y | X) <ref type="bibr" target="#b1">(Erhan et al. (2010)</ref>). However, we argue that applying this statement to unsupervised pre-training setup appears unconvincing. One can argue that using P (X) merely to initialize the model for learning P (Y | X) has a very weak effect; i.e. the gradients from learning P (Y | X) completely overwrite the initial weights, thus eliminating any regularizing effect that may have been obtained from learning P (X).</p><p>We argue that joint training is a more effective strategy, i.e. SWWAE; our approach tries to model P (Y | X) together with P (X) jointly during training. Comparisons between different regularizers are shown in appendix.</p><p>Moreover, training jointly with multiple losses helps avoid collapsing or learning trivial representation. For one thing, a common issue with auto-encoders is that they learn little more than the identity function; e.g, copying input to get perfect reconstruction. For another, sparse auto-encoders <ref type="bibr" target="#b19">(Makhzani &amp; Frey (2014)</ref>, <ref type="bibr" target="#b18">Makhzani &amp; Frey (2013)</ref>) attain a well known trivial solutions: adding an L 1 penalty on the hidden layers is likely to scale down the encoder weights and scale up the decoders weight in order to reconstruct while achieving small activations. We argue that a direct way to avoid such trivial solutions is to include a supervised loss, which directly optimizes a non-trivial, useful, criterion that helps factorize the data into semantically relevant factors of variation.  <ref type="formula" target="#formula_0">(2011)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">INTERMEDIATE L2 CONSTRAINTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We use the following notation to describe our architecture (assume square kernels) e.g.</p><p>(16)5c-(32)3c-2p-10fc, in which '(16)5c' denotes convolution layer with 16 feature maps while kernel size being set to 5. 2p denotes 2 ? 2 pooling layer and 10fc denotes fully-connection layer that connects to 10 hidden units. ReLU is omitted in the notation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">NECESSITY OF "WHERE"</head><p>We address the necessity of "where" by showing the difference of reconstructions using "where" versus not using "where". Upsampling is an alternative way to do unpooling but without dreaming up "where", in the respect that "what" is agnostic about "where" and hence it gets copied on all the positions. <ref type="figure" target="#fig_1">Figure 2</ref> displays a group of reconstructed digits sampled from MNIST's testing set which are generated by a trained SWWAE using MNIST training set. The architecture we use is: (16)5c-(32)3c-Xp and the pooling size being experimented varies from 2 to 16. Note we use hard max-pooling for this experiment and the architecture is trained in unsupervised mode. On one hand, as the generations given by unpooling are obviously clearer and cleaner than the ones by upsampling, this experiment demonstrates that "where" is critical information demanded by reconstructing; one can barely obtain well reconstructed images without preserving "where". On the other hand, this experiment can also be considered as an example using SWWAE for generative purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">INVARIANCE AND EQUIVARIANCE</head><p>In this section, we examine the relationship between "what" and "where" by using the visualization approach proposed with transforming auto-encoders <ref type="bibr" target="#b7">(Hinton et al. (2011)</ref>) in which a number of "capsules" are trained to learn a representation consisting of equivariant and invariant components. Analogously, the "what" and "where" in our model's representation correspond to the invariant and equivariant components, respectively. The experiment recipe is stated as follow.</p><p>(1) train a SWWAE using horizontally and vertically translated MNSIT digits from training set; (2) feed untranslated digits from testing set into SWWAE and obtain the "what" (R) and "where" (R 2 ); (3) horizontally or vertically translate same set of digits and feed it into SWWAE and cache "what" and "where" correspondingly; (4) plot the relationship between "what" and "where" obtained from translated digits versus untranslated ones, shown in <ref type="figure" target="#fig_2">figure 3</ref>. The architecture we use is: (32)5c-(32)3c-2p-(32)3c-16p and we use soft pooling/unpooling with ? = 100. (5) since this experiment demands a large pooling size, we hence plot the generations in figure 4 to make sure that SWWAE works appropriately under such large pooling settings.</p><p>We draw the conclusion from figure 3 that "what" and "where" behave much like the invariance and equivariance of capsules in <ref type="bibr" target="#b7">Hinton et al. (2011)</ref>. One one hand, "where" learns highly localized representation. Each element in the R 2 "where" has an approximately linear response to the pixellevel translation on either horizontal/vertical direction and learns to be invariant to another. On   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">MNIST &amp; SVHN</head><p>As a start, we access the effect of SWWAE on classification by performing both semi-supervised and supervised experiments on MNIST and SVHN. We attempt to demonstrate that introducing a paired Deconvnet with a group of reconstruction losses can help generalization and provide an effective solution to make use of unlabeled data. Note in the classification experiments, we use the hard version pooling because it performs better than its soft counterparts in terms of classification.</p><p>We start by constructing semi-supervised datasets for both two datasets. MNIST dataset consists of images of 10 different classes (0 to 9) of size 32x32 with 60,000 training samples and 10,000 test samples. We follow the previous work for data preparation: randomly select labeled samples from training set while the rest of the samples is used without labels The sizes of labeled subset are respectively 100, 600, 1000, 3000 and we ensure each class has same number of digits chosen in the labeled set. SVHN dataset consists of 73,257 digits for training, 26,032 digits for testing and 53,1131 extra training samples that are less difficult. Likewise, we construct labeled dataset for SVHN that contains 1000 samples uniformly distributed in 10 classes, chosen randomly from the non-extra training set. In order to attain reliable results, we run each experiment several rounds whereby datasets are refreshed before each round and we average the performances of all rounds as the final evaluation.</p><p>We approach the "standalone" regularization effect of SWWAE on both datasets, by plotting the validation error v.s. ? L2 * (? L2M and ? L2rec are combined to be equal for this experiment) in figure 5. By "standalone", we mean that no other well-known regularizer is applied.</p><p>We further evaluate SWWAE on the testing set of SVHN with the chosen hyperparameters indicated by validation error. <ref type="table" target="#tab_1">Table 1</ref> shows the results. We additionally evaluate SWWAE on SVHN under pure supervised manner (with all the available labels) that we find that the testing error decreases from 5.89% to 4.94% yielded by SWWAE versus a vanilla Convnet under same configuration.</p><p>The architecture we use for MNIST and SVHN are respectively (64)5c-2p-(64)3c-2p-(64)3c-2p-10fc and (128)5c-2p-(128)3c-(256)3c-2p-(256)3c-2p-10fc. More exploration on MNIST is shown in appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">STL-10</head><p>STL-10 contains larger 96x96 pixel images and relatively less labeled data (5000 training samples, 100,000 unlabeled samples and 8,000 test samples). The training set is mapped to 10 predefined folds with 1,000 images each. Therefore, STL-10 has a 100:1 ratio of the amount of unlabeled samples to the labeled ones in each fold. We follow the testing protocol of STL-10 that we first tune the hyper-parameters for each fold by validation error and let the best performed model predict the testing set. The final score is reported by averaging the testing score of 10 folds. For STL-10, we access the possibility to combine batch normalization <ref type="bibr" target="#b9">(Ioffe &amp; Szegedy (2015)</ref>) and SWWAE. Furthermore, we carry out spatial batch normalization which preserves the mean and standard deviation from each feature map while they get normalized independently based on their own statistics. We devise a VGG-style <ref type="bibr" target="#b29">(Simonyan &amp; Zisserman (2014)</ref>) deep net, (64)3c-4p-(64)3c-3p-(128)3c-(128)3c-2p-(256)3c-(256)3c-(256)3c-(512)3c-(512)3c-(512)3c-2p-10fc and each convolution layer is followed by a spatial batch normalization layer, which is applied in both Convnet and Deconvnet pathways. Results are shown in table 2.  The dataset CIFAR-10 and CIFAR-100 are sampled and labeled from the 80 million tiny images dataset <ref type="bibr" target="#b33">(Torralba et al. (2008)</ref>). Both datasets contain 60,000 32x32 images which are small portions of the set of 80 million images. In contrast to the former classification experiments, this experiment involves substantially more abundant unlabeled data in relation to the amount of labeled data. We carry out the SWWAE with a VGG-style network <ref type="bibr" target="#b29">(Simonyan &amp; Zisserman (2014)</ref>):</p><p>(128)3c-(256)3c-2p-(256)3c-(512)3c-2p-(512)3c-(512)3c-2p-(512)3c-(512)3c-2p-128fc-10fc in which each convolution is bundled and followed by spatial batch normalization <ref type="bibr" target="#b9">(Ioffe &amp; Szegedy (2015)</ref>) in both Convnet and Deconvnet. To compare with results from other approaches, we perform the experiments in the common experimental setting that only adopts contrast normalization, small translation and horizontal mirroring for data preprocessing. The results are shown in table 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION AND OUTLOOK</head><p>The overall system, which can be seen as pairing a Convnet with a Deconvnet, yields good accuracy on a variety of semi-supervised and supervised tasks. We envision that such architecture may also be useful in video related tasks where unlabeled samples abound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX: MORE MNIST</head><p>We tend to exhibit more experimental results on MNIST in two respects. First, on the validation set, we compare the performance of SWWAE against other regularization methods, shown in table 4. Note in order to make the comparison more realistic and closer to practical uses, we add dropout <ref type="bibr" target="#b8">(Hinton et al. (2012)</ref>) at fully-connected layers as the default for this set of comparisons. Regularizers under comparison include dropout on the convolution layers and L1 sparsity penalty on hidden layers. Besides, we also train SWWAE unsupervisedly and separately train a softmax classifier afterwards using labeled samples; this disjointly trained architecture is denoted by "unsup-sfx". We similarly try using SWWAE as an unsupervised pre-training approach, followed by fine-tuning the entire Convnet part driven by labeled data, which is denoted by "unsup-pretr". Note the difference between "unsup-pretr" and "unsup-sfx" lies in if the Convnet part is frozen when training the softmax classifier on top. In addition, "noL2M" is written for experiments that SWWAE is trained with only reconstruction loss at the input level, i.e. ? L2M = 0 and ? L2rec is chosen by validation error. Second, we report the testing set error rate obtained by SWWAE with chosen hyper-parameter of SWWAE and compare it with best published results in table 5. Note that for the experiments on MNIST testing set, the labeled set is generated by sampling from the entire MNIST training set; the experiments on validation set, instead, sample the labeled data only from a subset of the MNIST training set because the rest of which is deemed as validation set. The SWWAE configuration is (64)5c-2p-(64)3c-2p-(64)3c-2p-10fc.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Left (a): pooling-unpooling. Right (b): model architecture. For brevity, fully-connected layers are omitted in this figure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Generation quality comparison between using upsampling (left) and unpooling (right). From top to bottom, the pooling sizes are respectively 2, 4, 8, 16.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Scatter plots depicting feature response produced by translating the input. The horizontal axis represents the "what" or "where" output from one feature plane for an untranslated digit image; vertical axis represents the "what" or "where" output from the same feature plane if that image is translated by +3 or -3 pixels in either horizontal or vertical direction. From left to right, the figures are respectively: first (a): "what" of horizontally translated digits versus original digits; second (b): "where" of horizontally translated digits versus original digits; third (c): "what" of vertically translated digits versus original digits; fourth (d): "where" of vertically translated digits versus original digits. Note that circles are used to feature +3 translation and triangles for -3. In the "where" related plots, x and y denote two dimensions of "where" respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Reconstructed MNIST digits in the capsule emulation experiments. The top row shows original input; second row shows the reconstruction of those original inputs; the bottom two rows display reconstruction of horizontally translated digits in positive and negative direction respectively. the other hand, "what" learns to be locally stable that exhibits strong invariance to the input-Validation-error v.s. ? L2 * on a range of datasets for SWWAE semi-supervised experiments. Left (a): MNIST. Right (b): SVHN. Different curves denote different number of labels being used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Third, As a correspondence to layer-wise auto-encoder training, each intermediate encoder/pool/unpool/decoder units in SWWAE, combined with intermediate L2 terms, can be seen as a single-layer convolutional auto-encoder (Masci et al.</figDesc><table /><note>The reasons for adding intermediate L2 reconstruction terms are listed as follow. First, it prevents the feature planes from being shuffled so that the "where" map conveyed from encoder i th are guaranteed to match the "what" from decoder i th . Otherwise, the unpooling may see "what" and "where" with shuffle orders, and hence cannot work properly. Second, in particular when training with classification loss, intermediate terms disallow the scenario that upper layers become idle while only lower layers are busy at reconstructing, in which case filters from those unemployed layers are not regularized. The related classification performance comparison about intermediate L2 terms is shown in appendix.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Comparison between SWWAE and other best published results on SVHN with 1000 labels.</figDesc><table><row><cell>model / N</cell><cell>error rate (in %)</cell></row><row><cell>KNN</cell><cell>77.93</cell></row><row><cell>TSVM (Vapnik &amp; Vapnik (1998))</cell><cell>66.55</cell></row><row><cell>M1+KNN (Kingma et al. (2014))</cell><cell>65.63</cell></row><row><cell>M1+TSVM (Kingma et al. (2014))</cell><cell>54.33</cell></row><row><cell>M1+M2 (Kingma et al. (2014))</cell><cell>36.02</cell></row><row><cell cols="2">SWWAE without dropout (?L2 *  = 0.8) 27.83</cell></row><row><cell>SWWAE with dropout (?L2 *  = 0.4)</cell><cell>23.56</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparison between SWWAE and other best published results on STL-10.</figDesc><table><row><cell>model</cell><cell>accuracy</cell></row><row><cell cols="2">Multi-task Bayesian Optimization (Swersky et al. (2013)) 70.1%</cell></row><row><cell>Zero-bias Convnets + ADCU (Paine et al. (2014))</cell><cell>70.2%</cell></row><row><cell>Exemplar Convnets (Dosovitskiy et al. (2014))</cell><cell>75.4%</cell></row><row><cell>SWWAE</cell><cell>74.33%</cell></row><row><cell>Convnet of same configuration</cell><cell>57.45%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Accuracy of SWWAE on CIFAR-10 and CIFAR-100 in comparison with best published single-model results. Our results are obtained with the common experimental setting that we only adopt contrast normalization, small translation and horizontal mirroring for data preprocessing.</figDesc><table><row><cell>model</cell><cell cols="2">CIFAR-10 CIFAR-100</cell></row><row><cell>All-Convnet (Springenberg et al. (2014))</cell><cell>92.75%</cell><cell>66.29%</cell></row><row><cell>Highway Network (Srivastava et al. (2015))</cell><cell>92.40%</cell><cell>67.76%</cell></row><row><cell>Deeply-supervised nets (Lee et al. (2014))</cell><cell>92.03%</cell><cell>65.43%</cell></row><row><cell cols="2">Fractional Max-pooling with large augmentation (Graham (2014)) 95.50%</cell><cell>68.55%</cell></row><row><cell>SWWAE (?L2rec = 1, ?L2M = 0.2)</cell><cell>92.23%</cell><cell>69.12%</cell></row><row><cell>Convnet of same configuration</cell><cell>91.33%</cell><cell>67.50%</cell></row><row><cell>4.4 LARGE SCALE EXPERIMENTS</cell><cell></cell><cell></cell></row><row><cell>4.4.1 CIFAR WITH 80 MILLION TINY IMAGES</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Comparison against other regularization approaches and disjoint training approaches on MNIST dataset. The scores are validation error rate (in %). Dropout is added at the fully-connected layers as default.</figDesc><table><row><cell>model / N</cell><cell>100</cell><cell>600</cell><cell>1000</cell><cell>3000</cell></row><row><cell>SWWAE</cell><cell cols="3">10.66 ? 0.55 4.35 ? 0.30 3.17 ? 0.17</cell><cell>2.13 ? 0.10</cell></row><row><cell cols="2">dropout on convolution 14.23 ? 0.94</cell><cell>4.70 ? 0.38</cell><cell>3.37 ? 0.11</cell><cell>2.08 ? 0.10</cell></row><row><cell>L1</cell><cell>10.91 ? 0.29</cell><cell>4.61 ? 0.28</cell><cell>3.55 ? 0.31</cell><cell>2.67 ? 0.25</cell></row><row><cell>unsup-sfx</cell><cell>17.81 ? 0.06</cell><cell>8.41 ? 0.08</cell><cell>6.40 ? 0.06</cell><cell>4.76 ? 0.03</cell></row><row><cell>unsup-pretr</cell><cell>-</cell><cell>9.80 ? 0.06</cell><cell cols="2">6.135 ? 0.03 4.41 ? 3.11</cell></row><row><cell>noL2M</cell><cell>12.41 ? 1.95</cell><cell>4.63 ? 0.24</cell><cell cols="2">3.15 ? 0.22 2.08 ? 0.18</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Comparison of testing error rate (in %) between SWWAE and other best published results on MNIST dataset within semi-supervised setting.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank Xiang Zhang and Aditya Ramesh for many useful discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="766" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Why does unsupervised pre-training help deep learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="625" to="660" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Learning to linearize under uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03011</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6071</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Fractional max-pooling. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning fast approximations of sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Machine learning (ICML&apos;10)</title>
		<meeting>International Conference on Machine learning (ICML&apos;10)</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised learning of sparse features for scalable audio classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Jarrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Symposium on Music Information Retrieval (ISMIR&apos;11)</title>
		<meeting>International Symposium on Music Information Retrieval (ISMIR&apos;11)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A fast learning algorithm for deep belief nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee-Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1527" to="1554" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Transforming auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Geoffrey E Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida D</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks and Machine Learning-ICANN 2011</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Improving neural networks by preventing co-adaptation of feature detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Geoffrey E Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan R</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salakhutdinov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1207.0580</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast inference in sparse coding algorithms with applications to object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno>CBLL-TR-2008-12-01</idno>
	</analytic>
	<monogr>
		<title level="j">Computational and Biological Learning Lab</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Courant Institute ; NYU</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech Report</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning invariant features through topographic filter maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision and Pattern Recognition (CVPR&apos;09</title>
		<meeting>International Conference on Computer Vision and Pattern Recognition (CVPR&apos;09</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning convolutional feature hierachies for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-Lan</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Gregor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?l</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS 2010)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Diederik P Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3581" to="3589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Classification using discriminative restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="536" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Yu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.5185</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Deeply-supervised nets. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Challenges in Representation Learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Frey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5663</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">k-sparse autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">A winner-take-all method for training sparse convolutional autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Frey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.2752</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Stacked convolutional auto-encoders for hierarchical feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ueli</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Cire?an</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Neural Networks and Machine Learning-ICANN 2011</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="52" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">An analysis of unsupervised pre-training in light of recent advances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pooya</forename><surname>Tom Le Paine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Khorrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6597</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A sparse and locally shift invariant feature extractor applied to document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis and Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1213" to="1217" />
		</imprint>
	</monogr>
	<note>Ninth International Conference on</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unsupervised learning of invariant feature hierarchies with applications to object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition, 2007. CVPR&apos;07. IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semi-supervised learning of compact document representations with deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelio</forename><surname>Marc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szummer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="792" to="799" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Semi-supervised learning with ladder network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikko</forename><surname>Honkala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathias</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapani</forename><surname>Raiko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.02672</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapani</forename><surname>Raiko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.08215</idno>
		<title level="m">Lateral connections in denoising autoencoders support supervised learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The manifold tangent classifier</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salah</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Yann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2294" to="2302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Contractive auto-encoders: Explicit invariance during feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salah</forename><surname>Rifai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Machine Learning (ICML-11)</title>
		<meeting>the 28th International Conference on Machine Learning (ICML-11)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="833" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Striving for simplicity: The all convolutional net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6806</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Rupesh Kumar Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.06228</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Training very deep networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multi-task bayesian optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan P</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">80 million tiny images: A large data set for nonparametric object and scene recognition. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1958" to="1970" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Statistical learning theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naumovich</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlamimir</forename><surname>Vapnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Wiley</publisher>
			<biblScope unit="volume">1</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep learning via semi-supervised embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Ratle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Networks: Tricks of the Trade</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="639" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deconvolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Matthew D Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page">3000</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Convnet (lecun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cae (rifai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mtc (rifai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pl-Dae (</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kingma</surname></persName>
		</author>
		<idno>2.37 1.92 - M1+M2</idno>
		<editor>WTA-AE (Makhzani &amp; Frey</editor>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Laddernetwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rasmus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Since MNIST is a roughly binary dataset (0/1) and thus within unpooling stage, decoding doesn&apos;t necessarily demand the information from &quot;what&quot; for reconstruction; i.e., it could get perfect reconstruction by pinning 1 on the positions indicated by &quot;where</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rasmus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Therefore, we believe that reconstructing MNIST dataset renders</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>We reason that SWWAE not working so well as Ladder networks. insufficient regularization on the encoding pathway. However, this phe</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
