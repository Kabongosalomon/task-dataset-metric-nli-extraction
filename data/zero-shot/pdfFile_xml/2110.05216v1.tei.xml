<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">High-order Tensor Pooling with Attention for Action Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Data61/CSIRO</orgName>
								<orgName type="institution">Australian National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Data61/CSIRO</orgName>
								<orgName type="institution">Australian National University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Data61/CSIRO</orgName>
								<orgName type="institution">Australian National University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">High-order Tensor Pooling with Attention for Action Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We aim at capturing high-order statistics of feature vectors formed by a neural network, and propose end-to-end second-and higher-order pooling to form a tensor descriptor. Tensor descriptors require a robust similarity measure due to low numbers of aggregated vectors and the burstiness phenomenon, when a given feature appears more/less frequently than statistically expected. We show that the Heat Diffusion Process (HDP) on a graph Laplacian is closely related to the Eigenvalue Power Normalization (EPN) of the covariance/auto-correlation matrix, whose inverse forms a loopy graph Laplacian. We show that the HDP and the EPN play the same role, i.e., to boost or dampen the magnitude of the eigenspectrum thus preventing the burstiness. Finally, we equip higher-order tensors with EPN which acts as a spectral detector of higher-order occurrences to prevent burstiness. We prove that for a tensor of order r built from d dimensional feature descriptors, such a detector gives the likelihood if at least one higher-order occurrence is 'projected' into one of binom(d,r) subspaces represented by the tensor; thus forming a tensor power normalization metric endowed with binom(d,r) such 'detectors'. This work extends [KZ20, KWC20].</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Auto-correlation/covariance and higher-order tensor descriptors have been applied to many deep learning tasks, e.g. object, texture and action recognition, tracking and segmentation <ref type="bibr" target="#b44">[TPM06,</ref><ref type="bibr" target="#b37">PT06,</ref><ref type="bibr" target="#b33">LW12,</ref><ref type="bibr" target="#b2">CCBS12]</ref>. A seminal approach <ref type="bibr" target="#b44">[TPM06]</ref> aggregates multiple low level feature vectors (that capture various directional gradient statistics) extracted from image regions to form a covariance matrix which is then used as a datapoint for a nearest neighbor retrieval or training an SVM classifier. Such covariance descriptors have been extended to the object category recognition, tracking, and other applications [TPM06, PT06, WCX11, LW12, GIK13].</p><p>The role of pooling is to aggregate local feature descriptors extracted from an instance-to-classify e.g., image patch, subsequence or subgraph descriptors from an image, video or a graph, respectively, into a single descriptor according to some statistically meaningful operation that encourages invariance w.r.t. the order of local descriptors, preserves useful global statistics, and is constant in its dimensionality (local descr. counts do not affect the size of aggregated descriptor). Examples of pooling include average and max-pooling <ref type="bibr" target="#b1">[BPL10]</ref> often used with a sparse encoder. Second-order co-occurrence pooling, a strategy shown to result in a superior performance in semantic segmentation and visual concept detection compared to the first-order pooling <ref type="bibr" target="#b2">[CCBS12,</ref><ref type="bibr" target="#b28">KYGM16]</ref>, is performed by aggregating the outer product of some intermediate feature vectors extracted by an encoder (e.g., the output of last convolutional layer in CNN) over image regions or video frames. A natural extension led to higher-order descriptors [KYGM13, <ref type="bibr" target="#b28">KYGM16,</ref><ref type="bibr" target="#b21">KC16]</ref> e.g., third-order super-symmetric tensors (trilinear pooling) which improve results over the second-order descriptors (bilinear pooling) over 7% MAP on the PASCAL VOC07 challenge.  <ref type="figure" target="#fig_7">Figure 1</ref>: The intuitive principle of the EPN. Given a discrete spectrum following a Beta distribution in <ref type="figure" target="#fig_7">Fig. 1a</ref>, the pushforward measures by MaxExp and HDP in figs. 1b and 1d are very similar. Gamma in <ref type="figure" target="#fig_7">Fig. 1c</ref> is also similar for small ? to MaxExp and HDP. Note that all three EPN functions in bottom plots whiten the spectrum (map most values to be equal ?1) thus removing burstiness. This property allows us design our third contribution, that is the spectral detector. The pushforward EPN functions used above are illustrated in <ref type="figure" target="#fig_1">Fig. 2</ref>.</p><p>Tensor descriptors require an appropriate aggregation/pooling mechanism to obtain robust estimates of covariance, auto-correlation or higher-order statistics and tackle the problem of burstiness, a phenomenon that certain features may occur rarely or frequently in instances to classify but only a mere detection of presence/absence of a feature is relevant to the classification task. For instance, a CNN filter responding by a feature activation to a stimulus such as a tree leave may respond once, few or many times across different spatial regions depending on whether a part or an entire tree is present in an image. However, reliably detecting a leave (or few leaves), not the quantity per se, is a robust predictor of a tree <ref type="bibr" target="#b28">[KYGM16]</ref>. Furthermore, presenting a classifier with varying counts of a feature makes it simply harder for the classifier to generalize to unseen instances e.g., if training images contained a small part of a tree (few leaves shown), it is likely that test images containing entire trees (thousands of leaves) will be misclassified as the decision boundary of a classifier is sensitive to the observed feature counts. For this reason, higher-order representations undergo a non-linearity such as Power Normalization (PN) <ref type="bibr" target="#b28">[KYGM16,</ref><ref type="bibr" target="#b21">KC16]</ref> which role is to reduce/boost contributions from frequent/infrequent visual stimuli in an image, respectively. Similar mechanisms apply to the temporal domain/action classification <ref type="bibr" target="#b22">[KCP16]</ref>. PN methods can be split into element-and spectrum-wise, the latter referred to as Eigenvalue Power Normalization (EPN) <ref type="bibr" target="#b27">[KYGM13,</ref><ref type="bibr" target="#b28">KYGM16]</ref>.</p><p>So-called MaxExp and Gamma are two superior EPN operators with state-of-the-art performance [KYGM13, <ref type="bibr" target="#b28">KYGM16,</ref><ref type="bibr" target="#b30">KZP18]</ref>. Thus, we perform a theoretical analysis of such EPN operators along with an application to action recognition. <ref type="figure" target="#fig_7">Figure 1</ref> explains the principle of EPN pooling.</p><p>Our contributions are summarized as follows:  <ref type="bibr" target="#b20">KB09]</ref>, which is essential in higher-order descriptors with EPN.</p><p>As EPN prevents burstiness, it replaces counting correlated features with detecting them, thus being invariant to their spatial/temporal extent (invariance properties are of high interest to this workshop).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">EIGENVALUE POWER NORMALIZATION</head><p>This section provides the prerequisites on power normalization methods of high dimensional tensors. First, we introduce the notations. X ? R d1?d2...?dr denotes r-order tensor. By default r = 3 meaning that X is a third-order tensor with exceptions depending on the context. The i-th slice of this tensor is denoted as X :,:,i , which is a d 1 ? d 2 matrix. For a matrix X ? R d1?d2 and a vector x = (x 1 , ..., x d3 ) ? R d3 , X = X ? ? x gives a tensor X ? R d1?d2?d3 , where the i-th slice of X is given by X ? x i . A symmetric third-order tensor of rank one X ? R d?d?d can be obtained from x as X = ? ? 3 x (xx T ) ? ? x. X = ? ? r x means the r-order outer product of x, where the (i 1 , ..., i r )-th coefficient of X is given by X i1,...,ir = x i1 ? x i2 ... ? x ir . The Frobenius norm of a tensor X is given by X F = i,j,k X 2 ijk , where X ijk represents the ijk-th element of X . Similarly, the inner-product between two tensors X and Y is given by</p><formula xml:id="formula_0">X , Y = ijk X ijk Y ijk . The tensor product ? j in mode j between X ? R d1?d2...?dr and Y ? R d 1 ?d 2 ...?d r * , where d j = d j , is denoted as X ? j Y ? R d1...?dj?1?dj+1...?dr?d 1 ...?d j?1 ?d j+1 ...?d r * . The (i 1 , ..., i j?1 , i j+1 , ..., i r , i 1 , ..., i j?1 , i j+1 , ..., i r * )-th coefficient of X ? j Y is given by ij X i1,.</formula><p>..,ij ,...,ir ? Y i 1 ,...,ij ,...,i r * . We denote the spaces of d?d Symmetric Positive Semi-Definite (SPSD) and Symmetric Positive Definite (SPD) matrices as S d + and S d ++ , I r is an index sequence 1, 2, ..., r, I is the identity matrix, ? is a Moore-Penrose inverse, {e i : i ? I d } are the spanning bases of R d . Bold lowercase/uppercase letters denote vectors/matrices, bold uppercase mathcal letters denote tensors, and regular letters denote scalars.</p><p>The following proposition formalizes the notion of higher-order descriptors.</p><formula xml:id="formula_1">Proposition 1 ([KTP17]). Let ? ? {? 1 , ..., ? N ? R d } and ? * ? {? * 1 , ..., ? * M ? R d }</formula><p>be feature vectors extracted from two instances to classify e.g., video sequences, images, text documents, etc. Let w ? R N + , w * ? R M + be some non-negative weights and ?, ? * ? R d be the mean vectors of ? and ? * , respectively. A linearization of the sum of polynomial kernels of degree r</p><formula xml:id="formula_2">X (?; w, ?), X (? * ; w * , ? * ) = 1 N M N n=1 M m=1 w r n w * r m ? n ??, ? * m ?? * r ,</formula><p>(1) yields the tensor feature map</p><formula xml:id="formula_3">X (?; w, ?) = 1 N N n=1 w r n ? ? r (? n ??) ? R d?d...?d .<label>(2)</label></formula><p>? and ? * do not have to be zero-mean centered (? = ? * = 0) if one uses an auto-correlation matrix/tensor instead of covariance. The weights w and w * can differ for each feature vector e.g., they may be the same within each group of feature vectors (image patch, video subsequence) but differ across different groups (patches of different size or subsequences of different length).</p><p>The EPN [KYGM16] performs a spectrum transformation on a given higher-order descriptor X ? R d1?d2...?dr , as detailed in the following steps (?; U 1 , ..., U r ) = HOSVD(X ),</p><formula xml:id="formula_4">? = g (?),<label>(3)</label></formula><formula xml:id="formula_5">G(X ) = ((? ? 1 U 1 ) ...) ? r U r ,<label>(4)</label></formula><p>where HOSVD stands for Higher Order Singular Value Decomposition [LMV00, KB09], the small-case g acts on the so-called core tensor ? ? R d 1 ?d 2 ...?d r in an element-wise manner, where d i ? d i , ?i, and? ? R d 1 ?d 2 ...?d r is the power-normalized counterpart of ?. Moreover, {U i ? R di?d i } i?Ir are r singular vector matrices. The uppercase mathcal notation indicates that G is a spectrum-wise (c.f . element-wise) operator on X . As the input tensor X is super-symmetric by Eq. (2), i.e., we have X i1,i2,...,ir = X ?(i1,i2,...,ir) for any indexes (i 1 , i 2 , ..., i r ) and any permutation ?, thus we have U 1 = U 2 ... = U r .</p><p>Popular variants of EPN pooling <ref type="bibr" target="#b30">[KZP18]</ref> shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, are given below, two for SPD/SPSD matrices and two for indefinite matrices (Krein spaces):  <ref type="figure" target="#fig_1">Fig. 2b</ref> and HDP (t ? (0, 1)) from <ref type="figure" target="#fig_1">Fig. 2c</ref> to each other. Also, the circle in <ref type="figure" target="#fig_1">Fig. 2c</ref> highlights the region where the profile of HDP differs from MaxExp. Furthermore, note that the above EPN functions are soft approximations of the Grassmann map (the step function) in <ref type="figure" target="#fig_1">Fig. 2d</ref>. Finally, <ref type="figure" target="#fig_1">Fig. 2e</ref> shows that MaxExp and Gamma given by g(?) and g ? (?) are upper bounds of HDP given by g * (?).  <ref type="figure" target="#fig_1">Figure 2d</ref> shows that Gamma performs whitening/evening out the spectrum of X ? R d?d .</p><formula xml:id="formula_7">? g(?) ?1 ?0.6 ?0.2 0.2 0.6 1 ?1 ?0.6 ?0.2 0.2 0.6 1 MaxExp, ?=10 MaxExp, ?=2 SigmE, ?'=13 SigmE, ?'=3 (a) MaxExp &amp; SigmE ? g(?) ?1 ?0.6 ?0.2 0.2 0.6 1 ?1 ?0.6 ?0.2 0.2 0.6 1 Gamma, ?=0.1 Gamma, ?=0.5 AsinhE, ?'=1500 AsinhE, ?'=3.5 (b) Gamma &amp; AsinhE</formula><formula xml:id="formula_8">Gamma g(?; ?) = ? ? (e.g., ? 1 2 ), in matrix form, G(X; ?) = X ? (e.g., X 1 2 a.k.a. matrix square root). MaxExp g(?; ?) = 1 ? (1 ? ?) ? , in matrix form, G(X; ?) = I?(I?X) ? .</formula><p>The EPN induces a family of non-Euclidean distance G(X ) ? G(Y) F in the SPSD/SPD cone. The Power-Euclidean (PowE) metric 1 ? ||X ? ? Y ? || 2 is discussed by <ref type="bibr" target="#b10">[DKZ09]</ref> who point out that as ? ? 0, the Power-Euclidean metric converges to the Log-Euclidean (LogE) metric || Log(X) ? Log(Y)|| F . MSR distance is in fact close to the Cholesky-Euclidean (CholE) distance || Chol(X) ? Chol(Y)|| F suggested by <ref type="bibr" target="#b10">[DKZ09]</ref>. However, the best results for Power-Euclidean distance (whose underlying feature map is Gamma) are typically attained with 0 ? = 0.5 [LM17, KZP18], which means the above connections to the Log-Euclidean metric and 'robust covariance estimation' are somewhat loose. Gamma for element-wise matrix pooling (c.f . spectral/eigenvalue pooling) is connected <ref type="bibr" target="#b30">[KZP18]</ref> to an operator called MaxExp. Intuitively, MaxExp yields 'the probability of at least one co-occurrence event (? n ?? n = 1) occurring in ? n and ? n simultaneously' given N ? ? Bernoulli trials and two event vectors ?, ? ? {0, 1} N . In fact, element-wise MaxExp/Gamma have similar profiles as <ref type="figure" target="#fig_1">Fig. 2</ref> shows. As EPN whitens the eigenspectrum of signal, it also differs from the batch normalization of variance of gradient features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MAIN RESULTS</head><p>Below, we show a correspondence between a covariance/auto-correlation matrix and a graph Laplacian and reveal a connection between the EPN functions and HDP. We establish that for HDP with t &lt; 1, MaxExp and Gamma functions can upper bound HDP tightly for some parametrization ?(t) and ?(t). We reconsider a system of Ordinary Differential Equations describing HDP and show that the modified ODE results in MaxExp and Gamma. Finally, we show that MaxExp is a spectral detector and formulate the capacity of tensor descriptors to perform subspace-based detection thus providing a robust Tensor Power Normalization metric to tackle the burstiness problem. The proofs of all theorems below are given as Appendices in the Supplementary Material. Theorem 1. A structured multi-variate Gaussian distribution with covariance matrix X is associated with a weighted graph such that the precision matrix Q ? X ?1 corresponds to the graph Laplacian <ref type="bibr" target="#b51">[ZFC15]</ref>. Let X to be trace-normalized so that 0  <ref type="figure" target="#fig_3">Figure 3b</ref> simulates a single detection, an assignment into a subspace (r = 2). ? ? 0 and ? ? ?/2 simulate the case when the majority of feature descriptors fall close to the subspace boundary.</p><formula xml:id="formula_9">&lt; i ? i ? 1, and G ? (X) = U diag(1 ? (1 ? ?) ? )U T be our spectral MaxExp operator. Let K t (Q) = Exp(?tQ), t &gt; 0, be ? g(?) 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 e ? t(?) ? 1 e ?1 t(?) ? +1 1?(1??) ? ? 1?(1??) ? ? ? t(?), 1 ?+1 (a) ? = 2cos(?)sin(?) g(?)</formula><p>the Heat Diffusion Process on the graph. Then ?? &gt; 1, G ? (X) can be well approximated by some</p><formula xml:id="formula_10">K t (Q), 0 &lt; t &lt; 1. Similarly, K t (Q) can approximate Gamma.</formula><p>As the time parameter t is in the range (0, 1), we call K t (Q) a time-reversed heat diffusion process. This means that rather than diffusing the heat between the nodes fro t &gt; 1, the model reverses the process in the direction of the identity matrix, that is lim t?0 K t (Q) ? I, lim ??? G ? (X) ? I and lim ??0 X ? ? I. This coincides with eigenspectrum whitening which prevents busrsiness <ref type="bibr" target="#b30">[KZP18]</ref>. Theorem 1 does not state any approximation results, we thus have following theorems. Theorem 2. ?? &gt; 1, ?t(?), such that MaxExp function is a upper bound of HDP, i.e., 1?(1??) ? ? exp(?t(?)/?), ?? ? (t, ?), and gaps 1 and 2 between these two functions at ? = t(?) and ? = 1 ?+1 , where the auxiliary bound ( 1 e ?1) t(?) ? +1 (Appendix B) touches HDP and MaxExp as in <ref type="figure" target="#fig_3">Fig. 3a</ref>, resp., satisfy</p><formula xml:id="formula_11">e?1 e ? 1? e e?1 ? ? (?+1) ?+1 ? = 1 ? 2 = 1? ? ?+1 ? ? e ? e e?1 ? ?+1 ? ,<label>(6)</label></formula><p>One possible parameterization t(?) satisfying the above condition is t(?) = e e?1 ? ? (?+1) ?+1 and correspondingly ?(t) ? 0.5 4/(t 2 (e?1) 2 )+1?0.5.</p><p>Theorem 3. Gamma function is an upper bound of HDP, that is ? ?(t) ? exp(?t/?), and there exist a direct point other than at ? = 0 where Gamma and HDP touch. Moreover, the corresponding parametrizations are ?(t) = et and t(?) = e ?1 ?.</p><p>Theorems 2 and 3 give us a combined tighter bound min(1?(1??) ?(t) , ? ?(t) ) ? exp(?t/?) now can be used in the following theorems connecting MaxExp and Gamma to the Heat Diffusion Equation (HDE) <ref type="bibr" target="#b52">[Zhu15]</ref>, the system of the Ordinary Differential Equations describing HDP. The HDE is given as:</p><formula xml:id="formula_13">??(t) ?t + L?(t) = 0,<label>(8)</label></formula><p>where vector ?(t) ? R d describes some heat quantity of graph nodes at a time t, where L ? R d?d is the graph Laplacian. Theorem 4. MaxExp can be expressed as a modified Heat Diffusion Equation, where the largest eigenvalue of X is assumed to be ? max ? 1, and X = L ? , thus we have</p><formula xml:id="formula_14">??(t) ?t + Log (I?X) ?? ?t (1 ? ?(t)) = 0.<label>(9)</label></formula><p>Theorem 5. Gamma can be also expressed as a modified Heat Diffusion Equation</p><formula xml:id="formula_15">??(t) ?t + e Log(L)?(t) = 0,<label>(10)</label></formula><p>where Log(L) is a Log-Euclidean map of the graph Laplacian. Thus, Gamma is equal to HDP on a Log-Euclidean map of the graph Laplacian, a theoretical connection between Power-Euclidean and Log-Euclidean metrics.</p><p>Below, we derive of eigenvalue/spectral MaxExp. First, we establish its connection to Grassmann maps. <ref type="figure" target="#fig_1">Figure 2d</ref> shows a pooling operator g realizing the Grassmann feature map 1 whose step function suggest it can act as a detector. Remark below details how to obtain Grassmann maps. Remark 1. Assume we have top q largest eigenvalues of X with the corresponding eigenvectors and q &lt; min(Rank(X 1 ), ..., Rank(X M )) for the total of M covariance descriptors. Then, the pooling operator g(?, q) = [[1] i?Iq , [0] i?I d?q ] T where 1 is repeated q times in the vector followed by 0 repeated d?q times, realizes the feature map used in computations the Grassmann distance, that is G(X) = U diag(g(?))U T , U contains sorted eigenvectors of X (descending order of eigenvalues).</p><p>In the reminder of this section, we establish the derivation of MaxExp in the spectral setting for Higher-order Tensors (HoT). We show that third-order tensor descriptors combined with MaxExp outperform second-order descriptors. For a probability density f X (x), its characteristic function</p><formula xml:id="formula_16">? X = E (exp(jX?)) = ? i=0 j i i! E(X i )? i ,</formula><p>where X i is essentially our X of order i in Eq. (11). If one could reliably estimate X for i = 0, ..., ?, the underlying f X (x) can be found too. However, estimating just a single E(X i ) e.g., second-or third-order statistics, poses a choice between using (i) a less informative lower-order statistical moment E(X 2 ) but easier to estimate (matrix grows quadratically with d) vs. (ii) a more informative higher-order moment whose size explodes (e.g., cubically w.r.t. d for third-order tensors) thus requiring more data for robust estimations. By tackling the burstiness our EPN helps estimate the HoT descriptors more robustly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">HoT with EPN</head><p>Below, we show that EPN in fact retrieves factors which quantify whether there is at least one datapoint ? n , n ? I N , projected into each subspace spanned by r-tuples of eigenvectors from matrices U 1 = U 2 ... = U r . For brevity, assume order r = 3, a super-symmetric tensor, and any 3-tuple of eigenvectos u, v, and w from U . Note that u ? v, v ? w and u ? w due to orthogonality of eigenvectors for super-symmetric tensors e.g., U ? ? V = [X :,:,1 , ..., X :,:,d ] ? R d?d 2 where ? ? are eigenvalues of the unfolded tensor X (note they are not the core tensor of X obtained by the HOSVD, which we denote as ?). Moreover, note that if we have dunique eigenvectors, we can enumerate d r r-tuples and thus d r subspaces R d?r ? R d?d . For simplicity, we assume we have d such vectors, that is d = Rank(X :,:,i ), ?i ? I d , otherwise if d &lt; d, then we would have d r subspaces instead. For brevity, let ||?|| 2 = 1 and ? ? 0. Also, we write ? n instead of ? for n ? I N when index n matters. Firstly, let us remove weights and zero-mean centering of our super-symmetric tensor descriptor from Eq. (2):</p><formula xml:id="formula_17">X = 1 N n?I N ? ? r ? n ,<label>(11)</label></formula><p>and write the 'diagonalization' of X by eigenvectors u, v, and w, which produces the core tensor with factors (spectrum of X ):</p><formula xml:id="formula_18">? u,v,w = X ? 1 u ? 2 v ? 3 w,<label>(12)</label></formula><p>where ? u,v,w is a coefficient from the core tensor ? corresponding to eigenvectors u, v, and w. Now, let us combine Eq. 11 and 12 which yields:</p><formula xml:id="formula_19">? u,v,w = 1 N n?I N ? ? 3 ? n ? 1 u? 2 v? 3 w = 1 N n?I N ? n , u ? n , v ? n , w .<label>(13)</label></formula><p>Theorem 6. Let ? n be 'optimally' projected into subspace spanned by u, v and w when ? n = ? n , u ? n , v ? n , w is maximized. As our u, v, and w are orthogonal w.r.t. each other and ||? n || 2 = 1, simple Lagrange eq. L = ? r i=1 e T i ? n +?(||? n || 2 2 ?1) yields maximum of ? = (1/ ? r) r at ? n = [(1/ ? r), ..., (1/ ? r)] T . For each n ? I N , we store ? n = ? n /? in a so-called event vector ?.</p><p>Assume that ? ? {0, 1} N stores N outcomes of drawing from Bernoulli distribution under the i.i.d. assumption for which the probability p of an event (? n = 1) and 1?p for (? n = 0) are estimated by an expected value, p = avg n ? n = ? u,v,w /? (0 ? ? ? 1 in reality, ? u,v,w , ? are introduced below Eq. (13)). Then the probability of at least one projection event (? n = 1) into the subspace spanned by r-tuples in N trials is:? ) ? (assume some correct choice of ? given ?). As third-order tensors are indefinite, SigmE is a good choice as it works with Kerein spaces by design, is smooth and almost indistinguishable from MaxExp (see <ref type="figure" target="#fig_1">Figure 2b</ref>).</p><formula xml:id="formula_20">u,v,w = 1?(1?p) N = 1? 1? ? u,v,w ? N .<label>(14)</label></formula><p>Finally, consider the dot-product between EPN-norm. tensors G(X ) and G(Y) computed by Eq.</p><p>(3-5):</p><formula xml:id="formula_21">G(X ), G(Y) = u?U (X ) v?V (X ) w?W (X ) u ?U (Y) v ?V (Y) w ?W (Y) ? u,v,w? u ,v ,w u, u v, v w, w .<label>(15)</label></formula><p>Hence, all subspaces of X and Y spanned by r-tuples (3-tuples in this example) are compared against each other for alignment by the cosine distance. When two subspaces [u, v, w] T and [u , v , w ] T are aligned well, for a strong similarity between these subspaces to be yielded, a detection of at least one ? n and ? n in these subspaces evidenced by? u,v,w and? u ,v ,w is also needed. We call Eq. (15) together with Eq. (3-5) as Tensor Power Euclidean (TPE) dot-product with associated Tensor Power Euclidean metric ||X ?Y|| G = ||G(X ) ? G(Y)|| F .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">AR PIPELINE</head><p>Below we evaluate our tensor descriptors combined with EPN (and SigmE which we call MaxExp in the reminder of the paper for simplicity as SigmE is an extension of MaxExp to Krein spaces). <ref type="figure" target="#fig_4">Figure 4</ref> introduces our action recognition (AR) pipeline. For each video sequence (an instance to classify), we first extract subsequences of lengths st 1 , ..., st 3 with the stride equal half of the subsequence length. This allows our approach to attain an invariance to action localization. Moreover, we apply various sampling rates e.g., sr 1 , sr 2 , which brings some invariance to the action speed. We pass each subsequence through two I3D networks <ref type="bibr" target="#b9">[CZ18]</ref> which were trained on the RGB and optical flow videos, respectively. For each network, we extract a 400 dimensional feature vector per subsequence whose coefficients coincide with the class labels of the Kinetics dataset (I3D CNN is pre-trained on Kinetics off-the-shelf). Moreover, we use two more end-to-end trainable sub-streams of I3D denoted by (#) whose outputs are two C-dim. feature vectors per subsequence (e.g., we backpropagate w.r.t. the last FC and the last inception block of I3D). Thus, we obtain intermediate matrices with feature vectors denoted as ? (rgb,400d) , ? (opt,400d) , ? (rgb,C) , and ? (opt,C) which we pass through the count sketching mechanism from Appendix H, denoted (sk), to reduce the dimensionality to d so that concatenating the corresponding feature vectors with (?) results in the size of 4d ? 120. At this stage, we pass each group of feature vectors ? (i,j) by an attention mechanism i.e., ?</p><formula xml:id="formula_22">(i,j) w = w E ? (i,j) ?? (i,j)</formula><p>, where i ? {st 1 , st 2 , ...} and j ? {sr 1 , sr 2 , ..., } are selectors of the step size and the sample rate, respectively. Moreover, an attention network w : R d ? R takes as input a d dim. expected value over a given group of feature vectors E ? (i,j) to produce an attention score within range [0; 1]. The attention network w(?) consists of an FC layer followed by a ReLU and another FC layer and a sigmoid function. The groups of feature vectors reweighted by such an attention mechanism form the final feature vector matrix ? (f inal) ? R d?N , where d = 4d , which is then simply passed via Eq. (11). Finally, we obtain X ? S d?d + for r = 2, or X ? R d?d?d for r = 3, and we pass every X via Eq. (3-5) to obtain G(X ) ? R d?d?d , one per instance to classify. Finally, we combine our HoT descriptors with auxiliary descriptors which are firstly count sketched (Appendix H) to reduce their dimensionality and then concatenated with HoT, as our pipeline shows. Below, we briefly discuss popular CNN approaches and the auxiliary descriptors we use. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Datasets and Protocols</head><p>HMDB-51 [KJG + 11] consists of 6766 internet videos over 51 classes; each video has ?20-1000 frames. We report the mean accuracy across three splits. YUP++ [FPW17b] contains so-called video textures captured with the static or moving camera. It has 20 scene classes and 60 videos per class. We follow the standard splits (1/9 dataset for training). <ref type="bibr" target="#b38">[RAAS12]</ref> has 64 activities in 3748 clips e.g., fine-grained actions peel, slice, cut apart. We use the mean Average Precision (mAP) over 7-fold crossvalidation. For humancentric protocol <ref type="bibr" target="#b7">[CSGH18]</ref>, we use Faster-RCNN [RHGS15] to crop video around humans.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MPII Cooking Activities</head><p>Settings. For IDT, we applied PCA to trajectories (30 dim.), HOG (96 dim.), HOF (108 dim.), MBHx (96 dim.) and MBHy (96 dim.), and we obtained 213 dim. descriptors. We computed 1024 k-means and 256 dimensional GMM-based dictionaries, resp., and obtained 1024 and ?110K final descriptors (FV was then count sketched to 4K). We used the Adam optimizer with 1e?4 learning rate halved every 10 epochs. We ran our training for 50-200 epochs depending on the dataset. For second-and third-order descriptors, d (we say d but we mean4d ) was set within 200-1000 (400 for HMDB-51, 160 for YUP++, 520 for MPII) and d ? 150 (80 for HMDB-51, 60 for YUP++, 60 for MPII), respectively. On HMDB-51/YUP++, we used two FC layers intertwined by a ReLU followed by a SoftMax classifier. On MPII, we used one FC (rightmost of <ref type="figure" target="#fig_4">Figure 4)</ref>. Subsequence lengths were set to 48, 64, 80, 96, and sampling rates to 1,2 (and 3 for HMDB-51/YUP++).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluations</head><p>Firstly, we compare pipeline variants on HMBD-51 . <ref type="table" target="#tab_1">Table 1</ref> shows that the second-and third-order pooling (SO) and (TO) without our eigenvalue/spectral MaxExp underperform, with (TO) being worse than (SO), as without MaxExp, third-order descriptors are poorly estimated. The accuracy between MaxExp and HDP differs by ? 0.25% accuracy which validates our assumptions that EPN   GRP+IDT 75.5% <ref type="bibr" target="#b4">[CFHG17]</ref> with MaxExp is in fact equivalent to the Heat Diffusion Process. Finally, third-order descriptors combined with MaxExp and IDT achieve 87.2% accuracy and outperform (SO) by 1.5% accuracy. <ref type="table" target="#tab_2">Table 2</ref> shows that the accuracy on YUP++ attained by third-order descriptors (TO) is ? 0.6% higher than the accuracy of (SO). Results on YUP++ are close to saturation thus we do not expect big gains, yet we outperform other methods in the literature e.g., T-ResNet of <ref type="bibr" target="#b15">[FPW17b]</ref> by 5.6% accuracy. <ref type="table" target="#tab_3">Table 3</ref> shows the results on MPII. For MPII, we have applied human-centric crops and used both IDT and I3D auxiliary features (I3D network was used with subsequences and global sequences subsampled to length 64). The third-order descriptor scored 80.4% mAP vs. 77.3% attained by second-order pooling. We note that with d = 520 and d = 60 (we say d but we mean 4d here), second-and third-order descriptors contained 135K and 37820 unique coefficients, respectively. Decreasing d for second-order descriptors did not help improve results which shows the benefit of third-order descriptors. Our best score gains ? 4.9% over the state-of-the-art GRP+ID method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We have established a connection between Eigenvalue Power Normalization via the MaxExp operator with the Heat Diffusion Process. We have shown that MaxExp approximates HDP but does not require the Laplacian matrix. We have applied MaxExp to higher-order tensor descriptors and obtained Tensors Power Normalization metric endowed with d r 'detectors' of the likelihood if at least one higher-order occurrence is 'projected' into one of d r subspaces of dimension r represented by the tensor. Our experiments show that third-order descriptors outperform second-order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>High-order Tensor Pooling with Attention for Action Recognition -Supplementary Material -A Outline Proof of Theorem 1</head><p>Proof. The connection of GMRF and E follows <ref type="bibr" target="#b51">[ZFC15]</ref>. For the reminder of the proof, a simple visual inspection of profiles g(?) = 1?(1??) ? and g * (?) = exp(?t/?) shows that g(?) ? g * (?) or even 0 ? g(?)?g * (?) &lt; for some sufficiently small &gt; 0 which shows that g(?) is an upper bound of g * (?) on the interval ? ? [0; 1]. <ref type="figure" target="#fig_1">Figure 2e</ref> shows the profiles of g(?), g(?) ? and g * (?) for MaxExp, Gamma and HDP. The plot also shows that g(?) ? ? g * (?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Proof of Theorem 2</head><p>Working with MaxExp and HDP according to their original parametrization as illustrated in <ref type="figure" target="#fig_3">Figure 3a</ref> (see also the zoomed <ref type="figure">Figure 5b)</ref> is difficult/intractable. Thus, for this bound, we start by a parametrization y = t ? and we note that t and ? can be tied together, that is t? = ?. We obtain</p><formula xml:id="formula_23">e ?y ? 1 e ?1 y+1 ? 1? 1? t y ? = 1? 1? ? ?y ? ,<label>(16)</label></formula><p>where 1 e ?1 y + 1 is an upper bound of e ?y on y ? (0, 1) and a lower bound of 1 ? 1? ? ?y ? .</p><p>Moreover, the latter equation can be tightened (as in 'lowered down') to touch 1 e ?1 y + 1 on y ? (0, 1). This process is illsutrated in <ref type="figure">Figure 5a</ref>. To this end, we need to solve for the system of equations to obtain (y, ?) </p><p>which simply says that we search for (y, ?) for which both functions on the left-and right-hand side touch and their slopes/tangents (thus derivatives w.r.t. y) are equal. We could try directly 'lower (18)</p><p>Recall that we have assumed parametrization t(?) = ?(?) ? , thus t(?) = e e?1 ? ? (?+1) ?+1 <ref type="figure">(Eq. (7)</ref>). Furthermore, we have to check if y ? (0, 1) for 1 ? ? ? ? in order for the bound to hold as 1 e ?1 y+1 is an upper bound of e ?y only for y ? (0, 1). To this end, we firstly notice that y(?) is monotonically decreasing on 0 ? ? ? ? as shown in <ref type="figure">Figure 5c</ref>. Therefore, it suffices to check extremes of ? for 1 ? ? ? ?, that is y(1) = 1 2 e e?1 and lim ??? y(?) = 1 e?1 which verifies that y(1 ? ? ? ?) ? (0, 1). This completes the first part of the proof.  <ref type="formula" target="#formula_11">6)</ref>).</p><p>We also note that by design we 1 (?) = 1? 1? ? ?y ? ? 1 e ?1 y+1 where 1 e ?1 y+1 touches e ?y at y = 1. Thus, we readily obtain 1 (?) = e?1 e ? 1? e e?1 ? ? (?+1) ?+1 ? (the left part of Eq. (6)).</p><p>Finally, obtaining the parametrization ?(t) which is an inverse of t(?) requires simply a few of algebraic manipulations with the use of the Stirling approximation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Proof of Theorem 3</head><p>As in Appendix B, we assume parametrization y = t ? which yields a set of the following equations </p><p>We again seek a parametrization t(?) for which the Gamma and HDP functions touch. However, this time the strict bound can be achieved analytically (e.g., the analytical solution to the above   <ref type="figure">Figure 5</ref>: In <ref type="figure">Fig. 5a</ref>, we show pooling functions reparametrized according to y = t ? . Specifically, we have HDP given by e ?y , its upper bound 1 e ?1 y + 1 for y ? (0, 1), and MaxExp given by 1? 1? t (?) y ? which we 'lower down' onto 1 e ?1 y +1 as illustrated by the black arrow. As we tighten the bound, some initial MaxExp with t (?) becomes MaxExp with t(?). <ref type="figure">Fig. 5b</ref> illustrates the same pooling operations as in <ref type="figure">Fig. 5a</ref> but without the reparametrization, that is, we show g(?) rather than g ? (y). Note the corresponding y and ? ranges in both figures indicated by the blue dashed lines. <ref type="figure">Fig. 5c</ref> shows that y(?) is monotonically decreasing on ? ? (0, ?). </p><formula xml:id="formula_26">e ? t(?) ? 1 e ?1 t(?) ? +1 1?(1??) ? ? 1?(1??) ? ? ? t(?), 1 ?+1 (b)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Proof of Theorem 4</head><p>To obtain the proof for this expression, we note that the system of ODE from Eq. (8) and thus also Eq. (9) can be rewritten in the span of eigenvectors of the graph Laplacian <ref type="bibr" target="#b52">[Zhu15]</ref>. Thus, we write the standard Heat Diffusion Equation as</p><formula xml:id="formula_27">?? (t) ?t + ?? (t) = 0,<label>(20)</label></formula><p>where ? (t) is now expressed in the span of new bases (? (t) is not a derivative). Now simply write MaxExp as 1 ? 1?? ?1 ?(t) . In this parametrization, we use ? ?1 as we start from the eigenvectors of the graph Laplacian rather than a covariance/auto-correlation matrix, and we use the parametrization ?(t) derived earlier. Thus ?? (t) ?t = ? log 1?? ?1 1?? ?1 ?(t) ??(t) ?t . Plugging this result into Eq. (20), we obtain ? log 1?? ?1 ??(t) ?t 1?? ?1 ?(t) + f (?, t)?? (t) ? h(?, t) = 0.</p><p>After simple algebraic manipulations we find f (?, t) = ?? ?1 log 1?? ?1 ??(t) ?t and h(?, t) = ? log 1?? ?1 ??(t) ?t such that Eq. (21) holds. putting these results together we obtain the set of ODE given as ?? (t) ?t + log (1?? * ) (1 ? ? (t)) = 0.</p><p>which is equivalent to Eq. (9) as, in the above equation eigenvalues ? * = ? ?1 correspond to the covariance/auto-correlation and graph Laplacian, respectively, which completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Proof of Theorem 5</head><p>As above, we note that the system of ODE from Eq. (8) and thus also Eq. (10) can be rewritten in the span of eigenvectors of the graph Laplacian <ref type="bibr" target="#b52">[Zhu15]</ref>, that is Eq. (20). Now simply write Gamma as ? ?1 et . In this parametrization, we use ? ?1 as we start from the eigenvectors of the graph Laplacian rather than a covariance/auto-correlation matrix, and we use the previous result stating that ? = et. Thus ?? (t) ?t = e ? ?1 et log ? ?1 . Plugging this result into Eq. (20), we obtain ? e log (?) ? ?1 et + f (?)?? (t) = 0,</p><p>where f (?) must be equal e? ?1 log(?) for Eq. (23) to hold. Putting together these results we obtain ? e log (?) ? ?1 et + e log(?)? ?1 ?? (t) = 0,</p><p>which simply tells us that the desired result is yielded by the set of ODE given as ?? (t) ?t + e log(?)? (t) = 0.</p><p>which is equivalent to Eq. (10) which completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Proof of Remark 1</head><p>Proof. It trivially follows that G(X) = U diag(g(?))U T = U :,1:q U T :,1:q from the definition of g which acts as a selector of eignenvectors corresp. to q largest eigenvalues. This results coincides with the feature map of the Grassmann distance e.g., see [HHS + 15].</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Different EPN functions and their profiles. Note the similarity of Gamma (? ? (0, 1)) fromFig. 2a, MaxExp (? &gt; 1) from</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>AsinhE g(?; ? ) = Arcsinh(? ?) and G(X; ? ) = Log ? X + (I + ? 2 X 2 ) 1 2 . AsinhE is the Arcus Hyperbolic Sine function. SigmE g(?; ? ) = 2/(1 + e ?? ? ) ? 1 and G(X; ? ) = 2 I + Exp(?? X) ? ? I. SigmE stands for a zero-centered Logistic a.k.a. Sigmoid function. As shown in Figures 2a and 2b, AsinhE/SigmE extend Gamma/MaxExp to Krein spaces by reflecting function Gamma/MaxExp defined for non-negative eigenvalues ? by the vertical symmetry axis followed by the change of sign. Parameters 0 &lt; ? ? 1, ? ? 1, 0 &lt; ? ? 1 and ? ? 1 control effect/steepness of such non-linearities. Moreover, eigenvalues ? are typically normalized by i |? i | and therefore ?i, ?1 ? ? i ? 1. Figures 2c and 2d show the impact of PN by varying ? of Gamma.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>In Fig. 3a, the blue dashed lines indicate the range for which we provide bounds. Imagine 'lowering down' MaxExp onto HDP (black arrow). See details in Appendix B.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>AR pipeline with the attention mechanism. See Section 4 for details.Each of d r subspaces spanned by r-tuples acts as a detector of projections into this subspace. Eq. (14) is the spectral MaxExp pooling with ? normalization.Figure 3bsimulates a detector by defining ? u,v from Eq. (13) as the cosine distance explicitly, that is ? u,v = ?cos(?)sin(?), ? = 2. Note the detector-like responses of MaxExp, Gamma and HDP. Remark 2. We note that the event vector ? may contain negative values so extending Eq. (14) to Sgn(? u,v,w ) 1?(1? |?u,v,w| ? ) ? , where ? ? N , divides each of d r subspaces into 'positive' and 'negative' parts, ? compensates for non-binary values in event vectors ?. However, the above extension has a non-smooth derivative. Thus, we use in practice the smooth SigmE operator defined in our introduction as 2/ 1+e ?? |?u,v,w | ? ?1 ? Sgn(? u,v,w ) 1?(1? |?u,v,w| ?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>AR pipelines. Powerful CNN architectures include the two-stream network<ref type="bibr" target="#b42">[SZ14]</ref>, 3D spatiotemporal features [TBF + 15], spatio-temporal ResNet<ref type="bibr" target="#b13">[FPW16]</ref> and the I3D network pre-trained on Kinetics-400<ref type="bibr" target="#b9">[CZ18]</ref>. However, these networks operate on the RGB and optical flow frames thus failing to capture some domain-specific information which sophisticated low-level representations capture by design. One prominent example are Improved Dense Trajectory (IDT) descriptors of<ref type="bibr" target="#b50">[WS13]</ref> which are typically encoded with Bag-of-Words (BoW) of [SZ03, CDF + 04] or Fisher Vectors (FV) of [PD07, PSM10] and fused with the majority of the modern CNN-based approaches of [FG16, CKG17, CSGH18, WC18b, CWRS18] at the classifier level for the best performance. Finally, attention in AR was also investigated in [GR17, ZTM + 19]. Improved Dense Trajectories. CNNs improve their performance if combined with IDT which involves several sophisticated steps: (i) camera motion estimation, (ii) modeling motion descriptors along motion trajectories captured with the optical flow, (iii) pruning inconsistent matches, (iv) removing focus from humans by the use of a human detector. IDT are usually combined with video descriptors such as Histogram of Oriented Gradients (HOG) [FR94, KMS08], Histogram of Optical Flow (HOF) [DTS06] and Motion Boundary Histogram (MBH) [WKSL13] which are complementary to each other. Thus, we follow others and encode IDT descriptors by BoW/FV.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>??y) = 1 e ?1 ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>down' 1</head><label>1</label><figDesc>? 1? ? ?y ? onto e ?y but such an approach yields an intractable system of equations requiring numerical approximations and the use of the Lambert function. By solving Eq. (17) we obtain</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>The next part of the proof requires solving 2 (?) = 1? 1? ?(?) ?y ? ?e ?y which can be solved by plugging into it (y, ?) from Eq. (18). After a few of algebraic manipulations we have 2 (?part of Eq. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>system of equations exists) and thus an intermediate bounding function is not needed. After a few of algebraic manipulations we obtain a candidate solution y = ? which if combined with the intermediate equation e y t y ? = 1 readily yields ?(t) = et which completes the proof.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>As MaxExp, Gamma and HDP can be thought of as pushforward functions acting on the discrete distribution representing an eigenspectrum, we show that both MaxExp and Gamma are upper bounds of HDP, and we use these results to further show that MaxExp and Gamma can indeed be formulated as a modified system of Ordinary Differential Equations (ODE) defining the Heat Diffusion Equation. As a result, we show that Gamma is in fact equal to HDP on the Log-Euclidean maps<ref type="bibr" target="#b0">[AFPA06]</ref>. Finally, we note that MaxExp, Gamma and HDP are close approximations of the Grassmann metric [HHS + 15] which lets us design our spectral detector as detailed next. 3. EPN has been long speculated<ref type="bibr" target="#b27">[KYGM13,</ref><ref type="bibr" target="#b28">KYGM16]</ref> to perform spectral detection of higherorder occurrences. We prove that a tensor of order r, built from d dimensional feature vectors, coupled with MaxExp indeed detects and yields the likelihood if at least one higher-order occurrence is 'projected' into one of d</figDesc><table /><note>1. We show that for an SPD matrix, MaxExp and Gamma are in fact closely related to the time-reversed (t &lt; 1) Heat Diffusion Process (HDP) on a so-called Loopy Graph Laplacian representing a Gaussian Markov Random Field (GMRF) [ZFC15], thus inheriting the prop- erties of HDP [SK03] defined as Exp(?tL), t &gt; 0. 2.r subspaces of dimension r represented by the tensor; thus forming a Tensors Power Normalization metric endowed with d r such 'detectors'. 4. Additionally, in our Supp. Material, we show how to backpropagate through the Higher Order Singular Value Decomposition (HOSVD) defined in [LMV00,</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>(top) Our pipeline variants vs. (bottom) the state of the art on HMDB-51. 21% 75.34% 76.65% 76.06% (no EPN) 75.35% 73.95% 75.01% 74.77% HDP 81.43% 78.76% 80.05% 80.08% HDP 81.75% 79.55% 81.34% 80.88% MaxExp 81.65% 79.11% 80.12% 80.30% MaxExp 82.30% 79.89% 81.20% 81.13% MaxExp+IDT 86.14% 85.16% 85.81% 85.70% MaxExp+IDT 87.41% 86.73% 87.51% 87.21%</figDesc><table><row><cell>SO+</cell><cell>sp1</cell><cell>sp2</cell><cell>sp3 mean acc.</cell><cell>TO+</cell><cell>sp1</cell><cell>sp2</cell><cell>sp3 mean acc.</cell></row><row><cell cols="4">(no EPN) 76.ADL+ResNet+IDT 74.3% [WC18a]</cell><cell></cell><cell cols="3">STM Network+IDT 72.2% [FPW17a]</cell></row><row><cell cols="4">ADL+I3D 81.5% [WC18a]</cell><cell></cell><cell cols="3">Full-FT I3D 81.3% [CZ18]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>(top) Our pipeline variants vs. (bottom) the state of the art on YUP++.</figDesc><table><row><cell></cell><cell>static</cell><cell>dynamic</cell><cell>mixed</cell><cell>mean stat/dyn</cell><cell>mean all</cell></row><row><cell>SO+MaxExp SO+MaxExp+IDT TO+MaxExp+IDT T-ResNet [FPW17b] ADL I3D [WC18a]</cell><cell>92.52% 94.92% 95.36% 92.41% 95.10%</cell><cell>82.03% 86.63% 86.90% 81.50% 88.30%</cell><cell>89.44% 96.02% 97.04% 89.00% -</cell><cell>87.3% 90.8% 91.1% 87.0% 91.7%</cell><cell>88.0% 92.5% 93.1% 87.6% -</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>(top) Our pipeline variants vs. (bottom) the state of the art on MPII.</figDesc><table><row><cell></cell><cell>sp1</cell><cell>sp2</cell><cell>sp3</cell><cell>sp4</cell><cell>sp5</cell><cell>sp6</cell><cell>sp7</cell><cell>mAP</cell></row><row><cell>SO+MaxExp+IDT TO+MaxExp+IDT</cell><cell>75.7 78.6</cell><cell>82.5 83.4</cell><cell>79.4 81.5</cell><cell>75.1 78.8</cell><cell>75.7 81.7</cell><cell>76.8 79.2</cell><cell cols="2">75.9 77.3% 79.6 80.4%</cell></row><row><cell cols="2">KRP-FS 70.0% [CSGH18] GRP 68.4% [CFHG17]</cell><cell></cell><cell></cell><cell cols="4">KRP-FS+IDT 76.1% [CSGH18]</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Grassmann maps are not used in the reminder of this paper as they approximate HDP worse than MaxExp(Figure 2d). Grassman maps also yielded lower accuracies than MaxExp in our preliminary experiments.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Proof of Theorem 6</head><p>Proof. The proof follows the fair coin toss syllabus. The probability of all N outcomes to be {(? 1 = 0), ..., (? N = 0)} amounts to (1 ? p) N . The probability of at least one positive outcome (? n = 1) amounts to applying the logical 'or'</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Count Sketches</head><p>Sketching feature vectors by the count sketch of [CH08, WDL + 09] is used for their dimensionality reduction in this paper. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I Backpropagating through HOSVD and/or SVD</head><p>To backpropagate through HOSVD, note that eigenvector matrices of tensor X e.g., U 1 , ..., U 3 for the third order, are given by</p><p>.., M 3 are simply unfolded matrices of X along the first, second, and third mode. Proposition 3. Let M # = M M T = U ?U T be an SPD matrix with simple eigenvalues, i.e., ? ii = ? jj , ?i = j. Then U coincides also with the eigenvector matrix of tensor X for the given unfolding. To compute the derivative of U (we drop the index) w.r.t. M (and thus X ), one has to follow the chain rule:</p><p>Proposition 4. For SVD, we simply have to backpropagate through the chain rule:</p><p>Let X = U ?U T be an SPD matrix with simple eigenvalues, i.e., ? ii = ? jj , ?i = j, and U contain eigenvectors of matrix X, then one can apply ??ii ?X = u i u T i and ?uij ?X = u ij (? jj I?X) ? . Proof. The two rightmost steps ??ii ?X and ?uij ?X can be found in <ref type="bibr" target="#b34">[Mag85]</ref>. Proposition 5. For HOSVD, one has to follow the analogous chain rule as in Prop. 4, but expanded from Eq. (5). To obtain the der. of ?, again a chain rule applies to Eq. (13).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Log-euclidean metrics for fast and simple calculus on diffusion tensors. Magnetic resonance in medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Arsigny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fillard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pennec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ayache</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="411" to="421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Theoretical Analysis of Feature Pooling in Vision Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y-Lan</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Semantic Segmentation with Second-Order Pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
			<affiliation>
				<orgName type="collaboration">CDF + 04</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Dance</surname></persName>
			<affiliation>
				<orgName type="collaboration">CDF + 04</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fan</surname></persName>
			<affiliation>
				<orgName type="collaboration">CDF + 04</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Willamowski</surname></persName>
			<affiliation>
				<orgName type="collaboration">CDF + 04</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bray</surname></persName>
			<affiliation>
				<orgName type="collaboration">CDF + 04</orgName>
			</affiliation>
		</author>
		<title level="m">Visual categorization with bags of keypoints. ECCV Workshop</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generalized rank pooling for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gould</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Finding frequent items in data streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Cormode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marios</forename><surname>Hadjieleftheriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1530" to="1541" />
			<date type="published" when="2008-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Higher-order pooling of cnn features via kernel linearization for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gould</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Non-linear temporal subspace representations for activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suvrit</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2197" to="2206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Potion: Pose motion representation for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Choutas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?r?me</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7024" to="7033" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Quo Vadis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Action Recognition? A New Model and the Kinetics Dataset. CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Non-euclidean statistics for covariance matrices, with applications to diffusion tensor imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">L</forename><surname>Dryden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Koloydenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diwei</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Applied Statistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1102" to="1123" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Human Detection Using Oriented Histogram of Flow and Appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navneet</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>ECCV</publisher>
			<biblScope unit="page" from="428" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning end-to-end video classification with rank-pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basura</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Gould</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1187" to="1196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Spatiotemporal residual networks for video action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel</forename><surname>Pinz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">P</forename><surname>Wildes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3468" to="3476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Spatiotemporal multiplier networks for video action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pinz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Wildes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Temporal residual networks for dynamic scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel</forename><surname>Pinz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">P</forename><surname>Wildes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Orientation histograms for hand gesture recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roth</surname></persName>
		</author>
		<idno>TR94-03</idno>
		<imprint>
			<date type="published" when="1994-12" />
			<pubPlace>Cambridge, MA 02139</pubPlace>
		</imprint>
		<respStmt>
			<orgName>MERL -Mitsubishi Electric Research Laboratories</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Action recognition from video using feature covariance matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prakash</forename><surname>Ishwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janusz</forename><surname>Konrad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Img. Proc</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2479" to="2494" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Attentional pooling for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Girdhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Extrinsic methods for coding and dictionary learning on grassmann manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">]</forename><forename type="middle">M</forename><surname>Hhs + 15</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lovell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sanderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Tensor decompositions and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sparse coding for third-order super-symmetric tensor descriptors with application to texture recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tensor representations via kernel linearization for action recognition from 3d skeletons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Cherian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatih</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="37" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Hmdb: a large video database for human motion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hueihan</forename><surname>Kjg + 11] Hildegard Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Est?baliz</forename><surname>Jhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomaso</forename><surname>Garrote</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Poggio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Serre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2011 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2556" to="2563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">A Spatio-Temporal Descriptor Based on 3D-Gradients. BMCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Klaser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Marszalek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Domain adaptation by mixture of alignments of second-or higher-order scatter tensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuf</forename><surname>Tas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatih</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7139" to="7148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Tensor representations for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Cherian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Higher-order occurrence pooling on mid-and low-level features: Visual concept detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Higher-order occurrence pooling for bags-of-words: Visual concept detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gosselin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Power normalizations in fine-grained image, few-shot image and graph classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongguang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A deeper look at power normalizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatih</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5774" to="5783" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Improved Bilinear Pooling with CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Tsung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maji</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A multilinear singular value decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>De Lathauwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">De</forename><surname>Moor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vandewalle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1253" to="1278" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Local log-euclidean covariance matrix (l 2 ecm) for image representation and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">On differentiating eigenvalues and eigenvectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">R</forename><surname>Magnus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometric Theory</title>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Fisher kernels on visual vocabularies for image categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
		<respStmt>
			<orgName>CVPR</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Improving the Fisher Kernel for Large-Scale Image Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="page" from="143" to="156" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<title level="m">Covariance tracker. CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A database for fine grained activity detection of cooking activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sikandar</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards realtime object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Kernels and regularization on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Kondor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Learning Theory and Kernel Machines</title>
		<editor>Bernhard Sch?lkopf and Manfred K. Warmuth</editor>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="144" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Video Google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">ICCV</biblScope>
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Two-stream convolutional networks for action recognition in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="568" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Tbf + 15] Du Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paluri</surname></persName>
		</author>
		<title level="m">Learning Spatiotemporal Features with 3D Convolutional Networks. ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4489" to="4497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Region covariance: A fast descriptor for detection and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tuzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Meer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning discriminative video representations using adversarial perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning discriminative video representations using adversarial perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Cherian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="716" to="733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Tracking by third-order tensor representation. Systems, Man, and Cybernetics, Part B: Cybernetics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenli</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="385" to="396" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Feature hashing for large scale multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Wdl + 09] Kilian Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Langford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Attenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1113" to="1120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Dense Trajectories and Motion Boundary Descriptors for Action Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Klaser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Lin</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>IJCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Action Recognition with Improved Trajectories. ICCV</title>
		<imprint>
			<biblScope unit="page" from="3551" to="3558" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Graph signal processing -a probabilistic framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cha</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinei</forename><surname>Florencio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">A</forename><surname>Chou</surname></persName>
		</author>
		<idno>MSR-TR-2015-31</idno>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Microsoft</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Diffusion and random walks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><forename type="middle">E</forename><surname>Zhukov</surname></persName>
		</author>
		<ptr target="www.leonidzhukov.net/hse/2015/networks/lectures/lecture11.pdf" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Local temporal bilinear pooling for fine-grained action parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>+ 19] Yan Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krikamol</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Jarvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12005" to="12015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
