<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Published as a conference paper at ICLR 2018 GENERALIZING ACROSS DOMAINS VIA CROSS-GRADIENT TRAINING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiv</forename><surname>Shankar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Bombay</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vihari</forename><surname>Piratla</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Bombay</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumen</forename><surname>Chakrabarti</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Bombay</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddhartha</forename><surname>Chaudhuri</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Bombay</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Adobe Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Jyothi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Bombay</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunita</forename><surname>Sarawagi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Indian Institute of Technology</orgName>
								<address>
									<settlement>Bombay</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Published as a conference paper at ICLR 2018 GENERALIZING ACROSS DOMAINS VIA CROSS-GRADIENT TRAINING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present CROSSGRAD, a method to use multi-domain training data to learn a classifier that generalizes to new domains. CROSSGRAD does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain. Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training. In contrast, CROSSGRAD is free to use domain signals for predicting labels, if it can prevent overfitting on training domains. We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances. CROSSGRAD parallelly trains a label and a domain classifier on examples perturbed by loss gradients of each other's objectives. This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions. Empirical evaluation on three different applications where this setting is natural establishes that (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and that (2) data augmentation is a more stable and accurate method than domain adversarial training. 1 * These two authors contributed equally 1 Code and dataset can be found at https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>We investigate how to train a classification model using multi-domain training data, so as to generalize to labeling instances from unseen domains. This problem arises in many applications, viz., handwriting recognition, speech recognition, sentiment analysis, and sensor data interpretation. In these applications, domains may be defined by fonts, speakers, writers, etc. Most existing work on handling a target domain not seen at training time requires either labeled or unlabeled data from the target domain at test time. Often, a separate "adaptation" step is then run over the source and target domain instances, only after which target domain instances are labeled. In contrast, we consider the situation where, during training, we have labeled instances from several domains which we can collectively exploit so that the trained system can handle new domains without the adaptation step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">PROBLEM STATEMENT</head><p>Let D be a space of domains. During training we get labeled data from a proper subset D ? D of these domains. Each labeled example during training is a triple (x, y, d) where x is the input, y ? Y is the true class label from a finite set of labels Y and d ? D is the domain from which this example is sampled. We must train a classifier to predict the label y for examples sampled from all domains, including the subset D \ D not seen in the training set. Our goal is high accuracy for both in-domain (i.e., in D) and out-of-domain (i.e., in D \ D) test instances.</p><p>One challenge in learning a classifier that generalizes to unseen domains is that Pr(y|x) is typically harder to learn than Pr <ref type="bibr">(y|x, d)</ref>. While <ref type="bibr" target="#b31">Yang &amp; Hospedales (2015)</ref> addressed a similar setting, they assumed a specific geometry characterizing the domain, and performed kernel regression in this space. In contrast, in our setting, we wish to avoid any such explicit domain representation, appealing instead to the power of deep networks to discover implicit features.</p><p>Lacking any feature-space characterization of the domain, conventional training objectives (given a choice of hypotheses having sufficient capacity) will tend to settle to solutions that overfit on the set of domains seen during training. A popular technique in the domain adaptation literature to generalize to new domains is domain adversarial training <ref type="bibr" target="#b2">(Ganin et al., 2016;</ref><ref type="bibr" target="#b26">Tzeng et al., 2017)</ref>. As the name suggests, here the goal is to learn a transformation of input x to a domain-independent representation, with the hope that amputating domain signals will make the system robust to new domains. We show in this paper that such training does not necessarily safeguard against over-fitting of the network as a whole. We also argue that even if such such overfitting could be avoided, we do not necessarily want to wipe out domain signals, if it helps in-domain test instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">CONTRIBUTION</head><p>In a marked departure from domain adaptation via amputation of domain signals, we approach the problem using a form of data augmentation based on domain-guided perturbations of input instances. If we could model exactly how domain signals for d manifest in x, we could simply replace these signals with those from suitably sampled other domains d to perform data augmentation. We first conceptualize this in a Bayesian setting: discrete domain d 'causes' continuous multivariate g, which, in combination with y, 'causes' x. Given an instance x, if we can recover g, we can then perturb g to g , thus generating an augmented instance x . Because such perfect domain perturbation is not possible in reality, we first design an (imperfect) domain classifier network to be trained with a suitable loss function. Given an instance x, we use the loss gradient w.r.t. x to perturb x in directions that change the domain classifier loss the most. The training loss for the y-predictor network on original instances is combined with the training loss on the augmented instances. We call this approach cross-gradient training, which is embodied in a system we describe here, called CROSSGRAD. We carefully study the performance of CROSSGRAD on a variety of domain adaptive tasks: character recognition, handwriting recognition and spoken word recognition. We demonstrate performance gains on new domains without any out-of-domain instances available at training time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Domain adaptation has been studied under many different settings: two domains <ref type="bibr" target="#b2">(Ganin et al., 2016;</ref><ref type="bibr" target="#b26">Tzeng et al., 2017)</ref> or multiple domains <ref type="bibr" target="#b17">(Mansour et al., 2009;</ref>, with target domain data that is labeled <ref type="bibr" target="#b10">(III, 2007;</ref><ref type="bibr" target="#b11">III et al., 2010;</ref><ref type="bibr" target="#b21">Saenko et al., 2010)</ref> or unlabeled <ref type="bibr" target="#b7">(Gopalan et al., 2011;</ref><ref type="bibr" target="#b5">Gong et al., 2012;</ref><ref type="bibr" target="#b2">Ganin et al., 2016)</ref>, paired examples from source and target domain <ref type="bibr" target="#b14">(Kuan-Chuan et al., 2017)</ref>, or domain features attached with each domain <ref type="bibr" target="#b32">(Yang &amp; Hospedales, 2016)</ref>. Domain adaptation techniques have been applied to numerous tasks in speech, language processing and computer vision <ref type="bibr" target="#b29">(Woodland, 2001;</ref><ref type="bibr" target="#b23">Saon et al., 2013;</ref><ref type="bibr" target="#b12">Jiang &amp; Zhai, 2007;</ref><ref type="bibr" target="#b10">III, 2007;</ref><ref type="bibr" target="#b21">Saenko et al., 2010;</ref><ref type="bibr" target="#b7">Gopalan et al., 2011;</ref><ref type="bibr" target="#b16">Li et al., 2013;</ref><ref type="bibr" target="#b9">Huang &amp; Belongie, 2017;</ref><ref type="bibr" target="#b27">Upchurch et al., 2016)</ref>. However, unlike in our setting, these approaches typically assume the availability of some target domain data which is either labeled or unlabeled.</p><p>For neural networks a recent popular technique is domain adversarial networks (DANs) <ref type="bibr" target="#b25">(Tzeng et al., 2015;</ref><ref type="bibr" target="#b2">Ganin et al., 2016)</ref>. The main idea of DANs is to learn a representation in the last hidden layer (of a multilayer network) that cannot discriminate among different domains in the input to the first layer. A domain classifier is created with the last layer as input. If the last layer encapsulates no domain information apart from what can be inferred from the label, the accuracy of the domain classifier is low. The DAN approach makes sense when all domains are visible during training. In this paper, our goal is to generalize to unseen domains.</p><p>Domain generalization is traditionally addressed by learning representations that encompass information from all the training domains. <ref type="bibr" target="#b20">Muandet et al. (2013)</ref> learn a kernel-based representation that minimizes domain dissimilarity and retains the functional relationship with the label. <ref type="bibr" target="#b1">Gan et al. (2016)</ref> extends <ref type="bibr" target="#b20">Muandet et al. (2013)</ref> by exploiting attribute annotations of examples to learn new feature representations for the task of attribute detection. In <ref type="bibr" target="#b3">Ghifary et al. (2015)</ref>, features that are shared across several domains are estimated by jointly learning multiple data-reconstruction tasks.</p><p>Such representations are shown to be effective for domain generalization, but ignore any additional information that domain features can provide about labels.</p><p>Domain adversarial networks (DANs) <ref type="bibr" target="#b2">(Ganin et al., 2016)</ref> can also be used for domain generalization in order to learn domain independent representations. A limitation of DANs is that they can be misled by a representation layer that over-fits to the set of training domains. In the extreme case, a representation that simply outputs label logits via a last linear layer (making the softmax layer irrelevant) can keep both the adversarial loss and label loss small, and yet not be able to generalize to new test domains. In other words, not being able to infer the domain from the last layer does not imply that the classification is domain-robust.</p><p>Since we do not assume any extra information about the test domains, conventional approaches for regularization and generalizability are also relevant. <ref type="bibr" target="#b30">Xu et al. (2014)</ref> use exemplar-based SVM classifiers regularized by a low-rank constraint over predictions. <ref type="bibr" target="#b13">Khosla et al. (2012)</ref> also deploy SVM based classifier and regularize the domain specific components of the learners. The method most related to us is the adversarial training of <ref type="bibr" target="#b24">(Szegedy et al., 2013;</ref><ref type="bibr" target="#b6">Goodfellow et al., 2014;</ref><ref type="bibr" target="#b18">Miyato et al., 2016)</ref> where examples perturbed along the gradient of classifier loss are used to augment the training data. perturbs examples. Instead, our method attempts to model domain variation in a continuous space and perturbs examples along domain loss.</p><p>Our Bayesian model to capture the dependence among label, domains, and input is similar to   <ref type="figure" target="#fig_0">Fig. 1d</ref>), but the crucial difference is the way the dependence is modeled and estimated.</p><p>Our method attempts to model domain variation in a continuous space and project perturbation in that space to the instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OUR APPROACH</head><p>We assume that input objects are characterized by two uncorrelated or weakly correlated tags: their label and their domain. E.g. for a set of typeset characters, the label could be the corresponding character of the alphabet ('A', 'B' etc) and the domain could be the font used to draw the character. In general, it should be possible to change any one of these, while holding the other fixed.</p><p>We use a Bayesian network to model the dependence among the label y, domain d, and input x as shown in <ref type="figure" target="#fig_0">Figure 1</ref> obtained by a complicated, un-observed mixing 2 of y and g. In the training sample L, nodes y, d, x are observed but L spans only a proper subset D of the set of all domains D. During inference, only</p><p>x is observed and we need to compute the posterior Pr(y|x). As reflected in the network, y is not independent of d given x. However, since d is discrete and we observe only a subset of d's during training, we need to make additional assumptions to ensure that we can generalize to a new d during testing.</p><p>The assumption we make is that integrated over the training domains the distribution P (g) of the domain features is well-supported in L. More precisely, generalizability of a training set of domains D to the universe of domains D requires that</p><formula xml:id="formula_0">P (g) = d?D P (g|d)P (d) ? d?D P (g|d) P (d) P (D)<label>(A1)</label></formula><p>Under this assumption P (g) can be modeled during training, so that during inference we can infer y for a given x by estimating</p><formula xml:id="formula_1">Pr(y|x) = d?D Pr(y|x, d) Pr(d|x) = g Pr(y|x, g) Pr(g|x) ? Pr(y|x,?) (1) where? = argmax g Pr(g|x) is the inferred continuous representation of the domain of x.</formula><p>This assumption is key to our being able to claim generalization to new domains even though most real-life domains are discrete. For example, domains like fonts and speakers are discrete, but their variation can be captured via latent continuous features (e.g. slant, ligature size etc. of fonts; speaking rate, pitch, intensity, etc. for speech). The assumption states that as long as the training domains span the latent continuous features we can generalize to new fonts and speakers.</p><p>We next elaborate on how we estimate Pr(y|x,?) and? using the domain labeled data L = {(x, y, d)}. The main challenge in this task is to ensure that the model for Pr(y|x,?) is not overfitted on the inferred g's of the training domains. In many applications, the per-domain Pr(y|x, d) is significantly easier to train. So, an easy local minima is to choose a different g for each training d and generate separate classifiers for each distinct training domain. We must encourage the network to stay away from such easy solutions. We strive for generalization by moving along the continuous space g of domains to sample new training examples from hallucinated domains. Ideally, for each training instance (x i , y i ) from a given domain d i , we wish to generate a new x by transforming its (inferred) domain g i to a random domain sampled from P (g), keeping its label y i unchanged. Under the domain continuity assumption (A1), a model trained with such an ideally augmented dataset is expected to generalize to domains in D \ D.</p><p>However, there are many challenges to achieving such ideal augmentation. To avoid changing y i , it is convenient to draw a sample g by perturbing g i . But g i may not be reliably inferred, leading to a distorted sample of g. For example, if the g i obtained from an imperfect extraction conceals label information, then big jumps in the approximate g space could change the label too. We propose a more cautious data augmentation strategy that perturbs the input to make only small moves along the estimated domain features, while changing the label as little as possible. We arrive at our method as follows.? Domain inference. We create a model G(x) to extract domain features g from an input x. We supervise the training of G to predict the domain label d i as S(G(x i )) where S is a softmax transformation. We use J d to denote the cross-entropy loss function of this classifier. Specifically,</p><formula xml:id="formula_2">x rJ d rJ l J l J d y d C ? l G ? 1 d S ? 2 d ? d = (? 1 d , ? 2 d )<label>Figure</label></formula><formula xml:id="formula_3">J d (x i , d i )</formula><p>is the domain loss at the current instance.</p><p>Domain perturbation. Given an example (x i , y i , d i ), we seek to sample a new example (x i , y i ) (i.e., with the same label y i ), whose domain is as "far" from d i as possible.</p><p>To this end, consider setting</p><formula xml:id="formula_4">x i = x i + ? xi J d (x i , d i ).</formula><p>Intuitively, this perturbs the input along the direction of greatest domain change 3 , for a given budget of ||x i ? x i ||. However, this approach presupposes that the direction of domain change in our domain classifier is not highly correlated with the direction of label change. To enforce this in our model, we shall train the domain feature extractor G to avoid domain shifts when the data is perturbed to cause label shifts.</p><p>What is the consequent change of the continuous domain features? i ? This turns out to be</p><formula xml:id="formula_5">JJ ?? i J d (x i , d i ),</formula><p>where J is the Jacobian of? w.r.t. x. Geometrically, the JJ term is the (transpose of the) metric tensor matrix accounting for the distortion in mapping from the x-manifold to the?-manifold. While this perturbation is not very intuitive in terms of the direct relation between? and d, we show in the Appendix that the input perturbation ? xi J d (x i , d i ) is also the first step of a gradient descent process to induce the "natural" domain perturbation ?? i = ?? i J d (x i , d i ).</p><p>The above development leads to the network sketched in <ref type="figure">Figure 2</ref>, and an accompanying training algorithm, CROSSGRAD, shown in Algorithm 1. Here X, Y, D correspond to a minibatch of instances. Our proposed method integrates data augmentation and batch training as an alternating sequence of steps. The domain classifier is simultaneously trained with the perturbations from the label classifier network so as to be robust to label changes. Thus, we construct cross-objectives J l and J d , and update their respective parameter spaces. We found this scheme of simultaneously training both networks to be empirically superior to independent training even though the two classifiers do not share parameters.</p><p>Algorithm 1 CROSSGRAD training pseudocode.</p><formula xml:id="formula_6">1: Input: Labeled data {(x i , y i , d i )} M i=1</formula><p>, step sizes l , d , learning rate ?, data augmentation weights ? l , ? d , number of training steps n. 2: Output: Label and domain classifier parameters ? l , ? d 3: Initialize ? l , ? d {J l , J d are loss functions for the label and domain classifiers, respectively} 4: for n training steps do 5:</p><p>Sample a labeled batch (X, Y, D) 6:</p><formula xml:id="formula_7">X d := X + l ? ? X J d (X, D; ? d ) 7: X l := X + d ? ? X J l (X, Y ; ? l ) 8: ? l ? ? l ? ?? ? l ((1 ? ? l )J l (X, Y ; ? l ) + ? l J l (X d , Y ; ? l )) 9: ? d ? ? d ? ?? ? d ((1 ? ? d )J d (X, D; ? d ) + ? d J d (X l , D; ? d )) 10: end for</formula><p>If y and d are completely correlated, CROSSGRAD reduces to traditional adversarial training. If, on the other extreme, they are perfectly uncorrelated, removing domain signal should work well. The interesting and realistic situation is where they are only partially correlated. CROSSGRAD is designed to handle the whole spectrum of correlations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we demonstrate that CROSSGRAD provides effective domain generalization on four different classification tasks under three different model architectures. We provide evidence that our Bayesian characterization of domains as continuous features is responsible for such generalization. We establish that CROSSGRAD's domain guided perturbations provide a more consistent generalization to new domains than label adversarial perturbation <ref type="bibr" target="#b6">(Goodfellow et al., 2014)</ref> which we denote by LABELGRAD. Also, we show that DANs, a popular domain adaptation method that suppresses domain signals, provides little improvement over the baseline <ref type="bibr" target="#b2">(Ganin et al., 2016;</ref><ref type="bibr" target="#b26">Tzeng et al., 2017)</ref>.</p><p>We describe the four different datasets and present a summary in <ref type="table" target="#tab_1">Table 3</ref>.</p><p>Character recognition across fonts. We created this dataset from Google Fonts 4 . The task is to identify the character across different fonts as the domain. The label set consists of twenty-six letters of the alphabet and ten numbers. The data comprises of 109 fonts which are partitioned as 65% train, 25% test and 10% validation folds. For each font and label, two to eighteen images are generated by randomly rotating the image around the center and adding pixel-level random noise.  The neural network is <ref type="bibr">LeNet (LeCun et al., 1998)</ref> modified to have three pooled convolution layers instead of two and ReLU activations instead of tanh.</p><p>Handwriting recognition across authors. We used the LipiTk dataset that comprises of handwritten characters from the Devanagari script 5 . Each writer is considered as a domain, and the task is to recognize the character. The images are split on writers as 60% train, 25% test and 15% validation. The neural network is the same as for the Fonts dataset above.</p><p>MNIST across synthetic domains. This dataset derived from MNIST was introduced by <ref type="bibr" target="#b3">Ghifary et al. (2015)</ref>. Here, labels comprise the 10 digits and domains are created by rotating the images in multiples of 15 degrees: 0, 15, 30, 45, 60 and 75. The domains are labeled with the angle by which they are rotated, e.g., M15, M30, M45. We tested on domain M15 while training on the rest. The network is the 2-layer convolutional one used by <ref type="bibr" target="#b19">Motiian et al. (2017)</ref>.</p><p>Spoken word recognition across users. We used the Google Speech Command Dataset 6 that consists of spoken word commands from several speakers in different acoustic settings. Spoken words are labels and speakers are domains. We used 20% of domains each for testing and validation.</p><p>The number of training domains was 100 for the experiments in <ref type="table" target="#tab_3">Table 4</ref>. We also report performance with varying numbers of domains later in <ref type="table" target="#tab_6">Table 8</ref>. We use the architecture of <ref type="bibr" target="#b22">Sainath &amp; Parada (2015)</ref> 7 .</p><p>For all experiments, the set of domains in the training, test, and validation sets were disjoint. We selected hyper-parameters based on accuracy on the validation set as follows. For LABELGRAD the parameter ? was chosen from {0.1, 0.25, 0.75, 0.5, 0.9} and for CROSSGRAD we chose ? l = ? d from the same set of values. We chose ranges so that L ? norm of the perturbations are of similar sizes in LABELGRAD and CROSSGRAD. The multiples in the range came from {0.5, 1, 2, 2.5}.</p><p>The optimizer for the first three datasets is RMS prop with a learning rate (?) of 0.02 whereas for the last Speech dataset it is SGD with ? = 0.001 initially and 0.0001 after 15 iterations. In CROSSGRAD networks, g is incorporated in the label classifier network by concatenating with the output from the last but two hidden layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">OVERALL COMPARISON</head><p>In <ref type="table" target="#tab_3">Table 4</ref> we compare CROSSGRAD with domain adversarial networks (DAN), label adversarial perturbation (LABELGRAD), and a baseline that performs no special training. For the MNIST dataset the baseline is CCSA <ref type="bibr" target="#b19">(Motiian et al., 2017)</ref> and D-MTAE <ref type="bibr" target="#b3">(Ghifary et al., 2015)</ref>. We observe that, for all four datasets, CROSSGRAD provides an accuracy improvement. DAN, which is designed specifically for domain adaptation, is worse than LABELGRAD, which does not exploit domain signal in any way. While the gap between LABELGRAD and CROSSGRAD is not dramatic, it is consistent as supported by this   (a) g of domain 45 lies between g of 60 and 30.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">WHY DOES CROSSGRAD WORK?</head><p>We present insights on the working of CROSSGRAD via experiments on the MNIST dataset where the domains corresponding to image rotations are easy to interpret.</p><p>In <ref type="figure" target="#fig_3">Figure 6a</ref> we show PCA projections of the g embeddings for images from three different domains, corresponding to rotations by 30, 45, 60 degrees in green, blue, and yellow respectively. The g embeddings of domain 45 (blue) lies in between the g of domains 30 (green) and 60 (yellow) showing that the domain classifier has successfully extracted continuous representation of the domain even when the input domain labels are categorical. <ref type="figure" target="#fig_3">Figure 6b</ref> shows the same pattern for domains 0, 15, 30. Here again we see that the embedding of domain 15 (blue) lies in-between that of domain 0 (yellow) and 30 (green).</p><p>Next, we show that the g perturbed along gradients of domain loss, does manage to generate images that substitute for the missing domains during training. For example, the embeddings of the domain 45, when perturbed, scatters towards the domain 30 and 60 as can be seen in <ref type="figure" target="#fig_3">Figure 6c</ref>: note the scatter of perturbed 45 (red) points inside the 30 (green) zone, without any 45 (blue) points. <ref type="figure" target="#fig_3">Figure 6d</ref> depicts a similar pattern with perturbed domain embedding points (red) scattering towards domains 30 and 0 more than unperturbed domain 15 (blue). For example, between x-axis -1 and 1 dominated by the green domain (domain 30) we see many more red points (perturbed domain 15) than blue points (domain 15). Similarly in the lower right corner of domain 0 shown in yellow. This highlights the mechanism of CROSSGRAD working; that it is able to augment training with samples closer to unobserved domains.</p><p>Finally, we observe in <ref type="figure">Figure 7</ref> that the embeddings are not correlated with labels. For both domains 30 and 45 the colors corresponding to different labels are not clustered. This is a consequence of CROSSGRAD's symmetric training of the domain classifier via label-loss perturbed images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">WHEN IS DOMAIN GENERALIZATION EFFECTIVE?</head><p>We next present a couple of experiments that provide insight into the settings in which CROSSGRAD is most effective.</p><p>First, we show the effect of increasing the number of training domains. Intuitively, we expect CROSSGRAD to be most useful when training domains are scarce and do not directly cover the test domains. We verified this on the speech dataset where the number of available domains is large. We varied the number of training domains while keeping the test and validation data fixed. <ref type="table" target="#tab_6">Table 8</ref> summarizes our results. Note that CROSSGRAD outperforms the baseline and LABELGRAD most significantly when the number of training domains is small (40). As the training data starts to cover more and more of the possible domain variations, the marginal improvement provided by CROSS-GRAD decreases. In fact, when the models are trained on the full training data (consisting of more than 1000 domains), the baseline achieves an accuracy of 88.3%, and both CROSSGRAD and LA-BELGRAD provide no gains 8 beyond that. DAN, like in other datasets, provides unstable gains and is difficult to tune. LABELGRAD shows smaller relative gains than CROSSGRAD but follows the same trend of reducing gains with increasing number of domains.</p><p>In general, how CROSSGRAD handles multidimensional, non-linear involvement of g in determining x is difficult to diagnose. To initiate a basic understanding of how data augmentation supplies CROSSGRAD with hallucinated domains, we considered a restricted situation where the discrete   We conducted leave-one-domain-out experiments by picking one domain as the test domain, and providing the others as training domains. In <ref type="table" target="#tab_7">Table 9</ref> we compare the accuracy of different methods. We also compare against the numbers reported by the CCSA method of domain generalization <ref type="bibr" target="#b19">(Motiian et al., 2017)</ref> as reported by the authors.</p><p>It becomes immediately obvious from <ref type="table" target="#tab_7">Table 9</ref> that CROSSGRAD is beaten in only two cases: M0 and M75, which are the two extreme rotation angles. For angles in the middle, CROSSGRAD is able to interpolate the necessary domain representation g via 'hallucination' from other training domains. Recall from <ref type="figure" target="#fig_3">Figures 6c and 6d</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>Domain d and label y interact in complicated ways to influence the observable input x. Most domain adaption strategies implicitly consider the domain signal to be extraneous and seek to remove its effect to train more robust label predictors. We presented CROSSGRAD, which considers them in a more symmetric manner. CROSSGRAD provides a new data augmentation scheme based on the y (respectively, d) predictor using the gradient of the d (respectively, y) predictor over the input space, to generate perturbations. Experiments comparing CROSSGRAD with various recent adversarial paradigms show that CROSSGRAD can make better use of partially correlated y and d, without requiring explicit distributional assumptions about how they affect x. CROSSGRAD is at its best when training domains are scarce and do not directly cover test domains well. Future work includes extending CROSSGRAD to exploit labeled or unlabeled data in the test domain, and integrating the best of LABELGRAD and CROSSGRAD into a single algorithm.</p><p>Hence, the initial gradient descent step to affect a change of ?? in the domain features would increment x by J ??. The Jacobian, which is a matrix of first partial derivatives, can be computed by back-propagation. Thus we get</p><formula xml:id="formula_8">?x = J ??J d (?, d) = i ?? i ?x ?J d (?, d) ?? i ,</formula><p>which, by the chain rule, gives ?x = ? x J d (x, d).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>. Variables y ? Y and d ? D are discrete and g ? R q , x ? R r lie in continuous multi-dimensional spaces. The domain d induces a set of latent domain features g. The input x is Bayesian network to model dependence between label y, domain d, and input x.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>2: CROSSGRAD network design.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>g of domain 15 lies between g of 0 and 30. Adding g of perturbed domain 15 to above.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Comparing domain embeddings (g) across domains. Each color denotes a domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Comparing domain embeddings (g) across labels. Each color denotes a label. Unclustered colors indicates that label information is mostly absent from g.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Summary of datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>table and other experiments that we later describe.</figDesc><table><row><cell cols="5">Method Name Fonts Handwriting MNIST Speech</cell></row><row><cell>Baseline</cell><cell>68.5</cell><cell>82.5</cell><cell>95.6</cell><cell>72.6</cell></row><row><cell>DAN</cell><cell>68.9</cell><cell>83.8</cell><cell>98.0</cell><cell>70.4</cell></row><row><cell>LABELGRAD</cell><cell>71.4</cell><cell>86.3</cell><cell>97.8</cell><cell>72.7</cell></row><row><cell>CROSSGRAD</cell><cell>72.6</cell><cell>88.6</cell><cell>98.6</cell><cell>73.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Accuracy on four different datasets. The baseline for MNIST is CCSA.Changing model architecture. In order to make sure that these observed trends hold across model architectures, we compare different methods with the model changed to a 2-block ResNet<ref type="bibr" target="#b8">(He et al., 2016)</ref> instead ofLeNet (LeCun et al., 1998)  for the Fonts and Handwriting dataset inTable 5. For both datasets the ResNet model is significantly better than the LeNet model. But even for the higher capacity ResNet model, CROSSGRAD surpasses the baseline accuracy as well as other methods like LABELGRAD .</figDesc><table><row><cell></cell><cell>Fonts</cell><cell></cell><cell cols="2">Handwriting</cell></row><row><cell cols="5">Method Name LeNet ResNet LeNet ResNet</cell></row><row><cell>Baseline</cell><cell>68.5</cell><cell>80.2</cell><cell>82.5</cell><cell>91.5</cell></row><row><cell>DAN</cell><cell>68.9</cell><cell>81.1</cell><cell>83.8</cell><cell>88.5</cell></row><row><cell>LABELGRAD</cell><cell>71.4</cell><cell>80.5</cell><cell>86.3</cell><cell>91.8</cell></row><row><cell>CROSSGRAD</cell><cell>72.6</cell><cell>82.4</cell><cell>88.6</cell><cell>92.1</cell></row></table><note>5 http://lipitk.sourceforge.net/hpl-datasets.htm6 https://research.googleblog.com/2017/08/launching-speech-commands-dataset. html7 https://www.tensorflow.org/versions/master/tutorials/audio_recognition</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Accuracy with varying model architectures.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Domain 30, 45, 60</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>30 45 60</cell></row><row><cell>5</cell><cell>4</cell><cell>3</cell><cell>2</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8 :</head><label>8</label><figDesc>Accuracy on Google Speech Command Task. For each method we show the relative improvement (positive or negative) over the baseline.</figDesc><table><row><cell cols="2">domain is secretly a continuous 1-d space, namely, the angle of rotation in MNIST. In this setting,</cell></row><row><cell cols="2">a natural question is, given a set of training domains (angles), which test domains (angles) perform</cell></row><row><cell>well under CROSSGRAD?</cell><cell></cell></row><row><cell>Test domains ? CCSA</cell><cell>M0 M15 M30 M45 M60 M75 84.6 95.6 94.6 82.9 94.8 82.1</cell></row><row><cell>D-MTAE</cell><cell>82.5 96.3 93.4 78.6 94.2 80.5</cell></row><row><cell>LABELGRAD</cell><cell>89.7 97.8 98.0 97.1 96.6 92.1</cell></row><row><cell>DAN</cell><cell>86.7 98.0 97.8 97.4 96.9 89.1</cell></row><row><cell>CROSSGRAD</cell><cell>88.3 98.6 98.0 97.7 97.7 91.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9 :</head><label>9</label><figDesc>Accuracy on rotated MNIST.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>that the perturbed g during training covers for the missing test domains. In contrast, when M0 or M75 are in the test set, CROSSGRAD's domain loss gradient does not point in the direction of domains outside the training domains. If and how this insight might generalize to more dimensions or truly categorical domains is left as an open question.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The dependence of y on x could also be via continuous hidden variables but our model for domain generalization is agnostic of such structure.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We use ?x i J d as shorthand for the gradient ?xJ d evaluated at xi.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://fonts.google.com/?category=Handwriting&amp;subset=latin</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">The gap in accuracy between the baseline and CROSSGRAD for the case of 1000 domains is not statistically significant according to the MAPSSWE test<ref type="bibr" target="#b4">(Gillick &amp; Cox, 1989)</ref>.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGEMENTS</head><p>We gratefully acknowledge the support of NVIDIA Corporation with the donation of Titan X GPUs used for this research. We thank Google for supporting travel to the conference venue.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>Relating the "natural" perturbations of x and?. In Section 3, we claimed that the intuitive perturbation ? xi J d (x i , d i ) of x i attempts to induce the intuitive perturbation ?? i J d (x i , d i ) of? i , even though the exact relation between a perturbation of x i and that of? i requires the metric tensor transpose JJ . We will now prove this assertion. Of course, an isometric map G : x ? g, with an orthogonal Jacobian (J ?1 = J ), trivially has this property, but we present an alternative derivation which may give further insight into the interaction between the perturbations in the general case.</p><p>Consider perturbing? i to produce g i =? i + ?? i J d (x i , d i ). This yields a new augmented input instance x i as</p><p>We show next that the perturbed x i can be approximated by</p><p>In this proof we drop the subscript i for ease of notation. In the forward direction, the relationship between ?x and ?? can be expressed using the Jacobian J of? w.r.t. x:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?? = J?x</head><p>To invert the relationship for a non-square and possibly low-rank Jacobian, we use the Jacobian transpose method devised for inverse kinematics <ref type="bibr" target="#b0">(Balestrino et al., 1984;</ref><ref type="bibr" target="#b28">Wolovich &amp; Elliott, 1984)</ref>. Specifically, we write ?? =?(x ) ??(x), and recast the problem as trying to minimize the squared L2 error</p><p>L?(x) = 1 2 (?(x ) ??(x)) (?(x ) ??(x)) with gradient descent. The gradient of the above expression w.r.t. x is</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Robust control of robotic manipulators. IFAC Proceedings Volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Balestrino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">De</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sciavicco</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="2435" to="2440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning attributes equals multi-source domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="87" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno>17:59:1-59:35</idno>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Domain generalization for object recognition with multi-task autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bastiaan Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2551" to="2559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Some statistical issues in the comparison of speech recognition algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="1989" />
			<biblScope unit="page" from="532" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Geodesic flow kernel for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2066" to="2073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Domain adaptation for object recognition: An unsupervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ruonan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chellappa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="999" to="1006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Arbitrary style transfer in real-time with adaptive instance normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<idno>abs/1703.06868</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Frustratingly easy domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daum?</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="256" to="263" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Co-regularization based semi-supervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daum?</surname><genName>III</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="478" to="486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Instance weighting for domain adaptation in NLP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="264" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Undoing the damage of dataset bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="158" to="171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Zero-shot deep domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuan-Chuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ziyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ernst</surname></persName>
		</author>
		<idno>abs/1707.01922</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Curve style analysis in a set of shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Domain adaptation with multiple sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rostamizadeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1041" to="1048" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Virtual adversarial training for semi-supervised text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno>abs/1605.07725</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5715" to="5725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Domain generalization via invariant feature representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muandet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schlkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Adapting visual category models to new domains. ECCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for small-footprint keyword spotting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Parada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1478" to="1482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Speaker adaptation of neural network acoustic models using i-vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Saon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Soltau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nahamoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Picheny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ASRU</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="55" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6199</idno>
		<title level="m">Intriguing properties of neural networks</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4068" to="4076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adversarial discriminative domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2962" to="2971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">From A to Z: supervised transfer of style and content using deep neural network generators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Upchurch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bala</surname></persName>
		</author>
		<idno>abs/1603.02003</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A computational technique for inverse kinematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Wolovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Elliott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Decision and Control</title>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="page" from="1359" to="1363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Speaker adaptation for continuous density HMMs: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Woodland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ITRW</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="11" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Exploiting low-rank structure from latent domains for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="628" to="643" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A unified perspective on multi-domain and multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multivariate regression on the Grassmannian for predicting novel domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5071" to="5080" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multi-source domain adaptation: A causal view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3150" to="3157" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
