<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Remember Intentions: Retrospective-Memory-based Trajectory Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxin</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weibo</forename><surname>Mao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zhang</surname></persName>
							<email>zhangwenjun@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siheng</forename><surname>Chen</surname></persName>
							<email>sihengc@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shanghai AI Laboratory</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Remember Intentions: Retrospective-Memory-based Trajectory Prediction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To realize trajectory prediction, most previous methods adopt the parameter-based approach, which encodes all the seen past-future instance pairs into model parameters. However, in this way, the model parameters come from all seen instances, which means a huge amount of irrelevant seen instances might also involve in predicting the current situation, disturbing the performance. To provide a more explicit link between the current situation and the seen instances, we imitate the mechanism of retrospective memory in neuropsychology and propose MemoNet, an instance-based approach that predicts the movement intentions of agents by looking for similar scenarios in the training data. In MemoNet, we design a pair of memory banks to explicitly store representative instances in the training set, acting as prefrontal cortex in the neural system, and a trainable memory addresser to adaptively search a current situation with similar instances in the memory bank, acting like basal ganglia. During prediction, MemoNet recalls previous memory by using the memory addresser to index related instances in the memory bank. We further propose a two-step trajectory prediction system, where the first step is to leverage Memo-Net to predict the destination and the second step is to fulfill the whole trajectory according to the predicted destinations. Experiments show that the proposed MemoNet improves the FDE by 20.3%/10.2%/28.3% from the previous best method on SDD/ETH-UCY/NBA datasets. Experiments also show that our MemoNet has the ability to trace back to specific instances during prediction, promoting more interpretability.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Trajectory prediction aims to predict the future movements for one or multiple interacting agents given the past trajectories. On the one hand, this task has broad practical applications to autonomous driving <ref type="bibr" target="#b23">[24]</ref>, drones <ref type="bibr" target="#b5">[6]</ref>, surveillance systems <ref type="bibr" target="#b42">[42]</ref> and interactive robotics <ref type="bibr" target="#b17">[18]</ref>; on the other hand, this is a fundamental scientific question about linking <ref type="bibr">Figure 1</ref>. MemoNet mimics retrospective memory process. We use the memory bank to explicitly store representative instances, acting like prefrontal cortex; and the memory addresser to search similar memory instances with current situation, acting like basal ganglia. the past to the future. The overall strategy is to summarize useful experiences from a large amount of seen past-future pairs and then leverage those experiences to predict possible future intentions for the current situation.</p><p>To obtain useful experiences, previous works consider a parameter-based approach, which uses training data to optimize model parameters. In this way, all the experiences are implicitly summarized and stored in a model as a whole during the optimization process. For example, <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b46">46]</ref> use encoder-decoder architectures and <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15]</ref> consider generator-discriminator architectures to regress future trajectory predictions. <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b47">47]</ref> use conditional variational autoencoders to sample multiple future trajectory embedding from latent distributions. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b26">26]</ref> rely on a bivariate Gaussian Mixture Model to output position distributions. However, the parameter-based approach is not optimal for two reasons. First, it lacks interpretability because all model parameters do not have clear semantic meaning in the physical world. This is critical in safety-sensitive applications, such as autonomous driving. Second, since the model parameters are trained from all seen instances, a huge amount of irrelevant seen past-future pairs might also involve in predicting the current situation, disturbing the performance.</p><p>To promote more interpretability and provide a more explicit link between the current situation and the seen instances, we propose MemoNet whose working mechanism is inspired by human's retrospective memory in neuropsychology <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b8">9]</ref>, the process that human learns intended future actions by recalling information learned before. The proposed MemoNet achieves the intention prediction by searching for similar instances stored during training. In MemoNet, we use a pair of past and intention memory banks to store the features of past-future instance pairs and a memory addresser to search relevant instances with the new prediction case in the memory bank. The memory bank simulates the prefrontal cortex in the neural system, which records the human reaction when performing a task. The memory addresser simulates the basal ganglia in the neural system, which activates the related memory records in the prefrontal cortex. <ref type="figure">Fig.1</ref> shows an analogy between the retrospective memory process and our MemoNet process.</p><p>The proposed MemoNet includes four key designs. First, we propose a joint-reconstruction-based feature-learning architecture to initialize the pair of past and intention memory banks. The architecture contains two encoders and follows a joint-reconstruction structure to obtain compatible past trajectory and future intention features. Second, we propose a memory filter algorithm to erase the redundant memory instances in the memory banks. The filter algorithm is trainingfree and invariant to the permutation of training samples, providing high efficiency and robustness for the memory banks. Third, we propose a trainable memory addresser to search similar memory instances. The addresser contains a learnable attention network to compute similarity scores. To train such an addresser, we propose a pseudo-label generation to guide the addresser to correctly search most similar memory instances. Fourth, we propose an intention clustering to produce diverse intention predictions. Through the clustering algorithm, intentions with low-frequency occurrences are captured to promote the prediction diversity and intentions with high-frequency occurrences are merged to improve the prediction robustness.</p><p>We build a two-step trajectory prediction system, where the first step is to leverage MemoNet to predict the intentions and the second step is to fulfill the whole trajectory according to the predicted intentions. Note that MemoNet only predicts the destination to represent the intention because the destination carries most of the modality information in a trajectory. This two-step prediction disassembles a complex problem into two relatively simple problems, promoting a more accurate prediction. To evaluate the effectiveness of our method, we conduct experiments on three datasets: Stanford Drones (SDD), ETH-UCY and NBA. The quantitative result shows we outperform the previous state-of-theart method 20.3%/10.2%/28.3% on FDE representing we achieve an accurate intention prediction with the MemoNet. The qualitative results also reflect that our MemoNet has the ability to trace back to specific memorized samples during the prediction, promoting more interpretability.</p><p>The main contributions of this paper are: ? We propose MemoNet, a novel instance-based framework to achieve future intention prediction. The working mechanism of MemoNet is based on a more explicit link between the current situation and seen instances, imitating retrospective memory studied in neuropsychology.</p><p>? We propose four novel designs in MemoNet, including 1) reconstruction-based feature-learning architecture, which initializes the memory banks, 2) memory filtering, which reduces the redundancy in memory banks, 3) memory addresser, which searches similar memory instances with the incoming prediction case in memory banks, and 4) intention clustering, which promotes prediction diversity.</p><p>? We conduct experiments to evaluate our method on several real-world datasets. Our approach achieves the stateof-the-art on well-established pedestrian trajectory prediction datasets by reducing the FDE 20.3%/10.2%/28.3% on SDD/ETH-UCY/NBA datasets. Our approach also equips with the ability to trace back to specific memorized instances during the prediction, promoting more interpretability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Trajectory prediction. Early work on trajectory prediction adopts a deterministic approach using models such as social forces <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b34">34]</ref>, Markov process <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b44">44]</ref>, and RNNs <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b43">43]</ref>. Recently, researchers begin to propose frameworks to predict multi-model trajectories, which can be mainly categorized into two types: regression, generation. Regression frameworks mainly utilize encode-decode structures <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b46">46]</ref>, or reinforcement learning-based structure <ref type="bibr" target="#b24">[25]</ref>, or generator-discriminator structures <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15]</ref> with adding noise <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b46">46]</ref>, using random initialization <ref type="bibr" target="#b28">[28]</ref>, or using multi-head output <ref type="bibr" target="#b29">[29,</ref><ref type="bibr" target="#b41">41]</ref> to regress multiple future trajectories. Generation frameworks estimate the distribution of future trajectory or its embedding with deep generative models <ref type="bibr" target="#b18">[19]</ref>. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b26">26]</ref> utilize a Gaussian mixture distribution to model the future trajectory distribution and the model estimates its mean and covariance. The mainly used framework is conditional variational autoencoders <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b38">38,</ref><ref type="bibr" target="#b47">47]</ref>, which achieve the prediction by estimating the parameters of an intermediate distribution and sampling future trajectory features from such a distribution.</p><p>Both the regression and generation frameworks are parameter-based, utilizing training data to optimize model parameters. In such frameworks, learned experience is a hidden representation stored implicitly in model parameters as a whole, lacking the ability to address an individual instance of experience. In this work, we propose a new instance-based framework based on retrospective memory which memorizes various past trajectories and corresponding intentions. In predicting, the framework recalls similar previous memory instances for guiding future prediction. Compared with previous methods, our method provides a more explicit link between the current prediction and seen data, which promotes more interpretability and higher performance.</p><p>Memory Networks. The first proposed memory network is called Neural Turing Machines (NTM) <ref type="bibr" target="#b10">[11]</ref> which is analogous to a Von Neumann architecture consisting of a neural network controller and a memory bank. The NTM architecture is extended in meta-learning <ref type="bibr" target="#b39">[39]</ref> which implements a Least Recently Used memory access strategy to make predictions using few samples. <ref type="bibr" target="#b11">[12]</ref> proposes a differentiable neural computer that can read from and write to an external memory matrix. Memory network is also proved its effectiveness on question-answering tasks <ref type="bibr" target="#b45">[45]</ref> where the model stores the question-answering pair into a long-term memory as a knowledge base and outputs a textual response. <ref type="bibr" target="#b40">[40]</ref> proposes an end-to-end memory network for question-answering with a recurrent attention model in which the recurrence reads from a large external memory. <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b30">30]</ref> apply memory networks further into visual question-answering tasks <ref type="bibr" target="#b1">[2]</ref>. <ref type="bibr" target="#b31">[31]</ref> applies a generative memory for continual trajectory prediction.</p><p>A close related work with ours is <ref type="bibr" target="#b33">[33]</ref>, which leverages the memory mechanism to achieve single-agent trajectory prediction. However, the differences include four aspects: i) the previous work only considers single-agent trajectory prediction; while the proposed MemoNet is able to handle multi-agent trajectory prediction with social influence; ii) the memory bank in the previous work stores the entire trajectories; while MemoNet focuses on intention, which is more efficient in memorizing possible movement patterns; iii) the previous work uses fixed cosine similarity to search related memories; while MemoNet uses a trainable addresser to learn a similarity metric, leading to better memory searching; and iv) the previous work is hard to both ensure diversity and preserve precision while MemoNet adopts intention clustering to promote multi-modality prediction with robustness. Overall, the proposed MemoNet outperforms [33] by 28.7%/46.2% in FDE on SDD/ETH-UCY datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Problem Formulation</head><p>Trajectory prediction is to predict an agent's future trajectory from its past trajectory and neighboring agents' past trajectories. Mathematically, for a to-be-predicted agent, let x t ? R 2 be its spatial coordinate at timestamp t and X = [x ?Tp+1 , x ?Tp+2 , ? ? ? , x 0 ] ? R Tp?2 be its past trajectory over T p timestamps. Let N be the neighbouring agent set and X N = [X N1 , X N2 , ? ? ? , X N N ] ? R N ?Tp?2 be the past trajectories of neighbours, where X N ? ? R Tp?2 is the trajectory of the ?th neighbour. The future trajectory of the to-be-predicted agent is</p><formula xml:id="formula_0">Y = [y 1 , y 2 , ? ? ? , y T f ] ? R T f ?2</formula><p>where y t ? R 2 is the spatial coordinate of at future timestamp t. The overall goal is to train a prediction model g(?), so that the predicted future trajectory Y = g(X, X N ) is as close to the ground-truth Y as possible.</p><p>To reach this goal, we consider a two-step strategy, where we first predict the agent's intention and then fulfill the complete trajectory based on the predicted intention. The intuition behind is to disassemble a complex problem into two relatively simple problems, promoting a more accurate prediction. Here we represent the agent's intention by its destination as the destination could reflect most of the movement patterns. Mathematically, we target to learn an intention prediction model g int (?) that predicts a intention y T f = g int (X, X N ). We next target to train the trajectory fulfilling model g full (?) based on the predicted intention Y = g full (X, X N , y T f ). In this spirit, we propose Memo-Net for intention prediction; see Sec.4; we then build the overall prediction model based on MemoNet; see Sec.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">MemoNet: Intention Prediction</head><p>MemoNet exploits retrospective memory from similar scenarios of previous experience to obtain the possible multimodal future movement intentions. The core of MemoNet is to store representative instances in the memory bank and then use a memory addresser to search relevant seen instances with the current situation in the memory bank. Sec. 4.1 proposes the memory bank and Sec. 4.2 proposes the memory addresser. To enable diverse intention prediction, we propose intention clustering in Sec. 4.3. Finally, we summarize the inference process of MemoNet in Sec. 4.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Memory bank</head><p>Memory bank initialization. We consider a pair of correlated memory banks: a past memory bank and an intention memory bank. The past memory bank stores a set of past trajectory features and the intention memory bank stores a set of corresponding future intention features. They together associate the past with the future. Mathematically, let M past = {k i |i = 1, 2, ? ? ? , M } be the past memory bank, where k i is the instance at the ith memory address, recording the features extracted from the past trajectory with social influence in the ith training sample. Correspondingly, M int = {v i |i = 1, 2, ? ? ? , M } be the intention memory bank, where v i is the instance at the ith address, recording the features extracted from the future intention (destination) in the ith training sample. Both the past and the intention memory banks share the same size M .</p><p>To obtain the features in the memory bank pair k i , v i , we propose a joint-reconstruction-based feature learning architecture; see <ref type="figure">Fig 3(a)</ref>. The social encoder extracts the past feature with social influence of the past trajectory. The intention encoder extract the intention feature from the future intention (destination). The decoder receives the concatenated past-and-intention features and reconstructs the past trajectory and the future intention jointly. Mathematically, let E social (?) and E int (?) be the social encoder and intention encoder, D(?) be the decoder, given an agent's trajectory X, its neighbouring agents' trajectories X N , and its future  <ref type="figure">Figure 2</ref>. Inference phase of MemoNet. The red agent is to-be-predicted and the blue/orange agents are neighbours. According to the past feature obtained by the social encoder, we address related memory instances in the past memory bank through an attention network, producing similarity scores. The intention memory bank outputs future intention features for decoding coarse intention anchors according to the memory addresses with top similarity scores. At last, we utilize a clustering algorithm to obtain diverse and robust intention predictions.</p><p>intention y T f , the joint-reconstruction process is:</p><formula xml:id="formula_1">k = E social (X, X N ), v = E int (y T f ), X, y T f = D([k; v]),</formula><p>where [?; ?] represents the concatenate operation and X, y T f denote the reconstructed past trajectory and future intention.</p><p>To optimize the feature learning architecture, we use a joint-reconstruction loss function:</p><formula xml:id="formula_2">L rec = ? X ? X? 2 2 + ? y T f ? y T f 2 2 ,</formula><p>where ? is a weight hyperparameter. Through the proposed feature learning architecture, we obtain respective feature of the past and the intention. Their features are compatible because of the joint-reconstruction process.</p><p>Once we finish the feature learning architecture, we fix the past and the intention encoders and enumerate over all the past-intention samples in training data to initialize the past memory bank M int . Specifically, for the ith past/intention sample, we use the social encoder/intention encoder to get the past feature k i /intention feature v i storing at the ith address of the past/intention memory bank; see <ref type="figure">Fig.3(b)</ref>.</p><p>Memory bank filtering. When we write all the past and intention features into the memory bank pair, many instances could be redundant, which wastes the storage. We thus propose a filtering algorithm to erase redundant memory instances and preserve representative memory instances.</p><p>For features k i ,v i at ith address in initial memory bank pair M  for all address j in current Mpast,Mpast 5:</p><formula xml:id="formula_3">? 2 ? ? past , ?y T f i ?y T f j ? 2 ? ? int ,<label>(</label></formula><p>if Eq.(1) not satisfied for all addresses j then 6:</p><p>Add ki,vi into Mpast,Mint 7:</p><p>Delete ki,vi from M where ? past and ? int are two thresholds for tuning. We use this rule to filter the past and the intention memory bank; see Algorithm 1. Briefly, ? past /? int will control the memory size of the final past/intention memory banks.</p><p>Compared to previous method that uses a controller to reduce redundancy <ref type="bibr" target="#b33">[33]</ref>, our filtering has two advantages. First, our memory bank is invariant to the permutation of training samples; while in the previous method, various orderings of training samples would cause unstable memory banks. Second, our memory filter is training-free, which is more efficient; while the previous method needs to train the controller for multiple epochs.</p><p>Relations to previous methods. The proposed memory bank is similar to dictionary learning as both aim to infer a few representatives from input data to approximate incoming data, but differences include: i) a dictionary usually requires a fixed and predefine size; while the size of a memory bank is flexible and adaptive to the complexity of input data; ii) to make a prediction, the dictionary usually combines several atoms by weighted averaging; while the memory bank directly searches a single memory instance that allows an explicit link between the inference data and the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Memory addresser</head><p>The functionality of a memory addresser is to search the addresses of similar past memory instances in the memory </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Past Trajectory</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initial Past Memory Bank</head><p>Intention Encoder Social Encoder (b) Initialization process via enumerating past-intention samples. <ref type="figure">Figure 3</ref>. Memory bank initialization. We train a feature learning architecture by a joint-reconstruction process and initialize the memory bank by enumerating all past-intention samples using two encoders.</p><p>. . .  bank for an input past trajectory feature. The key is to find an appropriate similarity metric. The previous memory addressing mechanisms leverage the cosine distance between two features as the similarity metric <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b33">33]</ref>. However, any pre-defined function, including the cosine distance, might not be capable of fully reflecting the similarity between two feature vectors. To solve this issue, we propose a trainable addresser, which contains a shallow attention network to learn a similarity metric. Mathematically, given the input past feature q and the past memory bank M past = {k i |i = 1, 2, ? ? ? , |M|}, we calculate the similarity scores across all the memory instances, which is formulated as:</p><formula xml:id="formula_4">s i = F ATT (q, k i ) = F q (q)F T k (k i ) ?F q (q)? 2 ?F k (k i )? 2 , i = 1, 2, ? ? ? , M,</formula><p>where F q (?) and F k (?) are two individual MLPs that transform features to a space for more appropriate distance measuring, s i is the similarity score between the input feature and the ith memory instance. We then select the largest similarity scores and return their memory addresses.</p><p>To train such an addresser, we need to determine the "ground-truth" similarity score. Intuitively, the similarity score measured in the feature space should reflect the prediction error in the physical space. We thus consider a pseudo label which is related to the relative distance between the ground-truth intention of the input and the predicted inten-tions. Mathematically, let y T f be the ground-truth intention of the input trajectory and y</p><formula xml:id="formula_5">T f i = D([k i ; v i ])</formula><p>be the predicted intention of the ith memory instance produced by the aforementioned intention decoder D(?). The pseudo label the ith memory instance is defined as</p><formula xml:id="formula_6">max(0, dT?di dT ) ? [0, 1], where d i = ?y T f ? y T f i ? 2</formula><p>is the relative distance between two intentions and d T is a distance threshold. Based on this pseudo label, we train the addresser with the following loss:</p><formula xml:id="formula_7">L Addr = M i=1 (s i ? max(0, d T ? d i d T )) 2 ;</formula><p>see the training process of a memory addresser in <ref type="figure" target="#fig_6">Figure 4</ref>. <ref type="figure">Fig. 5(a)</ref> illustrates a scenario that the top few searched memory instances might fall into the same modality and cannot provide sufficient diversity. The reason is that the memory bank might recall numerous seen instances like the agent will move straight in various ways, but miss other movement modalities, such as sharp left turn or right turn. Note that although simply using memory bank filtering with a large ? past /? int could promote diversity, it would remove too many memory instances and make it harder to search relevant memory instances, deteriorating the performance. To achieve a diverse prediction preserving precision, we propose an intention clustering method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Intention diversity</head><p>Suppose that we need to predict K possible trajectories. Here we first find L (L ? K) memory instances based on the L largest similarity scores and then decode them into L intentions, which are called coarse intention anchors. We then use K-means clustering method to produce K possible intentions from the L coarse intention anchors. On one hand, since L ? K, the coarse intention anchors are more likely to capture more agents' movement patterns and the clustering operation is capable to preserves these patterns to produce a more diverse prediction. On the other hand, intention clustering preserves the enrichment of the memory bank and considers multiple memory instances to cluster a predicted intention, leading to a more precise and confident intention prediction, see the example in <ref type="figure">Fig.5(b)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Inference Phase</head><p>During inference, MemoNet involves four steps to obtain possible future intentions: past trajectory encoding, memory addressing, intention decoding and intention clustering; see <ref type="figure">Fig.2</ref>. First, we input the past trajectory and its neighbouring past trajectories to the social encoder E social (?) to obtain the past trajectory feature. Second, we search L most related memory instances in the past memory bank through the proposed memory addresser and return their addresses. According to the memory addresses, the intention memory bank outputs L corresponding future intention features. Third, the decoder D(?) decodes each of L intention features into L intention anchors. Fourth, we use the proposed clustering algorithm to refine L intention anchors to K final intentions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Trajectory prediction system</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Trajectory fulfilling</head><p>After obtaining an agent's trajectory intentions (destinations), we fulfill the whole trajectory through an encodingdecoding process conditioned on predicted intentions; see <ref type="figure">Fig.6</ref>. Mathematically, given a predicted intention y T f of the agent's past trajectory X with its neighbours' past trajectories X N , the trajectory fulfilling process is:</p><formula xml:id="formula_8">h x = E full (X, X N ), h ? x = [h x ; F d ( y T f )], Y, X full = D full (h ? x )</formula><p>, where E full (?) and D full (?) represent the trajectory fulfillment encoder and decoder, which share a same structure with E social (?) and D(?), respectively. We concatenate the trajectory feature h x with intention feature encoded by a MLP function F d (?) for whole trajectory Y decoding. To keep most past information, the fulfillment decoder also aim to reconstruct the past trajectory X full . To train the fulfillment encoder and decoder, we use the ? 2 loss:</p><formula xml:id="formula_9">L traj = ? X full ? X? 2 2 + ?? Y ? Y? 2 2 ,</formula><p>where ? is a weight hyperparamter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Overall training pipeline</head><p>To train the overall system with MemoNet, we design the following training pipeline:</p><p>1. Train two encoders E social (?), E int (?) and the decoder D(?) using the feature learning architecture with the jointreconstruction loss L rec .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MemoNet</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Past Trajectory</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fulfillment Decoder</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fulfillment Encoder</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predicted Trajectories</head><p>Predicted Intentions <ref type="figure">Figure 6</ref>. The inference of trajectory prediction system with Mem-oNet. The red color represents the to-be-predict agent and the blue/red color represent neighbours. We fulfill the whole trajectory conditioned on the prediction intentions from MemoNet.</p><p>2. Freeze two encoders E social (?), E int (?). Create the pair of initial past and intention memory banks M  3. Freeze the memory banks M past , M int , the past trajectory encoders E social (?), E int (?) and the decoder D(?). Train the memory addresser with the loss L Addr .</p><p>4. Freeze the MemoNet and train the trajectory fulfillment encoder E full (?) and decoder D full (?) with the loss L traj .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Datasets</head><p>Stanford Drone Dataset (SDD): SDD is a large-scale dataset collected from campus in bird's eye view. Following <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b32">32]</ref>, we use the standard train-test split and predict the future 4.8s (12 frames) using past 3.2s (8 frames).</p><p>ETH-UCY: The ETH-UCY dataset contains 5 subsets, including ETH, HOTEL, UNIV, ZARA1 and ZARA2 containing various scenes captured at 2.5Hz. We use the same segment length of 8s as SDD following previous works <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">32]</ref> and use the leave-one-out approach with 4 sets for training and the remaining set for testing.</p><p>NBA: The NBA trajectory dataset is collected by NBA using the SportVU tracking system, which reports the trajectories of the ten players and the ball in real basketball games. We randomly sample 50k samples for training and testing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Implementation details</head><p>For MemoNet, the feature dimensions of the past memory bank and the intention memory bank are 128 and 64, respectively. On SDD, we filter the initial memory banks with ? past = 1, ? int = 1 and the coarse intention anchor number L is 120. On ETH-UCY, we filter the initial memory banks with ? past = 0.02, ? int = 0.02 and the coarse intention anchor number L is 320. The coefficients ? and ? in loss functions are set to 1. We train the entire framework with SGD optimizer <ref type="bibr" target="#b4">[5]</ref>. We use an initial learning rate of 10 ?3 to train the feature learning framework, 10 ?4 to train the memory addresser, and 10 ?3 to train the trajectory fulfillment. All these modules are finetuned with a learning rate of 10 ?6 . See more details in the supplementary material.  <ref type="table">Table 3</ref>. minADE20 / minFDE20 (meters) of trajectory prediction (NBA dataset). Lower is better. The bold/underlined font represent the best/second best result. Our method achieves a 28.3% FDE improvement compared to NMMP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Social-LSTM [1]</head><p>Social-GAN <ref type="bibr" target="#b12">[13]</ref> Social-STGCNN <ref type="bibr" target="#b35">[35]</ref> STGAT <ref type="bibr" target="#b15">[16]</ref> NRI <ref type="bibr" target="#b19">[20]</ref> STAR <ref type="bibr" target="#b46">[46]</ref> PECNet <ref type="bibr" target="#b32">[32]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Quantitative results</head><p>Two used evaluation metrics are the minimum average displacement error (minADE K ), which is the minimum among K time-averaged distances of predicted trajectories compared to the ground-truths, and the minimum final displacement error (minFDE K ), which is the minimum distance among K predicted endpoints to the ground-truth endpoints.</p><p>On SDD dataset, we compare our method with current 9 state-of-the-art prediction methods; see <ref type="table" target="#tab_1">Table 1</ref>. We see that i) our MemoNet significantly outperforms all baselines in intention prediction measured by FDE. Our method reduces FDE from 15.88 to 12.66 compared to the current state-ofthe-art method, PECNet, achieving 20.3% improvement; ii) with a more precise intention prediction, our method predicts the whole trajectory more accurately. Our method outperforms PECNet by 14.1% in ADE.</p><p>On ETH-UCY dataset, we compare our method with 9 prediction methods; see <ref type="table">Table 2</ref>. We see that i) MemoNet outperforms competitive methods in predicting intention measured by FDE. Specifically, our method reduces the average FDE from 0.39 to 0.35 compared to the previous state-of-the-art method, AgentFormer, achieving 10.2% improvement; and ii) our method achieves the best or close to the best performance in ADE over all the five subsets.</p><p>On NBA dataset, we compare our proposed method with 8 prediction methods; see <ref type="table">Table 3</ref>. We see that MemoNet reduces FDE from 2.05 to 1.47 compare to the current stateof-the-art method, NMMP, achieving 28.3% improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Qualitative results</head><p>Visualization of diverse intention. <ref type="figure" target="#fig_10">Fig.7</ref> illustrates the diverse intention prediction with MemoNet, where the pink dots are coarse intention anchors. We see that with the help</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Past Trajectory Coarse Intention Anchor</head><p>Our Prediction Ground-Truth of intention clustering, MemoNet can provide diverse and accurate intention predictions. Visualization of predicted trajectory. <ref type="figure">Fig.8</ref> compares the best-of-20 predicted trajectories produced by our Mem-oNet and previous state-of-the-art method PECNet and MANTRA. We see that our predictions (red) are closer to the ground-truth (green) than other two methods. Especially, for challenging direction-turning cases (third column), previous methods fail to capture the right direction; while our MemoNet still provides precise prediction.</p><p>Visualization of explicit link. <ref type="figure">Fig.9</ref> shows prediction cases with their seen past-future trajectory instances traced by the addressed memory instances. We see that seen similar scenarios provide instance-level experience to obtain multimodal future intentions and reflects that our model can trace back to specific memorized samples during the prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Ablation studies</head><p>Effect of components in MemoNet. We explore the effect of each of four proposed key components in Mem-oNet, including memory bank, memory filtering, memory addresser and intention clustering. <ref type="table" target="#tab_3">Table 4</ref> presents the results. We see that i) the proposed memory bank can sig-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Past Trajectory</head><p>Ground-Truth MANTRA PECNet Ours <ref type="figure">Figure 8</ref>. We compare the best-of-20 predicted trajectories produced by our method and two previous methods on SDD. Our method achieves a more precise trajectory prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Current Prediction</head><p>Memory Instance 1 Memory Instance 2 Memory Instance 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Past Trajectory Predicted Intention Seen Intention</head><p>Address: 8957 Address: 7338 Address: 5075</p><p>Address: 9015 Address: 6670 Address: 751 <ref type="figure">Figure 9</ref>. Prediction cases with corresponding past-future trajectories traced by memory addresser. Our model promotes a more explicit link between the current situation and seen instances. nificantly improve the prediction performance; and ii) the memory filtering, learnable addresser and intention clustering all contribute to promoting accurate prediction.</p><p>Effect of the number of coarse intention anchors. <ref type="figure" target="#fig_4">Fig.10</ref> illustrates the influence of coarse intention anchor numbers L. We find that either too small or too large L causes performance degeneration as i) when L is small, the model tends to miss intention modality, causing insufficient diversity and worse prediction performance; and ii) when L is too large, the prediction involves too many irrelevant instances, also resulting in worse prediction performance.</p><p>Effect of thresholds in memories filtering. <ref type="table" target="#tab_4">Table 5</ref> reports the prediction errors with various thresholds ? past /? int in memory filtering. We see that i) an appropriate ? past /? int leads to a remarkable performance and lightweight storage; ii) when ? past /? int are too small, the model tends to preserve redundant information and decrease the intention diversity, wasting the storage and affecting the performance; and iii) when ? past /? int are too large, a large amount of useful infor-  mation are filtered out, which makes it harder to find relevant instances, deteriorating the performance.</p><p>Real-time inference speed. We run the whole inference model for 10 times on SDD dataset using one RTX-3090 GPU. The average prediction time is 18.03ms per sample, with a real-time predictions FPS=55.5, much faster than the common sampling rate of data collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>This paper proposes MemoNet, an instance-based approach that is designed based on the retrospective memory mechanism, where the seen instances are stored into a memory bank pair during training and could be used for relevant movement pattern matching during inference. The proposed MemoNet includes four key designs: a joint-reconstructionbased feature-learning architecture, a memory filtering algorithm, a learnable addresser, and an intention clustering method. Experiments show that our method significantly improves the state-of-the-art performance on trajectory prediction datasets and has the ability to trace back to specific instances during prediction, promoting more interpretability.</p><p>Limitation and future work. In this paper, we focus on memorizing past-intention pairs. However, it is a challenge to predict some special actions only using past trajectories, such as a sharp turn. A future work is to utilize the map information to generate environment conditioned prediction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>i</head><label></label><figDesc>to filter similar memory instances. For the ith and the jth addresses, if their memory instances have close past starting positions and future intentions, this pair of addresses is redundant and one should be removed. Mathematically, for memory instances in the ith address with its starting position x ?Tp+1 i and intention y T f i and the jth address with its starting position x ?Tp+1 j and intention y T f j , they are redundant when: ?x ?Tp+1 i ?x ?Tp+1 j</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>1 ) 1</head><label>11</label><figDesc>Algorithm Memory bank filtering Input: Initial memory banks M Filtered memory banks Mpast,Mint 1: Initialize Mpast = ?,Mint = ? 2: while M (0) past ? = ? and M (0) int ? = ? do 3:Randomly pick address i in Mpast, Mint 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>10 :</head><label>10</label><figDesc>return Mpast,Mint</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 4 .</head><label>4</label><figDesc>The addresser learning process. To train the attention network, we generate a pseudo label based on the relative distance between the decoded intentions and the ground-truth intentions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(a) No intention clustering (b) With intention clusteringFigure 5. Examples of intention prediction. With intention clustering, MemoNet produces a more diverse prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>by using E social (?), E int (?). Apply memory filtering to obtain the final past and intention memory banks M past and M int .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 7 .</head><label>7</label><figDesc>Diverse intention prediction by MemoNet on SDD, where 20 final intentions are clustered from 120 coarse intention anchors. MemoNet can provide diverse and accurate intention predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 .</head><label>10</label><figDesc>ADE/FDE as a function of the number of coarse intention anchors L on SDD. L = 120 provides the best performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Feature learning architecture via joint reconstruction.</figDesc><table><row><cell></cell><cell>Social</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Past Trajectory Future Intention Future Intention (a) Past Trajectory</cell><cell>Intention Encoder Encoder</cell><cell>c</cell><cell>c</cell><cell>Decoder Decoder</cell><cell>Reconstructed Trajectory Reconstructed Intention Reconstructed Intention Reconstructed Trajectory</cell><cell>Initial Past Memory Bank</cell><cell>Social Encoder Past Trajectory . . . Social Encoder</cell><cell>Intention Encoder Intention Intention . . . Intention Initial Intention Memory Bank Initial Intention Memory Bank Encoder . . . . . .</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>minADE20 / minFDE20 (pixels) of trajectory prediction (SDD dataset). Lower is better. The bold/underlined font represent the best/second best result. Our method achieves a 20.3% FDE improvement compared to PECNet. Ours 4.8s 27.23/41.44 20.60/33.10 19.30/32.70 16.27/29.38 14.67/26.72 13.90/22.90 12.60/22.30 8.96/17.76 9.96/15.88 8.56/12.66Table 2. minADE20 / minFDE20 (meters) of trajectory prediction (ETH-UCY dataset). Lower is better. The bold/underlined font represent the best/second best result. Our method achieves a 10.2% FDE improvement compared to Agentformer.</figDesc><table><row><cell>Time</cell><cell>Social -GAN [13]</cell><cell cols="2">Social-STGCNN [35]</cell><cell>Trajectron++ [38]</cell><cell>SOPHIE [37]</cell><cell>NMMP [15]</cell><cell cols="2">EvolveGraph [26]</cell><cell cols="2">CF-VAE [4]</cell><cell>MANTRA [33]</cell><cell>PECNet [32]</cell></row><row><cell>Subset</cell><cell cols="2">Social-GAN [13]</cell><cell cols="2">STGAT [16] NMMP [15]</cell><cell>MANTRA [33]</cell><cell>Transformer -TF [8]</cell><cell>STAR [46]</cell><cell cols="2">PECNet [32]</cell><cell>Trajectron++ [38]</cell><cell>Agentformer [47]</cell><cell>Ours</cell></row><row><cell>ETH</cell><cell cols="3">0.87/1.62 0.65/1.12</cell><cell>0.61/1.08</cell><cell>0.48/0.88</cell><cell>0.61/1.12</cell><cell cols="4">0.36/0.65 0.54/0.87 0.39/0.83</cell><cell>0.45/0.75 0.40/0.61</cell></row><row><cell cols="4">HOTEL 0.67/1.37 0.35/0.66</cell><cell>0.33/0.63</cell><cell>0.17/0.33</cell><cell>0.18/0.30</cell><cell cols="4">0.17/0.36 0.18/0.24 0.12/0.21</cell><cell>0.14/0.22 0.11/0.17</cell></row><row><cell>UNIV</cell><cell cols="3">0.76/1.52 0.52/1.10</cell><cell>0.52/1.11</cell><cell>0.37/0.81</cell><cell>0.35/0.65</cell><cell cols="4">0.31/0.62 0.35/0.60 0.20/0.44</cell><cell>0.25/0.45 0.24/0.43</cell></row><row><cell cols="4">ZARA1 0.35/0.68 0.34/0.69</cell><cell>0.32/0.66</cell><cell>0.27/0.58</cell><cell>0.22/0.38</cell><cell cols="4">0.29/0.52 0.22/0.39 0.15/0.33</cell><cell>0.18/0.30 0.18/0.32</cell></row><row><cell cols="4">ZARA2 0.42/0.84 0.29/0.60</cell><cell>0.43/0.85</cell><cell>0.30/0.67</cell><cell>0.17/0.32</cell><cell cols="4">0.22/0.46 0.17/0.30 0.11/0.25</cell><cell>0.14/0.24 0.14/0.24</cell></row><row><cell>AVG</cell><cell cols="3">0.61/1.21 0.43/0.83</cell><cell>0.41/0.82</cell><cell>0.32/0.65</cell><cell>0.31/0.55</cell><cell cols="4">0.26/0.53 0.29/0.48 0.19/0.41</cell><cell>0.23/0.39 0.21/0.35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Ablation study of each component in MemoNet on the SDD and ETH dataset. ?/? represent using cosine distance/learnable addresser. Each component is beneficial.</figDesc><table><row><cell>Memory Bank</cell><cell>Memory Filtering</cell><cell>Memory Addresser</cell><cell>Intention Clustering</cell><cell>SDD</cell><cell>ETH</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">14.16/27.76 0.78/1.44</cell></row><row><cell>?</cell><cell></cell><cell>?</cell><cell></cell><cell cols="2">9.64/15.25 0.55/0.94</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell cols="2">9.59/15.08 0.55/0.93</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell cols="2">9.50/14.78 0.53/0.89</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell cols="2">8.56/12.66 0.40/0.61</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Ablation study of thresholds ?past/?int in memory filtering on SDD. ?past = ?int = 1 achieves the best performance.?past/? int minADE 20 /minFDE 20 Memory Size</figDesc><table><row><cell>Storage</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research is partially supported by the National Key </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social lstm: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kratarth</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Vqa: Visual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Antol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aishwarya</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margaret</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2425" to="2433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Baddeley</surname></persName>
		</author>
		<title level="m">Essentials of human memory</title>
		<imprint>
			<publisher>Psychology Press</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>classic edition</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apratim</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Hanselmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Fritz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.09008</idno>
		<title level="m">Bernt Schiele, and Christoph-Nikolas Straehle. Conditional flow variational autoencoders for structured sequence prediction</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large-scale machine learning with stochastic gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">19th International Conference on Computational Statistics, COMPSTAT 2010</title>
		<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
	<note>-Keynote, Invited and Contributed Papers</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Science, technology and the future of small autonomous drones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Floreano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="460" to="466" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Vectornet: Encoding hd maps and agent dynamics from vectorized representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiyang</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congcong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11525" to="11533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Transformer networks for trajectory forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Giuliari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irtiza</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Galasso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 25th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10335" to="10342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cellular basis of working memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patricia S Goldman-Rakic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="477" to="485" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dynamic neural relational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Graber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="8513" to="8522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
		<title level="m">Neural turing machines</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Hybrid computing using a neural network with dynamic external memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malcolm</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Grabska-Barwi?ska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><forename type="middle">G?mez</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Agapiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">538</biblScope>
			<biblScope unit="issue">7626</biblScope>
			<biblScope unit="page" from="471" to="476" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Social force model for pedestrian dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Molnar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical review E</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">4282</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Collaborative motion prediction via neural motion message passing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="6319" to="6328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Stgat: Modeling spatial-temporal interactions for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingfan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huikun</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianlu</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoqi</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="6272" to="6281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The trajectron: Probabilistic multi-agent trajectory modeling with dynamic spatiotemporal graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2375" to="2384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Development and evaluation of an interactive humanoid robot&quot; robovie</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takayuki</forename><surname>Kanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Ishiguro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tetsuo</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michita</forename><surname>Imai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryohei</forename><surname>Nakatsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No. 02CH37292)</title>
		<meeting>2002 IEEE International Conference on Robotics and Automation (Cat. No. 02CH37292)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2002" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1848" to="1855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural relational inference for interacting systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Fetaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan-Chieh</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2688" to="2697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Activity forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">D</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">Andrew</forename><surname>Ziebart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Bagnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="201" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Ask me anything: Dynamic memory networks for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ondruska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1378" to="1387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namhoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="336" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Towards fully autonomous driving: Systems and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Levinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Askeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Dolson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soeren</forename><surname>Kammel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zico</forename><surname>Kolter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Pink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaughan</forename><surname>Pratt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 IEEE intelligent vehicles symposium (IV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="163" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">RAIN: reinforced hybrid attention inference network for motion forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengbo</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikanth</forename><surname>Malla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiho</forename><surname>Choi</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<title level="m">IEEE/CVF International Conference on Computer Vision, ICCV 2021</title>
		<meeting><address><addrLine>Montreal, QC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="16076" to="16086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Evolvegraph: Multi-agent trajectory prediction with dynamic relational reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiho</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Neural Information Processing Systems (NeurIPS)</title>
		<meeting>the Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Online multi-agent forecasting with interpretable collaborative graph neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanning</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Genjia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.00894</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Peeking into the future: Predicting future person activities and locations in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">Carlos</forename><surname>Niebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5725" to="5734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning lane graph representations for motion forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="541" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Visual question answering with memory-augmented networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6975" to="6984" />
		</imprint>
	</monogr>
	<note>Anton van den Hengel, and Ian Reid</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Continual multi-agent interaction behavior prediction with conditional generative memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengbo</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaofeng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiho</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics Autom. Lett</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">It is not the journey but the destination: Endpoint conditioned trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karttikeya</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harshayu</forename><surname>Girase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreyas</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuan-Hui</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="759" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mantra: Memory augmented networks for multiple trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Marchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Becattini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Seidenari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><forename type="middle">Del</forename><surname>Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Abnormal crowd behavior detection using social force model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramin</forename><surname>Mehran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="935" to="942" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Social-stgcnn: A social spatio-temporal graph convolutional neural network for human trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abduallah</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Kun Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Elhoseiny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Claudel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="14424" to="14432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Analysis of recurrent neural networks for probabilistic modeling of driver behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeremy</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><forename type="middle">A</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kochenderfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1289" to="1298" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noriaki</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1349" to="1358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Trajectron++: Multi-agent generative trajectory forecasting with heterogeneous data for control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Punarjay</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pavone</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Meta-learning with memoryaugmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.08895</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Collaborative uncertainty in multiagent trajectory forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohan</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siheng</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Intelligent distributed surveillance systems: a review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Valera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sergio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Velastin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEE Proceedings-Vision, Image and Signal Processing</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="page" from="192" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Social attention: Modeling attention in human crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Vemula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Muelling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Oh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE international Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4601" to="4607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Gaussian process dynamical models for human motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hertzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="283" to="298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.3916</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Memory networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph transformer networks for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunjun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="507" to="523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Agentformer: Agent-aware transformers for socio-temporal multi-agent forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinshuo</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanglan</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="9813" to="9823" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
