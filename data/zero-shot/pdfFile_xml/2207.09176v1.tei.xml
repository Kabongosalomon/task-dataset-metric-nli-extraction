<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Supervision Can Be a Good Few-Shot Learner</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><forename type="middle">Lu</forename><surname>1?</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangjian</forename><surname>Wen</surname></persName>
							<email>wenliangjian1@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianzhuang</forename><surname>Liu</surname></persName>
							<email>liu.jianzhuang@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajing</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinmei</forename><surname>Tian</surname></persName>
							<email>xinmei@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Science</orgName>
								<address>
									<country>Technology of China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Artificial Intelligence</orgName>
								<orgName type="institution">Hefei Comprehensive National Science Center</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Self-Supervision Can Be a Good Few-Shot Learner</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Few-shot image classification, self-supervised learning</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing few-shot learning (FSL) methods rely on training with a large labeled dataset, which prevents them from leveraging abundant unlabeled data. From an information-theoretic perspective, we propose an effective unsupervised FSL method, learning representations with self-supervision. Following the InfoMax principle, our method learns comprehensive representations by capturing the intrinsic structure of the data. Specifically, we maximize the mutual information (MI) of instances and their representations with a low-bias MI estimator to perform selfsupervised pre-training. Rather than supervised pre-training focusing on the discriminable features of the seen classes, our self-supervised model has less bias toward the seen classes, resulting in better generalization for unseen classes. We explain that supervised pre-training and selfsupervised pre-training are actually maximizing different MI objectives. Extensive experiments are further conducted to analyze their FSL performance with various training settings. Surprisingly, the results show that self-supervised pre-training can outperform supervised pre-training under the appropriate conditions. Compared with state-of-the-art FSL methods, our approach achieves comparable performance on widely used FSL benchmarks without any labels of the base classes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Several unsupervised FSL works <ref type="bibr" target="#b10">[3,</ref><ref type="bibr" target="#b42">35,</ref><ref type="bibr" target="#b44">37,</ref><ref type="bibr" target="#b45">38,</ref><ref type="bibr" target="#b64">57]</ref> attempt to solve the problem of label dependency. Most of them share a similar motivation of applying existing meta-learning methods (i.e., the popular supervised FSL solutions) to unsupervised data. Instead of leveraging category labels, these approaches generate (meta-)training tasks (or episodes) via different unsupervised ways, such as data augmentation <ref type="bibr" target="#b44">[37]</ref> or pseudo labels <ref type="bibr" target="#b42">[35]</ref>. Despite their worthy attempts, they still have a large performance gap compared with the top supervised FSL methods. Recent work <ref type="bibr" target="#b46">[39]</ref> indicates that the episodic training of meta-learning is data-inefficient in that it does not sufficiently exploit the training batch. Several studies <ref type="bibr" target="#b17">[10,</ref><ref type="bibr" target="#b26">19,</ref><ref type="bibr" target="#b35">28,</ref><ref type="bibr" target="#b78">71]</ref> of (supervised) FSL also show that a simple pre-training-&amp;-fine-tuning approach outperforms many sophisticated meta-learning methods.</p><p>From an information-theoretic perspective, we propose an effective unsupervised FSL method, i.e., learning the representations with self-supervised pretraining. Following the principle of InfoMax <ref type="bibr" target="#b53">[46]</ref>, the goal of our method is to preserve more information about high-dimensional raw data in the low-dimensional learned representations. In contrast to supervised pre-training <ref type="bibr" target="#b78">[71]</ref>, self-supervised pre-training focuses on capturing the intrinsic structure of the data. It learns comprehensive representations instead of the most discriminative representations about the base categories. Specifically, our self-supervised pre-training maximizes the mutual information (MI) between the representations of augmented views of the same instance. It is a lower bound of MI between the instance and its representations. Many contrastive learning methods <ref type="bibr" target="#b15">[8,</ref><ref type="bibr" target="#b38">31,</ref><ref type="bibr" target="#b59">52]</ref> maximize MI by optimizing a loss based on Noise-Contrastive Estimation <ref type="bibr" target="#b36">[29]</ref> (also called In-foNCE <ref type="bibr" target="#b59">[52]</ref>). However, recent progress <ref type="bibr" target="#b63">[56,</ref><ref type="bibr" target="#b73">66,</ref><ref type="bibr" target="#b84">77]</ref> shows that the MI estimation based on InfoNCE has high bias. We alternatively employ a low-bias MI estimator following the MI neural estimation <ref type="bibr" target="#b11">[4]</ref> to address the issue. The experiments in FSL demonstrate the effectiveness of our approach.</p><p>To better understand self-supervision and supervision in FSL, we explain that they are maximizing different MI targets. We further construct comprehensive experiments to analyze their different behaviors in FSL across various settings (i.e., backbones, data augmentations, and input sizes). The experiment results surprisingly show that, with appropriate settings, self-supervision without any labels of the base dataset can outperform supervision while exhibiting better scalability for network depth. We argue that self-supervision learns less bias toward the base classes than supervision, resulting in better generalization ability for unknown classes. In this manner, extending the network depth can learn more powerful representations without over-fitting to the seen classes.</p><p>The scalability of network depth provides an opportunity to use a deep model to guide the learning of a shallow model in FSL. We formulate this problem of unsupervised knowledge distillation as maximizing MI between the representations of different models. Consequently, we propose a simple yet effective loss to perform the knowledge distillation without labels. To the best of our knowledge, existing supervised FSL methods <ref type="bibr" target="#b27">[20,</ref><ref type="bibr" target="#b78">71]</ref> only perform the knowledge distillation between shallow models. In summary, our contributions are:</p><p>-From an information-theoretic perspective, we propose an effective unsupervised FSL approach that learns representations with self-supervision. Our method maximizes the MI between the instances and their representations with a low-bias MI estimator. -We indicate that the self-supervised pre-training and supervised pre-training maximize different targets of MI. We construct comprehensive experiments to analyze the difference between them for the FSL problem. -We present a simple yet effective self-supervised knowledge distillation for unsupervised FSL to improve the performance of a small model. -Extensive experiments are conducted to demonstrate the advantages of our method. Our unsupervised model achieves comparable results with the stateof-the-art supervised FSL ones on widely used benchmarks, i.e., mini -ImageNet <ref type="bibr" target="#b82">[75]</ref> and tiered -ImageNet <ref type="bibr" target="#b68">[61]</ref>, without any labels of the base classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Few-shot learning (FSL). The pioneering works of FSL date back to the Bayesian approach <ref type="bibr" target="#b47">[40,</ref><ref type="bibr" target="#b51">44]</ref>. In recent years, several papers <ref type="bibr" target="#b30">[23,</ref><ref type="bibr" target="#b50">43,</ref><ref type="bibr" target="#b60">53,</ref><ref type="bibr" target="#b70">63,</ref><ref type="bibr" target="#b72">65,</ref><ref type="bibr" target="#b82">75]</ref> address the problem with a meta-learning paradigm, where the model learns from a series of simulated learning tasks that mimic the real few-shot circumstances. Due to its elegant form and excellent results, it has attracted great interest. However, recent studies <ref type="bibr" target="#b17">[10,</ref><ref type="bibr" target="#b35">28,</ref><ref type="bibr" target="#b78">71]</ref> show that pre-training an embedding model with the classification loss (cross-entropy) is a simple but tough-to-beat baseline in FSL. Subsequently, many studies <ref type="bibr" target="#b20">[13,</ref><ref type="bibr" target="#b54">47,</ref><ref type="bibr" target="#b56">49,</ref><ref type="bibr" target="#b62">55,</ref><ref type="bibr" target="#b74">67]</ref> focus on how to learn a good embedding instead of designing complex meta-learning strategies. Although considerable progress has been made, the aforementioned approaches rely on the annotation of the base classes, limiting their applications. In addition, most existing supervised methods <ref type="bibr" target="#b17">[10,</ref><ref type="bibr" target="#b29">22,</ref><ref type="bibr" target="#b50">43,</ref><ref type="bibr" target="#b58">51,</ref><ref type="bibr" target="#b60">53,</ref><ref type="bibr" target="#b72">65,</ref><ref type="bibr" target="#b78">71,</ref><ref type="bibr" target="#b82">75]</ref> achieve their best results with a relatively shallow backbone, e.g., ResNet-10/12. Our paper demonstrates that it is possible to build an effective and scalable few-shot learner without any labels of the base classes. It suggests that we should rethink the significance of label information of the base dataset in FSL. InfoMax principle in FSL. Some recent studies <ref type="bibr" target="#b12">[5,</ref><ref type="bibr" target="#b26">19]</ref> address the problem of transductive FSL, where unlabeled query samples are utilized in the downstream fine-tuning, from the information-theoretic perspective. The most related work <ref type="bibr" target="#b12">[5]</ref> introduces the InfoMax principle <ref type="bibr" target="#b53">[46]</ref> to perform transductive fine-tuning. It maximizes the MI between the representations of query samples and their predicted labels during fine-tuning, while ours maximizes the MI between base samples and their representations during pre-training. Self-supervised learning (SSL). A self-supervised model learns representations in an unsupervised manner via various pretext tasks, such as colorization <ref type="bibr" target="#b48">[41,</ref><ref type="bibr" target="#b90">83]</ref>, inpainting <ref type="bibr" target="#b61">[54]</ref>, and rotation prediction <ref type="bibr" target="#b33">[26]</ref>. One of the most competitive methods is contrastive learning <ref type="bibr" target="#b15">[8,</ref><ref type="bibr" target="#b37">30,</ref><ref type="bibr" target="#b38">31,</ref><ref type="bibr" target="#b41">34,</ref><ref type="bibr" target="#b59">52,</ref><ref type="bibr" target="#b76">69]</ref>, which aligns the representation of samples from the same instance (the positive pair, e.g., two augmented views of the same image). A major problem of contrastive learning is the representation collapse, i.e., all outputs are a constant. One solution is the uniformity regularization, which encourages different images (the negative pair) to have dissimilar representations. Recent works <ref type="bibr" target="#b15">[8,</ref><ref type="bibr" target="#b38">31]</ref> typically optimize the In-foNCE loss <ref type="bibr" target="#b36">[29,</ref><ref type="bibr" target="#b59">52]</ref> to perform both alignment and uniformity, which is considered to maximize the MI between different views. Since InfoNCE can be decomposed into alignment and uniformity terms <ref type="bibr" target="#b16">[9,</ref><ref type="bibr" target="#b83">76]</ref>, many works introduce new forms of uniformity (and/or alignment) to design new objectives. Barlow Twins <ref type="bibr" target="#b89">[82]</ref> encourages the representations to be dissimilar for different channels, not for different samples. Chen and Li <ref type="bibr" target="#b16">[9]</ref> propose to explicitly match the distribution of representations to a prior distribution of high entropy as a new uniformity term. Some recent works <ref type="bibr" target="#b19">[12,</ref><ref type="bibr" target="#b34">27,</ref><ref type="bibr" target="#b79">72]</ref> introduce asymmetry in the alignment of the positive pair to learn meaningful representations without explicit uniformity. FSL with SSL. In natural language processing, self-supervised pre-training shows superior performance on few-shot learning <ref type="bibr" target="#b14">[7]</ref>. However, the application of SSL in the few-shot image classification is still an open problem. Most works <ref type="bibr" target="#b32">[25,</ref><ref type="bibr" target="#b56">49,</ref><ref type="bibr" target="#b74">67]</ref> leverage the pretext task of SSL as an auxiliary loss to enhance the representation learning of supervised pre-training. The performance of these methods degrades drastically without supervision. Another way is unsupervised FSL <ref type="bibr" target="#b10">[3,</ref><ref type="bibr" target="#b42">35,</ref><ref type="bibr" target="#b44">37,</ref><ref type="bibr" target="#b45">38,</ref><ref type="bibr" target="#b49">42,</ref><ref type="bibr" target="#b57">50,</ref><ref type="bibr" target="#b64">57]</ref>, whose setting is the same as ours. Most of these works <ref type="bibr" target="#b10">[3,</ref><ref type="bibr" target="#b42">35,</ref><ref type="bibr" target="#b44">37,</ref><ref type="bibr" target="#b45">38,</ref><ref type="bibr" target="#b57">50,</ref><ref type="bibr" target="#b64">57]</ref> simply adapt existing supervised meta-learning methods to the unsupervised versions. For example, CACTUs <ref type="bibr" target="#b42">[35]</ref> uses a clustering method to obtain pseudo-labels of samples and then applies a meta-learning algorithm. Their performance is still limited by the downstream meta-learning methods, having a large gap with the top supervised FSL methods. In addition, the recent work <ref type="bibr" target="#b28">[21]</ref> evaluates existing self-supervised methods on a benchmark <ref type="bibr" target="#b35">[28]</ref> of cross-domain few-shot image classification, where there is a large domain shift between the data of base and novel classes. Our approach also obtains the state-of-the-art results on this benchmark <ref type="bibr" target="#b35">[28]</ref> compared with other self-supervised and supervised methods (see our supplementary materials). Besides, similar works in continuous <ref type="bibr" target="#b31">[24]</ref> and open-world learning <ref type="bibr" target="#b25">[18]</ref> also employ SSL to enhance their performances, which can relate to FSL since these fields all aim to generalize the learned representations to the novel distribution. Chen et al. <ref type="bibr" target="#b23">[16]</ref> suggest that, in the transductive setting, the existing SSL method (MoCo v2 <ref type="bibr" target="#b18">[11]</ref>) can achieve competitive results with supervised FSL methods. However, their transductive FSL method requires the data of test classes for unsupervised pre-training, which is somewhat contrary to the motivation of FSL. prediction, where y s is the class label of image x s . As an N -way K-shot classification task T , K is relatively small (e.g., 1 or 5 usually) and the N novel categories are not in D base . FSL with supervised pre-training. Recent works <ref type="bibr" target="#b17">[10,</ref><ref type="bibr" target="#b78">71]</ref> show that a simple pre-training-&amp;-fine-tuning approach is a strong baseline for FSL. These methods pre-train an encoder (e.g., a convolution neural network) on D base with the standard classification objective. In downstream FSL tasks, a simple linear classifier (e.g., logistic regression in our case) is trained on the output features of the fixed encoder network with the support samples. Finally, the pre-trained encoder with the adapted classifier is used to infer the query samples (as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>). Unsupervised FSL setup. In contrast to supervised FSL where D base = {(x i , y i )}, only the unlabeled dataset D base ={x i } is available in the pre-training (or meta-training) stage for unsupervised FSL. Our self-supervised pre-training approach follows the standard pre-training-&amp;-fine-tuning strategy discussed above, except that the base dataset is unlabeled (as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>). Note that, for a fair comparison, our model is not trained on any additional (unlabeled) data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Self-Supervised Pre-Training for FSL</head><p>Self-supervised pre-training and supervised pre-training maximize different MI targets. Supervised pre-training aims to reduce the classification loss on the base dataset toward zero. A recent study <ref type="bibr" target="#b81">[74]</ref> shows that there is a pervasive phenomenon of neural collapse in the supervised training process, where the representations of within-class samples collapse to the class mean. It means the conditional entropy H(Z|Y ) of hidden representations Z given the class label Y is small. In fact, Boudiaf et al. <ref type="bibr" target="#b13">[6]</ref> indicate that minimizing the cross-entropy loss is equivalent to maximizing the mutual information I(Z; Y ) between representations Z and labels Y . Qin et al. <ref type="bibr" target="#b65">[58]</ref> also prove a similar result.</p><p>Maximizing I(Z; Y ) is beneficial for recognition on the base classes. However, since FSL requires the representations generalizing on the novel classes, overfitting to the base classes affects the performance of FSL. In this paper, following the InfoMax principle <ref type="bibr" target="#b53">[46]</ref>, our method aims to preserve the raw data information as much as possible in the learned representations. Theoretically, we maximize another MI target, i.e., the mutual information I(Z; X) between representations Z and data X, to learn meaningful representations for FSL. Comparing the two MI objectives I(Z; Y ) and I(Z; X), the supervised representations are only required to contain information about the associated labels of the images. In contrast, the representations with self-supervision are encouraged to contain comprehensive information about the data with less bias toward the base labels.</p><p>In practice, the calculation of I(Z; X) is intractable. We maximize an alternative MI objective I(Z 1 ; Z 2 ) = I(f (X 1 ); f (X 2 )), which is a lower bound of I(Z; X) <ref type="bibr" target="#b80">[73]</ref>, where X 1 and X 2 are two augmented views of X obtained by some data augmentations, and f is the encoder network. In addition, our encoder f (?) = h proj ? g(?) consists of a backbone g(?) (e.g., ResNet) and an extra projection head h proj (?) (e.g., MLP) following contrastive learning methods <ref type="bibr" target="#b15">[8,</ref><ref type="bibr" target="#b18">11]</ref>, as shown in <ref type="figure" target="#fig_2">Fig. 3a</ref>. The projection head is only used in the pre-training stage. In the fine-tuning stage, the linear classifier is trained on the representations before the projection head. Next, we introduce two MI estimators for I(Z 1 , Z 2 ) and describe how to perform self-supervised pre-training with them.</p><p>Maximizing I(Z 1 ; Z 2 ) with I N CE and I M IN E . Many contrastive learning methods <ref type="bibr" target="#b15">[8,</ref><ref type="bibr" target="#b59">52]</ref> maximize I(Z 1 ; Z 2 ) with the InfoNCE estimator proposed in <ref type="bibr" target="#b59">[52]</ref>:</p><formula xml:id="formula_0">I(Z 1 ; Z 2 ) = I(f (X 1 ); f (X 2 )) (1) ? E p(x 1 ,x 2 ) [C(x 1 , x 2 )] ? E p(x 1 ) [log( E p(x 2 ) [e C(x 1 ,x 2 ) ])] ? INCE(Z 1 ; Z 2 ),<label>(2)</label></formula><p>where p(x 1 , x 2 ) is the joint distribution (i.e., (x 1 , x 2 )?p(x 1 , x 2 ), and (x 1 , x 2 ) is a positive pair) and the critic C(x 1 , x 2 ) is parameterized by the encoder f , e.g.,</p><formula xml:id="formula_1">C(x 1 , x 2 ) = f T (x 1 )f (x 2 )/? with ? being temperature. Given a training batch {x i } 2B i=1</formula><p>where x i and x i+B are positive pair (i ? B), the well-known method SimCLR <ref type="bibr" target="#b15">[8]</ref> minimizes the contrastive loss 1 based on I N CE :</p><formula xml:id="formula_2">LNCE = ? 1 B B i=1 z T i zi+B/? Alignment + 1 2B 2B i=1 log( j? =i e z T i z j /? ) U nif ormity ,<label>(3)</label></formula><p>where z i = f (x i ). Despite the great success of I N CE in contrastive learning, the problem is that I N CE has high bias, especially when the batch size is small and MI is large. For detailed discussions we refer the reader to <ref type="bibr" target="#b63">[56,</ref><ref type="bibr" target="#b73">66]</ref>.  <ref type="bibr" target="#b11">[4]</ref>, which has lower bias than I N CE <ref type="bibr" target="#b63">[56,</ref><ref type="bibr" target="#b73">66]</ref>:</p><formula xml:id="formula_3">IMINE(Z 1 ; Z 2 ) ? E p(x 1 ,x 2 ) [C(x 1 , x 2 )] ? log( E p(x 1 )?p(x 2 ) [e C(x 1 ,x 2 ) ]),<label>(4)</label></formula><p>where p(x 1 ) ? p(x 2 ) is the product of the marginal distributions. We construct a simple experiment on the synthetic data to compare the estimation bias of I N CE and I M IN E , as shown in <ref type="figure">Fig. 2</ref>. Based on I M IN E (Z 1 ; Z 2 ), we can further propose a novel contrastive loss for self-supervised pre-training:</p><formula xml:id="formula_4">LMINE = ? 1 B B i=1 z T i zi+B/? Alignment + log( 2B i=1 z j ?N eg(z i ) e z T i z j /? ) U nif ormity ,<label>(5)</label></formula><p>where N eg(z i ) denotes the collection of negative samples of z i .</p><p>Improving L M IN E with asymmetric alignment. We can decompose both L M IN E (Eq. 5) and L N CE (Eq. 3) into two terms: the alignment term encourages the positive pair to be close, and the uniformity term pushes the negative pair away. In fact, the uniformity term is a regularization used to avoid the representation collapse, i.e., the output representations are the same for all samples <ref type="bibr" target="#b83">[76]</ref>. Alternatively, without the uniformity term, recent work SimSiam <ref type="bibr" target="#b19">[12]</ref> suggests that the Siamese model can learn meaningful representations by introducing asymmetry in the alignment term and obtains better results.</p><p>In our experiments <ref type="table">(Table 1)</ref>, when using the common data augmentation strategy <ref type="bibr" target="#b18">[11,</ref><ref type="bibr" target="#b19">12]</ref>, SimSiam is slightly better than models with contrastive loss (L N CE or L M IN E ). However, we empirically find that the SimSiam model fails to learn stably in FSL when using stronger data augmentation. When the variations in the positive pairs are large, the phenomenon of dimensional collapse <ref type="bibr" target="#b43">[36]</ref> occurs in SimSiam, i.e., a part of dimensionality of the embedding space vanishes (as shown in <ref type="figure" target="#fig_6">Fig. 6</ref>). In contrast, models with uniformity regularization do not suffer from significant dimensional collapse. This paper further improve L M IN E with the asymmetric alignment:  where ? is a weighting hyper-parameter, p i = h pred (z i ) is the output of the additional prediction head h pred (?) <ref type="bibr" target="#b19">[12]</ref>, and the SG (stop gradient) operation indicates that the back-propagation of the gradient stops here. Similar to the projection head, the prediction head is only used in the pre-training stage. Compared with SimSiam, our method can learn with stronger data augmentation to improve the invariance of the representations, resulting in better out-of-distribution generalization for FSL. Since our model can be considered as SimSiam with the Uniformity regularization, we term it UniSiam (as shown in <ref type="figure" target="#fig_2">Fig. 3b</ref>).</p><formula xml:id="formula_5">LAMINE = ? 1 2B B i=1 (p T i SG(zi+B) + p T i+B SG(zi)) Asymmetric Alignment + ? log( 2B i=1 z j ?N eg(z i ) e z T i z j /? ) U nif ormity ,<label>(6)</label></formula><p>Thus, we obtain the final self-supervised pre-training loss L AM IN E (Eq. 6). We can train our UniSiam model by minimizing this objective. After selfsupervised pre-training, the pre-trained backbone can be used in FSL tasks by training a classifier on the output embeddings (discussed in Sec. 3.1). Note that the projection head and prediction head are removed in the fine-tuning stage. Next, we introduce how to perform self-supervised knowledge distillation with a pre-trained UniSiam model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Self-Supervised Knowledge Distillation for Unsupervised FSL</head><p>A large model (teacher) trained with the self-supervised loss (Eq. 6) can be used to guide the learning of a small self-supervised model (student) 2 . In <ref type="bibr" target="#b77">[70]</ref>, the knowledge transfer from a teacher model to a student model is defined as maximizing the mutual information I(X s ; X t ) between the representations of them. Maximizing the objective is equivalent to minimizing the conditional entropy H(X t |X s ), since I(X s ; X t ) = H(X t ) ? H(X t |X s ) and the teacher model is fixed. It means the difference between their outputs should be as small as possible. So, simply aligning the outputs of them can achieve the purpose.</p><p>Specifically, as shown in <ref type="figure" target="#fig_2">Figure 3c</ref>, the pre-trained teacher encoder f t (?) (consisting of the backbone g t (?) and the projection head h t proj (?)) is used to guide the training of the student backbone g s (?) with a distillation head h dist (?). The self-supervised distillation objective can be written as:</p><formula xml:id="formula_6">L dist = ? 1 2B 2B i=1 (d s i ) T z t i ,<label>(7)</label></formula><p>where d s = h dist ? g s (x) is the output of the distillation head on the student backbone, and z t = h t proj ? g t (x) is the output of the teacher model. Finally, the total objective that combines both distillation and pre-training is:</p><formula xml:id="formula_7">L = ?LAMINE + (1 ? ?)L dist ,<label>(8)</label></formula><p>where ? is a hyper-parameter. We set ? = 0.5 for all our experiments. Given a large UniSiam model pre-trained by Eq. 6, we can employ it as a teacher network to guide the training of a small model (from scratch) by minimizing Eq. 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets and Settings</head><p>Datasets. We perform experiments on two widely used few-shot image classification datasets, mini -ImageNet <ref type="bibr" target="#b82">[75]</ref> and tiered -ImageNet <ref type="bibr" target="#b68">[61]</ref>. mini -ImageNet <ref type="bibr" target="#b82">[75]</ref> is a subset of ImageNet <ref type="bibr" target="#b69">[62]</ref>, which contains 100 classes with 600 images per class. We follow the split setting used in previous works <ref type="bibr" target="#b67">[60]</ref>, which randomly select 64, 16, and 20 classes for training, validation, and testing, respectively. tiered -ImageNet <ref type="bibr" target="#b68">[61]</ref> is a larger subset of ImageNet with 608 classes and about 1300 images per class. These classes are grouped into 34 high-level categories and then divided into 20 categories (351 classes) for training, 6 categories (97 classes) for validation, and 8 categories (160 classes) for testing. Implementation details. We use the networks of ResNet family <ref type="bibr" target="#b39">[32]</ref> as our backbones. The projection and prediction heads of UniSiam are MLPs with the same setting as SimSiam <ref type="bibr" target="#b19">[12]</ref>, except that the ResNets without bottleneck blocks (e.g., ResNet-18) on mini -ImageNet use 512 output dimensions to avoid overfitting. The distillation head is a 5-layer MLP with batch normalization applied to each hidden layer. All the hidden fully-connected layers are 2048-D, except that the penultimate layer is 512-D. We find that this distillation head structure, which is similar to the combination of the projection and the prediction (as shown in <ref type="figure" target="#fig_2">Figure 3c</ref>), is suited for the knowledge distillation. The output vectors of the projection, prediction, and distillation heads are normalized by their L2-norm <ref type="bibr" target="#b86">[79]</ref>. More implementation details can be found in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Self-Supervised vs. Supervised Pre-Training in FSL</head><p>In this subsection, we explore how several factors (network depth, image size, and data augmentation) affect the FSL performance of self-supervised and supervised  pre-training. On mini -ImageNet, we compare supervised pre-training (training with the cross-entropy loss <ref type="bibr" target="#b78">[71]</ref>) with our self-supervised UniSiam and two recent SSL models SimCLR <ref type="bibr" target="#b15">[8]</ref> and SimSiam <ref type="bibr" target="#b19">[12]</ref>. SimCLR is an well-known contrastive learning method that optimizes L N CE <ref type="figure" target="#fig_2">(Eq. 3)</ref>, and SimSiam is a relevant baseline to our UniSiam (i.e., ? = 0 in Eq. 6). More detailed comparison among the selfsupervised methods is in Sec 4.3. For a fair comparison, all methods use the same SGD optimization with cosine learning decay for 400 epochs, with batch size 256. Other hyper-parameters in each algorithm are chosen optimally using the grid search. To evaluate their performances in FSL, after pre-training on the base dataset of mini -ImageNet (i.e., the data of the training classes), we train a logistic regression classifier (with their fixed representations) for each few-shot classification task, which is sampled from the testing classes of mini -ImageNet. The reported results are the average of the accuracies on 3000 tasks for each method. More details about the baselines and evaluation can be found in the supplementary materials. Note that our self-supervised knowledge distillation is not used in this experiment. Network depth. <ref type="figure" target="#fig_4">Figure 4a</ref> compares the performances of different methods with various depths of ResNet (i.e., ResNet-10/18/34/50). The input image size is 224?224. We use the data augmentation (DA) strategy, widely used in selfsupervised learning <ref type="bibr" target="#b18">[11,</ref><ref type="bibr" target="#b19">12]</ref>, termed default DA. The details of the default DA are described in the supplementary materials.</p><p>We can find that when the backbone is shallow (i.e., ResNet-10), supervised pre-training has an advantage compared to self-supervised methods. However, as the network deepens, the self-supervised methods gradually outperform the supervised one. When the backbone changes from ResNet10 to ResNet50, the performance improvement of the self-supervised approach is larger than 4%. In contrast, the performance of supervised pre-training is decreased by 0.2%. Image size. <ref type="figure" target="#fig_4">Fig. 4b</ref> shows the performances of different approaches with various input sizes (160?160, 224?224, 288?288, and 384?384). All methods use ResNet-18 as the backbone with the default DA strategy. We find that a larger image size is more important for self-supervised methods. When the image size is small (i.e., 160?160), the performances of different methods are close. However, when the image size increases, self-supervised methods have larger performance gains compared with supervised pre-training. Although a larger image size can bring significant performance improvement, we still use the image size of 224?224 in other experiments following the typical setting in the community.</p><p>Data augmentation. <ref type="figure" target="#fig_5">Fig. 5</ref> shows the performances of various pre-training methods with different levels of data augmentation. All mehtods use the ResNet-18 backbone with input size 224?224. Here we introduces two effective DA for FSL: RandomVerticalFlip (RVF) and RandAugment (RA) <ref type="bibr" target="#b24">[17]</ref>. We set 4 levels of DA (from slight to heavy) as follows: (1) "Simple" denotes the strategy used for traditional supervised pre-training (including RandomResizedCrop, ColorJitter, and RandomHorizontalFlip), (2) "Default" is the same as the default DA mentioned above, (3) "Default+RVT" denotes the default DA plus the RVF, and (4) "Strong" represents the default DA plus RVF and RA. Supervised pre-training can bring more information than self-supervised methods in the case of simple DA. However, default DA substantially improves the performances of the self-supervised methods, but it has a limited gain for supervised pre-training. In addition, RVF can further improve the performances of all methods. RA improves the performances of most methods, except for SimSiam. We consider that the strong data augmentation leads to the dimensional collapse of SimSiam, as shown in the next subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Self-Supervised Pre-Training with Strong Augmentation</head><p>We compare SimCLR, SimSiam, and the variants of our UniSiam under default and strong DA (in <ref type="table">Table 1</ref>). We observe that self-supervised pre-training with the uniformity term obtains a larger improvement from strong DA compared with SimSiam. In addition, the uniformity term of L M IN E has a more significant improvement than the uniformity term of L N CE . Asymmetric alignment can also improve the FSL performance than the symmetric alignment.   <ref type="table">Table 1</ref>: Comparison of self-supervised methods under default and strong data augmentations. We report their 5-way 5-shot accuracy (%) on mini -ImageNet. "symm." and "asymm." denote using the symmetric alignment (Eq. 3 or Eq. 5) and the asymmetric alignment (Eq. 6) respectively.</p><p>To further demonstrate the importance of uniformity, we visualize the singular value spectrum of the embedding space of SimSiam and our UniSiam under different DAs in <ref type="figure" target="#fig_6">Fig. 6</ref>. The backbone is ResNet-50. Both SimSiam and UniSiam have a flat singular value spectrum when using the default DA. However, when DA is strong, some singular values of SimSiam are reduced. It means the features of SimSiam fall into a lower-dimensional subspace. This phenomenon is termed dimensional collapse by <ref type="bibr" target="#b43">[36]</ref>. In contrast, the singular value spectrum of UniSiam is flat even with strong DA, which indicates the significance of the uniformity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Our Self-Supervisied Knowledge Distillation</head><p>The previous work RFS <ref type="bibr" target="#b78">[71]</ref> employs the standard knowledge distillation <ref type="bibr" target="#b40">[33]</ref> to improve the supervised pre-training model in FSL. However, it is based on the logits that cannot be applied in unsupervised FSL. We use the standard knowledge distillation to transfer knowledge from a large supervised pre-training model to small ones, being a compared baseline to our self-supervised knowledge distillation (as shown in Tabel 2). Note that our method does not use any labels in the pre-training and the distillation stage. All methods use the default DA and the image size of 224?224. We can see that our knowledge distillation approach improves the performances of the smaller networks. Although the distillation loss allows supervised pre-training models to capture the relationships between classes to learn information beyond labels, our model after distillation still outperforms them when the backbones are larger (ResNet-18 and ResNet-34).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Comparison with the State-of-the-Art</head><p>We compare with state-of-the-art FSL approaches in <ref type="table">Table 3 and Table 4</ref>. Our method uses the strong DA and the image size of 224?224. In addition, we reim-  <ref type="table">Table 2</ref>: Effect of our self-supervised knowledge distillation. We report the 5-way 5-shot classification accuracy (%) on the mini -ImageNet dataset. <ref type="table">Table 3</ref>: Comparison to previous works on mini -ImageNet, using the averaged 5-way classification accuracy (%) with the 95% confidence interval on the testing split. Note that UniSiam+dist is trained by our self-supervised knowledge distillation ( <ref type="figure" target="#fig_2">Fig. 3c)</ref> with ResNet-50 being the teacher's backbone. ?: the results obtained from <ref type="bibr" target="#b17">[10]</ref>. ?: the results are from our implementations. Models that use knowledge distillation are tagged with the suffix "+dist". plement two unsupervised FSL methods (ProtoCLR <ref type="bibr" target="#b57">[50]</ref> and UMTRA <ref type="bibr" target="#b44">[37]</ref>) with the same DA strategy (strong DA) on mini -ImageNet. More baseline details are in the supplementary materials. On mini -ImageNet, our unsupervised UniSiam achieves the state-of-the-art results compared to other supervised methods with the ResNet-18 and ResNet-34 backbones. UniSiam also has a significant improvement than some methods that incorporate self-supervised objective and supervised pre-training ("sup.+ssl"). In addition, our method outperforms previous unsupervised FSL methods <ref type="bibr" target="#b44">[37,</ref><ref type="bibr" target="#b57">50]</ref> by a larger margin.</p><p>On tiered -ImageNet, since only a few studies use standard ResNet <ref type="bibr" target="#b39">[32]</ref> as their backbones, we also compare with some methods that use other backbones. For a fair comparison, we count the number of parameters and MACs of different backbones. Note that ResNet-12 modifies the original architecture of ResNet (e.g., larger channel dimensions). It has a larger computation overhead than standard</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Backbone (#Params) Size MACs 1-shot 5-shot <ref type="table">Table 4</ref>: Comparison to previous FSL works on tiered -ImageNet, using the averaged 5-way classification accuracy (%) on the testing split. ?: the results are from our implementations. ResNet-50 is the teacher's backbone.</p><p>ResNet-18, even with a smaller input size. Our method with a shallow backbone ResNet-18 is slightly worse than top supervised FSL methods on tiered -ImageNet. The main reasons are twofold. One is that increasing the number of classes alleviates the overfitting problem of supervised methods on the tiered -ImageNet dataset. The more important reason is that existing FSL methods utilize a variety of techniques to implicitly alleviate the problem of over-fitting to the base classes. For example, Robust+dist <ref type="bibr" target="#b27">[20]</ref> trains 20 different networks to learn diverse information for avoiding overfitting. RFS+dist <ref type="bibr" target="#b78">[71]</ref> repeats selfdistillation many times, which can capture the relation between the classes to learn more information beyond the labels. However, these methods require complicated processes and troublesome human designs, which limit their application and scalability. In contrast, our self-supervised UniSiam is a concise and effective approach that fundamentally avoids bias. When the backbone (i.e., ResNet-34) has similar computational overhead, UniSiam also achieves comparable results with the state-of-the-art supervised FSL methods on tiered -ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper proposes an effective few-shot learner without using any labels of the base dataset. From a unified information-theoretic perspective, our selfsupervised pre-training learns good embeddings with less bias toward the base classes for FSL by maximizing the MI of the instances and their representations. Compared with state-of-the-art supervised FSL methods, our UniSiam achieves comparable results on two popular FSL benchmarks. Considering the simplicity and effectiveness of the proposed approach, we believe it would motivate other researchers to rethink the role of label information of the base dataset in FSL. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Implementation Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Training Details</head><p>Self-supervised pre-training (UniSiam). We use the SGD optimizer with a weight decay of 10 ?4 , a momentum of 0.9, and a cosine decay schedule of learning rate. Note that our method does not require early stopping with the accuracy in the validation set (unlike many previous FSL works). The validation set is only used for model selection. The model of the last epoch is used for subsequent fine-tuning. For tiered -ImageNet, we follow SimSiam by setting the learning rate to 0.1 and the batch size to 512. For the smaller dataset mini -ImageNet, we use a larger learning rate of 0.3 with a smaller batch size of 256 to guarantee the convergence of pre-training. The numbers of epochs are 200 and 400 for tiered -ImageNet and mini -ImageNet, respectively. For our loss L AM IN E (Eq. 6), we set ? = 0.1. The temperature scalar ? is 2.0. All models are trained on 4 or 8 V100 GPUs. Self-supervised knowledge distillation (UniSiam+dist). The optimization details and hyper-parameters of self-supervised knowledge distillation are the same as in the pre-training, except that we set ? = 0.2 for tiered -ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Data Augmentation</head><p>The default data augmentation (in In the paragraph about the effect of data augmentation (Section 4.2), the simple data augmentation is a common data augmentation strategy in supervised pre-training, which includes RandomResizedCrop with scale in [0.2, 1.0], RandomHorizontalFlip with probability 0.5, and ColorJitter of {brightness, contrast, saturation} with strength {0.4,0.4,0.4}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Linear Classifier</head><p>The logistic regression is the default linear classifier in our experiments. Similar to the implementation of <ref type="bibr" target="#b87">[80]</ref>, we transform features with the power transformation in all our experiments. The value of power is 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Compared Methods</head><p>The projection head of SimCLR is a 2-layer MLP following the original paper. The hidden dimensions of the projection head are the same as our model. Our variant method with the symmetric alignment ( <ref type="table">Table 1</ref> in the manuscript) uses the same network architecture as SimCLR. For the unsupervised FSL methods (UMTRA and ProtoCLR), we use the same data augmentation strategy and backbone as ours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Mutual Information Estimation</head><p>We compare the mutual information (MI) estimators I M IN E and I N CE in the correlated Gaussian experiment <ref type="bibr" target="#b11">[4]</ref>. The two random variables x ? R 16 and y ? R 16 come from a multivariate Gaussian distribution with component-wise correlation corr(x i , y j ) = ? i,j ?, where ? ? (?1, 1) and ? i,j is Kronecker's delta. We consider the standardized Gaussian for marginal distributions p(x) and p(y) following <ref type="bibr" target="#b11">[4]</ref>. We employ I M IN E and I N CE to estimate the MI I(x, y) between x and y.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Additional Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Cross-Domain Few-Shot Image Classification</head><p>The recent work <ref type="bibr" target="#b28">[21]</ref> evaluates existing self-supervised learning methods on the benchmark of cross-domain few-shot learning (CDFSL) <ref type="bibr" target="#b35">[28]</ref>. The goal of CDFSL is to evaluate the performance of FSL methods in real scenarios, where there are significant domain shifts between the unknown downstream tasks and the pretraining dataset. The BSCD-FSL benchmark <ref type="bibr" target="#b35">[28]</ref> includes four different downstream datasets: CropDisease (crop disease images), EuroSAT (satellite images), ISIC (dermatology images), and ChestX (radiology images). We also evaluate our UniSiam model on these widely varying datasets, which is pre-trained on natural images.</p><p>We compare our results with those reported in <ref type="bibr" target="#b28">[21]</ref>. All methods use the same backbone of ResNet-50. In contrast to the compared models in <ref type="bibr" target="#b28">[21]</ref>, which use the ImageNet <ref type="bibr" target="#b69">[62]</ref> dataset for pre-training, our model is pre-trained on a small subset of ImageNet (i.e., the training classes of mini -ImageNet). As shown in <ref type="table">Table 5</ref>, though pre-trained on a smaller dataset, our UniSiam overall outperforms the previous self-supervised methods and the supervised baseline by a large margin. <ref type="table">Table 5</ref>: Average accuracy (%) of 5-way few-shot classification and 95% confidence interval on the BSCD-FSL dataset. The compared results are taken from <ref type="bibr" target="#b28">[21]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>In few-shot image classification, given a base dataset D base = {(x i , y i )}, the goal is to learn a pre-trained (or meta-) model that is capable of effectively solving the downstream few-shot task T , which consists of a support set S = {(x s , y s )} N * K s=1 for adaptation and a query set Q = {x q } Q q=1 for The overview of pre-training-&amp;-fine-tuning approach in FSL. (Left) In the pre-training stage, an encoder network is trained on a labeled (or unlabeled) base dataset with a supervised (or self-supervised) loss. (Right) In the fine-tuning stage, a linear classifier (e.g., logistic regression) is trained on the embeddings of a few support samples with the frozen pre-trained encoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>(a) SimCLR [8] for comparison. (b) Our UniSiam for self-supervised pretraining. (c) The architecture of our self-supervised knowledge distillation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Effect of network depth and image size. (a) Self-supervised methods have better scalability for network depth compared to supervised pre-training in FSL. (b) A larger image size improves the FSL performance of self-supervised methods. Note that unsupervised (unsup.) approaches perform pre-training on the base dataset without any labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Effect of data augmentation. Stronger data augmentation can substantially improve the performances of the selfsupervised pre-training compared to supervised pre-training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 :</head><label>6</label><figDesc>Singular value spectrum of embedding space. The uniformity regularization alleviates the dimensional collapse under strong DA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Section 4.2) follows the practice in existing works. It includes RandomResizedCrop with scale in [0.2, 1.0], RandomHor-izontalFlip with probability 0.5, ColorJitter [79] of {brightness, contrast, saturation, hue} with probability 0.8 and strength {0.4,0.4,0.4,0.1}, grayscale with probability 0.2, and GaussianBlur with probability 0.5 and the std of Gaussian kernel in [0.1, 2.0]. The strong data augmentation (in Section 4.2) adds Ran-domVerticalFlip with probability 0.5 and RandAugment [17] to the default data augmentation. The image size is 224?224 unless specified.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>We estimate MI between two multivariate Gaussians with the component-wise correlation ? (see the supplementary materials for details). When the true MI is large, I N CE has a high bias compared with I M IN E . Our work employs another MI estimator I M IN E following recent progress in the MI neural estimation</figDesc><table><row><cell>7UXH0, IMINE INCE</cell><cell>Fig. 2:</cell></row><row><cell>0XWXDO,QIRUPDWLRQ</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>.</head><label></label><figDesc>The research was supported by NSFC No. 61872329, and by MindSpore [1] which is a new deep learning computing framework.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Alignment: the difference between representation of two views of the same sample should be minimized. Uniformity: the difference between representation of two different samples should be maximized.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">While larger models have better performance, training a smaller model is also meaningful since it can be more easily deployed in practical scenarios such as edge devices.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">UniSiam (Ours) 224 unsup</title>
		<idno>63.26?0.36 81.13?0.26</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">UniSiam+dist (Ours) 224 unsup</title>
		<idno>64.10?0.36 82.26?0.25</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">UniSiam (Ours) ResNet-18 (11.2M) 224 1</title>
		<idno>8G unsup. 65.18?0.39 82.28?0.29</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Unisiam+dist</surname></persName>
		</author>
		<idno>Ours) ResNet-18 (11.2M</idno>
		<imprint>
			<biblScope unit="page">224</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cc+rot</surname></persName>
		</author>
		<idno>25] WRN-28-10 (36.5M</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Unisiam</surname></persName>
		</author>
		<idno>Ours) ResNet-34 (21.3M) 224 3.6G unsup. 67.57?0.39 84.12?0.28</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Unisiam+dist</surname></persName>
		</author>
		<idno>Ours) ResNet-34 (21.3M) 224 3.6G unsup. 68.65?0.39 85.70?0.27</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Unisiam</surname></persName>
		</author>
		<idno>Ours) ResNet-50 (23.5M) 224 4.1G unsup. 69.11?0.38 85.82?0.27</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Unisiam+dist</surname></persName>
		</author>
		<idno>Ours) ResNet-50 (23.5M</idno>
		<imprint>
			<biblScope unit="page">224</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Associative alignment for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Afrasiyabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Lalonde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gagn?</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Assume, augment and learn: Unsupervised few-shot meta-learning via random labels and data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<idno>arxiv:1902.09884</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baratin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajeshwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hjelm</surname></persName>
		</author>
		<title level="m">Mutual information neural estimation. In: ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Transductive information maximization for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Boudiaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">I</forename><surname>Masud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dolz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Piantanida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A unifying mutual information view of metric learning: Cross-entropy vs. pairwise losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Boudiaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">I</forename><surname>Masud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pedersoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Piantanida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.02803</idno>
		<title level="m">Intriguing properties of contrastive losses</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A closer look at few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04297</idno>
		<title level="m">Improved baselines with momentum contrastive learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Exploring simple siamese representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04390</idno>
		<title level="m">A new meta-baseline for few-shot learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Pareto self-supervised training for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Image deformation meta-networks for one-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Shot in the dark: Few-shot learning with no base-class labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CVPRW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Dhamija</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schwan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jafarzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Boult</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.07848</idno>
		<title level="m">Selfsupervised features improve open-world learning</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Diversity with cooperation: Ensemble methods for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dvornik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">How well do self-supervised models transfer?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ericsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gouk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.13377</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Metalearning with warped gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Flennerhag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Visin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Self-supervised training enhances online continual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gallardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>BMVC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Boosting few-shot visual learning with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Bootstrap your own latent: A new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Valko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A broader study of cross-domain few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Karlinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rosing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>AISTATS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<title level="m">Distilling the knowledge in a neural network</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Unsupervised learning via meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Understanding dimensional collapse in contrastive self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Unsupervised meta-learning for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khodadadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Boloni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Unsupervised meta-learning through latent-space interpolation in generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khodadadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zehtabian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vahidian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Boloni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">On episodes, prototypical networks, and few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laenen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bertinetto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning representations for automatic colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shakhnarovich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Meta-gmvae: Mixture of gaussian vae for unsupervised meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">One-shot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pietro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Adversarial feature hallucination networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Self-organization in a perceptual network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Linsker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Negative margin matters: Understanding margin in few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Prompt distribution learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Charting the right manifold: Manifold mixup for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mangla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Balasubramanian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>WACV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Self-supervised prototypical transfer learning for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Devos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grossglauser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICMLW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">A simple neural attentive meta-learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohaninejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<title level="m">Representation learning with contrastive predictive coding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Tadam: Task dependent adaptive metric for improved few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Oreshkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>L?pez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Self-training for few-shot transfer across extreme task differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Phoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.07734</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">On variational bounds of mutual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tucker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Unsupervised few-shot learning via distribution shift-based augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<idno>arxiv:2004.05805</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Neural network classifiers as mutual information evaluators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gedeon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICMLW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.00676</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Imagenet large scale visual recognition challenge. IJCV</note>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Delta-encoder: an effective sample synthesis method for few-shot object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Karlinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shtok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Understanding the limitations of variational mutual information estimators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">When does self-supervision improve few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Contrastive multiview coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Contrastive representation distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Rethinking few-shot image classification: a good embedding is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Understanding self-supervised learning dynamics without contrastive pairs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.06810</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">On mutual information maximization for representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Rubenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lucic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Prevalence of neural collapse during the terminal phase of deep learning training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vardan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Donoho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>PNAS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Mutual information gradient estimation for representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Improving generalization via scalable neighborhood component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros1</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Unsupervised feature learning via nonparametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Free lunch for few-shot learning: Distribution calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Few-shot learning via embedding adaptation with set-to-set functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zbontar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Deny</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.03230</idno>
		<title level="m">Barlow twins: Self-supervised learning via redundancy reduction</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Binocular mutual learning for improving few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Unisiam</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">92</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Unisiam</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">45</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
