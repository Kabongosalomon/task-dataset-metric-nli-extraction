<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Decoupling Makes Weakly Supervised Local Feature Better</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunhong</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sen University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">The Shenzhen Campus of Sun Yat-Sen University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Longguang</forename><surname>Wang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">National University of Defense Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">National University of Defense Technology</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">University of Oulu</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Ran</surname></persName>
							<affiliation key="aff4">
								<orgName type="laboratory">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Xu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">National University of Defense Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Sen University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">The Shenzhen Campus of Sun Yat-Sen University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">National University of Defense Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Decoupling Makes Weakly Supervised Local Feature Better</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Weakly supervised learning can help local feature methods to overcome the obstacle of acquiring a large-scale dataset with densely labeled correspondences. However, since weak supervision cannot distinguish the losses caused by the detection and description steps, directly conducting weakly supervised learning within a joint training describethen-detect pipeline suffers limited performance. In this paper, we propose a decoupled training describe-then-detect pipeline tailored for weakly supervised local feature learning. Within our pipeline, the detection step is decoupled from the description step and postponed until discriminative and robust descriptors are learned. In addition, we introduce a line-to-window search strategy to explicitly use the camera pose information for better descriptor learning. Extensive experiments show that our method, namely PoSFeat (Camera Pose Supervised Feature), outperforms previous fully and weakly supervised methods and achieves state-ofthe-art performance on a wide range of downstream task. * Corresponding author: Yulan Guo (guoyulan@sysu.edu.cn). Codes: https://github.com/The-Learning-And-Vision-Atelier-LAVA/PoSFeat. (a) DISK-W, a DISK model [46] trained with weak supervision (b) PoSFeat (ours)</p><p>Motivated by the success of deep learning, many efforts <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b49">50]</ref> have been made to replace the detection or description step in the detect-then-describe pipeline with CNNs. Recent works <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b45">46]</ref> find that keypoints and descriptors are interdependent and propose a joint training describe-then-detect pipeline. Specifically, the description network and detection network are combined into a single CNN and optimized jointly. The joint training describethen-detect pipeline achieves better performance than the detect-then-describe pipeline, especially under challenging conditions <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b44">45]</ref>. However, these methods are fully supervised and rely on dense ground-truth correspondence labels for training.</p><p>Because collecting a large dataset with pixel-level ground-truth correspondences is expensive, self-supervised and weakly supervised learning are investigated for training. Specifically, DeTone et al.</p><p>[12] used a single im-age and a virtual homography to generate image pairs to conduct self-supervised learning. However, homography transformation cannot cover complicated geometry transformations in real-world settings, resulting in limited performance. Noh et al. <ref type="bibr" target="#b29">[30]</ref> used landmark labels to train the local feature network, which suffers extremely poor performance on viewpoint changes. Owing to the convenience of collecting camera poses, Wang et al. <ref type="bibr" target="#b46">[47]</ref> introduced camera poses as weak supervision for descriptor learning. Although weakly supervised learning achieves promising results within the detect-then-describe pipeline, directly applying it to the joint training describe-then-detect pipeline is hard to produce satisfying results <ref type="bibr" target="#b45">[46]</ref>.</p><p>When a detection network and a description network are jointly optimized within a joint training describe-thendetect pipeline with only weak supervision (e.g., camera pose), the loss produced by these two components cannot be distinguished. Specifically, when only one component is failed <ref type="figure">(Fig. 2)</ref>, both the detection network and the description network cannot be correctly updated within a joint training describe-then-detect pipeline. As a result, the description network is hard to produce highly discriminative descriptors, and the detection network may produce false detected keypoints that are out of object boundaries, as shown in <ref type="figure">Fig. 1</ref>.</p><p>In this paper, we propose a decoupled training describethen-detect pipeline tailored for weakly supervised local feature learning. Our main insight is that, with only weak supervision, the detection network relies heavily on a good descriptor for accurate keypoint detection <ref type="figure">(Fig. 1)</ref>. Consequently, we decouple the detection network from the description network to postpone it until a discriminative and robust descriptor is learned. Different from the detect-thendescribe pipeline that relies on low-level structures for early detection, our keypoints detection depends on the higherlevel structures encoded in the descriptors. As a result, better robustness is achieved. In contrast to the joint training describe-then-detect pipeline that simultaneously perform detection and description optimization, the two networks are trained separately and thus the loss function for these two components are decoupled to address the ambiguity. It is demonstrated that our decoupled training describe-thendetect pipeline facilitates local feature methods to achieve much better performance with only weak supervision. Our contributions can be summarized as:</p><p>(1) We introduce a decoupled training describe-thendetect pipeline for weakly supervised local feature learning. This simple yet efficient pipeline significantly improves the performance of weakly supervised local features.</p><p>(2) We propose a line-to-window search strategy to exploit the weak supervision of camera poses for descriptor learning. This strategy can make full use of the geometric information of camera poses to reduce the search space and</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Finding pixel correspondences is a fundamental problem in computer vision. Sparse local feature <ref type="bibr">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b47">48]</ref>, as one of the mainstream methods to find correspondences, has been widely applied in many areas, such as simultaneous localization and mapping (SLAM) <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b51">52]</ref>, structure from motion (SfM) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b39">40]</ref>, and visual localization <ref type="bibr">[7,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b50">51]</ref>.</p><p>Traditional sparse local feature methods <ref type="bibr">[5,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b35">36]</ref> follow a detect-then-describe pipeline. Specifically, keypoints are first detected and then patches centered at these keypoints are used to generate descriptors. Early methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22]</ref> focus on the detection step and are proposed to distinguish distinctive areas to detect good keypoints. Later works pay more attention to the description step and make attempts to design powerful descriptors using advanced representations <ref type="bibr">[5,</ref><ref type="bibr">8,</ref><ref type="bibr" target="#b35">36]</ref>. <ref type="bibr">Figure</ref> 1. An illustration of the influence of ambiguity for weakly supervised local feature methods. Keypoints that succeed and fail to create landmarks are shown. (a) With joint training describethen-detect pipeline, DISK-W <ref type="bibr" target="#b45">[46]</ref> produces inaccurate keypoints that are out of the objects. (b) With our decoupled training describe-then-detect pipeline, PoSFeat can produce more reasonable keypoints. Best viewed in color. <ref type="figure">Figure 2</ref>. Motivation of decoupling. Two reasonable keypoints can be matched incorrectly due to the low discriminativeness of descriptors (e.g., caused by repetitive textures). Meanwhile, two false detected keypoints can also be matched with a high descriptor similarity. Best viewed in color. learn highly discriminative descriptors.</p><p>(3) Our method achieves state-of-the-art performance on three datasets and largely closes the gap between fully and weakly supervised methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Fully Supervised Local Feature Methods</head><p>Fully supervised methods conduct local feature learning using pixel-level ground-truth correspondences to provide supervision. Following the detect-then-describe pipeline, early learning-based methods <ref type="bibr">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b43">44]</ref> use CNNs to perform the detection or description steps. Specifically, QuadNet <ref type="bibr" target="#b38">[39]</ref> and Key.Net <ref type="bibr">[4]</ref> were proposed to use CNNs for keypoint detection. HardNet <ref type="bibr" target="#b26">[27]</ref> and SOSNet <ref type="bibr" target="#b43">[44]</ref> were developed to leverage CNNs to extract descriptors. Later, LIFT <ref type="bibr" target="#b49">[50]</ref> and LFNet <ref type="bibr" target="#b30">[31]</ref> were introduced to integrate both detection and description steps into an end-to-end architecture to achieve better performance. Note that, LIFT <ref type="bibr" target="#b49">[50]</ref> also introduced a decoupled training to address unstable training issue with full supervision in a detect-then-describe pipeline.</p><p>Recent works <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b45">46]</ref> follow a joint training describe-then-detect pipeline in which detection and description are combined into a single CNN and optimized jointly. Specifically, Dusmanu et al. <ref type="bibr" target="#b12">[13]</ref> first used a CNN to extract dense features and then selected local maxima of the dense feature map as keypoints. Revaud et al. <ref type="bibr" target="#b33">[34]</ref> further took both the repeatablity and reliability of the descriptors into consideration for better keypoint detection. Tyszkiewicz et al. <ref type="bibr" target="#b45">[46]</ref> used policy gradient to address the discreteness during the selection of sparse keypoints (namely, DISK). Luo et al. <ref type="bibr" target="#b23">[24]</ref> adopted deformable convolution to model the geometry information and detected keypoints at multiple scales. By jointly optimizing the detection network and the description network, joint training describe-then-detect pipeline achieves better performance than previous detect-then-describe pipeline.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Self-Supervised Local Feature Methods</head><p>As a large dataset with densely labeled correspondences is difficult to collect, self-supervised learning has been studied for local feature learning. Specifically, DeTone et al. <ref type="bibr" target="#b11">[12]</ref> used a virtual homography to generate an image pair from a single image to conduct self-supervised learning. This method uses a CNN pretrained on synthetic data as a teacher of the detection network. Differently, Christiansen et al. <ref type="bibr" target="#b10">[11]</ref> proposed an end-to-end framework to train both the detection network and the description network using virtual homography in a self-supervised manner. Later, Parihar et al. <ref type="bibr" target="#b31">[32]</ref> leveraged the homography to enhance the robustness of descriptors to rotation. Nevertheless, simple homography transformations used in these self-supervised methods may not hold in real cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Weakly Supervised Local Feature Methods</head><p>Noh et al. introduced DELF <ref type="bibr" target="#b29">[30]</ref>, which is trained with an image retrieval task, to achieve local feature extraction. However, the keypoints detected by DELF are sensitive to vierwpoint changew and thus cannot be applied in real world settings. For camera poses are easy to collect, Wang et al. <ref type="bibr" target="#b46">[47]</ref> used them as weak supervision and introduced an epipolar loss for descriptor learning. This method follows a detect-then-describe pipeline and relies on an off-the-shelf detection method (e.g., SIFT) to detect keypoints. Recently, Tyszkiewicz et al. <ref type="bibr" target="#b45">[46]</ref> developed DISK-W to integrate weakly supervised learning in a joint training describe-then-detect pipeline by adopting policy gradient. Nevertheless, when DISK-W is directly trained with a weakly supervised loss (rather than a fully-supervised loss), it suffers a notable performance drop on pixel-wise metrics. As weakly supervised loss cannot distinguish between errors introduced by false keypoints and inaccurate descriptors, this ambiguity hinders the joint training describe-thendetect pipeline to learn good local features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Learning-based Matcher Methods</head><p>Since a Brute Force Matcher (also named NN matcher) usually produces low quality raw matches, learning-based matchers are proposed to achieve better matching results. Sarlin et al. <ref type="bibr" target="#b36">[37]</ref> proposed SuperGlue to achieve robust matching with a graph neural network (GNN) and an optimal transport algorithm. Chen et al. <ref type="bibr">[10]</ref> improved the architecture of GNN to increase the efficiency of descriptor enhancement. Zhou et al. <ref type="bibr" target="#b52">[53]</ref> proposed a weakly supervised network to refine raw matches using patch matches as prior. Sun et al. <ref type="bibr" target="#b41">[42]</ref> introduced a detector-free matcher to achieve pixel correspondence in a coarse-to-fine manner. Note that, most matcher methods are not the direct competitors of local feature methods. Instead, they can be considered as a post processing step and combined with local features to achieve improved performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Decoupled Training Describe-then-Detect Pipeline</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overview</head><p>The decoupled training describe-then-detect pipeline is shown in <ref type="figure" target="#fig_1">Fig. 3</ref>. We train the description net and detection net individually to suppress the loss ambiguity caused by weak supervision. During training, we first leave out the detection network and optimize the description network to learn good descriptors with a line-to-window strategy. The description network is then frozen to train a detection network for keypoint detection. We follow CAPS <ref type="bibr" target="#b46">[47]</ref> to use ResUNet as the description net, which produces a feature map with 1/4 resolution and 128 dimensions as dense descriptors. Additionally, we design a shallow detection net to detect keypoints at the original resolution. For more details about the network architecture, please refer to the supplementary material.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Feature Description</head><p>Following the widely used paradigm <ref type="bibr" target="#b46">[47]</ref>, we impose supervision only on sparse query points sampled from paired images to conduct training of the description network. We first split an image into small grids of size g d ? g d , and randomly sample one point per grid as a query point. Then, we translate relative camera pose into an epipolar constraint and introduce a line-to-window search strategy to reduce search space (Sec. 3.2.1). Moreover, we formulate a loss function by encouraging the predicted matches to obey the epipolar constraint (Sec. 3.2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Line-to-Window Search</head><p>Given a query point x in the query image I 1 , our goal is to find its correspondence in the reference image I 2 . Since repetitive structures widely exist in a natural image, the commonly used coarse-to-fine strategy <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b46">47]</ref> usually selects a mismatched patch such that inferior performance is produced ( <ref type="figure" target="#fig_3">Fig. 4(a)</ref>). Intuitively, the correspondence of the query point x is constrained in an epipolar line in the reference image. Therefore, we introduce a line-to-window search strategy to reduce search space for better performance. Our line-to-window search strategy consists of two search steps, as illustrated in <ref type="figure" target="#fig_3">Fig. 4(b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search along An Epipolar Line.</head><p>For a query point x i ? I 1 , we first calculate its corresponding epipolar line L xi in the reference image I 2 based on the relative camera pose. Then, we uniformly sample N line points along this epipolar line to formulate the search space Y line = {y j i }(j = 1, ..., N line ). Next, we calculate the matching probability of x i over Y line :</p><formula xml:id="formula_0">P (y j i |F 1 (x i ), F 2 (Y line )) = exp(F 1 (x i ) T F 2 (y j i )) Y line exp(F 1 (x i ) T F 2 (y k i )) ,<label>(1)</label></formula><p>where F 1 and F 2 are the feature maps for I 1 and I 2 , respectively. Afterwards, we select y i with the maximum prob-ability from Y line to determine the coarse location of the correspondence of x i :</p><formula xml:id="formula_1">y i = arg max y j i P (y j i |F 1 (x i ), F 2 (Y line )).<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search in A Local Window.</head><p>Due to the discreteness of the candidates in Y line , the resultant corresponding point y i can be far from the groundtruth. To remedy this, a subsequent search is conducted in a local window. First, we calculate the center of the local window:</p><formula xml:id="formula_2">y center i = y i + 0.5 ? w patch ? u,<label>(3)</label></formula><p>where w patch is the window size of a local patch, u ? R 2 is a noise vector drawn from a uniform distribution U(0, 1) to avoid the convergence to trivial solution F (x) ? 0. Then, a local patch Y patch ? I 2 centered at y center i is cropped from F 2 as the search space. Next, we calculate the matching probability of x i over Y patch :</p><formula xml:id="formula_3">P (y j i |F 1 (x i ), F 2 (Y patch )) = exp(F 1 (x i ) T F 2 (y j i )) Y patch exp(F 1 (x i ) T F 2 (y k i ))</formula><p>.</p><p>(4) Because directly selecting the point with the maximum probability in the local patch is non-differentiable, we calculate the correspondence? i in a differentiable manner:</p><formula xml:id="formula_4">y i = E(y j i ) = y j i ?Y patch y j i ? P (y j i |F 1 (x i ), F 2 (Y patch )).</formula><p>(5) Compared to the previous coarse-to-fine search strategy <ref type="bibr" target="#b46">[47]</ref>, our line-to-window search strategy can make better use of the camera pose information to reduce search space and further improve the discriminativeness of descriptors (as demonstrated in Sec. 4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Loss Function</head><p>With only weak supervision of camera pose, we calculate the distance of the correspondence? i to the epipolar line L xi as the loss of query point x i <ref type="bibr" target="#b46">[47]</ref>:</p><formula xml:id="formula_5">L epi (? i , x i ) = distance(? i , L xi ).<label>(6)</label></formula><p>Then, we use the weighted sum of the losses over all query points as the final loss:</p><formula xml:id="formula_6">L desc = i Mi ?(xi) ? L epi (? i , x i ) i Mi ?(xi) .<label>(7)</label></formula><p>Here, M i is a binary mask (which is used to exclude query points whose epipolar lines are not in the reference image) and ?(x i ) is the variance of the probability distribution over</p><formula xml:id="formula_7">Y patch , ?(x i ) = ?? 2 i ? E(y j2 i )? (8)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Feature Detection</head><p>After feature description learning, the description network is frozen to produce dense descriptors for keypoint detection, as shown in <ref type="figure" target="#fig_1">Fig. 3</ref>. Since selecting discrete sparse keypoints is non-differentiable, we adopt the strategy introduced in DISK <ref type="bibr" target="#b45">[46]</ref>, which is based on policy gradient, to achieve network training.</p><p>First, dense descriptors F 1 and F 2 are respectively extracted from I 1 and I 2 , and fed to a detection network to produce keypoint heatmaps. Then, we divide these heatmaps into grids of size g k ? g k and select at most one keypoint from each grid cell. Specifically, we establish a probability distribution P kp over each grid cell based on the heatmap scores in this cell. Afterwards, P kp is used to probabilistically select candidate keypoints Q 1 = {x 1 , x 2 , ? ? ? } and Q 2 = {y 1 , y 2 , ? ? ? } from I 1 and I 2 , respectively. Next, a matching probability P m is calculated based on the feature similarity S i,j between each pair of candidate keypoints (x i , y j ). With only camera pose supervision, we adopt an epipolar reward similar to Eq. 6 to encourage y j to be close to the epipolar line of x i (i.e., L xi ):</p><formula xml:id="formula_8">R(x i , y j ) = ? p , if distance(y j , L xi ) ? ? ? n , if distance(y j , L xi ) &gt; ? ,<label>(9)</label></formula><p>where the reward threshold ? is empirically set to 2. The overall loss function is defined as:</p><formula xml:id="formula_9">L kp = ? 1 |Q 1 | + |Q 2 | xi,y j L rew (x i , y j ) + ? reg xi log P kp (x i ) + y j log P kp (y j ) ,<label>(10)</label></formula><p>where ? reg is a regularization penalty and the reward loss L rew (x i , y j ) is defined as:</p><formula xml:id="formula_10">L rew (x i , y j ) = P m (x i , y j )?R(x i , y j )?log(P kp (x i )P kp (y i )).</formula><p>(11) Since our descriptors are well optimized, P m can suppress spurious points with low scores. In contrast, in a joint pipeline, descriptors are under-optimized such that spurious points cannot be well distinguished. Please refer to the supplementary material for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Settings</head><p>Datasets The MegaDepth dataset <ref type="bibr" target="#b20">[21]</ref> was used for training. We used a subset of the training split of CAPS <ref type="bibr" target="#b46">[47]</ref>. Totally, 127 out of 196 scenes were used as the training set. Implementation Details During the training phase, images were resized to 640?480 with breaking the aspect ratio. All networks were trained using a SGD optimizer with nesterov momentum <ref type="bibr" target="#b42">[43]</ref>. The learning rate is set to 1 ? 10 ?3 and the batch size was set to 6. The description network was trained for 100,000 iterations, and the detection network was trained for 5,000 iterations. All experiments were conducted using Pytorch on a single NVIDIA RTX3090 GPU.</p><p>In our experiments, the number of sampled points N line was set to 100, the window size w patch was set to 0.1 (normalized height and width), and the grid size g d and g k were set to 16 and 8, respectively. Following <ref type="bibr" target="#b45">[46]</ref>, ? p , ? n , and ? reg were set to 1, -0.25, and -0.001, respectively. For more details, please refer to the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison with Previous Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Feature Matching</head><p>Settings. We first evaluate our method on the widely used HPatches dataset <ref type="bibr">[3]</ref>.Following D2-Net <ref type="bibr" target="#b12">[13]</ref>, 8 highresolution scenes are removed and the remaining 52 scenes with illumination changes and 56 scenes with viewpoint changes are included for evaluation. Mean matching accuracy (MMA) <ref type="bibr" target="#b12">[13]</ref> with thresholds ranging from 1 to 10 is used for evaluation. We also use a weighted sum of MMA at different thresholds for overall evaluation:</p><formula xml:id="formula_11">MMAscore = thr?[1,10] (2 ? 0.1 ? thr) ? MMA@thr thr?[1,10] (2 ? 0.1 ? thr)</formula><p>.</p><p>(12) Three families of methods are included for comparison:</p><p>? Patch-based methods: Hessian-Affine keypoints <ref type="bibr" target="#b25">[26]</ref> with Root-SIFT <ref type="bibr">[2]</ref> (Hes. Aff. + Root-SIFT), affine region detector HesAffNet <ref type="bibr" target="#b27">[28]</ref> with HardNet++ <ref type="bibr" target="#b26">[27]</ref> (HAN + HN++), and SIFT <ref type="bibr" target="#b21">[22]</ref> with ContextDesc <ref type="bibr" target="#b22">[23]</ref> (SIFT + ContextDesc).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MMAscore Overall</head><p>MMAscore Illumination MMAscore Viewpoint Hes. Aff. + Root-SIFT <ref type="bibr">[2]</ref> 0.584 0.544 0.624 HAN [28] + HN++ <ref type="bibr" target="#b26">[27]</ref> 0.633 0.634 0.633 SIFT <ref type="bibr" target="#b21">[22]</ref> + ContextDesc <ref type="bibr" target="#b22">[23]</ref> 0.636 0.613 0.657 D2Net <ref type="bibr" target="#b12">[13]</ref> 0.519 0.605 0.440 R2D2 <ref type="bibr" target="#b33">[34]</ref> 0.695 0.727 0.665 ASLFeat <ref type="bibr" target="#b23">[24]</ref> 0.739 0.795 0.687 DISK <ref type="bibr" target="#b45">[46]</ref> 0.763 0.813 0.716 DELF <ref type="bibr" target="#b29">[30]</ref> 0.571 0.903 0.262 SuperPoint <ref type="bibr" target="#b11">[12]</ref> 0.658 0.715 0.606 SIFT <ref type="bibr" target="#b21">[22]</ref>  ? Fully supervised dense feature methods: D2-Net <ref type="bibr" target="#b12">[13]</ref>, R2D2 <ref type="bibr" target="#b33">[34]</ref>, ASLFeat <ref type="bibr" target="#b23">[24]</ref>, and DISK <ref type="bibr" target="#b45">[46]</ref>.</p><p>? Weakly supervised dense feature methods: DELF <ref type="bibr" target="#b29">[30]</ref>, SuperPoint <ref type="bibr" target="#b11">[12]</ref>, DISK-W <ref type="bibr" target="#b45">[46]</ref>, and SIFT with CAPS <ref type="bibr" target="#b46">[47]</ref> (SIFT + CAPS).</p><p>Results. As shown in <ref type="figure">Fig. 5</ref> and <ref type="table">Table 1</ref>, the proposed PoSFeat outperforms all previous works, with the highest MMAscore being achieved. Compared to existing weakly supervised methods, our method produces significant performance improvements. Specifically, our method outper-forms DISK-W by notable margins under both illumination (0.826 vs. 0.803) and viewpoint (0.728 vs. 0.649) changes, and therefore achieves higher overall MMAscore (0.775 vs. 0.719). We also visualize the matching results in <ref type="figure">Fig. 6</ref>.</p><p>It can be seen that our PoSFeat produces more reasonable keypoints and less wrong matches. Compared to fully supervised methods, our method still performs favorably with higher MMA scores. This clearly demonstrates the superiority of our method. Note that, because DELF detects keypoints in a low resolution feature map with a fixed grid, it produces the best results under illumination change. However, our method significantly surpasses DELF under viewpoint change (0.728 vs. 0.262) and achieves much better overall performance (0.775 vs. 0.571).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Visual Localization</head><p>Settings. We then evaluate our method on the visual localization task with the Aachen Day-Night dataset <ref type="bibr" target="#b50">[51]</ref>.We adopt the official visual localization pipeline <ref type="bibr" target="#b0">1</ref>   <ref type="table">Table 2</ref>. Results achieved by different methods on the Aachen Day-Night dataset <ref type="bibr" target="#b50">[51]</ref>. 'LISRD' represents LISRD with Super-Point keypoints and AdaLAM <ref type="bibr">[9]</ref>. Two categories of methods are presented, including feature methods (top) and matchers (bottom).</p><p>(0.5m, 2 ? ), (1m, 5 ? ), and (5m, 10 ? ). We compare our method with two families of methods:</p><p>? Local feature methods: D2-Net <ref type="bibr" target="#b12">[13]</ref>, SuperPoint <ref type="bibr" target="#b11">[12]</ref>, R2D2 <ref type="bibr" target="#b33">[34]</ref>, ASLFeat <ref type="bibr" target="#b23">[24]</ref>, ISRF <ref type="bibr" target="#b24">[25]</ref>, and LISRD <ref type="bibr" target="#b32">[33]</ref>.</p><p>? Matcher methods: DualRC-Net <ref type="bibr" target="#b19">[20]</ref>, SuperGlue <ref type="bibr" target="#b36">[37]</ref> + SuperPoint, SparseNCNet <ref type="bibr" target="#b34">[35]</ref>, LoFTR <ref type="bibr" target="#b41">[42]</ref>, Patch2Pix <ref type="bibr" target="#b52">[53]</ref>, and SGMNet [10] + SuperPoint. As mentioned in Sec 2.4, matchers are the cooperators instead of the direct competitors of local features. Therefore, we group them separately.</p><p>Results. As shown in <ref type="table">Table 2</ref>, our PoSFeat achieves the state-of-the-art performance among the feature methods. Specifically, on Aachen Day-Night v1, our method achieves the best accuracy in terms of all metrics. Note that, although ASLFeat is a fully supervised method, our PoSFeat still outperforms it on (1m, 5 ? ). On Aachen Day-Night v1.1, our method also produces the best performance in all metrics. Note that, although R2D2 <ref type="bibr" target="#b33">[34]</ref>, ISRF <ref type="bibr" target="#b24">[25]</ref>, and LISRD <ref type="bibr" target="#b32">[33]</ref> are fully-supervised and trained on the Aachen Day-Night dataset, our PoSFeat still achieves better results. We additionally include matcher methods for further comparison. Although these methods take pairs of images as inputs, our PoSFeat achieves comparable or even better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">3D Reconstruction</head><p>Settings. We finally evaluate our method on the 3D reconstruction task. We conduct experiments on the ETH local feature benchmark <ref type="bibr" target="#b40">[41]</ref>. Four metrics are used for evaluation, including the number of registered images (# Imgs), the number of sparse points (# Pts), track length, and the mean reprojection error (Reproj. Err.). Four families of methods were included for comparison:</p><p>? Patch-based method: Root-SIFT <ref type="bibr">[2,</ref><ref type="bibr" target="#b21">22]</ref>.  <ref type="table">Table 3</ref>. Results achieved by different methods on the ETH local feature benchmark.</p><p>? Fully supervised dense feature methods: Reinforced Feature Points <ref type="bibr">[6]</ref> (RFP), DISK <ref type="bibr" target="#b45">[46]</ref>, DISK-W <ref type="bibr" target="#b45">[46]</ref>, D2-Net <ref type="bibr" target="#b12">[13]</ref>, and ASLFeat <ref type="bibr" target="#b23">[24]</ref>. ? Weakly supervised dense feature methods: Super-Point <ref type="bibr" target="#b11">[12]</ref> and CAPS <ref type="bibr" target="#b46">[47]</ref>. ? Fully supervised matcher method: CoAM <ref type="bibr" target="#b48">[49]</ref>. <ref type="table">Table 3</ref>, our method performs favorably against previous methods on the 3D reconstruction task. Specifically, our method produces the lowest reprojection error among all learning-based methods. Moreover, our method achieves the best or second best performance in terms of track length, which demonstrates that our keypoints are robust and thus can be tracked across a large amount of images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results. As shown in</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>In this section, we first conduct ablation experiments on the HPatches dataset <ref type="bibr">[3]</ref> to demonstrate the effectiveness of our decoupled training describe-then-detect pipeline and line-to-window search strategy. Then, we conduct experiments to study the effectiveness of hyper-parameters in our method, i.e., the number of points sampled from the epipolar line N line and the window size w patch . Results and model settings are shown in <ref type="figure">Fig. 7</ref> and <ref type="table">Table 4</ref>. Decoupled Training Describe-then-Detect Pipeline. We first constructed a network variant (Model 2) following the joint training describe-then-detect pipeline. That is, the description network and the detection network are jointly op-  <ref type="figure">Figure 7</ref>. Ablation results on HPatches. "L2W" denotes our line-to-window search strategy (illustrated in <ref type="figure" target="#fig_3">Fig 4(b)</ref>) and "C2F" denotes the coarse-to-fine search strategy <ref type="bibr" target="#b46">[47]</ref> (illustrated in <ref type="figure" target="#fig_3">Fig 4(a)</ref>). "learned" means that the keypoints are generated by a detection network and "SIFT" mean that SIFT keypoints (OpenCV default settings) are used. "decoupled" means the proposed decoupled training pipeline is adopted and 'joint' means the description network and the detection network are jointly optimized.</p><p>timized. Then, we developed Model 3 based on the detectthen-describe pipeline. Specifically, the description network is combined with SIFT keypoints in Model 3. As shown in <ref type="figure">Fig. 7</ref>, with only weak supervision, the ambiguity during optimization limits the performance of joint training describe-then-detect approaches (Model 2 and DISK-W). Moreover, Model 2 is even inferior to Model 3 under viewpoint change. Compared to Models 2 and 3, Model 1 with our decoupled training describe-thendetect pipeline produces much higher accuracy. This clearly demonstrates that our decoupled training describe-thendetect pipeline is well suitable to weakly supervised learning to achieve superior performance.</p><p>We further test different combinations of keypoints and descriptors (Models 5-8). It can be observed that the improvement mainly comes from the descriptor, and the keypoints are slightly improved on the viewpoint change. Besides, we also illustrate the keypoints produced by our method and DISK-W in <ref type="figure" target="#fig_5">Fig. 1</ref>. DISK-W generates considerable inaccurate keypoints out of objects (e.g., in the sky). In contrast, our model detects more reasonable keypoints. That is because those mismatched descriptors and  <ref type="table">Table 4</ref>. MMAscore achieved by our description network with different values of N line and w patch on the HPatches dataset. erroneous keypoints produced from two different components do not influence each other within our decoupled training describe-then-detect pipeline. Line-to-Window Search Strategy. To validate the effectiveness of our line-to-window search strategy, we developed a network variant (Model 4) by replacing our search strategy with a coarse-to-fine one (as proposed in <ref type="bibr" target="#b46">[47]</ref>, illustrated in <ref type="figure" target="#fig_3">Fig. 4(a)</ref>). For fair comparison with Model 3, SIFT keypoints are employed in this network variant. It can be observed that Model 3 outperforms Model 4 by significant margins. That is because, our line-to-window search strategy can make full use of the geometry information of camera poses to reduce the search space for accurate localization of correspondences. Consequently, higher accuracy can be achieved. Number of Sampled Points N line and Window Size w patch . We conduct experiments to study the effects of N line and w patch during our line-to-window search. More sampled points and a large window size are beneficial to the performance at the expense of higher computational cost. To achieve a trade-off between performance and computational complexity, w patch = 0.100 and N line = 100 are used as the default setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we introduce a decoupled training describe-then-detect pipeline tailored for weakly supervised local feature learning. Within our pipeline, the detection network is decoupled from the description network and postponed until discriminative and robust descriptors are obtained. In addition, we propose a line-to-window search strategy to explicitly use the camera pose information to reduce search space for better descriptor learning. Extensive experiments show that our method achieves the state-of-theart performance on three different evaluation frameworks and significantly closes the gap between fully-supervised and weakly supervised methods.  We first introduce the details of our model in Sec. 1 and discuss the query points generation during description network training in Sec. 2. Then, we expand the detection network training in Sec. 3. Next, we show detailed experimental settings in Sec. 4. After that, we give a discussion on the limitations and broader impact of our PoSFeat in Sec. 5. Finally, additional qualitative results are included in Sec. 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material for Decoupling Makes Weakly Supervised Local Feature Better</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Model Architecture</head><p>Our model consists of two parts, i.e. the description network and the detection network, as illustrated in <ref type="figure" target="#fig_5">Fig. 1</ref>. For description network, we adopts the ResUNet used in <ref type="bibr">[9]</ref>, which follows a widely used encoder-decoder architecture. We use a truncated ResNet-50 <ref type="bibr">[4]</ref> (pre-trained on ImageNet <ref type="bibr">[2]</ref>) as the encoder, and use several 3 ? 3 convolution layers combining with bilinear upsampling and residual connec-tion to construct the decoder. For detection network, we use a simple three-layer architecture. The first layer takes the original image and two feature maps from description network as inputs, and aggregate the original image and feature maps from description network for detection. For better aggregation of original image and feature maps, we use the instance normalization <ref type="bibr">[8]</ref> instead of batch normalization <ref type="bibr">[5]</ref> in our detection network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Query Points Generation in Description Network Training</head><p>We adopt grid-based random sampling to select query points for the training of description network to avoid the bias of pre-defined keypoints. When pre-defined keypoints (e.g. SIFT) are used to train the description network, the densities of SIFT keypoints in different areas vary a lot.  <ref type="figure">Figure 2</ref>. An illustration of pre-defined keypoints bias. We adopt PCA <ref type="bibr">[3]</ref> to visualize the descriptors of the original images (a). When the description network is trained with SIFT (b), there are insufficiently trained areas (black boxes), which leads to false keypoints detection. On the contrary. When the description network is trained with grid-based random sample (c), all the areas in the image will be sufficiently trained.</p><p>Consequently, areas with few SIFT keypoints are usually under optimized, as shown in <ref type="figure">Fig. 2</ref>. This bias limits the discriminativeness of the descriptors and leads to detection network produces considerable false keypoints detection.</p><p>To address this problem, we use grid-based random sampling to generate query points. Specifically, we first split the image into N g grids with the shape of g ? g. Then we uniformly select N g points with with one point in a grid. With this grid-based random sample strategy, the description network will be sufficiently trained in all areas, and thus detection network can produce more accurate keypoints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Detection Network Training</head><p>In this section, we present more details on the detection network training.</p><p>As described in the main paper, we first extract the feature maps F 1 and F 2 from a image pair I 1 and I 2 with the frozen description network. Then we feed F 1 and F 2 into the detection network to produce the keypoint heatmaps, and model the keypoint distributions based on the heatmaps. Specifically, we divide these heatmaps into grids and select at most one keypoint from each grid cell. For a pixel x in image I 1 , the probability that x is a keypoint can be formulated as,</p><formula xml:id="formula_12">P kp (x|F 1 ) = Softmax(F Gx 1 ) x ? Sigmoid(F 1 ) x ,<label>(1)</label></formula><p>in which F Gx 1 denotes the local heatmap of the grid cell that contains pixel x, Softmax(F Gx 1 ) x represents the local probability of x to be a keypoint, and Sigmoid(F 1 ) x represents the global probability of x to be a keypoint.</p><p>According to the keypoint probability distribution, we then select the candidate sets Q 1 = {x 1 , x 2 , ? ? ? |x i ? I 1 } and Q 2 = {y 1 , y 2 , ? ? ? |y i ? I 2 } to compute the similarity matrix S, whose elements are defined as,</p><formula xml:id="formula_13">S i,j = F 1 (x i ) ? F 2 (y j ) T , x i ? Q 1 y j ? Q 2 . (2)</formula><p>Afterwards, we can compute the matching probability P m according to the similarity matrix,</p><formula xml:id="formula_14">P m = Softmax(S) 1 ? Softmax(S) 2 ,<label>(3)</label></formula><p>in which Softmax(S) <ref type="bibr" target="#b0">1</ref> and Softmax(S) 2 denotes the softmax operation along the row and column, respectively. Next, we compute the rewards according to the epipolar constraints,</p><formula xml:id="formula_15">R(x i , y j ) = ? p , if distance(y j , L xi ) ? ? n , if distance(y j , L xi ) &gt; ,<label>(4)</label></formula><p>where the reward threshold is empirically set to 2. Since the description network is frozen and reliable, the matches with low matching probability are unreliable, and thus we further truncate the matching probability P m according to the reward to omit the false positive rewards for the unreliable matches. Specifically, we manually set P m (x i , y j ) = 0 for the pairs (x i , y j ) whose reward R(x i , y j ) = ? p and matching probability P m (x i , y j ) &lt; 0.9. Finally, we compute the loss for detection network,</p><formula xml:id="formula_16">L kp = ? 1 |Q 1 | + |Q 2 | xi,y j L rew (x i , y j ) + ? reg xi log P kp (x i ) + y j log P kp (y j ) ,<label>(5)</label></formula><p>where ? reg is a regularization penalty and the reward loss L rew (x i , y j ) is defined as:</p><formula xml:id="formula_17">L rew (x i , y j ) = P m (x i , y j )?R(x i , y j )?log(P kp (x i )P kp (y i )).<label>(6)</label></formula><p>Note that, the P m is truncated according to the rewards and thus the match pairs with positive rewards but low matching probability are left neutral.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Settings</head><p>In this section, we present the hyper-parameters of our method on different datasets. During inference, we apply non-maximum suppression (NMS) to detect keypoints, and use a mutual nearest neighbour matcher for matching. Instead of resizing the images, we crop the images from the top-left side to guarantee both the height and width of the images are divisible by 16.</p><p>HPatches Dataset <ref type="bibr" target="#b0">[1]</ref>. The NMS size is set to be 3?3 due to the existence of low-resolution images, and the maximum keypoint numbers are limited to be 8192. Aachen Day-Night Dataset <ref type="bibr">[10]</ref>. Because of the high image resolutions, the NMS size is set to be 7 ? 7 on the Aachen Day-Night dataset, and the maximum keypoint numbers are limited to be 16k. Note that, keypoints with scores smaller than 0.9 in the heatmaps are filtered out.</p><p>ETH Local Feature Benchmark <ref type="bibr">[7]</ref>. The NMS size is set to be 7 ? 7, and the maximum keypoints numbers are limited to be 20k. Keypoints with scores smaller than 0.9 in the heatmaps are also filtered out. We additionally applying ratio test during matching with a threshold 0.8 to achieve robust reconstruction.  <ref type="figure" target="#fig_3">Figure 4</ref>. The sparse 3D models of Aachen. These models are reconstructed using Colmap <ref type="bibr">[6]</ref> with features extracted by PoSFeat, and are further used to do night-time images localization. Note that these models are reconstructed based on the camera poses provided by the author of the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Limitations and Broader Impact</head><p>The PoSFeat suffers limited capability to deal with large rotation and scale changes. On the HPatches dataset, our PoSFeat produces limited performance on several scenes with pure rotation. On the ETH local feature benchmark, our PoSFeat cannot well handle the scenes with extreme scale changes thus has limited performance in #Imgs (e.g., only 419 images are registered in Mardrid Metropolis).</p><p>The PoSFeat is a general local feature method, although we only apply it with image matching, visual localization and 3D reconstruction in our paper, it can be easily extended to recognize or reconstruct human faces. Therefore, the researches and the applications about the recognition or reconstruction of human faces must strictly respect the personality rights and privacy regulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Visualization</head><p>We present some qualitative results in this section. The image matching results on HPatches are shown in <ref type="figure" target="#fig_1">Fig. 3</ref>. The 3D models of Aachen are illustrated in <ref type="figure" target="#fig_3">Fig. 4</ref>, which is reconstructed with the features extracted by PoSFeat, and is used to do visual localization on Aachen Day-Night dataset . And the 3D reconstruction results on ETH local feature benchmark are shown in <ref type="figure">Fig. 5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>L</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>The proposed decoupled training describe-then-detect pipeline. The detection network is decoupled from the description network and postponed until good descriptors are obtained.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>F2F</head><label></label><figDesc>Coarse-to-fine search (b) Line-to-window searchF2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>An illustration of the coarse-to-fine search strategy (a) and our line-to-window search strategy (b). The red line in F2 denotes the epipolar line corresponding to the query point in F1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .Figure 6 .</head><label>56</label><figDesc>Results achieved on the HPatches dataset[3]. Mean match accuracy (MMA) achieved at different thresholds are illustrated. Learning based methods with weak supervision are shown in solid lines while other methods are shown in dashed lines. The numbers of keypoints and matches for each method are also reported. Visualization results achieved on HPatches. For simplicity, only successfully matched keypoints are shown and colored according to their match errors. The colorbar is shown on the right. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 1 .</head><label>1</label><figDesc>Model architecture. The description network (a) and detection network (b) consist of several blocks, we report the scale and output channels of each block, and illustrate the details of each block in the bottom box.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 .</head><label>3</label><figDesc>Qualitative results on HPatches. The same as figures in main paper, only successfully matched keypoints are shown and colored according to their match errors. The colorbar is shown on the right. Best viewed in color.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>(</head><label></label><figDesc>b) Aachen Day-Night v1.1 (b) Aachen Day-Night v1.1 (a) Aachen Day-Night v1 (a) Aachen Day-Night v1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>[ 1 ]Figure 5 .</head><label>15</label><figDesc>Vassileios Balntas, Karel Lenc, Andrea Vedaldi, and Krystian Mikolajczyk. HPatches: A Benchmark and Evaluation of Handcrafted and Learned Local Descriptors. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2017. The sparse 3D reconstruction results on ETH local feature benchmark.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Loss for descriptors L desc Loss for descriptors L kp Loss for keypoints L</figDesc><table><row><cell>Keypoint Maps Keypoint Maps</cell><cell>Dense Descriptors Dense Descriptors</cell><cell>L desc</cell></row><row><cell></cell><cell>L desc L desc</cell><cell></cell><cell>kp</cell></row><row><cell>Description Net Description Net</cell><cell></cell><cell>Description Net</cell><cell>Detection</cell></row><row><cell></cell><cell></cell><cell>(frozen)</cell><cell>Net</cell></row><row><cell cols="2">Description Net Training</cell><cell></cell><cell>Detection Net Training</cell></row></table><note>kp Loss for keypoints</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>used in the local feature challenge of workshop on long-term visual localization under changing conditions. This challenge only evaluates the pose of night-time query images. Accuracy with different thresholds are used as metrics, including Method Aachen Day-Night v1Aachen Day-Night v1.1 (0.5m,2 ? ) (1m,5 ? ) (5m, 10 ? ) (0.5m,2 ? ) (1m,5 ? ) (5m, 10 ? )</figDesc><table><row><cell>SP [12] D2-Net [13] R2D2 [34] ASLFeat [24] ISRF [25] LISRD [33] PoSFeat (Ours)</cell><cell>74.5 74.5 76.5 81.6 --81.6</cell><cell>78.6 86.7 90.8 87.8 --90.8</cell><cell>89.8 100 100 100 --100</cell><cell>--71.2 -69.1 73.3 73.8</cell><cell>--86.9 -87.4 86.9 87.4</cell><cell>--97.9 -98.4 97.9 98.4</cell></row><row><cell>DualRC-Net [20]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>71.2</cell><cell>86.9</cell><cell>97.9</cell></row><row><cell>SP+SuperGlue [37]</cell><cell>79.6</cell><cell>90.8</cell><cell>100</cell><cell>73.3</cell><cell>88.0</cell><cell>98.4</cell></row><row><cell>Sparse-NCNet [35]</cell><cell>76.5</cell><cell>84.7</cell><cell>98.0</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>LoFTR [42]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>72.8</cell><cell>88.5</cell><cell>99.0</cell></row><row><cell>Patch2Pix [53]</cell><cell>79.6</cell><cell>87.8</cell><cell>100</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>SP+SGMNet [10]</cell><cell>77.6</cell><cell>88.8</cell><cell>99.0</cell><cell>72.3</cell><cell>85.3</cell><cell>97.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Kunhong Li 1,2 Longguang Wang 3 Li Liu 3,4 Qing Ran 5 Kai Xu 3 Yulan Guo 1,2,3 * 1 Sun Yat-Sen University 2 The Shenzhen Campus of Sun Yat-Sen University 3 National University of Defense Technology 4 University of Oulu 5 Alibaba Group</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ConvBlock 1_i 1, 64 ConvBlock 1_i 1, 64</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Img H?W?3</cell><cell></cell><cell>First layer First layer First layer</cell><cell>1/4, 64 1/4, 64 1/4, 64</cell><cell>Layer 1 Layer 1 Layer 1</cell><cell>1/4, 256 1/4, 256 1/4, 256</cell><cell>Layer 2 Layer 2 Layer 2</cell><cell>1/8, 512 1/8, 512 1/8, 512</cell><cell>Layer 3 Layer 3 Layer 3</cell><cell>1/16, 1024 1/16, 1024 1/16, 1024</cell><cell>UpBlock 2 UpBlock 2</cell><cell>1/8, 512 1/8, 512</cell><cell>UpBlock 1 UpBlock 1</cell><cell>1/4, 256 1/4, 256</cell><cell>Fine Conv Fine Conv Fine Conv</cell><cell>1/4, 128 1/4, 128 1/4, 128</cell><cell>L2 Norm L2 Norm L2 Norm</cell><cell cols="2">Desc H/4?W/4?128</cell><cell>C</cell><cell cols="2">ConvBlock 1_f 1/4, 128 ConvBlock 1_f 1/4, 128</cell><cell>Upsample ?4 Upsample ?4</cell><cell>C</cell><cell>ConvBlock 2 1/1, 128 2 1/1, 128 ConvBlock</cell><cell>OutBlock 1/1, 1 OutBlock 1/1, 1</cell><cell>Kpts H?W?1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">ResNet Encoder</cell><cell></cell><cell></cell><cell></cell><cell cols="3">Decoder</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">(a) Description Network</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">(b) Detection Network</cell></row><row><cell>C res C res C res</cell><cell></cell><cell></cell><cell></cell><cell cols="3">UpBlock UpBlock UpBlock</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Fine Conv Fine Conv Fine Conv</cell><cell></cell><cell></cell><cell cols="4">ConvBlock ConvBlock ConvBlock</cell><cell></cell><cell></cell><cell>OutBlock OutBlock OutBlock</cell></row><row><cell>C in C in C in</cell><cell>Upsample ?2 Upsample ?2 Upsample ?2 Upsample ?2</cell><cell>Conv 3?3 Conv 3?3 Conv 3?3 Conv 3?3</cell><cell>C in C in C in</cell><cell>C C C</cell><cell></cell><cell>Conv 3?3 Conv 3?3 Conv 3?3 Conv 3?3</cell><cell cols="2">C out C out C out</cell><cell>Batch Norm Batch Norm Batch Norm Batch Norm Batch Norm</cell><cell>ELU ELU ELU ELU ELU</cell><cell>C out C out C out</cell><cell cols="2">C in C in C in</cell><cell></cell><cell>Conv 3?3 Conv 3?3 Conv 3?3 Conv 3?3</cell><cell>Batch Norm Batch Norm Batch Norm Batch Norm</cell><cell>ELU ELU ELU ELU</cell><cell>C out C out C out</cell><cell>C in C in C in</cell><cell>Conv 3?3 Conv 3?3 Conv 3?3 Conv 3?3</cell><cell>Instance Instance Instance Instance</cell><cell>Norm Norm Norm Norm</cell><cell>PReLU PReLU PReLU PReLU</cell><cell>C out C out C out</cell><cell>C in C in C in</cell><cell>Conv 1?1 Conv 1?1 Conv 1?1 Conv 1?1</cell><cell>Instance Norm Instance Norm Instance Norm Instance Norm</cell><cell>SoftPlus SoftPlus SoftPlus SoftPlus</cell><cell>C out C out C out</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/tsattler/visuallocalizationbenchmark/tree/master/ local feature evaluation</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Building Rome in a Day</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasutaka</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Snavely</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="105" to="112" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Three Things Everyone Should Know to Improve Object Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Relja</forename><surname>Arandjelovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">HPatches: A Benchmark and Evaluation of Handcrafted and Learned Local Descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassileios</forename><surname>Balntas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karel</forename><surname>Lenc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krystian</forename><surname>Mikolajczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Net: Keypoint Detection by Handcrafted and Learned CNN Filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Axel</forename><surname>Barroso-Laguna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edgar</forename><surname>Riba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ponsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krystian</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Key</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5836" to="5844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">SURF: Speeded Up Robust Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="404" to="417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reinforced Feature Points: Optimizing Feature Detection and Description for a High-Level Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aritra</forename><surname>Bhowmik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Gumhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brachmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4948" to="4957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ground-to-aerial image geo-localization with a hard exemplar reweighting triplet loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudong</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gongjian</forename><surname>Wen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8391" to="8400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">BRIEF: Computing a Local Binary Descriptor Very Fast</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Calonder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Ozuysal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Trzcinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Strecha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1281" to="1298" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Handcrafted Outlier Detection Revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Cavalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">Ralf</forename><surname>Oswald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="770" to="787" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning to Match Features with Seeded Graph Matching Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuyang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiew-Lan</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Quan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">UnsuperPoint: End-to-end Unsupervised Interest Point Detector and Descriptor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikkel</forename><surname>Peter Hviid Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yury</forename><surname>Fly Kragh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Brodskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Karstoft</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.04011</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">SuperPoint: Self-Supervised Interest Point Detection and Description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Detone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="224" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">D2-Net: A Trainable CNN for Joint Detection and Description of Local Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Dusmanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Rocco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Beyond Cartesian Representations for Local Descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ebel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasiia</forename><surname>Mishchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwang Moo</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Trulls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="253" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Edge Detection Error in the Discrete Laplacian of Gaussian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Steve R Gunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Image Processing (ICIP)</title>
		<meeting>the International Conference on Image Processing (ICIP)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1998" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="515" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Soft exemplar highlighting for cross-view image-based geo-localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farid</forename><surname>Boussaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Bennamoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing (TIP)</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2094" to="2105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Combined Corner and Edge Detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Stephens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Alvey vision conference</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1988" />
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="147" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Image Matching Across Wide Baselines: From Paper to Practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhe</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasiia</forename><surname>Mishchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwang Moo</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Trulls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="517" to="547" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">BRISK: Binary Robust Invariant Scalable Keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Leutenegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margarita</forename><surname>Chli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><forename type="middle">Y</forename><surname>Siegwart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2548" to="2555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dual-Resolution Correspondence Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuda</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Prisacariu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">MegaDepth: Learning Single-View Depth Prediction From Internet Photos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengqi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Snavely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2041" to="2050" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Distinctive Image Features from Scale-Invariant Keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">ContextDesc: Local Descriptor Augmentation with Cross-Modality Context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Quan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">ASLFeat: Learning Local Features of Accurate Shape and Localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zixin</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuyang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Quan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Image Stylization for Robust Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iaroslav</forename><surname>Melekhov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Brostow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniyar</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Turmukhambetov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.06959</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Scale &amp; Affine Invariant Interest Point Detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krystian</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="86" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Working Hard to Know Your Neighbor&apos;s Margins: Local Descriptor Learning Loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasiia</forename><surname>Mishchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Radenovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Repeatability Is Not Enough: Learning Affine Regions via Discriminability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Radenovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">ORB-SLAM2: An Open-Source SLAM System for Monocular, Stereo, and RGB-D Cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raul</forename><surname>Mur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Artal</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><forename type="middle">D</forename><surname>Tard?s</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Robotics (TR)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1255" to="1262" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Large-Scale Image Retrieval With Attentive Deep Local Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonwoo</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">LF-Net: Learning Local Features from Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuki</forename><surname>Ono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Trulls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwang Moo</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">RoRD: Rotation-Robust Descriptors and Orthographic Views for Local Feature Matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Udit</forename><surname>Singh Parihar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniket</forename><surname>Gujarathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kinal</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satyajit</forename><surname>Tourani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourav</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Milford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K Madhava</forename><surname>Krishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<meeting>the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</meeting>
		<imprint>
			<biblScope unit="page" from="2021" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Online Invariance Selection for Local Feature Descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Pautrat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Oswald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="707" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">R2D2: Reliable and Repeatable Detector and Descriptor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cesar</forename><forename type="middle">De</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Humenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="12405" to="12415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Efficient neighbourhood consensus networks via submanifold sparse convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Rocco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Relja</forename><surname>Arandjelovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="605" to="621" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">ORB: An Efficient Alternative to SIFT or SURF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Rublee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Rabaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Konolige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Bradski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2564" to="2571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">SuperGlue: Learning Feature Matching With Graph Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul-Edouard</forename><surname>Sarlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Detone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Improving Image-Based Localization by Active Correspondence Search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leif</forename><surname>Kobbelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="752" to="765" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Quad-Networks: Unsupervised Learning to Rank for Interest Point Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolay</forename><surname>Savinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihito</forename><surname>Seki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubor</forename><surname>Ladicky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1822" to="1830" />
		</imprint>
	</monogr>
	<note>Torsten Sattler, and Marc Pollefeys</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Structurefrom-Motion Revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Johannes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Michael</forename><surname>Schonberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frahm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4104" to="4113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Comparative Evaluation of Hand-Crafted and Learned Local Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Johannes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Schonberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Hardmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1482" to="1491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">LoFTR: Detector-Free Local Feature Matching With Transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">On the Importance of Initialization And Momentum in Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">SOSNet: Second Order Similarity Regularization for Local Descriptor Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yurun</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuchao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huub</forename><surname>Heijnen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassileios</forename><surname>Balntas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="11016" to="11025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Long-Term Visual Localization Revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Toft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Maddern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Torii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Hammarstrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Stenborg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Safari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Pajdla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">DISK: Learning Local Features with Policy Gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Micha?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Tyszkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trulls</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning Feature Descriptors Using Camera Pose Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianqian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Snavely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">12346</biblScope>
			<biblScope unit="page" from="757" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Persistence-based interest point detection for 3D deformable surface</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xupeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferdous</forename><forename type="middle">Ahmed</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Graphics Theory and Applications (GRAPP)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="58" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Co-Attention for Conditioned Image Matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivia</forename><surname>Wiles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastien</forename><surname>Ehrhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15920" to="15929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">LIFT: Learned Invariant Feature Transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Kwang Moo Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Trulls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="467" to="483" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Reference Pose Generation for Long-term Visual Localization via Learned Features and View Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Scaramuzza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="821" to="844" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">GSLAM: A General SLAM Framework and Benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibiao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhui</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1110" to="1120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Epipolar-guided pixel-level correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qunjie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taixe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Halko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><forename type="middle">A</forename><surname>Per-Gunnar Martinsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tropp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIAM review</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="217" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Structurefrom-Motion Revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Johannes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Michael</forename><surname>Schonberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frahm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4104" to="4113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Comparative Evaluation of Hand-Crafted and Learned Local Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Johannes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Schonberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Hardmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1482" to="1491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.08022</idno>
		<title level="m">stance Normalization: The Missing Ingredient for Fast Stylization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Learning Feature Descriptors Using Camera Pose Supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianqian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Snavely</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">12346</biblScope>
			<biblScope unit="page" from="757" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Reference Pose Generation for Long-term Visual Localization via Learned Features and View Synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Scaramuzza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="821" to="844" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
