<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Accuracy Prediction with Non-neural Model for Neural Architecture Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Tan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
							<email>cheneh@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
							<email>tyliu@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Accuracy Prediction with Non-neural Model for Neural Architecture Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural architecture search (NAS) with an accuracy predictor that predicts the accuracy of candidate architectures has drawn increasing attention due to its simplicity and effectiveness. Previous works usually employ neural network-based predictors which require more delicate design and are easy to overfit. Considering that most architectures are represented as sequences of discrete symbols which are more like tabular data and preferred by non-neural predictors, in this paper, we study an alternative approach which uses non-neural model for accuracy prediction. Specifically, as decision tree based models can better handle tabular data, we leverage gradient boosting decision tree (GBDT) as the predictor for NAS. We demonstrate that the GBDT predictor can achieve comparable (if not better) prediction accuracy than neural network based predictors. Moreover, considering that a compact search space can ease the search process, we propose to prune the search space gradually according to important features derived from GBDT. In this way, NAS can be performed by first pruning the search space and then searching a neural architecture, which is more efficient and effective. Experiments on NASBench-101 and ImageNet demonstrate the effectiveness of using GBDT as predictor for NAS:</p><p>(1) On NASBench-101, it is 22x, 8x, and 6x more sample efficient than random search, regularized evolution, and Monte Carlo Tree Search (MCTS) in finding the global optimum; (2) It achieves 24.2% top-1 error rate on ImageNet, and further achieves 23.4% top-1 error rate on ImageNet when enhanced with search space pruning. Code is available at https://github.com/renqianluo/GBDT-NAS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Neural architecture search (NAS), which aims to automatically find neural network architectures, has been studied and shown its effectiveness in many tasks such as image classification <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52]</ref>, object detection [10, 6], network pruning [46], neural machine translation [31], text to speech [21]. Representative NAS methods include reinforcement learning based [52, 25], evolutionary algorithms based [27, 19], Bayesian methods based [50], gradient based [22, 19], Monte Carlo Tree Search (MCTS) based <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b36">37]</ref> and accuracy predictor based methods <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b38">39]</ref>. Among them, accuracy predictor based approaches, in which an accuracy predictor is used to predict the accuracy of candidate architectures in the search space and save the huge cost induced by training/evaluating these candidate architectures, are simple yet effective.</p><p>Previous works <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b39">40]</ref> usually employ neural network based models such as recurrent neural network (RNN), convolutional neural network (CNN), graph convolutional network (GCN) to build the predictor. Though neural predictors (i.e., neural network based predictors) have shown promising performance. They are easy to overfit and require delicate design <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b38">39]</ref>. Observing that the discrete representations of architectures are more like tabular data that are preferred by non-neural * The work was done when the first author was an intern at Microsoft Research Asia.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>models (e.g., tree based models) 2 , in this paper, we consider an alternative approach and explore how to build the accuracy predictor based on gradient boosting decision trees (GBDT). Our proposed NAS algorithm with a GBDT based predictor works as follows: 1) We reformulate the general representation of an architecture into one-hot features to make it suitable for GBDT. Given an architecture, we denote the presence or absence of an operator as 1 or 0. For example, we show two architectures and their features in <ref type="table" target="#tab_0">Table 1</ref>. 2) A GBDT predictor is trained with a few architectureaccuracy pairs. 3) The trained GBDT is used to predict the accuracy of more architectures in the search space and architectures with top predicted accuracy are selected for further evaluation. We call this algorithm GBDT-NAS.</p><p>Predicting the accuracy for all the candidate architectures is costly for large search space in real applications (e.g., search space of MobileNet-V3 is roughly 1e27), which can take billions of years.</p><p>Most predictor based methods <ref type="bibr" target="#b39">[40]</ref> choose to randomly sample a number of architectures from the search space to predict rather than all the architectures, resulting in sub-optimal result. Therefore, a compact search space can simplify the search process and help NAS to find better architectures with better sample efficiency. As GBDT is easier to tell the importance/contribution of a feature (i.e., the presence or absence of a candidate network operation), in order to improve sample efficiency, we propose to find not-well-performed candidate operations and prune them from the search space before searching for good architectures. Consequently, we propose to perform NAS by first pruning the search space using the GBDT as a pruner and then searching in the pruned search space using the same GBDT as a predictor, leading to a more efficient and effective NAS method which we call GBDT-NAS with search space search (GBDT-NAS-S3).</p><p>Extensive experiments on NASBench-101 and ImageNet demonstrate the effectiveness of our methods. Specifically, on NASBench-101, GBDT-NAS is 22x, 8x and 6x more sample efficient than random search, regularized evolution <ref type="bibr" target="#b26">[27]</ref> and MCTS <ref type="bibr" target="#b37">[38]</ref> respectively. It achieves 24.2% top-1 error rate on ImageNet. Moreover, GBDT-NAS-S3 achieves 23.4% top-1 error rate on ImageNet.</p><p>To sum up, our main contributions are listed as follows:</p><p>? We explore non-neural models (GBDT) as the accuracy predictor to better learn the representation of architectures and perform architecture search (GBDT-NAS), and show that it leads to better prediction accuracy against neural network based predictors.</p><p>? We further propose to first prune the search space using GBDT as a pruner and then conduct architecture search using GBDT as a predictor (GBDT-NAS-S3), which makes the overall search process more efficient and effective.</p><p>? Experiments on NASBench-101 and ImageNet verify the effectiveness and efficiency of our proposed GBDT-NAS and GBDT-NAS-S3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Neural Architecture Search <ref type="bibr" target="#b50">[51]</ref> introduces to use reinforcement learning to automatically search neural architecture and brings it to a thriving research area. Lots of works are emerged to explore different search algorithms including reinforcement learning <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b24">25]</ref>, evolutionary algorithm <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b26">27]</ref>, Bayesian optimization <ref type="bibr" target="#b49">[50]</ref>, accuracy prediction <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b39">40]</ref>, gradient based optimization <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b18">19]</ref> and MCTS <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b36">37]</ref>. Though all these algorithms have demonstrated effectiveness, accuracy predictor based methods have particularly drawn lots of interests due to its simplicity and effectiveness compared with other algorithms that need careful design and tuning. Accordingly, our proposed method is based on accuracy predictor.</p><p>Accuracy Predictor in NAS Considering that evaluating candidate architectures raises extremely high cost, <ref type="bibr" target="#b0">[1]</ref> proposes to encode a given architecture to continuous representation via RNN and predict its accuracy rather than really training it to speed up the search process. Further, NAO <ref type="bibr" target="#b21">[22]</ref> builds the accuracy predictor based on LSTM and fully connected layer to perform gradient based search. However, neural predictors are easy to overfit the architecture-accuracy paired data when applying to different tasks/datasets <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b39">40]</ref>, which requires delicate designing and tuning, and implicitly brings additional human efforts.</p><p>Recently, GCN is proposed to model architectures and predict the accuracy <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b38">39]</ref>. It points out that NASNet <ref type="bibr" target="#b51">[52]</ref> search space based on Inception <ref type="bibr" target="#b32">[33]</ref> backbone for computer vision tasks <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b18">19</ref>] is a directed acyclic graph that can be better modeled by GCN. However, in many scenarios, chain-like structure is more commonly used where each layer is only connected to the preceding layer (e.g., ResNets/Mobilenets in computer vision tasks <ref type="bibr" target="#b25">[26,</ref><ref type="bibr">4,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr">3,</ref><ref type="bibr" target="#b46">47]</ref>, encoder-decoder framework in language tasks <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b10">11]</ref> and speech tasks <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21]</ref>), and the architectures are commonly represented as sequences of discrete symbols from bottom layer to top layer, which are similar to tabular data. Neural predictors are easy to overfit on such structure data and GCN may fail when applying to such chain structure where the adjacent matrix is too sparse and only the diagonal has values. Such tabular data is preferred by non-neural models (e.g., tree based models) and thus we propose to utilize GBDT as the predictor, which is much simpler and more general to model both graph-like and chain-like structures and can be easily applied to different tasks without much tuning.</p><p>Search Space Search Search space plays an essential role in the search phase <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b42">43]</ref>. How to get an appropriate search space is critical in NAS. Sampling all the architectures in the search space is expensive and in-efficient, and sampling a small portion leads to sub-optimal. RegNet <ref type="bibr" target="#b25">[26]</ref> proposes to progressively prune the large search space via statistical tool (i.e., empirical distribution function) on a set of randomly sampled architectures to identify the best choice for different factors. Despite the impressive results, the search process heavily relies on human efforts. Specifically, the order of pruning is manually decided by human insights and statistical analyses which is similar to greedy search, and only one factor is considered at each time while different factors may have interactions. Therefore, a natural choice is to leverage models to automatically provide the pruning choices in a global way. GBDT automatically identifies the importance of different features according to some criterion, and is more simple and interpretable than neural networks. We propose to use GBDT to figure out the disappointing candidate operations automatically to prune the search space. Moreover, we can conduct higher-order analysis via combinations of different features during pruning.</p><p>LaNAS <ref type="bibr" target="#b36">[37]</ref> also proposes to automatically prune the search space recursively. It splits the search space into different sub-regions according to the predicted performance of different regions and different partition thresholds, which relies on the quality of predictor and partition threshold that are not easy to choose. Our method identifies the contribution of each candidate operation to the output which is more simple and efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Non-neural Predictor using GBDT</head><p>In this section, we introduce how to use GBDT as accuracy predictor for architecture search, which we call GBDT-NAS. In the following paragraphs, we first describe the design of input feature and output value to train a GBDT model, and then formulate our algorithm.</p><p>We describe a discrete neural network architecture as a sequence of tokens from bottom layer to top layer (e.g., 'conv 1x1, conv 3x3, conv 1x1, conv 3x3' to describe a 4-layer neural network, where each position represents the categorical choice for a layer). Considering categorical features may not be a good choice since the relative value of the category ID is meaningless, we convert the category feature into one-hot feature with O-dimension, where O is the number of candidate operations and the value of the one-hot feature is '1' or '0' (representing whether to use this operation or not). For example, if the candidate operations only contain 'conv 1x1 and conv 3x3', then the input feature of the 4-layer architecture demonstrated above is '[1,0,0,1,1,0,0,1]'. Examples of architectures are demonstrated in <ref type="table" target="#tab_0">Table 1</ref>. The output of GBDT is the accuracy of an architecture, where the target accuracy is normalized to ease model training. We use two ways for normalization: 1) min-max normalization <ref type="bibr" target="#b21">[22]</ref>, which rescales the values into [0, 1], i.e., y?ymin ymax?ymin . 2) standardization <ref type="bibr" target="#b39">[40]</ref>, which rescales the accuracy to be zero mean and standard variance, i.e., y?ymean ystd . The training of GBDT aims to minimize the mean squared error between predicted accuracy and target accuracy. We name our GBDT predictor based search algorithm as GBDT-NAS. It contains T iterations and each iteration mainly follows three steps:</p><p>? Train Predictor. Train the GBDT predictor with N architecture-accuracy pairs.</p><p>? Predict. Predict the accuracy of M randomly sampled architectures.</p><p>? Validation. Evaluate K architectures with the top K predicted accuracies. Combine them with the N architecture-accuracy pairs for next iteration.</p><p>Finally, the architecture with the highest valid accuracy is selected as the final result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Using GBDT for Search Space Search</head><p>In this section, we leverage the trained GBDT to search the search space by pruning unpromising candidate operations. In this way, searching in the pruned search space is more efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Motivation</head><p>Search space is critical for NAS <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b47">48]</ref>. First, different search spaces have different upper bounds of accuracy that may outweigh the effect of search algorithm. Second, the size of search space affects the effectiveness and efficiency of a search algorithm.</p><p>Ideally, when an accuracy predictor is well trained, one may consider using it to predict the accuracy of all the architectures in the search space (i.e., set M to be the size of search space). However, when applying to tasks with large search space, traversing all the architectures is time consuming although predicting the accuracy of a single architecture is negligible for GBDT. For example, a commonly used search space <ref type="bibr">[4,</ref><ref type="bibr" target="#b39">40]</ref> based on MobileNet-V2 <ref type="bibr" target="#b28">[29]</ref> backbone for computer vision tasks consists of more than 1e17 architectures <ref type="bibr">[4,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr">3]</ref> which would take millions of years for GBDT to predict on a single CPU and is inefficient. A commonly adopted approach <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b37">38]</ref> is to randomly sample a small set (i.e., M ) of architectures from the huge search space for prediction, which may lead to sub-optimal result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Pruning Search Space Using GBDT</head><p>We expect to search within a sub-space derived from the large one that contains potentially better architectures, which is more sampling efficient. Considering that GBDT can automatically determine the importance of a feature (the presence or absence of an operation) and can explain the accuracy prediction due to the advantage of tree-based model, in this paper, we leverage the explainable GBDT as the pruner to shrink a search space without human knowledge. A simple way is to use the automatically derived feature importance from the trained GBDT 3 . However, feature importance in GBDT only considers the contribution when training a GBDT model, which may not be entirely consistent with the feature importance in the accuracy of an architecture.</p><p>In this paper, we leverage SHapley Additive exPlanation (SHAP) value <ref type="bibr" target="#b19">[20]</ref>, which can measure the positive or negative contribution of a feature in GBDT prediction (i.e., architecture accuracy in the GBDT accuracy predictor) for each sample <ref type="bibr">4</ref> . Accordingly, in each iteration, we can get the average SHAP values for each operation in current search space. Then, we select the one with the lowest and extremely negative SHAP value, which implies the most negative contribution on the predicted accuracy, and then prune the search space according the feature. For example, if the average SHAP value of a feature value, layer_1_is_conv1x1=1 is extremely negative (e.g., ?0.2) among all the features, then we prune the search space with layer_1_is_conv1x1=1, and then all the architectures in the remaining space have layer_1_is_conv1x1=0 (do not choose conv1x1 at layer_1). We do this progressively until a certain number of features or all the extremely negative features have been pruned.</p><p>Further, since operations in a network may have interactions to cooperatively affect the network accuracy, pruning the search space considering the combinations of several operations is more reasonable and effective. To achieves this, we calculate the interaction SHAP values between any two features, which imply their cooperative contribution to the final accuracy prediction. Then we sort the combinations according to their interaction SHAP values and start from the most negative ones to prune. This can quickly find the most important feature combinations that affect the model output. We name the pruning method that uses SHAP value as first-order pruning shown in Alg. 4 and that uses interaction SHAP value as second-order pruning demonstrated in Alg. 5. if S f ea &lt; 0 then 10:</p><p>Z.add(f ea).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>end if 12: end for 13: Output: The pruned feature set Z.</p><p>In Alg. 4, we first calculate the SHAP values using the trained GBDT predictor f on current architecture-accuracy pairs X in line 3. Then we sort all the features according to the SHAP values in line 4. From line 6 to 10, we get the feature f ea with the current most negative SHAP values which indicates its negative contribution to the accuracy and add it the set Z which contains the operations required to be pruned. Alg. 5 is similar to Alg. 4 and is different in that we calculate the SHAP interaction values between each two features in line 3, and calculate the SHAP values of all the combinations of two features from line 7 to line 20.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">GBDT-NAS-S3</head><p>Finally, we formalize our GBDT-NAS enhanced with search space search (GBDT-NAS-S3 for short), which leverages GBDT to first search a good search space (GBDT as a pruner) and then search a good architecture (GBDT as an accuracy predictor, i.e., GBDT-NAS). As shown in Alg. 3, compared to GBDT-NAS, GBDT-NAS-S3 additionally uses the trained GBDT predictor f to perform the search Algorithm 2 Second-Order Pruning 1: Input: Trained GBDT accuracy predictor f . Current architecture pool X. One-hot feature set F . Number of features to be pruned N pf . 2: Z = ?. 3: S = SHAP _Interaction_V alues(f, X). 4: F2 = {(f eai, f eaj)|f eai ? F, f eaj ? F, 0 &lt;= i &lt; j &lt; |F |}. 5: Sort F2 according to S. 6: for l = 1, ? ? ? , N pf do 7:</p><p>(f ea1, f ea2) = F2.pop(). 8:</p><formula xml:id="formula_0">I11 = {i|xi[f ea1] = 1, xi[f ea2] = 1, xi ? X}. 9: I10 = {i|xi[f ea1] = 1, x1[f ea2] = 0, xi ? X}. 10: I01 = {i|xi[f ea1] = 0, x1[f ea2] = 1, xi ? X}. 11: S11 = i?I 11 S[i, f ea1, f ea2]/|I11|. 12: S10 = i?I 10 S[i, f ea1, f ea2]/|I10|. 13: S01 = i?I 01 S[i, f ea1, f ea2]/|I01|.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14:</head><p>if S11 &lt; 0 then 15:</p><p>Z.add(f ea1, f ea2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>16:</head><p>else if S10 &lt; 0 then 17:</p><p>Z.add(f ea1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>18:</head><p>else if S01 &lt; 0 then 19:</p><p>Z.add(f ea2). Train GBDT f using X and Y . 7:</p><p>Prune N pf features from the search space to get the pruned features Z , and Z = Z Z . 8:</p><p>Randomly sample M architectures with the constraints Z and get Xs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>Predict the accuracy of the architectures in Xs with f to get Ys.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10:</head><p>Select architectures from Xs with top K predicted accuracy in Ys and form X .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>Train and evaluate each architecture in X and get Y . 12: X = X X , Y = Y Y . 13: end for 14: Output: The architecture within X with the best accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We demonstrate the effectiveness of our proposed methods through experiments on two datasets: NASBench-101 <ref type="bibr" target="#b44">[45]</ref> and ImageNet. Since the search space of NASBench-101 is quite small, we only evaluate GBDT-NAS. We evaluate both GBDT-NAS and GBDT-NAS-S3 on ImageNet, which has much larger search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Analysis of GBDT as Predictor</head><p>We first analyze the performance of GBDT as predictor using NASBench-101. NASBench-101 is a dataset for evaluating NAS algorithms, which eliminates the efforts of training and evaluating candidate architectures. It defines a narrow search space containing only 423k CNN architectures and each architecture has been trained and evaluated on CIFAR-10 following exactly the same pipeline and setting. Thus, one can get architecture-accuracy pairs effortless via directly querying from the dataset, and use them to quickly evaluate a NAS algorithm and fairly compare it with other algorithms. The search space is graph-like structure following <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b18">19]</ref> which involves candidate connections between different nodes besides operations. We follow the encoding guide by the authors to represent the architecture in a sequence <ref type="bibr" target="#b44">[45]</ref>. For each node, we use its adjacent vector concatenated with its operation to represent it. Standardization is used to rescale the accuracy when training predictors.</p><p>We randomly sample 1100 architecture-accuracy pairs from the dataset. 1000 of them are used as training set and the remaining 100 pairs are used as test set. We train a GBDT model based on LightGBM <ref type="bibr" target="#b12">[13]</ref> with 100 trees and 31 leaves per tree. We also evaluate LSTM, GCN and Transfomer based accuracy predictors as baselines. For LSTM based predictor, we follow NAO <ref type="bibr" target="#b21">[22]</ref> and use a single layer LSTM of hidden size 16 followed by two fully connected layers of hidden size 64. For GCN based accuracy predictor, we follow <ref type="bibr" target="#b39">[40]</ref> with a 3-layer GCN of hidden size 144 followed by a fully connected layer of hidden size 128. For Transformer based accuracy predictor, we follow <ref type="bibr" target="#b34">[35]</ref> and use a 4-layer Transformer model.</p><p>All the models are trained on the same training set and tested on the same test set described above. To evaluate the predictors, we compute the pairwise accuracy following <ref type="bibr" target="#b21">[22]</ref> on the held out test set via</p><formula xml:id="formula_1">x 1 ?X,x 2 ?X 1 f (x 1 )?f (x 2 ) 1 y 1 ?y 2 |X|(|X|?1)/2</formula><p>, where 1 is the 0-1 indicator function. We run each setting for 100 times and report the average results in <ref type="table" target="#tab_1">Table 2</ref>.</p><p>It shows that the first two neural network based predictors (Transformer and LSTM) are easy to overfit. Even after careful hyper-parameter tuning, Transformer still shows severe overfitting, and LSTM has some improvements but still archives lower test accuracy than GBDT. GCN achieves good performance as we use the already tuned setting for NASBench by <ref type="bibr" target="#b39">[40]</ref>. Non-neural predictor (GBDT) achieves better prediction accuracy (82%) than neural networks (Transformer, LSTM, GCN). Note that graph-like architectures can not only be well modeled by GCN, but also be well modeled by GBDT which treats them as tabular data. However, training a GBDT model is much faster than training neural models and do not require much design of the neural predictor architecture or tuning of the hyper-parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">NASBench-101</head><p>Setup We then evaluate the performance of GBDT-NAS on NASBench-101. We mainly compare our method with several baselines: random search, regularized evolution <ref type="bibr" target="#b26">[27]</ref>, MCTS <ref type="bibr" target="#b37">[38]</ref> and GCN <ref type="bibr" target="#b39">[40]</ref>. Since the search space of NASBench-101 is small, we set M to be the size of the whole search space and search for only 1 iteration (i.e., T = 1). We run each algorithm for 100 times.</p><p>Results Following the guidelines suggested in NASBench-101 original publication, we plot the best test accuracy discovered with respect to the number of architecture-accuracy samples used by the algorithm in <ref type="figure" target="#fig_2">Fig. 1</ref>. GBDT-NAS is on average using 22x, 8x and 6x fewer architecture-accuracy samples than Random Search, Regularized Evolution, and MCTS respectively to find the global optimal. Though the search space in NASBench-101 is graph-like and well modeled by GCN, GBDT shows comparable performance by encoding the architectures as tabular data. Moreover, neural predictors required delicate design (e.g., depth, width, dropout) to avoid overfitting <ref type="bibr" target="#b39">[40]</ref> while GBDT can easily fit the data without much tuning. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">ImageNet</head><p>Model  <ref type="table">Table 3</ref>: Performances of different methods on ImageNet dataset. For NAO, we use the open source code and search on the same search space used in this paper. We run ProxylessNAS by optimizing accuracy without latency for fair comparison. '1st' and '2nd' indicate using first-order and second order SHAP values for pruning respectively.</p><p>Setup We adopt the search space used in ProxylessNAS <ref type="bibr">[4]</ref> which is based on MobileNetV2 backbone and is chain-like. It is not suitable to be modeled by GCN as the adjacent matrix is too sparse where only diagonal has values. Such chain-like structure is more like tabular data and preferred by GBDT rather than neural predictors. We search the operation of each layer and the candidate operations include mobile inverted bottleneck convolution layers <ref type="bibr" target="#b28">[29]</ref> with kernel size in {3, 5, 7} and expansion ratio in {3, 6}, and identity layer to perform elastic network depth, which yields totally (3 ? 2 + 1) 21 ? 5e17 candidate architectures.</p><p>During search, we split out 5000 images from the training set for validation. Since training on ImageNet is too costly, to reduce the resource required, we adopt the commonly used weight-sharing method to train the candidate architectures in a super-net <ref type="bibr" target="#b1">[2,</ref><ref type="bibr">3]</ref>. We train the super-net containing all the candidates for 20000 steps at each iteration with a batch size of 512.</p><p>The GBDT is trained with the same hyper-parameters used in NASBench-101 experiment. Min-max normalization is applied to normalize the accuracy numbers for GBDT. We use N = 1000, M = 5000, K = 300, T = 3 for evaluating both GBDT-NAS and GBDT-NAS-S3 as described in Alg. 3, according to preliminary study considering both effectiveness and efficiency. Since the search space contains 7 candidate operations and 21 layers, the number of features for an architecture is 7 ? 21 = 147. Specifically in GBDT-NAS-S3, we prune N pf = 20 features at each iteration to quickly narrow the space. The search runs for 1 day on 4 NVIDIA V100 GPUs.</p><p>We limit the FLOPS of the discovered architecture to be less than 600M for fair comparison with other works <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b4">5]</ref> and train it for 300 epochs. We implement random search as a baseline by randomly sampling 2000 architectures and training them using the super-net. The one with the best validation accuracy is selected for final evaluation. We also implement manual pruning to perform search space search as a baseline where we sequentially prune disappointing operations by doing statistics on architectures with certain operations similar to <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We list the results in <ref type="table">Table 3</ref>. We mainly compare our results to works sharing the same search space, and will apply it to very recently proposed better search space in <ref type="bibr">[3,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr">7]</ref> that have better accuracy. Results of our experiments are averaged across 5 runs. We can see that our proposed methods all demonstrate promising results. When using GBDT only as accuracy predictor, GBDT-NAS achieves 24.2% error rate. This shows that GBDT fits the chain-like architecture structure well. Further, when enhanced with search space search, GBDT-NAS-S3 achieves more improvements. Second-order pruning with 23.4% error rate outperforms first-order pruning with 23.8% error rate, demonstrating the effectiveness of considering combinations of feature interactions during search. We will try to use higher-order SHAP value to prune the search space in the future. Compared to other NAS works, our GBDT-NAS-S3 achieves better top-1 error rate under the 600M FLOPS constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Analysis</head><p>In this section, we study the hyper-parameters in GBDT-NAS. We mainly study N, K which respectively stands for the number of architecture-accuracy pairs to train the GBDT predictor, and the number of architectures to select for further validation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Study of Hyper-parameter N</head><p>Since GBDT predictor trains on N architecture-accuracy pairs, the number N is critical to the effect of the predictor. Small N may result in bad accuracy and large N leads to more resources required. Following the experiments of evaluating the accuracy predictor, we train the GBDT on N architecture-accuracy pairs queried from NASBench-101 dataset, and measure the pairwise accuracy of the GBDT predictor on a held-out set containing 100 architecture-accuracy pairs. We vary the value of K and evaluate on NASBench-101. Results are depicted in <ref type="figure" target="#fig_3">Fig. 2(b)</ref>. We can see that, when only a small number of architectures with top predicted accuracy are validated, the final discovered architecture shows a moderate test accuracy. With more architectures being evaluated, the discovered architecture achieves better test accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Study of Hyper-parameter K</head><p>Since the predictor is not 100% accurate, we cannot completely rely on the prediction to rank all the architectures. Therefore we need to further evaluate the top K architectures by really training and validating them on the valid dataset (querying the valid accuracy of these architectures in NASBench-101). Small K may potentially miss some well performing architectures that predicted to be bad by the predictor incorrectly, and large K leads to more resource required. We set N = 1000 and vary the value of K in GBDT-NAS and evaluate on NASBench-101. Results are depicted in <ref type="figure" target="#fig_3">Fig. 2(b)</ref>. We can see that, when only a small number of architectures with top predicted accuracy are validated, the final discovered architecture shows a moderate test accuracy. With more architectures are validated, the discovered architecture achieves better test accuracy. This implies that since the predictor is not 100% accurate, we cannot fully rely on its prediction to return the one with the best predicted accuracy. We need to select a number of architectures with the top predicted accuracies for further evaluation (training and validation) and return the one with the highest validated accuracy as the discovered one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Discovered Architectures and Analysis of Pruning the Search Space via GBDT</head><p>We show the architectures discovered for ImageNet, and conduct analysis on the effect of using GBDT for search space pruning.</p><p>We first plot the architectures for ImageNet discovered by GBDT-NAS, GBDT-NAS-S3 (first-order pruning) and GBDT-NAS-S3 (second-order pruning) in <ref type="figure" target="#fig_4">Fig. 3, Fig. 4</ref> and <ref type="figure" target="#fig_6">Fig. 5</ref> respectively.    Then, to demonstrate how we perform pruning using SHAP values, we visualize the SHAP values of some features using the official tool 5 in <ref type="figure" target="#fig_7">Fig. 6</ref>. Notice that the colored area contains multiple data points (architectures). Taking 'layer 1 is MB3 7x7' as an example, the SHAP value of this feature is extremely negative when the feature value is '1', which indicates that using a 'MB3' layer with kernel size 7 at layer 1 usually has bad accuracy. So we prune this feature and the following sampling process will not sample architectures that use 'MB3 7x7' at layer 1. The architecture discovered by GBDT-NAS in <ref type="figure" target="#fig_4">Fig. 3</ref> uses 'MB3 7x7' at 'layer 1' ('layer 1' starts from the layer right after the first gray bar, while the first two layers 'Conv 3x3' and 'MB1 3x3' before the bar are fixed as stem layers <ref type="bibr">[4]</ref>), which results in the final test error rate of 24.2%. However, the two architectures discovered by GBDT-NAS-S3 in <ref type="figure" target="#fig_5">Fig. 4</ref> and <ref type="figure" target="#fig_6">Fig. 5</ref> do not choose this operation at 'layer 1' as the operation is pruned due to its negative effect to the prediction determined by the SHAP value during the search. And these two architectures show better test error rate (23.8% and 23.5%) against the one by GBDT-NAS. Further, to demonstrate the effectiveness of the pruning methods during the search phase, we compare the average valid accuracies of architectures sampled from the search space with different pruning methods at each iteration (We totally run for T = 3 iterations) in <ref type="figure" target="#fig_8">Fig. 7</ref>.</p><p>The baseline uses no pruning method (i.e., GBDT-NAS, as shown in the red bar). We also show the results of pruning according to feature importance determined by GBDT for comparison. Specifically, we sort the features by their feature importance, and then prune the features in sequence. For each feature, we first calculate the average valid accuracies of architectures with and without the feature. Then the feature is pruned if the average valid accuracy of architectures with the feature is lower than the ones without the feature and the gap exceeds a certain margin (e.g., 1%).</p><p>Note that for each single method, the valid accuracy increases with more iterations since the super-net is trained to be better. At each iteration, compared to baseline without pruning, pruned search spaces show higher accuracy. Meanwhile SHAP value based pruning methods outperform the feature importance based method. This demonstrates that our GBDT based pruning indeed finds better sub-space. Moreover, the gap between SHAP value based pruning methods and baseline is increasing, implying that the sub-space after each iteration is becoming better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this paper, considering the tabular data representation of architectures which is preferred by nonneural models, we introduce GBDT into neural architecture search and develop two NAS algorithms: GBDT-NAS and GBDT-NAS-S3. In GBDT-NAS, we use GBDT as accuracy predictor to predict the accuracy of architectures. We further enhance GBDT-NAS with search space search and propose GBDT-NAS-S3, which additionally leverages learned information by GBDT to prune the search space. Experiments on NASBench-101 and ImageNet demonstrate the effectiveness of both methods. In our future work, we plan to use GBDT to search in more general search space and on more complicated tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Algorithm 1 First-Order Pruning 1 :</head><label>11</label><figDesc>Input: Trained GBDT accuracy predictor f . Current architecture pool X. One-hot feature set F . Number of features to be pruned N pf . 2: Z = ?. 3: S = SHAP _V alues(f, X). 4: Sort F according to S. 5: for l = 1, ? ? ? , N pf do 6: f ea = F.pop(). 7: I = {i|xi[f ea] = 1, xi ? X}. 8: S f ea = i?I S[i, f ea]/|I|. 9:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>20: end if 21: end for 22: Output: The pruned feature set Z. space search by pruning unpromising operations in line 7. If we remove this line, the algorithm degenerates to GBDT-NAS in Sec. 3. Algorithm 3 GBDT-NAS-S3 1: Input: Number of initial architectures N . Number of architectures M to predict. Number of top architectures K to evaluate. Number of search iterations T . Number of features to prune N pf . 2: Pruned feature set Z = ?. 3: Randomly sample N architectures to form X. 4: Train and evaluate architectures in X and get accuracy numbers Y . 5: for l = 1, ? ? ? , T do 6:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1 :</head><label>1</label><figDesc>Results of different methods on NASBench-101.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 :</head><label>2</label><figDesc>(a) Pairwise accuracy of GBDT predictor under different N . (b) Mean test accuracy of discovered architecture on NASBench-101 under different K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Architecture discovered by GBDT-NAS.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Architecture discovered by GBDT-NAS-S3 (first-order pruning).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Architecture discovered by GBDT-NAS-S3 (second-order pruning).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>SHAP values for several features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Average valid accuracy of the architectures sampled from search space pruned by different methods, evaluated with the shared weights during the search phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Two examples of 4-layer architectures with tabular data representation (one-hot features) and the corresponding accuracy. 'arch' is short for architecture.</figDesc><table><row><cell>Feature</cell><cell cols="2">arch 1 arch 2</cell></row><row><cell>layer 1 is conv1x1</cell><cell>1</cell><cell>0</cell></row><row><cell>layer 1 is conv3x3</cell><cell>0</cell><cell>1</cell></row><row><cell>layer 2 connects layer 1</cell><cell>1</cell><cell>1</cell></row><row><cell>layer 2 is conv1x1</cell><cell>1</cell><cell>0</cell></row><row><cell>layer 2 is conv3x3</cell><cell>0</cell><cell>1</cell></row><row><cell>layer 3 connects layer 1</cell><cell>1</cell><cell>0</cell></row><row><cell>layer 3 connects layer 2</cell><cell>0</cell><cell>1</cell></row><row><cell>layer 3 is conv1x1</cell><cell>0</cell><cell>0</cell></row><row><cell>layer 3 is conv3x3</cell><cell>1</cell><cell>1</cell></row><row><cell>layer 4 connects layer 1</cell><cell>0</cell><cell>0</cell></row><row><cell>layer 4 connects layer 2</cell><cell>0</cell><cell>1</cell></row><row><cell>layer 4 connects layer 3</cell><cell>1</cell><cell>1</cell></row><row><cell>layer 4 is conv1x1</cell><cell>0</cell><cell>0</cell></row><row><cell>layer 4 is conv3x3</cell><cell>1</cell><cell>1</cell></row><row><cell>accuracy (%)</cell><cell cols="2">92.50 93.20</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Pairwise accuracy of different predictors. Transformer* and LSTM* represent the setting that we carefully tune the hyper-parameters (e.g., depth, width, dropout, weight decay, normalization) of the two predictors on NASBench-101, which consumes a lot of human efforts. For GBDT, we directly use the default setting in LightGBM without much tuning.</figDesc><table><row><cell>Model</cell><cell cols="2">Train Acc. (%) Test Acc. (%)</cell></row><row><cell>Transformer</cell><cell>92</cell><cell>58</cell></row><row><cell>Transformer*</cell><cell>88</cell><cell>65</cell></row><row><cell>LSTM</cell><cell>96</cell><cell>73</cell></row><row><cell>LSTM*</cell><cell>87</cell><cell>80</cell></row><row><cell>GCN</cell><cell>85</cell><cell>80</cell></row><row><cell>GBDT</cell><cell>88</cell><cell>82</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Generally speaking, raw image/text/speech data with spatial or temporal smoothness is preferred by neural networks, graph data is preferred by graph neural networks, while tabular data is preferred by tree based models.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The feature importance in GBDT is determined by the average information gain when choosing this feature.4  SHAP value<ref type="bibr" target="#b19">[20]</ref> is a unified measure of different Shapley values<ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b31">32,</ref> 8]  which reflects the importance of features on the result considering their cooperation and interaction by solving a combined cooperative game theory problem<ref type="bibr" target="#b29">[30]</ref>. It attributes to each feature a value (real number) showing how it affects the output (positively or negatively).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://github.com/slundberg/shap</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We sincerely thank Guolin Ke for his valuable comments and suggestions.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Accelerating neural architecture search using performance prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otkrist</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Naik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Understanding and simplifying one-shot architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="549" to="558" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Once-for-all: Train one network and specialize it for efficient deployment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianzhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhekai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ligeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.00332</idno>
		<title level="m">Proxylessnas: Direct neural architecture search on target task and hardware</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12760</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Detnas: Backbone search for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6638" to="6648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.02049</idno>
		<title level="m">Joint architecture-recipe search using neural acquisition function</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anupam</forename><surname>Datta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shayak</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Zick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE symposium on security and privacy (SP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="598" to="617" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Densely connected search space for more flexible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiemin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Nas-fpn: Learning scalable feature pyramid architecture for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7036" to="7045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dynabert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04037</idno>
		<title level="m">Dynamic bert with adaptive width and depth</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ruoming Pang, Vijay Vasudevan, et al. Searching for mobilenetv3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grace</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1314" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Lightgbm: A highly efficient gradient boosting decision tree</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guolin</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Finley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taifeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiwei</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3146" to="3154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Random search and reproducibility for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liam</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameet</forename><surname>Talwalkar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.07638</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Neural speech synthesis with transformer network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naihan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6706" to="6713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Improving one-shot nas by suppressing the posterior fading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Analysis of regression in game theory approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Lipovetsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Conklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Stochastic Models in Business and Industry</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="319" to="330" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.00559</idno>
		<title level="m">Progressive neural architecture search</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.09055</idno>
		<title level="m">Darts: Differentiable architecture search</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A unified approach to interpreting model predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su-In</forename><surname>Lundberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4765" to="4774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.10389</idno>
		<title level="m">Semi-supervised neural architecture search</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.07233</idno>
		<title level="m">Neural architecture optimization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Risto Miikkulainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Rawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bala</forename><surname>Francon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hormoz</forename><surname>Raju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arshak</forename><surname>Shahrzad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Navruzyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duffy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.00548</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">Evolving deep neural networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renato</forename><surname>Negrinho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Gordon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.08792</idno>
		<title level="m">Deeparchitect: Automatically designing and training deep architectures</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameter sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melody</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4092" to="4101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Kaiming He, and Piotr Doll?r. Designing network design spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilija</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><forename type="middle">Prateek</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.13678</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alok</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.01548</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Large-scale evolution of image classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherry</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><forename type="middle">Leon</forename><surname>Suematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kurakin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2902" to="2911" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A value for n-person games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shapley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contributions to the Theory of Games</title>
		<imprint>
			<date type="published" when="1953" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="307" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The evolved transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5877" to="5886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Explaining prediction models and individual predictions with feature contributions. Knowledge and information systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>?trumbelj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Kononenko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="647" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11946</idno>
		<title level="m">Rethinking model scaling for convolutional neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Differentiable neural architecture search for spatial and channel dimensions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoliang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bichen</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12965" to="12974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Sample-efficient neural architecture search by learning action space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.06832</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Neural architecture search using deep neural networks and monte carlo tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linnan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiyang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuu</forename><surname>Jinnai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Fonseca</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.07440</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Npenas: Neural predictor guided evolution for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimin</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.12857</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00848</idno>
		<title level="m">Neural predictor for neural architecture search</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Genetic cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017-10" />
			<biblScope unit="page" from="1388" to="1397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Pc-darts: Partial channel connections for memory-efficient differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo-Jun</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongkai</forename><surname>Xiong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">M</forename><surname>Esperan?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.12522</idno>
		<title level="m">Nas evaluation is frustratingly hard</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Cars: Continuous evolution for efficient neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boxin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">NAS-bench-101: Towards reproducible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>Kamalika Chaudhuri and Ruslan Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Network slimming by slimmable networks: Towards one-shot architecture search for channel numbers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.11728</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengchong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter-Jan</forename><surname>Kindermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.11142</idno>
		<title level="m">Ruoming Pang, and Quoc Le. Bignas: Scaling up neural architecture search with big single-stage models</title>
		<imprint>
			<publisher>Xiaodan Song</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Understanding and robustifying differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arber</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yassine</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.09656</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Shufflenet: An extremely efficient convolutional neural network for mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengxiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6848" to="6856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Bayesnas: A bayesian approach for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongpeng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Pan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.04919</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01578</idno>
		<title level="m">Neural architecture search with reinforcement learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8697" to="8710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Feature with value &apos;0&apos; will not be pruned since by default the operation is to be sampled. For example, by default &apos;conv1x1&apos; is in the candidate operations and will be sampled. When &apos;layer_1_is_conv1x1=1&apos; has a very negative SHAP value which means using &apos;conv1x1&apos; at &apos;layer_1&apos; will lead to inferior prediction, we prune the &apos;layer_1_is_conv1x1&apos; from the search space and &apos;conv1x1&apos; will not be sampled to be the operation of &apos;layer_1&apos;. However, when &apos;layer_1_is_conv1x1=0&apos; has a very negative SHAP value which means not using &apos;conv1x1&apos; at &apos;layer_1&apos; will lead to inferior prediction, we do nothing since by default &apos;conv1x1&apos; will be sampled to be the operation of &apos;layer_1&apos; in other cases. We give the first-order pruning algorithm in Alg. 4 and second-order pruning algorithm in Alg. 5. Algorithm 4 First-Order Pruning 1: Input: Trained GBDT performance predictor f</title>
		<imprint/>
	</monogr>
	<note>Since the one-hot feature represents using or not using the corresponding operation, we only prune the features with value &apos;1&apos; (indicating that using this operation may lead to inferior prediction). Current architecture pool X. One-hot feature set F . Number of features to be pruned N pf . 2: Z = ?</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S = Shap _V</forename><surname>Alues</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">8: S f ea = i?I S[i, f ea]/|I|. 9: if S f ea &lt; 0 then 10: Z.add(f ea)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>I = {i|xi ; Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>X}</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">end if 12: end for 13: Output: The pruned feature set Z</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Algorithm 5 Second-Order Pruning 1: Input: Trained GBDT performance predictor f . Current architecture pool X. One-hot feature set F . Number of features to be pruned N pf</title>
		<editor>Z = ?</editor>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">f eaj)|0 &lt;= i &lt; j &lt; |f |}. 5: Sort F2 according to S. 6: for l = 1</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">? ? ?</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pf</surname></persName>
		</author>
		<editor>F2 = {(f eai</editor>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note>f ea1, f ea2) = F2.pop(</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>I11 = {i|xi</surname></persName>
		</author>
		<idno>xi ? X}. 9: I10 = {i|xi</idno>
		<imprint/>
	</monogr>
	<note>f ea1] = 1, xi[f ea2] = 1. f ea1] = 1, x1[f ea2] = 0, xi ? X}. 10: I01 = {i|xi[f ea1] = 0, x1[f ea2] = 1, xi ? X}. 11: S11 = i?I 11 S[i, f ea1, f ea2]/|I11|. 12: S10 = i?I 10 S[i, f ea1, f ea2]/|I10|. 13: S01 = i?I 01 S[i, f ea1, f ea2]/|I01|. 14: if S11 &lt; 0 then 15: Z.add(f ea1, f ea2). 16: else if S10 &lt; 0 then 17: Z.add(f ea1). 18: else if S01 &lt; 0 then 19: Z.add(f ea2). 20: end if 21: end for 22: Output: The pruned feature set Z</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
