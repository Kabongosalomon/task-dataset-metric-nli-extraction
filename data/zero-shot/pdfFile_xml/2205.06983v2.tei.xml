<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RASAT: Integrating Relational Structures into Pretrained Seq2Seq Model for Text-to-SQL</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiexing</forename><surname>Qi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyao</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangpeng</forename><surname>Wan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">NetMind.AI and ProtagoLabs</orgName>
								<address>
									<region>Virginia</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Microsoft Research</orgName>
								<address>
									<settlement>Redmond</settlement>
									<region>Washington</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenghu</forename><surname>Zhou</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">IGSNRR</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinbing</forename><surname>Wang</surname></persName>
							<email>xwang8@sjtu.edu.cnlin.zhouhan@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanshi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouhan</forename><surname>Lin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<settlement>Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">RASAT: Integrating Relational Structures into Pretrained Seq2Seq Model for Text-to-SQL</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Relational structures such as schema linking and schema encoding have been validated as a key component to qualitatively translating natural language into SQL queries. However, introducing these structural relations comes with prices: they often result in a specialized model structure, which largely prohibits using large pretrained models in text-to-SQL. To address this problem, we propose RASAT: a Transformer seq2seq architecture augmented with relation-aware self-attention that could leverage a variety of relational structures while inheriting the pretrained parameters from the T5 model effectively. Our model can incorporate almost all types of existing relations in the literature, and in addition, we propose introducing co-reference relations for the multiturn scenario. Experimental results on three widely used text-to-SQL datasets, covering both single-turn and multi-turn scenarios, have shown that RASAT could achieve state-of-theart results across all three benchmarks (75.5% EX on Spider, 52.6% IEX on SParC, and 37.4% IEX on CoSQL). 1 * Zhouhan Lin is the corresponding author. 1 Our implementation is available at https://github. com/LUMIA-group/rasat.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Text-to-SQL is the task that aims at translating natural language questions into SQL queries. Since it could significantly break down barriers for nonexpert users to interact with databases, it is among the most important semantic parsing tasks that are of practical importance <ref type="bibr">(Kamath and Das, 2018;</ref><ref type="bibr" target="#b6">Deng et al., 2021)</ref>.</p><p>Various types of relations have been introduced for this task since <ref type="bibr" target="#b25">Zhong et al. (2017)</ref> collected the first large-scale text-to-SQL dataset, which has resulted in significant boosts in the performance through recent years. For example, <ref type="bibr" target="#b1">Bogin et al. (2019b)</ref> introduced schema encoding to represent the schema structure of the database, and the resulting augmented LSTM encoder-decoder architecture was able to generalize better towards unseen database schema. <ref type="bibr">Lin et al. (2020a)</ref> introduced relations between the entity mentioned in the question and the matched entries in the database to utilize database content effectively. Their BERT-based encoder is followed by an LSTM-based pointer network as the decoder, which generalizes better between natural language variations and captures corresponding schema columns more precisely. RAT-SQL <ref type="bibr" target="#b10">(Wang et al., 2020a)</ref> introduced schema linking, which aligns mentions of entity names in the question to the corresponding schema columns or tables. Their augmented Transformer encoder is coupled with a specific tree-decoder. SADGA <ref type="bibr" target="#b2">(Cai et al., 2021)</ref> introduced the dependency structure of the natural language question and designed a graph neural network-based encoder with a tree-decoder. On the other hand, a tree-decoder that can generate grammatically correct SQL queries is usually needed to better decode the encoder output, among which <ref type="bibr" target="#b17">Yin and Neubig (2017)</ref> is one of the most widely used.</p><p>Although integrating various relational structures as well as using a tree-decoder have been shown to be vital to generating qualitative SQL queries and generalizing better towards unseen database schema, the dev of various specifically designed model architectures significantly deviate from the general sequential form, which has made it hard if one considers leveraging large pre-trained models for this task. Existing methods either use BERT output as the input embedding of the specifically designed model <ref type="bibr" target="#b4">(Cao et al., 2021;</ref><ref type="bibr" target="#b5">Choi et al., 2021;</ref><ref type="bibr" target="#b10">Wang et al., 2020a;</ref><ref type="bibr">Guo et al., 2019)</ref>, or stack a specific decoder on top of <ref type="bibr">BERT (Lin et al., 2020a)</ref>.</p><p>In another thread, pretrained seq2seq models just have unveiled their powerful potential for this task. Recent attempts by <ref type="bibr">Shaw et al. (2021)</ref> show that directly fine-tuning a T5 model <ref type="bibr">(Raffel et al., 2020)</ref> on this task without presenting any relational structures could achieve satisfying results. Moreover, <ref type="bibr">PICARD (Scholak et al., 2021)</ref> presents a way to prune invalid beam search results during inference time, thus drastically improving the grammatical correctness of the SQL queries generated by the autoregressive decoder that comes with T5.</p><p>In this work, different from the more common approach of fine-tuning the original pretrained model or using prompt tuning, we propose to augment the self-attention modules in the encoder and introduce new parameters to the model while still being able to leverage the pre-trained weights. We call the proposed model RASAT 2 . Our model can incorporate almost all existing types of relations in the literature, including schema encoding, schema linking, syntactic dependency of the question, etc., into a unified relation representation. In addition to that, we also introduce coreference relations to our model for multi-turn text-to-SQL tasks. Experimental results show that RASAT could effectively leverage the advantage of T5. It achieves the stateof-art performance in question execution accuracy (EX/IEX) on both multi-turn (SParC and CoSQL) and single-turn (Spider) text-to-SQL benchmarks. On SParC, RASAT surpasses all previous methods in interaction execution accuracy (IEX) and improves state-of-the-art performance from 21.6% to 52.6%, 31% absolute improvements. On CoSQL, we improve state-of-the-art IEX performance from 8.4% to 37.4%, achieving 29% absolute improvements. Moreover, on Spider, we improve state-ofthe-art execution accuracy from 75.1% to 75.5%, achieving 0.4% absolute improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Early works usually exploit a sketch-based slotfilling method that uses different modules to predict the corresponding part of SQL. These methods decompose the SQL generation task into several independent sketches and use different classifiers to predict corresponding part, such as SQLNet <ref type="bibr" target="#b16">(Xu et al., 2017)</ref>, <ref type="bibr">SQLOVA (Hwang et al., 2019)</ref>, X-SQL (He et al., 2019), RYANSQL <ref type="bibr">(Choi et al., 2021), et.al,.</ref> However, most of these methods only 2 RASAT: Relation-Aware Self-Attention-augmented T5 handle simple queries while failing to generate correct SQL in a complex setting such as on Spider.</p><p>Faced with the multi-table and complex SQL setting, using graph structures to encode various complex relationships is a major trend in the text-to-SQL task. For example, Global-GNN <ref type="bibr" target="#b0">(Bogin et al., 2019a)</ref> represents the complex database schema as a graph, RAT-SQL <ref type="bibr" target="#b10">(Wang et al., 2020a)</ref> introduces schema encoding and linking and assigns every two input items a relation, LGESQL <ref type="bibr" target="#b4">(Cao et al., 2021)</ref> further distinguishes local and non-local relations by exploiting a line graph enhanced hidden module, SADGA <ref type="bibr" target="#b2">(Cai et al., 2021)</ref> uses contextual structure and dependency structure to encode question-graph while database schema relations are used in schema graph, S 2 SQL (Hui et al., 2022) adds syntactic dependency information in relational graph attention network (RGAT) <ref type="bibr" target="#b11">(Wang et al., 2020b)</ref>.</p><p>For the conversational context-dependent textto-SQL task that includes multiple turns of interactions, such as SParC and CoSQL, the key challenge is how to take advantage of historical interaction context. Edit-SQL <ref type="bibr" target="#b22">(Zhang et al., 2019)</ref> edits the last turn's predicted SQL to generate the newly predicted SQL at the token level. IGSQL <ref type="bibr" target="#b3">(Cai and Wan, 2020)</ref> uses cross-turn and intra-turn schema graph layers to model database schema items in a conversational scenario. Tree-SQL <ref type="bibr" target="#b13">(Wang et al., 2021b</ref>) uses a tree-structured intermediate representation and assigns a probability to reuse subtree of historical Tree-SQLs. IST-SQL <ref type="bibr" target="#b12">(Wang et al., 2021a)</ref> proposes an interaction state tracking method to predict the SQL query. <ref type="bibr">RAT-SQL-TC (Li et al., 2021)</ref>adds two auxiliary training tasks to explicitly model the semantic changes in both turn grain and conversation grain. R 2 SQL (Hui et al., 2021) and HIE-SQL <ref type="bibr" target="#b23">(Zheng et al., 2022)</ref> introduce a dynamic schema-linking graph by adding the current utterance, interaction history utterances, database schema, and the last predicted SQL query. <ref type="bibr">Recently, Shaw et al. (2021)</ref> showed that finetuning a pre-trained T5-3B model could yield results competitive to the then-state-of-the-art. Based on this discovery, <ref type="bibr">Scholak et al. (2021)</ref> proposed to constrain the autoregressive decoder through incremental parsing during inference time, effectively filtering out grammatically incorrect sequences on the fly during beam search, which significantly improved the qualities of the generated SQL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task Formulation</head><p>Given a natural language question Q and database schema S =&lt; T , C &gt;, our goal is to predict the SQL query Y.</p><formula xml:id="formula_0">Here Q = {q i } |Q| i=1</formula><p>is a sequence of natural language tokens, and the schema S consists of a series of tables</p><formula xml:id="formula_1">T = {t i } |T | i=1 with their corresponding columns C = {C i } |T | i=1 . The content of database S is noted as V. For each table t i , the columns in this table is denoted as C i = {c ij } |C i | j=1 .</formula><p>For each table t i , the table name contains |t i | tokens t i = t i,1 , ? ? ? , t i,|t i | , and the same holds for column names. In this work, we present the predicted SQL query as a sequence of tokens,</p><formula xml:id="formula_2">Y = {y i } |Y| i=1 .</formula><p>In the multi-turn setting, our notations adapt correspondingly. i.e., Q = {Q i } |Q| i=1 denotes a sequence of questions in the interaction, with Q i denoting each question. Also, the target to be predicted is a sequence of SQL queries,</p><formula xml:id="formula_3">Y = {Y i } |Y| i=1 ,</formula><p>with each Y i denoting the corresponding SQL query for the i-th question Q i . Generally, for each question, there is one corresponding SQL query, such that |Q| = |Y|. While predicting Y i , only the questions in the interaction history are available, i.e., {Q 1 , ? ? ? , Q i }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Relation-aware Self-Attention</head><p>Relation-aware self-attention <ref type="bibr">(Shaw et al., 2018)</ref> augments the vanilla self-attention <ref type="bibr" target="#b9">(Vaswani et al., 2017)</ref> by introducing relation embeddings into the key and value entries. Assume the input to the self attention is a sequence of n embeddings X = {x i } n i=1 where x i ? R dx , then it calculates its output z as ( || means concatenate operation):</p><formula xml:id="formula_4">? (h) ij = softmax ? ? ? x i W (h) Q x j W (h) K + r K ij dz/H ? ? ? zi = H h=1 n j=1 ? (h) ij x j W (h) V + r V ij (1)</formula><p>where H is the number of heads, and W (h)</p><formula xml:id="formula_5">Q , W (h) K , W (h) V</formula><p>are learnable weights. The r K ij , r V ij are two different relation embeddings used to represent the relation r between the i-th and j-th token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RASAT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model Overview</head><p>The overall structure of our RASAT model is shown in <ref type="figure">Figure 1</ref>. Architecture-wise it is rather simple: the T5 model is taken as the base model, with its self-attention modules in the encoder substituted as relation-aware self-attentions.</p><p>The input to the encoder is a combination of question(s) Q, database schema S =&lt; T , C &gt; with the database name S, as well as database content mentions and necessary delimiters. We mostly follow <ref type="bibr">Shaw et al. (2021)</ref> and <ref type="bibr">Scholak et al. (2021)</ref> to serialize the inputs. Formally,</p><formula xml:id="formula_6">X = Q|S|t 1 :c 11 [v], ? ? ? ,c 1|T 1 | |t 2 :c 21 , ? ? ?</formula><p>(2) where t i is the table name, c ij is the j-th column name of the i-th table. The v ? V showing after column c 11 is the database content belonging to the column that has n-gram matches with the tokens in the question. As for delimiters, we use | to note the boundaries between Q, S, and different tables in the schema. Within each table, we use : to separate between table name and its columns. Between each column, , is used as the delimiter.</p><p>As for the multi-turn scenario, we add the questions in the history at the start of the sequence and truncate the trailing tokens in the front of the sequence when the sequence length reaches 512. i.e.,</p><formula xml:id="formula_7">X = Q 1 |Q 2 | ? ? ? |Q t |S|t 1 :c 11 [v], ? ? ? (3)</formula><p>where | are the corresponding delimiters. Next, we add various types of relations as triplets, linking between tokens in the serialized input, which naturally turns the input sequence into a graph ( <ref type="figure">Figure 1</ref>). We will elaborate on this in Subsection 4.2. Moreover, since almost all relation triplets, its head and tail correspond to either a word or a phrase, while the T5 model is at subword level, we also introduce relation propagation to map these relations to subword level, which is detailed in Subsection 4.3.</p><p>To fine-tune this model, we inherit all the parameters from T5 and randomly initialize the extra relation embeddings introduced by relation-aware self-attention. The overall increase of parameters is less than 0.01% (c.f. Appendix A).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Interaction Graph</head><p>Equipped with relation-aware self-attention, we can incorporate various types of relations into the  <ref type="figure">Figure 1</ref>: The overview of our model. Our model inherits the seq2seq architecture of T5, consisting of N layers of encoders and decoders. The self-attention modules in the encoder are substituted with relation-aware self-attention, introducing two additional relation embedding lookup tables R K and R V . We convert the sequential input into an interaction graph by introducing various types of relations and adapting them to the subword level through relation propagation. During the forward process, the relation-aware self-attention modules read out the relations of each token through the interaction graph and retrieve the corresponding relations embeddings from the lookup tables R K and R V .</p><formula xml:id="formula_8">INPUT: q 1,1 q 1,2 | ? | q t-1,1 q t-1,2 | q t,1 q t,2 q t,3 q t,4 | S | t 1 : c 11 [ v 1 ] , c 12 | t 2 : c 21 N ? N ?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Type Head H Tail T Edge Label Description</head><p>Schema Encoding  T5 model, as long as the relation can be presented as a triplet, with its head and tail being the tokens in the input sequence X. Formally, we present the triplet as &lt; H, r, T &gt;</p><formula xml:id="formula_9">T C PRIMARY-KEY T is the primary-key for H BELONGS-TO T is a column in H C C FOREIGN-KEY H is the foreign key for T Schema Linking Q T /C EXACT-MATCH H is part of T,</formula><p>where H, T are the head and tail items in the triplet, and r represents the relation. Given the input sequence X of length |X|, we assume that for each direction of a given pair of tokens, there only exists up to one relation. Thus, if we consider the tokens in X as vertices of a graph, it could have up to |X| 2 directed edges, with each edge corresponding to an entry in the adjacency matrix of the graph. In this paper, we call this graph, containing tokens from the whole input sequence as its vertices and the incorporated relations as its edges, as interaction graph.</p><p>We assign two relation embeddings for each type of introduced relation. Thus the Transformer encoder comes with two trainable lookup tables storing relations embeddings to compute the key and value in the self-attention (c.f. <ref type="figure">Figure 1</ref>). Formally, we denote them as R K , R V ? R ??d kv where ? is the kinds of relations and d kv is the dimension of each attention head in the key and value states. Note that we share the relation embedding between different heads and layers but untie them between key and value. During forward computation, for all the layers, r K ij and r V ij in Equation 1 are retrieved from the two trainable look-up tables.</p><p>We reserve a set of generic relations for serving as mock relations for token pairs that do not have a specific edge. In total, we have used 51 different relations in the model (c.f. Appendix D). Apart from the mock generic relations, there are generally 5 types of relations, which are: schema encoding, schema linking, question dependency structure, coreference between questions, and database content mentions. Please refer to <ref type="table" target="#tab_2">Table 1</ref> for some representative examples for each type. We will describe each of them in the following paragraphs.</p><p>Schema Encoding. Schema encoding relations refer to the relation between schema items, i.e., H, T ? S. These relations describe the structure information in a database schema. For example, PRIMARY-KEY indicates which column is the primary key of a table, BELONGS-TO shows which table a column belongs to, and FORIGN-KEY connects the foreign key in one table, and the primary key in another table.</p><p>Schema Linking. Schema linking relations refer to the relations between schema and question items, i.e., H ? S, T ? Q or vice versa. We follow the settings in RAT-SQL <ref type="bibr" target="#b10">(Wang et al., 2020a)</ref>, which uses n-gram matches to indicate question mentions of the schema items. Detecting these relations is shown to be challenging in previous works <ref type="bibr">(Guo et al., 2019;</ref><ref type="bibr" target="#b6">Deng et al., 2021)</ref> due to the common mismatch between natural language references and their actual names in the schema. Thus, we also discriminate between exact matches and partial matches to suppress the noise caused by imperfect matches.</p><p>Question Dependency Structure. This type of relation refers to the edges of a dependency tree of the question, i.e., H, T ? Q. Unlike the previous two relation types, it is less explored in the literature on text-to-SQL. Since it reflects the grammatical structure of the question, we believe it should also be beneficial for the task. In our work, to control the total number of relations and avoid unnecessary overfitting, we do not discriminate between different dependency relations. <ref type="figure">Figure 2</ref> shows an example of dependency relations in one of its questions.</p><p>Coreference Between Questions. This type of relation is unique to the multi-turn scenario. In a dialog with multiple turns, it is important for the model to figure out the referent of the pronouns correctly. <ref type="figure">Figure 2</ref> shows a typical case of coreference resolution. The question item "their" in Turn 1, "they" in Turn 2, and "they" in Turn 3 all refer to the question item "students" in Turn 1. i.e.,  <ref type="table" target="#tab_2">Table 1</ref> and is also widely used in many graph-structured models <ref type="bibr" target="#b10">(Wang et al., 2020a;</ref><ref type="bibr" target="#b4">Cao et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Relation Propagation</head><p>The various aforementioned types of relations are between types of items, with their H and T being either words or phrases. However, almost all pretrained models take input tokens at the subword level, resulting in a difference in the granularity between the relations and the input tokens. Previous works use an extra step to aggregate multiple subword tokens to obtain a single embedding for each item in the interaction graph, such as mean pooling, attentive pooling, or with BiLSTMs <ref type="bibr" target="#b10">(Wang et al., 2020a;</ref><ref type="bibr" target="#b4">Cao et al., 2021)</ref>. However, these aggregation methods are detrimental to inheriting the pre-trained knowledge in the pretrained models.</p><p>In this work, we adopt the other way: we propagate the relations into the subword level by cre-   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In this section, we will show our model's performance on three common text-to-SQL datasets: Spider <ref type="bibr" target="#b20">(Yu et al., 2018)</ref>, SParC <ref type="bibr" target="#b21">(Yu et al., 2019b)</ref> and CoSQL <ref type="bibr" target="#b18">(Yu et al., 2019a)</ref>. Besides, we experiment on a more realistic setting of the Spider dataset:</p><p>Spider-Realistic <ref type="bibr" target="#b6">(Deng et al., 2021)</ref> to test the generalizability of our model. The statistics of these datasets are shown in <ref type="table" target="#tab_6">Table 3</ref>. We also present a set of ablation studies to show the effect of our method on different sized models, as well as the relative contribution of different relations. In addition, we put 2 case studies in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiment Setup</head><p>Datasets Spider is a large-scale, multi-domain, and cross-database benchmark. SparC and CoSQL are multi-turn versions of Spider on which the dialogue state tracking is required. All test data is hidden to ensure fairness, and we submit our model to the organizer of the challenge for evaluation.    </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results on SParC</head><p>The results on SParC are shown in <ref type="table" target="#tab_5">Table 2</ref>. Our proposed RASAT model combined with PICARD achieves state-of-the-art results on all four evaluation metrics. Compared with the previous state-of-the-art RAT-SQL-TC + GAP (Li et al., 2021), RASAT + PICARD brings the QEM from 65.7% to 67.7% and IEM from 43.2% to 45.2% on the test set. In addition, our model can produce executable SQLs (with values), whereas many of the models listed in the table do not provide value predictions.</p><p>Among the models that can predict with values, the fine-tuned T5-3B model from UNIFIEDSKG <ref type="bibr" target="#b15">(Xie et al., 2022)</ref> is currently the state-of-the-art. We did comparison of QEX/IEX on the dev set since they did not report their performance on the test set. RASAT + PICARD surpasses all previous methods and improves the state-of-art QEX and IEX from 67.3% and 46.4% to 73.3% and 54.0%, with 6% and 7.6% absolute improvements, respectively.</p><p>Furthermore, on the official leaderboard of SParc which reports over test set, our proposed RASAT + PICARD brings the IEX from 21.6% to 52.6%, achieving 31% absolute improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results on CoSQL</head><p>Compared with SParC, CoSQL is labeled in a Wizard-of-Oz fashion, forming a more realistic and challenging testbed. Nevertheless, our proposed model could still achieve state-of-the-art results ( <ref type="table" target="#tab_8">Table 4</ref>) on all four evaluation metrics.</p><p>By comparing to the previous state-of-the-art HIE-SQL + GraPPa <ref type="bibr" target="#b23">(Zheng et al., 2022)</ref> and <ref type="bibr">T5-3B+PICARD (Scholak et al., 2021)</ref>, RASAT + PI-CARD brings the QEM from 54.6% to 55.7% and IEM from 24.6% to 26.5% on the test set.</p><p>For the same reason as on SParC, we mainly compare QEX/IEX performance on the dev set, and RASAT + PICARD surpasses all models that can predict executable SQLs (with values). Especially for IEX, our model surpasses the previous state-of-the-art from 26.2% to 39.6%, with 13.4% absolute improvement. Moreover, on the official leaderboard of CoSQL which reports over test set, RASAT + PICARD brings the IEX from 8.4% to 37.4%, with 29% absolute improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results on Spider and Spider-Realistic</head><p>The results on the Spider is provided in <ref type="table" target="#tab_9">Table 5</ref>. Our proposed RASAT model achieves state-of-theart performance in EX and competitive results in EM. On the dev set, compared with T5-3B, which also does not use the PICARD during beam search, our model's EX increases from 74.4% to 76.6%, achieving 2.2% absolute improvement. When augmented with PICARD, RASAT+PICARD brings the EX even higher to 80.5%, with 1.2% absolute improvement compared to T5-3B + PICARD. Furthermore, on the official leaderboard of Spider, our proposed RASAT + PICARD brings the EX from 75.1% to 75.5%, achieving new state-of-the-art.</p><p>Furthermore, we also evaluate our model on a more challenging Spider variant, Spider-Realistic <ref type="bibr" target="#b6">(Deng et al., 2021)</ref>. It is a evaluation dataset that has modified the user questions by removing or paraphrasing explicit mentions of column names to present a realistic and challenging setting. Our model also achieves a new state-of-the-art performance <ref type="table" target="#tab_10">(Table 6)</ref>, which suggests strong ability of our model to generalize to unseen data.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Ablation Study</head><p>In this subsection, we conduct a set of ablation studies to examine various aspects of the proposed model.  <ref type="table">Table 9</ref>: Ablation study on the relative contribution of different relation types. Experiment are conducted using RASAT(-small) on the Spider dataset.  <ref type="table" target="#tab_2">Table 10</ref>: Ablation study on the relative contribution of different relation types. Experiment are conducted using RASAT(-3B) on the SParC dataset. "Dp" is short for dependency relation, "Cf" for coreference relation, "SL" for schema linking relation, "SE" for schema encoding relation and "Db" means database content. performance gaps between its T5-3B counterpart. This suggests that the larger T5 model might have learned some of the relational structures implicitly. We believe this is consistent with the findings on other fine-tuning tasks, where larger pretrained models are more capable of capturing the abundant implicit dependencies in the raw text.</p><p>Relation Types. We conducted additional experiments to analyze the relative contribution of different relation types. The experimental results on Spider is shown in <ref type="table">Table 9</ref> while result on SParC is shown in <ref type="table" target="#tab_2">Table 10</ref> (since CoSQL has similar conversational modality with SParC, the experiments are only conducted on SParC). We find that both T5 and RASAT models can benefit from leveraging database content. Another important finding is that the performance has increased obviously by adding dependency relationship to RASAT(-small) on Spider. As for SParC, the database content plays a more important role by looking at EX results; from what we can see, IEX will decrease by 1.9% after removing database content from the input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we propose RASAT, a Relation-Aware Self-Attention-augmented T5 model for the textto-SQL generation. Compared with previous work, RASAT can introduce various structural relations into the sequential T5 model. Different from the more common approach of fine-tuning the original model or using prompt tuning, we propose to augment the self-attention modules in the encoder and introduce new parameters to the model while still being able to leverage the pre-trained weights. RASAT had achieved state-of-the-art performances, especially on execution accuracy, in the three most common text-to-SQL benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitation</head><p>Our method consumes plenty of computational resources since we leverage the large T5-3B model. We train our models on 8 A100 GPUs (80G) for around 2 days. Our model truncates the source sequences to 512, this may lead to information loss when a sample has long input. We find that about 3% of training data in CoSQL will be affected. We only work with English since it has richer analytical tools and resources than other language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2019.</head><p>Towards complex text-to-SQL in crossdomain database with intermediate representation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Model Size</head><p>Compared with the original T5 model, only two embedding matrices are added to the encoder in our model, with 2 ? ? ? d kv parameters. These embedding matrices are shared in each encoder layer and each head. Here ? = 51 is the total number of relations and d kv is the dimension of the key/value states in self-attention (64 in T5-small/base/large and 128 in T5-3B). The overall increase of parameters is less than 0.01%.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Output Comparation between T5 and Tree-based Decoder Model</head><p>Here we show the output difference between models used AST-tree-based decoder and T5. As it shown in <ref type="table" target="#tab_2">Table 12</ref>, models used AST-treebased decoder (such as RAT-SQL <ref type="bibr" target="#b10">(Wang et al., 2020a)</ref>, LGESQL <ref type="bibr" target="#b4">(Cao et al., 2021)</ref>) usually use a place holder (i.e. "value") to represent the real value("France" in this example). These output can not be executed in real database and they fail to evalute in EXecution Accuracy(EX/QEX/IEX) metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Case Study</head><p>In          </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Relations Used in Experiment</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Dp 65.0(+0.5) 45.5(-0.2) 69.9(+0.7) 50.7(+0.3) w/o Cf 65.0(+0.5) 45.0(-0.7) 69.4(+0.2) 50.0(-0.4) w/o Db 64.1(-0.4) 45.3(-0.4) 67.9(-1.3) 48.5(-1.9) w/o SL 64.5 45.5(-0.2) 68.8(-0.4) 49.4(-1.0) w/o SE 63.9(-0.6) 44.6(-1.1) 68.6(-0.6) 48.9(-1.5)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>and T is a span of the entire question PARTIAL-MATCH H is part of T, but the entire question does not contain T</figDesc><table><row><cell>Question Dependency</cell><cell>Q</cell><cell>Q</cell><cell>DEPENDENCY</cell><cell>H has a forward syntactic dependencies on T</cell></row><row><cell>Question Coreference</cell><cell>Q</cell><cell>Q</cell><cell>COREFERENCE</cell><cell>H is the coreference of T</cell></row><row><cell>Database Content</cell><cell>Q</cell><cell>C</cell><cell>VALUE-MATCH</cell><cell>H is part of the candidate cell values of column T</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table /><note>Description of some representatives for each relation type in the interaction graph. For a complete list of relations, please refer to Appendix D.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>? Q i , T ? Q j . To our best knowledge, there are no works utilizing this relation in the text-to-SQL literature despite the importance of this relation. Although pre-trained models like T5 are believed to have the capability to handle this implicitly, we still find that explicitly adding these links could significantly improve the model's performance.Database Content Mentions. Instead of mentioning the table or column names, the user could mention the values in a specific column. In this case, the informative mention could escape from the aforementioned schema linking. In this work, we follow the same procedures in BRIDGE(Lin  et al., 2020b)  to capture database content mentions. It first performs a fuzzy string match between the question tokens and the values of each column in the database. i.e., H ? Q, T ? V. Then the matched values are inserted after the corresponding column name in the input sequence. This relation is denoted as VALUE-MATCH in</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dep</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dep</cell></row><row><cell>Turn 1</cell><cell cols="5">Dep cat as their pets ? Dep Dep Dep Which students have a Dep Dep</cell></row><row><cell></cell><cell>Coref</cell><cell></cell><cell>Coref</cell><cell></cell><cell>Coref</cell></row><row><cell>Turn 2</cell><cell>What are</cell><cell>they</cell><cell cols="2">majoring</cell><cell>in ?</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Coref</cell><cell></cell></row><row><cell>Turn 3</cell><cell cols="3">Also , how old are</cell><cell>they</cell><cell>?</cell></row><row><cell cols="6">Figure 2: An example to show the coreference and syn-</cell></row><row><cell cols="6">tactic dependency relations on user questions between</cell></row><row><cell cols="2">different turns.</cell><cell></cell><cell></cell><cell></cell></row></table><note>H</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Results on SParC dataset. Models in the upper block do not predict SQL values, while the ones in the middle block do.</figDesc><table><row><cell></cell><cell cols="3">Spider Realistic SParC</cell><cell>CoSQL</cell></row><row><cell cols="2">Train 7000</cell><cell>-</cell><cell cols="2">3034/9025 2164/7485</cell></row><row><cell>Dev</cell><cell>1034</cell><cell>508</cell><cell>422/1203</cell><cell>292/1008</cell></row><row><cell>Test</cell><cell>2147</cell><cell>-</cell><cell>842/2498</cell><cell>551/2546</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Accordingly, we propagate the FOREIGN-KEY relation into 4 replicas, pointing from tokens in the source amenid to that of the target one, forming a dense connection between subword tokens on both sides. With relation propagating, we could conveniently adapt word or phrase level relations to our RASAT model while keeping the pretrained weights learned at the subword level intact.</figDesc><table /><note>Dataset statistics for Spider, Spider-Realistic (Realistic in table), SParC and CoSQL. For Spider and Spider-Realistic, the table shows the number of question-SQL pairs in the train-dev-test splits. For SParC and CoSQL, we list both the number of in- teractions and questions in the form of "#interac- tions/#questions".ating a dense connection of the same type of re- lations between the tokens in H and T . For ex- ample, column amenid is a foreign key in table has_amenity and the corresponding primary key is column amenid in table dorm_amenity. Such that there is a directed relation FOREIGN- KEY between the two column names. At subword level, amenid consists of two tokens amen and id.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Results on CoSQL dataset. Models in the upper block do not predict SQL values, while the ones in the middle block do.</figDesc><table><row><cell>Approach</cell><cell>Dev</cell><cell></cell><cell>Test</cell><cell></cell></row><row><cell></cell><cell cols="4">EM EX EM EX</cell></row><row><cell>RAT-SQL+BERT</cell><cell>69.7</cell><cell>-</cell><cell>65.6</cell><cell>-</cell></row><row><cell cols="2">LGESQL+ELECTRA 75.1</cell><cell>-</cell><cell>72.0</cell><cell>-</cell></row><row><cell>S?SQL + ELECTRA</cell><cell>76.4</cell><cell>-</cell><cell>72.1</cell><cell>-</cell></row><row><cell>BRIDGE v2+BERT</cell><cell cols="4">71.1 70.3 67.5 68.3</cell></row><row><cell>NatSQL+GAP</cell><cell cols="4">73.7 75.0 68.7 73.3</cell></row><row><cell>SmBoP + GraPPa</cell><cell cols="4">74.7 75.0 69.5 71.1</cell></row><row><cell>T5-3B</cell><cell cols="4">71.5 74.4 68.0 70.1</cell></row><row><cell>T5-3B + PICARD</cell><cell cols="4">75.5 79.3 71.9 75.1</cell></row><row><cell>RASAT</cell><cell cols="2">72.6 76.6</cell><cell>-</cell><cell>-</cell></row><row><cell>RASAT+PICARD</cell><cell cols="4">75.3 80.5 70.9 75.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>Approach</cell><cell>EM EX</cell></row><row><cell cols="2">RAT-SQL+STRUG (Deng et al., 2021) 62.2 65.7</cell></row><row><cell>T5-3B (Scholak et al., 2021)</cell><cell>62.0 64.1</cell></row><row><cell cols="2">T5-3B+PICARD (Scholak et al., 2021) 68.7 71.4</cell></row><row><cell>RASAT</cell><cell>65.2 65.8</cell></row><row><cell>RASAT+PICARD</cell><cell>69.7 71.9</cell></row><row><cell>: Results on Spider dataset. Models in the up-</cell><cell></cell></row><row><cell>per block do not predict SQL values, while the ones in</cell><cell></cell></row><row><cell>the middle block do. We compare RASAT with some</cell><cell></cell></row><row><cell>important baseline methods, such as RAT-SQL (Wang</cell><cell></cell></row><row><cell>et al., 2020a), Bridge (Lin et al., 2020b), GAZP (Zhong</cell><cell></cell></row><row><cell>et al., 2020), NatSQL (Gan et al., 2021), SmBoP (Ru-</cell><cell></cell></row><row><cell>bin and Berant, 2021), LGESQL (Cao et al., 2021),</cell><cell></cell></row><row><cell>S 2 SQL (Hui et al., 2022), T5 and PICARD (Scholak</cell><cell></cell></row><row><cell>et al., 2021).</cell><cell></cell></row><row><cell>coreference resolution, we use coreferee 3 to yield</cell><cell></cell></row><row><cell>coreference links. In total, 51 types of relations</cell><cell></cell></row><row><cell>are used (c.f. Appendix D for a detailed list). For</cell><cell></cell></row><row><cell>dependency parsing, stanza (Qi et al., 2020) is used.</cell><cell></cell></row><row><cell>The batch size we used is 2048. We use Adafac-</cell><cell></cell></row><row><cell>tor (Shazeer and Stern, 2018) as optimizer and the</cell><cell></cell></row><row><cell>learning rate is 1e-4. We set "parse with guards"</cell><cell></cell></row><row><cell>mode for PICARD and beam size is set to 8. The</cell><cell></cell></row><row><cell>max tokens to check for PICARD is 2. Experiments</cell><cell></cell></row><row><cell>are run on NVIDIA A100-SXM4-80GB GPUs.</cell><cell></cell></row></table><note>3 https://github.com/msg-systems/coreferee</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table /><note>Results on Spider-Realistic dataset. We re- produce Scholak et al. (2021) 's method to get the per- formance of T5-3B (+PICARD) and the performance of RAT-SQL+STRUG are from Deng et al. (2021) re- ported.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>EX accuracy of RASAT+PICARD and T5-3B+PICARD on the examples of Spider dev set with different levels of difficulty.</figDesc><table><row><cell>Approach</cell><cell>EM</cell><cell>EX</cell></row><row><cell>T5-small</cell><cell>47.2</cell><cell>47.8</cell></row><row><cell cols="3">RASAT(-small) 53.0(+5.8) 53.7(+5.9)</cell></row><row><cell>T5-base</cell><cell>57.2</cell><cell>57.9</cell></row><row><cell>RASAT(-base)</cell><cell cols="2">60.4(+3.2) 61.3(+3.4)</cell></row><row><cell>T5-large</cell><cell>65.3</cell><cell>67.2</cell></row><row><cell>RASAT(-large)</cell><cell cols="2">66.7(+1.4) 69.2(+2.0)</cell></row><row><cell>T5-3B</cell><cell>71.5</cell><cell>74.4</cell></row><row><cell>RASAT(-3B)</cell><cell cols="2">72.6(+1.1) 76.6(+2.2)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 8 :</head><label>8</label><figDesc>Result for different T5 model sizes on Spider dev set. The performance of T5 baselines are from Scholak et al. (2021).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>Due to the limited availability of the test sets, all numbers in this subsection are reported on the dev set.</figDesc><table><row><cell>Approach</cell><cell>EM</cell><cell>EX</cell></row><row><cell>T5-small</cell><cell>47.2</cell><cell>47.8</cell></row><row><cell>w/o db_content</cell><cell cols="2">45.8(-1.4) 46.9(-0.9)</cell></row><row><cell>RASAT(-small)</cell><cell>53.0</cell><cell>53.7</cell></row><row><cell>w/o db_content</cell><cell cols="2">52.6(-0.4) 52.9(-0.8)</cell></row><row><cell cols="3">w/o dependency 51.3(-1.7) 51.7(-2.0)</cell></row><row><cell></cell><cell></cell><cell>Effect on SQL difficulty. One might conjecture</cell></row><row><cell></cell><cell></cell><cell>that the introduced relations are only effective for</cell></row><row><cell></cell><cell></cell><cell>more difficult, longer SQL query predictions, while</cell></row><row><cell></cell><cell></cell><cell>for predicting short SQL queries, the original T5</cell></row><row><cell></cell><cell></cell><cell>model could handle equally well. Thus, we evalu-</cell></row><row><cell></cell><cell></cell><cell>ate our model according to the difficulty of the</cell></row><row><cell></cell><cell></cell><cell>examples, where the question/SQL pairs in the</cell></row><row><cell></cell><cell></cell><cell>dev set are categorized into four subsets, i.e., easy,</cell></row><row><cell></cell><cell></cell><cell>medium, hard, and extra hard, according to their</cell></row><row><cell></cell><cell></cell><cell>level of difficulty. In Table 7 we provide a com-</cell></row><row><cell></cell><cell></cell><cell>parison between T5-3B + PICARD (Scholak et al.,</cell></row><row><cell></cell><cell></cell><cell>2021) and RASAT + PICARD on the EX metric</cell></row><row><cell></cell><cell></cell><cell>on the four subsets. RASAT + PICARD surpasses</cell></row><row><cell></cell><cell></cell><cell>T5-3B + PICARD across all subsets, validating the</cell></row><row><cell></cell><cell></cell><cell>effectiveness of the introduced relational structures</cell></row><row><cell></cell><cell></cell><cell>for all SQL sequences.</cell></row><row><cell></cell><cell></cell><cell>Model Size Impact. To test the effectiveness of</cell></row><row><cell></cell><cell></cell><cell>the introduced relational structures on pretrained</cell></row><row><cell></cell><cell></cell><cell>models with different sizes, we implant RASAT</cell></row><row><cell></cell><cell></cell><cell>into four T5 models of different sizes (T5-small,</cell></row><row><cell></cell><cell></cell><cell>T5-base, T5-large, T5-3B) and test it on Spider</cell></row><row><cell></cell><cell></cell><cell>(Table 8). Interestingly, for smaller pretrained mod-</cell></row><row><cell></cell><cell></cell><cell>els, our RASAT model could bring even larger</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4524-4535, Florence, Italy. Association for Computational Linguistics.</figDesc><table><row><cell>the limits of transfer learning with a unified text-to-</cell><cell></cell><cell></cell></row><row><cell>text transformer. Journal of Machine Learning Re-</cell><cell></cell><cell></cell></row><row><cell>search, 21(140):1-67.</cell><cell></cell><cell></cell></row><row><cell>Ohad Rubin and Jonathan Berant. 2021. SmBoP:</cell><cell></cell><cell></cell></row><row><cell>Semi-autoregressive bottom-up semantic parsing. In</cell><cell></cell><cell></cell></row><row><cell>Proceedings of the 2021 Conference of the North</cell><cell></cell><cell></cell></row><row><cell>American Chapter of the Association for Computa-</cell><cell cols="2">Pengcheng He, Yi Mao, Kaushik Chakrabarti, and</cell></row><row><cell>tional Linguistics: Human Language Technologies,</cell><cell cols="2">Weizhu Chen. 2019. X-SQL: reinforce schema</cell></row><row><cell>pages 311-324, Online. Association for Computa-</cell><cell>representation with context.</cell><cell>arXiv preprint</cell></row><row><cell>tional Linguistics.</cell><cell>arXiv:1908.08113.</cell><cell></cell></row><row><cell>Torsten Scholak, Nathan Schucher, and Dzmitry Bah-danau. 2021. PICARD: Parsing incrementally for constrained auto-regressive decoding from language models. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 9895-9901, Online and Punta Cana, Domini-can Republic. Association for Computational Lin-guistics.</cell><cell cols="2">Binyuan Hui, Ruiying Geng, Qiyu Ren, Binhua Li, Yongbin Li, Jian Sun, Fei Huang, Luo Si, Pengfei Zhu, and Xiaodan Zhu. 2021. Dynamic hybrid rela-tion exploration network for cross-domain context-dependent semantic parsing. In Proceedings of the AAAI Conference on Artificial Intelligence, vol-ume 35, pages 13116-13124.</cell></row><row><cell>Peter Shaw, Ming-Wei Chang, Panupong Pasupat, and Kristina Toutanova. 2021. Compositional general-ization and natural language variation: Can a se-mantic parsing approach handle both? In Proceed-ings of the 59th Annual Meeting of the Association</cell><cell cols="2">Binyuan Hui, Ruiying Geng, Lihan Wang, Bowen Qin, Bowen Li, Jian Sun, and Yongbin Li. 2022. S 2 SQL: Injecting syntax to question-schema inter-action graph encoder for text-to-sql parsers. arXiv preprint arXiv:2203.06958.</cell></row><row><cell>for Computational Linguistics and the 11th Interna-tional Joint Conference on Natural Language Pro-cessing (Volume 1: Long Papers), pages 922-938, Online. Association for Computational Linguistics.</cell><cell cols="2">Wonseok Hwang, Jinyeong Yim, Seunghyun Park, and Minjoon Seo. 2019. A comprehensive exploration on wikisql with table-aware word contextualization. arXiv preprint arXiv:1902.01069.</cell></row><row><cell>Peter Shaw, Jakob Uszkoreit, and Ashish Vaswani. 2018. Self-attention with relative position represen-tations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for</cell><cell cols="2">Aishwarya Kamath and Rajarshi Das. 2018. survey on semantic parsing. arXiv preprint A arXiv:1812.00978.</cell></row><row><cell>Computational Linguistics: Human Language Tech-nologies, Volume 2 (Short Papers), pages 464-468, New Orleans, Louisiana. Association for Computa-tional Linguistics.</cell><cell cols="2">Yuntao Li, Hanchu Zhang, Yutian Li, Sirui Wang, Wei Wu, and Yan Zhang. 2021. Pay more attention to his-tory: A context modeling strategy for conversational text-to-sql.</cell></row><row><cell>Noam Shazeer and Mitchell Stern. 2018. Adafactor: Adaptive learning rates with sublinear memory cost. In International Conference on Machine Learning, pages 4596-4604. PMLR.</cell><cell cols="2">Xi Victoria Lin, Richard Socher, and Caiming Xiong. 2020a. Bridging textual and tabular data for cross-domain text-to-sql semantic parsing. In Findings of the Association for Computational Linguistics:</cell></row><row><cell></cell><cell>EMNLP 2020, pages 4870-4888.</cell><cell></cell></row><row><cell></cell><cell cols="2">Xi Victoria Lin, Richard Socher, and Caiming Xiong.</cell></row><row><cell></cell><cell cols="2">2020b. Bridging textual and tabular data for cross-</cell></row><row><cell></cell><cell cols="2">domain text-to-SQL semantic parsing. In Findings</cell></row><row><cell></cell><cell cols="2">of the Association for Computational Linguistics:</cell></row><row><cell></cell><cell cols="2">EMNLP 2020, pages 4870-4888, Online. Associa-</cell></row><row><cell></cell><cell>tion for Computational Linguistics.</cell><cell></cell></row><row><cell></cell><cell cols="2">Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton,</cell></row><row><cell></cell><cell cols="2">and Christopher D. Manning. 2020. Stanza: A</cell></row><row><cell></cell><cell cols="2">python natural language processing toolkit for many</cell></row><row><cell></cell><cell cols="2">human languages. In Proceedings of the 58th An-</cell></row><row><cell></cell><cell cols="2">nual Meeting of the Association for Computational</cell></row><row><cell></cell><cell cols="2">Linguistics: System Demonstrations, pages 101-</cell></row><row><cell></cell><cell cols="2">108, Online. Association for Computational Linguis-</cell></row><row><cell></cell><cell>tics.</cell><cell></cell></row><row><cell></cell><cell cols="2">Colin Raffel, Noam Shazeer, Adam Roberts, Kather-</cell></row><row><cell></cell><cell cols="2">ine Lee, Sharan Narang, Michael Matena, Yanqi</cell></row><row><cell></cell><cell cols="2">Zhou, Wei Li, and Peter J. Liu. 2020. Exploring</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 11 :</head><label>11</label><figDesc>The number of paramerter comparation between RASAT and the same size T5 model.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 13</head><label>13</label><figDesc>, we demonstrate how the introduced relation could help the model predict SQL structures more accurately by demonstrating 2 examples of question-SQL pairs sampled from the SParC dev set. We compare the predictions from T5-3B and our model, and both the two examples have three turns in the interaction. For the first case, the vanilla T5-3B model neglects the condition "employees who are under age 30" when answering Question #3, while RASAT-SQL predicts it correctly by exploiting the relations inside the contexts.For the second case, the database schema is more complex, and the table course_arrange has no such a column called course. If one would like to access column course, the foreign key must be used. RASAT gives the correct SQL since these types of relational structures are explicitly embedded in the RASAT model, while the vanilla T5-3B fails to do it.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 14</head><label>14</label><figDesc>What is the average, minimum, and maximum age of all singers from France? Tree-based model SELECT AVG(singer.Age) , MAX(singer.Age) , MIN(singer.Age) FROM singer WHERE singer.Country = "value" RASAT SELECT AVG(singer.Age) , MAX(singer.Age) , MIN(singer.Age) FROM singer WHERE singer.Country = "F rance"</figDesc><table><row><cell>shows all relations used in our experi-</cell></row><row><cell>ment while most of these are consistant with RAT-</cell></row><row><cell>SQL (Wang et al., 2020a) and LGESQL (Cao et al.,</cell></row><row><cell>2021). There are total 51 kinds relation used.</cell></row></table><note>Question</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 12 :</head><label>12</label><figDesc>An example to show the difference between AST-based decoder model's output and T5's output. Description A database about employee hiring and evaluation. Goal Find cities which more than one employee under age 30 come from. SELECT city FROM employee WHERE age &lt;30 RASAT SELECT city FROM employee WHERE age &lt;30 Question #3 Show the cities from which more than one employee originated. T5-3B SELECT city FROM employee GROUP BY city HAVING COUNT(*) &gt;1 RASAT SELECT city FROM employee WHERE age &lt;30 GROUP BY city HAVING COUNT(*) &gt;1 Description A database about courses and teachers. Goal Show names of teachers and the courses they are arranged to teach in ascending alphabetical order of the teacher's name. FROM course_arrange Question #2 Show names of teachers and the courses they are arranged to teach. T5-3B SELECT T2.name, T1.course FROM course_arrange AS T1 JOIN teacher AS T2 ON T1.teacher_id = T2.teacher_id RASAT SELECT T2.name, T3.course FROM course_arrange AS T1 JOIN teacher AS T2 ON T1.teacher_id = T2.teacher_id JOIN course AS T3 ON T1.course_id = T3.course_id Question #3 Sort the results by teacher's name T5-3B SELECT T2.name, T1.course FROM course_arrange AS T1 JOIN teacher AS T2 ON T1.teacher_id = T2.teacher_id ORDER BY T2.name RASAT SELECT T3.name, T2.course FROM course_arrange AS T1 JOIN course AS T2 ON T1.course_id = T2.course_id JOIN teacher AS T3 ON T1.teacher_id = T3.teacher_id ORDER BY T3.name</figDesc><table><row><cell cols="2">Question #1 Find all employees who are under age 30.</cell></row><row><cell>T5-3B</cell><cell>SELECT * FROM employee WHERE age &lt;30</cell></row><row><cell>RASAT</cell><cell>SELECT * FROM employee WHERE age &lt;30</cell></row><row><cell cols="2">Question #2 Which cities did they come from?</cell></row><row><cell>T5-3B</cell><cell></cell></row><row><cell cols="2">Question #1 Find all the course arrangements.</cell></row><row><cell>T5-3B</cell><cell>SELECT * FROM course_arrange</cell></row><row><cell>RASAT</cell><cell>SELECT *</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 13 :</head><label>13</label><figDesc>Some examples in the SParC dev set. RASAT gives all correct predictions in these cases while the original T5-3B model fails. Valuematch Question item H is spelled exactly the same as a value in column item T</figDesc><table><row><cell cols="3">Head H Tail T Edge label</cell><cell>Description</cell></row><row><cell></cell><cell></cell><cell>Question-Question-Dist*</cell><cell>Question item H is at a distance of * before question item T in the input question</cell></row><row><cell></cell><cell></cell><cell>Question-Question-Identity</cell><cell>Question item H is question item T itself</cell></row><row><cell></cell><cell></cell><cell>Question-Question-Generic</cell><cell>Question item H and question item T has no pre-defined relation</cell></row><row><cell>Q</cell><cell>Q</cell><cell>Forward-Syntax</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Backward-Syntax</cell><cell>Question item H has a forward/reverse/no syntactic dependencies on question item T</cell></row><row><cell></cell><cell></cell><cell>None-Syntax</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Co_Relations</cell><cell>Question item H and question item T are considered as a whole in coreference relation</cell></row><row><cell></cell><cell></cell><cell>Coref_Relations</cell><cell>Question item H is the coreference of question item T</cell></row><row><cell>Q</cell><cell>S</cell><cell>Question-*-Generic</cell><cell>Question item H and database item T has no pre-defined relation</cell></row><row><cell></cell><cell></cell><cell>Question-Table-Exactmatch</cell><cell></cell></row><row><cell>Q</cell><cell>T</cell><cell>Question-Table-Partialmatch</cell><cell>Question item H is spelled exactly/partially/not the same as table item T</cell></row><row><cell></cell><cell></cell><cell>Question-Table-Nomatch</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Question-Column-Exactmatch</cell><cell></cell></row><row><cell>Q</cell><cell>C</cell><cell>Question-Column-Partialmatch Question-Column-Nomatch</cell><cell>Question item H is spelled exactly/partially/not the same as column item T</cell></row><row><cell cols="3">Question-Column-S Q *-Question-Generic</cell><cell>Database item H and question item T has no pre-defined relation</cell></row><row><cell>S</cell><cell>S</cell><cell>*-*-Identity</cell><cell>Database item H is database item T itself</cell></row><row><cell>S</cell><cell>T</cell><cell>*-Table-Generic</cell><cell>Database item H and table item T has no pre-defined relation</cell></row><row><cell>S</cell><cell>C</cell><cell>*-Column-Generic</cell><cell>Database item H and column item T has no pre-defined relation</cell></row><row><cell>T</cell><cell>Q</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table - Table</head><label>-</label><figDesc>Question-ExactmatchTable item H is spelled exactly/partially/not the same as question item T</figDesc><table><row><cell></cell><cell></cell><cell>-Question-Partialmatch</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Table-Question-Nomatch</cell><cell></cell></row><row><cell>T</cell><cell>S</cell><cell>Table-*-Generic</cell><cell>Table item H and database item T has no pre-defined relation</cell></row><row><cell>T</cell><cell>T</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table - Table</head><label>-</label><figDesc></figDesc><table /><note>-Generic Table item H and table item T has no pre-defined relation</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table - Table</head><label>-</label><figDesc></figDesc><table /><note>-Identity Table item H is table item T itself</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table - Table -</head><label>--</label><figDesc>Fk At least one column in table item H is a foreign key for certain column in table item T Table-Table-Fkr At least one column in table item T is a foreign key for certain column in table item H Table-Table-Fkb Table item H and T satisfy both "Table-Table-Fk" and "Table-Table-Fkr" relations</figDesc><table><row><cell>T</cell><cell>C</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table -</head><label>-</label><figDesc>Valuematch Column item H is spelled exactly the same as a value in question item T</figDesc><table><row><cell></cell><cell></cell><cell>Column-Pk</cell><cell>Column item T is the primary key for table item H</cell></row><row><cell></cell><cell></cell><cell>Table-Column-Has</cell><cell>Column item T belongs to table item H</cell></row><row><cell></cell><cell></cell><cell>Table-Column-Generic</cell><cell>Table item H and column item T has no pre-defined relation</cell></row><row><cell></cell><cell></cell><cell>Column-Question-Exactmatch</cell><cell></cell></row><row><cell>C</cell><cell>Q</cell><cell>Column-Question-Partialmatch Column-Question-Nomatch</cell><cell>Column item H is spelled exactly/partially/not the same as table item T</cell></row><row><cell cols="3">Column-Question-C S Column-*-Generic</cell><cell>Column item H and database item T has no pre-defined relation</cell></row><row><cell></cell><cell></cell><cell>Column-Table-Pk</cell><cell>Column item H is the primary key for table item T</cell></row><row><cell>C</cell><cell>T</cell><cell>Column-Table-Has</cell><cell>Column item H belongs to table item T</cell></row><row><cell></cell><cell></cell><cell>Column-Table-Generic</cell><cell>Column item H and table item T has no pre-defined relation</cell></row><row><cell></cell><cell></cell><cell>Column-Column-Identity</cell><cell>Column item H is column item T itself</cell></row><row><cell>C</cell><cell>C</cell><cell>Column-Column-Sametable</cell><cell>Column item H and column item T are in the same table</cell></row><row><cell></cell><cell></cell><cell>Column-Column-Fk Column-Column-Fkr</cell><cell>Column item H has a forward/reverse foreign key constraint relation with Column item T</cell></row><row><cell></cell><cell></cell><cell>Column-Column-Generic</cell><cell>Column item H and column item T has no pre-defined relation</cell></row><row><cell>C</cell><cell>V</cell><cell>Has-Dbcontent</cell><cell>Db content item T belongs to column item H</cell></row><row><cell>V</cell><cell>C</cell><cell>Has-Dbcontent-R</cell><cell>Db content item H belongs to column item T</cell></row><row><cell></cell><cell></cell><cell>No-Relation</cell><cell>Item H and item T has no relation (Used when item H or item T is a delimiter)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head>Table 14 :</head><label>14</label><figDesc>All relations used in our experiment. V is the matched question item that extracted from Q.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was sponsored by the National Natural Science Foundation of China (NSFC) grant (No. 62106143), and Shanghai Pujiang Program (No. 21PJ1405700). We would like to thank Tao Yu, Hongjin Su, and Yusen Zhang for running evaluations on our submitted models.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Global reasoning over database structures for textto-SQL parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1378</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3659" to="3664" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Bogin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.06241</idno>
		<title level="m">Representing schema structure with graph neural networks for text-to-sql parsing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sadga: Structure-aware dual graph aggregation network for text-to-sql</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruichu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinjie</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="7664" to="7676" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">IGSQL: Database schema interaction graph based neural model for context-dependent text-to-SQL generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yitao</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Wan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.560</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6903" to="6912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">LGESQL: Line graph enhanced text-to-SQL model with mixed local and nonlocal relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruisheng</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Su</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.198</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2541" to="2555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">RYANSQL: Recursively applying sketch-based slot fillings for complex text-to-SQL in cross-domain databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeong Cheol</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunggyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong Ryeol</forename><surname>Shin</surname></persName>
		</author>
		<idno type="DOI">10.1162/coli_a_00403</idno>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="309" to="332" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Structure-grounded pretraining for text-to-SQL</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">Hassan</forename><surname>Awadallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.naacl-main.105</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1337" to="1350" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural SQL: Making SQL easier to infer from natural language specifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujian</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxia</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Purver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Woodward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Drake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaofu</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-emnlp.174</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2021</title>
		<meeting><address><addrLine>Punta Cana, Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2030" to="2042" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zecheng</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Guang</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Zhang</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">RAT-SQL: Relation-aware schema encoding and linking for text-to-SQL parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.677</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7567" to="7578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Relational graph attention network for aspect-based sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhou</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunyi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.295</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3229" to="3238" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Tracking interaction states for multiturn text-to-sql semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Run-Ze</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="13979" to="13987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">An interactive nl2sql approach with reuse strategy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaxia</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidan</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Database Systems for Advanced Applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="280" to="288" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teven</forename><forename type="middle">Le</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Drame</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-demos.6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Quentin Lhoest, and Alexander Rush</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianbao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Henry</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiqi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Scholak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chien-Sheng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.05966</idno>
		<title level="m">Unifiedskg: Unifying and multi-tasking structured knowledge grounding with text-to-text language models</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04436</idno>
		<title level="m">Sqlnet: Generating structured queries from natural language without reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A syntactic neural model for general-purpose code generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P17-1041</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="440" to="450" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">CoSQL: A conversational text-to-SQL challenge towards crossdomain natural language interfaces to databases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heyang</forename><surname>Er</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Chern Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youxuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungrok</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Fabbri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dixit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Lasecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1204</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1962" to="1979" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Score: Pretraining for context representation in conversational semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Polozov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Meek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">Hassan</forename><surname>Awadallah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Spider: A largescale human-labeled dataset for complex and crossdomain semantic parsing and text-to-SQL task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingning</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanelle</forename><surname>Roman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1425</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3911" to="3921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">SParC: Cross-domain semantic parsing in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chern Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heyang</forename><surname>Er</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreya</forename><surname>Dixit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Proctor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungrok</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Kraft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1443</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4511" to="4523" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Editing-based SQL query generation for cross-domain context-dependent questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heyang</forename><surname>Er</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungrok</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Victoria Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianze</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Radev</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1537</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5338" to="5349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Hie-sql: History information enhanced network for contextdependent text-to-sql semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanzhao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baohua</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changshan</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.07376</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Grounded adaptation for zeroshot executable semantic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida</forename><forename type="middle">I</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.558</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6869" to="6882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.00103</idno>
		<title level="m">Seq2sql: Generating structured queries from natural language using reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
