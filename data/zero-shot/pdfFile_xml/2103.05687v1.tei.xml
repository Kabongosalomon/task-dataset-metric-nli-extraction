<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Capturing Omni-Range Context for Omnidirectional Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
							<email>kailun.yang@kit.edu</email>
							<affiliation key="aff0">
								<orgName type="department">CV:HCI</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Zhang</surname></persName>
							<email>jiaming.zhang@kit.edu</email>
							<affiliation key="aff0">
								<orgName type="department">CV:HCI</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Rei?</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">CV:HCI</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">ZEISS</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Hu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Huawei Technologies</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
							<email>rainer.stiefelhagen@kit.edu</email>
							<affiliation key="aff0">
								<orgName type="department">CV:HCI</orgName>
								<orgName type="institution">Karlsruhe Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Capturing Omni-Range Context for Omnidirectional Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T02:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Convolutional Networks (ConvNets) excel at semantic segmentation and have become a vital component for perception in autonomous driving. Enabling an allencompassing view of street-scenes, omnidirectional cameras present themselves as a perfect fit in such systems. Most segmentation models for parsing urban environments operate on common, narrow Field of View (FoV) images. Transferring these models from the domain they were designed for to 360 ? perception, their performance drops dramatically, e.g., by an absolute 30.0% (mIoU) on established test-beds. To bridge the gap in terms of FoV and structural distribution between the imaging domains, we introduce Efficient Concurrent Attention Networks (ECANets), directly capturing the inherent long-range dependencies in omnidirectional imagery. In addition to the learned attentionbased contextual priors that can stretch across 360 ? images, we upgrade model training by leveraging multi-source and omni-supervised learning, taking advantage of both: Densely labeled and unlabeled data originating from multiple datasets. To foster progress in panoramic image segmentation, we put forward and extensively evaluate models on Wild PAnoramic Semantic Segmentation (WildPASS), a dataset designed to capture diverse scenes from all around the globe. Our novel model, training regimen and multisource prediction fusion elevate the performance (mIoU) to new state-of-the-art results on the public PASS (60.2%) and the fresh WildPASS (69.0%) benchmarks. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Convolutional Networks (ConvNets) reach striking performance on semantic segmentation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b33">34]</ref>, a dense visual recognition task that aims at transforming an image into its underlying semantic regions. Particularly, segmenting images of road scenes automatically is of interest as it lies vital groundwork for scene understanding in an autonomous driving environment <ref type="bibr" target="#b25">[26]</ref>. Most segmentation algorithms <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b72">73]</ref> are designed to work on pinholecamera images whose Field of View (FoV) is rather narrow, capturing only a fraction of what is occurring on and aside the road. For a more holistic view on street-scenes, omnidirectional cameras are becoming ubiquitous in autonomous driving systems <ref type="bibr" target="#b70">[71]</ref>, as their capability of all-around sensing, gives rise to comprehensive 360 ? scene understanding. Yet, rather than designing models based on the new imaging modality, predominantly, due to lack of sufficient labeled data, narrow FoV-trained models are applied to yield a segmentation <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b58">59]</ref>. Brought about by the large mismatch in FoV and structural distribution between imaging domains, this practice causes significant performance degradation, even to a point of rendering the perception of surroundings completely unreliable <ref type="bibr" target="#b69">[70]</ref>. <ref type="figure" target="#fig_0">Fig. 1</ref> shows the distribution of semantic classes along the viewing angle, where green-tinted regions indicate the section visible to a front-facing narrow FoV camera. It becomes apparent, that the positional priors in narrow-and omnidirectional images diverge severely, e.g., the road class occupies much of the center portion in narrow FoV images, which, in 360 ? images, is far smaller at viewing angles perpendicular to the front-facing direction (180 ? ). These observations suggest distinct contextual priors between the imaging techniques, which provide critical cues for semantic segmentation <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b86">87]</ref>. Here, we address the challenging problem of leveraging inherent long-range contextual priors unique to omnidirectional images, that previous systems fail to harvest <ref type="bibr" target="#b68">[69]</ref>. We lift the widely used, but computationally expensive non-local operations based on pixel-to-pixel correlations <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b63">64]</ref> to the 360 ? FoV scenario in a computationally efficient fashion, i.e., modeling correlations of each position to omni-range regions. By design, non-local attention <ref type="bibr" target="#b63">[64]</ref> is meant to aggregate associations from highly correlated positions like regions of homogeneous classes, which often lie in the horizontal direction at a similar height, e.g., the sidewalks can be distributed across 360 ? but principally in the lower part of street-scenes. As preliminary investigation, we calculate the mean of the Pearson correlation coefficient r(X dir ) of the probability distribution over the classes in either the horizontal r(X hor ) = 0.37 or vertical r(X ver ) = 0.16 direction. In light of the substantially larger class-correlation of pixels observed horizontally, one can expect designing an attention module with emphasis in the large-FoV widthwise dimension to be advantageous, which reinforces the model's discriminability while eliminating redundant computation on weakly-correlated pixels belonging to heterogeneous semantics. With this rationale, we propose Efficient Concurrent Attention Networks (ECANets) for capturing omni-range dependencies within wide-FoV imagery.</p><p>Aside from considering the inherent properties of 360 ? data in architecture design, training such models is not straightforward, as a lack of sufficient annotated panoramic images impedes optimization. The labeling process is extremely time-and labor-intensive, thus, only few surroundview datasets <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b75">76]</ref> are publicly accessible and none capture as diverse scenes as contemporary pinhole datasets <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b57">58]</ref> do. This is why, to unlock the full potential of our novel ECANet architecture, we propose a multi-source omni-supervised learning regimen that intertwines training on unlabeled, full-sized panoramic images and densely labeled pinhole images. By means of data distillation <ref type="bibr" target="#b45">[46]</ref> and our novel multi-source prediction fusion, we increase prediction certainty, ingrain long-range contextual priors while still benefiting from large-scale, narrow FoV segmentation datasets.</p><p>To facilitate progress in omnidirectional semantic image segmentation, we put forward the Wild PAnoramic Seman-tic Segmentation (WildPASS) dataset for evaluating models in unconstrained environments, featuring scenes collected from all around the globe, reflecting the perception challenge of autonomous driving in the real world. An exhaustive number of diverse experiments demonstrate the proposed ECANet model, learning-and fusion strategy make it possible to deploy highly efficient ConvNets for panoramic image segmentation, surpassing the state-of-the-art on the public PASS <ref type="bibr" target="#b68">[69]</ref> and novel WildPASS datasets. On a glance, we deliver the following contributions:</p><p>? </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Context-aware semantic segmentation. Semantic segmentation has progressed exponentially since the conception of fully convolutional networks <ref type="bibr" target="#b33">[34]</ref> and the groundwork laid by early encoder-decoder architectures <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>Building atop classification networks <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b21">22]</ref>, DeepLab <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>, PSPNet <ref type="bibr" target="#b90">[91]</ref>, RefineNet <ref type="bibr" target="#b30">[31]</ref> and DenseA-SPP <ref type="bibr" target="#b72">[73]</ref> leverage pre-trained models and achieve notable performance improvements. Yet, a lot of progress is driven by sub-modules like dilated convolutions <ref type="bibr" target="#b80">[81]</ref>, large kernels <ref type="bibr" target="#b42">[43]</ref>, pyramid-, strip-and atrous spatial pyramid pooling <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b90">91]</ref> for capturing structured context.</p><p>A second branch of work takes advantage of recent channel/spatial attention mechanisms <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b64">65]</ref> to exploit global context <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b85">86]</ref>, dimension-wise priors <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b71">72]</ref> and cross-modal features <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b66">67,</ref><ref type="bibr" target="#b87">88]</ref>. More recently, inspired by non-local blocks in recognition tasks <ref type="bibr" target="#b63">[64]</ref>, DANet <ref type="bibr" target="#b16">[17]</ref> and OCNet <ref type="bibr" target="#b82">[83]</ref> adopt self-attention <ref type="bibr" target="#b59">[60]</ref> to capture either associations between any pair of pixels/channels or dense object context, respectively. Further, point-wise attention is adaptively learned in <ref type="bibr" target="#b91">[92]</ref>. This trend prompts a variety of attention modules <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b31">32]</ref>, as well as graph-based models <ref type="bibr" target="#b76">[77,</ref><ref type="bibr" target="#b88">89]</ref> and factorized variants <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b74">75]</ref>. With the nature of dense prediction in segmentation, the computational cost induced by combinatorics of pixel-pairs becomes infeasible very fast, which is amplified when working on pixel-rich, extra-wide panoramic images. In order to reduce these pair-wise computations, CCNet <ref type="bibr" target="#b24">[25]</ref> operates in criss-cross paths, Axial-DeepLab <ref type="bibr" target="#b60">[61]</ref> propagates along height-and width-axis sequentially, while <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b76">77,</ref><ref type="bibr" target="#b93">94]</ref>  act on key responding positions. Addressing the nature of omni-range contextual priors in panoramic images, we propose an efficient concurrent attention module. Unlike context-aware networks <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b24">25]</ref> that only aggregate spatial dependency or refine pixel-level context, our attention concurrently highlights horizontally-driven dependencies and collects global contextual information for wide-FoV segmentation. While accuracy-oriented networks reach high performance, efficient networks like Fast-SCNN <ref type="bibr" target="#b44">[45]</ref>, CGNet <ref type="bibr" target="#b65">[66]</ref> and ERFNet <ref type="bibr" target="#b47">[48]</ref> aim to perform both swift and accurate segmentation. Further, a subset of compact ConvNets <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b78">79]</ref> utilize attention mechanisms to efficiently aggregate context. However, these methods do not consider inherent properties of omnidirectional imagery, and thus suffer from large accuracy degradation on such data. Our solution to solve this issue extends the line of efficient ConvNets and consistently elevates their performance and reliability when operating on panoramic images. Omnidirectional semantic segmentation. As systems progressed towards 360 ? perception, early omnidirectional segmentation works were based on fisheye images <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b73">74]</ref> or focused on indoor scenes <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b55">56]</ref> with surround-view systems in street-scenes being largely based on a multitude of cameras <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b46">47]</ref>. Motivated by the prospect of attaining 360 ? semantic perception based on a singular panoramic camera, recent works build semantic segmentation systems directly on top of this sensormodality <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b84">85]</ref>. However, these methods rely on either expensive manually labeled or synthesized omnidirectional data, that does not capture the diversity nor the realism as seen in large-scale pinhole image collections with rich ontologies <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b57">58]</ref>. With this sentiment in mind, we introduce the WildPASS dataset, comprising 360 ? images from over 60 cities and multiple continents, encouraging a more realistic assessment of panoramic segmentation performance. Yang et al. presented a framework <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b69">70]</ref> for re-using models trained on pinhole images via style trans-fer <ref type="bibr" target="#b92">[93]</ref> and separating the panorama into multiple partitions for predictions, each resembling a narrow FoV image. While quite accurate, running multiple forward passes suffers from high latency <ref type="bibr" target="#b68">[69]</ref> and disregards global context information within the panorama, as it is divided into patches. With our holistic view on panoramic image segmentation, we cut this computational burden by nearly a factor of four, extending the framework in <ref type="bibr" target="#b70">[71]</ref> with a multisource omni-supervised learning regimen that covers 360 ? imagery via data distillation <ref type="bibr" target="#b45">[46]</ref> as well as enjoying the advantages of large, readily available, labeled pinhole image datasets. Further, making best use of the multi-source setting, we integrate a prediction fusion scheme, improving semantic certainty and generalization, as indicated by performance measures on both: PASS and WildPASS datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Efficient Concurrent Attention</head><p>To capture omni-range contextual priors in panoramic images, we propose Efficient Concurrent Attention Networks (ECANets). Classical non-local methods <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b63">64]</ref> generate large affinity maps to measure the association among each pixel-pair, producing a complexity in space</p><formula xml:id="formula_0">of O((H e ?W e ) ? (H e ?W e )) ? O(H e 2 W e 2 )</formula><p>. H e ?W e denotes the spatial resolution of the feature map, therefore at the rather small scale of 128?64, the complexity already amounts to 67, 108, 864 attention-related computations. This substantially increases training footprint and inference requirement, thus hindering memory-efficient learning and fast execution. With the assumption that wide-FoV panoramas contain rich contextual dependencies in the horizontal dimension, our ECANet features a Horizontal Segment Attention (HSA) module ( <ref type="figure" target="#fig_1">Fig. 2</ref>) and a Pyramidal Space Attention (PSA) module ( <ref type="figure" target="#fig_2">Fig. 3</ref>) for efficient context aggregation, simultaneously lessening the computational burden to a large extent as compared to the non-local base-line <ref type="bibr" target="#b63">[64]</ref>. As shown in <ref type="figure" target="#fig_4">Fig. 4</ref>, the attended-to feature maps are passed through PSA at different scales and then concatenated with HSA-and backbone feature maps. Finally, the resulting feature map is transformed by convolution-and upsampling layers to yield the semantic maps.</p><p>Horizontal segment attention module. The HSA module ( <ref type="figure" target="#fig_1">Fig. 2</ref>) produces horizontally-driven feature maps for a given input I ? R Ce?He?We obtained from the backbone. For street-scenes, wide-FoV panoramas contain rich dependencies in the spatial dimension W , e.g., shared semantics between distant patches of sidewalk along the 360 ? can help in producing more consistent predictions. In this sentiment and with the aim of modeling self-attention to capture the wide FoV dependencies, the input feature is first divided into N segments (N = 4 in <ref type="figure" target="#fig_1">Fig. 2</ref>) along the H dimension. Each segment S ? R Ce?H?W has a smaller size with (H, W ) = ( He N , W e ), which is fed into convolution layers to generate feature maps of query Q, key K and value V to carry out self-attention <ref type="bibr" target="#b59">[60]</ref>. This reinforces the horizontal context aggregation and reduces the complexity to</p><formula xml:id="formula_1">O(N ? ( He N ?W e ) ? ( He N ?W e )) ? O(H e 2 W e 2 /N ).</formula><p>Further, advocating 360 ? region-level priors and to largely lessen computation burdens, we propose to apply a height-wise strip pooling on both the key feature K ? R C?H?W and value feature V ? R Ce?H?W . The resulting size of this strip pooling is H ? W , where H W but H =1 to enable interactions between vertically adjacent patches. The attention map A, is then computed from the reshaped query feature Q ? R (H?W )?C and the new key feature K ? R C?( H? W ) :</p><p>Q ? K ? A ? R (H?W )?( H? W ) (1) In this manner, the association between each pixel and strippooled regions is ingrained in the module's architecture, which directly enables learning relations along the horizontal axis, across the 360 ? . We apply the softmax function to the attention map, transpose it and attend to the value feature V ? R Ce?( H? W ) as follows:  <ref type="figure" target="#fig_2">Fig. 3</ref>), relating each pixel to globally distributed regions using spatial pooling. We depict the pyramid scales of the spatial pooling in <ref type="figure" target="#fig_4">Fig. 4</ref> with ( H, W ) = {(3, 3), (4, 4), (6, 6)}. In this manner, the complexity is i O(H e W e H i W i ), a con- </p><formula xml:id="formula_2">V ? A T ? S ? R Ce?(H?W )<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Multi-source Omni-supervised Learning</head><p>In the following, we consider the training of panoramic segmentation networks and propose a better suited regimen. Multi-source omni-supervision. We extend the design of <ref type="bibr" target="#b70">[71]</ref> based on data distillation <ref type="bibr" target="#b45">[46]</ref> and present a multisource omni-supervised learning regimen. As shown in <ref type="figure" target="#fig_4">Fig. 4</ref>, we train efficient networks on both labeled pinholeand unlabeled panoramic images in a multi-source setup. This adds diversity of FoV while simultaneously preventing the model from overfitting to pinhole images. While different datasets have heterogeneous class definitions, therefore hindering direct training by merging sources, we argue that the relationships encoded in their similar label hierarchies positively affect the generalization of feature representations. For example, street-scene datasets <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b57">58]</ref> have different definitions of road surfaces, but share similar class hierarchies that both comprise flat region and traffic object categories. As shown in <ref type="figure" target="#fig_4">Fig. 4</ref>, our approach is designed to enable learning with unequal sources in spite of their class-label conflicts. Precisely, to address the heterogeneity in semantic spaces, we append multiple output-heads to the efficient learner, each of which is a fully convolutional module with an upsampling layer for prediction in different label spaces (semantic spaces 1 and 2 for two sources, as illustrated in <ref type="figure" target="#fig_4">Fig. 4)</ref>.</p><p>For unlabeled panoramas, we create annotations using a sophisticated architecture pre-trained on pinhole sets by means of the PASS pipeline <ref type="bibr" target="#b68">[69]</ref>, as such we leverage the correspondence of FoV between pinhole images and partitioned panoramas for accurate segmentation. The panorama is rotated along the horizontal direction based on its 360 ? wrap-around structure, and the predictions on differently rotated transformations are ensembled, producing the annotation. While time-consuming due to the complex PASS  In the case of two domains, the network is enhanced with two heads for segmentation in heterogeneous label spaces. Annotations for the panoramas are automatically generated by seizing an ensemble of predictions on multiple transformations with the PASS pipeline <ref type="bibr" target="#b68">[69]</ref>. During testing, the efficient produces two sets of semantic maps with classes C1 and C2, which are fused in a post-processing step. On the right is an example of multi-space fusion, where green pixels on the uncertainty map denote areas with refined semantics (see the truck). pipeline and ensembling, the resulting fine-grained, high quality annotations are computed in advance and can be leveraged for data distillation <ref type="figure" target="#fig_4">(Fig. 4)</ref>. Unlike <ref type="bibr" target="#b70">[71]</ref> that uses a battery of single-city unlabeled images, we distill knowledge via diverse panoramas from all around the globe, which will unfold as crucial detail for attaining generalization to open omnidirectional domains. Multi-space fusion. In <ref type="bibr" target="#b70">[71]</ref>, while multi-space predictions are produced, only a single semantic map (i.e., the Vistasspace) is used for the inferred omnidirectional perception. We assess this to be sub-optimal as it disregards the overlap in labels of the multi-source semantic spaces. To address this, we propose to fuse the multi-space predictions in a post-processing step. As such, we consider the intersecting classes of all semantic spaces C j :</p><formula xml:id="formula_3">C IN = J j=1 C j .</formula><p>Based on the unnormalized output z j i for the i th pixel as produced by the trained j th output-head, the predicted class y j i is known as y j i = arg max c?Cj z j i,c . However, considering other candidate heads, the prediction will be updated as:</p><formula xml:id="formula_4">y j i = arg max c?C IN z j * i,c ,<label>(3)</label></formula><p>if the prediction of the optimal head j * is within the intersecting classes C IN . To find the optimal output-head j * , several strategies can be leveraged. A straightforward method based on the minimal uncertainty of the prediction is j * var = min j?J (var(z j i )), where uncertainty is modeled by the variance var(z j i ) = (1/C j ) Cj c=1 (z j i,c ?z j i ) 2 . An exemplary uncertainty map is visualized on the right side of <ref type="figure" target="#fig_4">Fig. 4</ref>. Likewise, a common method for fusing predictions is to simply choose the maximum confidence based on the prediction probability: j * conf = max j?J max ?(z j i,c ) with ?(?) denoting the softmax function. However, to select the optimal prediction, we make use of the calibrated confidence as given by the ratio of the highest and second highest probabilities: j * cal = max j?J</p><formula xml:id="formula_5">max1 z j i,c max2 z j i,c</formula><p>. Compared to using all values in j * var or just the maximum one in j * conf , this fusion refines panoramic segmentation by considering the top-2 predictions, as shown in <ref type="figure" target="#fig_4">Fig. 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">WildPASS Dataset</head><p>To foster research and to facilitate credible numerical evaluation for panoramic scene segmentation, we introduce the Wild PAnoramic Semantic Segmentation (Wild-PASS) dataset. Unlike mainstream large-scale datasets like Cityscapes <ref type="bibr" target="#b8">[9]</ref> and BDD <ref type="bibr" target="#b79">[80]</ref> that focus on urban scene understanding in Europe or North America, WildPASS embraces segmentation in the wild with images from all around the world based on Google Street View. As shown in <ref type="figure" target="#fig_5">Fig. 5</ref>, it includes unstructured and adverse road scenes like nighttime, as well as images taken from different viewpoints to paint a comprehensive picture of real-world challenges for navigational perception systems. Overall, we gather 2500 panoramas in 65 cities from all continents Asia, Europe, Africa, Oceania, North and South America (excluding only Antarctica). Following PASS <ref type="bibr" target="#b68">[69]</ref> and RainyNight <ref type="bibr" target="#b12">[13]</ref>, 500 panoramas from 25 cities are precisely annotated for the most critical navigation-related classes. We extend the semantics defined for panoramic segmentation [69] to 8 classes: Car, Road, Sidewalk, Crosswalk, Curb, Person, Truck and Bus. The remaining 2000 panoramas from 40 different cities are collected for omni-supervised learning. All images have a 360 ? ?70 ? FoV at 2048?400. WildPASS thereby is the largest panoramic street-scene segmentation benchmark, exceeding other evaluation-oriented WildDash (211 annotations) <ref type="bibr" target="#b83">[84]</ref>, ISSAFE (313 annotations) <ref type="bibr" target="#b87">[88]</ref> and PASS (400 annotations) <ref type="bibr" target="#b68">[69]</ref> datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experimental Setup</head><p>Our experiments are built on the Mapillary Vistas <ref type="bibr" target="#b37">[38]</ref> and IDD20K <ref type="bibr" target="#b57">[58]</ref> pinhole datasets for a multi-source setting. These datasets are appealing as they feature diverse viewpoints and unstructured scenes inherent in realworld unconstrained surroundings. Both datasets contain 18000/2000 and 14027/2036 images for training/validation, respectively. Following <ref type="bibr" target="#b70">[71]</ref>, we use 25 classes from Vistas and the level-3 labels (26 classes) of IDD20K, 15 of which overlap. We use the 2000 unlabeled panoramas of WildPASS to create omnidirectional annotations with PSP-Net50 <ref type="bibr" target="#b90">[91]</ref> for data distillation. We test on public PASS (400 annular images) and WildPASS (500 panoramas) datasets and evaluate with the mean Intersection over Union (mIoU) metric. Facilitating fair comparisons with omnidirectional segmentation frameworks <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b70">71]</ref>, ECANet is implemented using the ERFNet <ref type="bibr" target="#b47">[48]</ref> backbone pre-trained on ImageNet <ref type="bibr" target="#b49">[50]</ref>. We use N = 4 segments and a strip pooling of ( H, W ) = <ref type="bibr" target="#b1">(2,</ref><ref type="bibr" target="#b15">16)</ref> in HSA and spatial pooling of ( H, W ) = {(3, 3), (4, 4), (6, 6)} in PSA. ECANet is trained under Adam optimization <ref type="bibr" target="#b27">[28]</ref> with a Weight Decay of 2?10 ?4 and a Learning Rate of 1?10 ?4 that decreases exponentially over 200 epochs. We train with a batch-size of 12 and a resolution of 1024?512. For multi-source training, each iteration comprises a forward and backward pass per dataset with standard cross-entropy loss throughout.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results on PASS</head><p>As shown in <ref type="table" target="#tab_2">Table 1</ref>, we first present the results on the public Panoramic Annular Semantic Segmentation (PASS) dataset <ref type="bibr" target="#b68">[69]</ref>, which represents an unseen test-bed to our models. Thereby, the evaluation paradigm expects a trained model that can generalize well in an open, previously unseen domain. A variety of networks has been benchmarked on the PASS dataset, including some trained on Mapillary Vistas and some style-transferred using CycleGAN <ref type="bibr" target="#b68">[69,</ref><ref type="bibr" target="#b69">70]</ref>. Overall, even though the networks under our multi-source omni-supervision have not seen any annular image from the PASS domain, they outperform all previous models by large margins. In comparison to the PASS method using ringpadding <ref type="bibr" target="#b9">[10]</ref> for continuous segmentation and the singlepass OOSS method <ref type="bibr" target="#b70">[71]</ref>, our improvement is significant thanks to the diversity introduced in the data distillation. Moreover, our ECANet capturing omni-range dependencies, boosts mIoU to 60.2%, setting new state-of-the-art accuracy among 20 mainstream networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Results on WildPASS</head><p>Comparison with state-of-the-art. With the novel Wild-PASS dataset, we establish a benchmark for omnidirectional segmentation. The most accurate and efficiencyoriented architectures are trained on Mapillary Vistas and extensively evaluated on WildPASS.  <ref type="table">Table 3</ref>. Analysis of our approach for various efficient networks.</p><p>number of Parameters. It can be seen that they generally achieve unsatisfactory results. For example, DenseASPP is reported to have a mIoU of 65.8% on Vistas but degrades by more than 30.0% when taken to our challenging Wild-PASS. State-of-the-art panoramic segmentation frameworks PASS <ref type="bibr" target="#b68">[69]</ref> and OOSS <ref type="bibr" target="#b70">[71]</ref> improve upon the ERF-PSPNet baseline. However, PASS needs to separate the panorama into multiple partitions and thereby requires nearly 4 times of MACs, while OOSS is limited without materializing diverse panoramas in data distillation. Our proposed multisource omni-supervised approach outperforms both of them while maintaining the high efficiency of ERF-PSPNet. With concurrent attention, the proposed ECANet surpasses ERF-PSPNet and our multi-space fusion elevates mIoU to 69.0%, outperforming all previous methods. Effectiveness for different networks. Furthermore, we experiment with various efficient ConvNets to study how well our approach generalizes. As shown in <ref type="table">Table 3</ref>, the multi-source omni-supervision is advantageous for all efficient networks, as the mIoU scores on WildPASS are improved by significant amounts, even up to 37.4%. The multi-space fusion is also consistently effective and the benefit is most pronounced for more accurate networks. These results demonstrate that our novel learning regimen is not strictly tied to a specific architecture and enables reliable predictions for omndirectional imagery across the board.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Ablation Study</head><p>Ablation of multi-source omni-supervision. We first analyze our multi-source omni-supervision training method  The IDD20K-trained model does not contain all the classes and thus no fair evaluation is possible, yet, the multisource joint-training boosts the score to 39.8%. Finetuning on panoramas with generated annotations in both a single-or multi-source fashion improves the results on WildPASS. Omni-supervised learning by using the Pittsburgh dataset <ref type="bibr" target="#b70">[71]</ref> is limited by less diverse panoramic images. In comparison, omni-supervision on world-wide panoramas largely improves the mIoU to 66.8%, demonstrating the importance of diverse panoramic images in the data distillation process. We further compare to the state-ofthe-art domain adaptation method CLAN <ref type="bibr" target="#b34">[35]</ref> by adapting from pinhole to panoramic imagery and the multi-source semi-supervised method USSS <ref type="bibr" target="#b26">[27]</ref>. Moreover, PASS <ref type="bibr" target="#b68">[69]</ref> for panoramic-and Seamless <ref type="bibr" target="#b43">[44]</ref> for panoptic segmentation enable a smooth holistic understanding. However, both of the above frameworks remain sub-optimal in contrast to our method with ERF-PSPNet (68.1%) and ECANet (69.0%) which reaches high performances via multi-source omni-supervision and multi-space fusion.  Ablation of attention and fusion. <ref type="table" target="#tab_6">Table 5</ref> shows the mIoU, memory and computation requirement of our ECANet compared to its dissected versions using only HSA or PSA as well as non-local techniques from literature. It can be seen that our ECANet, while strengthening the horizontal context aggregation, is much more memory-efficient as compared to the non-local and dual attention modules. Moreover, ECANet clearly outperforms them as well as efficient axial-and criss-cross attention in omnidirectional segmentation. This demonstrates ECANet, by capturing essential omni-range contextual priors, is inherently robust in panoramic image segmentation. In the multi-source omnisupervised setting, we further compare different attention and context aggregation modules ( <ref type="table">Table 6</ref>). We experiment with N = {2, 4, 8} segments and verify that a 4-segment ECANet is most accurate. Moreover, our multi-space fusion method exceeds calibration-bypassed fusion methods that simply take the class with maximum probability from both spaces or from the space with minimum variance.   <ref type="table">Table 6</ref>. Accuracy analysis of efficient concurrent attention and fusion methods in the multi-source omni-supervised setting, and comparison against state-of-the-art context aggregation modules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Qualitative Analysis</head><p>than wrongly classifies into general road markings. The 3?3 attention map (orange) learned to highlight regions within the same height, which shows that it is meaningful to emphasize horizontal dependencies, forming a more discriminative feature representation. The 4?4 (blue) and 6?6 (purple) maps handle more detailed dependencies. On the other hand, the 2?16 (red) attention map captures semantically related regions in the horizontal direction stretching across 360 ? . For example, for the marked points in the first and last row, the spotlighted regions correspond to the strongly correlated homogeneous semantics, i.e., other cars and sidewalks, whose features are passed back, significantly improving the consistency of the segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We look into omnidirectional image segmentation from the context-aware perspective. To bridge the gap in terms of FoV and structural distribution, our proposed ECANet captures inherent omni-range dependencies that stretch across 360 ? , whose generalization is optimized via multisource omni-supervision and multi-space fusion. To foster progress in panoramic semantic perception, we establish and extensively evaluate models on WildPASS, a benchmark that captures diverse scenes from all around the world. Comprehensive experimental results show the proposed methods significantly elevate state-of-the-art accuracy for high-efficiency ConvNets on PASS and WildPASS.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1Figure 1 .</head><label>1</label><figDesc>WildPASS: https://github.com/elnino9ykl/WildPASS Top: Examples from our Wild PAnoramic Semantic Segmentation (WildPASS) dataset; bottom: Class distribution of pixel-class associations as unfolded over the angular direction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Horizontal Segment Attention (HSA) module. The omnidirectional image feature is divided into segments to model self-attention for capturing horizontal contextual information. To further reduce computation complexities and emphasize dependencies along the 360 ? width-wise direction, the association is measured between each pixel and gathering regions obtained with height-wise strip pooling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Pyramidal Space Attention (PSA) module. To capture global context in an efficient way, self-attention is modeled with the association measured between each pixel and globally distributed regions sampled using spatial pooling of pyramid scales. siderable reduction as compared to the non-local baseline. The attended-to feature maps are concatenated to the HSA module output and the features produced by the backbone. Thereby, the proposed ECANet gathers both: wide-FoV horizontal semantics and global dependencies for enhanced omni-range reasoning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Diagram of the multi-source omni-supervised learning regimen for omnidirectional semantic segmentation. During training, the efficient concurrent attention network is trained on the union of labeled pinhole images and unlabeled panoramas in a multi-source manner.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Example images in the WildPASS dataset, including fine labeled and unlabeled panoramas collected from all around the world.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Qualitative examples of omnidirectional semantic segmentation: (a) Input panorama. (b) Sub-attention maps for the red point in (a), generated with our omni-supervised ECANet including the 2?16 map from the HSA-and the {3?3, 4?4, 6?6} maps from the PSA module. The brighter, the higher correlation to the region (maps normalized for visualization). For instance, the red point on the left sidewalk in the last row is correlated to the right sidewalk region according to the 2?16 map. (c) Baseline (ERF-PSPNet [69]). (d) Ours.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6</head><label>6</label><figDesc>displays qualitative omnidirectional segmentation examples. For each panorama, we select a point and show their corresponding attention maps yielded from our ECANet. It can be observed that ECANet achieves more reliable segmentation than the pinhole-trained baseline, e.g., ours enables complete segmentation of the crosswalk rather</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Finally, all segments S ? R Ce?H?W are concatenated along the vertical dimension H amounting to the horizontally-driven output O ? R Ce?He?We . With this architectural design, we are able to greatly reduce the complexity to O(N ?( He N ?W e )?( H ? W )) ? O(H e W e H W ), as H W H e W e . Further, our HSA module selectively aggregates context, as each pixel gathers information from its semantically-correlated regions in the horizontal direction. Pyramidal space attention module. To capture global context, we introduce the PSA module (</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Accuracy analysis on the public PASS dataset<ref type="bibr" target="#b68">[69]</ref>.</figDesc><table><row><cell cols="2">Network and Method</cell><cell>mIoU</cell></row><row><cell>Vistas-trained</cell><cell>Fast-SCNN [45]</cell><cell>28.5%</cell></row><row><cell>Vistas-trained</cell><cell>SegNet [1]</cell><cell>25.7%</cell></row><row><cell>Vistas-trained</cell><cell>DRNet (ResNet18) [82]</cell><cell>28.0%</cell></row><row><cell>Vistas-trained</cell><cell>PSPNet (ResNet50) [91]</cell><cell>41.4%</cell></row><row><cell>Vistas-trained</cell><cell>DenseASPP (DenseNet121) [73]</cell><cell>33.3%</cell></row><row><cell>Vistas-trained</cell><cell>DANet (ResNet50) [17]</cell><cell>38.9%</cell></row><row><cell>Style-transferred</cell><cell>ENet [42]</cell><cell>31.0%</cell></row><row><cell>Style-transferred</cell><cell>SQNet [57]</cell><cell>27.9%</cell></row><row><cell>Style-transferred</cell><cell>ERFNet [48]</cell><cell>34.3%</cell></row><row><cell>Style-transferred</cell><cell>LinkNet [3]</cell><cell>30.5%</cell></row><row><cell>Style-transferred</cell><cell>PSPNet (ResNet18) [91]</cell><cell>34.8%</cell></row><row><cell>Style-transferred</cell><cell>ICNet [90]</cell><cell>25.7%</cell></row><row><cell>Style-transferred</cell><cell>ESPNet [36]</cell><cell>24.7%</cell></row><row><cell>Style-transferred</cell><cell>BiSeNet [79]</cell><cell>27.7%</cell></row><row><cell>Style-transferred</cell><cell>EDANet [33]</cell><cell>30.5%</cell></row><row><cell>Style-transferred</cell><cell>CGNet [66]</cell><cell>30.4%</cell></row><row><cell>Style-transferred</cell><cell>SwiftNet [40]</cell><cell>37.4%</cell></row><row><cell>Style-transferred</cell><cell>SwaftNet [70]</cell><cell>38.2%</cell></row><row><cell>Vistas-trained</cell><cell>ERF-PSPNet</cell><cell>32.2%</cell></row><row><cell>Style-transferred</cell><cell>ERF-PSPNet</cell><cell>39.2%</cell></row><row><cell>PASS [69]</cell><cell>ERF-PSPNet</cell><cell>58.2%</cell></row><row><cell>OOSS [71]</cell><cell>ERF-PSPNet</cell><cell>47.9%</cell></row><row><cell>Our method</cell><cell>ERF-PSPNet</cell><cell>58.4%</cell></row><row><cell>Our method</cell><cell>ECANet</cell><cell>60.2%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="2">Network</cell><cell>mIoU</cell><cell>Car</cell><cell>Road</cell><cell>Sidew.</cell><cell>Crossw.</cell><cell>Curb</cell><cell>Person</cell><cell>Truck</cell><cell>Bus</cell><cell>MACs</cell><cell>PARAMs</cell></row><row><cell cols="2">SegNet [1]</cell><cell>22.7%</cell><cell>57.2%</cell><cell>61.1%</cell><cell>18.2%</cell><cell>4.2%</cell><cell>14.1%</cell><cell>5.8%</cell><cell>9.6%</cell><cell>11.1%</cell><cell>398.3G</cell><cell>28.4M</cell></row><row><cell cols="2">PSPNet50 [91]</cell><cell>46.1%</cell><cell>80.0%</cell><cell>74.9%</cell><cell>51.7%</cell><cell>23.9%</cell><cell>31.4%</cell><cell>19.8%</cell><cell>38.9%</cell><cell>48.1%</cell><cell>403.0G</cell><cell>53.3M</cell></row><row><cell cols="2">DenseASPP [73]</cell><cell>33.2%</cell><cell>51.1%</cell><cell>69.1%</cell><cell>38.1%</cell><cell>16.4%</cell><cell>26.3%</cell><cell>8.7%</cell><cell>27.4%</cell><cell>28.4%</cell><cell>78.3G</cell><cell>8.3M</cell></row><row><cell cols="2">DANet [17]</cell><cell>47.2%</cell><cell>74.8%</cell><cell>72.2%</cell><cell>49.9%</cell><cell>28.9%</cell><cell>23.8%</cell><cell>25.4%</cell><cell>51.9%</cell><cell>50.6%</cell><cell>114.1G</cell><cell>47.4M</cell></row><row><cell cols="2">ENet [42]</cell><cell>23.8%</cell><cell>41.9%</cell><cell>58.3%</cell><cell>31.9%</cell><cell>9.2%</cell><cell>17.3%</cell><cell>3.2%</cell><cell>14.8%</cell><cell>13.9%</cell><cell>4.9G</cell><cell>0.4M</cell></row><row><cell cols="2">Fast-SCNN [45]</cell><cell>24.8%</cell><cell>45.9%</cell><cell>60.0%</cell><cell>31.7%</cell><cell>9.7%</cell><cell>17.1%</cell><cell>6.0%</cell><cell>14.2%</cell><cell>13.8%</cell><cell>1.7G</cell><cell>1.1M</cell></row><row><cell cols="2">PSPNet18 [91]</cell><cell>28.2%</cell><cell>58.2%</cell><cell>66.8%</cell><cell>28.4%</cell><cell>13.0%</cell><cell>19.2%</cell><cell>6.2%</cell><cell>18.2%</cell><cell>15.6%</cell><cell>235.0G</cell><cell>17.5M</cell></row><row><cell cols="2">DRNet22 [82]</cell><cell>27.3%</cell><cell>53.0%</cell><cell>66.2%</cell><cell>19.7%</cell><cell>7.1%</cell><cell>16.3%</cell><cell>7.5%</cell><cell>20.5%</cell><cell>28.2%</cell><cell>136.5G</cell><cell>15.9M</cell></row><row><cell cols="2">ERFNet [48]</cell><cell>29.8%</cell><cell>64.7%</cell><cell>68.0%</cell><cell>25.9%</cell><cell>6.2%</cell><cell>22.0%</cell><cell>9.0%</cell><cell>19.2%</cell><cell>23.0%</cell><cell>30.3G</cell><cell>2.1M</cell></row><row><cell cols="2">CGNet [66]</cell><cell>25.8%</cell><cell>49.7%</cell><cell>60.1%</cell><cell>24.0%</cell><cell>9.9%</cell><cell>15.3%</cell><cell>4.6%</cell><cell>16.1%</cell><cell>26.5%</cell><cell>7.0G</cell><cell>0.5M</cell></row><row><cell cols="2">SwiftNet [40]</cell><cell>30.0%</cell><cell>55.7%</cell><cell>64.1%</cell><cell>29.2%</cell><cell>16.2%</cell><cell>22.9%</cell><cell>8.5%</cell><cell>21.1%</cell><cell>22.2%</cell><cell>41.7G</cell><cell>11.8M</cell></row><row><cell cols="2">SwaftNet [70]</cell><cell>35.4%</cell><cell>64.0%</cell><cell>68.5%</cell><cell>37.2%</cell><cell>10.7%</cell><cell>26.7%</cell><cell>13.1%</cell><cell>27.8%</cell><cell>35.6%</cell><cell>41.8G</cell><cell>11.9M</cell></row><row><cell cols="2">ERF-PSPNet [69]</cell><cell>34.0%</cell><cell>66.3%</cell><cell>70.5%</cell><cell>36.5%</cell><cell>6.4%</cell><cell>24.1%</cell><cell>9.4%</cell><cell>26.5%</cell><cell>32.0%</cell><cell>26.6G</cell><cell>2.5M</cell></row><row><cell cols="2">PASS (ERF-PSPNet) [69]</cell><cell>64.7%</cell><cell>87.3%</cell><cell>80.0%</cell><cell>61.4%</cell><cell>71.1%</cell><cell>49.9%</cell><cell>72.2%</cell><cell>37.5%</cell><cell>57.9%</cell><cell>91.6G</cell><cell>2.5M</cell></row><row><cell cols="2">OOSS (ERF-PSPNet) [71]</cell><cell>56.1%</cell><cell>87.2%</cell><cell>79.3%</cell><cell>60.8%</cell><cell>28.0%</cell><cell>38.1%</cell><cell>54.5%</cell><cell>48.8%</cell><cell>52.2%</cell><cell>26.6G</cell><cell>2.5M</cell></row><row><cell cols="2">Our omni-supervised (ERF-PSPNet)</cell><cell>66.8%</cell><cell>90.5%</cell><cell>82.7%</cell><cell>65.6%</cell><cell>70.5%</cell><cell>51.5%</cell><cell>58.2%</cell><cell>62.0%</cell><cell>53.1%</cell><cell>26.6G</cell><cell>2.5M</cell></row><row><cell cols="2">With attention (ECANet)</cell><cell>67.7%</cell><cell>90.4%</cell><cell>83.7%</cell><cell>68.4%</cell><cell>67.8%</cell><cell>52.1%</cell><cell>61.4%</cell><cell>54.5%</cell><cell>63.3%</cell><cell>27.8G</cell><cell>2.6M</cell></row><row><cell cols="2">With fusion (ECANet)</cell><cell>69.0%</cell><cell>90.6%</cell><cell>85.7%</cell><cell>68.0%</cell><cell>67.9%</cell><cell>52.1%</cell><cell>66.0%</cell><cell>59.3%</cell><cell>62.3%</cell><cell>27.8G</cell><cell>2.6M</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">Table 2. Accuracy analysis on WildPASS.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Network</cell><cell cols="4">Vistas-trained Omni-supervised Multi-space fused</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ERF-PSPNet [69]</cell><cell>34.0%</cell><cell>66.8%</cell><cell></cell><cell>68.1%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fast-SCNN [45]</cell><cell>24.8%</cell><cell>45.4%</cell><cell></cell><cell>45.8%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CGNet [66]</cell><cell>25.8%</cell><cell>48.2%</cell><cell></cell><cell>48.8%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DRNet22 [82]</cell><cell>27.3%</cell><cell>64.7%</cell><cell></cell><cell>66.0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Our ECANet</cell><cell>39.7%</cell><cell>67.7%</cell><cell></cell><cell>69.0%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>shows their per-class accuracy as well as their computation complexity quantified by Multiply-Accumulate operations (MACs) and</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Analysis of our multi-source learning method.with ERF-PSPNet<ref type="bibr" target="#b68">[69]</ref> on Vistas validation set and our WildPASS. As shown inTable 4, while the single-source Vistas-learned model is accurate in the training domain (61.6%), it only yields a mIoU of 34.0% on WildPASS.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Ablation of efficient concurrent attention. Computation metrics correspond to the context aggregation of single-source trained networks after ERFNet backbone (feature res. at 128?64).</figDesc><table><row><cell>Network</cell><cell>mIoU</cell><cell>Memory</cell><cell>MACs</cell><cell>PARAMs</cell></row><row><cell>ERF-PSPNet [69]</cell><cell>34.0%</cell><cell>4.1M</cell><cell>4.6G</cell><cell>17K</cell></row><row><cell>ERFNet [48]</cell><cell>29.8%</cell><cell>224.0M</cell><cell>5.0G</cell><cell>189K</cell></row><row><cell>Non-local [64]</cell><cell>36.6%</cell><cell>261.3M</cell><cell>2.6G</cell><cell>38K</cell></row><row><cell>Dual attention [17]</cell><cell>36.7%</cell><cell>265.3M</cell><cell>2.9G</cell><cell>75K</cell></row><row><cell>Criss-cross attention [25]</cell><cell>38.3%</cell><cell>14.5M</cell><cell>0.7G</cell><cell>79K</cell></row><row><cell>Axial attention [61]</cell><cell>39.0%</cell><cell>22.5M</cell><cell>0.9G</cell><cell>104K</cell></row><row><cell>Our ECANet (HSA)</cell><cell>39.4%</cell><cell>5.3M</cell><cell>0.3G</cell><cell>43K</cell></row><row><cell>Our ECANet (PSA)</cell><cell>37.5%</cell><cell>14.7M</cell><cell>0.9G</cell><cell>116K</cell></row><row><cell>ECANet (HSA+PSA)</cell><cell>39.7%</cell><cell>20.0M</cell><cell>1.3G</cell><cell>159K</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Large scale joint semantic re-localisation and scene understanding via globally unique instance coordinate regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignas</forename><surname>Budvytis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Teichmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Vojir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Linknet: Exploiting encoder representations for efficient semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Chaurasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugenio</forename><surname>Culurciello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VCIP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A 2 -nets: Double attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">3d semantic modelling with label correction for extensive outdoor scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cars can&apos;t fly up in the sky: Improving urban-scene segmentation via height-driven attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungha</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanne</forename><forename type="middle">Taery</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Eliminating the blind spot: Adapting 3d object detection and monocular depth estimation to 360 ? panoramic imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gr?goire Payen De La Garanderie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toby</forename><forename type="middle">P</forename><surname>Amir Atapour Abarghouei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Breckon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Restricted deformable convolution-based road scene semantic segmentation using surround view cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuyuan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">CNN based semantic segmentation for urban traffic scenes using fisheye camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuyuan</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeqiang</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Wang</surname></persName>
		</author>
		<editor>IV</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rainy night scene understanding with near scene semantic adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Guang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honggang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Semir</forename><surname>Elezovikj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Boundary-aware feature propagation for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henghui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ai</forename><forename type="middle">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadia</forename><surname>Magnenat-Thalmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Learning hierarchical features for scene labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cl?ment</forename><surname>Farabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Camille</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Najman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Scene segmentation with dual relation-aware attention network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Dual attention network for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijie</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Strip pooling: Rethinking spatial pooling for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">AC-NET: Attention based network to exploit complementary features for RGBD semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Laurens van der Maaten, and Kilian Q. Weinberger. Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Interlaced sparse self-attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.12273</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Ordnet: Capturing omnirange dependencies for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaofei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianrui</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jizhong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Ccnet: Criss-cross attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Panoramic panoptic segmentation: Towards complete surrounding understanding via unsupervised contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Jaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.00868</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Universal semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarun</forename><surname>Kalluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pyramid attention network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingxue</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Expectation-maximization attention networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhisheng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Refinenet: Multi-path refinement networks for highresolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">D</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Covariance attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhou</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pongsak</forename><surname>Lasang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quansen</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Efficient dense modules of asymmetric convolution for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsueh-Ming</forename><surname>Shao-Yuan Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng-Wei</forename><surname>Hang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing-Jhih</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MM Asia</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Taking a closer look at domain shift: Category-level adversaries for semantics consistent domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yawei</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqing</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Espnet: Efficient spatial pyramid of dilated convolutions for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anat</forename><surname>Caspi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><forename type="middle">G</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Understanding 3d semantic structure around the vehicle with monocular cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenichi</forename><surname>Narioka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Nishimura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takayuki</forename><surname>Itamochi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teppei</forename><surname>Inomata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In IV</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The mapillary vistas dataset for semantic understanding of street scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Neuhold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Ollmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kontschieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonwoo</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">In defense of pre-trained imagenet architectures for real-time semantic segmentation of road-driving images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marin</forename><surname>Or?ic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Kre?o</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petra</forename><surname>Bevandic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sini?a?egvic</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Cross-view semantic segmentation for sensing surroundings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankai</forename><surname>Bowen Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ho Yin Tiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Andonian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Enet: A deep neural network architecture for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Chaurasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangpil</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugenio</forename><surname>Culurciello</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.02147</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Large kernel matters -improve semantic segmentation by global convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiming</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Seamless scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksander</forename><surname>Colovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kontschieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Fast-scnn: Fast semantic segmentation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Rudra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Poudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Data distillation: Towards omnisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilija</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Predicting semantic map representations from images using pyramid occupancy networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Roddick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Erfnet: Efficient residual factorized convnet for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Romera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><forename type="middle">Miguel</forename><surname>Bergasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Arroyo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Pcanet: Pyramid convolutional attention network for semantic segmentation. Image and Vision Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiwei</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuhao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The omniscape dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed Rida</forename><surname>Sekkat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohan</forename><surname>Dupuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Vasseur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Honeine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICRA, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Ranet: Region attention network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingguo</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lin</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Im2pano3d: Extrapolating 360 ? structure and semantics beyond the field of view</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Real-time fusion network for RGB-D semantic segmentation incorporating unexpected obstacle detection for road-driving images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Distortion-aware convolutional filters for dense prediction in panoramic images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Tateno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Tombari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Bernhard Nessler, and Sepp Hochreiter. Speeding up semantic segmentation for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Treml</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jos?</forename><surname>Arjona-Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupesh</forename><surname>Durgesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Friedmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Schuberth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Hofmarcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Widrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Bodenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Workshop</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">IDD: A dataset for exploring problems of autonomous navigation in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anbumani</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><forename type="middle">M</forename><surname>Namboodiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manmohan</forename><surname>Chandraker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Semantic object prediction and spatial sound superresolution with binaural sounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Arun Balajee Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Axial-deeplab: Stand-alone axial-attention for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Eca-net: Efficient channel attention for deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qilong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Banggu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peihua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghua</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Torontocity: Seeing the world with a million eyes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gell?rt</forename><surname>M?ttyus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Cheverie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sanja Fidler, and Raquel Urtasun</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ICCV</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Joon-Young Lee, and In So Kweon. CBAM: Convolutional block attention module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyun</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongchan</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Cgnet: A light-weight context guided network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Polarizationdriven semantic segmentation via efficient attention-bridged fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaite</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optics Express</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Semantic segmentation of panoramic images using a synthetic dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanyou</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SPIE</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">PASS: Panoramic annular semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><forename type="middle">Miguel</forename><surname>Bergasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Romera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">DS-PASS: Detail-sensitive panoramic annular semantic segmentation through swaftnet for surrounding sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaite</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IV</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Omnisupervised omnidirectional semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yicheng</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Is context-aware CNN ready for the surroundings? panoramic semantic segmentation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Denseaspp for semantic segmentation in street scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maoke</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Universal semantic segmentation for fisheye urban driving images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaozu</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaite</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwei</forename><surname>Wang</surname></persName>
		</author>
		<idno>SMC, 2020. 3</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Disentangled non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuliang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Woodscape: A multi-task, multi-camera fisheye dataset for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Senthil Kumar Yogamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hazem</forename><surname>Witt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjaya</forename><surname>Rashed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saquib</forename><surname>Nayak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Padraig</forename><surname>Mansoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Varley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Perrotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Derek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Dea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciar?n</forename><surname>P?rez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Horgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumanth</forename><surname>Sistu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Chennupati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Uric?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Milz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amende</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Chunhua Shen, and Nong Sang. Representative graph neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changxin</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Context prior for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changxin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nong</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Bisenet: Bilateral segmentation network for real-time semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changqian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changxin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nong</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Vashisht Madhavan, and Trevor Darrell. BDD100K: A diverse driving dataset for heterogeneous multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haofeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqi</forename><surname>Xian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangchen</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Dilated residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">A</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Ocnet: Object context network for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.00916</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Wilddashcreating hazard-aware benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Zendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katrin</forename><surname>Honauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Murschitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Steininger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><forename type="middle">Fern?ndez</forename><surname>Dom?nguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Orientation-aware semantic segmentation on icosahedron spheres</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Liwicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Ambrish Tyagi, and Amit Agrawal. Context encoding for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><forename type="middle">J</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Co-occurrent features in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">IS-SAFE: Improving semantic segmentation in accidents by fusing event-based data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kailun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rainer</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.08974</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Dual graph convolutional network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangtai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhai</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Icnet for real-time semantic segmentation on high-resolution images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Psanet: Pointwise spatial attention network for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycleconsistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Asymmetric non-local neural networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengdu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengteng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
