<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Long-Range Feature Propagating for Natural Image Matting</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Virtual Event</publisher>
				<availability status="unknown"><p>Copyright Virtual Event</p>
				</availability>
				<date type="published" when="2021-10-20">2021. October 20-24, 2021. October 20-24, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinglin</forename><surname>Liu</surname></persName>
							<email>qinglin.liu@outlook.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhe</forename><surname>Xie</surname></persName>
							<email>hzxie@hit.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengping</forename><surname>Zhang</surname></persName>
							<email>s.zhang@hit.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
							<email>bnzhong@hqu.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
							<email>rrji@xmu.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinglin</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhe</forename><surname>Xie</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengping</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><forename type="middle">Ji</forename></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Guangxi Normal University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="institution">Xiamen University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Long-Range Feature Propagating for Natural Image Matting</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 29th ACM International Conference on Multimedia (MM &apos;21)</title>
						<meeting>the 29th ACM International Conference on Multimedia (MM &apos;21) <address><addrLine>China</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Virtual Event</publisher>
							<date type="published" when="2021-10-20">2021. October 20-24, 2021. October 20-24, 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3474085.3475203</idno>
					<note>ACM Reference Format: Event, China . ACM, New York, NY, USA, 9 pages. https:// * Corresponding author.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CCS CONCEPTS ? Computing methodologies ? Computer vision</term>
					<term>Computer vision problems</term>
					<term>Image segmentation KEYWORDS Image matting, Neural network, Feature propagation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Natural image matting estimates the alpha values of unknown regions in the trimap. Recently, deep learning based methods propagate the alpha values from the known regions to unknown regions according to the similarity between them. However, we find that more than 50% pixels in the unknown regions cannot be correlated to pixels in known regions due to the limitation of small effective reception fields of common convolutional neural networks, which leads to inaccurate estimation when the pixels in the unknown regions cannot be inferred only with pixels in the reception fields. To solve this problem, we propose Long-Range Feature Propagating Network (LFPNet), which learns the long-range context features outside the reception fields for alpha matte estimation. Specifically, we first design the propagating module which extracts the context features from the downsampled image. Then, we present Center-Surround Pyramid Pooling (CSPP) that explicitly propagates the context features from the surrounding context image patch to the inner center image patch. Finally, we use the matting module which takes the image, trimap and context features to estimate the alpha matte. Experimental results demonstrate that the proposed method performs favorably against the state-of-the-art methods on the AlphaMatting and Adobe Image Matting datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Natural image matting aims to estimate the alpha mattes (opacity) of the foreground from natural images, which has many potential applications, such as image composition <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>, film postproduction <ref type="bibr" target="#b15">[16]</ref> and live streaming <ref type="bibr" target="#b14">[15]</ref>. Mathematically, the observed image I is modeled as a convex combination of the foreground F and background B as</p><formula xml:id="formula_0">I = F + (1 ? )B<label>(1)</label></formula><p>where is the opacity of the foreground at pixel . Since the foreground F , background B, and alpha matte are unknown, only the observed image I is known, image matting is an ill-defined problem. To address this problem, most existing methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45]</ref> need a trimap to indicate the known foreground and background regions and unknown regions in the image, which can be roughly categorized into sampling-based methods, propagation-based methods, and learning-based methods.</p><p>Sampling-based methods <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b40">41]</ref> select the best foreground and background color pairs in the known regions for the each pixel in unknown regions to estimate the alpha values based on assumptions on color association. Propagation-based methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b38">39]</ref> propagate the alpha values from the known regions to unknown regions according to the similarity between them. However, all the above methods are sensitive to the foreground and background color distributions overlap that are common in natural images, which leads to unexpected artifacts in the predicted alpha mattes <ref type="bibr" target="#b43">[44]</ref>. Recently, learning-based methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45]</ref> use neural networks to learn both the color information and natural structure from well-annotated datasets, which achieve better performance than traditional methods. However, these methods only learn local image features due to the small effective reception fields of neural networks, which ignore the long-range image features outside the reception fields. By analyzing the widely used Adobe Image Matting dataset <ref type="bibr" target="#b43">[44]</ref>, we find that more than 50% pixels in the unknown regions cannot be correlated to pixels in known regions in the range of the effective reception fields <ref type="bibr" target="#b28">[29]</ref>, which leads to inaccurate estimation.</p><p>To improve existing learning-based image matting methods, we propose the Long-Range Feature Propagating Network (LFPNet) for natural image matting, which learns the long-range features outside the reception fields to help distinguish the foreground and background locally. In particular, it consists of the propagating module and the matting module, as shown in <ref type="figure">Figure 1</ref>. Specifically, given the downsampled context image patch as input, the propagating module first extracts the rich context features around the inner center while avoiding the high computational cost. Then,  <ref type="figure">Figure 1</ref>: Overview of the proposed Long-Range Feature Propagating Network (LFPNet). LFPNet performs image matting in a patch-based crop-and-stitch manner. The propagating module takes the context image patch and context trimap patch centered on the inner center image patch and trimap patch as inputs to predict the context alpha matte and outputs context features. The matting module takes the inner center image patch , trimap patch , and context features as inputs to predict the inner center alpha matte patch , foreground patch , and background patch .</p><p>we devise a center-surround pyramid pooling (CSPP) as the bottleneck of the propagating module, which adopts a new designed center-surrounding pooling and an Atrous Spatial Pyramid Pooling (ASPP) <ref type="bibr" target="#b3">[4]</ref> to explicitly propagate the long-range context features from the context image patch to the inner center image patch and perform feature map smoothing. Finally, the matting module takes the input image, trimap and context features from the propagating module to estimate the alpha matte, foreground, and background simultaneously. Benefited from the long-range feature propagating, the proposed LFPNet performs well when the difference between the foreground and the background is small in a local region.</p><p>In summary, the contributions of this paper are threefold:</p><p>? We propose Long-Range Feature Propagating Network (LFP-Net) for image matting, which learns the long-range features outside the reception fields. LFPNet benefits the alpha matte estimation for the pixels in unknown regions by leveraging more pixels in the known foreground and background regions. ? We present Center-Surround Pyramid Pooling (CSPP) that generates the context features by explicitly propagating the features outside the reception fields to the inner center image patch.</p><p>? Experiment results on the AlphaMatting and Adobe Image Matting datasets demonstrate that the proposed method outperforms state-of-the-art methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Sampling-based methods. Sampling-based methods sample the pixels in known regions near the unknown regions to estimate the possible foreground and background colors for a given pixel. These methods design metrics to use the similarity between the unknown pixels and the known pixels to estimate the alpha value. Mishima <ref type="bibr" target="#b30">[31]</ref> proposes the first image matting method based on the foreground and background color sampling. Berman et al. <ref type="bibr" target="#b1">[2]</ref> propose to use the known pixels around the unknown pixel to obtain the alpha value of the unknown pixel with a linear function. Ruzon and Tomasi <ref type="bibr" target="#b35">[36]</ref> use statistical methods to cluster the foreground and background colors to estimate the foreground and background colors for pixels in the unknown regions. Bayesian Matting <ref type="bibr" target="#b8">[9]</ref> estimates the alpha value by using the Bayes' theorem to maximize the posterior probability. Robust Matting <ref type="bibr" target="#b40">[41]</ref> considers the spatial information and samples the foreground and background regions that are spatially close to estimate the alpha matte. Shared Matting <ref type="bibr" target="#b14">[15]</ref> uses only the pixels in the near boundaries between the known and unknown regions to speed the image matting. Global Matting <ref type="bibr" target="#b17">[18]</ref> samples all the pixels in the boundaries to prevent missing important information, but it results in slower speed. Shahrian et al. <ref type="bibr" target="#b37">[38]</ref> propose to use the distance from the known area to the unknown area to cluster the image into superpixels and then perform sampling. Feng et al. <ref type="bibr" target="#b11">[12]</ref> avoid the shortcomings of spatial assumptions by sampling the candidate foreground and background colors based on both color and spatial statistics, then use sparse coding to establish an objective function to estimate the alpha value.</p><p>Propagation-based methods. Propagation-based methods use a priori of local smoothing to formulate a cost function to propagate the alpha value from known regions to unknown regions. Poisson Matting <ref type="bibr" target="#b38">[39]</ref> uses Poisson equation to estimate alpha value. Close-form matting <ref type="bibr" target="#b24">[25]</ref> first establishes a Color-Line model, based on which a closed-form solution for alpha matte estimation is derived. Spectral matting <ref type="bibr" target="#b22">[23]</ref> introduces spectral clustering for the Close-form matting. He et al. <ref type="bibr" target="#b18">[19]</ref> accelerate the Close-form matting algorithm by increasing the window size of the Laplace matrix to reduce iterations. KNN matting <ref type="bibr" target="#b4">[5]</ref> collects K nearest neighbors globally in high-dimensional feature space to solve the image problem and gives a closed-form solution, which increases the speed while maintaining the accuracy of the matting. Information-flow Matting <ref type="bibr" target="#b0">[1]</ref> combines both local and non-local affinities to estimate the alpha matte.</p><p>Learning-based methods. Learning-based methods learn knowledge from the image and annotation to predict the alpha matte.</p><p>Benefiting from the development of deep learning and image matting datasets, many learning-based methods have emerged. Cho et al. <ref type="bibr" target="#b7">[8]</ref> propose a deep learning method to refine the alpha mattes from Close-Form matting <ref type="bibr" target="#b24">[25]</ref> and KNN matting <ref type="bibr" target="#b4">[5]</ref>. DIM <ref type="bibr" target="#b43">[44]</ref> provides the first large-scale image matting dataset and introduces the first end-to-end matting module with a refinement module. Al-phaGan <ref type="bibr" target="#b29">[30]</ref> uses the adversarial loss to improve the accuracy of matting. SampleNet <ref type="bibr" target="#b39">[40]</ref> uses the foreground and background information to supervise the network to improve prediction accuracy. AdaMatting <ref type="bibr" target="#b2">[3]</ref> refines the trimap while predicting the alpha matte. IndexNet <ref type="bibr" target="#b27">[28]</ref> reserves the pooling indices for unpooling operation and improves the gradient accuracy and visual perception of the results. GCAMatting <ref type="bibr" target="#b25">[26]</ref> designs a Guided Contextual Attention module to capture contextual affinity information to estimate the alpha matte of semi-transparent objects. FBAMatting <ref type="bibr" target="#b12">[13]</ref> designs a network to estimate the foreground color, background color and alpha matte at the same time, and uses a first-order approximation to the Bayesian formula to refine the prediction results. HDMatt <ref type="bibr" target="#b44">[45]</ref> introduces a Cross-Patch Contextual module to improve the performance under patch-based inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MOTIVATION</head><p>Recently, deep learning based methods propagate the alpha values from the known regions to unknown regions according to the similarity of the two regions. According to the statistics on the Adobe Image Matting dataset <ref type="bibr" target="#b43">[44]</ref>, we find that more than 50% pixels in the unknown regions cannot be correlated to pixels in known regions due to the limitation of the small effective reception fields, which leads to inaccurate estimation. In this section, we analyze the above observations in detail. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ratio</head><p>Unknown foreground pixel to known background pixel Unknown background pixel to known background pixel Unknown foreground pixel to known foreground pixel Unknown background pixel to known foreground pixel <ref type="figure">Figure 2</ref>: Ratio of the shortest distance from the pixels in the unknown regions to the foreground or background pixels in the known regions on the Adobe Image Matting dataset <ref type="bibr" target="#b43">[44]</ref>.</p><p>First, we collect the images whose trimaps contain foreground and background pixels in known regions in the Adobe Image Matting dataset. Then, we classify the pixels in unknown regions into the foreground and background pixels according to their alpha values. Finally, we calculate the Euclidean distance from each pixel in unknown regions to the nearest pixels in the known regions. As shown in <ref type="figure">Figure 2</ref>, the distance between the pixels in unknown regions and the pixels in known regions varies greatly. The distance between the background pixels in the unknown regions and the background pixels in the known regions is the shortest, but half of the pixels are more than 58 pixels away from the nearest known background pixels. Compared to the distance between the background pixels in the unknown regions and the background pixels in the known regions, the distance between the foreground or background pixels in the unknown regions and the foreground pixels in the known regions is farther, and half of the pixels are more than 167 pixels away from the nearest known foreground pixels, which exceeds the effective receptive field <ref type="bibr" target="#b28">[29]</ref> size of 75 pixels of the commonly used ResNet-50 <ref type="bibr" target="#b20">[21]</ref>. Besides, 25% of the pixels in the unknown regions are more than 500 pixels away from the nearest foreground pixels in the known regions.</p><p>Based on the observations, it is necessary to consider the longrange features outside the reception fields in natural image matting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THE PROPOSED METHOD</head><p>LFPNet follows a patch-based crop-and-stitch manner, which firstly crops an input image and trimap into patches and then estimates the alpha values of each patch. We denote the cropped image patch and trimap patch as inner center image patch and inner center trimap patch , respectively. To leverage the long-range features, we generate the context image patch and the context trimap patch by enlarging the crop patch and by a scale of 2, the context patch has four times the area and context information of the inner center patch.  The proposed LFPNet consists of two modules, including the propagating module and the matting module. Given the context image patch and the context trimap patch as input, the propagating module generates the context features and the context alpha matte patch . The matting module generates the inner center alpha matte , inner center foreground patch , and inner center background patch for the inner center image patch from the context features, the inner center image patch and the corresponding trimap .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Propagating Module</head><p>The propagating module extracts the long-range image features from the context image for alpha matte estimation. The propagating module consists of three components: the context encoder, Center-Surround Pyramid Pooling, the context decoder. The context encoder aims to extract context features with a small computational cost, which enables the network to leverage the context features for the alpha matte estimation. To reduce the computational cost of the context encoder, the input context image patches are downsampled by bicubic interpolation and convolution operations. Next, the ResNet-50 <ref type="bibr" target="#b20">[21]</ref> is adopted as the backbone to extract the context features from the context image patch. As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, a larger reception field contains more information, which helps to distinguish the foreground and background. To further enlarge the effective reception field <ref type="bibr" target="#b28">[29]</ref>, we replace the convolutional layers of 3 and 4 in ResNet-50 with the dilated convolutional layers whose dilation rates are 2 and 4, respectively. Consequently, the context encoder generates the context feature map for the context image patch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Center-Surround Pyramid Pooling.</head><p>To incorporate the features from the context image patch to the inner center image patch, we propose Center-Surround Pyramid Pooling (CSPP), which explicitly performs long-range feature propagating at multiple feature scales. The proposed CSPP contains two components: Center-Surround Pooling and Atrous Spatial Pyramid Pooling <ref type="bibr" target="#b3">[4]</ref>, as illustrated in <ref type="figure" target="#fig_5">Figure 4</ref>.</p><p>Center-Surround Pooling (CSP) aims to propagate the context feature map from the known regions to the near unknown regions. Specifically, CSP first divides the context feature map into 1 2 , 2 2 , 3 2 , and 6 2 blocks, which establishes the connections between the features of the unknown regions and known regions at different distances. Next, the multi-scale block-wise average pooling is applied on each block to obtain the average features of the block. Since the area of the surrounding regions is significantly larger than the area of the inner center image patch, the average features of most blocks are dominated by the features of the surrounding regions. Therefore, the features are propagated from the context image patch to the inner center image patch. Finally, the average features in each block are projected by 1 ? 1 convolutional layers, which are then concatenated with the context feature map to generate the coarsely propagated features.</p><p>Atrous Spatial Pyramid Pooling (ASPP) is adopted to smooth the coarsely propagated features while further enlarging the reception fields. Specifically, ASPP consists of a 1 ? 1 convolutional layer, a global average pooling layer followed by a 1 ? 1 convolutional layer, and four 3 ? 3 dilated convolutional layers with dilation rates of 3, 7, 12, 18. The feature maps generated by the six layers are concatenated and fed into the context decoder. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Matting Module</head><p>To estimate the alpha matte for the input image associated with the trimap, we present the matting module following DIM <ref type="bibr" target="#b43">[44]</ref>. The matting module adopts a U-Net style architecture, which contains the matting encoder for feature extraction and the matting decoder for alpha matte, foreground, and background estimation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Matting</head><p>Encoder. The matting encoder aims to extract multiscale image features from the inner center image patch and context features. To this aim, we also adopt the ResNet-50 <ref type="bibr" target="#b20">[21]</ref> as the backbone network due to its powerful feature extraction capability. To preserve the low-level image features of the image, we replace the shallow stem with a deep stem composed of multiple 3 ? 3 convolutional layers following Res2Net <ref type="bibr" target="#b13">[14]</ref>. To preserve spatial information of feature maps, we replace the convolutional layers of 3 and 4 with dilated convolutional layers with dilation rates of 2 and 4, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Matting</head><p>Decoder. The matting decoder utilizes the multiscale image features extracted by the matting encoder to estimate alpha matte. We adopt the residual blocks with bilinear upsampling layers and skip-connections as the basic building blocks, Specifically, we first adopt Pyramid Pooling Module <ref type="bibr" target="#b45">[46]</ref> to learn to fuse semantic information on multiple scales, which helps to make full use of features of different resolution image patches. Then, we stack four residual blocks with bilinear upsampling layers to upsample the feature maps to the resolution of the input image patch. To refines the details of the upsampled feature maps, we use skip-connections to incorporate the low-level features. Finally, we stack three convolutional layers to estimate the foreground , background the alpha matte following FBAMatting <ref type="bibr" target="#b12">[13]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Loss Function</head><p>We use the propagating loss and matting loss to train the propagating module and the matting module, respectively. Propagating Loss. Given the estimated context alpha matte C and the corresponding ground truth C gt , the propagating loss L is</p><formula xml:id="formula_1">defined as L = 1 |T | ?T | ? | (2)</formula><p>where T is the set of unknown pixels in the context trimap patch . Matting Loss. Given the estimated inner center alpha matte patch , inner center foreground patch F, the inner center background patch B, and the corresponding ground truth , F , B , the matting loss can be formulated as</p><formula xml:id="formula_2">L = L + L<label>(3)</label></formula><p>where L and L are the alpha matte loss and the foregroundbackground color loss, respectively. and are the weights for the two terms.</p><p>The alpha matte loss L is computed as</p><formula xml:id="formula_3">L = L + L + L<label>(4)</label></formula><p>where the weight alpha loss L , composite loss L , and Laplacian alpha loss L are defined as</p><formula xml:id="formula_4">L = (1, ?T ) |T | ?T | ? | (5) L = | + (1 ? ) ? | (6) L = Lap( , )<label>(7)</label></formula><p>where T is a set of unknown pixels in the inner center trimap , is the coefficient used to increase the weight for trimaps containing large unknown regions. Lap represents the Laplacian pyramid cost, which is defined as </p><formula xml:id="formula_5">Lap( , ) = 2 |L ( ), L ( )|<label>(8)</label></formula><p>where L ( ) and L ( ) are the -th level of the Laplacian pyramid representations of and , respectively. The foreground-background color loss L consists of the foreground background reconstruction loss L , foreground background composite loss L , and the Laplacian foreground background loss L , which can be computed as</p><formula xml:id="formula_6">L = L + L + L<label>(9)</label></formula><p>where</p><formula xml:id="formula_7">L = 1 |T | ? T | ? | + 1 |T | ? T | ? | (10) L = | + (1 ? ) ? | (11) L = Lap( , ) + Lap( , )<label>(12)</label></formula><p>where T and T are the set of foreground and unknown pixels and the set of background and unknown pixels in the inner center trimap , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS 5.1 Datasets</head><p>AlphaMatting. AlphaMatting <ref type="bibr" target="#b34">[35]</ref> is an image matting test dataset that consists of 8 real-world testing images for the online benchmark. Each testing image is with three different trimaps (i.e. "small", "large", "user") for evaluation. Adobe Image Matting. Adobe Image Matting <ref type="bibr" target="#b43">[44]</ref> is an image matting test dataset that consists of 1,000 high-resolution testing images. These images are synthesized from 50 foreground images and 1,000 background images from the PASCAL VOC dataset <ref type="bibr" target="#b10">[11]</ref>. Each testing image has a unique trimap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Implementation Details</head><p>The proposed LFPNet is implemented with PyTorch 1 <ref type="bibr" target="#b31">[32]</ref>. The coefficients in loss functions are set as = 1, = 0.25, = 5 ? 10 4 , and = 4. We use the Kaiming initializer <ref type="bibr" target="#b19">[20]</ref> to initialize the <ref type="bibr" target="#b0">1</ref> The source code is available at https://github.com/QLYoo/LFPNet. <ref type="table">Table 2</ref>: The quantitative results on the Adobe Image Matting dataset. Note that "Whole" methods take the whole images for image matting and "Patched" methods take image patches for image matting. ? denotes that the test-time augmentation is used during inference. The best results are highlighted in bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SAD MSE Grad Conn</head><p>Whole network parameters. To prevent overfitting, we adopt the ResNet-50 <ref type="bibr" target="#b20">[21]</ref> with group normalization <ref type="bibr" target="#b42">[43]</ref> and weight standardization <ref type="bibr" target="#b32">[33]</ref> pre-trained on ImageNet <ref type="bibr" target="#b9">[10]</ref> as the backbone for the encoders of the propagating module and matting module. Meanwhile, we pre-train the propagating module on upsampled Adobe Image Matting <ref type="bibr" target="#b43">[44]</ref> and Dinstinctions-646 datasets <ref type="bibr" target="#b33">[34]</ref>. We preprocess the images with several common data augmentation methods, including random affine transformation, random saturation transformation, random gray-scale transformation, random gamma transformation, random contrast transformation, and random composition. The images are randomly cropped to patches of dimensions 768?768, 640?640, 512?512, 448?448, 320?320. The trimap is generated from the alpha matte ground truth by random erosion and dilation with kernel sizes of 3 to 35 pixels. In addition, we randomly change the foreground regions in the trimap to the unknown regions.</p><p>We train the network with a batch size of 1 on the Adobe Image Matting dataset <ref type="bibr" target="#b43">[44]</ref> using an NVIDIA GTX 1080Ti GPU. We use the RAdam optimizer <ref type="bibr" target="#b26">[27]</ref> with a weight decay of 10 ?5 and betas of (0.5, 0.999). The learning rate is fixed to 10 ?5 in the training procedure. The training procedure, which includes three stages. First, (a) Image (b) Trimap (c) DIM <ref type="bibr" target="#b43">[44]</ref> (d) GCAMatting <ref type="bibr" target="#b25">[26]</ref> (e) SampleNet <ref type="bibr" target="#b39">[40]</ref> (f) AdaMatting <ref type="bibr" target="#b2">[3]</ref> (g) HDMatt <ref type="bibr" target="#b44">[45]</ref> (h) LFPNet (Ours) <ref type="figure">Figure 5</ref>: Qualitative comparison of the alpha matte results on the AlphaMatting dataset.</p><p>(a) Image (b) Trimap (c) DIM <ref type="bibr" target="#b43">[44]</ref> (d) IndexNet <ref type="bibr" target="#b27">[28]</ref> (e) FBAMatting <ref type="bibr" target="#b12">[13]</ref> (f) GCAMatting <ref type="bibr" target="#b25">[26]</ref> (g) LFPNet (Ours) (h) GT <ref type="figure">Figure 6</ref>: Qualitative comparison of the alpha matte results on the Adobe Image Matting dataset. GT stands for "Ground Truth".</p><p>we train the matting module for 35 epochs. Then, we reinitialize the optimizer and train the decoders of the propagating module and the matting module for 10 epochs. Finally, we reinitialize the optimizer and fine-tune the whole network for 5 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Comparison to the State-of-the-art Methods</head><p>We compare LFPNet to other state-of-the-art methods on the Al-phaMatting and Adobe Image Matting datasets. As shown in Tables 1 and 2, the proposed LFPNet achieves the best performance in terms of SAD, MSE, Gradient on the AlphaMatting dataset. LFPNet also achieves the best performance in terms of all metrics on the Adobe Image Matting dataset. Specifically, we use the patch-based crop-and-stitch inference <ref type="bibr" target="#b44">[45]</ref>, where the images are cropped into 1024 ? 1024 patches before being fed to the network. <ref type="figure">Figures 6 and  5</ref> give the qualitative results of the estimated alpha mattes, which indicates that the proposed LFPNet generates sharper alpha mattes and is more robust in local background interference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results on Real-world Images</head><p>LFPNet not only performs favorably against the state-of-the-art methods on the AlphaMatting and Adobe ImageMatting datasets, but also performs well on real-world high-resolution images. To demonstrate the performance of the proposed LFPnet, we collect some real-world high-resolution images from the Internet and annotate the corresponding trimaps. We use IndexNet <ref type="bibr" target="#b27">[28]</ref>, FBAMatting <ref type="bibr" target="#b12">[13]</ref>, GCAMatting <ref type="bibr" target="#b25">[26]</ref> and LFPNet to estimate the alpha mattes. Since IndexNet, FBAMatting and GCAMatting process the whole picture, we implement these methods on the CPUs to avoid insufficient memory errors. <ref type="figure">Figure 7</ref> gives the qualitative results of the estimated alpha mattes, LFPNet extracts finer image details while avoiding background interference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Ablation Study</head><p>To compare the performance with different parameters of the propagating module, the sizes of the inner center image patch and the context image patch, we conduct the ablation study on the Adobe Image Matting dataset <ref type="bibr" target="#b43">[44]</ref>. Propagating Module. To propagate long-range features for alpha matte estimation, the proposed LFPNet introduces the propagating module with Center-Surround Pyramid Pooling (CSPP). To evaluate the effectiveness of the propagating module, we compare the performance without the propagating module and with different architectures for extracting long-range features in the propagating module, including Non-Local Neural Network <ref type="bibr" target="#b41">[42]</ref> and Atrous Spatial Pyramid Pooling (ASPP) <ref type="bibr" target="#b3">[4]</ref>. As shown in <ref type="table" target="#tab_4">Table 3</ref>, the propagating module with CSPP archives the best results in terms of SAD, MSE, Grad, and Conn.</p><p>(a) Image (b) Trimap (c) IndexNet <ref type="bibr" target="#b27">[28]</ref> (d) FBAMatting <ref type="bibr" target="#b12">[13]</ref> (e) GCAMatting <ref type="bibr" target="#b25">[26]</ref> (f) LFPNet (Ours) <ref type="figure">Figure 7</ref>: Qualitative comparison of the alpha matte results on real-world high resolution images.  The Size of Inner Center Image Patch. The proposed LFPNet adopts use the patch-based inference strategy to process highresolution images. To investigate the effect of the size of the inner center image patch, we compare the performance with different sizes of the inner center image patch. The experimental results presented in <ref type="table" target="#tab_5">Table 4</ref> shows that larger inner center image patch size leads to accurate results, which indicates that rich image information benefits the alpha matte estimation.</p><p>The Size of Context Image Patch. To extract context features for alpha matte estimation, the propagating module of LFPNet takes the context image patch as input. To evaluate the impact of the size of the context image patch, we compare the performance with different sizes of the context image patch when fixing the size of the inner center image to 512 ? 512. As shown in <ref type="table" target="#tab_6">Table 5</ref>, the performance is better with large size of the context image patch, which indicates that the large context image patch provides more information that benefits the alpha matte estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this paper, we present Long-Range Feature Propagating Network (LFPNet) for natural image matting. Compared to existing deep learning methods that are limited by the small effective reception fields of convolutional neural networks, LFPNet learns the longrange context features outside the reception fields, which benefits the alpha matte estimation for the pixels in unknown regions by leveraging more pixels in the known foreground and background regions. Moreover, with the proposed center-surround pyramid pooling (CSPP), the smoothed long-range features can be explicitly propagated from the surrounding context image patch to the inner center image patch. Experiment results on the AlphaMatting and Adobe Image Matting datasets demonstrate that the proposed LFPNet outperforms the state-of-the-art methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) The full image/trimap/ground truth alpha matte (b) The inner center image (red bounding box)/trimap/estimated alpha matte (c) The context image (blue bounding box)/trimap/estimated alpha matte</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The illustration of the image, trimap and alpha matte in the Adobe Image Matting dataset. (a) shows the full image, trimap and alpha matte ground truth. (b) shows the inner center image patch, trimap and the predicted alpha matte. (c) shows the context image patch, trimap and the predicted alpha matte.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>4. 1 . 1</head><label>11</label><figDesc>Context Encoder. Different from the existing deep learning based methods that take only the inner center image patch as input, the context encoder takes the context image patch as input.Figures 3(b) and 3(c) give the comparison of the estimated alpha mattes with only inner center image and the context image, which indicates that the context features are necessary for the alpha matte estimation. Intuitively, the inner center image patch only contains a small part of the image, which makes it difficult for the networks to distinguish the foreground and background of the image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>4. 1 . 3</head><label>13</label><figDesc>Context Decoder. The context decoder aims to upsample the context features to the original size while recovering the lowlevel features lost during the downsampling process of the context encoder. Specifically, the context decoder consists of four convolutional layers followed by up-sampling layers and generates the context features for the context image patch. At the end of the context decoder, an additional convolutional layer is introduced to estimate the alpha matte of the context image patch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>The architecture of Center-Surround Pyramid Pooling (CSPP). The center-surround pooling (CSP) uses the multiscale block-wise average pooling to generate the coarsely propagated features. Atrous Spatial Pyramid Pooling (ASPP) uses multiple dilated convolutional layers to further smooth the coarsely propagated features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>The average ranking results on the AlphaMatting dataset. Note that S, L, U stand for small trimap, large trimap, and user trimap, respectively. The best results are highlighted in bold.</figDesc><table><row><cell>Methods</cell><cell>Overall</cell><cell>SAD S</cell><cell>L</cell><cell>U</cell><cell>Overall</cell><cell>MSE S</cell><cell>L</cell><cell>U</cell><cell>Overall</cell><cell>Grad S</cell><cell>L</cell><cell>U</cell></row><row><cell>LFPNet (Ours)</cell><cell>3.6</cell><cell cols="3">3.1 2.8 4.9</cell><cell>3.2</cell><cell cols="3">3.3 2.1 4.3</cell><cell>2.3</cell><cell cols="3">2.3 2.1 2.5</cell></row><row><cell>HDMatt [45]</cell><cell>9.5</cell><cell cols="2">11.6 8.1</cell><cell>8.8</cell><cell>9.6</cell><cell cols="2">12.4 8.1</cell><cell>8.4</cell><cell>7.8</cell><cell>8.9</cell><cell>6.1</cell><cell>8.5</cell></row><row><cell>Background Matting [37]</cell><cell>11.8</cell><cell>9.3</cell><cell cols="2">10 16.3</cell><cell>11.1</cell><cell>7.8</cell><cell cols="2">9.3 16.4</cell><cell>10.7</cell><cell>6.9</cell><cell>9</cell><cell>16.1</cell></row><row><cell>AdaMatting [3]</cell><cell>11.9</cell><cell cols="3">10.6 10.9 14.3</cell><cell>12.6</cell><cell cols="3">10.1 11.5 16.1</cell><cell>12.1</cell><cell>8.3</cell><cell cols="2">9.9 18.3</cell></row><row><cell>SampleNet Matting [40]</cell><cell>12.3</cell><cell cols="3">9.9 12.1 14.8</cell><cell>13</cell><cell cols="3">9.3 13.5 16.3</cell><cell>13.9</cell><cell cols="3">9.6 11.6 20.5</cell></row><row><cell>GCA Matting [26]</cell><cell>13.5</cell><cell cols="3">14.8 10.8 15.1</cell><cell>14.4</cell><cell cols="3">14.5 13 15.6</cell><cell>12.5</cell><cell cols="3">12.8 11 13.8</cell></row><row><cell>Deep Matting [44]</cell><cell>15.2</cell><cell cols="3">16.6 14.3 14.8</cell><cell>18.5</cell><cell cols="3">17.3 17.3 20.9</cell><cell>23</cell><cell cols="3">20.1 19.5 29.4</cell></row><row><cell>IndexNet Matting [28]</cell><cell>18.8</cell><cell cols="3">21.4 17.6 17.5</cell><cell>22.5</cell><cell cols="3">25.1 21 21.3</cell><cell>17.7</cell><cell cols="3">16.6 16.4 20.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>The effectiveness of the CSPP-based propagating module compared to the on the Adobe Image Matting dataset. Note that "P.M." represents "Propagating Module". The best results are highlighted in bold.</figDesc><table><row><cell>Method</cell><cell cols="4">SAD MSE Grad Conn</cell></row><row><cell>w/o P.M.</cell><cell>30.1</cell><cell>5.4</cell><cell>11.0</cell><cell>26.6</cell></row><row><cell cols="2">P.M. with Non-Local 26.8</cell><cell>4.6</cell><cell>9.5</cell><cell>22.5</cell></row><row><cell>P.M. with ASPP</cell><cell>24.1</cell><cell>4.1</cell><cell>8.7</cell><cell>19.3</cell></row><row><cell>P.M. with CSPP</cell><cell cols="2">23.2 3.7</cell><cell>8.0</cell><cell>18.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>The SAD, MSE, Grad, and Conn with different sizes of the inner center image patch on the Adobe Image Matting dataset. The best results are highlighted in bold.</figDesc><table><row><cell cols="5">Inner Image Patch Size SAD MSE Grad Conn</cell></row><row><cell>512</cell><cell>23.2</cell><cell>3.7</cell><cell>8.0</cell><cell>18.1</cell></row><row><cell>768</cell><cell>22.7</cell><cell>3.6</cell><cell>7.8</cell><cell>17.5</cell></row><row><cell>1024</cell><cell cols="2">22.4 3.6</cell><cell>7.6</cell><cell>17.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>The SAD, MSE, Grad, and Conn with different sizes of the context image patch on the Adobe Image Matting dataset. The best results are highlighted in bold.</figDesc><table><row><cell cols="5">Context Patch Size SAD MSE Grad Conn</cell></row><row><cell>512</cell><cell>24.1</cell><cell>3.9</cell><cell>8.5</cell><cell>19.0</cell></row><row><cell>768</cell><cell>23.5</cell><cell>3.7</cell><cell>8.2</cell><cell>18.4</cell></row><row><cell>1024</cell><cell cols="2">23.2 3.7</cell><cell>8.0</cell><cell>18.1</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by the National Natural Science Foundation of China (Nos. 61872112, 62072141 and 61972167).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Designing Effective Inter-Pixel Information Flow for Natural Image Matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yagiz</forename><surname>Aksoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Tunc Ozan Aydin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Method for removing from an image the background surrounding a selected object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arie</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arpag</forename><surname>Dadourian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Vlahos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Disentangled Image Matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaofan</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoshuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqiang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingzeyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Keung</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KNN Matting. TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2175" to="2188" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sketch2Photo: internet image montage</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><forename type="middle">Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shi Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH ASIA</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Robust Multi-Focus Image Fusion Using Edge Model and Multi-Matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai Kuen</forename><surname>Cham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1526" to="1541" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural Image Matting Using Deep Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyeon</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inso</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A Bayesian approach to digital matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yung-Yu</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Salesin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Szeliski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Pascal Visual Object Classes (VOC) Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="303" to="338" />
			<date type="published" when="2010-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A Cluster Sampling Method for Image Matting via Sparse Coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxue</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zili</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Forte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Piti?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">; F</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alpha</forename><surname>Matting</surname></persName>
		</author>
		<idno>abs:2003.07711</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Res2Net: A New Multi-Scale Backbone Architecture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shang-Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin-Yu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="652" to="662" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Shared Sampling for Real-Time Alpha Matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduardo</forename><surname>Simoes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lopes</forename><surname>Gastal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Manuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="575" to="584" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Integrated Foreground Segmentation and Boundary Matting for Live Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minglun</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1356" to="1370" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">RANDOM WALKS FOR INTERAC-TIVE ALPHA-MATTING</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Grady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?diger</forename><surname>Westermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VIIP</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A global sampling method for alpha matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Fast matting using large kernel matting Laplacian matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Context-Aware Image Matting for Simultaneous Foreground and Alpha Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Rav</forename><surname>Acha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<title level="m">Spectral Matting. TPAMI</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1699" to="1712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A Closed-Form Solution to Natural Image Matting. TPAMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anat</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="228" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Closed-Form Solution to Natural Image Matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="228" to="242" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Natural Image Matting via Guided Contextual Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaoyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongtao</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">On the Variance of the Adaptive Learning Rate and Beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoming</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengcheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Indices Matter: Learning to Index for Deep Image Matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songcen</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Understanding the effective receptive field in deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">AlphaGAN: Generative adversarial networks for natural image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Lutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Amplianitis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljosa</forename><surname>Smolic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Soft chroma key processing method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasushi</forename><surname>Mishima</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-Performance Deep Learning Library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<editor>Junjie Bai, and Soumith Chintala</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.10520</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">2019. Weight Standardization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Attention-Guided Hierarchical Structure Aggregation for Image Matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongsheng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingliang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A perceptually motivated online benchmark for image matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rhemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gelautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Alpha estimation in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Ruzon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Background Matting: The World is Your Green Screen</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumyadip</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Jayaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ira</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Improving Image Matting Using Comprehensive Sampling Sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Shahrian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepu</forename><surname>Rajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Poisson matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Keung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heung-Yeung</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning-Based Sampling for Natural Image Matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yagiz</forename><surname>Aksoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cengiz</forename><surname>Oztireli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tunc Ozan</forename><surname>Aydin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Optimized Color Sampling for Robust Matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Abhinav Gupta, and Kaiming He</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Non-local Neural Networks</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Group Normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep Image Matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">High-Resolution Deep Image Matting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haichao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Humphrey</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
