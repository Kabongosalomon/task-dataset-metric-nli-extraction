<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PointSCNet: Point Cloud Structure and Correlation Learning Based on Space Filling Curve-Guided Sampling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingye</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">China University of Geosciences</orgName>
								<address>
									<postCode>430074</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqi</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">China University of Geosciences</orgName>
								<address>
									<postCode>430074</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">China University of Geosciences</orgName>
								<address>
									<postCode>430074</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">China University of Geosciences</orgName>
								<address>
									<postCode>430074</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaiyi</forename><surname>Dong</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">China University of Geosciences</orgName>
								<address>
									<postCode>430074</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilin</forename><surname>Chen</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science and Engineering</orgName>
								<orgName type="institution">Wuhan Institute of Technology</orgName>
								<address>
									<postCode>430205</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Hubei Key Laboratory of Intelligent Robot</orgName>
								<orgName type="institution">Wuhan Institute of Technology</orgName>
								<address>
									<postCode>430205</postCode>
									<settlement>Wuhan</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PointSCNet: Point Cloud Structure and Correlation Learning Based on Space Filling Curve-Guided Sampling</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.3390/sym1010000</idno>
					<note type="submission">Received: 4 December 2021 Accepted: 14 December 2021</note>
					<note>symmetry S S Article 2021, 1, 0. https://doi.org/ Academic Editor: Tomohiro Inagaki</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T02:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Citation: Chen, X.; Wu, Y.; Xu, W.; Li, J.; Dong, H.; Chen, Y. PointSCNet: Point Cloud Structure and Correlation Learning Based on Space Filling Curve-Guided Sampling. Symmetry</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Point cloud is an ubiquitous form of 3D shapes and is suitable for countless applications in computer graphics due to its accessibility and expressiveness for 3D representation. The points are captured from the surface of objects by equipment such as 3D scanner, Light Detection and Ranging (LiDAR) or RGB-D cameras, or sampling from other 3D representations <ref type="bibr" target="#b0">[1]</ref>. While containing rich information about the surface, structure, and shape of 3D objects, they are unlikely to have as ordered and structured data as images that are arranged on regular pixel grids. Hence, although many classical deep neural networks have shown tremendous success in image processing, there are still a lot of challenges when it comes to deep learning methods for point cloud <ref type="bibr" target="#b1">[2]</ref>.</p><p>To coordinate these incompatibilities, an intuitive idea is transforming the point cloud into a structured representation. Earlier multi-view methods tried to project the 3D object onto multiple view-wise images to fit 2D image processing approaches <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref>. On the other hand, volumetric methods voxelized the point cloud to a regular 3D grid representation and adopted extensions of the 2D networks, such as 3D Convolutional Neural Network (CNN), for feature extraction <ref type="bibr" target="#b7">[8]</ref>. Moreover, some following voxel-based research introduced certain data structures (such as octree) to reorganize the input shape <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref>. While achieving impressive performances, these methods are often considered to have some inevitable shortcomings, such as losing 3D geometric information during 2D projection or having high computational and memory costs when processing voxels.</p><p>Against this backdrop, nowadays, research on directly consuming raw point clouds via end-to-end networks is becoming increasingly popular. The well-known PointNet <ref type="bibr" target="#b11">[12]</ref> and subsequent PointNet++ <ref type="bibr" target="#b12">[13]</ref> are the pioneer works of direct point cloud processing based on deep learning methods. The introduction of a symmetric function reflected by networks adapts to the inherent characteristics of a 3D points set. Inspired by PointNet and Pointnet++, many following research adopted the idea for point feature extraction or encoding to achieve the permutation invariance of point clouds <ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>.</p><p>The basic methodology of these point-based network is exacting point-wise high dimensional information and then aggregating a local or global representation of the point cloud for downstream tasks. Follow-up research based on this idea have demonstrated that the hierarchical structure with the subset abstraction procedure is effective for point cloud reasoning. It has been found that sampling central subsets of input points is essential for hierarchical structures <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref>. However, the most popular sampling and grouping methods, Farthest Point Sampling (FPS) and K-Nearest Neighbor (KNN), are based on low-dimension Euclidean distance exclusively, without sufficient consideration of the semantically high-level correlations of the points and their surrounding neighbors.</p><p>In the real world, there are inherent correlations between local regions of 3D objects, especially for Computer Aided Design (CAD) models or industrially manufactured products <ref type="bibr" target="#b19">[20]</ref>, such as the symmetric wing design of an airplane; the regular arrays of wheels for a car; or the distinct structure between the collar, sleeves and body part of a shirt. These geometric correlations of local regions play a crucial role in 3D object understanding and are significant for typical point cloud processing tasks such as shape classification and part segmentation.</p><p>Moreover, in the procedure of high dimensional information extraction, a basic and effective approach is using shared Multi-Layer Perceptron (MLP) or 1D CNN to project the input feature to a high dimensional space. Inspired by applications of attention mechanism for image processing, it can be inferred that, similar to image processing, information of critical local areas and feature channel of the point cloud has more impact on specific tasks.</p><p>Based on these issues above, this paper proposes a point cloud feature extraction network, namely PointSCNet, which captures global structure and local region correlations of the point cloud for shape classification and part segmentation tasks. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, a space-filling curve-guided sampling module is proposed to choose key points that represent geometrically significant local regions from the point cloud. Then, an information fusion module is designed to learn the structure and correlation information between those local regions. Moreover, a channel and spatial attention module is adopted for the final point cloud feature refinement.</p><p>The main contributions of this paper are summarized as follows:</p><p>? An end-to-end point cloud processing network, namely PointSCNet, is proposed to learn structure and correlation information between local regions of a point cloud for shape classification and part segmentation tasks. ?</p><p>The idea of a space-filling curve is adopted for points sampling and local sub-cloud generation. Specifically, points are encoded and sorted by Z-order curve coding, which makes the points contain meaningful geometric ordering. ? An information fusion module is designed to represent the local region correlation and shape structure information. The information fusion is achieved by correlating the local and structure feature via a correlation tensor and by skipping connection operations. ? A channel-spatial attention module is adopted to learn the significant points and crucial feature channels. The channel-spatial attention weights are learned for the refinement of the point cloud feature. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>This paper uses a deep learning method to extract point cloud features with construction and correlation information. In this section, recent research in highly related areas of our work, including traditional point cloud processing, point-wise embedding, point cloud structure reasoning, and attention in point cloud processing, are briefly summarized and analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Traditional Point Cloud Processing Methods</head><p>One of the biggest challenges in processing point clouds is dealing with unstructured point cloud data. The early methods of processing point clouds are mostly indirect representation conversion. Some methods try to convert the point cloud to structured data, such as octree and kd-tree <ref type="bibr" target="#b20">[21]</ref> to reduce the difficulty of analysis. Another classical method converts the point cloud to voxel models. The voxel-based methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref> use 3D convolution, which is a direct extension of image processing applications for point cloud. The advantages of the methods are that they can preserve the spatial relationship well at high voxel resolutions, but these methods are computationally very expensive. If the resolution of voxelization is reduced, the geometric information that the voxels can represent is significantly lost. FPNN <ref type="bibr" target="#b24">[25]</ref>and Vote3 <ref type="bibr" target="#b25">[26]</ref> proposed special methods to deal with the sparse problem, but their methods still cannot handle large-scale point cloud data well. Therefore, it is quite difficult to achieve real-time performance while considering the balance between accuracy and computational cost. Traditional methods inevitably lead to the loss of geometric information. This paper uses a point-by-point feature extraction method to overcome the high cost of voxel-based methods and is not conducive to processing low-resolution point clouds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Point-Wise Embedding</head><p>The research of PointNet <ref type="bibr" target="#b11">[12]</ref> is the breakthrough work for a deep learning-based direct point cloud processing method. Its groundbreaking proposal of a max-pooling symmetric function solves the problem of disordered point clouds. The MLP layer extracts the features and uses the maximum pooling aggregation to obtain the global features of the point clouds. Then, the PointNet++ <ref type="bibr" target="#b12">[13]</ref> proposed a multi-layer sampling and grouping method to improve the PointNet. Much research on point cloud processing <ref type="bibr" target="#b26">[27]</ref><ref type="bibr" target="#b27">[28]</ref><ref type="bibr" target="#b28">[29]</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref> later followed the idea of pointwise and hierarchical point feature extraction. However, the feature extraction in PointNet ignores geometrical structure information and the potential relationship between the local regions. Therefore, in this paper, the points are embedded based on the idea of PointNet++ first, and a space-filling curve-guided downsampling method and an information fusion method are proposed to learn the structure and correlation information of the point cloud.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Point Cloud Structure Reasoning</head><p>As an extension of point-wise feature learning, various methods have been proposed to reason the structure of points. The DGCNN <ref type="bibr" target="#b31">[32]</ref> captures the features between point neighborhoods through graph convolution. The network extracts point cloud structure information by capturing the topological relationship between points. MortonNet <ref type="bibr" target="#b18">[19]</ref> proposed an unsupervised way to learn the local structure of point clouds. In PCT <ref type="bibr" target="#b32">[33]</ref>, the KNN method is adopted to extract the features between the point fields. The SRN <ref type="bibr" target="#b13">[14]</ref> uses a concatenation for structural features and position coding between local sub-clouds, and the multi-scale features extracted by the method are used for point cloud processing, which improves the PointNet++ <ref type="bibr" target="#b12">[13]</ref>. However, these methods mainly pay attention to the relationship between local regions and ignore the relationship between the local region and the global shape. In this paper, a more effectively structure reasoning method is designed to capture the correlation between local regions and the shape structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Attention in Point Cloud Processing</head><p>Due to the advancement of an attention mechanism-based method in many deep learning applications <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b33">[34]</ref><ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref>, the attention mechanism meets the demand of dealing with unstructured data and is well applied in point cloud processing <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref>. The Point Transformer <ref type="bibr" target="#b37">[38]</ref> and Point Cloud Transformer <ref type="bibr" target="#b32">[33]</ref> have made precedents for the application of the Transformer <ref type="bibr" target="#b35">[36]</ref> in point cloud processing and achieved the state-of-the-art performance. The adoption of an attention mechanism for point cloud is mainly for exploring the relation between points and for enhancing the feature representation of attended points. Therefore, inspired by this idea, a channel-spacial attention module <ref type="bibr" target="#b38">[39]</ref> is designed for feature refinement by enhancing key points and crucial feature channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, the proposed PointSCNet first uses the original point set P ? R N?C as the input. C is the feature channel of the point set. After a regular sampling and grouping <ref type="bibr" target="#b12">[13]</ref> block, we obtain the sampled point set of N points with the original spatial position information, denoted as X position ?R N ?3 , and the embedded sampled point set with a C dimension feature, in which each point represents information of the surrounding points within a certain radius, denoted as X embedding ?R N ?C . Then, we send X embedding and X position to a Z-order sampling module for further sampling based on the points' geometrical relation. The sampled point set contains the shape structure and local regions correlation information, denoted as X Z?order ?R N ?C and X Z?order ?R N ?3 . After that, an information fusion module is designed to establish the correlation between each local sub-cloud and the entire point cloud for the shape structure and local region correlation information learning. Moreover, after the information fusion procedure, the point cloud feature is forwarded to a channel-spatial attention module for feature refinement.</p><p>The pipeline of classification and segmentation module is similar to the PointNet++ <ref type="bibr" target="#b12">[13]</ref>. The dimension of local point cloud features is increased to 1024 first, and then, an aggregate function pooling is adopted to obtain X global ?R 1?1024 global features. For the shape classifica-tion task, after being fed into the fully connected layers, the dimension of the global feature is reduced to 1 ? k as the output of the PointSCNet, where k is the number of classes. For the part segmentation task, the output is the segmentation result N ? k obtained by up-sampling the global feature X global , where k is the number of part classes. Then, a Z-order sampling block is designed for further generation of local regions. After the sampled point cloud feature is extracted, the feature fusion module is designed to learn the structure and correlation information. Lastly, the point cloud feature is forwarded to the PointCSA block, which is based on a channel-spatial attention mechanism to obtain the refined feature for classification and segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Initial Sampling and Grouping</head><p>The PointSCNet first uses the original point cloud data as input. A series of points X position ?R N ?3 in the space are sampled via FPS, and the ball query method is used to obtain all points that are within a radius to the sampled point, denoted as</p><formula xml:id="formula_0">d(X r , X position ) &lt; r, X r ?R N r ?3 ,<label>(1)</label></formula><p>where X position ?R N ?3 are the points sampled by FPS, X r ?R N r ?3 are the points around X position , and d() is the Euclidean distance. These points are encoded to a high-dimensional space through MLPs and aggregated to the sampled point via the aggregation function Pooling() to obtain X embedding ? R N ?C , and the aggregation function can be denoted as</p><formula xml:id="formula_1">X embedding = Pooling(Concat(Conv(X r ), X r ))),<label>(2)</label></formula><p>where X embedding ?R N ?C is the encoded points feature, max-pooling function is used for pooling operation, the Concat() function represents point feature concatenation, and the Conv() function is the 1D convolution operation.</p><p>After this procedure, the feature information of neighboring points is aggregated to all sampled points X embedding .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Z-Order Curve-Guided Sampling Module</head><p>The principle of a space-filling curve is to use a continuous curve to pass through all points in the space, and each point corresponds to a position code. After the FPS-based sampling and grouping, the Z-order curve coding function is adopted to further downsample the local sub-cloud X embedding to obtain local regions with semantically high-level correlations.</p><p>After the Z-order encoding, the 3D position coordinates of the local sub-cloud are mapped to the 1D feature space, as shown in <ref type="figure" target="#fig_2">Figure 3</ref>. The locality of the original point can be well preserved due to the nature of a Z-order curve, which means direct Euclidean neighbors in 1D tend to be similar to those in 3D. After the points are encoded and sorted, equally spaced points are sampled, as shown in <ref type="figure" target="#fig_3">Figure 4</ref>. Then, the point set with N points and C dimension feature, denoted as X Z?order ?R N ?C , and the point set with N points and 3D coordinate, denoted as X Z?order ?R N ?3 , are sampled. The final sampled point set represents the global structure and local correlation of the original point set.</p><p>Z-order 1024 points 64 points  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sampled Points Points</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Information Fusion of Local Feature and Structure Feature</head><p>After obtaining the Z-order based sampled point cloud, the local sub-cloud feature and the structure feature are correlated to learn the shape structure and local region correlation information. As shown in <ref type="figure">Figure 5</ref>, a correlation tensor, represented as N ? N ?2C, is developed to evaluate the correlation between a local sub-cloud feature, represented as N ?C, and a structure feature, represented as N ?C. The generation of the correlation tensor can be formalized as P structure = Fusion(X embedding , X Z?order ), P position = Fusion(X position , X Z?order ),</p><formula xml:id="formula_2">Fusion(X, Y) = ? ? ? ? ? Concat(X 1 , Y 1 ) Concat(X 1 , Y 2 ) ? ? ? Concat(X 1 , Y n ) Concat(X 2 , Y 1 ) Concat(X 2 , Y 2 ) ? ? ? Concat(X 2 , Y n ) . . . . . . . . . . . . Concat(X m , Y 1 ) Concat(X m , Y 2 ) ? ? ? Concat(X m , Y n ) ? ? ? ? ? ,<label>(3)</label></formula><p>where X ? R n?c and Y ? R m?c , and X, Y have the same numbers of feature channel. X i ? X and Y j ? Y are single points in point sets. The Concat() function is proposed to concatenate the feature channels of X i and Y j . Correlation tensor <ref type="figure">Figure 5</ref>. The correlation tensor is designed for the evaluation of the correlation between the local feature and structure feature. N and N represent the number of points sampled via FPS and Z-order sampling block, and C is the feature channel of points.</p><p>Then, 2D convolution layers are designed to obtain the structure and local correlation of the point cloud, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>. After the information fusion, a point cloud feature X C&amp;S ?R N ?C containing structure and correlation information is extracted. This process can be formalized as X C&amp;S = H(P structure , P position ) = Pooling(Relu(g(Concat(P structure , P position )))), <ref type="bibr" target="#b4">(5)</ref> where g() is the Conv2d function and Concat() is the concatenation operation. Finally, as shown in <ref type="figure" target="#fig_1">Figure 2</ref>, X C&amp;S , X embedding , and X position are fused together to the fusion feature X f usion via skip connections and the process can be formalized as</p><formula xml:id="formula_4">X f usion = Concat(X embedding + X C&amp;S , X position ),<label>(6)</label></formula><p>where X embedding ?R N ?C represents local point cloud features, X structure ?R N ?C represents skeleton point cloud features, X position ?R N ?3 represents point cloud location features, and the Concat function represents feature dimension concatenation of points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Points Channel-Spatial Attention Module</head><p>As shown in <ref type="figure">Figure 6</ref>, a channel-spatial attention module parallel to the channel attention block and the spatial attention block is adopted to strengthen the PointSCNet's ability by capturing the most important points and feature channels. In the channel attention module, the point cloud feature is aggregated by max-pooling and average pooling operation and then forwarded to convolution layers. The design of the convolution layer reduces the feature dimension first and then raises it for better feature extraction. The outputs of convolution layers are summed and activated to learn the weight of each feature channel. The channel attention block is formalized as Channel(X) = ReLU(MLP(Max(X) + Avg(X))), <ref type="bibr" target="#b6">(7)</ref> where X?R N ?C ,Max() and Avg() represent max-pooling and average-pooling functions. In the spatial attention module, the feature is fed to the MLPs with shared weights, and then, the information on each channel is aggregated through the batch normalization layer and the pooling layer to obtain the spatial position attention weight. The spatial attention block is formalized as Spatial(X) = Pooling(BN(MLP(X))).  <ref type="figure">Figure 6</ref>. Points channel-spatial attention module: The points feature is fed to the channel-spatial module to capture the most important points and feature channels. In channel attention module, channel weights are obtained via the two aggregation functions and convolution layers. In the spatial attention module, spatial weights are obtained via shared MLPs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, some quantitative and qualitative experiments are designed to demonstrate the performance of our proposed PointSCNet. First, the network is evaluated on shape classification and part segmentation tasks. Then, more quantitative analyses of the network are presented. Moreover, some more visualization experiments are performed to demonstrate the ability of PointSCNet quantitatively. Finally, the ablation study is designed to show the effectiveness of each module of PointSCNet. The source code of the PointSCNet is available at https://github.com/Chenguoz/PointSCNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Details</head><p>The development environment is Ubuntu18.04+Cuda11.1+Pytorch1.8.0, and the hardware environment includes a GPU device, an RTX3080 single discrete graphics card. In the classification task, we set the random sampling of 1024 points as the input of the PointSCNet and the random sampling of 2048 points in the segmentation task. Our training hyperparameters are set to the batch size of 24, the number of iterations is set to 200, the initial learning rate is set to 1 ? 10 ?3 , and the learning rate decays to the original 0.9 after every 20 iterations. The optimizer is Adam, and the weight decay rate is 1 ? 10 ?4 . In Z-order sampling, the number of sampled points is set to 64. The loss is measured by calculating the cross entropy between the real label and the predicted value. We set the number of local sub-clouds as N = 256, and the number of local sub-cloud feature channels as C = 192. The number of skeleton sub-clouds is N = 64.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Shape Classification on ModelNet40</head><p>The shape classification experiment was performed on the ModelNet40 <ref type="bibr" target="#b22">[23]</ref> dataset, which is the most commonly used dataset for training point cloud classification networks. The dataset has 9843 training data and 2468 test data, belonging to 40 different shape classes.</p><p>In the shape classification experiment, we randomly sampled 1024 point features as the input, and 64 regions were sampled based on the Z-order curve coding. The PointSCNet is compared with some of the state-of-the-art methods. As shown in <ref type="table">Table 1</ref>, the overall classification accuracy of PointSCNet on ModelNet40 reaches 93.7%, which outperforms or is on par with classical classification networks and recent state-of-the-art methods. <ref type="table">Table 1</ref>. Comparison with state-of-the-art methods on the ModelNet40 classification dataset. The column of "Acc" means overall accuracy(%). All results quoted are taken from the cited papers. "xyz" in the column of Input means the 3D coordinate of points and nr means normal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Input Points Acc PointNet++ <ref type="bibr" target="#b12">[13]</ref> is the pioneer work of hierarchical point cloud feature extraction, which captures the multi-scale local structure with hierarchical layers. It aggregates local features through a simple maximum pooling operation without using their structural relationship. The DGCNN <ref type="bibr" target="#b39">[40]</ref> and the SRN <ref type="bibr" target="#b13">[14]</ref> are both classical methods used to learn structural relation of point cloud. The DGCNN <ref type="bibr" target="#b39">[40]</ref> simply concatenates the feature relationships of local sub-clouds in different dimensions, and the captured structural relationship features cannot fully represent the structure of the point cloud.The SRN <ref type="bibr" target="#b13">[14]</ref> adopts a regular FPS-based sampling and grouping method to obtain local point clouds and simply concatenates the points position and geometry feature to capture the structure relationship. The PointSCNet uses the space-filling curve to sample the points in the point cloud that can characterize the point cloud structure and, then, processes them through a specially designed feature fusion module to explore the correlations between local regions and the structure of the point cloud. The performance is significantly improved compared with these baseline methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Part Segmentation on ShapeNet</head><p>The ShapeNet <ref type="bibr" target="#b49">[50]</ref> dataset covers 55 common object categories, and there are approximately 51,300 3D models. The part segmentation task is performed on the ShapeNet part segmentation dataset with 16,880 models and 16 categories. The 3D models are divided into 14,006 training point clouds and 2874 test point clouds, where each point is associated with a point-by-point label of the point cloud segmentation task. In the point cloud component segmentation task, we randomly sampled 2048 point features as the original input of PointSCNet. The quantitative results of PointSCNet and some classical state-of-the-art methods are shown in <ref type="table">Table 2</ref>. By capturing the skeleton structure features of the point cloud, the PointSCNet significantly outperforms Pointnet <ref type="bibr" target="#b11">[12]</ref>, Pointnet++ <ref type="bibr" target="#b12">[13]</ref>, and SRN <ref type="bibr" target="#b13">[14]</ref>, and the performance of PointSCNet is particularly outstanding in some specific classes, as shown in the table. <ref type="figure" target="#fig_6">Figure  7</ref> shows the visualization part segmentation result of PointSCNet. <ref type="table">Table 2</ref>. The performance of part segmentation task on ShapeNet. The metric is part-average Intersection-over-Union (IoU, %). All results quoted are taken from the cited papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class</head><p>Pointnet  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Additional Quantitative Analyses</head><p>The number of model parameters reflect the training speed of the network indirectly. Our PointSCNet adopts the space-filling curve-guided sampling strategy to capture a few points to represent local regions and the structure of the point cloud, which reduces the number of model parameters. The PointSCNet achieves outstanding classification accuracy with relatively few model parameters, as shown in <ref type="table" target="#tab_2">Table 3</ref>. For the PointNet <ref type="bibr" target="#b12">[13]</ref>, its multi-layer sampling structure introduces redundant information and slows down the training speed. <ref type="figure" target="#fig_7">Figure 8</ref> shows the loss curve of PointSCNet decreases more rapidly compared with the Pointnet++. The PCT <ref type="bibr" target="#b32">[33]</ref> network uses the Transformer structure repeatedly to capture the structural relationship characteristics of the point cloud. Hence, it has excessive parameters and its convergence speed is slow. The SRN <ref type="bibr" target="#b13">[14]</ref> adopts a regular FPS-based sampling and grouping method to obtain sub-regions and adopts a duplicated SRN module, which leads to a large number of parameters and a slow convergence speed too.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Additional Visualization Experiments</head><p>The heat map for points with a high response to PointSCNet is shown in <ref type="figure" target="#fig_8">Figure 9</ref>. The points are colored according to their response to the network and those with higher response are colored darker. The darker points in of the mug display the model structure. The darker points in the airplane mainly gather on one side of the symmetry axis, which indicates the symmetry of the airplane model. In the table model, both the model structure and a repetitive arrayed table leg are emphasized. The points with high responses appear on the rim of the bowl.</p><p>According to the visualization results, points with higher responses either present the structure of a point cloud or show the geometrical and locational interactions of local regions, which proves that the points sampled by the Z-order sampling module represents meaningful geometrical local regions and that the information fusion block extracts the structure and correlation information effectively. <ref type="figure" target="#fig_0">Figure 10</ref> shows the performance of our PointSCNet in feature extraction. By using t-SNE [52] to reduce the dimension of high-dimensional features to 2D, the classification ability of our network is visualized as shown in the figure. It can be seen that most of the classes are divided into separate clusters. For some clusters with similar point cloud structures, such as tables and stools being close in semantic space, the PointSCNet can still distinguish them precisely.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Ablation Study</head><p>A set of ablation studies were designed to test the impacts of critical components of our network, including the Z-order sampling block (Section 3.2), structure and correlation information fusion module (Section 3.3) and the channel-spatial attention block (Section 3.4). The ablation strategies and results are shown in <ref type="table">Table 4</ref>. It can be found that all of the critical components of the PointSCNet improve the network performance. The Z-order sampling block and C&amp;S module provide obvious improvement. The convergence speed is slow while only using the information fusion module. When all these three modules are used at the same time, the model training speed is greatly improved, and the highest accuracy of the classification task is achieved, which further proves the importance of each module. <ref type="table">Table 4</ref>. The strategies and results of ablation studies. "ZS" represents the Z-order curve guided sampling block. "C&amp;S" represents the structure and correlation information fusion module. "AM" is the channel-spatial attention module. " " represents existence, and "?" represents inexistence. "ToBestAcc" is the minimum number of epochs when the PointSCNet achieves the highest accuracy in the training phase. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ZS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>In this paper, a point cloud processing network named PointSCNet is proposed to learn the shape structure and local region correlation information based on space-filling curveguided sampling. Different from most existing methods using FPS method for downsampling, which only utilizes the low-dimension Euclidean distance, our proposed space-filling curveguided sampling module uses the Z-order curve for sampling to explore high-level correlations of points and local regions. The feature of sampled points are fused in the proposed information fusion block, in which the shape structure and local region correlation are learned. Finally, the channel-spatial module is designed to enhance the feature of key points. Quantitative and qualitative experimental results demonstrate that the proposed PointSCNet learns the point cloud structure and correlation effectively and achieves superior performance on shape classification and part segmentation tasks. The idea of structure and correlation learning can be adopted for related vision tasks other than 3D points processing. Hence, in the future, we plan to optimize our network and to apply the method to more vision scenarios <ref type="bibr" target="#b51">[53]</ref><ref type="bibr" target="#b52">[54]</ref><ref type="bibr" target="#b53">[55]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Learning structure and correlation on point cloud based on space-filling curve-guided sampling. Columns shown from left to right are the original input point cloud, points sampled by the Z-order space-filling curve, and the point cloud heat map based on the responses of points to the proposed network, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Model architecture of PointSCNet: The original point cloud is fed to a sampling and grouping block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>The point cloud structure obtained by sampling 1024 points in the original point cloud using the Z-order space-filling curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Sampling strategy based on Z-order curve sorting. Equally spaced points are sampled, and the spacing is set to 3 in the figure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Results of our PointSCNet on the part segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Experiment on the drop speed of the loss curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Heat map for points with high responses to PointSCNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 10 .</head><label>10</label><figDesc>Visualization results of t-SNE on the ModelNet40 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>The performance of PointSCNet on the ModelNet40 dataset to test classification tasks.</figDesc><table><row><cell>Method</cell><cell>Params</cell><cell>Acc</cell></row><row><cell>Pointnet [12]</cell><cell>3.472 M</cell><cell>89.2</cell></row><row><cell>Pointnet++ [13]</cell><cell>1.748 M</cell><cell>91.9</cell></row><row><cell>SRN [14]</cell><cell>3.743 M</cell><cell>91.5</cell></row><row><cell>DGCNN [40]</cell><cell>1.811 M</cell><cell>92.9</cell></row><row><cell>NPCT [33]</cell><cell>1.36 M</cell><cell>91.0</cell></row><row><cell>SPCT [33]</cell><cell>1.36 M</cell><cell>92.0</cell></row><row><cell>PCT [33]</cell><cell>2.88 M</cell><cell>93.2</cell></row><row><cell>PointSCNet</cell><cell>1.827 M</cell><cell>93.7</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of Interest:</head><p>The authors declare no conflicts of interest.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Rotational projection statistics for 3D local surface description and object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="63" to="86" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep learning for 3d point clouds: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bennamoun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="4338" to="4364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Volumetric and multi-view cnns for object classification on 3d data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06-27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learned-Miller, E. Multi-view convolutional neural networks for 3d shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision<address><addrLine>Santiago, Chile</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-12" />
			<biblScope unit="page" from="945" to="953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multi-view 3d object detection network for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07-21" />
			<biblScope unit="page" from="6526" to="6534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-view harmonized bilinear network for 3d object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-18" />
			<biblScope unit="page" from="186" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning relationships for multi-view 3D object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision<address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-02" />
			<biblScope unit="page" from="7504" to="7513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A 3d convolutional neural network for real-time object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maturana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Voxnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<meeting>the 2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning deep 3d representations at high resolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Osman Ulusoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Octnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07-21" />
			<biblScope unit="page" from="6620" to="6629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Octree-based convolutional neural networks for 3d shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>O-Cnn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Pointgrid: A deep network for 3d shape understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-18" />
			<biblScope unit="page" from="9204" to="9214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pointnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Honolulu, HI, USA, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07-21" />
			<biblScope unit="page" from="77" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pointnet++</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02413</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Structural relational reasoning of point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition<address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-15" />
			<biblScope unit="page" from="949" to="958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">P2p-net: Bidirectional point displacement net for shape transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Modeling point clouds with self-attention and gumbel subset sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition<address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-15" />
			<biblScope unit="page" from="3318" to="3327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sarode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Goforth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Aoki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Srivatsan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Choset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pcrnet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.07906</idno>
		<title level="m">Point cloud registration network using PointNet encoding. arXiv 2019</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A structured self-attentive sentence embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">N</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03130</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Mortonnet: Self-supervised learning of local features in 3D point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Thabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Alwassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.00230</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A grid-based secure product data exchange for cloud-based collaborative design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Coop. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<date type="published" when="2040006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Escape from cells: Deep kd-networks for the recognition of 3d point cloud models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klokov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision<address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-10-22" />
			<biblScope unit="page" from="863" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Richly-annotated 3d reconstructions of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nie?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scannet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07-21" />
			<biblScope unit="page" from="2432" to="2443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">3d shapenets: A deep representation for volumetric shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Inferring and executing programs for visual reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lawrence Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision<address><addrLine>Venice, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-10-22" />
			<biblScope unit="page" from="3008" to="3017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fpnn: Field probing neural networks for 3d data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pirk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="307" to="315" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Voting for voting in online point cloud object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Posner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="10" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning strictly rotation-invariant representations for point cloud classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Srinet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM International Conference on Multimedia</title>
		<meeting>the 27th ACM International Conference on Multimedia<address><addrLine>Nice France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-10-21" />
			<biblScope unit="page" from="980" to="988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Momen (e) t: Flavor the moments in learning to classify shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joseph-Rivlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zvirin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kimmel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision Workshops<address><addrLine>Seoul, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-10-27" />
			<biblScope unit="page" from="4085" to="4094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning representations and generative models for 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Achlioptas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Diamanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pmlr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stockholm</forename><surname>Stockholmsm?ssan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sweden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018-07-10" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="40" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">One millisecond deep feature extraction for point clouds by lookup tables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Justlookup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 IEEE International Conference on Multimedia and Expo (ICME)</title>
		<meeting>the 2019 IEEE International Conference on Multimedia and Expo (ICME)<address><addrLine>Shanghai, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07-08" />
			<biblScope unit="page" from="326" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Pointwise geometric and semantic learning network on 3D point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno>Eng. 2020</idno>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="57" to="75" />
		</imprint>
	</monogr>
	<note type="report_type">Integr. Comput.-Aided</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamic graph cnn for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">PCT: Point cloud transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Vis. Media</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="187" to="199" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.11929</idno>
		<title level="m">others. An image is worth 16x16 words: Transformers for image recognition at scale. arXiv 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Convolutional block attention module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cbam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)<address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-09-08" />
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Polosukhin, I. Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems</title>
		<meeting>the Advances in Neural Information Processing Systems<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-04" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unsupervised detection of distinctive regions on 3D shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph. (TOG)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Point</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Transformer</surname></persName>
		</author>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-10-11" />
			<biblScope unit="page" from="16259" to="16268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02155</idno>
		<title level="m">Self-attention with relative position representations. arXiv 2018</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dgcnn: A convolutional neural network over large-scale labeled graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Le Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">T</forename><surname>Bui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="533" to="543" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pointcnn: Convolution on x-transformed points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="820" to="830" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Relation-shape convolutional neural network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition<address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition<address><addrLine>Nashville, TN, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-06-20" />
			<biblScope unit="page" from="3172" to="3181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Curvenet: Curvature-based multitask learning deep networks for 3D object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Muzahid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/CAA J. Autom. Sin</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1177" to="1187" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning Inner-Group Relations on Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-10-11" />
			<biblScope unit="page" from="15477" to="15487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep learning on point sets with parameterized convolutional filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Spidercnn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)<address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-09-08" />
			<biblScope unit="page" from="87" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Annularly convolutional neural networks on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Komarichev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>A-Cnn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition<address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06-15" />
			<biblScope unit="page" from="7413" to="7422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Robust point clouds processing using nonlocal neural networks with adaptive sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pointasnl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition<address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-06-13" />
			<biblScope unit="page" from="5588" to="5597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">So-net: Self-organizing network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition<address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-18" />
			<biblScope unit="page" from="9397" to="9406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.03012</idno>
		<title level="m">others. Shapenet: An information-rich 3d model repository. arXiv 2015</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Van der Maaten, L.; Hinton, G. Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Atzmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lipman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.10091.52</idno>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Point convolutional neural networks by extension operators</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Part-based visual tracking with spatially regularized correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Vis. Comput</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="509" to="527" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Deep Learning Methods for 3D Human Pose Estimation under Different Supervision Paradigms: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">2267</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">3D Capsule Hand Pose Estimation Network Based on Structural Relationship Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">1636</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
