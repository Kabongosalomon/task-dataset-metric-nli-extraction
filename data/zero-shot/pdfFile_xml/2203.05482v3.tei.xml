<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time ImageNet Accuracy (top-1, %) Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-07-01">1 Jul 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Wortsman</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Ilharco</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samir</forename><forename type="middle">Yitzhak</forename><surname>Gadre</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Columbia Uni-versity</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Google Research</orgName>
								<address>
									<country>Brain Team</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Gontijo-Lopes</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Google Research</orgName>
								<address>
									<country>Brain Team</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><forename type="middle">S</forename><surname>Morcos</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Meta AI Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongseok</forename><surname>Namkoong</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Columbia Uni-versity</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Carmon</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Equal contribution</orgName>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Equal contribution</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Google Research</orgName>
								<address>
									<country>Brain Team</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Equal contribution</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time ImageNet Accuracy (top-1, %) Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-07-01">1 Jul 2022</date>
						</imprint>
					</monogr>
					<note>Correspondence to: &lt;mitchnw@uw.edu&gt;. Proceedings of the 39 th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copy-right 2022 by the author(s). 75 76 77 78 79 80 81</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The conventional recipe for maximizing model accuracy is to (1) train multiple models with various hyperparameters and (2) pick the individual model which performs best on a held-out validation set, discarding the remainder. In this paper, we revisit the second step of this procedure in the context of fine-tuning large pre-trained models, where fine-tuned models often appear to lie in a single low error basin. We show that averaging the weights of multiple models finetuned with different hyperparameter configurations often improves accuracy and robustness. Unlike a conventional ensemble, we may average many models without incurring any additional inference or memory costs-we call the results "model soups." When fine-tuning large pre-trained models such as CLIP, ALIGN, and a ViT-G pretrained on JFT, our soup recipe provides significant improvements over the best model in a hyperparameter sweep on ImageNet. The resulting ViT-G model, which attains 90.94% top-1 accuracy on ImageNet, achieved a new state of the art. Furthermore, we show that the model soup approach extends to multiple image classification and natural language processing tasks, improves out-of-distribution performance, and improves zero-shot performance on new downstream tasks. Finally, we analytically relate the performance similarity of weight-averaging and logitensembling to flatness of the loss and confidence of the predictions, and validate this relation empirically. Code is available at https://github. com/mlfoundations/model-soups.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ViT-G  90.45 -CoAtNet-7   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, research has shown that models pre-trained on large and diverse datasets learn representations that transfer well to a variety of tasks. As a result, machine learning practitioners now commonly develop solutions for downstream tasks by fine-tuning large pre-trained models <ref type="bibr" target="#b103">Yosinski et al., 2014;</ref><ref type="bibr" target="#b51">Kornblith et al., 2019;</ref>. Typically, the fine-tuning process involves two steps: (1) fine-tune models with a variety of hyperparameter configurations, and (2) select the model which achieves the highest accuracy on the held-out validation set. The remaining models are then discarded.</p><p>Selecting a single model and discarding the rest has several downsides. For one, ensembling outputs of many models can outperform the best single model, albeit at a high computational cost during inference. For another, fine-tuning a model on downstream tasks can sometimes reduce out-ofdistribution performance <ref type="bibr" target="#b74">(Radford et al., 2021;</ref><ref type="bibr" target="#b1">Andreassen et al., 2021;</ref><ref type="bibr" target="#b99">Wortsman et al., 2021;</ref>, and the best single model on the target distribution may not be the best model on out-of-distribution data.</p><p>In this work, we propose a more accurate and robust alternative to the second step of the conventional recipe in the context of fine-tuning a large pre-trained model. Instead of selecting the individual fine-tuned model which achieves the highest accuracy on the held-out validation set, we average the weights of models fine-tuned independently, and refer to the result as a model soup. Given the results of the first stepa hyperparameter sweep over fine-tuned models-averaging several of these models to form a model soup requires no additional training and adds no cost at inference time.</p><p>Since the loss landscape of neural network training is nonconvex with many solutions in different loss basins, it is perhaps surprising that averaging the weights of independently fine-tuned models achieves high performance. However, recent work <ref type="bibr" target="#b69">(Neyshabur et al., 2020)</ref> observes that fine-tuned models optimized independently from the same pre-trained initialization lie in the same basin of the error landscape, inspiring our method. Weight averaging along a single training trajectory has previously been shown to improve the performance of models in non-transfer settings <ref type="bibr" target="#b87">(Szegedy et al., 2016;</ref>. Our approach extends weight averaging to the context of fine-tuning, where we find that it also works across many independent runs with varied hyperparemeter configurations. Our use of a diverse set of fine-tuned models is inspired by <ref type="bibr" target="#b37">Gontijo-Lopes et al. (2022)</ref> who observe that ensembling independent runs trained with different hyperparameters improves performance.</p><p>We perform a comprehensive experimental study of finetuning to understand the behavior of model soups. For our main results we fine-tune CLIP <ref type="bibr" target="#b74">(Radford et al., 2021)</ref> and ALIGN <ref type="bibr" target="#b45">(Jia et al., 2021)</ref>, which are pre-trained with a contrastive loss on image-text pairs, and a ViT-G model pre-trained on JFT . Our results show that model soups often outperform the best individual model on both the in-distribution and natural distribution shift test sets <ref type="bibr">(Table 1</ref>, <ref type="figure" target="#fig_0">Figure 1</ref>, <ref type="figure" target="#fig_5">Figure 5</ref>). A model soup composed of ViT-G models achieves 90.94% on ImageNet <ref type="bibr" target="#b21">(Deng et al., 2009)</ref>, surpassing the previous state of the art of 90.88% attained by the CoAtNet model  while requiring 25% fewer FLOPs at inference time. 1 In general, model soups can approach the performance of ensembling, with no additional computational cost or memory relative to a single model during inference. Beyond ImageNet and associated distribution shifts, our results show that model soups are applicable when fine-tuning on tasks from the WILDS <ref type="bibr" target="#b49">(Koh et al., 2021)</ref> benchmark, and when fine-tuning transformer models <ref type="bibr" target="#b90">(Vaswani et al., 2017;</ref><ref type="bibr" target="#b22">Devlin et al., 2019a;</ref><ref type="bibr" target="#b76">Raffel et al., 2020b)</ref> for text classification.</p><p>While the most straightforward approach to making a model soup is to average all the weights uniformly, we find that greedy soups, where models are sequentially added to the soup if they improve accuracy on held-out data, outperforms uniform averaging. Greedy soups avoid adding in models which may lie in a different basin of the error landscape, which could happen if, for example, models are fine-tuned with high learning rates.</p><p>In addition to empirical observations, we analytically relate the similarity in loss between weight-averaging and logit-ensembling to the flatness of the loss (i.e., its second derivative on a line between models) and confidence of the predictions (expressed via the variance of a logits difference drawn from the weight-average softmax). We empirically validate our approximation on a subset of the models we train and show that it is strongly correlated with the true averaging vs. ensembling performance difference, particularly in the learning rate regimes where soups are effective and models achieve higher accuracy.</p><p>Paper outline. Our method of model soups is presented and evaluated in Sections 2 and 3, respectively. Next, Section 4 includes our analysis relating model soups and ensembles, Section 5 details the scope and limitations of the proposed method, and Section 6 contextualizes model soups by reviewing related work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head><p>This section highlights three recipes for model souping, the uniform, greedy, and learned soup, though the greedy soup is our central method. We summarize the methods described </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Cost</head><p>Best on val. set f (x, arg max i ValAcc(? i )) O(1) Ensemble</p><formula xml:id="formula_0">1 k k i=1 f (x, ? i ) O(k) Uniform soup f x, 1 k k i=1 ? i O(1) Greedy soup Recipe 1 O(1) Learned soup Appendix I O(1)</formula><p>in this section in <ref type="table" target="#tab_2">Table 2</ref>.</p><p>We consider a neural network f (x, ?) with input data x and parameters ? ? R d . Fine-tuning is analogous to standard neural network training but includes an important distinction: the parameters are initialized to those found via pre-training.</p><p>Let ? = FineTune(? 0 , h) denote the parameters obtained by fine-tuning with pre-trained initialization ? 0 and hyperparameter configuration h. The hyperparameter configuration can include the choice of optimizer, data augmentation, training iterations, and a random seed which will determine data order.</p><p>For hyperparameter configurations h 1 , ..., h k let ? i = FineTune(? 0 , h i ). Conventionally, the parameters ? j which attain the highest accuracy on a held out validation set are selected, and the remaining parameters are discarded. Instead, model soups f (x, ? S ) use an average of ? i , i.e.,</p><formula xml:id="formula_1">? S = 1 |S| i?S ? i where S ? {1, ..., k}.</formula><p>The uniform soup is constructed by averaging all fine-tuned models ? i and so S = {1, ..., n}.</p><p>There are settings in which a hyperparameter configuration can produce a model with low accuracy that results in a low accuracy uniform soup. This issue can be circumvented with a greedy soup (Recipe 1). The greedy soup is constructed by sequentially adding each model as a potential ingredient in the soup, and only keeping the model in the soup if performance on a held out validation set (disjoint from the training and test sets) improves. Before running this procedure we sort the models in decreasing order of validation set accuracy, and so the greedy soup can be no worse than the best individual model on the held-out validation set. We also explore a more advanced learned soup recipe that optimizes model interpolation weights by gradient-based minibatch optimization (see Appendix I for details). This procedure requires simultaneously loading all models in memory which currently hinders its use with large networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recipe 1 GreedySoup</head><p>Input: Potential soup ingredients {? 1 , ..., ? k } (sorted in decreasing order of ValAcc(? i )).</p><formula xml:id="formula_2">ingredients ? {} for i = 1 to k do if ValAcc(average(ingredients ? {? i })) ? ValAcc(average(ingredients)) then ingredients ? ingredients ? {? i } return average(ingredients)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>This section presents our key experimental findings. We begin with experimental setup (Section 3.1) then provide intuition for model soups by examining error landscape visualizations (Section 3.2). Next we present our main results (Section 3.3), using model soups as an alternative to selecting the best performing individual model. The appendix includes additional results on model soups in the context of robust fine-tuning (Appendix D) and model soups constructed by fine-tuning on different datasets (Appendix E).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Experimental setup</head><p>Our experiments explore the application of model soups when fine-tuning various models. The primary models we fine-tune are the CLIP <ref type="bibr" target="#b74">(Radford et al., 2021)</ref>, ALIGN <ref type="bibr" target="#b45">(Jia et al., 2021)</ref>, and BASIC  models pretrained with contrastive supervision from image-text pairs, a ViT-G/14 model pre-trained on JFT-3B , and transformer models for text classification <ref type="bibr" target="#b22">(Devlin et al., 2019a;</ref><ref type="bibr" target="#b75">Raffel et al., 2020a)</ref>. Unless otherwise mentioned, experiments use the CLIP ViT-B/32 model. Fine-tuning is performed end-to-end (all parameters are modified) which typically results in better accuracy than training only the final linear layer <ref type="bibr" target="#b51">(Kornblith et al., 2019;</ref><ref type="bibr" target="#b0">Agrawal et al., 2014;</ref><ref type="bibr" target="#b15">Chatfield et al., 2014;</ref><ref type="bibr" target="#b2">Azizpour et al., 2015)</ref>.</p><p>We consider two different methods for initializing the final linear layer before fine-tuning. The first method initializes the model from a linear probe (LP), as described in <ref type="bibr" target="#b54">Kumar et al. (2022)</ref>, and we refer to this method as LP initialization. The second method uses the zero-shot initialization, e.g., using the classifier produced by the text tower of CLIP or ALIGN as the initialization. Both methods for initializing the model produce similar trends when applicable, and unless otherwise stated we use the LP initialization.</p><p>For the ensemble baselines <ref type="bibr" target="#b24">(Dietterich, 2000;</ref><ref type="bibr" target="#b55">Lakshminarayanan et al., 2017)</ref> we ensemble the logits (unormalized outputs) of models as in <ref type="bibr" target="#b37">Gontijo-Lopes et al. (2022)</ref>. Finetuning uses a supervised cross-entropy loss and, unless otherwise mentioned, is conducted on ImageNet <ref type="bibr" target="#b21">(Deng et al., 2009)</ref>. When fine-tuning on ImageNet we also evaluate on   The solution with the highest accuracy is often not a fine-tuned model but rather lies between fine-tuned models. This figure shows loss and error on a two dimensional slice of the loss and error landscapes. We use the zero-shot initialization ?0 and fine-tune twice (illustrated by the gray arrows), independently, to obtain solutions ?1 and ?2. As in , we obtain an orthonormal basis u1, u2 for the plane spanned by these models, and the x and y-axis show movement in parameter space in these directions, respectively.  Each point corresponds to a pair of models ?1, ?2 that are finetuned independently from a shared initialization ?0 with different hyperparameter configurations. The angle ? between between solutions refers to the angle between ?1 ? ?0 and ?2 ? ?0 (i.e., the initialization is treated as the origin). Accuracy is averaged over ImageNet and the five distribution shifts described in Section 3.1.</p><p>the five natural distribution shifts: ImageNetV2 <ref type="bibr" target="#b77">(Recht et al., 2019)</ref>, ImageNet-R <ref type="bibr">(Hendrycks et al., 2021a)</ref>, ImageNet-Sketch , ObjectNet <ref type="bibr" target="#b5">(Barbu et al., 2019)</ref>, and ImageNet-A <ref type="bibr">(Hendrycks et al., 2021b)</ref>. We often report results averaged over these five distribution shifts. Since the official ImageNet validation set is typically used as the test set, we use roughly 2% of the ImageNet training set as a held-out validation set for constructing greedy soups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Intuition and motivation</head><p>Error landscape visualizations. To provide intuition, we visualize a two dimensional slice of the training loss and test error landscape when fine-tuning CLIP on ImageNet.</p><p>In these experiments, we use the zero-shot initialization ? 0 ? R d and fine-tune twice, independently, to produce solutions ? 1 and ? 2 . The points ? 0 , ? 1 and ? 2 define a plane in parameter space, and we evaluate the ImageNet train loss, ImageNet test error, and the test error on the five aforementioned distribution shifts on this plane. The results are illustrated in <ref type="figure" target="#fig_2">Figure 2</ref> where the zero-shot initialization (? 0 ) is shown as a star and a solution fine-tuned with learning rate 3 ? 10 ?5 (? 1 ) is shown as a blue square. For ? 2 we either use the same learning rate as ? 1 (but vary the random seed) or learning rate 3 ? 10 ?6 . For both the in-distribution and out-of-distribution test sets, the loss/error contours are basin-shaped, and none of the three points is optimal.</p><p>These results suggest that (1) interpolating the weights of two fine-tuned solutions can improve accuracy compared to individual models and (2) more uncorrelated solutionsmodels that form an angle 2 closer to 90 degrees-may lead to higher accuracy on the linear interpolation path.</p><p>To investigate the correlation between accuracy improvement and angle, we consider a series of models trained with different seeds, learning rates, and data augmentation. For each pair ? 1 , ? 2 , we compare the accuracy of their average with the average of their accuracies, Acc 1 2 ? 1 + 1 2 ? 2 ? 1 2 (Acc (? 1 ) + Acc (? 2 )), which we refer to as the interpo-   <ref type="figure" target="#fig_3">Figure 3</ref> illustrates the results, in which we observe that the interpolation advantage is correlated with the angle ? and that varying the learning rate, seed, or data augmentation can produce solutions which are more orthogonal. Experimental details and discussion of high learning rates provided in Appendix J.1.</p><p>Ensemble comparison. <ref type="figure" target="#fig_4">Figure 4</ref> observes that ensemble performance is correlated with soup performance for moderate and small learning rates. We consider pairs of models selected at random from the individual solutions in <ref type="figure" target="#fig_0">Figure 1</ref>, and find that the maximum learning rate of the models in the pair is indicative of the ensemble accuracy, soup accuracy, and their relation: When learning rate is small, ensemble accuracy and soup accuracy are similar, but both are suboptimal. For moderate learning rate values, ensemble accuracy and soup accuracy are both high. For high learning rate values, ensemble performance exceeds soup performance, but ensembles/soups with moderate learning rates perform better. Overall, ensembles achieve higher accuracy on Ima-geNet while the reverse is true on the distribution shifts.</p><p>One dimensional hyperparameter grids. Finally, in Appendix F we ask the question: for a one dimensional grid of hyperparameters {h a , ..., h b }, how does averaging the models fine-tuned with hyperparameter configurations h a and h b corresponding to the endpoints compare with picking the best individual model fine-tuned with hyperparameter configuration h ? {h a , ..., h b }? The hyperparameters we vary are optimizer, augmentation, and learning rate. For the majority of grid searches, the average of the endpoints outperforms the best individual model in the grid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Model soups</head><p>With the gains of averaging two fine-tuned models in mind, we turn our attention to averaging many models with different hyperparameters: this section presents our main results, which show that averaging fine-tuned models can be used as an alternative to the conventional procedure of selecting the single model which performs best on the held-out validation set. We explore CLIP <ref type="bibr" target="#b74">(Radford et al., 2021)</ref> and ALIGN <ref type="bibr" target="#b45">(Jia et al., 2021)</ref> fine-tuned on ImageNet <ref type="bibr" target="#b21">(Deng et al., 2009</ref>) (Section 3.3.1), ViT-G pre-trained on JFT-3B  and fine-tuned on ImageNet (Section 3.3.2), and transformer models fine-tuned on text classification tasks (Section 3.3.3). Appendix G additionally explores (1) CLIP ViT-L fine-tuned on WILDS <ref type="bibr" target="#b49">(Koh et al., 2021)</ref> and CIFAR-10 and (2) an ImageNet-22k-pretrained ViT-B fine-tuned on ImageNet. Moreover, Appendix C shows that model soups improve accuracy when fine-tuning BASIC . <ref type="table">Table 3</ref>: Ablation on multiple methods from <ref type="table" target="#tab_2">Table 2</ref> and their variants when when fine-tuning CLIP ViT-B/32 with the random hyperparameter search described in Section 3.3.1. For "Greedy soup (random order)", we try three random model orders when running the greedy soup procedure (by default, models are sorted by decreasing held-out val accuracy). The "Learned soup" and its variants are descried in Appendix I. The best in best individual model refers to ImageNet accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ImageNet</head><p>Dist For ALIGN we use a grid search over learning rate, data augmentation, and mixup, obtaining 12 fine-tuned models (details in Appendix J.2.2). To form our greedy soups, we sort models in order of decreasing accuracy on the held-out validation set before applying Recipe 1. For both CLIP and ALIGN, the greedy soup selects 5 models. <ref type="figure" target="#fig_0">Figure 1</ref> and 5 show the performance of the resulting models and their uniform and greedy soups for CLIP and ALIGN. The greedy soup improves on over the best model in the hyperparameter sweep by 0.7 and 0.5 percentage points, respectively.</p><p>Furthermore, we show that, for essentially any number of models, the greedy soup outperforms the best single model on both the ImageNet and the out-of-distribution test sets. We consider an additional setting where we prepare a sequence of soups by sequentially adding CLIP models from the hyperparameter sweep in random order. Appendix <ref type="figure">Figure B</ref>.1 shows the performance of the uniform and greedy soup, as well as the best single model so far and a logit ensemble, as a function of the number of models considered. The greedy soup is better than the uniform soup on Ima-geNet and comparable to it out-of-distribution. The logit ensemble is better than the greedy soup on ImageNet, but worse out-of-distribution. <ref type="table">Table 3</ref> lists the performance of the CLIP soups and baselines described above, as well as additional soup variants described in Appendix I.</p><p>To further establish the generality of the model soup, we replicate the CLIP hyperparameter sweep experiment on two image classification tasks from WILDS <ref type="bibr" target="#b49">(Koh et al., 2021)</ref>, namely FMoW <ref type="bibr" target="#b16">(Christie et al., 2018)</ref> and iWild-Cam . Appendix <ref type="figure">Figure G</ref>.1 shows results qualitatively similar to our ImageNet experiment, and Appendix J.2.1 describes experimental details.</p><p>We report several additional variants and baselines for the experiment described above. In Appendix H we present results for different hyperparameter sweeps and fine-tuning initializations, when fine-tuning CLIP on ImageNet. For instance, we try a standard grid search which is similar to the grid search described for ALIGN above, and an extreme grid search which includes solutions fine-tuned with extreme hyperparameters that result in badly performing models (details in Appendix J.2.1). Moreover, Appendix L compares model soups with additional baselines, including distillation from an ensemble as in <ref type="bibr" target="#b42">Hinton et al. (2014)</ref>, exponential moving averaging <ref type="bibr" target="#b87">(Szegedy et al., 2016)</ref>, stochastic weight averaging , and sharpness aware minimization .</p><p>We highlight a few interesting takeaways from these experiments: (1) The greedy soup outperforms the best individual model-with no extra training and no extra compute during inference, we were able to produce a better model. (2) While the uniform soup can outperform the best individual model, we only observe this when all individual models achieve high accuracy (e.g., when fine-tuning ALIGN in <ref type="figure" target="#fig_0">Figure 1</ref>); unlike the examples in <ref type="figure" target="#fig_2">Figure 2</ref>, there can be an error barrier between fine-tuned models. We mainly observe this when fine-tuning with high learning rates (this is illustrated in Appendix J.1, <ref type="figure">Figure J</ref>.1). However, these high learning rate models also have a lower accuracy, and are therefore excluded by the greedy soup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">FINE-TUNING A VIT-G MODEL PRE-TRAINED ON JFT-3B</head><p>To test whether the gains obtained by model soups are additive with other techniques used to obtain state-of-the-art models, we applied our greedy soup technique to 58 ViT-G/14 models fine-tuned on ImageNet. We vary the learning rate, decay schedule, loss function, and minimum crop size in the data augmentation, and optionally apply RandAugment (Cubuk et al., 2020), mixup <ref type="bibr" target="#b107">(Zhang et al., 2017)</ref>, or CutMix <ref type="bibr" target="#b105">(Yun et al., 2019)</ref>. We also train four models with sharpness-aware minimization (SAM) . For further details of our hyperparameter sweep, see Appendix J.2.3. For each model training run, we save exponential moving averages (EMA) of the weights <ref type="bibr" target="#b87">(Szegedy et al., 2016)</ref> computed with decay factors of 0.999 (low EMA) and 0.9999999 (high EMA). Whereas high EMA generally provides the best single-model accuracy, both greedy soup  and greedy ensembling attain higher validation accuracy when applied to parameters with low EMA. We report the highest single model accuracy numbers obtained with either EMA decay value, but perform greedy soup and ensembling with models trained with EMA decay of 0.999. For each combination of training run and EMA decay rate, we evaluate accuracy on our held out validation set every 1000 steps. We use these accuracy values to pick the best checkpoint for ensembling, souping, and subsequent evaluation.</p><p>In <ref type="table" target="#tab_6">Table 4</ref>, we report results on the ImageNet validation set and the five distribution shift datasets studied above as well as two relabeled ImageNet validation sets, ReaL  and multilabel <ref type="bibr" target="#b81">(Shankar et al., 2020)</ref>. Our greedy soup procedure selects 14 of the 58 models finetuned as part of our hyperparameter sweep, and this soup performs statistically significantly better than the best individually fine-tuned model selected based on our held out validation set on all datasets except for ObjectNet. Even when we give an unfair advantage to individually fine-tuned models by selecting them based on their performance on each test set (denoted "oracle" in <ref type="table" target="#tab_6">Table 4</ref>), the greedy soup, which was selected using only in-distribution data, remains superior on most datasets. Only on ReaL and ObjectNet does there exist an individual model that performs statistically significantly better than the soup, and the best model differs between those two datasets. Greedy ensembling performs similarly to the greedy soup in terms of ImageNet top-1 and multilabel accuracy, and slightly better on ReaL, but significantly worse on all distribution shift datasets except for ImageNet-V2. Thus, greedy soup can provide additional gains on top of standard hyperparameter tuning even in the extremely high accuracy regime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">FINE-TUNING ON TEXT CLASSIFICATION TASKS</head><p>To test whether the gains obtained by model soups extend to domains beyond image classification, we conduct preliminary experiments with natural language processing (NLP). While more investigation is warranted to establish the applicability of model soups for NLP, we believe our experiments are a promising initial step. In particular, we fine-tune BERT <ref type="bibr" target="#b23">(Devlin et al., 2019b)</ref> and T5 <ref type="bibr" target="#b76">(Raffel et al., 2020b</ref>) models on four text classification tasks from the GLUE benchmark <ref type="bibr" target="#b92">(Wang et al., 2018)</ref>: MRPC <ref type="bibr" target="#b26">(Dolan and Brockett, 2005)</ref>, RTE <ref type="bibr" target="#b19">(Dagan et al., 2005;</ref><ref type="bibr" target="#b4">Bar-Haim et al., 2006;</ref><ref type="bibr" target="#b35">Giampiccolo et al., 2007;</ref><ref type="bibr" target="#b8">Bentivogli et al., 2009</ref>), CoLA <ref type="bibr" target="#b94">(Warstadt et al., 2019)</ref> and SST-2 , as in <ref type="bibr" target="#b25">(Dodge et al., 2020)</ref>. We use the standard metric for each dataset: average of accuracy and F 1 score for MRPC, accuracy for RTE, Matthews correlation for CoLA <ref type="bibr" target="#b64">(Matthews, 1975)</ref> and accuracy for SST-2. Details are provided in Appendix J.4.</p><p>We fine-tune 32 models for each dataset with a random hyper-parameter search over learning rate, batch size, number of epochs and random seed. <ref type="table" target="#tab_7">Table 5</ref> reports the corresponding metric on the validation set for BERT-base uncased <ref type="bibr" target="#b22">(Devlin et al., 2019a)</ref> and T5-base <ref type="bibr" target="#b76">(Raffel et al., 2020b)</ref>. Additional experimental details and results for more models are provided in Appendix J.5. While the improvements are not as pronounced as in image classification, the greedy soup can improve performance over the best individual model in many cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Analytically comparing soups to ensembles</head><p>The goal of this section is to obtain complementary analytical insight into the effectiveness of model soups. For simplicity, we consider a soup consisting of only two models with parameters ? 0 and ? 1 . For weighting parameter ? ? [0, 1] we let ? ? = (1 ? ?)? 0 + ?? 1 denote the weightaveraged soup. We would like to understand when the soup error, err ? := E x,y 1{arg max i f i (x; ? ? ) = y}, would be lower that the best of both endpoints, min{err 0 , err 1 }.</p><p>Note that just convexity of err ? in ? does not by itself imply superiority of the soup to both endpoints, as the minimum of err ? over ? may be obtained at the endpoints even when err ? is convex. To get further leverage on the problem, we compare the soup to the logit-level ensemble f ens</p><formula xml:id="formula_3">? (x) = (1? ?)f (x; ? 0 ) + ?f (x; ? 1 ).</formula><p>The rich literature on ensembles (see Sec. 6) tells us that the expected error of the ensemble, err ens ? , is often strictly below min{err 0 , err 1 } for neural networks. Therefore, whenever err ? ? err ens ? we expect the soup to outperform both endpoint models.</p><p>To analytically compare the soup and the ensemble, we replace the 0-1 loss with a differentiable surrogate. Specifically, we consider the cross-entropy loss (f, y) = log y e f y ?fy . We let L soup</p><formula xml:id="formula_4">? = E x,y (?f (x; ? ? ), y)</formula><p>denote the ?-calibrated expected loss of the soup, and similarly define L ens ? = E x,y (?f ens ? (x), y) for the ensemble. We derive the following approximation for the loss difference:</p><formula xml:id="formula_5">L soup ? ? L ens ? ? ?(1 ? ?) 2 ? d 2 d? 2 L soup ? + ? 2 E x Var Y ?p sftmx (?f (x;??)) [?f Y (x)] ,<label>(1)</label></formula><p>where [p sftmx (f )] i = e fi / j e fj is the standard "softmax" distribution and ?f (x) = f (x; ? 1 ) ? f (x; ? 0 ) is the difference between the endpoint logits. We obtain our approximation in the regime where the logits are not too far from linear; see Appendix K.3 for a detailed derivation.</p><p>The first term in approximation <ref type="formula" target="#formula_5">(1)</ref> is negatively proportional to the second derivative of the loss along the trajectory: when the approximation holds, convexity of the loss indeed favors the soup. However, the second term in the approximation does not follow from the "convex basin" intuition. This term always favors the ensemble, but is small in one of two cases: (a) the somewhat trivial case when the endpoint models are similar (so that ?f is small) and (b) when the soup produces confident predictions, implying that p sftmx (?f (x; ? ? )) is close to a point mass and consequently the variance term is small.</p><p>To test our approximation, we evaluate it over of set of finetuned models with different learning rates, augmentation strategies, random seeds and ? values. We set ? to calibrate the soup model, and find that it improves the ability of our approximation to predict the soup/ensemble error difference; see Appendix K.4 for detailed description of our setup. <ref type="figure">Figure K</ref>.1 summarizes the results of our empirical evaluations. When excluding the high learning rate of 10 ?4 (center and right panels), 3 we see that the approximation is strongly correlated with both the true difference in loss as well as the difference in error, and the approximation and true loss difference generally agree in sign. Additional details are provided in Appendix K.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Scope and limitations</head><p>While this work has so far demonstrated that averaging many fine-tuned models is a useful technique for improving accuracy, this section explores two limitations of the approach. The first is the applicability of model soups, and the second is the failure of model soups to substantially improve calibration.</p><p>Applicability. So far our experiments have mainly explored models pre-trained on large, heterogeneous datasets. In Appendix G we also explore model soups for an ImageNet-22k pre-trained model. While the greedy soup still provides improvements on ImageNet, these improvements are less substantial compared to those observed when fine-tuning CLIP and ALIGN.</p><p>Calibration. While ensembles improve model calibration <ref type="bibr" target="#b38">(Guo et al., 2017;</ref>, model soups do not have the same effect. As hyperparameters can also have an effect on calibration, we consider the ensemble and soup of 20 models which are identical other than random seed. Results are illustrated in <ref type="figure">Figure B</ref>.2 using the calibration metrics of .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Related work</head><p>Averaging model weights. Averaging the weights of models is a popular approach in convex optimization and deep learning. Most applications study models along the same optimization trajectory, e.g. <ref type="bibr" target="#b79">(Ruppert, 1988;</ref><ref type="bibr">Polyak, 1990;</ref><ref type="bibr" target="#b87">Szegedy et al., 2016;</ref><ref type="bibr" target="#b108">Zhang et al., 2019;</ref><ref type="bibr" target="#b47">Kaddour et al., 2022;</ref><ref type="bibr" target="#b46">Junczys-Dowmunt et al., 2016)</ref>. By contrast, Nagarajan and Kolter <ref type="formula" target="#formula_5">(2019)</ref>  <ref type="formula" target="#formula_6">(2020)</ref>, a) we average across independent runs with hyperparemter diversity, b) we modify all weights in the network, and c) we consider the transfer setting. <ref type="bibr" target="#b63">Matena and Raffel (2021)</ref> merge models with the same pre-trained initialization that are fine-tuned on different text classification tasks. They also propose Fisher information as an alternative technique for model merging. We experiment with averaging models which are trained on different datasets in Appendix E, however, in contrast to <ref type="bibr" target="#b63">Matena and Raffel (2021)</ref> we do not use data from the target distribution. <ref type="bibr" target="#b99">Wortsman et al. (2021)</ref> average zero-shot and fine-tuned models, finding improvements in-and out-of-distribution. In contrast to <ref type="bibr" target="#b99">Wortsman et al. (2021)</ref>, we average models across many independent runs which provides more substantial improvements.</p><p>Stochastic Weight Averaging (SWA) , which averages weights along a single optimization trajectory, is also motivated by the relation between ensembling model outputs and averaging model weights. In contrast, the averaging we propose is across independent runs. Moreover, while their analysis relates the averaged network outputs (i.e., the logit ensemble) to the output of the a network with the averaged weights, our analysis (Section 4) goes a step further and relates the classification losses associated with these two vectors.</p><p>Pre-training and fine-tuning. In computer vision and natural language processing, the best performing models are often pre-trained on a large dataset before being finetuned on data from the target task <ref type="bibr" target="#b103">Yosinski et al., 2014;</ref><ref type="bibr" target="#b82">Sharif Razavian et al., 2014;</ref><ref type="bibr" target="#b62">Mahajan et al., 2018;</ref><ref type="bibr" target="#b51">Kornblith et al., 2019;</ref><ref type="bibr" target="#b102">Yalniz et al., 2019;</ref><ref type="bibr" target="#b11">Bommasani et al., 2021)</ref>. This paradigm is also referred to as trans-fer learning. Recently, image-text pre-training has become increasingly popular in computer vision as a pre-training task <ref type="bibr" target="#b74">(Radford et al., 2021;</ref><ref type="bibr" target="#b45">Jia et al., 2021;</ref><ref type="bibr" target="#b66">Mu et al., 2021;</ref><ref type="bibr" target="#b104">Yu et al., 2022)</ref>. Recent work has explored alternative strategies for adapting these models to specific target tasks <ref type="bibr" target="#b110">(Zhou et al., 2021;</ref>, for instance via a lightweight residual feature adapter. In contrast, our work explores standard end-to-end fine-tuned models. Other work has attempted to improve transfer learning by regularizing models toward their initialization <ref type="bibr" target="#b101">(Xuhong et al., 2018)</ref>, choosing layers to tune on a per-example basis <ref type="bibr" target="#b39">(Guo et al., 2019)</ref>, reinitializing layers over the course of training <ref type="bibr" target="#b58">(Li et al., 2020)</ref>, or using multiple pretrained models with data-dependent gating <ref type="bibr" target="#b84">(Shu et al., 2021)</ref>.</p><p>Ensembles. Combining the outputs of many models is a foundational technique for improving the accuracy and robustness of machine learning models <ref type="bibr" target="#b24">(Dietterich, 2000;</ref><ref type="bibr" target="#b6">Bauer and Kohavi, 1999;</ref><ref type="bibr" target="#b13">Breiman, 1996;</ref><ref type="bibr" target="#b32">Friedman et al., 2001;</ref><ref type="bibr" target="#b55">Lakshminarayanan et al., 2017;</ref><ref type="bibr" target="#b31">Freund and Schapire, 1997)</ref>. <ref type="bibr" target="#b70">Ovadia et al. (2019)</ref> show that ensembles exhibit high accuracy under distribution shift. <ref type="bibr" target="#b67">Mustafa et al. (2020)</ref> propose a method for identifying subsets of pre-trained models for fine-tuning and later ensembling them, finding strong in-distribution accuracy and robustness to distribution shift. Gontijo-Lopes et al. <ref type="formula" target="#formula_6">(2022)</ref> conduct a large-scale study of ensembles, finding that higher divergence in training methodology leads to uncorrelated errors and better ensemble accuracy. Finally, previous work has explored building ensembles of models produced by hyperparameter searches <ref type="bibr" target="#b85">(Snoek et al., 2015;</ref><ref type="bibr" target="#b65">Mendoza et al., 2016;</ref><ref type="bibr" target="#b80">Saikia et al., 2020)</ref>, including greedy selection strategies <ref type="bibr" target="#b14">(Caruana et al., 2004;</ref><ref type="bibr" target="#b57">L?vesque et al., 2016;</ref><ref type="bibr" target="#b96">Wenzel et al., 2020)</ref>. Importantly, ensembles require a separate inference pass through each model, which increases computational costs. When the number of models is large, this can be prohibitively expensive. Unlike ensembles, model soups require no extra compute at inference time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>Our results challenge the conventional procedure of selecting the best model on the held-out validation set when finetuning. With no extra compute during inference, we are often able to produce a better model by averaging the weights of multiple fine-tuned solutions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Overview</head><p>The appendix is organizes via the following contributions:</p><p>? Appendix B (Additional figures) supplements the main text with additional figures.</p><p>? Appendix C (BASIC) presents additional experiments exploring model soups for BASIC .</p><p>? Appendix D (Robust fine-tuning) compares model soups with WiSE-FT <ref type="bibr" target="#b99">(Wortsman et al., 2021)</ref>, a technique for fine-tuning while preserving robustness.</p><p>? Appendix E (Cross-dataset soups) explores soups for models which are trained on different datasets to improve zero-shot transfer.</p><p>? Appendix F (Analysis of 1D hyperparameter grids) compares the performance of averaging endpoints with intermediate solutions for hyperparemters on a one dimensional grid.</p><p>? Appendix G (Additional fine-tuning and pre-training datasets) explores model soups for additional datasets.</p><p>? Appendix H (Additional grid searches and initializations) supplements the results in the main text with other hyperparameter sweeps and model initializations (i.e., zero-shot instead of LP initialization).</p><p>? Appendix I (Learned soup) describes the more advanced souping procedure where we learn the soup mixing coefficients with gradient based optimization on the held-out validation set.</p><p>? Appendix J (Experimental details) provides additional details for the experiments.</p><p>? Appendix K (Analytical comparison details) supplements Section 4 in analytically comparing soups and ensembles.</p><p>? Appendix L (Additional baselines) compares soups with additional baselines including stochastic weight averaging  and sharpenss aware minimization . Avg. accuracy on 5 distribution shifts <ref type="figure">Figure B</ref>.1: For essentially any number of models, the greedy soup outperforms the best single model on both ImageNet and the out-of-distribution test sets. On the x-axis we show the number of models considered in a random search over hyperparameters while the y-axis displays the accuracy of various methods for model selection which are summarized in <ref type="table" target="#tab_2">Table 2</ref>. All methods require the same amount of training and compute cost during inference with the exception of the ensembles, which require a separate pass through each model. Results are for fine-tuning CLIP ViT-B/32, averaged over three random orders (shown with faded lines). Expected calibration error (ECE) is computed using equal-mass binning. The soup in this figure is the uniform soup, and all models in this experiment are fine-tuned CLIP ViT-B/32 models with the same hyperparameters but different random seeds. The calibrated soup and calibrated ensemble refer to a soup and ensemble composed of models which are calibrated through temperature scaling <ref type="bibr" target="#b38">(Guo et al., 2017)</ref>. Calibrating models before ensembling or souping had no effect on accuracy and so these curves are omitted from the plots on the left.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Additional figures</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. BASIC</head><p>After our initial submission we tested model soups when fine-tuning BASIC-L . Due to memory constraints, we fine-tune with a batch size of 64 instead of 512. We initialize with the zero-shot classification head and train for 8 epochs using the Adafactor optimizer <ref type="bibr" target="#b83">(Shazeer and Stern, 2018</ref>) at a resolution of 500 ? 500. We sweep over a grid of learning rates (1 ? 10 ?5 or 2 ? 10 ?5 ) and 10 data augmentation settings, resulting in 20 different models. We use random crops and flips with a minimum crop size of 90% of the image together with mixup <ref type="bibr" target="#b107">(Zhang et al., 2017)</ref> or CutMix <ref type="bibr" target="#b105">(Yun et al., 2019)</ref> with ? ? {0.2, 0.4}, AutoAugment with (num_layers, magnitude) ? {(2, 10), (2, 15), (2, 20), (2, 25), (3, 10)}.</p><p>We additionally train models with random crops and flips with minimum crop sizes of 5% and 90% without additional augmentation.</p><p>As in our ViT-G/14 experiments (Section 3.3.2), we save exponential moving averages with low and high EMA decay factors, and find that low EMA weights provide better performance for greedy souping and greedy ensembling whereas high EMA weights provide better single-model performance. We adjust the EMA factors for the difference in batch size and thus use a decay factor of 0.999 1/8 for our low EMA configuration and 0.9999999 1/8 for our high EMA configuration. During each training run, for each set of EMA weights, we evaluate accuracy on our held out validation set every 5000 steps and use the best checkpoint for ensembling, souping, and subsequent evaluation. We resize the full image to 500 ? 500 for evaluation.</p><p>Results are shown in <ref type="table" target="#tab_10">Table C</ref>.1. The greedy soup consistently outperforms the individual model with highest accuracy on the held-out validation set. The best BASIC-L model on each individual test set sometimes outperforms the greedy soup, but selecting the model on the test set will generally overestimate its true accuracy.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Robust fine-tuning</head><p>Wortsman et al. <ref type="formula" target="#formula_5">(2021)</ref> introduce WiSE-FT, a method for improving the robustness of a model ? 1 which is fine-tuned from initialization ? 0 by linearly interpolating ? 1 and ? 0 . An intriguing observation was that, once the data augmentation is fixed, interpolating between ? 1 and ? 0 often traces a similar curve regardless of hyperparameters. 4 In other words, a reasonable hypothesis was that this curve is Pareto optimal-no hyperparameter configuration would surpass it. In <ref type="figure">Figure D</ref>.1, we trace the curves when interpolating between ? 1 and ? 0 for a random hyperparameter search (left) and the standard grid search described in Appendix J.2.1 (right) when fine-tuning CLIP ViT-B/32. We find that the uniform soup and greedy soup lie beyond these interpolation curves. Moreover, we find interpolating between these soups and the initialization also provides additional accuracy improvements on the distribution shifts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Cross-dataset soups</head><p>So far, our experiments have studied soups of models fine-tuned on the same dataset with different hyperparameters. In this section, we prepare soups containing models fine-tuned on different datasets. We evaluate the resulting soups on a held-out dataset, from which no labeled training data is used (i.e., zero-shot evaluation).</p><p>Concretely, we consider soups based on the CLIP zero-shot initialization along with six models fine-tuned independently on CIFAR-10 ( <ref type="bibr" target="#b53">Krizhevsky et al., 2009</ref>), Describable Textures <ref type="bibr" target="#b17">(Cimpoi et al., 2014)</ref>, Food-101 <ref type="bibr" target="#b12">(Bossard et al., 2014)</ref>, SUN397 <ref type="bibr" target="#b100">(Xiao et al., 2016)</ref>, Stanford Cars <ref type="bibr" target="#b52">(Krause et al., 2013)</ref> and ImageNet <ref type="bibr" target="#b21">(Deng et al., 2009)</ref>. We evaluate on CIFAR-100 <ref type="bibr" target="#b53">(Krizhevsky et al., 2009</ref>), which does not share classes with CIFAR-10. Since each task has a different set of classes, the last layers cannot be part of the soup. Hence, during fine-tuning, we freeze the linear head produced by CLIP's text tower so that task-specific learning is captured only in the backbone weights. At test time, we use the "backbone soup" with a zero-shot head constructed from CLIP's text tower and the CIFAR-100 class names with the prompt-ensembling used for ImageNet by <ref type="bibr" target="#b74">Radford et al. (2021)</ref>. <ref type="figure" target="#fig_0">Figure E.1 (left)</ref> shows that a model soup containing models trained on each of these datasets and the zero-shot model improves zero-shot performance on CIFAR-100 by 6.4 percentage points over the CLIP baseline. Moreover, <ref type="figure" target="#fig_0">Figure E.1 (right)</ref> shows that the choice of which fine-tuned models to include can have a substantial impact on the accuracy of the resulting soup. See Appendix J.3 for additional details. The results are illustrated in <ref type="figure" target="#fig_0">Figure F.1, where each square represents a grid {h a , .</ref>.., h b }. The average of the endpoints often outperforms the best individual model in the grid. A notable exception is when the learning rate 10 ?4 is the left endpoint of the grid. As this experiment uses AdamW, this learning rate is too high for fine-tuning and, unlike the examples in <ref type="figure" target="#fig_2">Figure 2</ref>, there is a high error barrier between the two fine-tuned solutions (see <ref type="figure">Figure J</ref>.1, lower right for example).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Analysis of 1D hyperparameter grids</head><p>When varying optimizer we use minimal data augmentation and LR 3 ? 10 ?5 for RMSProp <ref type="bibr" target="#b88">(Tieleman and Hinton, 2012)</ref>, Adam (Kingma and Ba, 2014), and AdamW <ref type="bibr" target="#b60">(Loshchilov and Hutter, 2019)</ref>. SGD requires a larger learning rate, and so we use 0.1. When varying augmentation strength, we use minimal data augmentation and LR 3 ? 10 ?5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Additional fine-tuning and pre-training datasets</head><p>In this section we explore fine-tuning or pre-training on additional datasets. First, <ref type="figure">Figure G</ref> pre-training is smaller and less diverse. While the greedy soup offers an improvement, the improvement is less substantial than <ref type="figure" target="#fig_0">Figure 1</ref> which uses the same model and hyperparameter search but a different pre-training dataset.</p><p>Finally, we fine-tune a ViT-B/32 model five times on ImageNet, using the best hyperparameters found by the hyperparameter sweep, varying only the random seed. This experiment is conducted both for a model pre-trained on ImageNet-22k <ref type="bibr" target="#b21">(Deng et al., 2009</ref>) and a pre-trained CLIP model. The results are shown in <ref type="figure">Figure G</ref>.4, comparing, for an experimental budget of 1 ? k ? 5 models: (i) the individual model with random seed k, (ii) the model soup composed of models with random seeds 1 through k, and (iii) the ensemble composed of models with random seeds 1 through k. The performance of the model soup appears correlated with the performance of the ensemble. Moreover, we find that CLIP models are more amenable to both ensembling and souping than models pre-trained on ImageNet-22k. Avg. accuracy on 5 distribution shifts <ref type="figure">Figure G</ref>.4: For a CLIP and ImageNet-22k pre-trained ViT-B/32 model, we use the best hyperparameters found by the hyperparameter sweep to fine-tune multiple times, varying only the random seed. For an experimental budget of 1 ? k ? 5 models, we show: (i) the individual model with random seed k, (ii) the model soup composed of models with random seeds 1 through k, and (iii) the ensemble composed of models with random seeds 1 through k.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H. Additional grid searches and initializations</head><p>This section recreates <ref type="figure">Figure B</ref>.1 with different initializations (linear probe initialization or zero-shot) and different grid searches (standard and extreme grid) when fine-tuning CLIP ViT-B/32. The standard and extreme grid searches are described in Section J.2.1. <ref type="figure">Figure H</ref>.1 considers the linear probe (LP) initialization and the standard grid. <ref type="figure">Figure H.</ref>2 considers the linear probe (LP) initialization and the extreme grid. <ref type="figure">Figure H.</ref>3 considers the zero-shot initialization and the standard grid. <ref type="figure">Figure H</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Learned soup</head><p>In addition to the greedy soup method described in the text, we also explore a more advanced souping procedure, which removes the sequential constraint from the greedy soup and requires only a single pass through the held out validation set. We refer to this method as the learned soup, as it involves learning the soup mixing coefficients for each of the ingredients on the held-out validation set. However, the learned soup has the downside of requiring all models to be simultaneously loaded in memory. In practice we combine the models on CPU before moving the parameters to GPU for each batch. For loss and validation set {(x i , y i )} n i=1 , we find mixing coefficients ? ? R k and temperature scaling parameter ? via arg min</p><formula xml:id="formula_6">??R k ,??R n j=1 ? ? f x j , k i=1 ? i ? i , y j .<label>(2)</label></formula><p>In practice we find better results when ? is parameterized as the output of a softmax, so that each ? i is positive and values sum to one. We optimizer the aforementioned equation with gradient based mini-batch optimization for three epochs over the held-out validation set with the AdamW otpimizer and constant learning rate 0.1.</p><p>As presented in <ref type="table">Table 3</ref>, we also try a "by layer" variant of the learned soup. For this we learn a separate ? for each layer of the network. Finally, another way to get non-uniform mixing coefficients is to sample with replacement in the greedy soup procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J. Experimental details J.1. Error landscape visualizations</head><p>To supplement <ref type="figure" target="#fig_2">Figure 2</ref>, we provide an identical experiment but with a 10x bigger learning rate instead of 10x smaller. Results are illustrated in <ref type="figure">Figure J</ref>.1 with linear instead of log scaling for the contour lines. Since the error difference is more substantial, linear scaling was more clear. When fine-tuning with a larger learning rate, error increases on the path between the two fine-tuned solutions. All error landscape visualizations use CLIP ViT-B/32 fine-tuned on ImageNet for 10 epochs with minimal data augmentation, as used by CLIP during pre-training. When computing angles between the two fine-tuned solutions, as in <ref type="figure" target="#fig_3">Figure 3</ref>, we use the repeated weights which constitute the majority of the network parameters. We ignore gain terms which tend to skew positive if occurring before ReLU activations.</p><p>In <ref type="figure" target="#fig_3">Figure 3</ref> we consider solutions fine-tuned with learning rates less that 10 ?4 . As in <ref type="figure">Figure J</ref>.1, if a learning rate that is large is used accuracy will decrease on the path in weight space between the two models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.2. Model soups</head><p>This section describes the set of hyperparameters used for searches. For all ImageNet experiments, we withhold 2% of the training set and use these examples as the held-out validation set for model selection in greedy and learned soup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.2.1. CLIP EXPERIMENTS</head><p>Unless otherwise mentioned, all experiments used the AdamW optimizer <ref type="bibr" target="#b60">(Loshchilov and Hutter, 2019)</ref> with cosine annealing learning rate schedule <ref type="bibr" target="#b59">(Loshchilov and Hutter, 2016)</ref> for 10 epochs at batch size 512 at a resolution of 224?224. When necessary we discretize augmentation strength into minimal, medium, and strong. Minimal augmentation uses only a random crop consisting of 90%-100% of the total image area. Medium is the default augmentation used by the timm library <ref type="bibr" target="#b97">(Wightman, 2019)</ref>. Strong refers to RandAugment (Cubuk et al., 2020) (N = 2, M = 15).</p><p>We now provide the low level details for the hyperparemter searches, which are standard grid, extreme grid, and random search. The standard grid includes learning rates 3 ? 10 ?5 , 2 ? 10 ?5 , 1 ? 10 ?5 , 3 ? 10 ?6 , where 2 ? 10 ?5 , 1 ? 10 ?5 typically perform the best. Augmentation strengths are minimal, medium, or strong. Mixup is either off or on at ? = 0.5. We consider all combinations of the above, running each hyperparameter configuration with two random seeds.</p><p>The extreme grid considers learning rates 3 ? 10 ?4 , 1 ? 10 ?4 , 3 ? 10 ?5 , 2 ? 10 ?5 , 1 ? 10 ?5 , 3 ? 10 ?6 , 1 ? 10 ?6 , 1 ? 10 ?7 , where 2 ? 10 ?5 , 1 ? 10 ?5 typically perform the best. Augmentation strengths are minimal, medium, or strong. Mixup is either off or on at ? = 0.5. Moreover, we include the initialization in this search, which often outperforms some of the extreme learning rates but is far from the most accurate model. The random search chooses learning rate 10 ??1 where ? 1 is selected uniformly at random from 4 to 6. Weight decay is chosen randomly as 10 ??2 where ? 2 is selected uniformly at random from 0.2 to 4. With probability 0.5, label smoothing is set to 0 and otherwise it is selected uniformly at random between 0 and 0.25. Fine-tuning epochs are chosen randomly between four and sixteen. Mixup is 0 with probability 0.5, and otherwise is chosen uniformly at random from 0 to 0.9. With probability 1/3 we use minimal augmentation, otherwise we use randaug where M and N are chosen uniformly at random between 0 and 20 and 0 and 2 respectively.</p><p>When fine-tuning on WILDS-FMoW and WILDS-iWildCam for <ref type="figure">Figure G</ref>.1, we use the same random search as when we fine-tune CLIP on ImageNet. The only difference is that we are able to use a larger ViT-L/14 model as the datasets are smaller. This also requires us to change the default batch size from 512 to 128.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.2.2. ALIGN EXPERIMENTS</head><p>We fine-tuned ALIGN EfficientNet-L2 models using AdamW with weight decay of 0.1 at a resolution of 289 ? 289 for 25 epochs, with the final layer initialized from a linear probe without data augmentation. We fine-tuned 5 models with standard Inception-style random crops (consisting of 5% to 100% of the total image area with an aspect ratio between 0.75 and 1.33) and different learning rates (1 ? 10 ?6 , 2 ? 10 ?6 , 5 ? 10 ?6 , 1 ? 10 ?5 , and 2 ? 10 ?5 ). We also fine-tuned 7 additional models at a learning rate of 5 ? 10 ?6 with different data augmentation strategies. Specifically, we varied the random cropping strategy (either Inception-style crops or less aggressive crops consisting of 90% to 100% of the total image area with an aspect ratio between 0.95 and 1.05), the use of RandAugment (Cubuk et al., 2020) (off or N = 2, M = 15), and the use of mixup <ref type="bibr" target="#b107">(Zhang et al., 2017)</ref> (off or ? = 0.5) and trained models with all combinations of these strategies. Our soups are obtained by considering these 12 models as well as the linear probe initialization. We perform evaluation at 360 ? 360 resolution using a square center crop from images. The accuracy we attain with greedy soup approaches that reported by <ref type="bibr" target="#b45">Jia et al. (2021)</ref>, which evaluated at 600 ? 600 resolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.2.3. VIT-G/14 EXPERIMENTS</head><p>These models are initialized with a backbone that was pretrained on the JFT-3B dataset  and linear probes obtained at either the 224 ? 224 resolution at which the ViT-G/14 was pretrained or at the 518 ? 518 resolution used for fine-tuning. Models are fine-tuned at a batch size of 512 for either 10,000 or 20,000 steps (approximately 4 or 8 epochs) using the Adafactor optimizer <ref type="bibr" target="#b83">(Shazeer and Stern, 2018)</ref> with learning rates of 3 ? 10 ?5 or 5 ? 10 ?5 ; a constant or cosine decay learning rate schedule; and softmax or binary cross-entropy loss. When fine-tuning with binary cross-entropy loss, we use a linear probe that is also trained with binary cross-entropy loss. We vary data augmentation, applying <ref type="bibr">RandAugment (Cubuk et al., 2020)</ref>, mixup <ref type="bibr" target="#b107">(Zhang et al., 2017)</ref>, or CutMix <ref type="bibr" target="#b105">(Yun et al., 2019)</ref> of varying strengths and random cropping with a minimum crop size of 5%, 70%, 90%, or 100% of the full image. When applying SAM, we consider models with perturbations either synchronized or unsynchronized across accelerators, including one model with synchronized perturbations and a combination of CutMix and SAM. All models are fine-tuned at 518 ? 518 resolution and evaluated by rescaling test images to 550 ? 550 (without preserving the aspect ratio) and taking a 518 ? 518 central crop.</p><p>We manually tuned hyperparameters with the goal of maximizing single-model accuracy. After settling on the use of Adafactor as the optimizer, we included all subsequently trained models in the pool of models to be used for greedy soup.</p><p>The model that performs best on the holdout set is initialized with a 224 ? 224 linear probe and fine-tuned with a learning rate of 3e-5 and a constant learning rate decay schedule, with softmax cross-entropy loss, a minimum crop size of 90%, and CutMix with ? = 0.2. The model that performs best on the official ImageNet validation set is initialized with a 518 ? 518 linear probe and fine-tuned at a learning rate of 3e-5 and a constant learning rate decay schedule, with softmax cross-entropy loss, a minimum crop size of 90%, CutMix with ? = 0.2, and SAM. The greedy soup contains models trained with a wide range of different hyperparameter values including different learning rates, linear probes, loss functions, and every form of data augmentation and minimum crop size investigated. Notably, although models trained with SAM with synchronized perturbations are included in the greedy soup, the greedy soup process skips over the models trained with SAM with unsynchronized perturbations because adding them produces a large drop in holdout accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.3. Cross-dataset soups details</head><p>When fine-tuning we initialize with CLIP ViT-B/32 and use learning rate 3 ? 10 ?5 for 10 epochs with mini-batch size of 512. We train with minimal augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J.4. Text classification datasets</head><p>We study four text classification datasets from the GLUE benchmark <ref type="bibr" target="#b92">(Wang et al., 2018)</ref>.</p><p>Microsoft Research Paraphrase Corpus (MRPC; <ref type="bibr" target="#b26">(Dolan and Brockett, 2005)</ref>) contains pairs of sentences, labeled as either nearly semantically equivalent, or not. The dataset is evaluated using the average of F 1 and accuracy. The training set consists of 3.7 thousand samples and the validation set of 409 samples. clipping of 1.0, no weight decay, and with the learning rate being decayed linearly to zero at the end of training. We use pre-trained weights from the Huggingface Transformers library <ref type="bibr">(Wolf et al., 2020)</ref>. For BERT models, we use the uncased version.</p><p>Fine-tuning occurs without any additional parameters to avoid distorting the features from the pre-trained models <ref type="bibr" target="#b54">(Kumar et al., 2022)</ref>. For such, the classification tasks are adapted to be suited to the pre-training objective of BERT and T5. For T5, the tasks are cast as a sequence-to-sequence problem. For instance, for sentiment analyses, an example is to predict "A) positive" from "sentence: The best movie I've ever seen! | options: A) positive B) negative | label:". For BERT, the tasks are cast as a masked language modeling problem. For instance, for linguistic acceptability, an example is to predict "A) acceptable" for the inputs "sentence: model soups are grammatical. | options: A) acceptable B) unacceptable | label: <ref type="bibr">[MASK]</ref> [MASK] [MASK]". For evaluation, we select which of the options is given the highest probability according to the model.</p><p>The full set of results is shown in <ref type="table" target="#tab_11">Table J</ref>.1. On 10 out of the 20 combinations of models and datasets, the greedy soup shows better performance than the best individual model from the hyperparameter search. Uniform soups show worse performance than the best individual model on all experiments, which could be an artifact of the broad range of hyperparameters used in the search. While the experiments varied only basic hyperparameters such as learning rate and batch size, we hypothesize that a broader set of hyperparameter choices (e.g. data augmentation <ref type="bibr" target="#b95">(Wei and Zou, 2019;</ref><ref type="bibr" target="#b61">Ma, 2019)</ref>) could lead to more diverse models and better soups.</p><p>Finally, as a word of caution for practitioners, we remind readers that many recent language models have tied weights on the output and embedding layers <ref type="bibr" target="#b73">(Press and Wolf, 2017)</ref>. For this reason, caution is needed when writing code to average models in-place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K. Analytical comparison details K.1. Notation and preliminaries</head><p>We begin by restating and adding to the notation used in Section 4. For a model with parameter vector ? ? R d and input vector x, we let f (x; ?) ? R C denote the model's logit output for C-way classification. Throughout, we fix two endpoint models ? 0 and ? 1 , and for an interpolation parameter ? ? [0, 1] define</p><formula xml:id="formula_7">? ? := (1 ? ?)? 0 + ?? 1 , and f soup ? (x) := f (x; ? ? )</formula><p>to be the "soup" weight averaged model and its corresponding logits. We also write</p><formula xml:id="formula_8">f ens ? (x) := (1 ? ?)f (x; ? 0 ) + ?f (x; ? 1 )</formula><p>for the logits of the ensemble model. We write ? = ? 1 ? ? 0 for the difference of the two endpoints.</p><p>For a logit vector f ? R C and a ground-truth label y, denote the cross-entropy loss by</p><formula xml:id="formula_9">(f ; y) = log ? ? y exp{f y ? f y } ? ? .</formula><p>For some distribution over x, y we write the expected ?-calibrated log losses of the soup and ensemble as</p><formula xml:id="formula_10">L soup ? = E x,y (?f (x; ? ? ), y) and L ens ? = E x,y (?f ens ? (x), y),</formula><p>respectively.</p><p>We have the following expression for the derivatives of cross entropy w.r.t. logits. The gradient is</p><formula xml:id="formula_11">? f (f, y) = p sftmx (f ) ? e (y) ,</formula><p>where e (i) is the ith standard basis vector and p sftmx (f ) ? R C has e fi / j e fj in its ith entry. The Hessian is</p><formula xml:id="formula_12">? 2 f (f, y) = diag (p sftmx (f )) ? [p sftmx (f )][p sftmx (f )] T , so that for any v ? R C , we have v T ? 2 f (f, y) v = Var Y ?p sftmx (f ) [v Y ].</formula><p>Finally, we use ? T ?f (x; ?) to denote a vector in R C whose ith entry is ? T ?[f (x; ?)] i . Similarly, ? T ? 2 f (x; ?)? denotes a vector in R C whose ith entry is ? T [? 2 f (x; ?)] i ?, where gradients and Hessian are with respect to ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K.2. An exact expression for logit difference</head><p>We use the fundamental theorem of calculus and elemntary algebraic manipulation to obtain an exact integral form for the difference between the soup and ensemble logits. To streamline notation we drop the dependence of the logits on the input x.</p><formula xml:id="formula_13">f ens ? ? f soup ? = (1 ? ?) [f (? 0 ) ? f (? ? )] + ? [f (? 1 ) ? f (? ? )] = ? (1 ? ?) ? 0 ? T ?f (? t ) dt + ? 1 ? ? T ?f (? t ) dt = ? (1 ? ?) ? 0 ? T ?f (? ? ) + t ? ? T ?f (? ? ) ?d? dt + ? 1 ? ? T ?f (? ? ) + t ? ? T ?f (? ? ) ?d? dt = ? (1 ? ?) ? 0 t ? ? T ? 2 f (? ? ) ? d? dt + ? 1 ? t ? ? T ? 2 f (? ? ) ? d? dt = (1 ? ?) ? 0 ? t ? T ? 2 f (? ? ) ? d? dt + ? 1 ? t ? ? T ? 2 f (? ? ) ? d? dt = (1 ? ?) ? 0 ? T ? 2 f (? ? ) ? d? ? 0 dt + ? 1 ? ? T ? 2 f (? ? ) ? d? 1 ? dt = 1 0 ? T ? 2 f (? ? ) ? w ? (? ) d?,<label>(3)</label></formula><p>where</p><formula xml:id="formula_14">w ? (? ) = (1 ? ?) ? ? ? ? ? (1 ? ? ) otherwise = min {(1 ? ?) ?, ? (1 ? ? )} . Note that 1 0 w ? (? )d? = ?(1 ? ?) 2 . ?0.5 ?0.4 ?0.3 ?0.2 ?0.1 0.0 0.1 0.2</formula><p>Difference in loss between ensembles and interpolation  <ref type="formula" target="#formula_5">(1)</ref> for the performance difference of a 2-model soup and ensemble. Each marker on the scatter plots represent a different choice of endpoint models (?0, ?1) and interpolation weight ?. In every scatter plot, the vertical axis shows the true performance difference between the soup and ensemble (in loss for the left and center panes, and error for the right pane), where a positive value indicates the ensemble is better. The horizontal axis shows our approximation for the loss difference. The top row shows results with inverse temperature ? chosen to calibrate the soup, and the bottom row shows results for ? fixed to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K.4. Detailed empirical evaluations</head><p>Evaluation setup. We evaluated our bounds on checkpoints from the ViT-B/32 fine-tuning experiments from the extreme grid search described in Section J.2.1. We selected three learning rate values (10 ?6 , 10 ?5 and 10 ?4 ), two levels augmentation (none and RandAugment+MixUp), and considered two different random seeds (0 and 1). From these checkpoints (as well as the initialization) we constructed the following (? 0 , ? 1 ) pairs:</p><p>? All pairs with different learning rate, the same augmentation level and seed 0,</p><p>? All pairs with the same learning rate, different augmentation level and seed 0,</p><p>? All pairs with the same learning rate and augmentation level, but different seeds,</p><p>? All checkpoints with seed 0 coupled with the initialization.</p><p>This results in 21 pairs overall. For each pair and each ? ? {0, 0.1, . . . , 0.9, 1.0} we evaluated err ? , err ens ? , L soup ? , L ens ? , as well as the approximation (1). We performed this evaluation on the ImageNet validation set as well as on the 5 OOD test sets considered throughout this paper.</p><p>The effect of temperature calibration. Since our ultimate goal is to accurately predict the difference in error rather than the difference in loss, we introduce the inverse-temperature parameter ? to the loss, and tune it to calibrate the soup model. Specifically, for every model pair, value of ? and test set, we take ? = arg min ? E x,y (?f soup ? (x); y).</p><p>While choosing ? based on the soup rather the ensemble might skew the loss in favor of the soup, it has no effect on the difference in prediction error. Moreover, in preliminary experiments calibrating the ensemble produced very similar results. In contrast, as shown in <ref type="figure">Figure K</ref>.1, fixing ? = 1 throughout results in far poorer prediction of the difference in error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>L. Additional baselines</head><p>This section explores additional baselines for model soups, including distillation from an ensemble as in <ref type="bibr" target="#b42">Hinton et al. (2014)</ref>  <ref type="table">(Table L</ref>.1), fix-augmentation as in <ref type="bibr" target="#b89">Touvron et al. (2019)</ref>  <ref type="table">(Table L.</ref>2), weight-averaging along a trajectory as in <ref type="bibr" target="#b87">Szegedy et al. (2016)</ref>;   <ref type="figure" target="#fig_0">(Figures L.1 and L.</ref>2), and Sharpness Aware Minimization as in   <ref type="table">(Table L.</ref>3).</p><p>Unless otherwise mentioned, we fine-tune CLIP ViT-B/32 models with AdamW <ref type="bibr" target="#b60">(Loshchilov and Hutter, 2019)</ref> and cosine annealing learning rate <ref type="bibr" target="#b59">(Loshchilov and Hutter, 2016)</ref> for 10 epochs on ImageNet with a learning rate of 2e-5 and medium augmentation (data augmentation policies are discussed in more detail in Section J.2.1).</p><p>We explore the baseline of distillation <ref type="bibr" target="#b42">(Hinton et al., 2014;</ref> from the ensemble of three models trained with different data augmentation. As previously reported <ref type="bibr" target="#b3">(Bagherinezhad et al., 2018;</ref>, we find that it improves accuracy to run distillation with data augmentation. Unfortunately, this substantially increases the computational resources necessary to distill from the ensemble. As we cannot cache the predictions of the models in the ensemble, it is necessary to perform a forward pass for each model in the ensemble at each step of fine-tuning. This makes distilling from an ensemble similarly expensive as training the models which constitute the ensemble. Nevertheless, as illustrated in <ref type="table">Table L</ref>.1, model soups still perform favorably. <ref type="table">Table L</ref>.1 also introduces stochastic augmentation. For each data point, stochastic augmentation randomly applies minimal, medium, or strong data augmentation. Additionally, <ref type="table">Table L</ref>.2 explores an alternative method for merging augmentations together. This augmentation policy, which we refer to as fix-aug, is introduced by <ref type="bibr" target="#b89">Touvron et al. (2019)</ref>. For fix-aug, strong augmentation is used for all but the final epoch, which uses minimal augmentation.  <ref type="bibr" target="#b87">(Szegedy et al., 2016)</ref> and stochastic weight averages (SWA) . We find that EMA and SWA can improve the accuracy of a single model but that model soups provide improvements even when applied to models which have weight-averaging along their trajectory. We try learning rates 10 ?5 and 3 ? 10 ?5 and three learning rate schedulers: constant, cosine annealing with restarts, and cosine annealing (all schedules have a short warm up period). In <ref type="figure">Figure L</ref>  <ref type="table">Table L</ref>.3 explores the relation between model soups and sharpness-aware minimization (SAM) . In line with previous results, we find that SAM improves accuracy over vanilla fine-tuning. Souping two models trained with SAM improves over either individual model, although the magnitude of the gain is smaller than for vanilla fine-tuning. Souping models trained with and without SAM yields higher accuracy than souping models trained only with vanilla fine-tuning or only with SAM.</p><p>As a final comparison that is potentially useful, we augment <ref type="figure" target="#fig_0">Figure 1</ref> with additional comparisons from <ref type="table">Table 3</ref>. Results are shown in <ref type="figure">Figure L.</ref>  The improvements offered by model soups are additive with weight-averaging along a trajectory (by SWA or EMA with decay ?). The soup is the average of the model with minimal, medium and strong data aug. Results are shown for a ImageNet-21k pre-trained ViT-B/32 model fine-tuned on ImageNet. For SWA, we average checkpoints which are saved after each of the 10 epochs, while SWA 70% only averages checkpoints after fine-tune is 70% complete.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Model soups improve accuracy over the best individual model when performing a large, random hyperparameter search for fine-tuning a CLIP ViT-B/32 model on ImageNet. The uniform soup (blue circle) averages all fine-tuned models (green diamonds) in a random hyperparameter search over learning rate, weightdecay, iterations, data augmentation, mixup, and label smoothing. The greedy soup adds models sequentially to the model soup, keeping a model in the soup if accuracy on the held-out validation set does not decrease.MethodImageNet acc. Distribution (top-1, %) shifts</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The solution with the highest accuracy is often not a fine-tuned model but rather lies between fine-tuned models. This figure shows loss and error on a two dimensional slice of the loss and error landscapes. We use the zero-shot initialization ?0 and fine-tune twice (illustrated by the gray arrows), independently, to obtain solutions ?1 and ?2. As in Garipov et al. (2018), we obtain an orthonormal basis u1, u2 for the plane spanned by these models, and the x and y-axis show movement in parameter space in these directions, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>The advantage of averaging solutions (y-axis) is correlated with the angle ? between between solutions, while varying hyperparameter configurations between pairs enables a larger ?.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Ensemble performance is correlated with model soup performance. Each point on the scatter plot is a model pair with different hyperparameters. The x-axis is the accuracy when the weights of the two models are averaged (i.e., the two model soup) while the y-axis is the accuracy of the two model ensemble. Ensembles often perform slightly better than soups on ImageNet (left) while the reverse is true on the distribution shifts (right). Each model pair consists of two random greed diamonds fromFigure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Model soups improve accuracy when fine-tuning ALIGN. lation advantage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>model ensembling, model soups improve accuracy, but unlike model ensembling, model soups do not improve calibration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure D. 1 :</head><label>1</label><figDesc>Model soups compared to baselines for robust fine-tuning. WiSE-FT<ref type="bibr" target="#b99">(Wortsman et al., 2021)</ref> improves the robustness of model ?1 fine-tuned from initialization ?0 by interpolating between ?1 and ?0. Above we display the accuracy of models along these interpolation curves both for regular fine-tuned models and model soups (left: random hyperparameter search using the LP initialization, right: grid search using the zero-shot initialization). The model soups lie beyond the WiSE-FT curves generated by any individual model, and accuracy can be improved on the distribution shifts by applying WiSE-FT to the model soups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>This section asks: for a one dimensional grid of hyperparameters {h a , ..., h b }, how does averaging the models fine-tuned with hyperparameter configurations h a and h b corresponding to the endpoints compare with picking the best individual model fine-tuned with hyperparameter configuration h ? {h a , ..., h b }?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Model soups can improve zero-shot performance on new downstream tasks. (left) Starting with zero-shot CLIP we create a soup by adding models fine-tuned on ImageNet, CIFAR-10, Food101, SUN397, DTD, and Cars, and evaluate on CIFAR-100. Different orders for adding models are shown with faded lines. (right) The average change in CIFAR-100 accuracy when a model fine-tuned on the dataset listed in the y-axis is added to the model soup. ??{?a,...,?b} Acc (?) Figure F.1: Analysis of 1D hyperparameter grids, where the average of models at the endpoints often outperforms the best individual model in the grid. In particular, colors and numbers indicate the percentage point improvement obtained by averaging the models on the x and y axis versus taking the best individual model in the range between them. Results are shown for the CLIP ViT-B/32 model fine-tuned on ImagNet.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>.1 displays results when finetuning a CLIP ViT-L model on two datasets included in the WILDS<ref type="bibr" target="#b49">(Koh et al., 2021)</ref> challenge, FMoW<ref type="bibr" target="#b16">(Christie et al., 2018)</ref> and iWildCam.Next,Figure G.2 displays results for fine-tuning a CLIP ViT-L model on CIFAR-10 (Krizhevsky et al., 2009). The y-axis of Figure G.2 displays accuracy on CIFAR-10.1 (Recht et al., 2019), a reproduction of CIFAR-10 with a distribution shift. The individual models are fine-tuned with the random hyperparameter search described in Section J.2.1. In addition, Figure G.3 shows results when fine-tuning a ViT-B/32 (Dosovitskiy et al., 2021) model pre-trained on ImageNet-22k<ref type="bibr" target="#b21">(Deng et al., 2009</ref>) and fine-tuned on ImageNet. This differs from many of our other experiments as the dataset used for 65 1: Model soups improve accuracy when fine-tuning on the diverse classification tasksWILDS-FMoW (Koh et al., 2021;<ref type="bibr" target="#b16">Christie et al., 2018)</ref> andWILDS-iWildCam (Koh et al., 2021;. Results are shown for the CLIP ViT-L/14 model and a random hyperparameter search over learning rate, weight-decay, iterations, data augmentation, mixup, and label smoothing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head></head><label></label><figDesc>Fine-tuning a CLIP ViT-L model on CIFAR-10 (Krizhevsky et al., 2009) with the random hyperparameter search described in Section J.2.1. The y-axis displays accuracy on CIFAR-10.1 (Recht et al., 2019), a reproduction of CIFAR-10 with a distribution shift. Fine-tuning on ImageNet, using a ViT-B/32 (Dosovitskiy et al., 2021) pre-trained on ImageNet-22k (Deng et al.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>Figure B.1 with the LP initialization and the standard grid hyperparameter search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure H. 2 :</head><label>2</label><figDesc>ReplicatingFigure B.1 with the LP initialization and the extreme grid hyperparameter search.Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference timeFigure B.1 with the zero-shot initialization and the standard grid hyperparameter search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure H. 4 :</head><label>4</label><figDesc>ReplicatingFigure B.1 with the zero-shot initialization and the extreme grid hyperparameter search.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head></head><label></label><figDesc>Figure 2with a 10x larger learning rate instead of 10x smaller in the second row.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>Validation of the analytical approximation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure</head><label></label><figDesc>L.1 and Figure L.2 apply model soups to solutions which already average along the fine-tuning trajectory. Methods for averaging along an individual optimization trajectory include exponential moving averages (EMA)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>.1 we fine-tune a CLIP pre-trained ViT-B/32, while Figure L.2 fine-tunes an ImageNet-21k pre-trained ViT-B/32.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure</head><label></label><figDesc>Figure L.2: The improvements offered by model soups are additive with weight-averaging along a trajectory (by SWA or EMA with decay ?). The soup is the average of the model with minimal, medium and strong data aug. Results are shown for a ImageNet-21k pre-trained ViT-B/32 model fine-tuned on ImageNet. For SWA, we average checkpoints which are saved after each of the 10 epochs, while SWA 70% only averages checkpoints after fine-tune is 70% complete.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Proceedings of the 39 th International Conference on Machine Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copyright 2022 by the author(s).</figDesc><table><row><cell>Avg. accuracy on 5 distribution shifts</cell><cell>35 40 45 50 55</cell><cell>75</cell><cell>76</cell><cell>77</cell><cell>78</cell><cell>79</cell><cell>80</cell><cell>81 Greedy Soup Uniform Soup Initialization Various hyperparameters</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">ImageNet Accuracy (top-1, %)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Model soups improve accuracy over the best individual model when fine-tuning a JFT-3B pre-trained ViT-G/14 model on ImageNet. Instead of selecting the best model from a hyperparameter sweep during fine-tuning, model soups average the weights of multiple fine-tuned models. To evaluate performance under distribution shift we consider average accuracy on ImageNet-V2,</figDesc><table><row><cell>90.88</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>The primary methods contrasted in this work. Each ?i is a model found through fine-tuning from a shared initialization. Cost refers to the memory and compute requirements during inference relative to a single model. All methods require the same training.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Greedy soup improves over the best individual models obtained in a hyperparameter sweep for ViT-G/14 pre-trained on JFT-3B and fine-tuned on ImageNet, both in-and out-of-distribution. Accuracy numbers not significantly different from the best are bold-faced. Statistical comparisons are performed using an exact McNemar test or permutation test at ? = 0.05. Avg shift accuracy of the best model on each test set is the best average accuracy of any individual model. Analogous results when fine-tuning BASIC-L are available in Appendix C.</figDesc><table><row><cell></cell><cell></cell><cell>ImageNet</cell><cell></cell><cell></cell><cell cols="2">Distribution shifts</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="9">Top-1 ReaL Multilabel IN-V2 IN-R IN-Sketch ObjectNet IN-A Avg shifts</cell></row><row><cell>ViT/G-14 (Zhai et al., 2021)</cell><cell cols="2">90.45 90.81</cell><cell cols="2">-83.33</cell><cell>-</cell><cell>-</cell><cell>70.53</cell><cell>-</cell><cell>-</cell></row><row><cell>CoAtNet-7 (Dai et al., 2021)</cell><cell>90.88</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Our models/evaluations based on ViT-G/14:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">ViT/G-14 (Zhai et al., 2021) (reevaluated) 90.47 90.86</cell><cell cols="3">96.89 83.39 94.38</cell><cell>72.37</cell><cell cols="2">71.16 89.00</cell><cell>82.06</cell></row><row><cell>Best model on held out val set</cell><cell cols="2">90.72 91.04</cell><cell cols="3">96.94 83.76 95.04</cell><cell>73.16</cell><cell cols="2">78.20 91.75</cell><cell>84.38</cell></row><row><cell>Best model on each test set (oracle)</cell><cell cols="2">90.78 91.78</cell><cell cols="3">97.29 84.31 95.04</cell><cell>73.73</cell><cell cols="2">79.03 92.16</cell><cell>84.68</cell></row><row><cell>Greedy ensemble</cell><cell cols="2">90.93 91.29</cell><cell cols="3">97.23 84.14 94.85</cell><cell>73.07</cell><cell cols="2">77.87 91.69</cell><cell>84.33</cell></row><row><cell>Greedy soup</cell><cell cols="2">90.94 91.20</cell><cell cols="3">97.17 84.22 95.46</cell><cell>74.23</cell><cell cols="2">78.52 92.67</cell><cell>85.02</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Performance of model soups on four text classification datasets from the GLUE benchmark<ref type="bibr" target="#b92">(Wang et al., 2018)</ref>.</figDesc><table><row><cell>Model</cell><cell>Method</cell><cell>MRPC</cell><cell>RTE</cell><cell>CoLA</cell><cell>SST-2</cell></row><row><cell>BERT (Devlin et al., 2019b)</cell><cell>Best individual model Greedy soup</cell><cell>88.3 88.3 (+0.0)</cell><cell>61.0 61.7 (+0.7)</cell><cell>59.1 59.1 (+0.0)</cell><cell>92.5 93.0 (+0.5)</cell></row><row><cell>T5 (Raffel et al., 2020b)</cell><cell>Best individual model Greedy soup</cell><cell>91.8 92.4 (+0.6)</cell><cell>78.3 79.1 (+0.8)</cell><cell>58.8 60.2 (+0.4)</cell><cell>94.6 94.7 (+0.1)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc><ref type="bibr" target="#b56">LeCun, 1998)</ref> from the same random initialization are connected in weight space by a linear path of high accuracy.<ref type="bibr" target="#b30">Frankle et al. (2020)</ref> find that, when training a pair of models from scratch on harder datasets such as ImageNet with the same hyperparameter configuration and initialization but different data order, interpolating weights achieves no better than random accuracy. However, Frankle et al.(2020)  showed that when the two models share a portion of their optimization trajectory, accuracy does not drop when they are averaged.Analogously, Neyshabur  et al. (2020)  demonstrate that when two models are finetuned with the same pre-trained initialization, the interpolated model attains at least the accuracy of the endpoints.</figDesc><table><row><cell>; Frankle et al. (2020); Neyshabur et al. (2020); Von Oswald et al. (2020) and Matena and Raffel (2021) weight-average mod-els which share an initialization but are optimized indepen-dently. Nagarajan and Kolter (2019) observed that models trained on MNIST (Unlike Nagarajan and Kolter (2019); Frankle et al. (2020); Neyshabur et al. (2020) we consider averaging many models with varied hyperparameter configurations. In the late phases of training, Von Oswald et al. (2020) make copies of a subset of the neural network parameters (e.g, the batch norm weights, the classification layer, etc.). These parameters are then optimized independently and subse-</cell></row></table><note>quently averaged. In contrast to Von Oswald et al.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>ence Foundation (ISF) grant no. 2486/21, the Len Blavatnik and the Blavatnik Family foundation, and The Yandex Initiative for Machine Learning. This work is in part supported by the NSF AI Institute for Foundations of Machine Learning (IFML), Open Philanthropy, NSF IIS 1652052, IIS 17303166, DARPA N66001-19-2-4031, DARPA W911NF-15-1-0543 and gifts from Allen Institute for AI.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table C .</head><label>C</label><figDesc></figDesc><table><row><cell>Avg. accuracy on 5 distribution shifts</cell><cell>35 40 45 50 55</cell><cell>75</cell><cell>76</cell><cell>77</cell><cell>78</cell><cell>79</cell><cell>80</cell><cell>81</cell><cell>Avg. accuracy on 5 distribution shifts</cell><cell>44 46 48 50 52 54</cell><cell>60</cell><cell>65</cell><cell>70</cell><cell>75</cell><cell>80</cell><cell cols="2">Greedy Soup Uniform soup Initialization Individual models with various hyperparameters Interpolate with initialization (WiSE-FT) Minimal data aug Various stronger aug (with and without mixup) Minimal data aug with mixup</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">ImageNet Accuracy (top-1, %)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">ImageNet Accuracy (top-1, %)</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ImageNet</cell><cell></cell><cell></cell><cell cols="2">Distribution shifts</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Method</cell><cell></cell><cell></cell><cell cols="10">Top-1 ReaL Multilabel IN-V2 IN-R IN-Sketch ObjectNet IN-A Avg shifts</cell></row><row><cell cols="6">ViT/G-14 (Zhai et al., 2021)</cell><cell></cell><cell></cell><cell cols="4">90.45 90.81</cell><cell cols="2">-83.33</cell><cell>-</cell><cell>-</cell><cell>70.53</cell><cell>-</cell><cell>-</cell></row><row><cell cols="6">CoAtNet-7 (Dai et al., 2021)</cell><cell></cell><cell></cell><cell cols="2">90.88</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="10">BASIC-L (zero-shot) (Pham et al., 2021) 85.70</cell><cell></cell><cell>-</cell><cell cols="3">-80.60 95.70</cell><cell>76.10</cell><cell cols="2">82.30 85.60</cell><cell>84.06</cell></row><row><cell cols="7">CoCa (zero-shot) (Yu et al., 2022)</cell><cell></cell><cell cols="2">86.30</cell><cell></cell><cell>-</cell><cell cols="3">-80.70 96.50</cell><cell>77.60</cell><cell cols="2">82.70 90.20</cell><cell>85.54</cell></row><row><cell cols="7">CoCa (fine-tuned) (Yu et al., 2022)</cell><cell></cell><cell cols="2">91.00</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="7">ViT-G/14 greedy soup (Table 4)</cell><cell></cell><cell cols="4">90.94 91.20</cell><cell cols="3">97.17 84.22 95.46</cell><cell>74.23</cell><cell cols="2">78.52 92.67</cell><cell>85.02</cell></row><row><cell cols="10">Our models/evaluations with fine-tuned BASIC-L:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Best model on held out val set</cell><cell></cell><cell cols="4">90.83 90.84</cell><cell cols="3">98.16 84.42 95.50</cell><cell>76.98</cell><cell cols="2">78.09 93.13</cell><cell>85.63</cell></row><row><cell cols="5">Greedy ensemble</cell><cell></cell><cell></cell><cell></cell><cell cols="4">91.02 91.11</cell><cell cols="3">98.46 84.65 95.79</cell><cell>76.63</cell><cell cols="2">79.91 94.05</cell><cell>86.20</cell></row><row><cell cols="4">Greedy soup</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">90.98 91.03</cell><cell cols="3">98.37 84.63 96.10</cell><cell>77.18</cell><cell cols="2">79.94 94.17</cell><cell>86.40</cell></row><row><cell cols="7">Best model on each test set (oracle)</cell><cell></cell><cell cols="4">90.87 91.24</cell><cell cols="3">98.41 84.84 95.89</cell><cell>77.30</cell><cell cols="2">80.94 94.47</cell><cell>86.54</cell></row></table><note>1: Greedy soup improves over the best individual model on the held-out validation set when fine-tuning BASIC-L (Pham et al., 2021). Among the best model on the held out val set, the greedy ensemble, and the greedy soup, numbers not significantly different from the best are bold-faced. Statistical comparisons are performed using an exact McNemar test or permutation test at ? = 0.05. Avg shift accuracy of the best model on each test set is the best average accuracy of any individual model. For CoCa (Yu et al., 2022), a model which was introduced after our initial submission, evaluations were only available to one decimal place.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table J</head><label>J</label><figDesc>.1: Performance of model soups on four text classification datasets from the GLUE benchmark<ref type="bibr" target="#b92">(Wang et al., 2018)</ref>.</figDesc><table><row><cell>Model</cell><cell>Method</cell><cell>MRPC</cell><cell>RTE</cell><cell>CoLA</cell><cell>SST-2</cell></row><row><cell></cell><cell>Best individual model</cell><cell>88.3</cell><cell>61.0</cell><cell>59.1</cell><cell>92.5</cell></row><row><cell>BERT-base (Devlin et al., 2019b)</cell><cell>Uniform soup</cell><cell>76.0</cell><cell>52.7</cell><cell>0.0</cell><cell>89.9</cell></row><row><cell></cell><cell>Greedy soup</cell><cell>88.3</cell><cell>61.7</cell><cell>59.1</cell><cell>93.0</cell></row><row><cell></cell><cell>Best individual model</cell><cell>88.8</cell><cell>56.7</cell><cell>63.1</cell><cell>92.2</cell></row><row><cell>BERT-large (Devlin et al., 2019b)</cell><cell>Uniform soup</cell><cell>15.8</cell><cell>52.7</cell><cell>1.90</cell><cell>50.8</cell></row><row><cell></cell><cell>Greedy soup</cell><cell>88.8</cell><cell>56.7</cell><cell>63.1</cell><cell>92.3</cell></row><row><cell></cell><cell>Best individual model</cell><cell>89.7</cell><cell>70.0</cell><cell>42.2</cell><cell>91.7</cell></row><row><cell>T5-small (Raffel et al., 2020b)</cell><cell>Uniform soup</cell><cell>82.7</cell><cell>61.7</cell><cell>10.4</cell><cell>91.1</cell></row><row><cell></cell><cell>Greedy soup</cell><cell>89.7</cell><cell>70.0</cell><cell>43.0</cell><cell>91.7</cell></row><row><cell></cell><cell>Best individual model</cell><cell>91.8</cell><cell>78.3</cell><cell>58.8</cell><cell>94.6</cell></row><row><cell>T5-base (Raffel et al., 2020b)</cell><cell>Uniform soup</cell><cell>86.4</cell><cell>71.8</cell><cell>12.3</cell><cell>94.6</cell></row><row><cell></cell><cell>Greedy soup</cell><cell>92.4</cell><cell>79.1</cell><cell>60.2</cell><cell>94.7</cell></row><row><cell></cell><cell>Best individual model</cell><cell>93.4</cell><cell>82.7</cell><cell>61.7</cell><cell>96.3</cell></row><row><cell>T5-large (Raffel et al., 2020b)</cell><cell>Uniform soup</cell><cell>74.8</cell><cell>50.2</cell><cell>0.00</cell><cell>96.0</cell></row><row><cell></cell><cell>Greedy soup</cell><cell>93.4</cell><cell>84.8</cell><cell>62.7</cell><cell>96.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>The improvements offered by model soups are additive with weight-averaging along a trajectory (by SWA or EMA with decay ?). The soup is the average of the model with minimal, medium and strong data aug. Results are shown for a CLIP ViT-B/32 model fine-tuned on ImageNet. For SWA, we average checkpoints which are saved after each of the 10 epochs, while SWA 70% only averages checkpoints after fine-tune is 70% complete.</figDesc><table><row><cell></cell><cell></cell><cell>LR = 1e-05, LR schedule = constant LR = 1e-05, LR schedule = constant</cell><cell>LR = 3e-05, LR schedule = constant LR = 3e-05, LR schedule = constant</cell></row><row><cell></cell><cell>80</cell><cell></cell><cell>80</cell></row><row><cell>ImageNet (top-1, %) ImageNet (top-1, %)</cell><cell>77 78 79 78.0 78.5 79.0</cell><cell></cell><cell>77 78 79 78.0 ImageNet (top-1, %) 78.5 79.0 ImageNet (top-1, %)</cell></row><row><cell cols="2">No EMA No EMA No EMA 77.5 76 76 77 78 79 80 76 77 78 79 80 No EMA 77.5 78.0 78.5 79.0 No EMA 77.5 78.0 78.5 79.0 Figure L.1: No EMA ImageNet (top-1, %) ImageNet (top-1, %) ImageNet (top-1, %) ImageNet (top-1, %)</cell><cell>3 ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 LR = 1e-05, LR schedule = cosine annealing with restarts ?=0.99 SWA ?=0.99 SWA ?=0.99 ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 SWA LR = 1e-05, LR schedule = cosine annealing Soup Minimal aug SWA (70%) SWA (70%) SWA (70%) ?=0.99 ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 SWA SWA (70%) ?=0.99 ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 SWA SWA (70%) LR = 1e-05, LR schedule = cosine annealing with restarts ?=0.99 ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 SWA SWA (70%) LR = 1e-05, LR schedule = cosine annealing Soup Minimal aug</cell><cell>No EMA No EMA No EMA Medium aug ?=0.99 ?=0.99 LR = 3e-05, LR schedule = cosine annealing with restarts ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 SWA ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 SWA ?=0.99 ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 SWA LR = 3e-05, LR schedule = cosine annealing Strong aug No EMA ?=0.99 ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 SWA 77.5 76 76 77 78 79 80 ImageNet (top-1, %) 76 77 78 79 80 ImageNet (top-1, %) No EMA ?=0.99 ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 SWA 77.5 78.0 78.5 79.0 ImageNet (top-1, %) LR = 3e-05, LR schedule = cosine annealing with restarts No EMA ?=0.99 ?=0.999 ?=0.9999 ?=0.99999 ?=0.999999 SWA 77.5 78.0 78.5 79.0 ImageNet (top-1, %) LR = 3e-05, LR schedule = cosine annealing Medium aug Strong aug</cell><cell>SWA (70%) SWA (70%) SWA (70%) SWA (70%) SWA (70%) SWA (70%)</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Since our initial submission, we attain 90.98% with BA-SIC, which ties the newer CoCa model<ref type="bibr" target="#b104">(Yu et al., 2022)</ref> to their reported precision; see Appendix C.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In particular, the angle ? between ?1 ? ?0 and ?2 ? ?0, i.e., the angle between the arrows shown inFigure 2.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Fine-tuned models with learning rate 10 ?4 are far in weight space from the initial model and are often rejected when forming greedy soups. Therefore, we do not expect our approximation to be tight for these learning rates.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">This is visible inFigure D.1 (right) where different data augmentations are shown with different colors. On the other hand, inFigure D.1 (left) there are many different methods of data augmentation as we conduct a random hyperparameter search.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Recognizing Textual Entailment (RTE;<ref type="bibr" target="#b92">(Wang et al., 2018)</ref>) contains pair of sentences, and the task is to predict whether the first sentence (the premise) entails or contradicts the second sentence (the hypothesis). The data is originally from a series of datasets<ref type="bibr" target="#b19">(Dagan et al., 2005;</ref><ref type="bibr" target="#b4">Bar-Haim et al., 2006;</ref><ref type="bibr" target="#b35">Giampiccolo et al., 2007;</ref><ref type="bibr" target="#b8">Bentivogli et al., 2009</ref>). The dataset is evaluated using classification accuracy. The training set consists of 2.5 thousand samples and the validation set of 277 samples.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Ting Chen, Jesse Dodge, Ben Eysenbach, David Fleet, Pieter-Jan Kindermans, Mohammad Norouzi, Sarah Pratt and Vivek Ramanujan for helpful discussions and draft feedback, Lucas Beyer and Xiaohua Zhai for assistance with ViT-G/14 fine-tuning, and Hyak at UW for computing support. YC was supported in part by the Israeli Sci-</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K.3. Derivation of approximation</head><p>We continue to suppress the dependence on x in order to simplify notation. We begin with the following first order approximation of the pointwise log-loss difference between the ensemble and soup, which is also a lower bound due to convexity.</p><p>Now, we approximate the ensemble and soup logit difference using eq. 3 by assuming that <ref type="bibr">1]</ref>; this holds when the logits are approximately quadratic along the line between the checkpoints. The resulting approximation is</p><p>Combining the two approximation above, we obtain</p><p>To relate this expression to the Hessian of the loss with respect to the parameters, we note that for any ? (by the chain rule)</p><p>When setting ? = ? ? , we note that the second term on the RHS is (up to a constant) our approximation for the loss difference). Recalling the expression for the cross-entropy Hessian, the first term is</p><p>As a final approximation, we let</p><p>this holds when logits are too far from linear in ?.</p><p>Substituting back and making x explicit, we obtain</p><p>where we have used</p><p>Scaling all logits by ?, the approximation becomes</p><p>Averaging the result over x, we arrive at the approximation (1), which we repeat here for ease of reference:  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Analyzing the performance of multilayer neural networks for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pulkit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="329" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">The evolution of out-of-distribution robustness throughout fine-tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Andreassen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasaman</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnam</forename><surname>Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2106.15831" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">From generic to specific deep representations for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Sharif Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josephine</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuto</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Carlsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition workshops</title>
		<meeting>the IEEE conference on computer vision and pattern recognition workshops</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="36" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Label refinery: Improving imagenet classification through label progression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hessam</forename><surname>Bagherinezhad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxwell</forename><surname>Horton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.02641</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The second pascal recognising textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Bar-Haim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Idan</forename><surname>Szpektor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the II PASCAL challenge</title>
		<meeting>of the II PASCAL challenge</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognition models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Barbu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Alverio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gutfreund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Katz</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/97af07a14cacba681feacf3012730892-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">An empirical comparison of voting classification algorithms: Bagging, boosting, and variants. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Kohavi</surname></persName>
		</author>
		<idno type="DOI">https:/link.springer.com/article/10.1023/A:1007515423169</idno>
		<ptr target="https://link.springer.com/article/10.1023/A:1007515423169" />
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The iwildcam 2021 competition dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Beery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arushi</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elijah</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vighnesh</forename><surname>Birodkar</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2105.03494" />
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR) FGVC8 Workshop</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">The fifth pascal recognizing textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<editor>TAC</editor>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>H?naff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kolesnikov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07159</idno>
		<title level="m">Xiaohua Zhai, and A?ron van den Oord. Are we done with imagenet? arXiv preprint</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Knowledge distillation: A good teacher is patient and consistent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Am?lie</forename><surname>Royer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larisa</forename><surname>Markeeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2106.05237" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">On the opportunities and risks of foundation models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishi</forename><surname>Bommasani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Drew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Hudson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russ</forename><surname>Adeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simran</forename><surname>Altman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sydney Von Arx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeannette</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bohg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brunskill</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2108.07258" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Food-101-mining discriminative components with random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Bossard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<ptr target="https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/" />
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Bagging predictors. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Breiman</surname></persName>
		</author>
		<idno type="DOI">https:/link.springer.com/article/10.1007/BF00058655</idno>
		<ptr target="https://link.springer.com/article/10" />
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rich Caruana, Art Munson, and Alexandru Niculescu-Mizil. Getting the most out of ensemble selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">/</forename><forename type="middle">Rich</forename><surname>Bf00058655</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandru</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Crew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ksikes</surname></persName>
		</author>
		<idno type="DOI">https:/link.springer.com/article/10.1007/BF00058655</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the twenty-first international conference on Machine learning</title>
		<meeting>the twenty-first international conference on Machine learning</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="828" to="833" />
		</imprint>
	</monogr>
	<note>Sixth International Conference on Data Mining (ICDM&apos;06)</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Return of the devil in the details: Delving deep into convolutional nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ken</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Functional map of the world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gordon</forename><surname>Christie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Fendley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mukherjee</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1711.07846" />
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Describing textures in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mircea</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sammy</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1311.3618" />
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">RandAugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1909.13719" />
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The pascal recognising textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Ido Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning Challenges Workshop</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">CoAtNet: Marrying convolution and attention for all data sizes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/5206848" />
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">North American Chapter of the Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://aclanthology.org/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Ensemble methods in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dietterich</surname></persName>
		</author>
		<idno type="DOI">https:/link.springer.com/chapter/10.1007/3-540-45014-9_1</idno>
		<idno>10. 1007/3-540-45014-9_1</idno>
		<ptr target="https://link.springer.com/chapter" />
	</analytic>
	<monogr>
		<title level="m">International workshop on multiple classifier systems</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fine-tuning pretrained language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06305</idno>
	</analytic>
	<monogr>
		<title level="m">Weight initializations, data orders, and early stopping</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automatically constructing a corpus of sentential paraphrases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Brockett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IWP</title>
		<meeting>of IWP</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="647" to="655" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2010.11929" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sharpness-aware minimization for efficiently improving generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Foret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Kleiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Mobahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behnam</forename><surname>Neyshabur</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=6Tm1mposlrM" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Linear mode connectivity and the lottery ticket hypothesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Gintare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dziugaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Carbin</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1912" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A decision-theoretic generalization of on-line learning and an application to boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<ptr target="https://www.sciencedirect.com/science/article/pii/S002200009791504X" />
	</analytic>
	<monogr>
		<title level="j">Journal of Computer and System Sciences</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The elements of statistical learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Springer series in statistics</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijie</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renrui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teli</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongyao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.04544</idno>
		<title level="m">Clip-adapter: Better vision-language models with feature adapters</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Loss surfaces, mode connectivity, and fast ensembling of dnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timur</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitrii</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Wilson</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1802.10026" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The third pascal recognizing textual entailment challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ido</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the ACL-PASCAL workshop on textual entailment and paraphrasing</title>
		<meeting>of the ACL-PASCAL workshop on textual entailment and paraphrasing</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">No one representation to rule them all: Overlapping features of training methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Gontijo-Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin Dogus</forename><surname>Cubuk</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=BK-4qbGgIE3" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1706.04599" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Spottune: transfer learning through adaptive fine-tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhui</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristen</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tajana</forename><surname>Rosing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4805" to="4814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The many faces of robustness: A critical analysis of out-of-distribution generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Dorundo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samyak</forename><surname>Parajuli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2006.16241" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV), 2021a</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1907.07174" />
		<title level="m">Natural adversarial examples. Conference on Computer Vision and Pattern Recognition (CVPR), 2021b</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Dark knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<ptr target="https://www.ttic.edu/dl/dark14.pdf" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1503.02531" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS) Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Averaging weights leads to wider optima and better generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Izmailov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitrii</forename><surname>Podoprikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timur</forename><surname>Garipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Vetrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Wilson</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1803.05407" />
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Scaling up visual and vision-language representation learning with noisy text supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zarana</forename><surname>Parekh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhsuan</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duerig</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2102.05918" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">The amu-uedin submission to the wmt16 news translation task: Attention-based nmt models as feature functions in phrase-based smt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Dwojak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.04809</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Kaddour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ricardo</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><forename type="middle">J</forename><surname>Kusner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.00661</idno>
	</analytic>
	<monogr>
		<title level="m">Questions for flat-minima optimization of modern neural networks</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">WILDS: A benchmark of in-the-wild distribution shifts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pang</forename><surname>Wei Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiori</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Marklund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sang</forename><forename type="middle">Michael</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akshay</forename><surname>Balsubramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">Lanas</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irena</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Stavness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Berton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imran</forename><forename type="middle">S</forename><surname>Earnshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Haque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Beery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anshul</forename><surname>Leskovec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emma</forename><surname>Kundaje</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Pierson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2012.07421" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Big transfer (bit): General visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1912.11370" />
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Do better imagenet models transfer better?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1805.08974" />
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<ptr target="https://ieeexplore.ieee.org/document/6755945" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV) Workshops</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="https://www.cs.toronto.edu/?kriz/learning-features-2009-TR.pdf" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Fine-tuning can distort pretrained features and underperform out-of-distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ananya</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditi</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robbie</forename><forename type="middle">Matthew</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=UYneFzXSJWh" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Simple and scalable predictive uncertainty estimation using deep ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1612.01474" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Bayesian hyperparameter optimization for ensemble learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien-Charles</forename><surname>L?vesque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Gagn?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Sabourin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.06394</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Rifle: Backpropagation in depth for deep transfer learning through re-initializing the fully-connected layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyi</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhe</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Zhong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejing</forename><surname>Dou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6010" to="6019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1608.03983" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Bkg6RiCqY7" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Ma</surname></persName>
		</author>
		<ptr target="https://github.com/makcedward/nlpaug" />
		<title level="m">Nlp augmentation</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Exploring the limits of weakly supervised pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vignesh</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1805.00932" />
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Ashwin Bharambe, and Laurens Van Der Maaten</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Merging models with fisherweighted averaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2111.09832" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Comparison of the predicted and observed secondary structure of t4 phage lysozyme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Brian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biochimica et Biophysica Acta (BBA)-Protein Structure</title>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Jost Tobias Springenberg, and Frank Hutter. Towards automatically-tuned neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hector</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Feurer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Automatic Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="58" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Slip: Self-supervision meets language-image pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.12750</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Deep ensembles for low-data transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Basil</forename><surname>Mustafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Riquelme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andr? Susano</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2010.06866" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Uniform convergence may be unable to explain generalization in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J. Zico</forename><surname>Vaishnavh Nagarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kolter</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/05e97c207235d63ceb1db43c60db7bbb-Paper" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">What is being transferred in transfer learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanie</forename><surname>Behnam Neyshabur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Sedghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2008.11687" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Can you trust your model&apos;s uncertainty? evaluating predictive uncertainty under dataset shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Ovadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Fertig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Nado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">V</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1906.02530" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Combined scaling for zero-shot transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Golnaz</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2111.10050" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time Boris Teodorovich Polyak. New method of stochastic approximation type. Automation and remote control</title>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Using the output embedding to improve language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/E17-2025" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-04" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="157" to="163" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2103.00020" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v21/20-074.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Exploring the limits of transfer learning with a unified textto-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="http://jmlr.org/papers/v21/20-074.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">140</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Do ImageNet classifiers generalize to ImageNet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1902.10811" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Mitigating bias in calibration error estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Cain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael C</forename><surname>Mozer</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2012.08668" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Efficient estimations from a slowly convergent robbins-monro process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ruppert</surname></persName>
		</author>
		<ptr target="https" />
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Optimized generic feature learning for few-shot classification across domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07926</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Evaluating machine accuracy on imagenet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaishaal</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horia</forename><surname>Mania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v119/shankar20c/shankar20c.pdf" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Cnn features off-the-shelf: an astounding baseline for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Sharif Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Azizpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josephine</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Carlsson</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1403.6382" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition workshops</title>
		<meeting>the IEEE conference on computer vision and pattern recognition workshops</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Adafactor: Adaptive learning rates with sublinear memory cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Stern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4596" to="4604" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Zoo-tuning: Adaptive transfer from a zoo of models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Kou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangjie</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9626" to="9637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Scalable bayesian optimization using deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Rippel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadathur</forename><surname>Satish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narayanan</forename><surname>Sundaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostofa</forename><surname>Patwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mr</forename><surname>Prabhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Adams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2171" to="2180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title level="m" type="main">Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural networks for machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tijmen</forename><surname>Tieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="26" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Fixing the train-test resolution discrepancy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Jegou</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/d03a857a23b5285736c4d55e0bb067c8-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seijin</forename><surname>Johannes Von Oswald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Sacramento</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Meulemans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Henning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Benjamin F Grewe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.12927</idno>
		<title level="m">Neural networks with late-phase weights</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b92">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel R</forename><surname>Bowman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07461</idno>
		<title level="m">Glue: A multi-task benchmark and analysis platform for natural language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Learning robust global representations by penalizing local predictive power</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haohan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songwei</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1905.13549" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Warstadt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<title level="m">Neural network acceptability judgments. TACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="625" to="641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11196</idno>
		<title level="m">Eda: Easy data augmentation techniques for boosting performance on text classification tasks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Wenzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodolphe</forename><surname>Jenatton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.13570</idno>
		<title level="m">Hyperparameter ensembles for robustness and uncertainty quantification</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Pytorch image models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Wightman</surname></persName>
		</author>
		<ptr target="https://github.com/rwightman/pytorch-image-models" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Transformers: Stateof-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joe</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yacine</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Canwen</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Teven</forename><forename type="middle">Le</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Scao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariama</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rush</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m">Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time Thomas Wolf</title>
		<imprint>
			<date type="published" when="2020-10" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Robust fine-tuning of zero-shot models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Wortsman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Gontijo-Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongseok</forename><surname>Namkoong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludwig</forename><surname>Schmidt</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2109.01903" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Sun database: Exploring a large collection of scene categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Ehinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oliva</surname></persName>
		</author>
		<idno type="DOI">https:/link.springer.com/article/10.1007/s11263-014-0748-y</idno>
		<ptr target="https://link.springer.com/article/10.1007/s11263-014-0748-y" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Explicit inductive bias for transfer learning with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Li Xuhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franck</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davoine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2825" to="2834" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">Billion-scale semi-supervised learning for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>I Zeki Yalniz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mahajan</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1905" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">How transferable are features in deep neural networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Yosinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Clune</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hod</forename><surname>Lipson</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1411.1792" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zirui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Legg</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mojtaba</forename><surname>Seyedhosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01917</idno>
		<title level="m">Coca: Contrastive captioners are image-text foundation models</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6023" to="6032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">Scaling vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2106.04560" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1710.09412" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Lookahead optimizer: k steps forward, 1 step back</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Michael R Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1907.08610" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renrui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongyao</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunchang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.03930</idno>
		<title level="m">Tip-adapter: Trainingfree clip-adapter for better vision-language modeling</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Learning to prompt for vision-language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingkang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2109.01134" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">2019)) contains sentences labeled as either grammatical or ungrammatical. Models are evaluated on Matthews correlation (MCC; (Matthews, 1975)), which ranges between ?1 and 1. The training set consists of 8.6 thousand samples and the validation set consists of 1043 samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Warstadt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Corpus of Linguistic Acceptability (CoLA</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<monogr>
		<title level="m" type="main">contains sentences labelled as expressing positive or negative sentiment, collected from movie reviews. The dataset is evaluated using classification accuracy. The training set consists of 67 thousand samples and the validation set consists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanford Sentiment Treebank ;</forename><surname>Socher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">873</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<analytic>
		<title level="a" type="main">Fine-tuning details for text classification tasks Each model is fine-tuned 32 times on each dataset, performing a random hyperparameter search. The learning rate is chosen uniformly in log space over</title>
	</analytic>
	<monogr>
		<title level="j">J</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>10 ?6 , 10 ?3 ], the batch size is chosen uniformly from {8, 16, 32, 64} and the number of epochs from {2, 3, 5}. Evaluation is conducted once at the end of training. without early stopping. We use a maximum sequence length of 128 tokens and train with Adam (Kingma and</note>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<title level="m" type="main">1: Comparing model soups to network distillation from an ensemble of models trained with different data augmentations. Stochastic data augmentation randomly applies minimal, medium, or strong data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Table</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>ImageNet Distribution shifts Individual model (LR 3e-05. minimal aug</note>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
				<idno>3e-05) 80.24 47.97</idno>
		<title level="m">Soup minimal, medium, and strong aug</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
				<title level="m">Ensemble minimal, medium, and strong aug (LR 3e-05)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
				<idno>1e-05) 80.08 49.75</idno>
		<title level="m">Soup minimal, medium, and strong aug</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
				<title level="m">Ensemble minimal, medium, and strong aug (LR 1e-05)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b119">
	<monogr>
		<title level="m" type="main">2: Comparing models soups of different augmentations with another method which combines different augmentation strategiesfix aug</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Table</surname></persName>
		</author>
		<editor>Touvron et al.</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>For fix aug we use strong data augmentation for all except the final epoch for which we</note>
</biblStruct>

<biblStruct xml:id="b120">
	<monogr>
				<idno>3e-05) 80.24 47.97</idno>
		<title level="m">Soup minimal, medium, and strong aug</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<monogr>
				<title level="m">Soup minimal, medium, strong, and fix aug (LR 3e</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
				<idno>1e-05) 80.08 49.75</idno>
		<title level="m">Soup minimal, medium, and strong aug</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
				<idno>LR 1e-05) 80.17 49.71</idno>
		<title level="m">Soup minimal, medium, strong, and fix aug</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b124">
	<monogr>
		<title level="m" type="main">3: Applying model soups to models trained with sharpness aware minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Table</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Foret</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
