<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cognitive Graph for Multi-Hop Reading Comprehension at Scale</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Ding</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ? DAMO Academy</orgName>
								<address>
									<country>Alibaba Group</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ? DAMO Academy</orgName>
								<address>
									<country>Alibaba Group</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ? DAMO Academy</orgName>
								<address>
									<country>Alibaba Group</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
							<email>yang.yhx@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ? DAMO Academy</orgName>
								<address>
									<country>Alibaba Group</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
							<email>jietang@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Technology</orgName>
								<orgName type="institution">Tsinghua University ? DAMO Academy</orgName>
								<address>
									<country>Alibaba Group</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cognitive Graph for Multi-Hop Reading Comprehension at Scale</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a new CogQA framework for multi-hop question answering in web-scale documents. Founded on the dual process theory in cognitive science, the framework gradually builds a cognitive graph in an iterative process by coordinating an implicit extraction module (System 1) and an explicit reasoning module (System 2). While giving accurate answers, our framework further provides explainable reasoning paths. Specifically, our implementation 1 based on BERT and graph neural network (GNN) efficiently handles millions of documents for multi-hop reasoning questions in the HotpotQA fullwiki dataset, achieving a winning joint F 1 score of 34.9 on the leaderboard, compared to 23.6 of the best competitor. 2</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep learning models have made significant strides in machine reading comprehension and even outperformed human on single paragraph question answering (QA) benchmarks including SQuAD <ref type="bibr" target="#b30">(Wang et al., 2018b;</ref><ref type="bibr" target="#b6">Devlin et al., 2018;</ref><ref type="bibr" target="#b20">Rajpurkar et al., 2016)</ref>. However, to cross the chasm of reading comprehension ability between machine and human, three main challenges lie ahead: 1) Reasoning ability. As revealed by adversarial tests <ref type="bibr" target="#b14">(Jia and Liang, 2017)</ref>, models for single paragraph QA tend to seek answers in sentences matched by the question, which does not involve complex reasoning. Therefore, multi-hop QA becomes the next frontier to conquer <ref type="bibr" target="#b34">(Yang et al., 2018)</ref>. 2) Explainability. Explicit reasoning paths, which enable verification of logical rigor, are vital for the reliability of QA systems. HotpotQA <ref type="bibr" target="#b34">(Yang et al., 2018)</ref> requires <ref type="bibr">1</ref> Codes are avaliable at https://github.com/ THUDM/CogQA 2 https://hotpotqa.github.io, March 4, 2019 <ref type="figure">Figure 1</ref>: An example of cognitive graph for multi-hop QA. Each hop node corresponds to an entity (e.g., "Los Angeles") followed by its introductory paragraph. The circles mean ans nodes, answer candidates to the question. Cognitive graph mimics human reasoning process. Edges are built when calling an entity to "mind". The solid black edges are the correct reasoning path. models to provide supporting sentences, which means unordered and sentence-level explainability, yet humans can interpret answers with step by step solutions, indicating an ordered and entitylevel explainability. 3) Scalability. For any practically useful QA system, scalability is indispensable. Existing QA systems based on machine comprehension generally follow retrievalextraction framework in DrQA , reducing the scope of sources to a few paragraphs by pre-retrieval. This framework is a simple compromise between single paragraph QA and scalable information retrieval, compared to human's ability to breeze through reasoning with knowledge in massive-capacity memory <ref type="bibr" target="#b32">(Wang et al., 2003)</ref>. Therefore, insights on the solutions to these challenges can be drawn from the cognitive process of humans. Dual process theory <ref type="bibr" target="#b7">(Evans, 1984</ref><ref type="bibr" target="#b8">(Evans, , 2003</ref><ref type="bibr" target="#b9">(Evans, , 2008</ref><ref type="bibr" target="#b24">Sloman, 1996)</ref> suggests that our brains first retrieve relevant information follow-ing attention via an implicit, unconscious and intuitive process called System 1, based on which another explicit, conscious and controllable reasoning process, System 2, is then conducted. System 1 could provide resources according to requests, while System 2 enables diving deeper into relational information by performing sequential thinking in the working memory, which is slower but with human-unique rationality <ref type="bibr" target="#b0">(Baddeley, 1992)</ref>. For complex reasoning, the two systems are coordinated to perform fast and slow thinking (Kahneman and Egan, 2011) iteratively.</p><p>In this paper, we propose a framework, namely Cognitive Graph QA (CogQA), contributing to tackling all challenges above. Inspired by the dual process theory, the framework comprises functionally different System 1 and 2 modules. System 1 extracts question-relevant entities and answer candidates from paragraphs and encodes their semantic information. Extracted entities are organized as a cognitive graph <ref type="figure">(Figure 1)</ref>, which resembles the working memory. System 2 then conducts the reasoning procedure over the graph, and collects clues to guide System 1 to better extract next-hop entities. The above process is iterated until all possible answers are found, and then the final answer is chosen based on reasoning results from System 2. An efficient implementation based on BERT <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref> and graph neural network (GNN) <ref type="bibr" target="#b1">(Battaglia et al., 2018)</ref> is introduced.</p><p>Our contributions are as follows:</p><p>? We propose the novel CogQA framework for multi-hop reading comprehension QA at scale according to human cognition. ? We show that the cognitive graph structure in our framework offers ordered and entitylevel explainability and suits for relational reasoning. ? Our implementation based on BERT and GNN surpasses previous works and other competitors substantially on all the metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Cognitive Graph QA Framework</head><p>Reasoning ability of humankind depends critically on relational structures of information. Intuitively, we adopt a directed graph structure for step-bystep deduction and exploration in cognitive process of multi-hop QA. In our reading comprehension setting, each node in this cognitive graph G corresponds with an entity or possible answer x, also interchangeably denoted as node x. The ex- traction module System 1, reads the introductory paragraph para <ref type="bibr">[x]</ref> of entity x and extracts answer candidates and useful next-hop entities from the paragraph. G is then expanded with these new nodes, providing explicit structure for the reasoning module, System 2. In this paper, we assume that System 2 conducts deep learning based instead of rule-based reasoning by computing hidden representations X of nodes. Thus System 1 is also required to summarize para[x] into a semantic vector as initial hidden representation when extracting spans. Then System 2 updates X based on graph structure as reasoning results for downstream prediction.</p><p>Explainability is enjoyed owing to explicit reasoning paths in the cognitive graph. Besides simple paths, the cognitive graph can also clearly display joint or loopy reasoning processes, where new predecessors might bring new clues about the answer. Clues in our framework is a form-flexible concept, referring to information from predecessors for guiding System 1 to better extract spans. Apart from newly added nodes, those nodes with new incoming edges also need revisits due to new clues. We refer to both of them as frontier nodes.</p><p>Scalability means that the time consumption of QA will not grow significantly along with the number of paragraphs. Our framework can scale </p><formula xml:id="formula_0">O m V K 2 7 V n Q E t E y 8 n F c j R 6 J W / u v 2 Y p I J K Q z j W 2 v f c x A Q Z V o Y R T i e l b q p p g s k I D 6 h v q c S C 6 i C b H T x B J 1 b p o y h W t q R B M / X 3 R I a F 1 m M R 2 k 6 B z V A v e l P x P 8 9 P T X Q Z Z E w m q a G S z B d F K U c m R t P v U Z 8 p S g w f W 4 K J Y v Z W R I Z Y Y W J s R i U b g r f 4 8 j J p n V U 9 t + r d n V d q V 3 k c R T i C Y z g F D y 6 g B j f Q g C Y Q E P A M r / D m K O f F</formula><p>e X c + 5 q 0 F J 5 8 5 h D 9 w P n 8 A Q k C Q C g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " </p><formula xml:id="formula_1">E T V q K s X M M W f H 5 T n G J 4 h k R 7 z G n Z E = " &gt; A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 k V Q Y / F I n j w U N F + y H Y p 2 T T b h i b Z J c k K Z e m v</formula><formula xml:id="formula_2">O m V K 2 7 V n Q E t E y 8 n F c j R 6 J W / u v 2 Y p I J K Q z j W 2 v f c x A Q Z V o Y R T i e l b q p p g s k I D 6 h v q c S C 6 i C b H T x B J 1 b p o y h W t q R B M / X 3 R I a F 1 m M R 2 k 6 B z V A v e l P x P 8 9 P T X Q Z Z E w m q a G S z B d F K U c m R t P v U Z 8 p S g w f W 4 K J Y v Z W R I Z Y Y W J s R i U b g r f 4 8 j J p n V U 9 t + r d n V d q V 3 k c R T i C Y z g F D y 6 g B j f Q g C Y Q E P A M r / D m K O f F</formula><p>e X c + 5 q 0 F J 5 8 5 h D 9 w P n 8 A Q k C Q C g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " </p><formula xml:id="formula_3">E T V q K s X M M W f H 5 T n G J 4 h k R 7 z G n Z E = " &gt; A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 k V Q Y / F I n j w U N F + y H Y p 2 T T b h i b Z J c k K Z e m v</formula><formula xml:id="formula_4">O m V K 2 7 V n Q E t E y 8 n F c j R 6 J W / u v 2 Y p I J K Q z j W 2 v f c x A Q Z V o Y R T i e l b q p p g s k I D 6 h v q c S C 6 i C b H T x B J 1 b p o y h W t q R B M / X 3 R I a F 1 m M R 2 k 6 B z V A v e l P x P 8 9 P T X Q Z Z E w m q a G S z B d F K U c m R t P v U Z 8 p S g w f W 4 K J Y v Z W R I Z Y Y W J s R i U b g r f 4 8 j J p n V U 9 t + r d n V d q V 3 k c R T i C Y z g F D y 6 g B j f Q g C Y Q E P A M r / D m K O f F</formula><p>e X c + 5 q 0 F J 5 8 5 h D 9 w P n 8 A Q k C Q C g = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; ? EN &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; E 0 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; </p><formula xml:id="formula_5">E T V q K s X M M W f H 5 T n G J 4 h k R 7 z G n Z E = " &gt; A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 k V Q Y / F I n j w U N F + y H Y p 2 T T b h i b Z J c k K Z e m v</formula><formula xml:id="formula_6">I o 0 B g O x j f z f z 2 E y r N Y 9 k w k w T 9 i A 4 l D z m j x k q P j b 7 b L 1 f c q j s H W S V e T i q Q o 9 4 v f / U G M U s j l I Y J q n X X c x P j Z 1 Q Z z g R O S 7 1 U Y 0 L Z m A 6 x a 6 m k E W o / m 5 8 6 J W d W G Z A w V r a k I X P 1 9 0 R G I 6 0 n U W A 7 I 2 p G e t m b i f 9 5 3 d S E N 3 7 G Z Z I a l G y x K E w F M T G Z / U 0 G X C E z Y m I J Z Y r b W w k b U U W Z s e m U b A j e 8 s u r p H V R 9 S 6 r 7 s N V p X a b x 1 G E E z i F c / D g G m p w D 3 V o A o M h P M M r v D n C e X H</formula><p>e n Y 9 F a 8 H J Z 4 7 h D 5 z P H 9 P v j X 0 = &lt; / l a t e x i t &gt; T1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>T [SEP ]</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; TN &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; ? ?</p><p>[CLS] T ok1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[SEP ]</head><p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; ? T okN &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; T ok 0 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt;</p><formula xml:id="formula_7">? Question + clues[x,G] Paragraph[x]</formula><p>Hop span</p><p>x &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " T 8 1 e 0 F N 4 e i L N 0 l 7 c s i e D R U g h 6 J c = "   in nature since the only operation referred to all paragraphs is to access some specific paragraphs by their title indexes. For multi-hop questions, traditional retrieval-extraction frameworks might sacrifice the potential of follow-up models, because paragraphs multiple hops away from the question could share few common words and little semantic relation with the question, leading to a failed retrieval. However, these paragraphs can be discovered by iteratively expanding with clues in our framework. Algorithm 1 describes the procedure of our framework CogQA. After initialization, an iterative process for graph expansion and reasoning begins. In each step we visit a frontier node x, and System 1 reads para[x] under the guidance of clues and the question Q, extracts spans and generates semantic vector sem[x, Q, clues]. Meanwhile, System 2 updates hidden representation X and prepares clues[y, G] for any successor node y. The final prediction is made based on X.</p><formula xml:id="formula_8">&gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K o k K e i x 6 8 d i C / Y A 2 l M 1 2 0 q 7 d b M L u R i y h v 8 C L B 0 W 8 + p O 8 + W / c t j l o 6 4 O B x 3 s z z M w L E s G 1 c d 1 v Z 2 V 1 b X 1 j s 7 B V 3 N 7 Z 3 d s v H R w 2 d Z w q h g 0 W i 1 i 1 A 6 p R c I k N w 4 3 A d q K Q R o H A V j C 6 n f q t R 1 S a x / L e j B P 0 I z q Q P O S M G i v V n 3 q l s l t x Z y D L x M t J G X L U e q W v b j 9 m a Y T S M E G 1 7 n h u Y v y M K s O Z w E m x m 2 p M K B v R A X Y s l T R C 7 W e z Q y f k 1 C p 9 E s b K l j R k p v 6 e y G i k 9 T g K b G d E z V A v e l P x P 6 + T m v D a z 7 h M U o O S z R e F q S A m J t O v S Z 8 r Z E a M L a F M c X s r Y U O q K D M 2 m 6 I N w V t 8 e Z k 0 z y v e R c W t X 5 a r N 3 k c B T i G E z g D D 6 6 g C n d Q g w Y w Q H i G V 3 h</formula><formula xml:id="formula_9">4 t K G H b U V s W n U G C M X Z 0 = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 B I v g q S R V 0 G P R i 8 c K t h b a U D b b S b t 2 s x t 2 N 4 U S + h + 8 e F D E q / / H m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 M O F M G 8 / 7 d g p r 6 x u b W 8 X t 0 s 7 u 3 v 5 B + f C o p W W q K D a p 5 F K 1 Q 6 K R M 4 F N w w z H d q K Q x C H H x 3 B 0 O / M f x 6 g 0 k + L B T B I M Y j I Q L G K U G C u 1 G g r H v V q v X P G q 3 h z u K v F z U o E c j V 7 5 q 9 u X N I 1 R G M q J 1 h 3 f S 0 y Q E W U Y 5 T g t d V O N C a E j M s C O p Y L E q I N</formula><formula xml:id="formula_10">Z I x C P V D b C m n E n a M s x w 2 o 0 V x S L g t B N M 7 j K / 8 0 S V Z p F s m m l M f Y F H k o W M Y J N J z c H j + a B c c a v u H G i V e D m p Q I 7 G o P z V H 0 Y k E V Q a w r H W P c + N j Z 9 i Z R j h d F b q J 5 r G m E z w i P Y s l V h Q 7 a f z W 2 f o z C p D F E b K l j R o</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Implementation</head><p>The main part to implement the CogQA framework is to determine the concrete models of System 1 and 2, and the form of clues.</p><p>Our implementation uses BERT as System 1 and GNN as System 2. Meanwhile, clues <ref type="bibr">[x, G]</ref> are sentences in paragraphs of x's predecessor nodes, from which x is extracted. We directly pass raw sentences as clues, rather than any form of computed hidden states, for easy training of System 1. Because raw sentences are self-contained and independent of computations from previous iterative steps, training at different iterative steps is then decoupled, leading to efficiency gains during training. Details are introduced in ? 3.4. Hidden representations X for graph nodes are updated each time by a propagation step of GNN.</p><p>Our overall model is illustrated in <ref type="figure">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System 1</head><p>The extraction capacity of System 1 model is fundamental to construct the cognitive graph, thus a powerful model is needed. Recently, BERT <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref> has become one of the most successful language representation models on various NLP tasks, including SQuAD <ref type="bibr" target="#b20">(Rajpurkar et al., 2016)</ref>. BERT consists of multiple layers of Transformer <ref type="bibr" target="#b27">(Vaswani et al., 2017)</ref>, a self-attention based architecture, and is elaborately pre-trained on large corpora. Input sentences are composed of two different functional parts A and B.</p><p>We use BERT as System 1, and its input when visiting the node x is as follows:</p><formula xml:id="formula_11">[CLS] Question [SEP ] clues[x, G] [SEP ] Sentence A P ara[x] Sentence B</formula><p>where clues[x, G] are sentences passed from predecessor nodes. The output vectors of BERT are denoted as T ? R L?H , where L is the length of the input sequence and H is the dimension size of the hidden representations.</p><p>It is worth noting that for answer node x, P ara[x] is probably missing. Thus we do not extract spans but can still calculate sem[x, Q, clues] based on "Sentence A" part. And when extracting 1-hop nodes from question to initialize G, we do not calculate semantic vectors and only the Question part exists in the input.</p><p>Span Extraction Answers and next-hop entities have different properties. Answer extraction relies heavily on the character indicated by the question. For example "New York City" is more possible to be the answer of a where question than "2019", while next-hop entities are often the entities whose description matches statements in the question. Therefore, we predict answer spans and next-hop spans separately.</p><p>We introduce "pointer vectors" S hop , E hop , S ans , E ans as additional learnable parameters to predict targeted spans. The probability of the i th input token to be the start of an answer span P start ans [i] is calculated as follows:</p><formula xml:id="formula_12">P start ans [i] = e Sans?T i j e Sans?T j<label>(1)</label></formula><p>Let P end ans [i] be the probability of the i th input token to be the end of an answer span, which can be calculated following the same formula. We only focus on the positions with top K start probabilities {start k }. For each k, the end position end k is given by:</p><formula xml:id="formula_13">end k = arg max start k ?j?start k +maxL P end ans [j] (2)</formula><p>where maxL is the maximum possible length of spans.</p><p>To identify irrelevant paragraphs, we leverage negative sampling introduced in ? 3.4.1 to train System 1 to generate a negative threshold. In top K spans, those whose start probability is less than the negative threshold will be discarded. Because the 0 th token [CLS] is pre-trained to synthesize all input tokens for the Next Sentence Prediction task <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref>, P start ans [0] acts as the threshold in our implementation.</p><p>We expand the cognitive graph with remaining predicted answer spans as new "answer nodes". The same process is followed to expand "next-hop nodes" by replacing S ans , E ans with S hop , E hop .</p><p>Semantics Generation As mentioned above, outputs of BERT at position 0 have the ability to summarize the sequence. Thus the most straightforward method is to use T 0 as sem[x, Q, clues]. However, the last few layers in BERT are mainly in charge of transforming hidden representations for span predictions. In our experiment, the usage of the third-to-last layer output at position 0 as sem[x, Q, clues] performs the best.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">System 2</head><p>The first function of System 2 is to prepare clues[x, G] for frontier nodes, which we implement it as collecting the raw sentences of x's predecessor nodes that mention x.</p><p>The second function, to update hidden representations X, is the core function of System 2. Hidden representations X ? R n?H stand for the understandings of all n entities in G. To fully understand the relation between an entity x and the question Q, barely analyzing semantics sem[x, Q, clues] is insufficient. GNN has been proposed to perform deep learning on graph (Kipf and Welling, 2017), especially relational reasoning owing to the inductive bias of graph structure <ref type="bibr" target="#b1">(Battaglia et al., 2018)</ref>.</p><p>In our implementation, a variant of GNN is designed to serve as System 2. For each node x, the initial hidden representation X[x] ? R H is the semantic vector sem[x, Q, clues] from System 1. Let X be the new hidden representations after a propagation step of GNN, and ? ? R n?H be aggregated vectors passed from neighbours in the propagation. The updating formulas of X are as follows:</p><formula xml:id="formula_14">? = ?((AD ?1 ) T ?(XW 1 )) (3) X = ?(XW 2 + ?)<label>(4)</label></formula><p>where ? is the activation function and W 1 , W 2 ? R H?H are weight matrices. A is the adjacent matrix of G, which is column-normalized to AD ?1 where D jj = i A ij . Transformed hidden vector ?(XW 1 ) is left multiplied by (AD ?1 ) T , which can be explained as a localized spectral filter by <ref type="bibr" target="#b5">Defferrard et al. (2016)</ref>.</p><p>In the iterative step of visiting frontier node x, its hidden representation X[x] is updated following Equation <ref type="formula" target="#formula_14">(3)(4)</ref>. In experiments, we observe that this "asynchronous updating" shows no apparent difference in performance with updating X of all the nodes together by multiple steps after G is finalized, which is more efficient and adopted in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Predictor</head><p>The questions in HotpotQA dataset generally fall into three categories: special question, alternative question and general question, which are treated as three different downstream prediction tasks taking X as input. In the test set, they can also be easily categorized according to interrogative words.</p><p>Special question is the most common case, requesting to find spans such as locations, dates or entity names in paragraphs. We use a two-layer fully connected network (FCN) to serve as predictor F:</p><formula xml:id="formula_15">answer = arg max answer node x F(X[x])<label>(5)</label></formula><p>Alternative and general question both aims to compare a certain property of entity x and y in HotpotQA, respectively answered with entity name and "yes or no". These questions are regarded as binary classification with input X[x] ? X[y] and solved by another two identical FCNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Training</head><p>Our model is trained under a supervised paradigm with negative sampling. In the training set, the next-hop and answer spans are pre-extracted in paragraphs. More exactly, for each para[x] relevant to question Q, we have spans data D[x, Q] = {(y1, start1, end1), ..., (yn, startn, endn)} where the span from start i to end i in para[x] is fuzzy matched with the name of an entity or answer y i . See ? 4.1 for detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Task #1: Span Extraction</head><p>The ground truths of P start ans , P end ans , P start hop , P end hop are constructed based on D[x, Q]. There is at most one answer span (y, start, end) in every paragraph, thus gt start ans is an one-hot vector where gt start ans [start] = 1. However, multiple different next-hop spans might appear in one paragraph, so that gt start hop [start i ] = 1/k where k is the number of next-hop spans.</p><p>For the sake of the ability to discriminate irrelevant paragraphs, irrelevant negative hop nodes are added to G in advance. As mentioned in ? 3.1, the output of [CLS], T 0 , is in charge of generating negative threshold. Therefore, P start ans for each negative hop node is the one-hot vector where gt start ans [0] = 1. Cross entropy loss is used to train the span extraction task in System 1. The losses for the end position and for the next-hop spans are defined in the same way as follows.</p><formula xml:id="formula_16">L start ans = ? i gt start ans [i] ? log P start ans [i]<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Task #2: Answer Node Prediction</head><p>To command the reasoning ability, our model must learn to identify the correct answer node from a cognitive graph. For each question in the training set, we construct a training sample for this task. Each training sample is a composition of the goldonly graph, which is the union of all correct reasoning paths, and negative nodes. Negative nodes include negative hop nodes used in Task #1 and two negative answer nodes. A negative answer node is constructed from a span extracted at random from a randomly chosen hop node. For special question, we first compute the final answer probabilities for each node by performing softmax on the outputs of F. Loss L is defined as cross entropy between the probabilities and onehot vector of answer node ans.</p><formula xml:id="formula_17">L = ? log softmax F(X) [ans]<label>(7)</label></formula><p>Alternative and general questions are optimized by binary cross entropy in similar ways. The losses of this task not only are back-propagated to optimize predictors and System 2, but also fine-tune System 1 through semantic vectors sem[x, Q, clues].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset</head><p>We use the full-wiki setting of HotpotQA to conduct our experiments. 112,779 questions are collected by crowdsourcing based on the first paragraphs in Wikipedia documents, 84% of which require multi-hop reasoning. The data are split into a training set (90,564 questions), a development set (7,405 questions) and a test set (7,405 questions). All questions in development and test sets are hard multi-hop cases.</p><p>In the training set, for each question, an answer and paragraphs of 2 gold (useful) entities are provided, with multiple supporting facts, sentences containing key information for reasoning, marked out. There are also 8 unhelpful negative paragraphs for training. During evaluation, only questions are offered and meanwhile supporting facts are required besides the answer.</p><p>To construct cognitive graphs for training, edges in gold-only cognitive graphs are inferred from supporting facts by fuzzy matching based on Levenshtein distance <ref type="bibr" target="#b19">(Navarro, 2001)</ref>. For each supporting fact in para <ref type="bibr">[x]</ref>, if any gold entity or the answer, denoted as y, is fuzzy matched with a span in the supporting fact, edge (x, y) is added.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Details</head><p>We use pre-trained BERT-base model released by <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref> in System 1. The hidden size H is 768, unchanged in node vectors of GNN and predictors. All the activation functions in our model are gelu <ref type="bibr" target="#b10">(Hendrycks and Gimpel, 2016</ref> BERT and GNN are optimized by two different Adam optimizers, where ? 1 = 0.9, ? 2 = 0.999. The predictors share the same optimizer as GNN. The learning rate for parameters in BERT warmup over the first 10% steps, and then linearly decays to zero.</p><p>To select out supporting facts, we just regard the sentences in the clues of any node in graph as supporting facts. In the initialization of G, these 1-hop spans exist in the question and can also be detected by fuzzy matching with supporting facts in training set. The extracted 1-hop entities by our framework can improve the retrieval phase of other models (See ? 4.3), which motivated us to separate out the extraction of 1-hop entities to another BERT-base model for the purpose of reuse in implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>The first category is previous work or competitor:</p><p>? <ref type="bibr" target="#b34">Yang et al. (2018)</ref> The strong baseline model proposed in the original HotpotQA paper <ref type="bibr" target="#b34">(Yang et al., 2018)</ref>. It follows the retrieval-extraction framework of DrQA (2017) and subsumes the advanced techniques in QA, such as self-attention, character-level model, bi-attention.</p><p>? GRN, QFE, DecompRC, MultiQA The other models on the leaderboard. 3 ? BERT State-of-art model on single-hop QA. BERT in original paper requires singleparagraph input and pre-trained BERT can barely handle paragraphs of at most 512 tokens, much fewer than the average length of concatenated paragraphs. We add relevant sentences from predecessor nodes in the cognitive graph to every paragraphs and report the answer span with maximum start probability in all paragraphs. <ref type="bibr" target="#b34">? Yang et al. (2018</ref><ref type="bibr">)-IR Yang et al. (2018</ref> with Improved Retrieval. <ref type="bibr" target="#b34">Yang et al. (2018)</ref> uses traditional inverted index filtering strategy to retrieve relevant paragraphs. The effectiveness might be challenged due to its failures to find out entities mentioned in question sometimes. The main reason is that word-level matching in retrieval usually neglect language models, which indicates importance and POS of words. We improve the retrieval by adding 1-hop entities spotted in the question by our model, increasing the coverage of supporting facts from 56% to 72%. Another category is for ablation study:</p><p>? CogQA-onlyR model initializes G with the same entities retrieved in <ref type="bibr" target="#b34">Yang et al. (2018)</ref> as <ref type="formula" target="#formula_12">1</ref>  Overall Performance Our CogQA outperforms all baselines on all metrics by a significant margin (See <ref type="table" target="#tab_3">Table 1</ref>). The leap of performance mainly results from the superiority of the CogQA framework over traditional retrieval-extraction methods.</p><p>Since paragraphs that are multi-hop away may share few common words literally or even little semantic relation with the question, retrievalextraction framework fails to find the paragraphs that become related only after the reasoning clues connected to them are found. Our framework, however, gradually discovers relevant entities following clues.</p><p>Logical Rigor QA systems are often criticized to answer questions with shallow pattern matching, not based on reasoning. To evaluate logical rigor of QA, we use JointEM AnsEM , the proportion of "joint correct answers" in correct answers. The joint correct answers are those deduced from all necessary and correct supporting facts. Thus, this proportion stands for logical rigor of reasoning. The proportion of our method is up to 33.4%, far outnumbering 7.9% of <ref type="bibr" target="#b34">Yang et al. (2018)</ref>   Multi-hop Reasoning <ref type="figure" target="#fig_9">Figure 3</ref> illustrates joint F 1 scores and average hops of 8 types of questions, including general, alternative and special questions with different interrogative word. As the hop number increases, the performance of <ref type="bibr" target="#b34">Yang et al. (2018)</ref> and <ref type="bibr" target="#b34">Yang et al. (2018)</ref>-IR drops dramatically, while our approach is surprisingly robust. However, there is no improvement in alternative and general questions, because the evidence for judgment cannot be inferred from supporting facts, leading to lack of supervision. Further human labeling is needed to answer these questions.</p><p>Ablation Studies To study the impacts of initial entities in cognitive graphs, CogQA-onlyR begins with the same initial paragraphs as <ref type="bibr" target="#b34">(Yang et al., 2018)</ref>. We find that CogQA-onlyR still performs significantly better. The performance decreases slightly compared to CogQA, indicating that the contribution mainly comes from the framework. To compare against the retrieval-extraction framework, CogQA-onlyQ is designed that it only starts with the entities that appear in the question. Free of elaborate retrieval methods, this setting can be regarded as a natural thinking pattern of human being, in which only explicit and reliable relations are needed in reasoning. CogQA-onlyQ still outperforms all the baselines, which may reveal the superiority of CogQA framework over the retrieval-extraction framework.</p><p>BERT is not the key factor of improvement, although plays a necessary role. Vanilla BERT performs similar or even slightly poorer to <ref type="bibr" target="#b34">(Yang et al., 2018)</ref> in this multi-hop QA task, possibly because of the pertinently designed architectures in <ref type="bibr" target="#b34">Yang et al. (2018)</ref> to better leverage supervision of supporting facts.</p><p>To investigate the impacts of the absence of System 2, we design a System 1 only approach, CogQA-sys1, which inherits the iterative framework but outputs answer spans with maximum predicted probability. On Ans metrics, the improvement over the best competitor decreases about 50%, highlighting the reasoning capacity of GNN on cognitive graphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case Study</head><p>We show how the cognitive graph clearly explains complex reasoning processes in our experiments in <ref type="figure" target="#fig_10">Figure 4</ref>. The cognitive graph highlights the heart of the question in case (1)i.e., to choose between the number of members in two houses. CogQA makes the right choice based on semantic similarity between "Senate" and "upper house". Case (2) illustrates that the robustness of the answer can be boosted by exploring parallel reasoning paths. Case (3) is a semantic retrieval question without any entity mentioned, which is intractable for CogQA-onlyQ or even human. Once combined with information retrieval, our model finally gets the answer "Marijus Adomaitis" while the annotated ground truth is "Ten Walls". However, when backtracking the reasoning process in cognitive graph, we find that the model has already reached "Ten Walls" and answers with his real name, which is acceptable and even more accurate. Such explainable advantages are not enjoyed by black-box models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related work</head><p>Machine Reading Comprehension The research focus of machine reading comprehension (MRC) has been gradually transferred from cloze-style tasks <ref type="bibr" target="#b11">(Hermann et al., 2015;</ref><ref type="bibr" target="#b12">Hill et al., 2015)</ref> to more complex QA tasks <ref type="bibr" target="#b20">(Rajpurkar et al., 2016)</ref> recent years. Compared to the traditional compu-tational linguistic pipeline <ref type="bibr" target="#b11">(Hermann et al., 2015)</ref>, neural network models, for example BiDAF <ref type="bibr" target="#b21">(Seo et al., 2017a)</ref> and R-net <ref type="bibr" target="#b31">(Wang et al., 2017)</ref>, exhibit outstanding capacity for answer extraction in text. Pre-trained on large corpra, recent BERTbased models nearly settle down the single paragraph MRC-QA problem with performances beyond human-level, driving researchers to pay more attention to multi-hop reasoning.</p><p>Multi-Hop QA Pioneering datasets of multi-hop QA are either based on limited knowledge base schemas <ref type="bibr" target="#b25">(Talmor and Berant, 2018)</ref>, or under multiple choices setting <ref type="bibr" target="#b33">(Welbl et al., 2018)</ref>. The noise in these datasets also restricted the development of multi-hop QA until high-quality Hot-potQA <ref type="bibr" target="#b34">(Yang et al., 2018)</ref> is released recently. The idea of "multi-step reasoning" also breeds multi-turn methods in single paragraph QA <ref type="bibr" target="#b17">(Kumar et al., 2016;</ref><ref type="bibr" target="#b22">Seo et al., 2017b;</ref><ref type="bibr" target="#b23">Shen et al., 2017)</ref>, assuming that models can capture information at deeper level implicitly by reading the text again.</p><p>Open-Domain QA Open-Domain QA (QA at scale) refers to the setting where the search space of the supporting evidence is extremely large. Approaches to get paragraph-level answers has been thoroughly investigated by the information retrieval community, which can be dated back to the 1990s <ref type="bibr" target="#b2">(Belkin, 1993;</ref><ref type="bibr" target="#b28">Voorhees et al., 1999;</ref><ref type="bibr" target="#b18">Moldovan et al., 2000)</ref>. Recently, DrQA ) leverages a neural model to extract the accurate answer from retrieved paragraphs, usually called retrieval-extraction framework, greatly advancing this time-honored research topic again. Improvements are made to enhance retrieval by heuristic sampling <ref type="bibr" target="#b4">(Clark and Gardner, 2018)</ref> or reinforcement learning <ref type="bibr" target="#b13">(Hu et al., 2018;</ref><ref type="bibr" target="#b29">Wang et al., 2018a)</ref>, while for complex reasoning, necessary revisits to the framework are neglected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and Conclusion</head><p>We present a new framework CogQA to tackle multi-hop machine reading problem at scale. The reasoning process is organized as cognitive graph, reaching unprecedented entity-level explainability. Our implementation based on BERT and GNN obtains state-of-art results on HotpotQA dataset, which shows the efficacy of our framework.</p><p>Multiple future research directions may be envisioned. Benefiting from the explicit structure in the cognitive graph, System 2 in CogQA has potential to leverage neural logic techniques to improve reliability. Moreover, we expect that prospective architectures combining attention and recurrent mechanisms will largely improve the capacity of System 1 by optimizing the interaction between systems. Finally, we believe that our framework can generalize to other cognitive tasks, such as conversational AI and sequential recommendation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Ques &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 1 E W x M O F j D R T 3 7 b R b 7 Z l g c Y D i w 9 o = " &gt; A A A B 6 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l U 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b p Z h N 2 N 0 I J / Q t e P C j i 1 T / k z X / j p s 1 B q w 8 G H u / N M D M v S A T X x n W / n N L a + s b m V n m 7 s r O 7 t 3 9 Q P T z q 6 D h V D N s s F r H q B V S j 4 B L b h h u B v U Q h j Q K B 3 W B 6 l / v d R 1 S a x / L B z B L 0 I z q W P O S M m l x q p a i H 1 Z p b d x c g f 4 l X k B o U a A 6 r n 4 N R z N I I p W G C a t 3 3 3 M T 4 G V W G M 4 H z y i D V m F A 2 p W P s W y p p h N r P F r f O y Z l V R i S M l S 1 p y E L 9 O Z H R S O t Z F N j O i J q J X v V y 8 T + v n 5 r w x s + 4 T F K D k i 0 X h a k g J i b 5 4 2 T E F T I j Z p Z Q p r i 9 l b A J V Z Q Z G 0 / F h u C t v v y X d C 7 q 3 m X d b V 3 V G r d F H G U 4 g V M 4 B w + u o Q H 3 0 I Q 2 M J j A E 7 z A q x M 5 z 8 6 b 8 7 5 s L T n F z D H 8 g v P x D R W c j k I = &lt; / l a t e x i t &gt; System 1 (BERT) E [CLS] &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E T V q K s X M M W f H 5 T n G J 4 h k R 7 z G n Z E = " &gt; A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B U 9 k V Q Y / F I n j w U N F + y H Y p 2 T T b h i b Z J c k K Z e m v 8 O J B E a / + H G / + G 9 N 2 D 9 r 6 Y O D x 3 g w z 8 8 K E M 2 1 c 9 9 s p r K y u r W 8 U N 0 t b 2 z u 7 e + X 9 g 5 a O U 0 V o k 8 Q 8 V p 0 Q a 8 q Z p E 3 D D K e d R F E s Q k 7 b 4 a g + 9 d t P V G k W y w c z T m g g 8 E C y i B F s r P R 4 3 c v 8 + u 1 9 M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>8 O J B E a / + H G / + G 9 N 2 D 9 r 6 Y O D x 3 g w z 8 8 K E M 2 1 c 9 9 s p r K y u r W 8 U N 0 t b 2 z u 7 e + X 9 g 5 a O U 0 V o k 8 Q 8 V p 0 Q a 8 q Z p E 3 D D K e d R F E s Q k 7 b 4 a g + 9 d t P V G k W y w c z T m g g 8 E C y i B F s r P R 4 3 c v 8 + u 1 9 M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>8 O J B E a / + H G / + G 9 N 2 D 9 r 6 Y O D x 3 g w z 8 8 K E M 2 1 c 9 9 s p r K y u r W 8 U N 0 t b 2 z u 7 e + X 9 g 5 a O U 0 V o k 8 Q 8 V p 0 Q a 8 q Z p E 3 D D K e d R F E s Q k 7 b 4 a g + 9 d t P V G k W y w c z T m g g 8 E C y i B F s r P R 4 3 c v 8 + u 1 9 M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>8 O J B E a / + H G / + G 9 N 2 D 9 r 6 Y O D x 3 g w z 8 8 K E M 2 1 c 9 9 s p r K y u r W 8 U N 0 t b 2 z u 7 e + X 9 g 5 a O U 0 V o k 8 Q 8 V p 0 Q a 8 q Z p E 3 D D K e d R F E s Q k 7 b 4 a g + 9 d t P V G k W y w c z T m g g 8 E C y i B F s r P R 4 3 c v 8 + u 1 9 M O m V K 2 7 V n Q E t E y 8 n F c j R 6 J W / u v 2 Y p I J K Q z j W 2 v f c x A Q Z V o Y R T i e l b q p p g s k I D 6 h v q c S C 6i C b H T x B J 1 b p o y h W t q R B M / X 3 R I a F 1 m M R 2 k 6 B z V A v e l P x P 8 9 P T X Q Z Z E w m q a G S z B d F K U c m R t P v U Z 8 p S g w f W 4 K J Y v Z W R I Z Y Y W J s R i U b g r f 4 8 j J p n V U 9 t + r d n V d q V 3 k c R T i C Y z g F D y 6 g B j f Q g C Y Q E P A M r / D m K O f F e Xc + 5 q 0 F J 5 8 5 h D 9 w P n 8 A Q k C Q C g = = &lt; / l a t e x i t &gt; E1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B i 3 4 J 8 S Y W q 1 K L t B c T 2 Q B N y I g A I M = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q M e i C B 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T o Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M b 2 Z + + 4 l r I 2 L 1 i J O E + x E d K h E K R t F K D 7 d 9 r 1 + u u F V 3 D r J K v J x U I E e j X / 7 q D W K W R l w h k 9 S Y r u c m 6 G d U o 2 C S T 0 u 9 1 P C E s j E d 8 q 6 l i k b c + N n 8 1 C k 5 s 8 q A h L G 2 p Z D M 1 d 8 T G Y 2 M m U S B 7 Y w o j s y y N x P / 8 7 o p h l d + J l S S I l d s s S h M J c G Y z P 4 m A 6 E 5 Q z m x h D I t 7 K 2 E j a i m D G 0 6 J R u C t / z y K m l d V D 2 3 6 t 1 f V u r X e R x F O I F T O A c P a l C H O 2 h A E x g M 4 R l e 4 c 2 R z o v z 7 n w s W g t O P n M M f + B 8 / g C 9 7 4 1 t &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B i 3 4 J 8 S Y W q 1 K L t B c T 2 Q B N y I g A I M = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q M e i C B 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T o Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M b 2 Z + + 4 l r I 2 L 1 i J O E + x E d K h E K R t F K D 7 d 9 r 1 + u u F V 3 D r J K v J x U I E e j X / 7 q D W K W R l w h k 9 S Y r u c m 6 G d U o 2 C S T 0 u 9 1 P C E s j E d 8 q 6 l i k b c + N n 8 1 C k 5 s 8 q A h L G 2 p Z D M 1 d 8 T G Y 2 M m U S B 7 Y w o j s y y N x P / 8 7 o p h l d + J l S S I l d s s S h M J c G Y z P 4 m A 6 E 5 Q z m x h D I t 7 K 2 E j a i m D G 0 6 J R u C t / z y K m l d V D 2 3 6 t 1 f V u r X e R x F O I F T O A c P a l C H O 2 h A E x g M 4 R l e 4 c 2 R z o v z 7 n w s W g t O P n M M f + B 8 / g C 9 7 4 1 t &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B i 3 4 J 8 S Y W q 1 K L t B c T 2 Q B N y I g A I M = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q M e i C B 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T o Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M b 2 Z + + 4 l r I 2 L 1 i J O E + x E d K h E K R t F K D 7 d 9 r 1 + u u F V 3 D r J K v J x U I E e j X / 7 q D W K W R l w h k 9 S Y r u c m 6 G d U o 2 C S T 0 u 9 1 P C E s j E d 8 q 6 l i k b c + N n 8 1 C k 5 s 8 q A h L G 2 p Z D M 1 d 8 T G Y 2 M m U S B 7 Y w o j s y y N x P / 8 7 o p h l d + J l S S I l d s s S h M J c G Y z P 4 m A 6 E 5 Q z m x h D I t 7 K 2 E j a i m D G 0 6 J R u C t / z y K m l d V D 2 3 6 t 1 f V u r X e R x F O I F T O A c P a l C H O 2 h A E x g M 4 R l e 4 c 2 R z o v z 7 n w s W g t O P n M M f + B 8 / g C 9 7 4 1 t &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " B i 3 4 J 8 S Y W q 1 K L t B c T 2 Q B N y I g A I M = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q M e i C B 4 r 2 g 9 o Q 9 l s N + 3 S z S b s T o Q S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 I J H C o O t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U M n G q G W + y W M a 6 E 1 D D p V C 8 i Q I l 7 y S a 0 y i Q v B 2 M b 2 Z + + 4 l r I 2 L 1 i J O E + x E d K h E K R t F K D 7 d 9 r 1 + u u F V 3 D r J K v J x U I E e j X / 7 q D W K W R l w h k 9 S Y r u c m 6 G d U o 2 C S T 0 u 9 1 P C E s j E d 8 q 6 l i k b c + N n 8 1 C k 5 s 8 q A h L G 2 p Z D M 1 d 8 T G Y 2 M m U S B 7 Y w o j s y y N x P / 8 7 o p h l d + J l S S I l d s s S h M J c G Y z P 4 m A 6 E 5 Q z m x h D I t 7 K 2 E j a i m D G 0 6 J R u C t / z y K m l d V D 2 3 6 t 1 f V u r X e R x F O I F T O A c P a l C H O 2 h A E x g M 4 R l e 4 c 2 R z o v z 7 n w s W g t O P n M M f + B 8 / g C 9 7 4 1 t &lt; / l a t e x i t &gt; E [SEP ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>T0&lt;</head><label></label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " X 9 3 J Y N B 4 G t 2 W C A 5 0 t Q L V i 2 9 7 O S U = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l U 0 G P R i 8 e K / Y I 2 l M 1 2 0 i 7 d b M L u R i i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E s G 1 c d 1 v p 7 C 2 v r G 5 V d w u 7 e z u 7 R + U D 4 9 a O k 4 V w y a L R a w 6 A d U o u M S m 4 U Z g J 1 F</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " y c a g f I h P A c q 9 S u B 1 / H I t S l u E l d 4 = " &gt; A A A B 6 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b R U 0 l U 0 G P R i 8 c K / Y I 2 l M 1 2 0 y 7 d 3 Y T d j V B C / 4 I X D 4 p 4 9 Q 9 5 8 9 + 4 S X P Q 1 g c D j / d m m J k X x J x p 4 7 r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 5 1 d J Q o Q t s k 4 p H q B V h T z i R t G 2 Y 4 7 c W K Y h F w 2 g 2 m 9 5 n f f a J K s 0 i 2 z C y m v s B j y U J G s M m k 1 p C d D 6 s 1 t + 7 m Q K v E K 0 g N C j S H 1 a / B K C K J o N I Q j r X u e 2 5 s / B Q r w w i n 8 8 o g 0 T T G Z I r H t G + p x I J q P 8 1 v n a M z q 4 x Q G C l b 0 q B c / T 2 R Y q H 1 T A S 2 U 2 A z 0 c t e J v 7 n 9 R M T 3 v o p k 3 F i q C S L R W H C k Y l Q 9 j g a M U W J 4 T N L M F H M 3 o r I B C t M j I 2 n Y k P w l l 9 e J Z 3 L u n d V d x + v a 4 2 7 I o 4 y n M A p X I A H N 9 C A B 2 h C G w h M 4 B l e 4 c 0 R z o v z 7 n w s W k t O M X M M f + B 8 / g C L g o 3 n &lt; / l a t e x i t &gt; T 0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>z H p w X 5 9 3 5 m L e u O P n M E f y B 8 / k D 5 u O M / g = = &lt; / l a t e x i t &gt; P rev 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N H a j n 1 S 7 d</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>s f u 3 U P b N K 3 4 2 k s i W M O 1 d / T 2 Q k 1 n o S h 7 Y z J m a o l 7 2 Z + J / X S U 1 0 H W R M J K l B Q R e L o p S 7 R r q z 1 9 0 + U 0 g N n 1 h C q G L 2 V p c O i S L U 2 I B K N g R / + e V V 0 q p V / Y u q d 3 9 Z q d / k c R T h B E 7 h H H y 4 g j r c Q Q O a Q O E J n u E V 3 h z p v D j v z s e i t e D k M 8 f w B 8 7 n D z 1 R j u Y = &lt; / l a t e x i t &gt; Next &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " / 0 4 f U x 5 C b t N J G N P y U D B D Q P l o L 6 0 = " &gt; A A A B 6 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 B I v g q S Q q 6 L H o x Z N U s B / Q h r L Z T t u l u 5 u w u x F L 6 F / w 4 k E R r / 4 h b / 4 b N 2 0 O 2 v p g 4 P H e D D P z w p g z b T z v 2 y m s r K 6 t b x Q 3 S 1 v b O 7 t 7 5 f 2 D p o 4 S R b F B I x 6 p d k g 0 c i a x Y Z j h 2 I 4 V E h F y b I X j m 8 x v P a L S L J I P Z h J j I M h Q s g G j x G T S H T 6 Z X r n i V b 0 Z 3 G X i 5 6 Q C O e q 9 8 l e 3 H 9 F E o D S U E 6 0 7 v h e b I C X K M M p x W u o m G m N C x 2 S I H U s l E a i D d H b r 1 D 2 x S t 8 d R M q W N O 5 M / T 2 R E q H 1 R I S 2 U x A z 0 o t e J v 7 n d R I z u A p S J u P E o K T z R Y O E u y Z y s 8 f d P l N I D Z 9 Y Q q h i 9 l a X j o g i 1 N h 4 S j Y E f / H l Z d I 8 q / r n V e / + o l K 7 z u M o w h E c w y n 4 c A k 1 u I U 6 N I D C C J 7 h F d 4 c 4 b w 4 7 8 7 H v L X g 5 D O H 8 A f O 5 w 8 X C o 5 D &lt; / l a t e x i t &gt; Ans &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " E z J a u H C F V m w 9 r V Y L A t 7 M I e B 3 P s 8 = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l U 0 G P V i 8 e K 9 g P a U D b b S b t 0 s w m 7 G 6 G E / g Q v H h T x 6 i / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n c L K 6 t r 6 R n G z t L W 9 s 7 t X 3 j 9 o 6 j h V D B s s F r F q B 1 S j 4 B I b h h u B 7 U Q h j Q K B r W B 0 O / V b T 6 g 0 j + W j G S f o R 3 Q g e c g Z N V Z 6 u J a 6 V 6 6 4 V X c G s k y 8 n F Q g R 7 1 X / u r 2 Y 5 Z G K A 0 T V O u O 5 y b G z 6 g y n A m c l L q p x o S y E R 1 g x 1 J J I 9 R + N j t 1 Q k 6 s 0 i d h r G x J Q 2 b q 7 4 m M R l q P o 8 B 2 R t Q M 9 a I 3 F f / z O q k J r / y M y y Q 1 K N l 8 U Z g K Y m I y / Z v 0 u U J m x N g S y h S 3 t x I 2 p I o y Y 9 M p 2 R C 8 x Z e X S f O s 6 p 1 X 3 f u L S u 0 m j 6 M I R 3 A M p + D B J d T g D u r Q A A Y D e I Z X e H O E 8 + K 8 O x / z 1 o K T z x z C H z i f P z N j j b w = &lt; / l a t e x i t &gt; T 0 j &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 8 W P q C a I D G 1 8 8 D s w r 9 / 9 7 u 5 G r o t k = " &gt; A A A B 6 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b R U 9 m 1 g h 6 L X j x W 6 B e 0 S 8 m m 2 T Y 2 y S 5 J V i h L / 4 I X D 4 p 4 9 Q 9 5 8 9 + Y b f e g r Q 8 G H u / N M D M v i D n T x n W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q 6 y h R h L</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>0 MFigure 2 :</head><label>02</label><figDesc>r v 6 e S L H Q e i o C 2 y m w G e t l L x P / 8 3 q J C W / 8 l M k 4 M V S S x a I w 4 c h E K H s c D Z m i x P C p J Z g o Z m 9 F Z I w V J s b G U 7 I h e M s v r 5 L 2 Z d W r V d 2 H q 0 r 9 N o + j C C d w C h f g w T X U 4 R 4 a 0 A I C Y 3 i G V 3 h z h P P i v D s f i 9 a C k 8 8 c w x 8 4 n z + N B 4 3 o &lt; / l a t e x i t &gt; T 0 k &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 6 P s 7 j 3 D C j P 4 T d y O 7 D F 0 / y E / W Y Z Q = " &gt; A A A B 6 3 i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b R U 0 l U 0 G P R i 8 c K / Y I 2 l M 1 2 0 y 7 d 3 Y T d j V B C / 4 I X D 4 p 4 9 Q 9 5 8 9 + 4 S X P Q 1 g c D j / d m m J k X x J x p 4 7 r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 5 1 d J Q o Q t s k 4 p H q B V h T z i R t G 2 Y 4 7 c W K Y h F w 2 g 2 m 9 5 n f f a J K s 0 i 2 z C y m v s B j y U J G s M m k 1 n B 6 P q z W 3 L q b A 6 0 S r y A 1 K N A c V r 8 G o 4 g k g k p D O N a 6 7 7 m x 8 V O s D C O c z i u D R N M Y k y k e 0 7 6 l E g u q / T S / d Y 7 O r D J C Y a R s S Y N y 9 f d E i o X W M x H Y T o H N R C 9 7 m f i f 1 0 9 M e O u n T M a J o Z I s F o U J R y Z C 2 e N o x B Q l h s 8 s w U Q x e y s i E 6 w w M T a e i g 3 B W 3 5 5 l X Q u 6 9 5 V 3 X 2 8 r j X u i j j K c A K n c A E e 3 E A D H q A J b S A w g W d 4 h T d H O C / O u / O x a C 0 5 x c w x / I H z + Q O O j I 3 p &lt; / l a t e x i t &gt; T 0M &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; ? E &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n t a 3 4 g E + X G + 4 L V 5 X U q H 2 R D 7 n 1 o 0= " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 6 K o k K e i y K 4 E W o Y N p C G 8 p m u 2 m X 7 m 7 C 7 k Y o o b / B i w d F v P q D v P l v 3 L Q 5 a O u D g c d 7 M 8 z M C x P O t H H d b 2 d p e W V 1 b b 2 0 U d 7 c 2 t 7 Z r e z t N 3 W c K k J 9 E v N Y t U O s K W e S + o Y Z T t u J o l i E n L b C 0 U 3 u t 5 6 o 0 i y W j 2 a c 0 E D g g W Q R I 9 h Y y b / t 3 Z + U e 5 W q W 3 O n Q I v E K 0 g V C j R6 l a 9 u P y a p o N I Q j r X u e G 5 i g g w r w w i n k 3 I 3 1 T T B Z I Q H t G O p x I L q I J s e O 0 H H V u m j K F a 2 p E F T 9 f d E h o X W Y x H a T o H N U M 9 7 u f i f 1 0 l N d B V k T C a p o Z L M F k U p R y Z G + e e o z x Q l h o 8 t w U Q x e y s i Q 6 w w M T a f P A R v / u V F 0 j y r e e c 1 9 + G i W r 8 u 4 i j B I R z B K X h w C X W 4 g w b 4 Q I D B M 7 z C m y O d F + f d + Z i 1 L j n F z A H 8 g f P 5 A 3 8 3 j d A = &lt; / l a t e x i t &gt;T ok 0 M &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " ( n u l l ) " &gt; ( n u l l ) &lt; / l a t e x i t &gt;? | {z } &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " i 4 j o 7 G w t G w K o N 3 Y e H 1 g v l b s k D w c = " &gt; A A A C B H i c b V C 7 T s M w F H X K q 5 R X g L F L R I X E V C W l E o y V W B i L R B 9 S E 1 W O c 9 N a d Z z I d p C q K A M L v 8 L C A E K s f A Q b f 4 P T Z o C W I 1 k + O u d e X 9 / j J 4 x K Z d v f R m V j c 2 t 7 p 7 p b 2 9 s / O D w y j 0 / 6 M k 4 F g R 6 J W S y G P p b A K I e e o o r B M B G A I 5 / B w J / d F P 7 g A Y S k M b 9 X 8 w S 8 C E 8 4 D S n B S k t j s + 6 m P A D h C 0 w g c 6 c y K W 6 n Z S c q z 8 d m w 2 7 a C 1 j r x C l J A 5 X o j s 0 v N 4 h J G g F X h G E p R 4 5 + x 8 u w U J Q w y G t u K k E P m O E J j D T l O A L p Z Y s l c u t c K 4 E V x k I f r q y F + r s j w 5 G U 8 8 j X l R F W U 7 n q F e J / 3 i h V 4 b W X U Z 6 k C j h Z D g p T Z q n Y K h K x A i q A K D b X B B N B 9 V 8 t M s U 6 E K V z q + k Q n N W V 1 0 m / 1 X Q u m / Z d u 9 F p l 3 F U U R 2 d o Q v k o C v U Q b e o i 3 q I o E f 0 j F 7 R m / F k v B j v x s e y t G K U P a f o D 4 z P H y W f m F s = &lt; / l a t e x i t &gt; | {z } &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q 2 q 8 1 5 a b 4 2 R F 6 7 V F A u b 4 6 k m u 5 l k = " &gt; A A A C B H i c b V C 7 T s M w F H X K q 5 R X g L F L R I X E V C W l E o y V W B i L R B 9 S E 1 W O c 9 N a d Z z I d p C q K A M L v 8 L C A E K s f A Q b f 4 P T Z o C W I 1 k + O u d e X 9 / j J 4 x K Z d v f R m V j c 2 t 7 p 7 p b 2 9 s / O D w y j 0 / 6 M k 4 F g R 6 J W S y G P p b A K I e e o o r B M B G A I 5 / B w J / d F P 7 g A Y S k M b 9 X 8 w S 8 C E 8 4 D S n B S k t j s + 6 m P A D h C 0 w g c 6 c y K e 6 W b S c q z 8 d m w 2 7 a C 1 j rx C l J A 5 X o j s 0 v N 4 h J G g F X h G E p R 4 5 + x 8 u w U J Q w y G t u K k E P m O E J j D T l O A L p Z Y s l c u t c K 4 E V x k I f r q y F + r s j w 5 G U 8 8 j X l R F W U 7 n q F e J / 3 i h V 4 b W X U Z 6 k C j h Z D g p T Z q n Y K h K x A i q A K D b X B B N B 9 V 8 t M s U 6 E K V z q + k Q n N W V 1 0 m / 1 X Q u m / Z d u 9 F p l 3 F U U R 2 d o Q v k o C v U Q b e o i 3 q I o E f 0 j F 7 R m / F k v B j v x s e y t G K U P a f o D 4 z P H y Q X m F o = &lt; / l a t e x i t &gt; z }| { &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W k m k O Q q V 4 y / G 2 C w E G j e y + G F e k F c = " &gt; A A A C A n i c b V D L S g M x F M 3 U V 6 2 v U V f i J l g E V 2 V G i 7 o s u H F Z w T 6 g M 5 R M e q c N z W S G J C O U o b j x V 9 y 4 U M S t X + H O v z H T z k J b D 4 Q c z r n 3 J v c E C W d K O 8 6 3 V V p Z X V v f K G 9 W t r Z 3 d v f s / Y O 2 i l N J o U V j H s t u Q B R w J q C l m e b Q T S S Q K O D Q C c Y 3 u d 9 5 A K l Y L O 7 1 J A E / I k P B Q k a J N l L f P v J i Y w e S U M i 8 k U r y + 9 J J 9 H T a t 6 t O z Z k B L x O 3 I F V U o N m 3 v 7 x B T N M I h K a c K N V z z R w / I 1 I z y m F a 8 V I F Z v 6 Y D K F n q C A R K D + b r T D F p 0 Y Z 4 D C W 5 g i N Z + r v j o x E S k 2 i w F R G R I / U o p e L / 3 m 9 V I f X f s Z E k m o Q d P 5 Q m H K s Y 5 z n g Q d M A t V 8 Y g i h k p m / Y j o i J g 9 t U q u Y E N z F l Z d J + 7 z m X t S c u 3 q 1 U S / i K K N j d I L O k I u u U A P d o i Z q I Y o e 0 T N 6 R W / W k / V i v V s f 8 9 K S V f Q c o j + w P n 8 A 7 1 2 X u A = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " W k m k O Q q V 4 y / G 2 C w E G j e y + G F e k F c = " &gt; A A A C A n i c b V D L S g M x F M 3 U V 6 2 v U V f i J l g E V 2 V G i 7 o s u H F Z w T 6 g M 5 R M e q c N z W S G J C O U o b j x V 9 y 4 U M S t X + H O v z H T z k J b D 4 Q c z r n 3 J v c E C W d K O 8 6 3 V V p Z X V v f K G 9 W t r Z 3 d v f s / Y O 2 i l N J o U V j H s t u Q B R w J q C l m e b Q T S S Q K O D Q C c Y 3 u d 9 5 A K l Y L O 7 1 J A E / I k P B Q k a J N l L f P v J i Y w e S U M i 8 k U r y + 9 J J 9 H T a t 6 t O z Z k B L x O 3 I F V U o N m 3 v 7 x B T N M I h K a c K N V z z R w / I 1 I z y m F a 8 V I F Z v 6 Y D K F n q C A R K D + b r T D F p 0 Y Z 4 D C W 5 g i N Z + r v j o x E S k 2 i w F R G R I / U o p e L / 3 m 9 V I f X f s Z E k m o Q d P 5 Q m H K s Y 5 z n g Q d M A t V 8 Y g i h k p m / Y j o i J g 9 t U q u Y E N z F l Z d J + 7 z m X t S c u 3 q 1 U S / i K K N j d I L O k I u u U A P d o i Z q I Y o e 0 T N 6 R W / W k / V i v V s f 8 9 K S V f Q c o j + w P n 8 A 7 1 2 X u A = = &lt; / la t e x i t &gt; Ans span sem[x, Q, clues] P rev 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " p u K 5 8 M F B v g D 1 n t + j W d z 8 p L 4 e O O M = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l U 0 G P R i 8 c K 9 g P a U D b b S b t 2 k w 2 7 m 0 I J / Q 9 e P C j i 1 f / j z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 1 D J V D B t M C q n a A d U o e I w N w 4 3 A d q K Q R o H A V j C 6 m / m t M S r N Z f x o J g n 6 E R 3 E P O S M G i s 1 6 w r H P a 9 X r r h V d w 6 y S r y c V C B H v V f + 6 v Y l S y O M D R N U 6 4 7 n J s b P q D K c C Z y W u q n G h L I R H W D H 0 p h G q P 1 s f u 2 U n F m l T 0 K p b M W G z N X f E x m N t J 5 E g e 2 M q B n q Z W 8 m / u d 1 U h P e + B m P k 9 R g z B a L w l Q Q I 8 n s d d L n C p k R E 0 s o U 9 z e S t i Q K s q M D a h k Q / C W X 1 4 l z Y u q d 1 l 1 H 6 4 q t d s 8 j i K c w C m c g w f X U I N 7 q E M D G D z B M 7 z C m y O d F + f d + V i 0 F p x 8 5 h j + w P n 8 A T v N j u U = &lt; / l a t e x i t &gt; + &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 2 6 B D Q s R l 0 A v W j q p X x B R v c a k + k h Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S I I Q k l U 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 0 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O y u r a + s b m 4 W t 4 v b O 7 t 5 + 6 e C w q e N U M W y w W M S q H V C N g k t s G G 4 E t h O F N A o E t o L R 3 d R v P a H S P J Y P Z p y g H 9 G B 5 C F n 1 F i p f t 4 r l d 2 K O w N Z J l 5 O y p C j 1 i t 9 d f s x S y O U h g m q d c d z E + N n V B n O B E 6 K 3 V R j Q t m I D r B j q a Q R a j + b H T o h p 1 b p k z B W t q Q h M / X 3 R E Y j r c d R Y D s j a o Z 6 0 Z u K / 3 m d 1 I Q 3 f s Z l k h q U b L 4 o T A U x M Z l + T f p c I T N i b A l l i t t b C R t S R Z m x 2 R R t C N 7 i y 8 u k e V H x L i t u / a p c v c 3 j K M A x n M A Z e H A N V b i H G j S A A c I z v M K b 8 + i 8 O O / O x 7 x 1 x c l n j u A P n M 8 f c i + M s Q = = &lt; / l a t e x i t &gt; X[P rev 2 ] &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 3 4 x c t z R h X y n C 5 M R S N 2 g E d H 2 p 5 u w = " &gt; A A A B + 3 i c b V D L S s N A F L 2 p r 1 p f s S 7 d B I v g q i R V 0 G X R j c s K 9 g F p C J P p p B 0 6 m Y S Z S b G E / I o b F 4 q 4 9 U f c + T d O 2 i y 0 9 c D A 4 Z x 7 u W d O k D A q l W 1 / G 5 W N z a 3 t n e p u b W / / 4 P D I P K 7 3 Z J w K T L o 4 Z r E Y B E g S R j n p K q o Y G S S C o C h g p B 9 M 7 w q / P y N C 0 p g / q n l C v A i N O Q 0 p R k p L v l k f R k h N g j A b 5 G 5 H k J n f 8 n y z Y T f t B a x 1 4 p S k A S U 6 v v k 1 H M U 4 j Q h X m C E p X c d O l J c h o S h m J K 8 N U 0 k S h K d o T F x N O Y q I 9 L J F 9 t w 6 1 8 r I C m O h H 1 f W Q v 2 9 k a F I y n k U 6 M k i q V z 1 C v E / z 0 1 V e O N l l C e p I h w v D 4 U p s 1 R s F U V Y I y o I V m y u C c K C 6 q w W n i C B s N J 1 1 X Q J z u q X 1 0 m v 1 X Q u m / b D V a N 9 W 9 Z R h V M 4 g w t w 4 B r a c A 8 d 6 A K G J 3 i G V 3 g z c u P F e D c + l q M V o 9 w 5 g T 8 w P n 8 A / Z y U Z Q = = &lt; / l a t e x i t &gt; X[P rev 1 ] &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " T X Q J q D I e E 3 F A z t K M 5 j G 5 i p 1 F Y + c = " &gt; A A A B + 3 i c b V B N S 8 N A F H y p X 7 V + x X r 0 s l g E T y V R Q Y 9 F L x 4 r 2 F p o Q 9 h s N + 3 S z S b s b o o l 5 K 9 4 8 a C I V / + I N / + N m z Y H b R 1 Y G G b e 4 8 1 O k H C m t O N 8 W 5 W 1 9 Y 3 N r e p 2 b W d 3 b / / A P q x 3 V Z x K Q j s k 5 r H s B V h R z g T t a K Y 5 7 S W S 4 i j g 9 D G Y 3 B b + 4 5 R K x W L x o G c J 9 S I 8 E i x k B G s j + X Z 9 E G E 9 D s K s l / f b k k 5 9 1 / P t h t N 0 5 k C r x C 1 J A 0 q 0 f f t r M I x J G l G h C c d K 9 V 0 n 0 V 6 G p W a E 0 7 w 2 S B V N M J n g E e 0 b K n B E l Z f N s + f o 1 C h D F M b S P K H R X P 2 9 k e F I q V k U m M k i q V r 2 C v E / r 5 / q 8 N r L m E h S T Q V Z H A p T j n S M i i L Q k E l K N J 8 Z g o l k J i s i Y y w x 0 a a u m i n B X f 7 y K u m e N 9 2 L p n N / 2 W j d l H V U 4 R h O 4 A x c u I I W 3 E E b O k D g C Z 7 h F d 6 s 3 H q x 3 q 2 P x W j F K n e O 4 A + s z x / 8 F 5 R k &lt; / l a t e x i t &gt; y &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " c s 1 Q 9 f e t / 6 G N t c + T z w / y 6 W C T X 8 Y = " &gt; A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l U 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 0 I o / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 b u a 3 n 1 B p H s s H k y X o R 3 Q o e c g Z N V Z q Z P 1 y x a 2 6 c 5 B V 4 u W k A j n q / f J X b x C z N E J p m K B a d z 0 3 M f 6 E K s O Z w G m p l 2 p M K B v T I X Y t l T R C 7 U / m h 0 7 J m V U G J I y V L W n I X P 0 9 M a G R 1 l k U 2 M 6 I m p F e 9 m b i f 1 4 3 N e G N P + E y S Q 1 K t l g U p o K Y m M y + J g O u k B m R W U K Z 4 v Z W w k Z U U W Z s N i U b g r f 8 8 i p p X V S 9 y 6 r b u K r U b v M 4 i n A C p 3 A O H l x D D e 6 h D k 1 g g P A M r / D m P D o v z r v z s W g t O P n M M f y B 8 / k D 6 G e M / w = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " T k l O c w p A 1 D 9 + Y i e O L H I 8 7 2 S L Y N c = " &gt; A A A B 9 H i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F c l R k V d F l 0 4 7 K C f c B 0 K J k 0 0 4 Z m k j H J F M v Q 7 3 D j Q h G 3 f o w 7 / 8 Z M O w t t P R A 4 n H M v 9 + S E C W f a u O 6 3 s 7 K 6 t r 6 x W d o q b + / s 7 u 1 X D g 5 b W q a K 0 C a R X K p O i D X l T N C m Y Y b T T q I o j k N O 2 + H o N v f b Y 6 o 0 k + L B T B I a x H g g W M Q I N l Y K u j E 2 w z D K O l P / K e h V q m 7 N n Q E t E 6 8 g V S j Q 6 F W + u n 1 J 0 p g K Q z j W 2 v f c x A Q Z V o Y R T q f l b q p p g s k I D 6 h v q c A x 1 U E 2 C z 1 F p 1 b p o 0 g q + 4 R B M / X 3 R o Z j r S d x a C f z k H r R y 8 X / P D 8 1 0 X W Q M Z G k h g o y P x S l H B m J 8 g Z Q n y l K D J 9 Y g o l i N i s i Q 6 w w M b a n s i 3 B W / z y M m m d 1 7 y L m n t / W a 3 f F H W U 4 B h O 4 A w 8 u I I 6 3 E E D m k D g E Z 7 h F d 6 c s f P i v D s f 8 9 E V p 9 g 5 g j 9 w P n 8 A F q C S T A = = &lt; / l a t e x i t &gt; ( &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " G G 7 z A f y y j z E F C k q a q Z i I d 0 l V t + 4 = " &gt; A A A C H H i c b V D L S s N A F J 3 U V 6 2 v q k s 3 w S K 4 K k k r 6 L L g x m U F + 4 C m l M n k J h 0 6 m Y S Z G 6 G E f o g b f 8 W N C 0 X c u B D 8 G 6 e P R W 0 9 z M D h n H v v z D 1 + K r h G x / m x C h u b W 9 s 7 x d 3 S 3 v 7 B 4 V H 5 + K S t k 0 w x a L F E J K r r U w 2 C S 2 g h R w H d V A G N f Q E d f 3 Q 7 9 T u P o D R P 5 A O O U + j H N J I 8 5 I y i k Q b l u i c g R C 8 v e T 5 E X O Z U 8 E h C M C l 5 3 u y A D J Y 0 x a M h V g f l i l N 1 Z r D X i b s g F b J A c 1 D + 8 o K E Z T F I Z I J q 3 X O d F P s 5 V c i Z A D M 3 0 5 B S N q I R 9 A y V N A b d z 2 f L T e w L o w R 2 m C h z J d o z d b k j p 7 H W 4 9 g 3 l T H F o V 7 1 p u J / X i / D 8 K a f c 5 l m C J L N H w o z Y W N i T 5 O y A 6 6 A o R g b Q p n i 5 q 8 2 G 1 J F G Z o 8 S y Y E d 3 X l d d K u V d 1 6 1 b m / q j R q i z i K 5 I y c k 0 v i k m v S I H e k S V q E k S f y Q t 7 I u / V s v V o f 1 u e 8 t G A t e k 7 J H 1 j f v x l v o U 8 = &lt; / l a t e x i t &gt; [x] &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " I x 9 k W d 0 z R N X S I 2 2 F 6 B 6 c J w Y t c D M = " &gt; A A A B 8 H i c b V B N S 8 N A E J 3 4 W e t X 1 a O X Y B E 8 l U Q F P R b 1 4 L G C / Z A 0 l M 1 2 2 y 7 d 3 Y T d i V h C f 4 U X D 4 p 4 9 e d 4 8 9 + 4 b X P Q 1 g c D j / d m m J k X J Y I b 9 L x v Z 2 l 5 Z X V t v b B R 3 N z a 3 t k t 7 e 0 3 T J x q y u o 0 F r F u R c Q w w R W r I 0 f B W o l m R E a C N a P h 9 c R v P j J t e K z u c Z S w U J K + 4 j 1 O C V r p o X 3 D B J L g K e y U y l 7 F m 8 J d J H 5 O y p C j 1 i l 9 t b s x T S V T S A U x J v C 9 B M O M a O R U s H G x n R q W E D o k f R Z Y q o h k J s y m B 4 / d Y 6 t 0 3 V 6 s b S l 0 p + r v i Y x I Y 0 Y y s p 2 S 4 M D M e x P x P y 9 I s X c Z Z l w l K T J F Z 4 t 6 q X A x d i f f u 1 2 u G U U x s o R Q z e 2 t L h 0 Q T S j a j I o 2 B H / + 5 U X S O K 3 4 Z x X v 7 r x c v c r j K M A h H M E J + H A B V b i F G t S B g o R n e I U 3 R z s v z r v z M W t d c v K Z A / g D 5 / M H p O S Q T A = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " e R V + c F Y y U V w c n s S D a s a v M i X e v I M = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m 0 o M e i F 4 8 V 7 Q e 0 o W y 2 m 3 b p Z h N 2 J 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k E h h 0 H W / n c L a + s b m V n G 7 t L O 7 t 3 9 Q P j x q m T j V j D d Z L G P d C a j h U i j e R I G S d x L N a R R I 3 g 7 G t z O / / c S 1 E b F 6 x E n C / Y g O l Q g F o 2 i l h 3 b f 6 5 c r b t W d g 6 w S L y c V y N H o l 7 9 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 1 I v N T y h b E y H v G u p o h E 3 f j Y / d U r O r D I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 b W f C Z W k y B V b L A p T S T A m s 7 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t O y Y b g L b + 8 S l o X V e + y 6 t 7 X K v W b P I 4 i n M A p n I M H V 1 C H O 2 h A E x g M 4 R l e 4 c 2 R z o v z 7 n w s W g t O P n M M f + B 8 / g D a B Y 2 B &lt; / l a t e x i t &gt; W 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " U p 5 t O w w g S U X l w k A G w 0 d Y Y C a L o 5 4 = " &gt; A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m q o M e i F 4 8 V 7 Q e 0 o W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s t H M 0 n Q j + h Q 8 p A z a q z 0 0 O 7 X + u W K W 3 X n I K v E y 0 k F c j T 6 5 a / e I G Z p h N I w Q b X u e m 5 i / I w q w 5 n A a a m X a k w o G 9 M h d i 2 V N E L t Z / N T p + T M K g M S x s q W N G S u / p 7 I a K T 1 J A p s Z 0 T N S C 9 7 M / E / r 5 u a 8 N r P u E x S g 5 I t F o W p I C Y m s 7 / J g C t k R k w s o U x x e y t h I 6 o o M z a d k g 3 B W 3 5 5 l b R q V e + i 6 t 5 f V u o 3 e R x F O I F T O A c P r q A O d 9 C A J j A Y w j O 8 w p s j n B f n 3 f l Y t B a c f O Y Y / s D 5 / A H b i Y 2 C &lt; / l a t e x i t &gt; Overview of CogQA implementation. When visiting the node x, System 1 generates new hop and answer nodes based on the clues[x, G] discovered by System 2. It also creates the inital representation sem[x, Q, clues], based on which the GNN in System 2 updates the hidden representations X[x].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 3 :</head><label>3</label><figDesc>Model performance on 8 types of questions with different hops.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 4 :</head><label>4</label><figDesc>Case Study. Different forms of cognitive graphs in our results, i.e., Tree, Directed Acyclic Graph (DAG), Cyclic Graph. Circles are candidate answer nodes while rounded rectangles are hop nodes. Green circles are the final answers given by CogQA and check marks represent the annotated ground truth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Algorithm 1: Cognitive Graph QA Input: System 1 model S1, System 2 model S2, Question Q, Predictor F,Wiki Database W 1 Initialize cognitive graph G with entities mentioned in Q and mark them frontier nodes 2 repeat 3 pop a node x from frontier nodes 4 collect clues[x, G] from predecessor nodes of x // eg. clues can be sentences where x is mentioned 5 fetch para[x] in W if any 6 generate sem[x, Q, clues] with S1 // initial X[x] 7 if x is a hop node then 8find hop and answer spans in para[x]  with S1 X with S2 21 until there is no frontier node in G or G is large enough; 22 Return arg max</figDesc><table><row><cell>9</cell><cell>for y in hop spans do</cell></row><row><cell>10</cell><cell>if y / ? G and y ? W then</cell></row><row><cell>11</cell><cell>create a new hop node for y</cell></row><row><cell>12</cell><cell>if y ? G and edge(x, y) / ? G then</cell></row><row><cell>13</cell><cell>add edge (x, y) to G</cell></row><row><cell>14</cell><cell>mark node y as a frontier node</cell></row><row><cell>15</cell><cell>end</cell></row><row><cell>16</cell><cell>for y in answer spans do</cell></row><row><cell>18</cell><cell>end</cell></row><row><cell>19</cell><cell>end</cell></row><row><cell>20</cell><cell>update hidden representation answer node x F(X[x])</cell></row></table><note>17 add new answer node y and edge (x, y) to G</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Results on HotpotQA (fullwiki setting). The test set is not public. The maintainer of HotpotQA only offers EM and F 1 for every submission. N/A means the model cannot find supporting facts.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>and 30.3% of QFE.</figDesc><table><row><cell></cell><cell>0.6</cell><cell></cell><cell cols="2">CogQA</cell><cell></cell><cell>3.2</cell><cell>Average</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">CogQA-onlyR</cell><cell></cell><cell>hops</cell></row><row><cell></cell><cell>0.5</cell><cell></cell><cell cols="2">Yang et al. (2018) Yang et al. (2018)-IR</cell><cell></cell><cell>3.0</cell><cell>CGQA</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Average hops</cell><cell></cell></row><row><cell></cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2.8</cell><cell>CGQA-</cell></row><row><cell>Joint F1 score</cell><cell>0.3 0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2.6 2.4</cell><cell>Average hops</cell><cell>onlyR BIR Yang et al. (2018)</cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2.2</cell></row><row><cell></cell><cell>al te rn at iv e 0</cell><cell>g en er al w hi ch</cell><cell>Question type w ho w ha t</cell><cell>o th er w he re</cell><cell>w he n</cell><cell>2.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Question type</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">All these models are unpublished before this paper.4  Thus it is possible that overall F1 is lower than both precision and recall.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The work is supported by Development Program of China (2016QY01W0200), NSFC for Distinguished Young Scholar (61825602), NSFC (61836013), and a research fund supported by Alibaba. The authors would like to thank Junyang Lin, Zhilin Yang and Fei Sun for their insightful feedback, and responsible reviewers of ACL 2019 for their valuable suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Working memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Baddeley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">255</biblScope>
			<biblScope unit="issue">5044</biblScope>
			<biblScope unit="page" from="556" to="559" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><forename type="middle">B</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinicius</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Faulkner</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.01261</idno>
		<title level="m">Relational inductive biases, deep learning, and graph networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Interaction with texts: Information retrieval as information-seeking behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><forename type="middle">J</forename><surname>Belkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Retrieval</title>
		<imprint>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reading wikipedia to answer opendomain questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Simple and effective multi-paragraph reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="845" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?l</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3844" to="3852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Heuristic and analytic processes in reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="451" to="468" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">In two minds: dualprocess accounts of reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="454" to="459" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Dual-processing accounts of reasoning, judgment, and social cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>St</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Psychol</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="255" to="278" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.08415</idno>
		<title level="m">Bridging nonlinearities and stochastic regularizers with gaussian error linear units</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Teaching machines to read and comprehend</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Moritz Hermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Kocisky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lasse</forename><surname>Espeholt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Suleyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1693" to="1701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The goldilocks principle: Reading children&apos;s books with explicit memory representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02301</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Reinforced mnemonic reader for machine reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 27th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4099" to="4106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Adversarial examples for evaluating reading comprehension systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2021" to="2031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Thinking, fast and slow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Egan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<pubPlace>Farrar, Straus and Giroux New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Semisupervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Ask me anything: Dynamic memory networks for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ondruska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1378" to="1387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The structure and performance of an open-domain question answering system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanda</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Pasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roxana</forename><surname>Girju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Goodrum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasile</forename><surname>Rus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 38th annual meeting on association for computational linguistics</title>
		<meeting>the 38th annual meeting on association for computational linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="563" to="570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A guided tour to approximate string matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gonzalo</forename><surname>Navarro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM computing surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="88" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Squad: 100,000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bidirectional attention flow for machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniruddha</forename><surname>Kembhavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Query-reduction networks for question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjoon</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Reasonet: Learning to stop reading in machine comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yelong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Po-Sen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1047" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The empirical case for two systems of reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sloman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">The web as a knowledge-base for answering complex questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Talmor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Berant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="641" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The trec-8 question answering track report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trec</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="77" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">r 3 : Reinforced ranker-reader for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerry</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multigranularity hierarchical attention fusion networks for reading comprehension and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1705" to="1714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Gated self-matching networks for reading comprehension and question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baobao</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="189" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Discovering the capacity of human memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain and Mind</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="198" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Constructing datasets for multi-hop reading comprehension across documents. Transactions of the Association of Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="287" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
