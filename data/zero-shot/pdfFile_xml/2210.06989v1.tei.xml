<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Multi-Task Meta Learning: learn how to adapt to unseen tasks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richa</forename><surname>Upadhyay</surname></persName>
							<email>richa.upadhyay@ltu.se</email>
							<affiliation key="aff0">
								<orgName type="institution">Lule? University of Technology</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Prakash</surname></persName>
							<email>prakash.chandra.chhipa@ltu.se</email>
							<affiliation key="aff1">
								<orgName type="institution">Lule? University of Technology</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chhipa</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Lule? University of Technology</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Phlypo</surname></persName>
							<email>ronald.phlypo@grenoble-inp.fr</email>
							<affiliation key="aff2">
								<orgName type="laboratory">Grenoble INP, GIPSA-lab</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajkumar</forename><surname>Saini</surname></persName>
							<email>rajkumar.saini@ltu.se</email>
							<affiliation key="aff3">
								<orgName type="institution">Lule? University of Technology</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Liwicki</surname></persName>
							<email>marcus.liwicki@ltu.se</email>
							<affiliation key="aff4">
								<orgName type="institution">Lule? University of Technology</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Multi-Task Meta Learning: learn how to adapt to unseen tasks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work aims to integrate two learning paradigms Multi-Task Learning (MTL) and meta learning, to bring together the best of both worlds, i.e., simultaneous learning of multiple tasks, an element of MTL and promptly adapting to new tasks with fewer data, a quality of meta learning. We propose Multi-task Meta Learning (MTML), an approach to enhance MTL compared to single task learning by employing meta learning. The fundamental idea of this work is to train a multi-task model, such that when an unseen task is introduced, it can learn in fewer steps whilst offering a performance at least as good as conventional single task learning on the new task or inclusion within the MTL. By conducting various experiments, we demonstrate this paradigm on two datasets and four tasks: NYU-v2 and the taskonomy dataset for which we perform semantic segmentation, depth estimation, surface normal estimation, and edge detection. MTML achieves state-of-the-art results for most of the tasks, and MTL also performs reasonably well for all tasks compared to single task learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Multi-task learning (MTL) involves learning many tasks in a single, combined network architecture <ref type="bibr" target="#b6">[7]</ref>. This is in contrast to single task learning, which trains dedicated networks, one for each task. The prime argument backing MTL is that the knowledge absorbed by the network having learned one task may help to improve the performance on another task when these are trained together. However, in a multi-task setting, when there is a need to add a new task to the existing architecture, the new network has to be re-trained from scratch for the new set of tasks, leading to the loss of previously gained knowledge. On the other hand, re-using information acquired during learning of a task to quickly adapt to a new task is a feature of meta learning <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b11">12]</ref>. The paradigm of meta-learning-also referred to as learning to learn <ref type="bibr" target="#b41">[42]</ref>-gathers experience by learning several tasks (learning episodes) and utilizes the overall meta knowledge to enhance its future performances on yet unseen tasks. In meta learning, the network is trained sequentially on the multiple learning episodes (also called tasks in this context); for that reason, the multiple tasks in meta learning should not be confused with multi-task learning which trains all the tasks simultaneously. The tasks in meta learning are usually identical in nature (e.g., classification only) and very often sampled from a distribution of related tasks. Meta-learning thus learns the distribution over the tasks rather than the specific tasks themselves. The latter are considered samples from this distribution, which implies that all tasks must be of similar nature, e.g., classification or regression. . This work introduces a MTML paradigm, taking advantage from both multi-task and meta learning and constructed as follows: the episodes used for meta learning are assorted multi-task combinations, trained by employing the two-level meta optimization scheme introduced by MAML <ref type="bibr" target="#b11">[12]</ref>. Because of the MTL episodes, adding similar or distinct tasks becomes easier, and meta learning helps to adapt to new tasks in few training iterations and shows good generalization performance. The contributions of this work are:</p><p>1. a new approach for creating MTL episodes required for meta learning (training phase); 2. a robust learning mechanism called MTML enabling faster training of new tasks and better performance on all of the tasks in a MTL framework; 3. extensive comparative performance analysis of singletask, MTL, and MTML learning paradigms on two publicly available datasets.</p><p>This article is organized as follows; Section 2, discusses the related works in multi-task learning and also multi-task meta learning. Section 3, introduces MTL, meta learning and details the MTML formulation. The experimental setup, datasets, tasks, and results are given in Section 4. At last, Section 5 draws the conclusion and opens up to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>In this section we discuss some recent works in MTL, and also highlight a few works that state to bring together MTL and meta learning. Several articles dealing with MTL emphasize on the network architecture design to enhance the performance on the tasks <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b35">36]</ref>. In <ref type="bibr" target="#b43">[44]</ref>, the authors presented excellent surveys of deep multi-task architectures and compares various task balancing techniques for these tasks. One solution to overcome negative transfer in MTL is an appropriate grouping of tasks while training and few articles discuss methods that learn task clustering <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b38">39]</ref>. In <ref type="bibr" target="#b47">[48]</ref>, the authors propose to determine the task transfer relationships between 26 tasks in order to learn to group tasks for MTL. Other <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b49">49]</ref> discuss task embedding primarily for meta learning as a means to learn task relationships. The Authors of <ref type="bibr" target="#b39">[40]</ref> presented an approach that selectively determines which layers of a network to activate for a task in a multi-task setting in order to reduce the number of parameters by estimating a select-or-skip policy. A similar work <ref type="bibr" target="#b15">[16]</ref> is focused on automatically searching for an effective end to end trainable network topology for solving multiple tasks.</p><p>Many research studies present a combination of both learning paradigms for various applications. <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b25">26]</ref> apply meta learning optimization in a multi-task scenario to achieve good generalization for unseen data sets on the same tasks. In <ref type="bibr" target="#b28">[29]</ref> for efficient communication between two tasks in MTL, a gradient passing mechanism is proposed which has similar traits to gradient based meta learning. A meta learning approach is followed for sharing parameters across multiple tasks and languages in <ref type="bibr" target="#b40">[41]</ref>, the model is trained on various task-language pairs rather than training all the tasks simultaneously. In <ref type="bibr" target="#b25">[26]</ref>, the tasks of dialogue generation give a context and persona information is learned for multiple personas following meta optimization. Here the multiple learning episodes (persona information) are considered as multiple tasks. Additionally, <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b4">5]</ref> use multiple tasks for the multiple training episodes in meta learning and hence tagged their paradigm multi-task meta learning. Similarly, in <ref type="bibr" target="#b44">[45]</ref> it is theoretically and empirically proved that MTL is a computationally efficient alternative to gradient based meta learning algorithm, as for an adequately deep network, the learned predictive functions of MTL and meta learning are very similar. Another work <ref type="bibr" target="#b0">[1]</ref>, presented multi-modal meta-learning for only one clas-sification task, while used the transference metric <ref type="bibr" target="#b10">[11]</ref> of MTL to update shared parameters.</p><p>Most of the works in the literature related to MTL concentrate on making it more efficient in terms of its performance, number of parameters, generalization to unseen data, etc., by adopting new architectures, learning better task grouping, soft parameter sharing, neural architecture search, and integration with other algorithms. Adding to the list, this work puts together meta learning concept to enable the addition of an unseen task to an MTL architecture, resulting in faster training of the newly added task and better generalization to unseen data compared to single-task learning. The MTL allows the joint learning of homogeneous as well as heterogeneous tasks. The latter is currently considered a limitation of meta learning. In contrast, meta learning aids in quicker learning of an unseen task with fewer data samples, which is challenging for MTL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Formulation of Multi-task Meta Learning</head><p>Multi-task learning: a learning paradigm aiming to train multiple tasks together, thereby leveraging the information gained from one task to improve the performance on other tasks. In a multi-task setting, the shared representations help to enhance the learning capabilities of all the involved tasks compared to training them individually <ref type="bibr" target="#b31">[32]</ref>. As illustrated in <ref type="figure" target="#fig_1">Figure 1a</ref>, N non-identical-but relatedtasks are sampled from a task distribution, yielding T = {T 1 , T 2 , ..., T N }. The data set for all the tasks is represented by</p><formula xml:id="formula_0">D = {(D train i ) J i=1 , (D val i ) K i=J+1 , (D test i ) M i=K+1 }, i.e.</formula><p>, D is split into J train, K ? J validation, and M ? K test instances. A multi-task network architecture is trained using the training data (D train i ) J i=1 . The objective is to minimize the combined loss L, by optimizing the network parameters</p><formula xml:id="formula_1">? = {(? i ) N i=1 }, such that ? * = min ? N i=1 L i (? i , (D train ) i ) .<label>(1)</label></formula><p>The validation set {D val i } K i=J+1 is used for hyper-parameter tuning of the model, i.e., to assure generalization of the model to data instances not used during training. The optimal parameters ? * i are used in the inference on the unseen test data {D test i } M i=K+1 to report model performance. Meta learning: Many state-of-the-art meta learning paradigms <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b26">27]</ref> considered the multiple learning episodes in meta training as multiple tasks, and the average loss across the episodes is used for optimization. In such a few-shot learning framework (a species of meta learning), every n-way, k-shot learning episode (i.e., n classes and k data samples of each class) is sampled from a base data set using two-step episodic sampling, as shown in <ref type="figure" target="#fig_1">Figure 1b</ref>. Here classes are discrete output variables also known as labels. First, one samples the episode  classes from the class distribution, organized into source classes C s = {C s1 , C s2 , ..., C s N 1 } and target classes C t = {C t1 , C t2 , .., C t N 2 }; where N 1 and N 2 represent the number of source and target classes, respectively, and C s ? C t = ?. Second, one samples an episode (k data points) from the data set based on the classes sampled in the previous step. Consider an example of 2-way k-shot learning: each learning episode ( i.e., task) will contain the training instances of two classes, say</p><formula xml:id="formula_2">T 1 = {C s1 , C s2 }...T E M = {C s N 1 ?1 , C s N 1 },</formula><p>thereby creating E M learning episodes (tasks) for meta training. The meta learners iterate over the learning episodes intending to carry out the process of learning to learn <ref type="bibr" target="#b11">[12]</ref>. As such, the underlying model adapts well to examples from unseen classes and achieves better generalization. It employs a two-step optimization <ref type="bibr" target="#b18">[19]</ref> for all the learning episodes. First, it follows taskspecific learning by optimizing task-specific parameters {? ? } E M ?=1 given the meta parameters ? (p) of the pth iteration:</p><formula xml:id="formula_3">? (p+1) ? (? (p) ) = arg min ? L ? (?, ? (p) , (D train ) ? ) (2)</formula><p>Here, L ? represents the loss for the ? th learning episode, D train ? are the training data set. The meta parameters i.e. ? are often referred to as meta knowledge or knowledge across tasks <ref type="bibr" target="#b18">[19]</ref>. In <ref type="figure" target="#fig_1">Figure 1b</ref>, a data instance is indexed by i, and an episode is indexed by ?. The second step corresponds to multiple task learning: at this meta stage, the aim is to reduce the meta loss L meta -using the unseen validation instances (D val ) ? -by optimizing the ? given the task parameters of the (p + 1)th iteration:</p><formula xml:id="formula_4">? (p+1) (? (p+1) ) = arg min ? E M ?=1 L meta (? (p+1) ? , ?, (D val ) ? ) (3)</formula><p>Iterating forth and back between <ref type="formula">(2)</ref> and <ref type="formula">(3)</ref> would result in an optimal meta learner, i.e., ? (p) ? ? * .</p><p>During meta testing (adaptation stage) the meta knowledge ? * is used as initial parameters for learning new, unseen tasks (episodes), say,</p><formula xml:id="formula_5">T 1 = {C t1 , C t2 }......T E K = {C t N 1 ?1 , C t N 1 }.</formula><p>Therefore, the test tasks are fine-tuned on the model using meta parameters, which help achieve the best performance for the new tasks in few gradient steps. As shown in <ref type="figure" target="#fig_1">Figure 1b</ref>, all the test tasks or episodes are trained sequentially, and hence, the outputs of all the tasks are achieved consecutively in contrast to MTL <ref type="figure" target="#fig_1">(Figure 1a</ref>), which outputs all the tasks simultaneously.</p><p>Multi-task meta learning: In order to enhance performance on the tasks, to guarantee better generalization, and for the ease of adding new tasks to the already trained multi-task models, meta learning is fused with MTL. In a broad sense, in this work, the multi-task architecture is used along with the bi-level meta optimization to establish MTML. Particularly, an optimization-based meta learning approach <ref type="bibr" target="#b20">[21]</ref>, recognized as Model Agnostic Meta Learning (MAML) <ref type="bibr" target="#b11">[12]</ref> is adopted, which performs a gradient descent two-level optimization compatible with any model. As illustrated in <ref type="figure" target="#fig_1">Figure 1c</ref>, source and target tasks are sampled for a distribution of tasks, given by T s = {T s1 , T s2 , .., T s N 1 } and T t = {T t1 , T t2 , .., T t N 2 }, respectively. Learning episodes are created from the source tasks analogous to meta learning, but since the nature of the tasks can be heterogeneous (e.g., not all are classification tasks), these learning episodes cannot be created using the source classes. Therefore, using the power set of the source task set 2 Ts , after excluding the singletons and the empty set, one has 2 N1 ? N 1 ? 1 multi-task combinations of the source classes that can be used as multi-task learning episodes. These multi-task episodes are used to train the network using the two-level meta optimization, discussed in equations <ref type="bibr" target="#b1">(2)</ref> and <ref type="formula">(3)</ref>. Although the multi-task combinations successively trained the network, they output all the tasks concurrently. New unseen tasks can now be introduced as target tasks. Either all source and target tasks or only the target tasks (as required) are then fine-tuned in the meta testing stage, which is similar to training in MTL, except it utilizes the meta parameters from the validation (meta training) stage. The task heads are fine-tuned if the purpose is to solely improve the target tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental evaluations</head><p>To analyze the performance of the proposed MTML algorithm, a wide range of experiments were conducted. This section elaborates on the data sets, the network design, and the training protocol employed, along with an extensive discussion of the experimental outcomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data sets, tasks and network architecture</head><p>For the performance analysis of our proposed approach, two publicly available data sets are used: the NYU-v2 data set <ref type="bibr" target="#b33">[34]</ref> and the tiny taskonomy data set <ref type="bibr" target="#b47">[48]</ref>. Both of these data sets contain a large variety of indoor scene images in standard 3-channel RGB image format. Four tasks are used in this work: semantic segmentation (T 1 ), depth estimation (T 2 ), surface normal estimation (T 3 ), and edge detection (T 4 ). For the NYU-v2 dataset, we use the train-test split and the task labels given by <ref type="bibr" target="#b39">[40]</ref>. For tiny taskonomy, the standard train-val-test split given by <ref type="bibr" target="#b47">[48]</ref> are used.</p><p>A very commonly used multi-task architecture is used for this work: a shared backbone network, followed by task-specific heads. The common backbone in the network allows sharing of the low and mid-level features through their model parameters, while specific high-level features are learned by the task specific heads <ref type="bibr" target="#b43">[44]</ref>. Since all tasks chosen for this work are at pixel level, this network's architecture makes sense. In this work, dilated ResNet-50 <ref type="bibr" target="#b46">[47]</ref> is employed as the backbone, which gives the shared representations of the input RGB image. These representations are then fed as inputs to the task heads. For all the four tasks, DeepLab V3 <ref type="bibr" target="#b7">[8]</ref> network is used for the task heads, which make use of atrous convolutions 1 <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b16">17]</ref> to regulate the resolution of the features generated by the Deep Neural Network (DNN), while modifying the filter's area of operation. The Atrous Spatial Pyramid Pooling (ASPP) module used in DeepLab v3 architecture helps to extract dense feature maps by discarding the down-sampling in the last layers and employing up-sampling in the filters of the corresponding layers, thereby interpolating the weights of the filters by zeros i.e. holes (i.e., trous). This makes it suitable for pixel-level dense prediction tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Training protocol</head><p>To training the above architecture, an input RGB image of size 256 ? 256 is normalized and fed to the backbone network in batches of 64 images. A minimal learning rate of 0.00001 is considered, to administer sufficient training for all the tasks, since some tasks are harder than others. Taskspecific early stopping (patience = 35) and overall early stopping (patience = 50) are employed to avoid overfitting the backbone network and the task heads during training. AdamW <ref type="bibr" target="#b30">[31]</ref> is used as an optimizer since it decouples weight decay from gradient update by modifying Adam's <ref type="bibr" target="#b23">[24]</ref> implementation of L 2 regularization. The losses are cross-entropy loss for semantic segmentation, a combined depth loss <ref type="bibr" target="#b19">[20]</ref> for depth estimation, inverse cosine similarity loss for surface normal prediction, and Huber loss <ref type="bibr" target="#b34">[35]</ref> for edge detection. The task-specific losses are balanced using the uncertainty <ref type="bibr" target="#b22">[23]</ref>, and the so-obtained combined loss is back-propagated. The evaluation metrics used in this work are similar to those used in <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b36">37]</ref>. For semantic segmentation, cross-entropy (lower is better) and intersection over union (IoU, higher is better) are respectively used for taskonomy and NYU-v2 datasets. Mean absolute error (lower is better) is calculated for depth estimation on both data sets. For the taskonomy data set, cosine similarity is used to evaluate surface normal prediction. In contrast, for the NYU-v2 dataset, the mean and median of angular error (lower is better) between prediction and ground truth and percentage of pixels whose predicted values are within 11.25 ? , 22.5 ? , and 30 ? <ref type="bibr" target="#b39">[40]</ref> (higher is better) of the ground truth are calculated. For edge detection mean absolute error (lower is better) is calculated between the prediction and ground truth for both data sets. For fair comparison, the hyper-parameters were determined for the single task models to perform their best, and the multi-task models were then trained under similar setting.</p><p>In a MTML arrangement, as discussed in Section 3, the network is trained using multi-task learning episodes. In episodes having less than four tasks, it is trained as usual, but for the task absent in the combination, the task loss is set to zero and the losses are combined as usual for backpropagation. The parameters of the corresponding task head are not updated by freezing the layers. To carry out a comparative performance analysis of all the experiments, they are evaluated using the same test set, and all the models are trained with the same hyper-parameters. The models are trained on NVIDIA A100 Tensor Core GPUs, with 40 GB on-board HBM2 VRAM. All experiments are repeated <ref type="table">Table 1</ref>: Performance of the single task, MTL, and MTML approaches introduced in this work on the NYU-v2 and taskonomy datasets (across the three learning paradigms, p &lt; 0.05 for all the tasks). Some previous state-of-the-art works in the literature are also mentioned in this table for a suitable comparison of the evaluation metrics. In this table, MAE is mean absolute error, CE denotes cross entropy metric, mIoU represents mean intersection over union metric and CS stands for cosine similarity metric. For comparison, it should be noted that, the backbone network in single-task <ref type="bibr" target="#b39">[40]</ref> and Multi-task <ref type="bibr" target="#b39">[40]</ref> is ResNet 34, while that in single task (ours) and MTL(ours) is ResNet 50, and both <ref type="bibr" target="#b39">[40]</ref> and this work use DeepLab V3 <ref type="bibr" target="#b7">[8]</ref>   three times with different random seeds to ensure and evaluate the consistency of the model. The results are shown in terms of mean and standard deviation. <ref type="table">Table 1</ref> displays performance for the four tasks as available in the literature, along with the single task, multi-task, and MTML performance obtained in this work. For the NYU-v2 data set, our proposed MTML approach outper-forms all the baseline works for three out of four tasks. For the semantic segmentation task, our single-task learning model performs best. While in the taskonomy data set, depth estimation, surface normal prediction, and edge detection show best performance under single task, MTL, and MTML models, respectively. It is evident that for the semantic segmentation task, the performance of our models appears to be inferior to the performance reported in literature. Similar deterioration was observed in many of the ex-  <ref type="figure">Figure 3</ref>: The charts demonstrate the number of epochs for the single-task, multi-task, and MTML for the NYU-v2 dataset. The x-axis displays the tasks (T1 -T4) for the experiments mentioned in <ref type="table" target="#tab_1">Table 2</ref>. The blue bar represents the number of training epochs, and the orange refers to the epochs required by an unseen task to fine-tune the already trained multi-task and MTML model. The orange bar on top of the blue depicts the number of epochs the model is further trained during fine-tuning the unseen task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Discussion</head><p>periments and is discussed in the forthcoming subsections. <ref type="figure" target="#fig_2">Figure 2</ref> displays the output of all the tasks on NYU-v2 and taskonomy data sets for a single task, MTL and MTML experiments, i.e., 'ours' in <ref type="table">Table 1</ref> (Exp. 1, 2.3 and 5.4 in <ref type="table" target="#tab_1">Tables 2 &amp; 3</ref>). Similar to the quantitative performance, it is evident from the qualitative results that MTML outperforms the rest for all the tasks.</p><p>MTL performs comparable to single task for unseen tasks: To analyze the performance of the proposed methods for various task combinations, the effect of adding a new task is studied in an already-trained network, and the effect on performance is investigated with fewer data from the new tasks, the experiments listed in <ref type="table" target="#tab_1">Table 2</ref> (NYU-v2) and 3 (taskonomy) were designed and executed. To test <ref type="table">Table 3</ref>: Test set evaluation results for a single task, multi-task, and MTML experiments on the taskonomy dataset Exp. No. <ref type="table" target="#tab_1">Tasks Involved  Tasks  Trained  Tested  T1  T2  T3  T4  ( +Tn is fine</ref> , and leave-one-out (Exp. 7, 8, and 9). In these experiments, '+Tn' indicates that the network is first trained on some tasks and further fine-tuned on the n th task, which in this work is considered as the addition of a new task to a multi-task architecture. It is observed that for the NYU-v2 dataset, the MTL experiments, i.e., Exp. 2 and 7 (all variants), perform almost identical or even better than their single task counterparts for most of the tasks. Similar behavior can be seen for the taskonomy dataset, except for the segmentation task, which performs poorly in the MTL setting. The experiments fine-tune an unseen task on a multi-task network trained by other tasks (which is the addition of a new task in MTL), i.e., Exp. 3 and 8: for the NYU-v2 data set the fine-tuning on the surface normal estimation task (Exp. 3.1, 3.2, 8.3) gives better metrics than its equivalent single-task experiment (Exp 1), while the metrics for depth estimation become worse. It is therefore established that training all the tasks together in a multi-task setting (Exp. 2.3) is better than fine-tuning some tasks (Exp. 3.3, 3.2, 8.4); in the former case there is more scope for learning than the latter, which is already very well (pre-)trained on some tasks. Additionally, for some of the multi-task models (Exp. <ref type="bibr">8.1, 8.2, 8.</ref>3) the addition of an unseen task to the pre-trained models not only gives comparably good performance on the unseen task, but it also enhances the metrics for the already trained tasks (compare Exp. 7 and 8). Similar traits as above are also valid for the taskonomy data set, except for the semantic segmentation task which performs the best in single-task learning.</p><p>MTML outperforms on the NYU-v2 data set: In Exp 5.4 under the MTML setting, 7 out of 8 evaluation metrics perform better than their corresponding single task metrics (Exp. 1) for NYU-v2 data set. The meta testing phase in MTML involves fine-tuning a new unseen task (Exp. 5, and 9) where depth and surface normal estimation tasks give consistently good outcomes, whilst in most of the experiments the performance of the semantic segmentation task worsened because of over-fitting caused by rigorous bi-level training using task combinations in MTML. However, of all the experiments in <ref type="table" target="#tab_1">Table 2</ref>, the best value of IoU is 45.05 for semantic segmentation, which is achieved in Exp. 9.1, where it is fine-tuned on the model multi-task meta trained on the remaining three tasks. In Exp. 4 &amp; 6, the fine-tuning was performed using 50% of the training data in multi-task and MTML settings. For the NYU-v2 data set, almost identical performance to their 100% training data counterpart (Exp. <ref type="bibr">3 &amp; 5)</ref> for all tasks are achieved. A similar trait is observed in the case of the taskonomy data set, see <ref type="table">Table  3</ref>, except for the semantic segmentation task which is less over-fit as compared to the experiments that perform finetuning on 100% data.</p><p>MTML quickly adapts to unseen tasks: Apart from some metrics, overall, MTML achieves equal to superior performance with respect to MTL. For both data sets, in the MTML framework (Exp. 5 and 9) all tasks but semantic segmentation achieve approximately equivalent or better outcomes than MTL or single-task learning. It is worth noting that the same performance is attained in a significantly lower number of fine-tuning epochs than in MTL and corresponding single-task learning, see <ref type="figure">Figure 3</ref>. It is evident that the unseen tasks (T3, T4, or both) that are added in Exp. 3 and 5 learn faster than its parallel single-task model. This implies that models trained using meta (two-level) optimization in the multi-task scheme quickly adapt to new tasks. The only trade-off is that they also consume significantly more steps than MTL and single task learning in the (meta) training stage. An elaborated table with more information on the number of epochs for all the experiments is appended as supplementary material. The source code to reproduce all reported results is in the supplementary material and will be available at-https://github.com/abcd/ABCD/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Unsatisfactory performance of the semantic segmentation task</head><p>For the taskonomy data set, from the performance analysis of table 3, one observes that for the semantic segmentation task the outcomes are very unsatisfying. It was expected that MTML should outperform the others, but, in contrast, it gives the worst results. We investigated the cause for this and came up with a couple of possible explanations:</p><p>? The segmentation masks given for each image are not annotated by humans, in fact, they are pseudo labels, i.e., the masks are distilled from FCIS <ref type="bibr" target="#b27">[28]</ref>. While testing the MTML experiments 5, 6, and 9, it was discovered that these models learn better than the ground truth labels (masks), as they can identify objects present in the image which were not originally annotated A few such examples are shown in <ref type="figure" target="#fig_4">Figure  4</ref>. This is one of the causes of the degradation of the semantic segmentation results. ? The classes of semantic segmentation are highly unbalanced and several images only contain 'background' class.</p><p>For the NYU-v2 dataset, there is a slight degradation in  the performance of the semantic segmentation task for the MTML experiments (Exp. <ref type="bibr">5, 9.2, 9.3, 9.4</ref> of <ref type="table" target="#tab_1">Table 2</ref>). This is primarily because of the extensive training in the meta training phase, which leads to overfitting the model for this task. During training, the IoU metric for these experiments is about 99%. This can be solved using task-specific hyperparameters, like learning rate, weight decay, etc. In this work, all the hyper-parameters for all four tasks are identical so as to obtain an appropriate comparison between singletask, multi-task and MTML paradigms. Another reason for the under-performance of semantic segmentation can probably be related to negative transfer <ref type="bibr" target="#b6">[7]</ref>. Although all the tasks are pixel-level, negative transfer is possible because of the nature of the tasks: segmentation is the only pixel-level classification task while all others are regression tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This work proposes to combine multi-task and meta learning by introducing multi-task learning episodes to meta train the network and allows to further test the network by introducing a new (unseen) task. Theoretically, such an ensemble should deliver good performance for the new task in fewer steps than training the single task from scratch. Comprehensive empirical analysis of MTML performance supports the hypothesis that MTML indeed performs best compared to vanilla MTL and single-task learning. In addition to that, it allows for swift adaptation to an unseen task even with fewer data. However, we do observe that the semantic segmentation task under-performs, probably because of over-fitting, the presences of pseudo labels, or negative task transfer. Overall, MTML is a robust ap-</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Block diagram illustrating the formulation of the learning paradigms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>The figure illustrates sample images of the input, its corresponding ground truths, single task (Exp. 1), MTL (Exp. 2.3) and MTML (Exp. 5.4) outputs for semantic segmentation (Seg.), depth estimation (Depth), surface normal estimation (SN), and edge detection (Edge) for both the NYU-v2 and taskonomy datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>This figure shows the input RGB image, the corresponding ground truth (GT) segmentation mask and the predicted segmentation mask (Pred.) by the MTML model. The red box highlights the object not present in the ground truth (pseudo labels), but the proposed MTML model learns to detect and segment them. For example, in the image (a), the plant (class-potted plant) is not identified in the pseudo labels (b), yet segmented in the prediction (c).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>network for task specific heads</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Taskonomy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NYU</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model</cell><cell cols="2">Parameters Segmen-</cell><cell>Depth</cell><cell>Surface</cell><cell>Edge</cell><cell>Segmen-</cell><cell>Depth</cell><cell></cell><cell cols="3">Surface Normal</cell><cell></cell><cell>Edge</cell></row><row><cell></cell><cell></cell><cell>tation</cell><cell cols="3">Estimation Normal Detection</cell><cell>tation</cell><cell>Estimation</cell><cell cols="2">Error ?</cell><cell></cell><cell>Theta ?</cell><cell></cell><cell>Detection</cell></row><row><cell></cell><cell>in Millions</cell><cell>CE ?</cell><cell>MAE ?</cell><cell>CS ?</cell><cell>MAE ?</cell><cell>mIoU ?</cell><cell>MAE ?</cell><cell cols="4">Mean Median 11.25 ? 22.5 ?</cell><cell>30 ?</cell><cell>MAE ?</cell></row><row><cell>Single Task [40]</cell><cell>124</cell><cell>0.575</cell><cell>0.022</cell><cell>0.707</cell><cell>0.212</cell><cell>27.5</cell><cell>0.62</cell><cell>17.5</cell><cell>15.2</cell><cell>34.9</cell><cell>73.3</cell><cell>85.7</cell><cell>-</cell></row><row><cell>Multi-Task [40]</cell><cell>41</cell><cell>0.587</cell><cell>0.024</cell><cell>0.696</cell><cell>0.203</cell><cell>24.1</cell><cell>0.58</cell><cell>16.6</cell><cell>13.4</cell><cell>42.5</cell><cell>73.2</cell><cell>84.6</cell><cell>-</cell></row><row><cell>Adashare [40]</cell><cell>41</cell><cell>0.566</cell><cell>0.025</cell><cell>0.702</cell><cell>0.2</cell><cell>30.2</cell><cell>0.55</cell><cell>16.6</cell><cell>12.9</cell><cell>45</cell><cell>71.7</cell><cell>83</cell><cell>-</cell></row><row><cell>Cross Stitch [33]</cell><cell>124</cell><cell>0.56</cell><cell>0.022</cell><cell>0.679</cell><cell>0.217</cell><cell>24.5</cell><cell>0.58</cell><cell>17.2</cell><cell>14</cell><cell>41.4</cell><cell>70.5</cell><cell>82.9</cell><cell>-</cell></row><row><cell>MTAN [30]</cell><cell>114</cell><cell>0.637</cell><cell>0.023</cell><cell>0.687</cell><cell>0.206</cell><cell>26</cell><cell>0.57</cell><cell>16.6</cell><cell>13</cell><cell>43.7</cell><cell>73.3</cell><cell>84.4</cell><cell>-</cell></row><row><cell>NDDR CNN [13]</cell><cell>133</cell><cell>0.539</cell><cell>0.024</cell><cell>0.7</cell><cell>0.203</cell><cell>21.6</cell><cell>0.66</cell><cell>17.1</cell><cell>14.5</cell><cell>37.4</cell><cell>73.7</cell><cell>85.6</cell><cell>-</cell></row><row><cell>Sluice [37]</cell><cell>124</cell><cell>0.596</cell><cell>0.024</cell><cell>0.695</cell><cell>0.207</cell><cell>23.8</cell><cell>0.58</cell><cell>17.2</cell><cell>14.4</cell><cell>38.9</cell><cell>71.8</cell><cell>83.9</cell><cell>-</cell></row><row><cell>Learn2branch [16]</cell><cell>51</cell><cell>0.462</cell><cell>0.018</cell><cell>0.709</cell><cell>0.136</cell><cell></cell><cell cols="4">No results on NYU dataset</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Single task (Ours)</cell><cell>39.6</cell><cell>0.491</cell><cell>0.013</cell><cell>0.931</cell><cell>0.049</cell><cell>42.53</cell><cell>0.11</cell><cell>15.88</cell><cell>13.97</cell><cell cols="3">41.62 73.20 88.56</cell><cell>0.15</cell></row><row><cell>MTL (Ours)</cell><cell>88</cell><cell>0.628</cell><cell>0.013</cell><cell>0.930</cell><cell>0.050</cell><cell>42.25</cell><cell>0.12</cell><cell>15.04</cell><cell>16.06</cell><cell cols="3">42.24 72.52 87.72</cell><cell>0.16</cell></row><row><cell>MTML (Ours)</cell><cell>88</cell><cell>2.300</cell><cell>0.063</cell><cell>0.931</cell><cell>0.046</cell><cell>41.51</cell><cell>0.10</cell><cell>13.34</cell><cell>10.24</cell><cell cols="3">52.40 76.17 88.51</cell><cell>0.10</cell></row><row><cell>Dataset</cell><cell></cell><cell></cell><cell cols="2">Taskonomy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NYU</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Image</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Tasks</cell><cell>Seg.</cell><cell cols="2">Depth</cell><cell>SN</cell><cell cols="2">Edge</cell><cell>Seg.</cell><cell></cell><cell>Depth</cell><cell></cell><cell>SN</cell><cell></cell><cell>Edge</cell></row><row><cell>Ground Truth</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Single task</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Multi-task</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Multi-task Meta</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Test set evaluation results for a single task, multi-task, and MTML experiments on the NYU-v2 dataset</figDesc><table><row><cell>Exp. No.</cell><cell>Tasks Involved</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Atrous convolution comes from the french convolution? trous which could be translated as sparse kernel convolution.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>proach that can efficiently train several tasks together and is capable of faster adaptation to new tasks if these are not too far off from the already learned tasks.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Revisit multimodal meta-learning through the lens of multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milad</forename><surname>Abdollahzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Touba</forename><surname>Malekzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai Man</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>A. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Task2vec: Task embedding for meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Achille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Tewari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Charless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Soatto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6430" to="6439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">When is multitask learning effective? semantic sequence prediction under varying data conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alonso</forename><surname>H?ctor Mart?nez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Identifying beneficial task relations for multi-task learning in</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>S?gaard</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08303</idno>
	</analytic>
	<monogr>
		<title level="m">deep neural networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Tasknorm: Rethinking batch normalization for meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bronskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Requeima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1153" to="1164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Meta multi-task learning for speech emotion recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruichu</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaibin</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenjie</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3336" to="3340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="75" />
			<date type="published" when="1997-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Rethinking atrous convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05587</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Instance-aware semantic segmentation via multi-task network cascades</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Efficiently identifying task groupings for multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Amid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhe</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="27503" to="27516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Measuring and harnessing transference in multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Amid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhe</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>Doina Precup and Yee Whye Teh</editor>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017-08" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="6" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nddr-cnn: Layerwise feature fusing in multi-task cnns by neural discriminative dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3205" to="3214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Bayesian metalearning for few-shot policy adaptation across robotic platforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Ghadirzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petra</forename><surname>Poklukar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M?rten</forename><surname>Bj?rkman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danica</forename><surname>Kragic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1274" to="1280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast image scanning with deep max-pooling convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Giusti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Cire?an</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Image Processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="4034" to="4038" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning to branch for multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengsheng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Yu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ulbricht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3854" to="3863" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A real-time algorithm for signal analysis with the help of the wavelet transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Holschneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Kronland-Martinet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Morlet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ph</forename><surname>Tchamitchian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wavelets</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="286" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Meta-learning in neural networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Micaelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Micaelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05439</idno>
		<title level="m">Meta-learning in neural networks: A survey</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Revisiting single image depth estimation: Toward higher resolution maps with accurate object boundaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mete</forename><surname>Ozay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takayuki</forename><surname>Okatani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1043" to="1051" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A survey of deep meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Huisman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">N</forename><surname>Van Rijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aske</forename><surname>Plaat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="4483" to="4541" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Task-embedded control networks for few-shot imitation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bloesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew J</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on robot learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="783" to="795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Multi-task learning using uncertainty to weigh losses for scene geometry and semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7482" to="7491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenguo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohong</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinghui</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.06527</idno>
		<title level="m">Meta reinforcement learning with task embedding and shared policy</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Generating personalized dialogue via multi-task meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woon Seng</forename><surname>Kong Aik Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th Workshop on the Semantics and Pragmatics of Dialogue -Full Papers</title>
		<meeting>the 25th Workshop on the Semantics and Pragmatics of Dialogue -Full Papers<address><addrLine>Potsdam, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-09" />
		</imprint>
	</monogr>
	<note>SEMDIAL</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwonjoon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10657" to="10665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Fully convolutional instance-aware semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4438" to="4446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Meta-learning multi-task communication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Endto-end multi-task learning with attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Johns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew J</forename><surname>Davison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1871" to="1880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The benefit of multitask representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardino</forename><surname>Romera-Paredes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">81</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cross-stitch networks for multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3994" to="4003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Derek Hoiem and Rob Fergus. Indoor segmentation and support inference from rgbd images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet Kohli Nathan</forename><surname>Silberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Edge loss functions for deep-learning depth-map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandip</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuvan</forename><surname>Jhamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning with Applications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">100218</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Omninet: A unified architecture for multi-modal multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhojeet</forename><surname>Pramanik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priyanka</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aman</forename><surname>Hussain</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Latent multi-task architecture learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Bingel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>S?gaard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4822" to="4829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning task relatedness in multi-task learning for images in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gjorgji</forename><surname>Strezoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Nanne Van Noord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Worring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 on International Conference on Multimedia Retrieval</title>
		<meeting>the 2019 on International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="78" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Adashare: Learning what to share for efficient deep multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ximeng</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rameswar</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rogerio</forename><surname>Feris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8728" to="8740" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Meta-learning for effective multi-task and multilingual modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Tarunesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sushil</forename><surname>Khyalia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishwajeet</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preethi</forename><surname>Jyothi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.10368</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Learning to Learn: Introduction and Overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorien</forename><surname>Pratt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Springer US</publisher>
			<biblScope unit="page" from="3" to="17" />
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Hierarchical inter-attention network for document classification with multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiao</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3569" to="3575" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Multi-task learning for dense prediction tasks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wouter</forename><surname>Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Bridging multi-task learning and meta-learning: Towards efficient training and effective adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pad-net: Multi-tasks guided prediction-and-distillation network for simultaneous depth estimation and scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="675" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dilated residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Funkhouser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Taskonomy: Disentangling task transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Amir R Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">B</forename><surname>Sax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Learning to multitask</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Learning and transferring multi-task deep representation for face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanpeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">08</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
