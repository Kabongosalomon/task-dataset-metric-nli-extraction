<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MASKGROUP: HIERARCHICAL POINT GROUPING AND MASKING FOR 3D INSTANCE SEGMENTATION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory on Machine Perception</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory on Machine Perception</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Zeng</surname></persName>
							<email>zeng@pku.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Key Laboratory on Machine Perception</orgName>
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
							<email>yunhe.wang@huawei.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MASKGROUP: HIERARCHICAL POINT GROUPING AND MASKING FOR 3D INSTANCE SEGMENTATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Point Cloud</term>
					<term>3D Instance Segmentation</term>
					<term>Hierarchical Point Grouping</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper studies the 3D instance segmentation problem, which has a variety of real-world applications such as robotics and augmented reality. Since the surroundings of 3D objects are of high complexity, the separating of different objects is very difficult. To address this challenging problem, we propose a novel framework to group and refine the 3D instances. In practice, we first learn an offset vector for each point and shift it to its predicted instance center. To better group these points, we propose a Hierarchical Point Grouping algorithm to merge the centrally aggregated points progressively. All points are grouped into small clusters, which further gradually undergo another clustering procedure to merge into larger groups. These multi-scale groups are exploited for instance prediction, which is beneficial for predicting instances with different scales. In addition, a novel MaskScoreNet is developed to produce binary point masks of these groups for further refining the segmentation results. Extensive experiments conducted on the ScanNetV2 and S3DIS benchmarks demonstrate the effectiveness of the proposed method. For instance, our MaskGroup achieves a 66.4% mAP with the 0.5 IoU threshold on the ScanNetV2 test set, which is 1.9% higher than the state-of-the-art method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>To tackle the 3D instance segmentation problem, a series of detection-based methods <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> are explored for predicting 3D bounding boxes from the observed point data. These methods produce a mask to obtain the instance inside the bounding box. Moreover, the embedding-based approaches <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7]</ref> learn a spatial or feature embedding vector for each point, and utilize the clustering algorithm to obtain the instance. For example, Jiang et al. <ref type="bibr" target="#b5">[6]</ref> proposed PointGroup, an end-to-end bottom-up architecture which groups the 3D points by considering the void space between objects. PointGroup first learns a space offset to move the object points towards their instance Need a small gap to separate objects that are very close.</p><p>Need a large gap to avoid dropping some points of an object. centers. Then, all points are clustered according to the distance of the blank space. Two points within a certain distance are merged into one group. However, it is hard to decide on a specific single distance to meet a variety of situations, because objects are lying from each other with different distances (As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>). Additionally, since the objects in the 3D space are of high complexity, noisy points are usually existing in the grouped instances, which hinders the performance.</p><p>To enhance the performance of 3D instance segmentation, we present a masked hierarchical point grouping approach, namely MaskGroup. In practice, we first learn the offsets and semantic labels for the input 3D points. Since the sizes of observed 3D objects in the given environment are often various, we then propose a Hierarchical Point Grouping (HPG) algorithm for carefully merging the points of each object progressively. Specifically, a small gap is utilized to cluster points into several initial groups. Then we exploit progressively enlarged distances to merge small groups from the previous step into larger groups. The clustered groups obtained in different steps contain multi-scale information which can be further used for the final instance predictions with better results.</p><p>In addition, the clustered points obtained using the hierarchical grouping may have some noisy points for each instance due to the complex enviroment of 3D point data. To effectively refine and evaluate these groups, we propose a tiny MaskScoreNet to mask out the background points via a mask branch and simultaneously evaluate the quality of each mask via a score branch. The mask branch predicts a binary mask for the points in a group to distinguish the actual points in object instances. The score branch further predicts a binary quality score for the masked group.</p><p>Our contributions are summarized as follows: <ref type="bibr" target="#b0">(1)</ref> In order to make full use of the multi-scale information of 3D instances, we propose a Hierarchical Point Grouping algorithm to merge the points into different groups progressively. <ref type="bibr" target="#b1">(2)</ref> We proposed a novel MaskScoreNet to refine the clustered groups, which produces binary point masks for all grouped instances to eliminate noisy points and predicts confidence scores for final instances, simultaneously. (3) The proposed method, i.e., MaskGroup, achieves state-of-the-art results on the challenging ScanNetV2 and S3DIS benchmarks, demonstrating its effectiveness for 3D instance segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">RELATED WORK</head><p>3D instance segmentation for large scale point clouds has attracted great research interest <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b4">5]</ref> in recent years. Similar to the detection-based 2D instance segmentation methods, Kundu et al. <ref type="bibr" target="#b9">[10]</ref> proposed 3D-RCNN, which builds upon Faster R-CNN to predict 3D bounding boxes from point clouds. Yang et al. proposed BoNet <ref type="bibr" target="#b0">[1]</ref>, which predicts the box from the global point features and produces a point mask for the bounding box.</p><p>The embedding-based idea in 2D instance segmentation is also extended into the 3D domain. Wang et al. <ref type="bibr" target="#b10">[11]</ref> proposed to learn the neighborhood relationship for each pair of points and access the instance according to similar relations. Several methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> extended the 2D embedding idea to point cloud, which encourage points in the same instance to lie close in the embedding space, and adopt mean-shift algorithm for clustering. Qi et al. proposed VoteNet <ref type="bibr" target="#b11">[12]</ref>, which learns shift vectors to move points towards their instance centers and can be seen as a kind of spatial embedding. Engelmann et al. <ref type="bibr" target="#b4">[5]</ref> proposed to learn a spatial embedding of points and group points within a certain distance into one group, and use learned feature embedding to merge the group. Jiang et al. <ref type="bibr" target="#b5">[6]</ref> proposed PointGroup, which also learns the spatial embedding, but groups the points connected with each other into an instance. OccuSeg <ref type="bibr" target="#b6">[7]</ref> utilizes both spatial and feature embedding to progressively group the point into an instance.</p><p>The hierarchical approach is also used in 3D scene analysis <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14]</ref>, which is mainly utilized for bottom-up context aggregation for hierarchical scene graph. Our paper proposes the hierarchical grouping and masking to capture multi-scale information for instance prediction, which is quite different from the above mentioned papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE PROPOSED MASKGROUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Method Overview</head><p>3D instance segmentation task aims to separate different objects in 3D scene and predict the semantic label of each instance. Our proposed method is depicted in <ref type="figure" target="#fig_1">Fig. 2</ref>.</p><p>The input 3D scene is represented as a point cloud P with N points in total, i.e., P = {p i } N i=0 ? R N ?k0 , where k 0 is the channel number of point feature such as the point location ? i = (x i , y i , z i ) and color q i = (r i , g i , b i ). Then a voxel-based backbone network <ref type="bibr" target="#b14">[15]</ref> is applied to extract the</p><formula xml:id="formula_0">3D features F b = {F b i } N i=0 ? R N ?k1 , where each point i has a corresponding feature vector F b i ? R k1</formula><p>, k 1 is the feature length. After that, two sub-branches are exploited to obtain the semantic labels S = {s i } N i=0 ? R N and the offset vec-</p><formula xml:id="formula_1">tors D = {d i } N i=0 ? R N ?3 , where d i = (?x i , ?y i , ?z i ).</formula><p>Adding the offsets to original coordinates, we obtain the es-</p><formula xml:id="formula_2">timated object centroids O = {o i } N i=0 ? R N ?3 , where o i = ? i + d i .</formula><p>In order to separate objects with the same semantics, we explore the void space in O or P . Given a clustering radius r 1 manually, we can merge the points within r 1 into |G 1 | groups</p><formula xml:id="formula_3">G 1 = {G 1 i } |G 1 | i=0 .</formula><p>However, it is difficult to select a proper r 1 that works well for instances with different scales. To this end, we proposed a hierarchical point grouping algorithm to cluster the points via a multi-scale scheme. First, a small radius is utilized to cluster points into several small groups. Then we exploit progressively enlarged clustering radius to merge small groups into larger groups for H steps. The clus-</p><formula xml:id="formula_4">tered groups G = {G 1 ? ... ? G H } = {G i } |G| i=0</formula><p>obtained in different steps contain multi-scale information and are further used for final instance prediction.</p><p>However, the roughly clustered groups G may contain some noisy points. We then propose a MaskScoreNet to refine and evaluate these groups. For each group G i , MaskScoreNet predicts a binary mask M i to eliminate noisy points in this group and also outputs a score E i to indicate the confidence score of this masked group.</p><p>In inference stage, the groups</p><formula xml:id="formula_5">G = {G i } |G| i=0 , masks M = {M i } |M | i=0 and their corresponding scores E = {E i } |E| i=0</formula><p>( |G| = |M | = |E|) are fed into the Non Maximum Suppression (NMS) module to obtain final instance predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Backbone Network Architecture</head><p>The backbone network consists of a feature extraction network and two sub-branch networks for semantic prediction and object centroid regression The feature extraction network takes points P as input and obtains point features F b .</p><p>A multi-layer perceptron (MLP) is applied to produce se-</p><formula xml:id="formula_6">mantic scores B = {b i } N i=0 ? R N ?C for the N points,</formula><p>where C is the number of semantic classes. The semantic labels S = {s i } N i=0 ? R N are the classes with the highest score. This semantic branch is supervised by a semantic segmenta-</p><formula xml:id="formula_7">tion loss L sem = 1 N N i=1 H(b i ,? i )</formula><p>, where? i is the ground truth semantic label of point i, H(?) represents the cross entropy function.</p><p>Another MLP encodes F b to produce 3-dimensional offset vectors D for the N points. This centroid branch is super- vised using the following L 1 regression loss:</p><formula xml:id="formula_8">L off = 1 |?| |?| ? =1 1 N? N? i=1 ||di + ?i ??i||,<label>(1)</label></formula><p>where? i is the ground truth centroid of i-th point that belongs to?-th instance, N? is the number of points in the?-th instance and |?| is the number of ground truth instance.</p><p>To ensure that the points are moving towards their instance centroids, following <ref type="bibr" target="#b15">[16]</ref>, we adopt a direction loss L dir to constrain the direction of predicted offset vectors:</p><formula xml:id="formula_9">L dir = ? 1 |?| |?| ? =1 1 N? N? i=1 di ||di||2 ?? i ? ?i ||?i ? ?i||2 ,<label>(2)</label></formula><p>where ? i represents the 3D position of the i-th point of th? i-th instance. With the learned offset vector d i , we can obtain the estimated object centroid o i = ? i + d i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Hierarchical Point Grouping</head><p>With spatial information like 3D point positions and estimated object centroids, we can cluster points into different groups. Traditional methods for instance clustering in 3D instance segmentation rarely consider the multi-scale information, e.g., PointGroup <ref type="bibr" target="#b5">[6]</ref> utilized a single radius threshold for point grouping, which is insufficient for capturing information for instances with different scales. Multi-scale information has been widely used in 2D object detection and instance segmentation <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, e.g., Feature Pyramid Networks <ref type="bibr" target="#b16">[17]</ref>. And some hierarchically ideas are used for analyzing 3D scenes <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. However, it is still less explored for 3D instance segmentation.</p><p>To this end, we propose a hierarchical point grouping algorithm that takes multiple spacing distance into consideration. Specifically, we take the groups G h?1 found in (h?1) th round as input. Especially, when h = 1, each group in G 0 is a single point. In the 1 st round, we use a small spatial distance r 1 to group the points. If two points have the same semantics and the distance between them is smaller than r 1 , then we put them into the same group. At the end of the 1 st round, we obtain a set of initial groups</p><formula xml:id="formula_10">G 1 = {G 1 i } |G 1 | i=0 with a number of |G 1 |.</formula><p>In the next round, we take groups G 1 in the first round as inputs. For two groups G 1 i and G 1 j with the same semantics, we merge them into a new group if the distance between two groups is smaller than radius r 2 . All point within a group has the same semantics, so the semantic label of a group G i is defined as the label of its point, We denote the semantic label of group G i as S[G i ]. The distance ||G i , G j || between group G i and G j is calculated as the minimum distance between points in these two groups. In this way, we obtain some new groups</p><formula xml:id="formula_11">G 2 = {G 2 i } |G 2 |</formula><p>i=0 with a number of |G 2 |. We repeat this process for H times. For each round, we have r h?1 &lt; r h , so we can merge groups in last round into larger groups gradually. We collect the groups in all rounds and eliminate the groups in which the number of its points is fewer than N ? , finally get G = {G 1 ? ... ? G H }. These point groups obtained in different stages contain clustering information for different scales. For example, since G 1 is clustered with a small radius, point group in G 1 can better segment instances with small scales. Meanwhile, larger instances are better segmented in G H . Point groups with multiple scales G will be exploited for final instance prediction, which is beneficial for more accurate 3D instance segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">MaskScoreNet</head><p>After the hierarchical point grouping step, we obtain a set of groups G = {G i } |G| i=0 , where |G| is the total number of groups collected from all grouping steps. Group G i consists of N i g points, i.e., G = {p j } Ng j=0 (we omit i for simplicity). Some groups in G are well grouped and some contain inaccurate points. Therefore, we design a novel MaskScoreNet to refine the groups G and also evaluate the quality of each group.</p><p>Recall that, each point i has a corresponding backbone feature vector F b i ? R k1 . So, for a group G = {p j } Ng j=0 , we can create a group feature F g ? R N g?k1 by selecting the corresponding point features from F b ,</p><p>The group G assigned with group feature F g is fed into a small U-Net to better aggregate the group information, the output features F m are fed into a MLP (mask branch) to predict a binary mask M = {m j } Ng j=0 (we omit i for simplicity), where m j is the confidence score for j-th point in G, which indicates the probability of this point belonging to G. The mask loss function for all groups is formulated as:</p><formula xml:id="formula_12">Lmask = ? 1 |G| |G| g=0 1 Ng Ng i=0 (milog(mi) + (1 ?mi)log(1 ? mi)),<label>(3)</label></formula><p>wherem i is the ground-truth mask value corresponding to m i . To obtain the ground-truth mask, we first found out the ground-truth instance I? which has the largest Intersection over Union (IoU) between cluster G :</p><formula xml:id="formula_13">g = argmax i IoU(G, Ii) | Ii ?? ,<label>(4)</label></formula><p>where? is a set of ground-truth instances. Then we can get the value ofm i : mi = 1, if point i in both G and I? 0, otherwise .</p><p>To evaluate the quality of the masked groups, we propose a MaskPooling layer that uses the predicted mask M to average pool the group feature G across the points, and obtain a feature vector F e to represent the masked group. After that, a score branch (MLP and Sigmoid) is utilized to predict the quality score E for the masked group based on F e . The score loss is defined as:</p><formula xml:id="formula_15">Lscore = ? 1 |G| |G| i=1</formula><p>(?ilog(Ei) + (1 ??i)log(1 ? Ei)), <ref type="bibr" target="#b5">(6)</ref> where? i is the ground-truth score between 0 and 1 for M i , which is decided by the IoU between M i and its corresponding ground-truth instances <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Network Training</head><p>We train the whole framework in an end-to-end manner with the total loss as:</p><formula xml:id="formula_16">L = Lsem + L of f + L dir + L mask + Lscore.<label>(7)</label></formula><p>4. EXPERIMENTS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setting</head><p>We evaluate the proposed method on two large scale 3D indoor scene datasets, i.e., ScanNetV2 <ref type="bibr" target="#b31">[32]</ref> and S3DIS <ref type="bibr" target="#b27">[28]</ref>. ScanNetV2 contains 1613 scenes with 18 object categories, in which all points are annotated with semantic and instance labels. S3DIS <ref type="bibr" target="#b27">[28]</ref> contains 6 sub-datasets and has 271 scenes in total. All points are annotated with instance labels and one of the 13 semantic labels. In the data processing part, we set the voxel size to 0.02m. We randomly crop the scene to make sure the number of points in each scene to be equal or fewer than 250k. In the inference phase, all scenes are fed into the network without cropping. In the hierarchical point grouping part, we set the clustering radii r as 0.01m, 0.03m, and 0.05m in different stages. We use the same cluster radius setting for ScanNetV2 and S3DIS datasets. We have tried to use a different combinations of clustering radii for S3DIS, but observe no performance improvement. It demonstrate that our method has good generalization performance on different datasets. The minimum cluster point number N ? is empirically set as 50. The threshold of IoU for NMS is set to 0.7 The proposed method is trained via Adam optimizer with a base learning rate of 0.001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparisons with state-of-the-arts</head><p>Instance Segmentation on ScanNetV2 <ref type="bibr" target="#b31">[32]</ref>. We compare our MaskGroup on the testing set of ScanNetV2 with a number of prior methods, including 3D-BoNet <ref type="bibr" target="#b0">[1]</ref>, 3D-MPA <ref type="bibr" target="#b4">[5]</ref>, PointGroup <ref type="bibr" target="#b5">[6]</ref>, GICN <ref type="bibr" target="#b24">[25]</ref>, OccuSeg <ref type="bibr" target="#b6">[7]</ref>, Dyco3D <ref type="bibr" target="#b25">[26]</ref> and PE <ref type="bibr" target="#b26">[27]</ref>. We report the results of AP 50 , AP 25 , and AP of different models in <ref type="table" target="#tab_0">Table 1</ref>. Our MaskGroup achieves the highest AP 50 score of 66.4% and outperforms all prior methods. Specifically, the AP 50 score of our method is 2.6% and 2.3% higher than GICN <ref type="bibr" target="#b24">[25]</ref> and DyCo3D <ref type="bibr" target="#b25">[26]</ref>, respectively. Moreover, our MaskGroup obtains 1.9% higher AP 50 than the for- mer best solution PE <ref type="bibr" target="#b26">[27]</ref> which has 64.5% AP 50 score. Our method has a higher AP score than most of the prior models and obtains slightly worse AP than OccuSeg <ref type="bibr" target="#b6">[7]</ref>. However, MaskGroup achieves 3.0% and 5.3% better AP 50 and AP <ref type="bibr" target="#b24">25</ref> than OccuSeg, respectively, demonstrating the superiority of our proposed method. <ref type="table" target="#tab_0">Table 1</ref> in supplementary material also lists detailed performance on each category and totally our MaskGroup ranks the 1 st place in 10 out of 18 classes. <ref type="figure" target="#fig_0">Fig.1</ref> in supplementary material shows the qualitative results on the validation set of ScanNetV2. We also provide some qualitative results of PointGroup and our proposed MaskGroup, as shown in <ref type="figure" target="#fig_1">Fig.2</ref> in supplementary material. Our method obtains better results than PointGroup.</p><p>Instance Segmentation on S3DIS <ref type="bibr" target="#b27">[28]</ref>. We report the performance of mean precision (mPrec) and mean recall (mRec) on the 5th sub-datasets results, as well as 6-fold cross validation results. As is shown in <ref type="table">Table 2</ref>, our MaskGroup achieves competitive performance with prior methods under different evaluation protocols. Specifically, MaskGroup gets 65.0% and 69.9% on AP 50 in terms of Area5 and 6-Fold results, which are 7.2% and 5.9% higher than PointGroup <ref type="bibr" target="#b5">[6]</ref>, respectively. Moreover, the proposed MaskGroup outperforms recent methods like MPNet <ref type="bibr" target="#b28">[29]</ref>, InsEmb <ref type="bibr" target="#b29">[30]</ref> and ICM-3D <ref type="bibr" target="#b30">[31]</ref> in terms of mean precision and recall. MaskGroup achieves competitive results with DyCo3D <ref type="bibr" target="#b25">[26]</ref> and OccuSeg <ref type="bibr" target="#b6">[7]</ref>, with higher recall and slightly lower precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Studies</head><p>In this section, we conduct extensive ablation studies on the ScanNetV2 validation set to analyze the impacts of different modules in MaskGroup. Without Mask Prediction. We remove the mask branch and MaskPool layer from our MaskGroup model to examine the effectiveness of MaskScoreNet. This degraded model B only obtains the AP score of 39.2%, AP 50 score of 58.3% and AP 25 score of 71.5%, as shown in <ref type="table">Table 3</ref>. The whole MaskGroup model E achieves 41.9%/62.7%/73.6% for AP/AP 50 /AP 25 scores. It demonstrates that the mask branch can effectively refine the roughly clustered groups and is beneficial for the final predictions. Meanwhile, compare to the baseline A, the model B encounters slight performance drop. This observation implies that it is necessary to use the mask branch together with the HPG module, because using the HPG without masking will bring some poorly grouped proposal instances. Without Hierarchical Grouping. We use one stage grouping strategy to cluster the points, which results in a degraded model C without using the hierarchical point grouping (HPG) algorithm. It achieves the AP score of 40.4%, AP 50 score of 59.8%, AP 25 score of 70.5%, which are 1.5%, 2.9% and 3.1% lower than the whole model with HPG (model E). It demonstrates that the proposed HPG algorithm is beneficial for 3D instance segmentation. Without MaskPool layer. We remove the MaskPool layer from our model to examine its effectiveness. This degraded model D obtains the AP score of 39.4%, AP 50 score of 61.1%, AP 25 score of 72.7%, which are 2.5%, 1.6% and 0.9% lower than the whole model E for AP/AP 50 /AP 25 scores. It demonstrates that the proposed MaskPool is beneficial for 3D instance segmentation. Impacts of Multi-scale Groups. By using hierarchical point grouping, we could make use of clusters in multi-scales for final predictions. Here we elaborate the effectiveness of this multi-scale strategy. <ref type="table">Table 4</ref> shows the results of using groups obtained with different clustering radii. If we use only one clustering radius for grouping, the hierarchical grouping algorithm degrades into a common single-step algorithm. A small grouping radius r=0.01m can mainly group small objects that are closely located. It achieves the AP/AP 50 /AP 25 scores of 37.5%/59.4%/71.0%, which are not satisfactory, because it will drop many points in an object and makes the segmented instances incomplete. The radius of r=0.03 can achieve the best performance among all single radius settings. With a larger radius r=0.05, the results begin to decrease as the large radius will cause some over-grouped instances. Even though r=0.01 can not perform well as other two larger radii, combining the groups obtained by r=0.01 and r=0.03 takes advantage of both scales, which results in better performance than single scale setting, i.e.62.6% vs (59.4%, 61.9%) AP 50 scores. Combining all multi-scale groups obtained with r={0.01, 0.03, 0.05}, it achieves better performance. With even more multi-scale groups, i.e., 4 to 6 scales, the performance will be further improved and begin to converge. These results demonstrate that our hierarchical grouping algorithm can take advantage of multi-scale information to obtain better 3D instance segmentation results. Considering the trade-off between accuracy and complexity, we choose r={0.01, 0.03, 0.05} in our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSION</head><p>In this paper, we propose a novel framework named MaskGroup for accurate 3D instance segmentation. To better group the points in 3D scenes, we propose a Hierarchical Point Grouping algorithm to merge them progressively into groups with different distances. These multi-scale groups are then exploited for instance prediction, which is beneficial for predicting instances with different scales. What's more, we propose a MaskScoreNet to produce binary point masks for all grouped instances and effectively eliminate noisy points from the instances. MaskGroup achieves 66.4% AP 50 on the testing set of ScanNetV2 and outperforms prior methods, demonstrating the effectiveness of our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">APPENDIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Avg <ref type="formula" target="#formula_14">AP50</ref>   <ref type="figure">Fig. 3</ref>. Some 3D instance segmentation results on the validation set of ScanNetV2 obtained by our method. <ref type="table" target="#tab_2">Table 5</ref> lists detailed performance for each category on ScanNetV2 benchmark. Our proposed MaskGroup ranks the 1 st place in 10 out of 18 classes. <ref type="figure">Fig. 3</ref> shows the qualitative results on the validation set of ScanNetV2. The scene in the first row mainly contains some tables and chairs, which can well be separated using the void space. The second row shows a scene with some chairs which are lie very close spatially and our model segments these chairs well. We can also segment different "pillow", even they are located on the bed and are difficult to recognize as shown in the third row. Some instances are not annotated in the ground-truth, like the "refrigerator" in the last row. However, our method can also produce good segmentation results. These results demonstrate that the proposed approach achieves robust instance segmentation results for complex environments.</p><p>We provide some qualitative results of PointGroup <ref type="bibr" target="#b5">[6]</ref> and our proposed MaskGroup, as shown in <ref type="figure">Fig. 5</ref>. Our method obtains better results than PointGroup. We also visualize several failure cases in <ref type="figure">Fig. 4</ref>. In the first row, the doors and cabinets are not perfectly segmented, which exhibit quite similar geometric shapes and close spatial locations. In the second row, there are massive of small objects in the table, making it quite challenging to achieve accuracy instance segmentation. <ref type="figure">Fig. 6</ref> shows the qualitative results of the effectiveness of the mask branch. As we can see, the mask prediction branch can mask out some wrong points for the 2 nd round groups. For example, the instance "bookshelf" has a complicated shape, which is difficult for point grouping. With the help of the proposed mask branch, the instance of the "bookshelf" is well segmented after the mask operation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input Geometry</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GT Semantic</head><p>Predicted Semantic Predicted Instance GT Instance <ref type="figure">Fig. 4</ref>. Visualization of some failure cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PointGroup</head><p>MaskGroup (Ours) GT. Instance </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Illustration of 3D points in complex environment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>The overall architecture of our proposed MaskGroup.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Comparisons of PointGroup and our proposed MaskGroup. Visualization of the hierarchical point grouping and the mask prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Quantitative results on the ScanNetV2 testing set in terms of AP, AP 50 andAP 25 .</figDesc><table><row><cell>Methods</cell><cell></cell><cell cols="2">Publication</cell><cell>AP</cell><cell cols="2">AP50 AP25</cell></row><row><cell>3D-SIS [2]</cell><cell></cell><cell cols="2">CVPR'19</cell><cell>16.1</cell><cell>38.2</cell><cell>55.8</cell></row><row><cell>SALoss [23]</cell><cell></cell><cell cols="2">IROS'20</cell><cell>26.2</cell><cell>45.9</cell><cell>69.5</cell></row><row><cell cols="2">PanopticFusion [24]</cell><cell cols="2">IROS'19</cell><cell>21.4</cell><cell>47.8</cell><cell>69.3</cell></row><row><cell>3D-BoNet [1]</cell><cell></cell><cell cols="3">NeurIPS'19 25.3</cell><cell>48.8</cell><cell>68.7</cell></row><row><cell>3D-MPA [5]</cell><cell></cell><cell cols="2">CVPR'20</cell><cell>35.5</cell><cell>61.1</cell><cell>73.7</cell></row><row><cell>OccuSeg [7]</cell><cell></cell><cell cols="2">CVPR'20</cell><cell>44.3</cell><cell>63.4</cell><cell>73.9</cell></row><row><cell>PointGroup [6]</cell><cell></cell><cell cols="2">CVPR'20</cell><cell>40.7</cell><cell>63.6</cell><cell>77.8</cell></row><row><cell>GICN [25]</cell><cell></cell><cell cols="2">arXiv'20</cell><cell>34.1</cell><cell>63.8</cell><cell>78.8</cell></row><row><cell>DyCo3D [26]</cell><cell></cell><cell cols="2">CVPR'21</cell><cell>39.5</cell><cell>64.1</cell><cell>76.1</cell></row><row><cell>PE [27]</cell><cell></cell><cell cols="2">CVPR'21</cell><cell>39.6</cell><cell>64.5</cell><cell>77.6</cell></row><row><cell cols="2">MaskGroup (Ours)</cell><cell>-</cell><cell></cell><cell>43.4</cell><cell>66.4</cell><cell>79.2</cell></row><row><cell cols="7">Table 2. Comparisons with state-of-the-arts on S3DIS [28].</cell></row><row><cell></cell><cell></cell><cell>Area5</cell><cell></cell><cell></cell><cell>6-Fold</cell><cell></cell></row><row><cell>Methods</cell><cell cols="6">AP50 mPrec mRec AP50 mPrec mRec</cell></row><row><cell>GICN [25]</cell><cell>-</cell><cell>61.5</cell><cell>43.2</cell><cell>-</cell><cell>68.5</cell><cell>50.8</cell></row><row><cell cols="3">PointGroup [6] 57.8 61.9</cell><cell cols="2">62.1 64.0</cell><cell>69.6</cell><cell>69.2</cell></row><row><cell>OccuSeg [7]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>72.8</cell><cell>60.3</cell></row><row><cell>MPNet [29]</cell><cell>-</cell><cell>62.5</cell><cell>49.0</cell><cell>-</cell><cell>68.4</cell><cell>53.7</cell></row><row><cell>InsEmb [30]</cell><cell>-</cell><cell>61.3</cell><cell>48.5</cell><cell>-</cell><cell>67.2</cell><cell>51.8</cell></row><row><cell>DyCo3D [26]</cell><cell>-</cell><cell>64.3</cell><cell>64.2</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>ICM-3D [31]</cell><cell>-</cell><cell>57.4</cell><cell>45.0</cell><cell>-</cell><cell>65.9</cell><cell>49.8</cell></row><row><cell>MaskGroup</cell><cell cols="2">65.0 62.9</cell><cell cols="2">64.7 69.9</cell><cell>66.6</cell><cell>69.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .Table 4 .</head><label>34</label><figDesc>Ablation results using different modules on the ScanNet v2 validation set. Ablation results using different grouping radii.</figDesc><table><row><cell>Score HPG Mask MaskPool</cell><cell>AP</cell><cell cols="2">AP50 AP25</cell></row><row><cell>A</cell><cell>39.9</cell><cell>58.9</cell><cell>70.3</cell></row><row><cell>B</cell><cell>39.2</cell><cell>58.3</cell><cell>71.5</cell></row><row><cell>C</cell><cell>40.4</cell><cell>59.8</cell><cell>70.5</cell></row><row><cell>D</cell><cell>39.4</cell><cell>61.1</cell><cell>72.7</cell></row><row><cell>E</cell><cell>41.9</cell><cell>62.7</cell><cell>73.6</cell></row><row><cell>Hierarchical Grouping</cell><cell>AP</cell><cell cols="2">AP50 AP25</cell></row><row><cell>{0.01}</cell><cell>37.5</cell><cell>59.4</cell><cell>71.0</cell></row><row><cell>{0.03}</cell><cell>41.5</cell><cell>61.9</cell><cell>72.3</cell></row><row><cell>{0.05}</cell><cell>41.4</cell><cell>61.3</cell><cell>72.0</cell></row><row><cell>{0.01, 0.03}</cell><cell>41.5</cell><cell>62.6</cell><cell>72.9</cell></row><row><cell>{0.01, 0.03, 0.05}</cell><cell>41.9</cell><cell>62.7</cell><cell>73.6</cell></row><row><cell>{0.01, 0.03, 0.05, 0.07}</cell><cell>42.1</cell><cell>63.0</cell><cell>73.8</cell></row><row><cell>{0.01, 0.03, 0.05, 0.07, 0.09}</cell><cell>42.2</cell><cell>63.3</cell><cell>74.0</cell></row><row><cell cols="2">{0.01, 0.03, 0.05, 0.07, 0.09, 0.11} 42.0</cell><cell>63.3</cell><cell>74.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5 .</head><label>5</label><figDesc>.390 0.169 0.065 0.275 0.029 0.069 0.000 0.087 0.043 0.014 0.027 0.000 0.112 0.351 0.168 0.438 0.138 3D-SIS<ref type="bibr" target="#b1">[2]</ref> 0.382 1.000 0.432 0.245 0.190 0.577 0.013 0.263 0.033 0.320 0.240 0.075 0.422 0.857 0.117 0.699 0.271 0.883 0.235 PanopticFusion<ref type="bibr" target="#b23">[24]</ref> 0.478 0.667 0.712 0.595 0.259 0.550 0.000 0.613 0.175 0.250 0.434 0.437 0.411 0.857 0.485 0.591 0.267 0.944 0.35 3D instance segmentation results on ScanNetV2<ref type="bibr" target="#b31">[32]</ref> testing set with AP 50 scores. Our method yields the highest average AP 50 performance among all existing methods published in the literature.</figDesc><table><row><cell></cell><cell></cell><cell>bathtub</cell><cell>bed</cell><cell>bookshe.</cell><cell>cabinet</cell><cell>chair</cell><cell>counter</cell><cell>curtain</cell><cell>desk</cell><cell>door</cell><cell>otherfu.</cell><cell>picture</cell><cell>refrige.</cell><cell>s. curtain</cell><cell>sink</cell><cell>sofa</cell><cell>table</cell><cell>toilet</cell><cell>window</cell></row><row><cell cols="19">SGPN [11] 0.208 03D-BoNet [1] 0.143 0.488 1.000 0.672 0.590 0.301 0.484 0.098 0.620 0.306 0.341 0.259 0.125 0.434 0.796 0.402 0.499 0.513 0.909 0.439</cell></row><row><cell>MTML [16]</cell><cell>0.549</cell><cell cols="17">1.000 0.807 0.588 0.327 0.647 0.004 0.815 0.180 0.418 0.364 0.182 0.445 1.000 0.442 0.688 0.571 1.000 0.396</cell></row><row><cell>3D-MPA [5]</cell><cell>0.611</cell><cell cols="17">1.000 0.833 0.765 0.526 0.756 0.136 0.588 0.470 0.438 0.432 0.358 0.650 0.857 0.429 0.765 0.557 1.000 0.430</cell></row><row><cell>PointGroup [6]</cell><cell>0.636</cell><cell cols="17">1.000 0.765 0.624 0.505 0.797 0.116 0.696 0.384 0.441 0.559 0.476 0.596 1.000 0.666 0.756 0.556 0.997 0.513</cell></row><row><cell>GICN [25]</cell><cell>0.638</cell><cell cols="17">1.000 0.895 0.800 0.480 0.676 0.144 0.737 0.354 0.447 0.400 0.365 0.700 1.000 0.569 0.836 0.599 1.000 0.473</cell></row><row><cell>DyCo3D [26]</cell><cell>0.641</cell><cell cols="17">1.000 0.841 0.893 0.531 0.802 0.115 0.588 0.448 0.438 0.537 0.430 0.550 0.857 0.534 0.764 0.657 0.987 0.568</cell></row><row><cell>PE [27]</cell><cell>0.645</cell><cell cols="17">1.000 0.773 0.798 0.538 0.786 0.088 0.799 0.350 0.435 0.547 0.545 0.646 0.933 0.562 0.761 0.556 0.997 0.501</cell></row><row><cell>MaskGroup (Ours)</cell><cell>0.664</cell><cell cols="17">1.000 0.822 0.764 0.616 0.815 0.139 0.694 0.597 0.459 0.566 0.599 0.600 0.516 0.715 0.819 0.635 1.000 0.603</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning object bounding boxes for 3d instance segmentation on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Markham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Trigoni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">3d-sis: 3d semantic instance segmentation of rgb-d scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">JSIS3D: joint semanticinstance segmentation of 3d point clouds with multi-task pointwise networks and multi-value conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quang-Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duc</forename><forename type="middle">Thanh</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binh-Son</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Roig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai-Kit</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Associatively segmenting instances and semantics in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">3d-mpa: Multi-proposal aggregation for 3d semantic instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Bokeloh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Fathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pointgroup: Dual-set point grouping for 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Wing</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Occuseg: Occupancy-aware 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Instance segmentation in 3d scenes using semantic superpoint tree networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songcen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2783" to="2792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hierarchical aggregation for 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiemin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15467" to="15476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">3d-rcnn: Instance-level 3d object reconstruction via render-andcompare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhijit</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">SGPN: similarity group proposal network for 3d point cloud instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiangui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep hough voting for 3d object detection in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Or</forename><surname>Litany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Hierarchy denoising recursive autoencoders for 3d scene layout prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhelun</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1771" to="1780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">3d scene graph: A structure for unified semantics, 3d space, and camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Yang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5664" to="5673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">3d semantic segmentation with submanifold sparse convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Engelcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">3d instance segmentation via multi-task metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Lahoud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin R</forename><surname>Oswald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An empirical study of adder neural networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinghao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minjing</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">3d scene graph: A structure for unified semantics, 3d space, and camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Yang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Amir Roshan Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hierarchy denoising recursive autoencoders for 3d scene layout prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel</forename><forename type="middle">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhelun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Acquisition of localization confidence for accurate object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruixuan</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayuan</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tete</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Gs3d: An efficient 3d object detection framework for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">3d instance embedding learning with a structure-aware loss function for point cloud segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhidong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunxiang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE RA</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Panopticfusion: Online volumetric semantic mapping at the level of stuff and things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaku</forename><surname>Narita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Seno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoya</forename><surname>Ishikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yohsuke</forename><surname>Kaji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IROS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Learning gaussian instance segmentation in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Hung</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shang-Yi</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shao-Chi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwann-Tzong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyng-Luh</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">DyCo3d: Robust instance segmentation of 3d point clouds through dynamic convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Tong He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Point cloud instance segmentation using probabilistic embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Wonka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Amir R Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Brilakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>3d semantic parsing of large-scale indoor spaces,&quot; in CVPR</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning and memorizing representative prototypes for 3d point cloud semantic and instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Instance-aware embedding for point cloud instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Tong He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Icm-3d: Instantiated category modeling for 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruihang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE RA</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Scannet: Richlyannotated 3d reconstructions of indoor scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Angel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manolis</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej</forename><surname>Savva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Halber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nie?ner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
