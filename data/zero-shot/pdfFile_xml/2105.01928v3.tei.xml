<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Instances as Queries</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Fang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EIC</orgName>
								<orgName type="institution">Huazhong University of Science &amp; Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shusheng</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EIC</orgName>
								<orgName type="institution">Huazhong University of Science &amp; Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Applied Research Center (ARC)</orgName>
								<address>
									<postCode>PCG 3</postCode>
									<settlement>Tencent</settlement>
									<region>Tencent</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EIC</orgName>
								<orgName type="institution">Huazhong University of Science &amp; Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Applied Research Center (ARC)</orgName>
								<address>
									<postCode>PCG 3</postCode>
									<settlement>Tencent</settlement>
									<region>Tencent</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Fang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Shan</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Applied Research Center (ARC)</orgName>
								<address>
									<postCode>PCG 3</postCode>
									<settlement>Tencent</settlement>
									<region>Tencent</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EIC</orgName>
								<orgName type="institution">Huazhong University of Science &amp; Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of EIC</orgName>
								<orgName type="institution">Huazhong University of Science &amp; Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Instances as Queries</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, query based object detection frameworks achieve comparable performance with previous state-ofthe-art object detectors. However, how to fully leverage such frameworks to perform instance segmentation remains an open problem. In this paper, we present QueryInst (Instances as Queries), a query based instance segmentation method driven by parallel supervision on dynamic mask heads. The key insight of QueryInst is to leverage the intrinsic one-to-one correspondence in object queries across different stages, as well as one-to-one correspondence between mask RoI features and object queries in the same stage. This approach eliminates the explicit multi-stage mask head connection and the proposal distribution inconsistency issues inherent in non-query based multi-stage instance segmentation methods. We conduct extensive experiments on three challenging benchmarks, i.e., COCO, CityScapes, and YouTube-VIS to evaluate the effectiveness of QueryInst in instance segmentation and video instance segmentation (VIS) task. Specifically, using ResNet-101-FPN backbone, QueryInst obtains 48.1 box AP and 42.8 mask AP on COCO test-dev, which is 2 points higher than HTC in terms of both box AP and mask AP, while runs 2.4 times faster. For video instance segmentation, QueryInst achieves the best performance among all online VIS approaches and strikes a decent speed-accuracy trade-off. Code is available at https://github.com/hustvl/ QueryInst.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Instance segmentation is a fundamental yet challenging computer vision task that requires an algorithm to assign a pixel-level mask with a category label for each instance of interest in image. Prevalent state-of-the-art instance seg-* Equal contributions. This work was done while Shusheng Yang was interning at Applied Research Center (ARC), Tencent PCG. ? Corresponding author, E-mail: xgwang@hust.edu.cn. mentation methods are based on high performing object detectors and follow a multi-stage paradigm. Among which, the Mask R-CNN family <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b41">42]</ref> is the most successful one, where the regions-of-interest (RoI) for instance segmentation is extracted via a region-wise pooling operation (e.g., RoIPool <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b17">18]</ref> or RoIAlign <ref type="bibr" target="#b20">[21]</ref>) based on the box-level localization information from the region proposal network (RPN) <ref type="bibr" target="#b38">[39]</ref>, or the previous stage boundingbox prediction <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. The final instance mask is obtained via feeding the RoI feature into the mask head, which is a small fully convolutional network (FCN) <ref type="bibr" target="#b32">[33]</ref>. Recently, DETR <ref type="bibr" target="#b6">[7]</ref> is proposed to reformulate object detection as a query based direct set prediction problem, whose input is mere 100 learned object queries. Follow-up works <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b13">14]</ref> in object detection improve this query based approach and achieve comparable performance with state-of-the-art detectors such as Cascade R-CNN <ref type="bibr" target="#b3">[4]</ref>. The results show that query based instance-level perception is a very promising research direction. Thus, enabling query based detection framework to perform instance segmentation is highly desirable. However, we find that it is inefficient to integrate the previous successful practices in Cascade Mask R-CNN <ref type="bibr" target="#b4">[5]</ref> and HTC <ref type="bibr" target="#b8">[9]</ref>, which are state-of-the-art mask generation solutions in the non-query based paradigm, directly into query based detectors for instance mask generation. Therefore, an instance segmentation method tailored for the query based end-to-end framework is urgently needed.</p><p>To bridge this gap, we propose QueryInst (Instances as Queries), a query based end-to-end instance segmentation method driven by parallel supervision on dynamic mask heads <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b41">42]</ref>. The key insight of QueryInst is to leverage the intrinsic one-to-one correspondence in object queries across different stages, and one-to-one correspondence between mask RoI features and object queries in the same stage. Specifically, we set up dynamic mask heads in parallel with each other, which transform each mask RoI feature adaptively according to the corresponding query, and are simultaneously trained in all stages. The mask gradient not only flows back to the backbone feature extractor, but also to the object query, which is intrinsically one-toone interlinked in different stages. The queries implicitly carry the multi-stage mask information, which is read by RoI features in dynamic mask heads for final mask generation. There is no explicit connection between different stage mask heads or mask features. Moreover, the queries are shared between object detection and instance segmentation sub-networks in each stage, enabling cross-task communications that one task can take advantage of the information from the other task. We demonstrate that this shared query design can fully leverage the synergy between object detection and instance segmentation. When the training is completed, we throw away all the dynamic mask heads in the intermediate stages and only use the final stage predictions for inference. Under such a scheme, QueryInst surpasses the state-of-the-art HTC in terms of AP while runs much faster. Concretely, our main contributions are summarized as follows:</p><p>? We attempt to solve instance segmentation from a new perspective that uses parallel dynamic mask heads in the query based end-to-end detection framework. This novel solution enables such a new framework to outperform well-established and highly-optimized non-query based multi-stage schemes such as Cascade Mask R-CNN and HTC in terms of both accuracy and speed (see <ref type="figure" target="#fig_0">Fig. 1</ref>). Specifically, using ResNet-101-FPN backbone <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b26">27]</ref> ? We set up a task-joint paradigm for query based ob-ject detection and instance segmentation by leveraging the shared query and multi-head self-attention design. This paradigm establishes a kind of communication and synergy between detection and segmentation tasks, which encourages this two tasks to benefits from each other. We demonstrate that our architecture design can also significantly improve the object detection performance.</p><p>? We extend the QueryInst to video instance segmentation task (VIS) <ref type="bibr" target="#b56">[57]</ref> task by simply adding a vanilla track head. Experiments on YouTube-VIS dataset <ref type="bibr" target="#b56">[57]</ref> indicate that with same tracking approach, our methods outperforms MaskTrack R-CNN <ref type="bibr" target="#b56">[57]</ref> and SipMask-VIS <ref type="bibr" target="#b5">[6]</ref> by a large margin. QueryInst-VIS can even outperform well-designed VIS approaches such as STEm-Seg <ref type="bibr" target="#b0">[1]</ref> and VisTR <ref type="bibr" target="#b52">[53]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Query Based Methods. Recently, query based methods emerged to tackle the set-prediction problems. Concretely, DETR <ref type="bibr" target="#b6">[7]</ref> first introduces the query based methods with transformer architecture to object detection. Deformable DETR <ref type="bibr" target="#b61">[62]</ref>, UP-DETR <ref type="bibr" target="#b13">[14]</ref>, ACT <ref type="bibr" target="#b57">[58]</ref> and TSP <ref type="bibr" target="#b42">[43]</ref> improve the performance on the top of DETR. The recently proposed Sparse R-CNN <ref type="bibr" target="#b41">[42]</ref> builds a query based setprediction framework upon R-CNN <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b38">39]</ref> based detector. For segmentation, VisTR <ref type="bibr" target="#b52">[53]</ref> introduces a query based sequence matching and segmentation method to video instance segmentation, building a fully end-toend framework for instance segmentation in video. Max-DeepLab <ref type="bibr" target="#b48">[49]</ref> presents the first box-free end-to-end panoptic segmentation model with a global memory as external query. Trackformer <ref type="bibr" target="#b34">[35]</ref> and Transtrack <ref type="bibr" target="#b40">[41]</ref> build a query based multiple object tracktor upon DETR and Deformable DETR, respectively, and attain comparable results to the non-query based methods. AS-Net <ref type="bibr" target="#b10">[11]</ref> introduces a query based set-prediction pipeline to human object interaction and obtains promising results. Despite query based setprediction method is being widely used to many computer vision tasks, few efforts are conducted to build a successful query based instance segmentation framework. We aim to achieve this goal in this paper.</p><p>Object Detection. Object detection is a fundamental computer vision task which aims to detect visual objects with bounding boxes. With the propose of R-CNN <ref type="bibr" target="#b18">[19]</ref>, Fast R-CNN <ref type="bibr" target="#b17">[18]</ref> and Faster R-CNN <ref type="bibr" target="#b38">[39]</ref>, anchor based methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b30">31]</ref> dominate object detection for a long period. CenterNet <ref type="bibr" target="#b59">[60]</ref> and FCOS <ref type="bibr" target="#b44">[45]</ref> establish anchor-free detectors with competitive detection performance. Recently, with the proposed DETR <ref type="bibr" target="#b6">[7]</ref>, query based set-prediction methods catch lots of attentions. Deformable DETR <ref type="bibr" target="#b61">[62]</ref> introduces deformable convolution <ref type="bibr" target="#b60">[61]</ref> to the DETR framework, achieving better performance with faster training convergence. UP-DETR <ref type="bibr" target="#b13">[14]</ref> extends DETR to unsupervised scenarios. ACT <ref type="bibr" target="#b57">[58]</ref> and TSP <ref type="bibr" target="#b42">[43]</ref> introduce the adaptive clustering module and a new bipartite matching method to DETR. Sparse R-CNN <ref type="bibr" target="#b41">[42]</ref> build a query based detector on top of R-CNN architecture, while OneNet <ref type="bibr" target="#b39">[40]</ref> and DeFCN <ref type="bibr" target="#b49">[50]</ref> are end-to-end detector built upon the onestage FCOS <ref type="bibr" target="#b44">[45]</ref>. In this work, we present a query based instance segmentation method on the top of the query based Sparse R-CNN detector.</p><p>Instance Segmentation. Instance segmentation is a fundamental yet challenging computer vision task that requires an algorithm to assign a pixel-level mask with a category label for each instance of interest in image. Mask R-CNN <ref type="bibr" target="#b20">[21]</ref> introduces a fully convolutional mask head to Faster R-CNN <ref type="bibr" target="#b17">[18]</ref> detector. Casacde Mask R-CNN <ref type="bibr" target="#b4">[5]</ref> simply combine the Casacde R-CNN <ref type="bibr" target="#b3">[4]</ref> with Mask R-CNN. HTC <ref type="bibr" target="#b8">[9]</ref> presents interleaved execution and mask information flow and achieves state-of-the-art performance.</p><p>In addition to R-CNN based methods, YOLACT <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b1">2]</ref>, Sip-Mask <ref type="bibr" target="#b5">[6]</ref>, CondInst <ref type="bibr" target="#b45">[46]</ref> and SOLO <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b51">52]</ref> build one-stage instance segmentation framework on the top of one-stage framework, achieving comparable results with favorable inference speed. Following the R-CNN based methods, we present a query based instance segmentation framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Instances as Queries</head><p>We propose QueryInst (Instances as Queries), a query based end-to-end instance segmentation method. QueryInst consists of a query based object detector and six dynamic mask heads driven by parallel supervision. Our key insight is to leverage the intrinsic one-to-one correspondence in queries across different stages. This correspondence exists in all query based framework <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b6">7]</ref> regardless of the specific instantiations and applications. The overall architecture of QueryInst is illustrated in <ref type="figure" target="#fig_1">Fig. 2</ref> (c).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Query based Object Detector</head><p>QueryInst can be built on any multi-stage query based object detector <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b41">42]</ref>. We choose Sparse R-CNN <ref type="bibr" target="#b41">[42]</ref> as our default instantiation, which has six query stages. The object detection pipeline is depicted in <ref type="figure" target="#fig_1">Fig. 2</ref> (a) and can be formulated as follows:</p><formula xml:id="formula_0">x box t ? P box x FPN , b t?1 , q * t?1 ? MSA t q t?1 , x box * t , q t ? DynConv box t x box t , q * t?1 , b t ? B t x box * t ,<label>(1)</label></formula><p>where q ? R N ?d denotes the object query. N and d denote the length (number) and dimension of query q. At </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Mask Head Architecture</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Vanilla Mask Head</head><p>For instance mask prediction, we first adopt the widely used vanilla mask head architecture design in Mask R-CNN <ref type="bibr" target="#b20">[21]</ref> as our instance segmentation baseline. The model architecture is depicted in <ref type="figure" target="#fig_1">Fig. 2 (b)</ref>. Based on the object detection is enhanced by two consecutive conv-layers, whose kernel parameters are produced by q * t?1 .</p><p>pipeline described in Sec. 3.1, the mask generation process can be expressed as follows:</p><formula xml:id="formula_1">x mask t ? P mask x FPN , b t , m t ? M t x mask t ,<label>(2)</label></formula><p>where b t is the bounding box predictions from the object detector. P mask denotes a region-wise pooling operator for mask RoI features extraction. M t indicates the mask FCN head consisting of a stack of four consecutive conv-layers, one dconv-layer and one 1 ? 1 conv-layer for mask generation <ref type="bibr" target="#b20">[21]</ref>. m t is the current stage mask predictions.</p><p>Overall, this vanilla design is an analogy of Cascade Mask R-CNN <ref type="bibr" target="#b4">[5]</ref> in a query based framework. However, we find that this design is not as effective as the original Cascade Mask R-CNN. Moreover, establishing explicit mask flow following HTC <ref type="bibr" target="#b8">[9]</ref> on top of this design ( <ref type="figure" target="#fig_1">Fig. 2 (b)</ref>) can only bring moderate improvements at a cost of large drops in both training and inference speed. Part of the reasons may be the number of queries in our framework is much smaller than the number of proposals in Cascade Mask R-CNN and HTC, resulting in limited availability of training samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Dynamic Mask Head</head><p>Our goal is to design a mask prediction head tailor-made for query based instance segmentation frameworks. To this end, we propose to leverage dynamic mask heads driven by parallel supervision to replace the vanilla design in Sec. 3.2.1. The dynamic mask head at stage t consists of a dynamic mask convolution module DynConv mask t (see <ref type="figure" target="#fig_2">Fig. 3</ref>) <ref type="bibr" target="#b41">[42]</ref> following by a vanilla mask head M t <ref type="bibr" target="#b20">[21]</ref>. The mask generation pipeline is reformulated as follows:</p><formula xml:id="formula_2">x mask t ? P mask x FPN , b t , x mask * t ? DynConv mask t x mask t , q * t?1 , m t ? M t x mask * t .<label>(3)</label></formula><p>It is noteworthy that the only difference between the proposed dynamic mask head and vanilla mask head is the existence of DynConv mask t . We demonstrate that DynConv mask t enables (1) per-mask information flow in queries driven by parallel mask branch supervision, and (2) communication and synergy for joint detection and instance segmentation in the following two sub-sections, respectively. The effectiveness of these two properties is verified in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Per-mask Information Flow with Parallel Supervision</head><p>In query based models such as <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b41">42]</ref>, the model learns different specialization for each query slot <ref type="bibr" target="#b6">[7]</ref>, i.e., q t [s] is the transformed and refined version of previous stage q t?1 [s] in the same s-th slot. Moreover, x mask t [s] corresponds to and is refined by q t [s] <ref type="bibr" target="#b41">[42]</ref>. Therefore there is an one-to-one correspondence across different stage queries inherent in these frameworks, as well as one-to-one correspondence between mask RoI features and object queries in the same stage.</p><p>QueryInst is driven by parallel supervision on dynamic mask heads, which fully leverages the intrinsic one-to-one correspondence in object queries across different stages. Specifically, we set up dynamic mask heads in parallel with each other, which transform each mask RoI feature x mask t adaptively in DynConv mask t according to the corresponding query q * t?1 , and are simultaneously trained in all stages. Inside DynConv mask t , the query acts as memory and is read by mask RoI features x mask t in the forward pass and written by x mask t in the backward pass. During training, the per-mask information (i.e., the mask gradient) not only flows back to mask RoI features x mask t , but also to the object query q * t?1 , which is intrinsically one-to-one interlinked in different stages. Therefore the per-mask information flow is naturally established by leveraging the inherent properties of query based frameworks, with no additional connection needed. After the training is completed, the information for mask prediction is stored in queries.</p><p>During inference, we throw away all dynamic mask heads in 5 intermediate stages and only use the final stage predictions for inference. The queries implicitly carry the multi-stage information for mask prediction, which is read by mask RoI features x mask t in dynamic mask convolution DynConv mask t at the last stage for final mask generation. Without DynConv mask t , the link between mask RoI features and the query is lost, and mask heads in different stages are isolated. Even though parallel supervision is applied to all mask heads, the information related to mask generation cannot flow into queries. In this condition, QueryInst degenerates to Cascade Mask R-CNN with a fixed number (i.e., N ) of proposals across all stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Shared Query and MSA for Joint Detection and Segmentation</head><p>At stage t, a multi-head self-attention MSA t is applied to the query q t?1 . MSA t projects the query q t?1 to a high dimensional embedding space and its output q * t?1 is read by the dynamic box convolution DynConv box t and dynamic mask convolution DynConv mask t respectively, to enhance the task-specific features x box t and x mask t . Throughout this process, the query and MSA are shared between detection and instance segmentation tasks. Both detection and segmentation information flow back into the query through MSA. This task-joint paradigm establishes a kind of communication and synergy between detection and segmentation tasks, which encourages these two tasks to benefits from each other. The query learns a better instancelevel representation with the guidance of two highly correlated tasks. We observe a performance decrease using separate queries or MSA in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Comparisons with Cascade Mask R-CNN and HTC</head><p>Cascade Mask R-CNN <ref type="bibr" target="#b4">[5]</ref> presents a multi-stage architecture to resample with higher intersection over union (IoU) thresholds for the latter stages, and progressively refine the training distributions of region proposals <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. This resampling operation guarantees the availability of a large number of accurate localized proposals for the final stage. Despite outperforming non-cascade counterparts, the effectiveness of Cascade Mask R-CNN mainly stems from the progressively refined proposal recall. Whereas, the mask heads across different stages are isolated, and the input feature for mask head always come from the same FPN feature regardless of the stage.</p><p>To mitigate the aforementioned drawback of Cascade Mask R-CNN, HTC <ref type="bibr" target="#b8">[9]</ref> improves Cascade Mask R-CNN by introducing direct and explicit connections across the mask heads at different stages. The current stage mask features are combined with the accumulated mask features from all previous stages. Equivalently, the mask head of the final stage is 3? deeper than the first stage. Therefore the final stage mask prediction can benefit from deeper features. Establishing direct mask information flow as HTC can alleviate the issue in Cascade Mask R-CNN to some extent. However, this explicit connection across mask heads at different R-CNN stages results in inefficient training and inference.</p><p>There are some potential issues inherent in the aforementioned non-query based instance segmentation paradigms. For Cascade Mask R-CNN and HTC, the quality of proposals in different stages is refined in the statistical sense <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9]</ref>. For each stage, the number and distribution of training samples are quite different, and there is no explicit and intrinsic correspondence for each individual proposal across different stages <ref type="bibr" target="#b58">[59]</ref>. Moreover, there is also a mismatch between the training and inference sample distribution <ref type="bibr" target="#b47">[48]</ref>. Therefore, introducing direct connections at the architecture-level is necessary for the mask heads in different stages to explicitly learn the correspondence <ref type="bibr" target="#b8">[9]</ref>.</p><p>Our method does not directly solve the aforementioned issues, but bypasses them. For QueryInst, the connections across stages are naturally established by one-to-one correspondence inherent in queries. This approach eliminates the explicit multi-stage mask head connection and the proposal distribution inconsistency issues. We show that the proposed new paradigm can surpass Cascade Mask R-CNN and HTC in terms of both accuracy and speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">QueryInst-VIS for Video Instance Segmentation</head><p>Video instance segmentation (VIS) <ref type="bibr" target="#b56">[57]</ref> is a highly relevant task to still-image instance segmentation that aims at detecting, classifying, segmenting and tracking visual instances over video frames. We demonstrate that QueryInst can be easily extended to VIS with minimal modifications by simply adding the vanilla track head in Mask-Track R-CNN baseline <ref type="bibr" target="#b56">[57]</ref>. The proposed model coined as QueryInst-VIS can perform video instance segmentation in an online manner while operating at real-time. The total training and inference pipeline keep the same as Mask-Track R-CNN. We evaluate QueryInst-VIS on the challenging YouTube-VIS <ref type="bibr" target="#b56">[57]</ref> benchmark to demonstrate its effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Dataset</head><p>COCO. Most of our experiments are conducted on the challenging COCO dataset <ref type="bibr" target="#b28">[29]</ref>. Following the common practice, we use the COCO train2017 split (115k images) for training and the val2017 split (5k images) as validation for our ablation study. We report our main results on the testdev split (20k images). Cityscapes. Cityscapes <ref type="bibr" target="#b11">[12]</ref> is an ego-centric street-scene dataset with 8 categories, 2975 train images, and 500 validation images for instance segmentation. The images are with higher resolution (1024 ? 2048 pixels) compared with COCO, and have more pixel-accurate ground-truth. YouTube-VIS. In addition to static-image instance segmentation, we demonstrate the effectiveness of our QueryInst on video instance segmentation. YouTube-VIS <ref type="bibr" target="#b56">[57]</ref> is a challenging dataset for video instance segmentation task, which has a 40-category label set, 4, 883 unique video instances and 131k high-quality manual annotations. There are 2, 238 training videos, 302 validation videos, and 343 test videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>Training Setup. Our implementation is based on MMDetection <ref type="bibr" target="#b9">[10]</ref> and Detectron2 <ref type="bibr" target="#b53">[54]</ref>. Following <ref type="bibr" target="#b41">[42]</ref>, the default training schedule is 36 epochs and the initial learning rate is set to 2.5 ? 10 ?5 , divided by 10 at 27-th epoch and <ref type="bibr" target="#b32">33</ref>  <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b41">42]</ref>. In total, the R-CNN head of QueryInst contains 6 stages in parallel as <ref type="bibr" target="#b41">[42]</ref>. The mask head is trained by minimizing dice loss <ref type="bibr" target="#b35">[36]</ref>. Without special mentioning, we adopt QueryInst model trained with 100 queries and ResNet-50-FPN <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b26">27]</ref> as backbone in our experiments in the ablation studies. Inference. Given an input image, QueryInst directly outputs top 100 bounding box predictions with their scores and corresponding instance masks without further postprocessing. For inference, we use the final stage masks as the predictions and ignore all the parallel DynConv mask at the intermediate stages. The inference speed reported is measured using a single Titan Xp GPU with inputs resized to have their shorter side being 800 and their longer side less or equal to 1333.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Main Results</head><p>Comparisons on COCO Instance Segmentation.</p><p>The comparison of QueryInst with the state-of-the-art instance segmentation methods on COCO test-dev are listed in Tab. 1. We have tested different backbones and data augmentations. CondInst <ref type="bibr" target="#b45">[46]</ref> (with auxiliary semantic branch) and SOLOv2 <ref type="bibr" target="#b51">[52]</ref> are the latest state-of-the-art in-stance segmentation approach based on dynamic convolutions. A 5-stage QueryInst trained with 100 queries outperforms them with over 1.1 mask AP gain under similar inference speed. QueryInst trained with 100 queries can also surpass Cascade Mask R-CNN [21] by 1.5 mask AP while runs with the same FPS. For fair comparisons with HTC <ref type="bibr" target="#b8">[9]</ref>, we train HTC using the 36 epochs training schedule and multi-scale data augmentations following the standard setting in <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b53">54]</ref>, yielding ? 1 higher mask AP than original results reported in <ref type="bibr" target="#b8">[9]</ref>. Under same experimental conditions, QueryInst outperforms the state-ofthe-art HTC in terms of both accuracy and speed. Moreover, QueryInst outperforms HTC in terms of AP at different IoU thresholds (AP 50 and AP 75 ) as well as AP at different scales (AP S , AP M and AP L ), regardless of the experimental configuration. We also find that compared with Cascade Mask R-CNN and HTC, the query based QueryInst can benefit more from stronger data argumentation used in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b41">42]</ref>    We also apply QueryInst to the recent state-of-the-art Swin Transformer <ref type="bibr" target="#b31">[32]</ref> backbone without further modifications, and we find the proposed model is quite capable of adapting with Swin-L. Without bells and whistles, QueryInst can achieve the art performance in instance segmentation 2 as well as object detection <ref type="bibr" target="#b2">3</ref> . For the first time, we demonstrate that an end-to-end query based framework driven by parallel supervision is competitive with wellestablished and highly-optimized methods in instance-level recognition tasks. Comparisons on Cityscapes Instance Segmentation. We also conduct experiments on Cityscapes dataset to demonstrate the generalization of QueryInst. Following the standard setting in <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b20">21]</ref>, all models are first pre-trained on COCO train2017 split then finetuned on Cityscapes using fine annotations for 24k iterations with batch size 8 (1 image per GPU). The initial learning rate is linearly scaled to 1.25 ? 10 ?5 and is reduced by a factor of 10 at step 18k.</p><p>The results are shown in Tab.      <ref type="table">Table 6</ref>: Impacts of using shared query and MSA.</p><p>VIS model on YouTube-VIS train set for 12 epochs. The maximum number of instances in one frame in YouTube-VIS dataset is 10, so we set the number of queries to 10 in QueryInst-VIS. The setting enables the model to operate at real-time (&gt; 30 FPS).</p><p>As mentioned in Sec. 3.6, QueryInst-VIS adopts the vanilla track method of MaskTrack R-CNN <ref type="bibr" target="#b56">[57]</ref> and SipMask-VIS <ref type="bibr" target="#b5">[6]</ref>, while it obtains 4.3 AP improvement compared to MaskTrack R-CNN and 2.1 AP improvement compared to SipMask-VIS. Moreover, QueryInst can outperform many well-established and highly-optimized VIS approaches, such as STEm-Seg, CompFeat and VisTR in terms of both accuracy and speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>Study of Parallel Supervision and DynConv mask . We show that applying parallel mask head supervision and DynConv mask are both indispensable for good performance. As shown in Tab. 5, using parallel supervision on vanilla mask head cannot bring large improvement, because mask heads in different stages are isolated and there is no cross-stage per-mask information flow established (Sec. 3.2.1). Using DynConv mask without parallel super- vision on each stage can only bring moderate improvement, for mask gradients injected from the final stage cannot fully driven the per-mask information flow across queries in all stages. When DynConv mask in all stages are driven by parallel supervision simultaneously, QueryInst achieves significant improvement in accuracy with only little drops in inference speed. The reason is that during inference, we throw away all the parallel DynConv mask in the intermediate stage and only use the final stage mask predictions. The per-mask information is written and preserved in queries during training, which only need to be read out at the final stage during inference. Study of Query and MSA. Tab. 6 studies the impact of using shared query and MSA. As expected in Sec. 3.4, using shared query and MSA simultaneously establishes a kind of communication and synergy between detection and segmentation tasks, which encourages this two tasks to benefits from each other and achieves the highest box AP and mask AP. Moreover, this configuration consumes minimal parameters and computation budgets. Therefore we choose using shared query and MSA as the default instantiation of our QueryInst.  tectures on query and non-query based frameworks. All stages are simultaneously trained. For non-query based frameworks, the 1-st row is the results of Cascade Mask R-CNN <ref type="bibr" target="#b4">[5]</ref> and the 2-nd row is HTC <ref type="bibr" target="#b8">[9]</ref>. We have the following 3 major observations. First, we find that directly integrating cascade mask head <ref type="bibr" target="#b4">[5]</ref> and HTC mask flow <ref type="bibr" target="#b8">[9]</ref> into the query based model is not as effective as in its original framework. When cascade mask head is applied (3-th row), the query based model is 0.5 AP box and 0.6 AP mask lower than the original Cascade Mask R-CNN (1-th row). When HTC mask flow is applied (4-th row), the query based model is 0.6 AP box and 0.4 AP mask lower than the original HTC (2-th row). These results demonstrate that previous successful empirical practice from non-query based multi-stage models is possibly inadequate for query based models (Sec. 3.2.1).</p><p>Second, when the proposed parallel DynConv mask is applied to the query based model, QueryInst (5-th row) outperforms the baseline (3-th row) by 0.7 AP box and 1.9 AP mask , while maintaining a high FPS. Moreover, QueryInst also beat original HTC (2-th row) in terms of both AP box and AP mask while runs about 3? faster. <ref type="figure" target="#fig_5">Fig. 4</ref> demonstrates the effects of DynConv mask qualitatively.</p><p>Last, we also find that for query based approaches, HTC mask flow cannot bring further improvement on top of parallel DynConv mask architecture <ref type="bibr">(6-th row</ref>  that the proposed parallel DynConv mask enables adequate mask information flow propagating across queries in different stage for high quality mask generation. Therefore establishing explicit mask feature flow as HTC is redundant and is harmful for model efficiency. In consideration of the speed-accuracy trade-off, we choose <ref type="figure" target="#fig_1">Fig. 2</ref> (c) as as the default instantiation of our QueryInst.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose an efficient query based endto-end instance segmentation framework, QueryInst, driven by parallel supervision on dynamic mask heads. To our knowledge, QueryInst is the first query based instance segmentation method that outperforms previous state-of-the-art non-query based instance segmentation approaches. Extensive study proves that parallel mask supervision can bring great performance improvement without any decent for inference speed, while dynamic mask head with both shared query and MSA joints two sub-tasks of detection and segmentation naturally. We hope this work can strength the understanding of query based frameworks and facilitate future research. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Illustration of 4 Different Query and MSA Configurations</head><p>We study the impact of using shared query and shared MSA in the paper. <ref type="figure">Fig. 5</ref> gives an illustration for our ablation study. <ref type="figure">Fig. 5</ref> from left to right corresponds to configurations in Tab. 6 in our paper from top to bottom. Using the shared query and shared MSA configuration, QueryInst achieves the best performance in terms of both box AP and mask AP with the least additional overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training Time of QueryInst</head><p>Here, we compare the training time of QueryInst with the state-of-the-art instance segmentation method HTC <ref type="bibr" target="#b8">[9]</ref>. As shown in Tab 7, under the same experimental configuration, QueryInst outperforms HTC using less training time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of Different Training Schedules and Data Augmentations to the Mask R-CNN Family</head><p>In Tab. 1, we find that for Cascade Mask R-CNN and HTC, stronger data augmentation cannot bring significant improvements under the 3? training schedule. Here we give a detailed experimental study in Tab. 8.</p><p>We choose Mask R-CNN with ResNet-101-FPN backbone as a representative. Using modest data augmentation (640 ? 800), the 3? schedule works well for the model to converge to near optimum, the performance begins to degenerate under longer training schedules. These findings are consistent with <ref type="bibr" target="#b19">[20]</ref>.</p><p>Using stronger data augmentation (480 ? 800, w/ crop) cannot bring further improvements under the 3? schedule, but can boost the performance as the training time becomes longer.</p><p>Compared with the Mask R-CNN family (Mask R-CNN, Cascade Mask R-CNN &amp; HTC), the proposed QueryInst can benefit from stronger data augmentation even under the 3? schedule. We will conduct further study of these properties in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qualitative Results on COCO</head><p>We provide some qualitative results on COCO <ref type="bibr" target="#b28">[29]</ref> val split in <ref type="figure" target="#fig_6">Fig. 6</ref>. <ref type="figure" target="#fig_7">Fig. 7</ref> gives some qualitative results on Cityscapes <ref type="bibr" target="#b11">[12]</ref> test split.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qualitative Results on Cityscapes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional Visualization of Dynamic Mask Feature</head><p>In <ref type="figure" target="#fig_8">Fig. 8</ref>, we provide more visualization results to study the effects of DynConv mask . The first row shows mask features x mask directly extracted from FPN. The second row shows mask features x mask * enhanced by queries in DynConv mask . The last row is ground-truth instance masks. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>AP vs. FPS on COCO test-dev. QueryInst outperforms current state-of-the-art methods in terms of both accuracy and speed. The speed is measured using a single Titan Xp GPU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>(c) QueryInst with dynamic mask head (b) Sparse R-CNN with vanilla mask head (a) Sparse R-CNN Overview of QueryInst. The red arrows indicate mask branches. Please note that QueryInst consists of 6 stage in parallel, i.e., t = {1, 2, 3, 4, 5, 6}. The figure only shows 2 stages. stage t, a pooling operator P box extracts the current stage bounding box features x box t from FPN [27] features x FPN under the guidance of previous stage bounding box predictions b t?1 . Meanwhile, a multi-head self-attention module MSA t is applied to the input query q t?1 to get the transformed query q * t?1 . Then, a box dynamic convolution module DynConv box t takes x box t and q * t?1 as inputs and enhances the x box t by reading q * t?1 while generating q t for the next stage. Finally, the enhanced bounding box features x box * t are fed into the box prediction branch B t for current bounding box prediction b t .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Illustrations of DynConv mask t at stage t. x mask * t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 2</head><label>2</label><figDesc>0.0 38.9 + 1.0 6.0 ? 5.1 Fig. 2 (c) 44.5 + 0.7 39.8 + 1.9 10.5 ? 0.6 44.4 + 0.6 40.0 + 2.1 5.4 ? 5.7</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Effects of DynConv mask . The first row shows mask features x mask directly extracted from FPN. The second row shows mask features x mask * enhanced by queries in DynConv mask . Last row is ground-truth instance masks. The results show that mask features enhanced by queries yield more genuine and accurate details and carry more information of instances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :</head><label>6</label><figDesc>Object detection and instance segmentation qualitative results on COCO val split.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 :</head><label>7</label><figDesc>Object detection and instance segmentation qualitative results on Cityscapes test split.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>More visualization results on the study of DynConv mask .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>, QueryInst obtains 48.1 AP box and 42.8 AP mask on COCO test-dev, which is 2 point higher than HTC in terms of both box AP and mask AP, while runs 2.4? faster. Without bells and whistles,</figDesc><table /><note>our best model achieves 50.4 AP box and 46.6 AP mask on COCO test-dev.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>-th epoch, respectively. We adopt AdamW optimizer with Method Backbone Aug. Epochs AP box AP AP 50 AP 75 AP S AP M AP L FPS Mask R-CNN [21] ResNet-50-FPN 640 ? 800 36 41.3 37.5 59.3 40.2 21.1 39.6 48.3 14.0 CondInst w/ sem. [46] -38.6 60.2 41.4 20.6 41.0 51.1 14.1 SOLOv2 [51] 40.4 38.8 59.9 41.7 16.5 41.7 56.2 13.8 QueryInst (5 Stage, 100 Queries) 44.5 39.9 62.2 43.0 22.9 41.7 51.9 13.5</figDesc><table><row><cell>Cascade Mask R-CNN [5]</cell><cell></cell><cell></cell><cell></cell><cell>44.5 38.6 60.0 41.7 21.7 40.8 49.6 10.4</cell></row><row><cell>HTC [9] QueryInst (100 Queries)</cell><cell cols="2">ResNet-50-FPN 640 ? 800</cell><cell>36</cell><cell>44.9 39.7 61.4 43.1 22.6 42.2 50.6 3.1 44.8 40.1 62.3 43.4 23.3 42.1 52.0 10.5</cell></row><row><cell>QueryInst (300 Queries)</cell><cell></cell><cell></cell><cell></cell><cell>45.6 40.6 63.0 44.0 23.4 42.5 52.8 7.0</cell></row><row><cell>Cascade Mask R-CNN</cell><cell></cell><cell></cell><cell></cell><cell>45.7 39.8 61.6 43.0 22.4 42.2 50.8 8.7</cell></row><row><cell>HTC</cell><cell cols="2">ResNet-101-FPN 640 ? 800</cell><cell>36</cell><cell>46.2 40.7 62.7 44.2 23.1 43.4 52.7 2.5</cell></row><row><cell>QueryInst (300 Queries)</cell><cell></cell><cell></cell><cell></cell><cell>47.0 41.7 64.4 45.3 24.2 43.9 53.9 6.1</cell></row><row><cell>Cascade Mask R-CNN</cell><cell></cell><cell></cell><cell></cell><cell>46.2 40.0 61.7 43.5 22.5 42.5 51.2 8.7</cell></row><row><cell>HTC Sparse R-CNN (300 Queries)</cell><cell>ResNet-101-FPN</cell><cell>480 ? 800 w/ crop</cell><cell>36</cell><cell>46.3 40.8 62.6 44.3 23.0 43.5 52.6 2.5 46.3 ? ? ? ? ? ? 6.9</cell></row><row><cell>QueryInst (300 Queries)</cell><cell></cell><cell></cell><cell></cell><cell>48.1 42.8 65.6 46.7 24.6 45.0 55.5 6.1</cell></row><row><cell>QueryInst (300 Queries)</cell><cell>ResNeXt-101-FPN w/ DCN</cell><cell>480 ? 800 w/ crop</cell><cell>36</cell><cell>50.4 44.6 68.1 48.7 26.6 46.9 57.7 3.1</cell></row><row><cell>QueryInst (300 Queries) @ val</cell><cell>Swin-L</cell><cell>400 ? 1200 w/ crop</cell><cell>50</cell><cell>56.1 48.9 74.0 53.9 30.8 52.6 68.3 3.3</cell></row><row><cell>QueryInst (300 Queries)</cell><cell>Swin-L</cell><cell>400 ? 1200 w/ crop</cell><cell>50</cell><cell>56.1 49.1 74.2 53.8 31.5 51.8 63.2 3.3</cell></row></table><note>Main results on COCO test-dev. The numbers under "Aug." indicate the scale range of the shorter size of inputs with a stride of 32. AP box denotes box AP. AP without superscript denotes mask AP. The best results are in bold for each configuration. Superscript " " indicates the FPS data are measured on a single RTX 2080Ti GPU with batch size 1.1 ? 10 ?4 weight decay. Hyper-parameters, configurations as well as the label assignment procedures follow the setting in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>QueryInst surpasses HTC by 2.0 mask AP and 1.8 box AP while runs 2.4? faster. Further, QueryInst Method Backbone AP val AP AP 50 person rider car trunk bus train mcycle bicycle Mask R-CNN [21] ResNet-50 36.4 32.0 58.1 34.8 27.0 49.1 30.1 40.9 30.9 24.1 18.7 BShapeNet+ [26] ResNet-50 ? 32.9 58.8 36.6 24.8 50.4 33.7 41.0 33.7 25.4 17.8 UPSNet [56] ResNet-50 37.8 33.0 59.7 35.9 27.4 51.9 31.8 43.1 31.4 23.8 19.1 CondInst [46] ResNet-50 37.5 33.2 57.2 35.1 27.7 54.5 29.5 42.3 33.8 23.9 18.9 CondInst [46] w/ sem. DCN-101-BiFPN 39.3 33.9 58.2 35.6 28.1 55.0 32.1 44.2 33.6 24.5 18.6 QueryInst ResNet-50 39.4 34.4 59.6 40.4 30.7 56.8 29.1 40.5 30.8 26.0 21.1</figDesc><table><row><cell>1 . Specifically, using ResNet-101-FPN [27]</cell></row><row><cell>backbone and stronger multi-scale data argumentation with</cell></row><row><cell>random crop,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Instance segmentation results on Cityscapes val (AP val column) and test (remain columns) split. The best results are in bold.</figDesc><table><row><cell>Method</cell><cell>Backbone</cell><cell>AP</cell><cell>AP 50</cell><cell>AP 75</cell><cell>AR 1</cell><cell>AR 10</cell><cell>FPS</cell></row><row><cell>MaskTrack R-CNN [57]</cell><cell>ResNet-50</cell><cell>30.3</cell><cell>51.1</cell><cell>32.6</cell><cell>31.0</cell><cell>35.5</cell><cell>22.1</cell></row><row><cell>SipMask-VIS [6]</cell><cell>ResNet-50</cell><cell>32.5</cell><cell>53.0</cell><cell>33.3</cell><cell>33.5</cell><cell>38.9</cell><cell>30.9</cell></row><row><cell>SipMask-VIS  *</cell><cell>ResNet-50</cell><cell>33.7</cell><cell>54.1</cell><cell>35.8</cell><cell>35.4</cell><cell>40.1</cell><cell>30.9</cell></row><row><cell>STEm-Seg [1]</cell><cell>ResNet-50</cell><cell>30.6</cell><cell>50.7</cell><cell>33.5</cell><cell>31.6</cell><cell>37.1</cell><cell>4.4</cell></row><row><cell>STEm-Seg</cell><cell>ResNet-101</cell><cell>34.6</cell><cell>55.8</cell><cell>37.9</cell><cell>34.4</cell><cell>41.6</cell><cell>2.1</cell></row><row><cell>CompFeat [16]</cell><cell>ResNet-50</cell><cell>35.3</cell><cell>56.0</cell><cell>38.6</cell><cell>33.1</cell><cell>40.3</cell><cell>-</cell></row><row><cell>VisTR [53]</cell><cell>ResNet-50</cell><cell>34.4</cell><cell>55.7</cell><cell>36.5</cell><cell>33.5</cell><cell>38.9</cell><cell>30.0</cell></row><row><cell>VisTR</cell><cell>ResNet-101</cell><cell>35.3</cell><cell>57.0</cell><cell>36.2</cell><cell>34.3</cell><cell>40.4</cell><cell>27.7</cell></row><row><cell>QueryInst-VIS</cell><cell>ResNet-50</cell><cell>34.6</cell><cell>55.8</cell><cell>36.5</cell><cell>35.4</cell><cell>42.4</cell><cell>32.3</cell></row><row><cell>QueryInst-VIS  *</cell><cell>ResNet-50</cell><cell>36.2</cell><cell>56.7</cell><cell>39.7</cell><cell>36.1</cell><cell>42.9</cell><cell>32.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Comparisons with state-of-the-art video instance segmentation methods on YouTube-VIS val set. Methods with superscript " * " indicates using multi-scale data argumentation during training. The best results are in bold. FPN, 300 queries, 480 ? 800 w/ crop, 36 epochs) reported in [10] is 46.3 box AP. Under the same experimental setting, QueryInst can achieve 48.1 box AP, which outperform Sparse R-CNN by 1.8 box AP. We also show in the ablation study that QueryInst can outperform Cascade Mask R-CNN and HTC based on a weaker query based detector.</figDesc><table><row><cell>with deformable ResNeXt-101-FPN backbone [55, 13, 61]</cell></row><row><cell>achieves 44.6 mask AP and 50.4 box AP without bells and</cell></row><row><cell>whistles.</cell></row><row><cell>We demonstrate that the instance segmentation perfor-</cell></row><row><cell>mance of QueryInst is not simply come from the accurate</cell></row><row><cell>bounding box provided by Sparse R-CNN [42] object de-</cell></row><row><cell>tector. On the contrary, QueryInst can largely improve the</cell></row><row><cell>detection performance. The best result of Sparse R-CNN</cell></row><row><cell>(ResNet-101-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>2. QueryInst achieves 39.4 AP on val split and 34.4 AP on test split, surpassing several strong baselines. Notably, compared to the dynamic convolution based method CondInst [46], QueryInst with ResNet-50 backbone outperforms CondInst with both ResNet-101-DCN-BiFPN backbone and semantic branch. Overall, our QueryInst achieves leading results on Cityscapes dataset without bells and whistles. Video Instance Segmentation Results on YouTube-VIS. Tab. 3 shows the video instance segmentation results on YouTube-VIS val set. Following the standard setting in [57], we first pre-train the instance segmentation model on COCO train2017, then we finetune the corresponding DynConv mask Fig. AP box ? box AP mask ? mask FPS ? FPS</figDesc><table><row><cell>Cascade Mask Head [5] Mask Flow [9] Non-query Based HTC Type</cell><cell>44.3 44.4 + 0.1 39.3 + 0.8 3.1 ? 7.3 38.5 10.4</cell></row><row><cell>Query Based</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Impacts of different mask head architectures on different frameworks. The setting in blue is our default instantiation.</figDesc><table /><note>Parallel DynConv mask</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Impacts of parallel supervision and DynConv mask . Shared MSA Shared Query AP box ? box AP mask ? mask</figDesc><table><row><cell>43.4</cell><cell>38.1</cell></row><row><cell cols="2">43.9 + 0.5 38.3 + 0.2</cell></row><row><cell cols="2">44.1 + 0.7 39.5 + 1.4</cell></row><row><cell cols="2">44.5 + 1.1 39.8 + 1.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Study of Different Mask Head.Tab. 4 studies the impact of different mask head archi-</figDesc><table><row><cell cols="2">(a) Separate query,</cell><cell cols="2">(b) Separate query,</cell><cell>(c) Share query,</cell><cell>(d) Share query,</cell></row><row><cell>Separate MSA.</cell><cell></cell><cell cols="2">Share MSA.</cell><cell>Separate MSA.</cell><cell>Share MSA.</cell></row><row><cell cols="5">Figure 5: Illustration of 4 different query and MSA configurations. We use (d) as the default instantiation of QueryInst.</cell></row><row><cell>Methods</cell><cell cols="3">Sched. Training Time AP</cell></row><row><cell>HTC [9]</cell><cell>3?</cell><cell>? 41 hours</cell><cell>39.7</cell></row><row><cell>QueryInst (100 Queries)</cell><cell>3?</cell><cell>? 35 hours</cell><cell>40.1</cell></row><row><cell>QueryInst (300 Queries)</cell><cell>3?</cell><cell>? 38 hours</cell><cell>40.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Training time comparisons between QueryInst and HTC. All models use ResNet-50-FPN [23, 27] as backbone and are trained with 3? schedule (? 36 epochs) on 8 NVIDIA V100 GPUs (2 images per GPU). QueryInst achieves better performance while needs less training time.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc>Object detection and instance segmentation performance of Mask R-CNN with ResNet-101-FPN backbone using training schedules from 2? (180k iterations) to 6? (540k iterations) and different data augmentations on COCO val. The numbers under "Aug." indicate the scale range of the shorter size of inputs with a stride of 32.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We experimentally study the effects of different training schedules and data augmentations to the Mask R-CNN family in the Appendix.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://paperswithcode.com/sota/ instance-segmentation-on-coco 3 https://paperswithcode.com/sota/ object-detection-on-coco</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Stem-seg: Spatio-temporal embeddings for instance segmentation in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Athar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aljosa</forename><surname>Osep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">YOLACT++: better real-time instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bolya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanyi</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Jae</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ArXiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">YOLACT: real-time instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bolya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanyi</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><forename type="middle">Jae</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cascade R-CNN: delving into high quality object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Cascade r-cnn: High quality object detection and instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Sipmask: Spatial information preservation for fast image and video instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiale</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisham</forename><surname>Rao Muhammad Anwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Cholakkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">End-toend object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Imputer: Sequence modelling via imputation and dynamic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chitwan</forename><surname>Saharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Mohammad Norouzi, and Navdeep Jaitly</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>ICML</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Hybrid task cascade for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dazhi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qijie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07155</idno>
		<title level="m">Chen Change Loy, and Dahua Lin. MMDetection: Open mmlab detection toolbox and benchmark</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Reformulating hoi detection as adaptive set prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.05983</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Up-detr: Unsupervised pre-training for object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yugeng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junying</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.09094</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><forename type="middle">Toutanova</forename><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Compfeat: Comprehensive feature aggregation for video instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Humphrey</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.03400</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Fast convergence of detr with spatially modulated co-attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.07448</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Rethinking imagenet pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Spatial pyramid pooling in deep convolutional networks for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mask scoring r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaojin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongchao</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Dynamic filter networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><forename type="middle">De</forename><surname>Brabandere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinne</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Instance segmentation and object detection with bounding shape masks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Young</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ba Rom</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kang</surname></persName>
		</author>
		<idno>abs/1810.10327</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Microsoft COCO: common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Path aggregation network for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifang</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">SSD: single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14030</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Grid r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Trackformer: Multi-object tracking with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Meinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taixe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.02702</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">V-net: Fully convolutional neural networks for volumetric medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fausto</forename><surname>Milletari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nassir</forename><surname>Navab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seyed-Ahmad</forename><surname>Ahmadi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Parallel wavenet: Fast high-fidelity speech synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Babuschkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Lockhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Cobo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Stimberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Libra r-cnn: Towards balanced learning for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huajun</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Onenet: Towards end-to-end one-stage object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.05780</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rufeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinkun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinting</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15460</idno>
		<title level="m">Transtrack: Multiple-object tracking with transformer</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Sparse r-cnn: End-to-end object detection with learnable proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rufeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenfeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayoshi</forename><surname>Tomizuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehuan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhu</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.12450</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Rethinking transformer-based set prediction for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengcao</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><surname>Kitani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.10881</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Conditional convolutions for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Fcos: A simple and strong anchor-free object detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.03026</idno>
		<title level="m">stance and panoptic segmentation using conditional convolutions</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Scnet: Training inference sample consistency for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Haeyong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Max-deeplab: End-to-end panoptic segmentation with mask transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.00759</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">End-to-end object detection with fully convolutional network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongbin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanning</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.03544</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">SOLO: Segmenting objects by locations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rufeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.10152</idno>
		<title level="m">Solov2: Dynamic, faster and stronger</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">End-toend video instance segmentation with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoliang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoshan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxia</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.14503</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wan-Yen</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Detectron2</surname></persName>
		</author>
		<ptr target="https://github.com/facebookresearch/detectron2" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Upsnet: A unified panoptic segmentation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renjie</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8818" to="8826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Video instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">End-to-end object detection with adaptive clustering transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.09315</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Probabilistic two-stage detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<idno type="arXiv">arXivpreprintarXiv:2103.07461</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dequan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.07850</idno>
		<title level="m">Objects as points</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Deformable convnets v2: More deformable, better results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xizhou</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Deformable detr: Deformable transformers for endto-end object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.04159</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
