<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DeliData: A dataset for deliberation in multi-party problem solving</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Karadzhov</surname></persName>
							<email>georgi.karadzhov@cl.cam.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Stafford</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Sheffield</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Cambridge</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DeliData: A dataset for deliberation in multi-party problem solving</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Group deliberation enables people to collaborate and solve problems, however it is understudied due to a lack of resources. To this end, we introduce the first publicly available dataset containing collaborative conversations on solving a cognitive task, consisting of 500 group dialogues and 14k utterances. In 64% of these conversations, the group members are able to find a better solution than they had identified individually. Furthermore, we propose a novel annotation schema that captures deliberation cues and release 50 dialogues annotated with it. Finally, we use the proposed dataset to develop and evaluate two methods for generating deliberation utterances. The data collection platform, dataset and annotated corpus are publicly available at https://delibot.xyz</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Group deliberation occurs in a variety of contexts, such as hiring panels, study groups, and scientific project meetings. It is traditionally explored in the field of psychology, where researchers examine the conditions under which a group can make better decisions. <ref type="bibr" target="#b18">Mercier and Sperber (2011)</ref> discuss how a group can outperform even the most knowledgeable individual within it -the assembly bonus effect. This was also demonstrated by <ref type="bibr" target="#b20">(Navajas et al., 2018)</ref> who showed that small focus groups can outperform the wisdom of the crowd.</p><p>In order to study what makes deliberations successful and learn how to intervene to this effect, we need a dataset that contains discussions where groups collaborate to solve a task. Furthermore, the task should be such that the decisions made can be objectively measured as correct or incorrect. Most existing datasets are between two interlocutors <ref type="bibr" target="#b4">(Budzianowski et al., 2018;</ref><ref type="bibr" target="#b9">Dinan et al., 2019;</ref><ref type="bibr" target="#b2">Anderson et al., 1991)</ref>, thus not containing group discussions. Focusing on group datasets, one could consider negotiation dialogues <ref type="bibr" target="#b0">(Afantenos et al., 2012)</ref>, which while multi-party are adversarial in nature, therefore not containing collaboration. Publicly available datasets containing collaborative group discussions are WikiDisputes <ref type="bibr">(De Kock and Vlachos, 2021)</ref> and <ref type="bibr">AMI (Carletta et al., 2005)</ref>, but neither contains an objective measure of success, thus making it impossible to evaluate how well did the conversation go. <ref type="bibr" target="#b21">Niculae and Danescu-Niculescu-Mizil (2016)</ref> collected a group dataset containing collaborative problem-solving conversations with an objective measurement of success but their dataset is not publicly available.</p><p>In this work, we present the first publicly available dataset for group deliberation, containing a quantitative measure of task performance: Deli-Data -Deliberation Dataset. An example conversation is shown in <ref type="figure">Figure 1</ref>, with a group deliberating to solve the Wason card selection task <ref type="bibr" target="#b28">(Wason, 1968</ref>), a well-studied task in cognitive psychology. In the example, the group engages in various deliberation strategies: a participant is moderating the conversation by prompting the group for a response (utterance 1), whereas in utterance 4 a participant suggests exploring a different solution. Overall, the group starts with the common, but wrong, solution (utterances 2 and 3) and converges on the correct solution (utterances 6 and 9).</p><p>The DeliData corpus contains 500 group dialogues, together with a measure of task performance before and after the group discussion. Given these measures, we show that after discussing the solution, 64% of the groups perform better at the Wason task, compared to their solo performances. Moreover, in 43.8% of the groups who had a correct answer as their final solution, none of the participants had solved the task correctly by themselves, thus demonstrating how people can solve the task better through deliberation. In our analysis, we also show, that groups of 3 or more people solve the task better than conversations with 2 participants.</p><p>To aid future analysis and dialogue system de-arXiv:2108.05271v2 [cs.CL] 7 May 2022 <ref type="figure">Figure 1</ref>: Abridged conversation from our dataset between 3 people solving the Wason card selection task velopment we propose an annotation schema that captures conversational dynamics and deliberation cues in collaborative conversations, and release an annotated corpus with 50 dialogues using it. Finally, we experiment with generating utterances that probe the conversation by asking questions, using both retrieval and generative approaches.</p><p>2 Related Work <ref type="bibr" target="#b21">Niculae and Danescu-Niculescu-Mizil (2016)</ref> investigated group collaboration in the context of playing a game attempting to geo-locate a photo on the map. In their experimental setup, they evaluate each participant individually, after that they initiate a group discussion and finally ask the group to make a decision together. Unfortunately, their dataset is not publicly available, and thus cannot be used in future studies. Likewise, <ref type="bibr" target="#b15">Kim et al. (2021)</ref> investigates how groups of people collaborate in solving a task together, as well as how can dialogue system can be incorporated within the discussion. Unfortunately, their dataset contains only 12 discussions, making it too small for any reasonable analysis or dialogue systems training, and similarly to <ref type="bibr" target="#b21">(Niculae and Danescu-Niculescu-Mizil, 2016)</ref>, their dataset is also not publicly available.</p><p>Wikipedia is a popular source of collaborative conversations. <ref type="bibr" target="#b12">Hua et al. (2018)</ref> collect 91M discussions from Wikipedia, together with the discussed edits. It is the largest dataset that captures group collaboration, but it is not supported by an annotated corpus. This is partly addressed by <ref type="bibr" target="#b1">Al-Khatib et al. (2018)</ref>, who annotate 200k discussion turns from Wikipedia in 33 dimensions based on discourse acts, argumentative relations and semantic frames. However, unlike the conversations of <ref type="bibr" target="#b21">Niculae and Danescu-Niculescu-Mizil (2016)</ref> and the work presented in this paper, it is impossible to know whether the participants in a conversation on Wikipedia reached a better decision, which renders assessing constructiveness more difficult because there is no objectively correct answer.</p><p>Related to constructive conversations is the research on negotiation dialogues which have been explored in the context of games <ref type="bibr" target="#b13">(Keizer et al., 2017;</ref><ref type="bibr" target="#b6">Cuay?huitl et al., 2015)</ref> and trading <ref type="bibr" target="#b10">(He et al., 2018;</ref><ref type="bibr" target="#b16">Lewis et al., 2017)</ref>. However, even though negotiation dialogue research often deals with multiparty conversations <ref type="bibr" target="#b6">(Cuay?huitl et al., 2015)</ref>, such systems are by nature adversarial, rather than constructive.</p><p>Multiparty conversations are also the focus of <ref type="bibr">Carletta et al. (2005)</ref>, who created a multi-modal corpus of business meetings containing audio, video, transcriptions and auxiliary materials provided to the participants. However, they did not explore deliberation strategies, nor tried to measure the productivity of the group. Using parts of this dataset, the CALO project <ref type="bibr" target="#b26">(Tur et al., 2010)</ref> proposed a toolkit to assist group meetings, such as dialogue act segmentation, action item recognition and others, but no attempt to assess constructiveness was made. <ref type="bibr">Finally, de Bayser et al. (2019)</ref> evaluated turn prediction in the context of group dialogues. They evaluate their system on 3 datasets: one is proprietary, one is artificially created by combining 1-to-1 dialogues from <ref type="bibr" target="#b4">Budzianowski et al. (2018)</ref>, the third dataset consists of transcripts of a popular TV show, which while containing true multi-party dialogues they are not collaborative.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>In our experiments with the Wason card selection task <ref type="bibr" target="#b28">(Wason, 1968)</ref>, participants are presented with 4 cards with a number or a letter on them.</p><p>They have to answer the following question "Which cards should you turn to test the rule: All cards with vowels on one side have an even number on the other.?". Most people initially select the vowel and the even number (i.e. selecting the two cards mentioned in the question), which is incorrect, demonstrating confirmation bias <ref type="bibr" target="#b18">(Mercier and Sperber, 2011)</ref>. The correct answer is to turn the vowel, to check for an even number on the other side, and to turn the odd number, to verify there isn't a vowel on the other side.</p><p>We calculate task performance in two ways. First, we consider a coarse-grained (binary) scoring of the task -Correct -1 if the vowel and odd number are selected, Incorrect -0 otherwise. Recognising that the coarse-grained scoring may needlessly penalise answers that are close to the correct one, we also devised an alternative finegrained scoring. We grant 0.25 points for (i) turning a vowel or an odd number, and (ii) for not turning the even number or the consonant. Therefore, if the participant submitted a correct solution, their score would be 1, if they are off by one card -0.75 and so on. We also calculate performance gain, by subtracting the average of the solo solutions from the average of the group performance. For example, if the average score of participants' solo submissions was 0.5 and improved to 0.75 after the discussion, the group performance gain would be 0.75 ? 0.5 = 0.25. We collect the data using the following protocol (full participant instructions available at Appendix A.1):</p><p>1. Solo Phase. Each of the participants in the group is presented with the same 4 cards and submits a solution to the task. 2. Group Phase. Following the solo phase solution submission, participants gain access to a chatbox to share their solutions and discuss. We encourage them to do so for at least 5 minutes but no longer than 7 minutes without enforcing these time limits; thus there are cases with very short and very long conversations. 3. Revised Submission. After discussing their solutions, the participants are asked to revise their initial card selection and submit again.</p><p>We posted our data collection on the crowdsourcing platform Mechanical Turk with the following job specification:</p><p>1. Everyone who completes the task is paid $2.00 (approx. ?1.60). Participants are given a bonus of $1.00 (?0.80) if they return the right answer. As the average time for partic-ipation is about 8 minutes, each participant is paid ?12/hour (or ?18/hour if they solve the task correctly). This is between 35% and 102% above UK's National Living Wage 1 . 2. No personal information is collected and the participants are asked not to share anything that may reveal personal details. 3. We recruited only adult participants from countries where English is a primary language, and they complete a simple reading comprehension test. The only language used in our dataset is English. Participants are informed that we are investigating how people collaborate in solving a cognitive task and that we will be saving chat transcripts. This experimental protocol was approved by the ethics committee of the authors' institution.</p><p>The data collection is performed using a web application we call DialogueDen, which we opensource together with this study. The design of the platform allows us to record solo and group selections and the state of the game in key points of the experiment. This data can be used to identify when a participant reached the correct decision, even if they don't express it explicitly in the chat. Moreover, we integrated a number of features to DialogueDen that are specific for the data collection on Mechanical Turk, addressing various issues that arise when collecting group conversations in an unsupervised manner. These are part of the code release and are presented in detail in Appendix A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DeliData dataset</head><p>Using the experimental protocol above we initially conducted a pilot study, where we collected 18 group dialogues, with 53 volunteers from a university psychology department, who didn't have prior knowledge of the task. After that, we ran a larger scale data collection on Mechanical Turk which is often used for data collection in behavioural research and often produces similar results to in-lab experiments <ref type="bibr" target="#b5">(Crump et al., 2013)</ref>. This data collection was not moderated in any way, making it an in-the-wild data collection. We ensure the quality and anonymity of the data from MTurk by manually checking each conversation. We excluded a total of 160 conversations that were too short, of poor quality or with too few actively engaged par- ticipants. Thus, we release 482 dialogues that are of comparable quality to our in-lab pilot. Summarised statistics of the two subsets are presented in <ref type="table">Table 1</ref>. While the two subsets differ in terms of absolute performance, the improvement from solo to group performance is substantial in both data collections for both coarse-and finegrained metrics, in agreement with results from psychology research on offline deliberation <ref type="bibr" target="#b18">(Mercier and Sperber, 2011)</ref>, and thus validating our data collection approach using MTurk. Another difference is that the average number of utterances per dialogue is lower on MTurk, which we attribute to the psychology student volunteers being more dedicated than crowd workers.</p><p>In <ref type="table" target="#tab_2">Table 2</ref> we compare three multi-party dialogue datasets: StreetCrowd <ref type="bibr" target="#b21">(Niculae and Danescu-Niculescu-Mizil, 2016)</ref>, Settlers of Catan (SoC) <ref type="bibr" target="#b0">(Afantenos et al., 2012)</ref>, and ours. Of these three, only two are collaborative -ours and StreetCrowd, as SoC is among players competing against each other. Ours is the only one containing collaborative group conversations available for research. Moreover, while it contains fewer dialogues than StreetCrowd, these are 2.5 times longer in terms of utterances, thus more likely to exhibit collaborative strategies spanning over multiple utterances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Annotating deliberation cues 5.1 Annotation Schema</head><p>In order to annotate the conversations collected we first considered using the annotation schema previously proposed for discourse parsing (Zhang   <ref type="bibr">, 2018)</ref>. While both of these schemata capture some discussion markers (such as Agreement or Argumentation), they fail to identify which utterances are helping the group in terms of deliberation.</p><p>In terms of collaborative discussions, the MapTask schema by <ref type="bibr">Carletta et al. (1996)</ref> annotates conversations between two participants, who play a game together. However, they did not annotate reasoning utterances, limiting their annotation to basic interactions such as question and answer utterances.</p><p>To address this, we propose an annotation schema that contains 3 levels of annotation, each focusing on different aspects of deliberation. <ref type="figure" target="#fig_0">Figure 2</ref> gives the overview of the schema, and we describe it in detail in the remainder of this section.</p><p>At the top level of the schema, we are interested in identifying probing deliberation, i.e. any utterance that provokes discussion, deliberation or argumentation without introducing novel information (Hey, @Cat what do you think was the solution?). We also recognise that most utterances in a conversation are not probing, but are inherently useful for the conversations. We label these utterances as non-probing deliberation, and they include all discussions that are concerned with the task's solution and participants' reasoning (I think the answer is A, because we have to check each vowel for sure). Finally, we include a None label that covers all utterances that are not related to the previous two categories. These utterances often include familiarities (Greetings fellas) or hesitation cues (hmm...). After distinguishing between probing and non-probing deliberation, we classify each utterance into 5 roles at the second level:</p><p>? Moderation (exclusive to probing deliberation): Moderation utterances are not concerned directly with the task at hand, but rather with how participants converse about it (Let's discuss our initial solutions). ? Reasoning: Utterances focusing on argumentation and can be both probing (Why did you think it wasn't 8?) and non-probing (I think it would be 7 to test if it would be incorrect). ? Solution: Utterances that are managing the solution of the task. Can be both probing (Are we going for A and 4?) or non-probing (I think the answer is 7 and A). ? Agree and Disagree (exclusive to nonprobing-deliberation): Utterances expressing agreement or disagreement with a previous argument or solution. An important caveat with Reasoning is that it takes a priority over other labels.</p><p>Some of the utterances may carry additional information beyond what is captured by their type and role, i.e. the first two levels of the annotation. Therefore, we introduce a set of additional labels that mark specific phenomena in the conversation, which we defined as follows:</p><p>? specific_addressee: Utterances explicitly addressing specific participant(s) (@Llama what do you think?) ? complete_solution and partial_solution: Utterances advocating for either a complete task solution (Let's turn A and 7), or a partial one (one of the cards is A). ? solution_summary: Utterances that recall previous solutions to prompt for an agreement (So, do we all agree on A and 5?). ? consider_opposite -utterance suggesting an opposite solution. (maybe not L?)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Annotated dataset</head><p>Using the annotation schema introduced in this section we annotated 50 dialogues and a total of 1696 utterances from the dataset presented in section 4.</p><p>We performed an annotation agreement study between 3 annotators on 41 of the dialogues using Cohen's kappa <ref type="bibr">(Cohen, 1960)</ref>. We obtained an inter-annotator agreement of 0.75 on the first level, 0.71 on the second level, and an average agreement of 0.53 on the additional labels. The label distribution for the first two levels is presented in <ref type="table" target="#tab_4">Table 3</ref>. Overall, the number of   Reasoning and Solution utterances are substantial, confirming that the subjects in our data collection engaged in substantial discussions about the solutions and their reasoning. The corpus also contains 214 Probing utterances, which are similarly distributed between Moderation, Reasoning, and Solution, thus suggesting that the strategies chosen for annotation are commonly used. Finally, 450 utterances were annotated as non-deliberative ("None"), and are excluded from the table.</p><p>In <ref type="table" target="#tab_5">Table 4</ref> we present the distribution of additional labels. In column Count we show the total number of occurrences of each of these labels, while in Prevalence we show how often this label occurs in all utterances, including those without annotation for an additional label. The most prevalent label is complete_solution, appearing in about 20% of the utterances. While the other additional labels occur less in the conversation (around 5% or less), they might be useful for dialogue analysis.</p><p>6 Analysis and Experiments 6.1 Two-party and multi-party conversations While in our dataset two-party and multi-party (3 or more participants) conversations have similar statis-tics, there are notable differences that we highlight in this section. In <ref type="figure" target="#fig_1">Figure 3</ref>, we present histograms comparing three conversational statistics -the total number of messages, number of unique tokens and participation balance, represented by entropy. First, dialogues between two interlocutors have mostly between 10 and 25 utterances, while group discussions in DeliData are uniformly represented in a larger range, between 20 and 40 utterances, with a long tail of conversations longer than 50 utterances. This naturally occurs, as multiparty discussions, contain more arguments and exchange of ideas. Likewise, participants in these discussions tend to use a larger vocabulary of words, as shown on the histograms of the unique tokens.</p><p>In this analysis, we also look at how balanced are the conversations, i.e. whether all of the participants contributed equally. We calculate the participation entropy similarly to <ref type="bibr" target="#b21">Niculae and Danescu-Niculescu-Mizil (2016)</ref>, where the entropy is maximised if everyone participated equally, and approaches 0 if there is a large imbalance. In our dataset, the balance for two-party conversation is better, where 40 % of the discussions are almost uniformly balanced, while in the multi-party discussions, it is often the case that one of the participants is driving the discussion. This is not surprising, as in one-to-one conversations if one of the participants asks a question, it is customary that the other participant answers. Such is not the case for multiparty discussions, where some of the participants may decide to have a more passive role.</p><p>Besides conversation statistics, we analyse the difference in task performance. Verifying for the initial conditions first, the solo performance of both types of groups is comparable -0.597 and 0.585. On the other hand, the collective performance of these groups was 0.694 for two-party conversations and 0.724 for multi-party, thus the performance gain is 0.096 and 0.139 respectively. Therefore, we argue that it is the multi-party (as opposed to two-party) discussion that led to an improved conversational performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Propagation of correct solutions</head><p>Analysing our data we found out that there is 0.36 <ref type="bibr">Kendall's Tau B correlation Kendall (1938)</ref> between group consensus and performance gain. An investigation of how correct solutions propagate through the conversations showed that 21.2% of conversations started and finished with the same amount of correct submissions, thus the participants didn't convince anyone of the correctness of their response. In 35% of the discussions where a single participant had answered correctly in their solo submission, they convinced at least one more participant in the group phase. However the reverse also happened -in 4% of all dialogues, the group convinced a participant with the correct answer to change it, which is considerably rarer than changing to the correct solution. Finally, in 43.8% of the groups in which at least one participant submitted a correct response after the conversation, no participant had submitted a correct solution in their solo phase. This supports the group is better than the sum of its parts hypothesis, suggesting that deliberation offers more than just facilitating the spread of a correct solution among group members, and is consistent with the findings of <ref type="bibr" target="#b19">Moshman and Geil (1998)</ref> and <ref type="bibr" target="#b24">Schulz-Hardt et al. (2006)</ref>, who show that deliberation plays a bigger role in task success, compared to individual participants' ability.</p><p>Furthermore, we present an analysis of different solution propagation patterns based on the annotation schema. We compared the groups where at least one of the participants had the correct solution in their solo phase, to the groups which reach the correct solution without anyone knowing the solution in their solo phase (referred to as DELI). The DELI subset contains a higher percentage of probing (17.3% vs 14.4%), and reasoning (43.8% vs 37.8%) utterances, suggesting that the participants are actively engaging in deliberation to get to the correct solution. Naturally, the DELI subset contains fewer utterances that propose a solution (30.4% vs 35.7%), as participants are more engaged with the reasoning behind the solution, opposed to the solution itself. These findings are suggestive of the rich source of information about the dynamics of deliberation present in the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Predicting conversation success</head><p>In order to analyse the factors that make a conversation constructive as well as showcase possible applications of the DeliData corpus, we perform a series of modelling experiments, where we predict the constructiveness of a conversation.</p><p>Given the size of our dataset and the potential instability of neural models, herein we use a simple decision tree classifier <ref type="bibr" target="#b23">(Pedregosa et al., 2011)</ref> with a maximum depth of 7 and minimum samples per leaf set to 5 and use leave-one-out cross-validation (LOOCV). As the dataset is imbalanced (318 conversations with performance gain and 182 without), we evaluate our models using the area under the ROC curve. For these experiments we considered 4 types of features:(i) interaction (SC Interaction) and (ii) linguistic (SC Linguistic) features, borrowed from StreetCrowd (Niculae and Danescu-Niculescu-Mizil, 2016), (iii) participation dynamics (i.e. whether one of the participants dominated the conversation), and finally (iv) conversational statistics (number of messages, tokens, etc.). Full experimental details can be found in Appendix A.3 and the code will be made publicly available. As shown in <ref type="table" target="#tab_7">Table 5</ref>, the interaction features from StreetCrowd don't transfer well in our setup, if used alone, achieving performance that is below the baseline. On the other hand, SC Linguistic features together with participation features, achieve fair stand-alone performance. Finally, without feature combinations, conversational statistics are the best predictor of conversational performance. Interestingly, the best performance from feature combinations is achieved by using the interaction features from StreetCrowd, the participation dynamics and the conversational statistics. Both SC Interaction and Participation Dynamics, model how participants interact with each other, providing a glimpse into group collaboration. These results suggest that conversational dynamics are a strong addition to traditional feature-based approaches for dialogue classification. On table 5 we also report model stability, which is the consistency of the selected features in the first two levels of the decision tree.  by themselves are not as stable as other feature sets, the best combination achieves perfect stability, by producing consistent decision trees in every split of the LOOCV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>While SC Interaction and Participation Dynamics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Generating Probing Utterances</head><p>We conclude by developing and evaluating two methods for generating probing utterances. We consider two different approaches -a retrieval-based approach and a generative approach with language models. The task setup is: given the previous dialogue utterances and the Role of a probing utterance (i.e. Probing-Moderation, Probing-Reasoning, Probing-Solution), generate the most appropriate utterance to continue the dialogue. For these experiments, we consider the 50 annotated dialogues using the annotation schema of Section 5 as we assume the Role of the utterance to be generated given, and split them into a training set of 30 dialogues and a test set of 20. In our experiments we compare 4 candidate responses:</p><p>? Original. We take the utterance by the human participant from the original dataset. ? Random. We sample from the training data a random utterance that has the same Role as the one we need to generate. This is a strong baseline, as sampling for the same role often yields a contextually adequate utterance (albeit not necessarily the best). ? Retrieval. We find the most similar utterance with the same Role in our training dataset.</p><p>To calculate similarity we encode the context of the probing utterance using a pretrained DialoGPT model ? Generative We use a pretrained DialoGPT to generate the next utterance based on the current conversation context. For every method (except for the original) we replaced with placeholders both the mentions of participants and solutions. Once we generate an utterance, if it has a mention of a participant or a solution, we use a simple rule-based system to select appropriate substitution from the context. We</p><p>Context but if we are trying to verify then maybe we select them all Original how else could you know? Random</p><p>Why did you press V Retrieval How many cards do you think at minimum we need to flip to confirm the rule Generative I think he means that the list of possible candidates is a list that will be evaluated in the upcoming days.   show an abridged example from our experiments in <ref type="table" target="#tab_8">Table 6</ref> (additional examples in Appendix C). We evaluate the three generated candidate responses using both automatic and human evaluation. First we applied three commonly used measures for evaluating NLG applications -BLEU 4 <ref type="bibr" target="#b22">(Papineni et al., 2002)</ref>, sentence similarity using RoBERTa <ref type="bibr" target="#b17">(Liu et al., 2019)</ref>, and BERTScore <ref type="bibr" target="#b30">(Zhang et al., 2019)</ref>. As none of our NLG methods is trained to generate the same utterance as the Original, we do not expect that any of the candidate responses will achieve strong results, but automatic measures for NLG evaluation can be a good proxy for the quality of generated responses. On <ref type="table" target="#tab_9">Table 7</ref>, we present the results where we compare to the Original response. The Retrieval approach has the best overall performance, with BLEU-4 score of 0.39 compared to 0.35 and 0.09. If we consider just the Similarity and BertScore measures, the Retrieval and Random approaches have similar performance. On the other hand, Generative performs consistently worse on all measures.</p><p>We also perform a human evaluation study, where we asked people to rate the generated responses. We recruited 28 workers from Prolific using comparable worker qualifications and payment level as on MechanicalTurk. We gave crowd workers the following instructions: "Please rank the 4 candidate responses from 1 (for the best response) to 4 (for the worst). You can give the same rank for responses you consider equally good/bad by placing them in the same box.". We asked each of the crowd workers to rank 10 sets of candidate responses, which resulted in 280 annotations of 89 probing cases. First, we compared the average ranks of each of the NLG methods. The Original and the Retrieval approaches had similar ranks -2.12 and 2.15, while the Random candidate was ranked on average at 2.23. Finally, the generative approach performed the worst, being ranked on average at 3.02. To gain a more fine-grained understanding on which method is preferable, we calculated the pairwise preferences (adjusted for ties), presented in <ref type="table" target="#tab_10">Table 8</ref>, which showed similar results, with the Original and Retrieval being considered equal, followed closely by Random, and Generative a distant fourth.</p><p>Qualitative analysis showed that the responses of the Retrieval are coherent despite the simple representation of dialogue context. Also, we found that, while large-scale pre-trained language models can be adequate in responding to general queries, they fail to produce good responses where more advanced vocabulary and reasoning are required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future work</head><p>In this work, we introduced a dataset containing conversations where a group of participants collaborate in order to solve a task. Furthermore, we proposed an annotation schema and annotated corpus that capture key elements of group deliberation, such as probing. This dataset can be analysed to test theories of the dynamics of group deliberation and develop dialogue agents that could be used to improve the outcome in numerous setups, for example debating groups, project meetings, etc., and thus a step towards addressing the call for "discourse optimization" of <ref type="bibr" target="#b27">Vecchi et al. (2021)</ref>. Such dialogue agents can roughly be decomposed into 3 major modules -determining intervention timing, intervention type (i.e. moderation, probing for reasoning) and generating a probing utterance. Given that we present an adequate approach for probing generation, we advise that future researchers focus on the first 2 modules.</p><p>In this work, we present a corpus containing conversations, where participants collaborate to solve a cognitive task. Details on our setup and ethical considerations are presented in Section 3 and appendices A.1 and A.2, but in this section we will reiterate the most important points.</p><p>We collected our dataset using the crowdsourcing platform MechanicalTurk and in-lab volunteers for the initial experiments. Participants gave informed consent to their participation, and we told them the purpose of the study and that the transcripts of the dialogues would be collected and used for further research. The only language used in our dataset is English. Participants were free to withdraw at any time. We asked participants not to share any personal information, and as part of quality control, we have removed any instances of such (like the city they were living in, or the institution they were studying in). We asked the participants not to use any offensive language, and as part of the quality control, we verified whether this is the case, fortunately not finding any such instances. When recruiting participants, we selected adult participants from countries where English is a primary language and where MechanicalTurk operated at the time of collection: US, Canada, UK, Ireland, Australia. Besides that, we did not put any restrictions on (nor have a record of) participants' exact age, gender, nationality, race, political leaning, education, etc.</p><p>Crowd workers were paid on average between ?12/hour and ?18/hour (approx. $16.46/h-$24.68/h), depending on their time of participation and whether they solved the task correctly. This is well above the UK's living wage (?8.91/hour), as well as the minimum wage in the US ($7.25) 2 . Moreover, in cases where we were unable to start the data collection (due to inactive users for example), we paid the participants for their time.</p><p>For our human evaluation experiments, we recruited participants from Prolific. We put similar qualification requirements as on MechanicalTurk, namely, minimum age of 18, fluent in English, and minimum approval rate of 90%. We paid annotators in the same pay range as on MechanicalTurk, averaging ?14.25/hr (19.5$/h).</p><p>The full experimental design was approved by the ethics committee of the authors' institution. We 2 https://www.dol.gov/general/topic/wages/minimumwage will release the DeliData corpus under Creative Commons 4.0.</p><p>Limitations While this work aims to investigate how people collaborate in order to solve a task, we limit the scope of our dataset and experiments to the Wason Card Selection Task. Future work may be needed to evaluate whether this dataset would apply to other types of problem-solving (for example in a business setting).</p><p>Finally, we excluded conversations based on poor quality, i.e. when participants are not discussing the task at all. That said, participants are still getting paid if the conversation was excluded to no fault of their own.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Predicting Performance Gain</head><p>To encourage reproducibility we will describe in details how we predict performance gain.</p><p>Conversation Statistics (9 features): Number of participants in the chat, total number of messages, average number of messages per player, average number of tokens per player, total unique tokens, average unique tokens per player, participants' individual performance, diversity in participants' individual solutions, and group consensus.</p><p>Participation Dynamics (13 features). In the context of this work, we built a solution and participation tracker. Knowing the cards, presented to the participants, we track each solution proposal, as well as per participant change of solution. We do this by applying a simple rule-based system -if the message mentions one or more of the cards we save this as participant's solution proposal. Next time the same participant proposes a different solution we mark this event as a solution change.</p><p>Complimentary to the solution tracker, we also keep a record of how actively each participant engages in the discussion. We identify 4 categories of participation, based on how many messages each player issued -0, 0-20, 40-50, 50-100 %. Thus we are able to record both more silent users, and those who participate more than the rest of the group.</p><p>That said, we extract the following features: Number of solution changes (normalised by the number of messages), The 4 categories of participation at 20/50/all messages.</p><p>StreetCrowd Features For more details, please refer to <ref type="bibr" target="#b21">(Niculae and Danescu-Niculescu-Mizil, 2016</ref>).</p><p>? Interaction Features (6 features). These features are calculated based on the whole conversation (rather than on an individual message). First, <ref type="bibr" target="#b21">(Niculae and Danescu-Niculescu-Mizil, 2016)</ref> include language matching on stopword, token and POS tag levels. Further, the interaction features capture agreement and disagreement markers in words.</p><p>? Linguistic Features (15 features). These are message level features, that capture specific linguistic phenomena: message length (and it's variation), psycholinguistic features from LIWC (Tausczik and Pennebaker, 2010), task specific jargon, and POS patterns.</p><p>Model Selection and Hyperparameter Search. Due to the relatively small size of the dataset, and the high information load of each conversation (large number of utterances), the selection of an appropriate model is a challenging endeavour. In our experiments, we found out that most models are either unable to generalise well or are very unstable in terms of performance. Models that performed poorly in either generalisation or stability were: Linear Regression, Support Vector Machine (both linear and RBF kernels), Random-Forest, K-Nearest Neighbour, and a multilayer perceptron. Thus, we selected a decision tree, as it is a fairly stable model by design, and it allows us to analyse variability between different runs of the model. We performed hyperparameter search with the following parameters: Max Depth: [2, 3, 5, 7 (selected), 20, max] and Min Samples per leaf: [1, 2, 3, 5 (selected), 10]. Total number of parameter tuning runs -30. The best model is selected based on model accuracy and stability. Due to the size of the model and the dataset, the hyperparameter search does not require any special infrastructure and the training time is negligible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Packages used</head><p>For training and evaluation of the performance gain we used <ref type="bibr" target="#b23">(Pedregosa et al., 2011</ref>) version 1.0.2. For general language tasks and featurisers we used NLTK <ref type="bibr" target="#b3">(Bird et al., 2009)</ref>   Why A? Probing Reasoning Narwhal The rule is that all cards with a vowel on one side have an even number on the other side.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NPD Solution</head><p>Narwhal Well, our third card is a vowel to start with. We do not know what is on the other side of that card. If we flip our only apparent vowel and we find an even number, that is a pretty good indication to the rule right off the start.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NPD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reasoning partial_solution</head><p>Beaver ok NPD Agree Bee makes sense NPD Agree Narwhal None of the other cards would do us any good to flip them over because they are either an odd number or a consonant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NPD Reasoning</head><p>Narwhal So A is the way to go. NPD Solution complete_solution Bee sounds good to me. NPD Agree Beaver</p><p>A it is, NPD Agree complete_solution Bee</p><p>Thanks for the help, Narwhal Thanks for being willing to listen!  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Context</head><p>but it says it might be as simple as we think and it seems pretty simple to put U and 2 as that is the vowel and the even number Original</p><p>So is it 7 ? Random so 2 , U , and 7 Retrieval So you think the 2 Card ? Generative I concur </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Hierarchical annotation structure</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Comparison between conversational statistics of two-party dialogues(left) and group dialogues (right). Each of the histograms is showing percentage of dialogues on the y-axis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Multiparty dialogue corpora comparison et al., 2017), Wikipedia discussions (Al-Khatib et al.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Frequencies for the labels in the top two levels of the annotation schema</figDesc><table><row><cell>Additional Label</cell><cell cols="2">Count Prevalence</cell></row><row><cell cols="2">specific_addressee 55</cell><cell>4.4 %</cell></row><row><cell cols="2">complete_solution 258</cell><cell>20.7 %</cell></row><row><cell>partial_solution</cell><cell>79</cell><cell>6.3 %</cell></row><row><cell cols="2">solution_summary 40</cell><cell>3.2 %</cell></row><row><cell>consider_opposite</cell><cell>11</cell><cell>0.9 %</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Label distribution the additional labels</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Predicting conversation performance</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Utterances generated by different methods</figDesc><table><row><cell>Method</cell><cell cols="2">BLEU-4 Similarity</cell><cell>BERT</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Score</cell></row><row><cell>Retrieval</cell><cell>0.39</cell><cell>0.56</cell><cell>0.83</cell></row><row><cell>Random</cell><cell>0.35</cell><cell>0.55</cell><cell>0.83</cell></row><row><cell cols="2">Generative 0.09</cell><cell>0.42</cell><cell>0.79</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Automatic evaluation of Probing generation</figDesc><table><row><cell cols="4">Original Retrieval Random Generative</cell><cell></cell></row><row><cell>-</cell><cell>0.5</cell><cell>0.46</cell><cell>0.28</cell><cell>Original</cell></row><row><cell>0.5</cell><cell>-</cell><cell>0.48</cell><cell>0.29</cell><cell>Retrieval</cell></row><row><cell>0.54</cell><cell>0.52</cell><cell>-</cell><cell>0.27</cell><cell>Random</cell></row><row><cell>0.72</cell><cell>0.71</cell><cell>0.73</cell><cell>-</cell><cell>Generative</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8 :</head><label>8</label><figDesc>The table reports pairwise preferences in columns over rows, i.e. the first column reports the preference of the Original text vs the other 3 methods.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 :</head><label>9</label><figDesc>Constructive conversation ending in a correct solution</figDesc><table><row><cell>User</cell><cell>Utterance</cell><cell>Is Probing</cell><cell>Role</cell><cell>Additional Labels</cell></row><row><cell>Beaver</cell><cell>I think we should check all four cards.</cell><cell>NPD</cell><cell>Solution</cell><cell>complete_solution</cell></row><row><cell>Bee</cell><cell>I am going with the last 2</cell><cell>NPD</cell><cell>Solution</cell><cell>complete_solution</cell></row><row><cell cols="2">Narwhal At the very least we should definitely</cell><cell>NPD</cell><cell>Solution</cell><cell>partial_solution</cell></row><row><cell></cell><cell>include the 3rd card.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Beaver</cell><cell>Ok, anything else?</cell><cell>Probing</cell><cell>Moderation</cell><cell></cell></row><row><cell>Bee</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>Non-constructive conversation C Examples of different approaches to generating utterances Retrieval so what we are supposed to discuss about Generative hey</figDesc><table><row><cell>Context</cell><cell></cell></row><row><cell>Narwhal</cell><cell>Hello</cell></row><row><cell>Dolphin</cell><cell>Hi</cell></row><row><cell>Original</cell><cell>Anyone have any suggestion to a solution</cell></row><row><cell>Random</cell><cell>Dolphin what did you select</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 11 :</head><label>11</label><figDesc>Example of different methods for generating Probing-Moderation utterances</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 12 :</head><label>12</label><figDesc>Example of different methods for generating Probing-Solution utterances</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">?8.91/hour as of 01/04/2021, based on https: //www.gov.uk/government/publications/ the-national-minimum-wage-in-2021</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">. Quality Control. We perform two kinds of quality control over the collected data. Initially, we automatically exclude all conversations that either have only a single participant in them or have less than 10 messages. Then, each conversation is manually checked, to ensure that no personal information was shared.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A Reproducibility Checklist  Participants are given the following description of the task and experiment:</p><p>1. You will be part of a small-group chat (3-5 people), where you will try solving a puzzle.</p><p>2. Finish the task by yourself 3. Participate in a group discussion (via the chat), collaborate with the other participants and try to find the best solution together. Give your best effort both in solving the task and in the group discussion.</p><p>4. You are expected to participate actively in the conversation for at least 5 minutes.</p><p>5. Based on the discussion and arguments you had, submit the revised task solution again. You can submit the same answer if you believe it's the correct one.</p><p>6. Task: Each of the 4 cards below has a letter on one side and a number on the other. Which card(s) do you need to turn to test the rule: All cards with vowels on one side have an even number on the other. NB: Select ONLY the card(s) required to verify the rule. Most people get this task wrong.</p><p>7. Please remember that these transcripts may be used in future research, and therefore you have the right to withdraw from this study at any given time. To do so, press the "Leave room" button above. Please ensure you do not use any offensive language or disclose any personal information which would make you identifiable to others as it's important that your anonymity is maintained. Any information which may reveal your identity will be deleted from this chat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Data Collection: Mechanical Turk Modifications</head><p>We recognise that collecting data on Mechanical-Turk, we will face more challenging conditions compared to a controlled lab setup. Moreover, by design, MechanicalTurk is providing a platform for a single person to complete a task. As we aim at collecting group dialogues we applied to following recruitment protocol that enables synchronous data collection between multiple turkers:</p><p>1. Room Routing. Every crowd worker that joins our task is routed to a group that is recruiting participants or if none available -creates a new room. As we recognise, that some participants might leave after joining a room, we identified the following 3 room states:</p><p>(a) Recruiting: if the room has less than 3 active participants, a new participant can join at any time (b) Final Call: After there are at least 3 people in the room, a 1-minute timer starts, which allows for up to 2 more participants to join. By allowing more than 3 people to join, we mitigate the effect of inactive or leaving participants. (c) Ready to Start: Once the final call timer elapses, the game is ready to start.</p><p>2. Crowd worker requirements. To get highquality data collection, the crowd workers participating in our task should meet the following conditions:</p><p>(a) Complete a simple reading comprehension test (b) Fluency in English, which is established by being a resident of countries where English is an official language (c) Have more than 95% success rate on previous crowd-sourcing tasks (d) Have completed at least 1000 tasks on Mechanical Turk 3. Notifications. Sometimes it takes a while for a group of 3 people to be ready, and, naturally, some of the participants may be inactive while waiting. To ensure that everyone is online, when the group is ready to start, there are audible notifications during key phases of the experiment, as well if someone is being inactive or not responsive during the game.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Modelling strategic conversation: model, annotation design and corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stergos</forename><surname>Afantenos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farah</forename><surname>Benamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anais</forename><surname>Cadilhac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cedric</forename><surname>D?gremont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Denis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Guhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Keizer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Modeling deliberative argumentation strategies on Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Al-Khatib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henning</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Herpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1237</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2545" to="2555" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The hcrc map task corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miles</forename><surname>Bader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><forename type="middle">Gurman</forename><surname>Bard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elizabeth</forename><surname>Boyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gwyneth</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Garrod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacqueline</forename><surname>Kowtko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1177/002383099103400404</idno>
	</analytic>
	<monogr>
		<title level="j">Language and Speech</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="351" to="366" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Natural language processing with Python: analyzing text with the natural language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewan</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Reilly Media, Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multiwoz-a largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pawe?</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Hsien</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-Hsiang</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I?igo</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Osman Ramadan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gasic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5016" to="5026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Evaluating amazon&apos;s mechanical turk as a tool for experimental behavioral research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">V</forename><surname>Crump</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><forename type="middle">M</forename><surname>Mcdonnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gureckis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">57410</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heriberto</forename><surname>Cuay?huitl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Lemon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.08099</idno>
		<title level="m">Strategic dialogue management via deep reinforcement learning</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Learning multiparty turn-taking models from dialogue logs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maira</forename><surname>Gatti De Bayser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paulo</forename><surname>Cavalin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02090</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Claudio Pinhanez, and Bianca Zadrozny</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">2021. I beg to differ: A study of constructive disagreement in online conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>De Kock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</meeting>
		<imprint>
			<biblScope unit="page" from="2017" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Wizard of Wikipedia: Knowledge-powered conversational agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Decoupling strategy and generation in negotiation dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anusha</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2333" to="2343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">2017. spacy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Montani</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Wikiconv: A corpus of the complete conversational history of a large online collaborative community</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqing</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Taraborelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nithum</forename><surname>Thain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffery</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Dixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2818" to="2823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Evaluating persuasion strategies and deep reinforcement learning methods for negotiation dialogue agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Guhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heriberto</forename><surname>Cuay?huitl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Efstathiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus-Peter</forename><surname>Engelbrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Dobre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lascarides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Lemon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ACL</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A NEW MEASURE OF RANK CORRELATION</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Kendall</surname></persName>
		</author>
		<idno type="DOI">10.1093/biomet/30.1-2.81</idno>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="81" to="93" />
			<date type="published" when="1938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Moderator chatbot for deliberative discussion: Effects of discussion structure and discussant facilitation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soomin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinsu</forename><surname>Eun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Seering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joonhwan</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1145/3449161</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">CSCW1</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deal or no deal? end-to-end learning of negotiation dialogues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2443" to="2453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>abs/1907.11692</idno>
	</analytic>
	<monogr>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Why do humans reason? arguments for an argumentative theory. Behavioral and brain sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Mercier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Sperber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="57" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Moshman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Molly</forename><surname>Geil</surname></persName>
		</author>
		<title level="m">Collaborative reasoning: Evidence for collective rationality. Thinking &amp; Reasoning</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="231" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Aggregated knowledge from a small number of debates outperforms the wisdom of large crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joaquin</forename><surname>Navajas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><surname>Niella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerry</forename><surname>Garbulsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bahador</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariano</forename><surname>Sigman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="126" to="132" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Conversational markers of constructive discussions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Niculae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Danescu-Niculescu-Mizil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="568" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bleu: A method for automatic evaluation of machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salim</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Todd</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Jing</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073135</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02</title>
		<meeting>the 40th Annual Meeting on Association for Computational Linguistics, ACL &apos;02<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Group decision making in hidden profile situations: dissent as a facilitator for decision quality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Schulz-Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Brodbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudolf</forename><surname>Mojzisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Kerschreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of personality and social psychology</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1080</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The psychological meaning of words: Liwc and computerized text analysis methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">W</forename><surname>Tausczik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="24" to="54" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The calo meeting assistant system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gokhan</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Stolcke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynn</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Dowding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Favre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Fern?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Frampton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Frandsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1601" to="1611" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Towards argument mining for social good: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Eva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neele</forename><surname>Vecchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iman</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriella</forename><surname>Jundi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lapesa</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.107</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1338" to="1352" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Reasoning about a rule</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peter C Wason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly journal of experimental psychology</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="281" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Characterizing online discussion using coarse discourse sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Culbertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Paritosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th AAAI International Conference on Web and Social Media (ICWSM)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Bertscore: Evaluating text generation with BERT. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varsha</forename><surname>Kishore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Artzi</surname></persName>
		</author>
		<idno>abs/1904.09675</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
