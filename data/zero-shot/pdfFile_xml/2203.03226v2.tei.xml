<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Signature and Log-signature for the Study of Empirical Distributions Generated with GANs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>De Curt? Y D?az</surname></persName>
							<email>decurtoydiaz@innocimda.com</email>
							<affiliation key="aff0">
								<orgName type="department">Centre for Intelligent Multidimensional Data Analysis</orgName>
								<orgName type="institution">HK Science Park</orgName>
								<address>
									<settlement>Shatin, Hong Kong</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Electrical Engineering</orgName>
								<orgName type="institution">City University of Hong Kong</orgName>
								<address>
									<settlement>Kowloon, Hong Kong</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Signature and Log-signature for the Study of Empirical Distributions Generated with GANs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>GAN</term>
					<term>PCA</term>
					<term>t-SNE</term>
					<term>Clustering</term>
					<term>NASA</term>
					<term>Perseverance</term>
					<term>Sig- nature Transform</term>
					<term>Mars</term>
					<term>Segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>0000?0002?8334?4719] , I. de Zarz? i Cubero 1[0000?0002?5844?7871] , and Hong Yan 1,2[0000?0001?9661?3095]</p><p>Abstract. In this paper, we develop a new and systematic method to explore and analyze samples taken by NASA Perseverance on the surface of the planet Mars. A novel in this context PCA adaptive t-SNE is proposed, as well as the introduction of statistical measures to study the goodness of fit of the sample distribution. We go beyond visualization by generating synthetic imagery using Stylegan2-ADA that resemble the original terrain distribution. We also conduct synthetic image generation using the recently introduced Scored-based Generative Modeling. We bring forward the use of the recently developed Signature Transform as a way to measure the similarity between image distributions and provide detailed acquaintance and extensive evaluations. We are the first to pioneer RMSE and MAE Signature and log-signature 3 as an alternative to measure GAN convergence. Insights on state-of-the-art instance segmentation of the samples by the use of a model DeepLabv3 are also given.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Space Exploration has become ubiquitous, from NASA missions to other planets to the privatization of the space sector led by companies such as SpaceX, Blue Origin or Virgin Galactic. The need to study and analyze the amount of data that will be generated in such missions will become essential to improve the Return on Investment. Moreover, the current thread of sending small unmanned autonomous vehicles (nanorovers) to the Moon (e.g. Astrobotic) and in the future also to Mars and others will make research in this setting available to pursue at universities worldwide. In this context, our aim is to provide a first approach to deal with the data collected by NASA Perseverance and extract purposeful information. We first visualize the data, for instance by the use of K-means Clustering and t-SNE (t-distributed Stochastic Neighbor Embedding), and then extract a subset of the samples useful for the application under consideration. In our case we focus on synthetic image generation and instance segmentation and then finally go through thorough testing, analysis and review of the algorithms used and the results obtained.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview</head><p>With the advent of Deep Learning, applications that rely on huge amounts of data have emerged to be game changers in a wide range of topics and across the disciplines. The dramatic improvement in accuracy and speed has paved the way for the first time to use automated learning techniques in scenarios where reliability is key, such as safety-critical systems and self-driving cars. The use of these techniques in space exploration is starting to take place; as conditions in other planets are adverse for humans, robots are in charge of teleoperated missions on their own prior to human settlement. Autonomy will be crucial for the possibility of humanity to establish elsewhere.</p><p>In this work we initiate a journey through several techniques that will give us the ability to understand the data, analyse it and even generate new synthetic samples, sometimes indistinguishable at the human eye by learning the original distribution by the use of examples and sampling from it. We will also extract semantic information from the collected images as a way to show that we can apply successfully on other planets the same techniques we use on Earth for systems that learn by itself. These algorithms are the seed for more complex enterprises under the condition of scarce data. After all, our ability to compile large amounts of information from other planets is bounded, such as SLAM and VIO.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Data Collection</head><p>The first stage of our study consists on data collection. We provide scripts to massively scrape data from NASA Website 4 using the tools Selenium 5 and Beautiful Soup <ref type="bibr" target="#b5">6</ref> . Images from NASA Perseverance and Curiosity are provided in the project webpage. Scripts and detailed information of the process of data acquisition can be found in our repository on GitHub 7 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Visualization</head><p>With the aim of using a subset of the collected data for synthetic image generation and instance segmentation, we visualize the data to look for a significant portion of the samples to use, and identify outliers and points outside the distribution. Also, it is important to consider that images are taken using contrasting configurations of cameras; and we choose a subset that describes well the terrain of the surface of Mars. The techniques under study are K-means Clustering with a prior projection on the 2D plane by the use of PCA(2) and t-SNE with a prior reduction of dimensionality using PCA which adjusts the number of Principal Components to explain for 99% of variance, <ref type="figure" target="#fig_1">Figure 1</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">K-means Clustering</head><p>We project the data into a 2D plane by the use of PCA and then apply Kmeans Clustering, where k is the number of cameras used on each mission. Due to the high dimensionality of the problem, the need to use a more sophisticated technique arises. The resultant projection does not show well defined clusters and not all outliers are correctly rejected. K-means Clustering is a lineal technique and a lot of information is lost on the 2D plane projection. So we then propose to use t-SNE which is based on a probabilistic measure to accomplish the task. We introduce an adaptive t-SNE technique with a varying degree of explainability of variance given by PCA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">t-SNE</head><p>t-SNE (t-Distributed Stochastic Neighbor Embedding) was proposed in <ref type="bibr" target="#b40">[41]</ref> and introduces a probabilistic technique to visualize and understand high-dimensional data such as images. We perform a prior dimensionality reduction by the use of PCA, in which we choose adaptively the number of Principal Components that explains the 99% of the variance, <ref type="figure" target="#fig_2">Figure 2</ref>. Proposing then a PCA adaptive t-SNE. Having this adaptive behavior is central to the task at hand to extend the validity of the technique to a varying number of data points, camera settings, and changing environments. This technique allows us to select a subset of the original data taken by MastCam-Z which is useful for synthetic terrain generation and instance segmentation. It helps identify out-of-distribution points, and clusters together all images pertaining to cameras pointing to martian terrain. The subset of data is released as a dataset on its own 8 , both in PNG image format and in TFRecords for rapid importation and training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Synthetic Generation of Samples</head><p>The field of synthetic image generation has seen rapid progress. The necessity to generate synthetic imagery given some training data in many applications (simulated environments, additional training data, style-transfer) has seen great research efforts to establish a stable, principled way to accomplish the task. Generative Adversarial Networks (GANs) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b21">22]</ref> and VAE (Variational AutoEncoders) <ref type="bibr" target="#b24">[25]</ref> offer stable training mechanisms to achieve convergence. Yet, more progress is needed as the capacity of the network is mainly bounded by the GPU memory and training resources available <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b2">3]</ref>. Results often suffer from mode collapse and gradient explosion, and its good performance to accomplish complex tasks such as generating additional multi-view frames is yet to be proven.</p><p>The work presented in <ref type="bibr" target="#b38">[39]</ref> introduced a new type of generative model based on annealed Langevin <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b43">44]</ref>. The method is further developed in <ref type="bibr" target="#b39">[40]</ref>, where they show competitive image generation. Diffusion Probabilistic Models <ref type="bibr" target="#b16">[17]</ref> achieved state-of-the-art results on CIFAR10 building on the same principles derived from diffusion-based methods <ref type="bibr" target="#b13">[14]</ref>. However, Score-based Generative Models <ref type="bibr" target="#b18">[19]</ref> suffer from the same drawbacks of GANs and their real-time implementation is not viable due to the sampling step where the dimension of the output must be the same as the dimension of the input. That is, they are hugely dependent on GPU memory resources and necessitate high computing time.</p><p>Supplemental recent approaches <ref type="bibr" target="#b46">[47]</ref> are based on the attention mechanism <ref type="bibr" target="#b41">[42]</ref> building mainly on Vision Transformers <ref type="bibr" target="#b10">[11]</ref>. Other techniques like NeRF <ref type="bibr" target="#b33">[34]</ref> could be essential to add structure to the learning paradigm. In the context of space exploration, these techniques could have a huge impact, as the number of data is by definition scarce; although diminishing, due to our limitation to collect high-resolution data in other planets. Bandwidth and latency of operating a commercial robot at thousands of km from Earth severely limit the real-time data acquisition and capacity of reaction of human-controlled rovers. Indeed, being able to synthesize new useful data from few observations could enable fast and improved SLAM and VIO, as well as enhance autonomous capabilities of the extraterrestrial robot counterparts. We focus on the problem of generating synthetic images with a limited amount of data, being Stylegan2-ADA <ref type="bibr" target="#b20">[21]</ref> the baseline method of choice for our studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Stylegan2-ADA</head><p>GANs learn a probability distribution from samples by training concomitantly two networks, the Generator (G) produces images that resemble the original training instances while the Discriminator (D) determines their fidelity. The networks are trained until convergence in a zero-sum game fashion. Reference <ref type="bibr" target="#b20">[21]</ref> goes beyond the common GAN architecture by leveraging the concept of Stochastic Discriminator Augmentation and proposing an Adaptive Discriminator Augmentation (ADA) that helps the network converge to same accuracy levels as before but with a few thousand samples; which makes it ideal for our application. We train the network with a subset of 5025 samples from the NASA Perseverance mission using an NVIDIA-P100 on the cloud during 48h. The results obtained are consistent. We sample the trained model to generate 100, 1000 and 10000 samples, see <ref type="figure" target="#fig_3">Figure 3</ref>; and release the data publicly for testing purposes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Score-based Generative Modeling</head><p>Based on annealed langevin <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40]</ref>, Score-based Generative Modeling introduces a new way to generate synthetic data as an alternative to adversarial learning in GANs.</p><p>We conduct synthetic image generation using grayscale data from NASA Perseverance at image size 28 ? 28 and sample the learned distribution using PC (Predict-Correct) Sampling, Euler-Maruyama, and ODE Sampling, <ref type="figure" target="#fig_4">Figure 4</ref>.</p><p>If we then compute the likelihood on the dataset by the use of the learned model and a batch size of 32 we get an average number of bits per dimension of 6.18. In comparison for example to an average number of bits per dimension on MNIST of 3.98. This means the subset of samples from NASA Perseverance we have chosen is a good candidate to test learning models such as GANs and Scorebased Generative Modeling because the learned latent spaces have to incorporate complex features such as description of the terrain, rocks and sky while keeping the number of samples low. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Statistical Analysis of the Generated Distribution</head><p>Considering the original subset of data from NASA Perseverance and the generated synthetic dataset of 1000 images as two distributions we want to compare, we propose a preliminary statistical analysis by means of a non-parametric test: Kruskal-Wallis <ref type="bibr" target="#b26">[27]</ref>. In order to proceed with the evaluation, we compute the mean of the RGB image intensities or gray-scale as a proxy of image descriptor; although unadorn, mean intensity can provide rough texture information for an initial assessment. We first test the homoscedasticity, or equality of variances, by means of the test of Levene; and we also test for normality of the two distributions. Finally we compute goodness of fit by Kruskal-Wallis. In the case of homoscedasticity we reject the null hypothesis (significant p-value less than 0.05), same for normality of the original distribution (as expected as the original samples do not follow a distribution Gaussian). In the case of the synthetic samples, we accept the null hypothesis for the case of normality and we can assure the distribution is normal, which makes sense as the GAN architecture models initially the samples as noise White Gaussian and then modifies them step by  step to fit the original distribution. We cannot accept though the null hypothesis for goodness of fit, which means that a more sophisticated way of measuring the sample quality in GAN has to be proposed, as has already been extensively seen in the current literature. For example, MS-SSIM <ref type="bibr" target="#b35">[36]</ref> and FID <ref type="bibr" target="#b15">[16]</ref> are the most accepted measures. However, this simple non-parametric analysis, <ref type="figure" target="#fig_6">Figure 5</ref>, can serve as a unit test for GAN and other variational methods once the model is trained and the authors have not seen it widely used in the community so far. <ref type="table">Table 1</ref>: Interpretation of statistical measures given the proposed pipeline under study, <ref type="figure" target="#fig_6">Figure 5</ref>.</p><formula xml:id="formula_0">v V v b 2 D w 6 P q s c n X R 0 l i t A O i X i k + g H W l D N J O 4 Y Z T v u x o l g E n P a C 2 V 3 m 9 5 6 o 0 i y S j 2 Y e U 1 / g i W Q h I 9 h k k l t 3 r 0 b V m v 1 y o H X i F a Q G B d q j 6 t d w H J F E U G k I x 1 o P P D c 2 f o q V Y Y T T R W W Y a B p j M s M T O r B U Y k G 1 n + a 7 L t C F V c Y o j J R 9 0 q B c / d 2 R Y q H 1 X A S 2 U m A z 1 a t e J v 7 n D R I T 3 v o p k 3 F i q C T L Q W H C k Y l Q d j g a M 0 W J 4 X N L M F H M 7 o r I F C t M j I 2 n Y k P w V k 9 e J 9 1 G 3 b u u N x + a t V a j i K M M Z 3 A O l + D B D b T g H t r Q A Q J T e I Z X e H O E 8 + K 8 O x / L 0 p J T 9 J z C H z i f P 8 X g j V 4 = &lt; / l a t e x i t &gt; 0.05 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " W J c B A p b N Y f x e i N I o y B U M S J J V 4 C E = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l K U Y + F X j x W M G 2 h D W W z n b Z L N 5 u w u x F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y l s b e / s 7 h X 3 S w e H R 8 c n 5 d O z t o 5 T x d B n s Y h V N 6 Q a B Z f o G 2 4 E d h O F N A o F d s J p c + F 3 n l B p H s t H M 0 s w i O h Y 8 h F n 1 F j J b w 4 y b z 4 o V 9 y q u w T Z J F 5 O K p C j N S h / 9 Y c x S y O U h g m q d c 9 z E x N k V B n O B M 5 L / V R j Q t m U j r F n q a Q R 6 i B b H j s n V 1 Y Z k l G s b E l D l u r v i Y x G W s + i 0 H Z G 1 E z 0 u r c Q / / N 6 q R n d B R m X S W p Q s t W i U S q I i c n i c z L k C p k R M 0 s o U 9 z e S t i E K s q M z a d k Q / D W X 9 4 k 7 V r V u 6 n W H + q V R i 2 P o w g X c A n X 4 M E t N O A e W u A D A w 7 P 8 A p v j n R e n H f n Y 9 V a c P K Z c / g D 5 / M H f T y O c A = = &lt; / l a t e x i t &gt; C1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 4 b V + p H y G d o I 9 a R n W q B f A J U 7 O l w = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l K U Y + F X j x W M G 2 h D W W z n b Z L N 5 u w u x F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y l s b e / s 7 h X 3 S w e H R 8 c n 5 d O z t o 5 T x d B n s Y h V N 6 Q a B Z f o G 2 4 E d h O F N A o F d s J p c + F 3 n l B p H s t H M 0 s w i O h Y 8 h F n 1 F j J b w 6 y 2 n x Q r r h V d w m y S b y c V C B H a 1 D + 6 g 9 j l k Y o D R N U 6 5 7 n J i b I q D K c C Z y X + q n G h L I p H W P P U k k j 1 E G 2 P H Z O r q w y J K N Y 2 Z K G L N X f E x m N t J 5 F o e 2 M q J n o d W 8 h / u f 1 U j O 6 C z I u k 9 S g Z K t F o 1 Q Q E 5 P F 5 2 T I F T I j Z p Z Q p r i 9 l b A J V Z Q Z m 0 / J h u C t v 7 x J 2 r W q d 1 O t P 9 Q r j V o e R x E u 4 B K u w Y N b a M A 9 t M A</formula><formula xml:id="formula_1">Test Population Result Interpretation 1 C1 and C2 ? ? (a) (b) 2 C2 ? ? (c) (d) 3 C1 and C2 ? ? (e) (f)</formula><p>Description and interpretation of statistical measures in <ref type="table">Table 1</ref>.</p><p>(a) Necessary condition but not sufficient to assert that both populations originate from the same distribution. (b) There is not enough statistical evidence to attest both populations samples originate from the same distribution. (c) With high probability the synthetic distribution generated is still close enough to the initial distribution of noise from the GAN architecture. The samples may not show enough fidelity, and there is probably bad generalization behavior.</p><p>(d) The synthetic distribution is far from the initial distribution of noise and has deviated from the original Normal and may be close to the target distribution. (e) If (a) then there is enough statistical evidence to confirm that both populations originate from the same distribution given this image descriptor. (f) There is not enough statistical evidence to attest both populations are from the same distribution.</p><p>We have proposed statistical measures and a visualization pipeline to study and understand the data under consideration. However, the highly dimensional nature of images and the fact that video streams are sequential introduces a notion of time and space that our analysis has not taken into consideration. Indeed, the data consists on a sequence of images captured during a given lineal period of time following a specific path on the surface of Mars. To this effect, in the next section we borrow tools from harmonic analysis to provide further interpretation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Signature Transform and Harmonic Analysis</head><p>The Signature Transform <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b34">35</ref>] is a roughly equivalent to Fourier; instead of extracting information about frequency extracts information about order and area.</p><p>Howbeit, the Signature Transform differs from Fourier by the fact that it utilizes a basis of the space of functions of paths, a more general case to the basis of space of paths found in the preceding.</p><p>Following <ref type="bibr" target="#b1">[2]</ref>, the truncated signature of order N of the path x is defined as a collection of coordinate iterated integrals</p><formula xml:id="formula_2">S N (x) = ? ? ? ? ? ? ? ? 0&lt;t1&lt;???&lt;ta&lt;1 a c=1 df zc dt (t c )dt 1 ? ? ? dt a ? ? 1?z1,...,za?d ? ? ? 1?a?N .<label>(1)</label></formula><p>The Signature is a homomorphism from the monoid of paths into the grouplike elements of a closed tensor algebra, Equation 2. It provides a graduated summary of the path x. These extracted features of a path are at the center of the definition of a rough path <ref type="bibr" target="#b29">[30]</ref>; they remove the necessity to take into account the inner detailed structure of the path.</p><formula xml:id="formula_3">S : f ? F | f : [x, y] ? E = R d ?? T (E) = T (R d ) = ? c=0 R d ?c . (2)</formula><p>It has many advantages over other tools of harmonic analysis for ML. It is a universal non-linearity, which means that every continuous function of the input stream may be approximated arbitrary well by a linear function of its signature. Also, among other properties, presents outstanding robustness behavior to missing or irregularly sampled data along with optional invariance in terms of translation and sampling. It has recently been introduced in the context of Deep Learning to add some structure to the learning process; and seems a promising tool in Generative Models and Reinforcement Learning; as well as a good theoretical framework. It mainly works on streams of data which could describe from video sequences to all the set of our life experiences. Scilicet, under the correct assumptions and the right application, it could potentially compress all human experiences in a representation that could be stored and processed efficiently.</p><p>Here we propose to do a preliminary study in terms of harmonic analysis and understand its properties to compare the original and synthetic samples. The Signature <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b11">12]</ref> of an input stream of data encodes the order in which data arrives without caring precisely when it arrives. This property which is known as invariance to time reparameterisations <ref type="bibr" target="#b28">[29]</ref>, makes it an ideal candidate to measure GAN generated distributions against an original data stream. That is to say, when sampling the GAN model, instances of the latent space are retrieved in no specific order although the original data is by definition time dependent, as recorded video streams or image captured by sensors are constrained and bounded by time physics. However, GANs are not able to generate yet data lineally in time and space, and thus the comparison using other methods may be biased or not take into account all the relevant cues.</p><p>Withal, it is important to note that the number of components of the truncated signature does not depend on the number of data samples into consideration. Namely, it maps the infinite-dimensional space of streams of data S(R d ) into a finite-dimensional space of dimension (d N +1 ? 1)/(d ? 1), where N corresponds to the order of the truncated signature, which makes it very appropriate to process long sequential data with varying length or unevenly sampled data.</p><p>At the same time, we can introduce the concept of log-signature <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b34">35]</ref>, which is a more compact representation than the Signature. Definition 1. If ? t ? E is a path segment and S is its Signature then</p><formula xml:id="formula_4">S = 1 + S 1 + S 2 + . . . ?c, S c ? E ?c log (1 + x) = x ? x 2 /2 + . . . log S = S 1 + S 2 + . . . ? S 1 + S 2 + . . . 2 /2 + . . . The series log S = S 1 + S 2 + . . . ? S 1 + S 2 + . . . 2 /2 + . . . which is well</formula><p>defined, is referred to as the log-signature of ?.</p><p>Unlike the Signature, the log-signature does not guarantee universality <ref type="bibr" target="#b29">[30]</ref> and thus it needs to be combined with non-linear models for learning. However, it is empirically more robust to sparsely sampled data. There is a one-to-one correspondence between the Signature and the log-signature as the logarithm map is bijective <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b27">28]</ref>. This statement also holds true for the truncated case up to the same degree.</p><p>In this line of work, we perform a comparison of the mean signature and logsignature of original against synthetic samples at size 64 ? 64 and observe that synthetic samples encompass the most relevant information from the original harmonic distribution, see <ref type="figure" target="#fig_7">Figure 6</ref>. We compare against a set of 1000 and 5000 synthetic samples and each instance is considered to be a path x of dimension 64 to which we apply the Signature and log-signature transforms. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">RMSE and MAE Signature and Log-signature</head><p>We propose to use the element-wise mean of the truncated signaturesS N , <ref type="figure" target="#fig_8">Figure  7</ref>, to analyse the convergence of GAN learned models by the use of RMSE (Root Mean Squared Error) and MAE (Mean Absolute Error); we name the measures RMSE and MAE Signature and RMSE and MAE log-signature. For instance, in  <ref type="figure" target="#fig_9">Figure 8</ref> we can observe that the model is attaining good convergence, although is not capturing all the information present in the original distribution. RMSE and MAE Signature and log-signature can be used not only to compare models but also to keep performance of training across several epochs and analytically detect overfitting, <ref type="table" target="#tab_0">Table 2</ref>. Although all measures capture information about the visual cues present in the distributions, RMSE and MAE Signature and MAE log-signature are more accurate at keeping track of the GAN training procedure convergence, while RMSE log-signature is less precise. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Evaluation</head><p>We enclose results of the proposed measures using several state-of-the-art pretrained models, <ref type="table">Table 3</ref>. For the evaluation and testing we use the standard AFHQ dataset <ref type="bibr" target="#b8">[9]</ref> classes 'cat', 'dog' and 'wild' and MetFaces <ref type="bibr" target="#b20">[21]</ref>, together with the corresponding pretrained models. To compute RMSE and MAES N and logS N we generate 1000 synthetic samples of each model and compare against the full original dataset. The samples are transformed to grayscale and resized at 64 ? 64 previous to the Signature Transform. Visual comparison of the spectrum is provided in <ref type="figure" target="#fig_1">Figures 9 and 10</ref> where it can be seen that the trained models are actually learning the empirical distribution of the original data.</p><p>In <ref type="table">Table 3</ref> we compare the recently developed models {r, t}-Stylegan3-ada <ref type="bibr" target="#b21">[22]</ref> against Stylegan2-ada using MetFaces, where we can see that t-Stylegan3-ada clearly outperforms Stylegan2-ada and r-Stylegan3-ada, which agree with the FID results reported in <ref type="bibr" target="#b21">[22]</ref>. Visual comparison of the spectrum of the Signatures for the given dataset can be seen in <ref type="figure" target="#fig_1">Figure 10</ref>. <ref type="table">Table 3</ref>: RMSE and MAE Signature and log-signature evaluation and comparison on AFHQ and MetFaces using state-of-the-art pretrained models of Stylegan2ada <ref type="bibr" target="#b20">[21]</ref> and Stylegan3-ada <ref type="bibr" target="#b21">[22]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Instance Segmentation</head><p>Instance Segmentation is the problem of assigning to each pixel a corresponding semantic label according to some training attributes of choice. This formulation can be of utmost importance in many applications, from self-driving vehicles to drone guidance in unknown environments (e.g. the NASA helicopter Ingenuity). The extraction of semantic information from visual sensors is one of the enablers of intelligence as we humans conceive it. After all, visual input is our main source of trigger towards actionable tasks; and man-made robots as we have conceived them do suffer or are blessed from this fact. However, current trend in robotics allows to fuse this information with input from other sensors, such as LiDARs, radars, event-cameras, low-power bluetooth (UWB) <ref type="bibr" target="#b44">[45]</ref> and even audio features. We will focus here though mainly on the study of visual information, and let for future works the mixture of other sensor inputs.</p><p>We propose an initial pipeline for instance segmentation on the surface of Mars by using a model DeepLab-v3 <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b4">5]</ref> pre-trained on the dataset ADE20K <ref type="bibr" target="#b47">[48]</ref>, which contains many samples from terrains on Earth with attributes that can appear on Mars (rocks, sky, sand, terrain). We use the model without retraining or finetuning, <ref type="figure" target="#fig_1">Figure 11</ref>, as we do not possess segmentation masks of the given samples. Finetuning on a subset of the samples from Mars, e.g. 200 correctly labeled instances, would allow for state-of-the-art results on real-time data sent by a rover acting as a relay on the surface of the planet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Other Applications</head><p>Beyond synthetic image generation and instance segmentation, which are indeed intermediate steps for other tasks, the main goal of using automated learning techniques in space exploration is the capacity to provide robots with a highdegree of autonomy so that they can explore efficiently the surface of other planets. Teleoperation is hard in a context where bandwidth and latency depend on many factors, and the higher the autonomy we confer to the rovers, the greater will be the benefits of a continued presence of humanity in other celestial bodies. As a consequence, one application in this regard that is capital is the ability to model 3D environments as accurately as possible <ref type="bibr" target="#b8">9</ref> . Being style-transfer from simulation, see <ref type="figure" target="#fig_1">Figure 12</ref>, to super-realistic images one of the main utilizations of GANs and synthetic image generation in this context. Furthermore, having accurate positioning measurements to contrast against other sensor inputs is very important when dealing with self-driving vehicles. And therefore, being able to process visual imagery while extracting telling information, such as visual cues to understand and predict future trajectories, discovering possible paths to avoid obstacles, having accurate recognition of elements in the environment, and real-time weather and temperature forecast of varying paths to plan precisely for any inconvenient without the need of human intervention. They are among the most pressing applications that need immediate attention from the research community. <ref type="figure" target="#fig_1">Fig. 12</ref>: NASA Curiosity simulator that lets you explore the surface of Mars.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Conclusions</head><p>In this paper, we have presented a pipeline for visual understanding of the imagery captured by the sensors of robots in other planets to introduce an adaptive technique based on t-SNE and PCA that without the need of hyperparameter tuning puts forward exceptional visualization capabilities of the missions. We compare the technique against traditional K-means Clustering to see its many advantages. Furthermore, we go beyond and generate synthetic samples from the surface of Mars by the use of Stylegan2-ADA and propose an effective methodology to statistically test their goodness-of-fit according to the original distribution. Additionally, we conduct synthetic image generation by the use of Scorebased Generative Modeling and experiment with several methods of sampling. We are also the first to propose the use of the Signature Transform to assess GAN convergence by introducing RMSE and MAE Signature and log-signature. Semantic understanding of the samples is achieved through state-of-the-art instance segmentation and we gain insights on how superior performance in other planets could be attained by leveraging networks trained on data from Earth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head><p>In Section A we provide further evaluation results using the statistical measures proposed in Section 6 to assess image quality of synthetic samples. Section B gives special emphasis to the definition of RMSE and MAE Signature and logsignature. In Section C we visualize through the use of the PCA Adaptive t-SNE technique introduced in Section 4 the original and synthetic sets used in the evaluations in Section 7 and Section A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A</head><p>In <ref type="table">Table 4</ref> we can see evaluation test measures of homoscedasticity (T1), normality (T2) and goodness of fit (T3) on NASA Perseverance, AFHQ <ref type="bibr" target="#b8">[9]</ref> and MetFaces <ref type="bibr" target="#b20">[21]</ref>. According to the interpretation proposed in <ref type="table">Table 1</ref>, we can conclude given this image descriptor for example that the models of Stylegan2-ada trained on AFHQ Cat and Wild are very good approximations of the original distributions (we accept the null hypothesis for goodness of fit), although we cannot conclude that the distributions are equal as the equality of variances is not assured. On AFHQ Dog, the model needs more training as T2 (normality of the synthetic distribution) is accepted and therefore the learned distribution is close to the original white noise. The same conclusion holds true for the model trained on NASA Perseverance, more training is needed. For the case of Met-Faces, the learned distribution is far from the original white noise, but we cannot accept the null hypothesis for goodness of fit (there are possible interpretations: there is overfit, the model needs more capacity to represent all the features from the original distribution or it needs more training). <ref type="table">Table 4</ref>: Evaluation of the statistical test measures of homoscedasticity (T1), normality (T2) and goodness of fit (T3) on AFHQ and MetFaces using stateof-the-art pretrained models of Stylegan2-ada <ref type="bibr" target="#b20">[21]</ref> and Stylegan3-ada <ref type="bibr" target="#b21">[22]</ref> and NASA Perseverance.</p><formula xml:id="formula_5">Model Dataset T1 T2 T3 Stylegan2-ada NASA Perseverance ? ? ? AFHQ Cat ? ? ? Dog ? ? ? Wild ? ? ? MetFaces ? ? ? r-Stylegan3-ada ? ? ? t-Stylegan3-ada ? ? ? B</formula><p>To further expand the concepts illustrated in Section 7 we analytically describe the abstraction of a set of images as a unevenly sampled stream of data, e.g. a path, as well as the definitions to measure the similarity between image distributions.</p><p>We can understand a stream of data x ? S(R d ) as a discrete representation of a path. This definition of the signature of a stream of data is independent of the choice of linear interpolation of X by the invariance to time reparameterizations <ref type="bibr" target="#b1">[2]</ref>. where z ? {1, . . . , n} is the specific component index of the given signature.</p><p>Then RMSE and MAE Signature, <ref type="table" target="#tab_0">Tables 2 and 3</ref>, can be defined as follows. The case for log-signature is analogous.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C</head><p>In <ref type="figure" target="#fig_1">Figure 13</ref> and 14 we visualize using PCA Adaptive t-SNE the sets of images of AFHQ and MetFaces, original and synthetic, used in the evaluations in <ref type="table">Tables  3 and 4</ref>. We can observe for instance that the synthetic samples of AFHQ Cat and Wild resemble very much the original distribution, both in variability and quality, while AFHQ Dog lacks some variability but achieves very good quality samples, which agrees with the analytical interpretation of the proposed statistical measures, <ref type="table">Table 4</ref>. Visualization across several epochs of training of NASA Perseverance can be seen on <ref type="figure" target="#fig_1">Figure 15</ref>. In <ref type="figure" target="#fig_1">Figure 14</ref> we can perceive that the synthetic samples generated with t-Stylegan3-ada show better quality than Stylegan2-ada and r-Stylegan3-ada, and the model is clearly learning the original distribution. However, there is room for improvement in terms of variability and scope. These arguments agree with RMSE and MAE Signature and log-signature, <ref type="table">Table 3</ref>. In <ref type="figure" target="#fig_1">Figure 15</ref> we can see the PCA Adaptive t-SNE visualization of original and synthetic samples from NASA Perseverance across several epochs of training as in <ref type="table" target="#tab_0">Table 2</ref>. Results shown in <ref type="figure" target="#fig_3">Figure 3</ref> and <ref type="table">Table 4</ref> originate from epoch iteration 798, which achieves the best RMSE Signature and MAE Signature and logsignature. Visual inspection of iteration 798 corroborates the interpretation from <ref type="table">Table 4</ref> that the samples are close to the original white noise and the model is far from being a good representation of the original distribution as only captures a small subset of the visual cues present in the data. Furthermore, RMSE and MAE Signature and log-signature in <ref type="table" target="#tab_0">Table 2</ref> correctly detect overfitting on iteration 983. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>Visualization pipeline under study.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>K-means Clustering (left) and t-SNE (right) on images from NASA Curiosity (upper figures) and Perseverance (lower figures).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Grid of 100 samples generated by Stylegan2-ADA trained at size 256?256 using samples from NASA Perseverance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Grid of 100 samples generated by PC Sampling (left), Euler-Maruyama (middle) and ODE Sampling (right). The models are trained at size 28 ? 28 during 71 epochs using samples from NASA Perseverance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>3 &lt; l a t e x i t s h a 1 _</head><label>31</label><figDesc>b a s e 6 4 = " Z u A f n Y + q V W O i e R w p E u q w v l D 3 z t 0 = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l K U Y 8 F L z 1 W M G 2 h D W W z n b Z L N 5 u w u x F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y l s b e / s 7 h X 3 S w e H R 8 c n 5 d O z t o 5 T x d B n s Y h V N 6 Q a B Z f o G 2 4 E d h O F N A o F d s L p / c L v P K H S P J a P Z p Z g E N G x 5 C P O q L G S 3 x x k 7 n x Q r r h V d w m y S b y c V C B H a 1 D + 6 g 9 j l k Y o D R N U 6 5 7 n J i b I q D K c C Z y X + q n G h L I p H W P P U k k j 1 E G 2 P H Z O r q w y J K N Y 2 Z K G L N X f E x m N t J 5 F o e 2 M q J n o d W 8 h / u f 1 U j O 6 C z I u k 9 S g Z K t F o 1 Q Q E 5 P F 5 2 T I F T I j Z p Z Q p r i 9 l b A J V Z Q Z m 0 / J h u C t v 7 x J 2 r W q d 1 O t P 9 Q r j V o e R x E u 4 B K u w Y N b a E A T W u A D A w 7 P 8 A p v j n R e n H f n Y 9 V a c P K Z c / g D 5 / M H g 1 + O d A = = &lt; / l a t e x i t &gt; H0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r F J q i n R G n g c d t L E F b P s b e N p w P B Y = " &gt; A A A B 6 3 i c b V D L S g M x F L 1 T X 7 W + q i 7 d B I v g q s y U + l g W 3 L i s Y B / Q D i W T Z t r Q J D M k G a E M / Q U 3 L h R x 6 w + 5 8 2 / M T G e h r Q d C D u f c y 7 3 3 B D F n 2 r j u t 1 P a 2 N z a 3 i n</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>C2Fig. 5 :</head><label>5</label><figDesc>H B h y e 4 R X e H O m 8 O O / O x 6 q 1 4 O Q z 5 / A H z u c P f s G O c Q = = &lt; / l a t e x i t &gt; Statistical measures to study goodness of fit to initially assess GAN convergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 :</head><label>6</label><figDesc>Spectrum of the mean signature (a,b) and log-signature (c,d) of a 64dimensional path up to level 3 of original ('o') against 1000 (a,c) and 5000 (b,d) synthetic ('x') samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>&lt;Fig. 7 :</head><label>7</label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " W J c B A p b N Y f x e i N I o y B U M S J J V 4 C E = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l K U Y + F X j x W M G 2 h D W W z n b Z L N 5 u w u x F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y l s b e / s 7 h X 3 S w e H R 8 c n 5 d O z t o 5 T x d B n s Y h V N 6 Q a B Z f o G 2 4 E d h O F N A o F d s J p c + F 3 n l B p H s t H M 0 s w i O h Y 8 h F n 1 F j J b w 4 y b z 4 o V 9 y q u w T Z J F 5 O K p C j N S h / 9 Y c x S y O U h g m q d c 9 z E x N k V B n O B M 5 L / V R j Q t m U j r F n q a Q R 6 i B b H j s n V 1 Y Z k l G s b E l D l u r v i Y x G W s + i 0 H Z G 1 E z 0 u r c Q / / N 6 q R n d B R m X S W p Q s t W i U S q I i c n i c z L k C p k R M 0 s o U 9 z e S t i E K s q M z a d k Q / D W X 9 4 k 7 V r V u 6 n W H + q V R i 2 P o w g X c A n X 4 M E t N O A e W u A D A w 7 P 8 A p v j n R e n H f n Y 9 V a c P K Z c / g D 5 / M H f T y O c A = = &lt; / l a t e x i t &gt; C1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 0 4 b V + p H y G d o I 9 a R n W q B f A J U 7 O l w = " &gt; A A A B 7 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l K U Y + F X j x W M G 2 h D W W z n b Z L N 5 u w u x F K 6 G / w 4 k E R r / 4 g b / 4 b t 2 0 O 2 v p g 4 P H e D D P z w k R w b V z 3 2 y l s b e / s 7 h X 3 S w e H R 8 c n 5 d O z t o 5 T x d B n s Y h V N 6 Q a B Z f o G 2 4 E d h O F N A o F d s J p c + F 3 n l B p H s t H M 0 s w i O h Y 8 h F n 1 F j J b w 6 y 2 n x Q r r h V d w m y S b y c V C B H a 1 D + 6 g 9 j l k Y o D R N U 6 5 7 n J i b I q D K c C Z y X + q n G h L I p H W P P U k k j 1 E G 2 P H Z O r q w y J K N Y 2 Z K G L N X f E x m N t J 5 F o e 2 M q J n o d W 8 h / u f 1 U j O 6 C z I u k 9 S g Z K t F o 1 Q Q E 5 P F 5 2 T I F T I j Z p Z Q p r i 9 l b A J V Z Q Z m 0 / J h u C t v 7 x J 2 r W q d 1 O t P 9 Q r j V o e R x E u 4 B K u w Y N b a M A 9 t M A H B h y e 4 R X e H O m 8 O O / O x 6 q 1 4 O Q z 5 / A H z u c P f s G O c Q = = &lt; / l a t e x i t &gt; C2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l h D h h e c j i q M a U p C 8 c s D V A f 4 g s a c = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k p 6 r H g x W M F + w F t K J v N p l 2 7 y Y b d S a G U / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f z s b m 1 v b O b m G v u H 9 w e H R c O j l t G Z V p x p t M S a U 7 A T V c i o Q 3 U a D k n V R z G g e S t 4 P R 3 d x v j 7 k 2 Q i W P O E m 5 H 9 N B I i L B K F q p 1 R u H C k 2 / V H Y r 7 g J k n X g 5 K U O O R r / 0 1 Q s V y 2 K e I J P U m K 7 n p u h P q U b B J J 8 V e 5 n h K W U j O u B d S x M a c + N P F 9 f O y K V V Q h I p b S t B s l B / T 0 x p b M w k D m x n T H F o V r 2 5 + J / X z T C 6 9 a c i S T P k C V s u i j J J U J H 5 6 y Q U m j O U E 0 s o 0 8 L e S t i Q a s r Q B l S 0 I X i r L 6 + T V r X i X V d q D 7 V y v Z r H U Y B z u I A r 8 O A G 6 n A P D W g C g y d 4 h l d 4 c 5 T z 4 r w 7 H 8 v W D S e f O Y M / c D 5 / A M m N j z s = &lt; / l a t e x i t &gt; . . . &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l h D h h e c j i q M a U p C 8 c s D V A f 4 g s a c = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k p 6 r H g x W M F + w F t K J v N p l 2 7 y Y b d S a G U / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f z s b m 1 v b O b m G v u H 9 w e H R c O j l t G Z V p x p t M S a U 7 A T V c i o Q 3 U a D k n V R z G g e S t 4 P R 3 d x v j 7 k 2 Q i W P O E m 5 H 9 N B I i L B K F q p 1 R u H C k 2 / V H Y r 7 g J k n X g 5 K U O O R r / 0 1 Q s V y 2 K e I J P U m K 7 n p u h P q U b B J J 8 V e 5 n h K W U j O u B d S x M a c + N P F 9 f O y K V V Q h I p b S t B s l B / T 0 x p b M w k D m x n T H F o V r 2 5 + J / X z T C 6 9 a c i S T P k C V s u i j J J U J H 5 6 y Q U m j O U E 0 s o 0 8 L e S t i Q a s r Q B l S 0 I X i r L 6 + T V r X i X V d q D 7 V y v Z r H U Y B z u I A r 8 O A G 6 n A P D W g C g y d 4 h l d 4 c 5 T z 4 r w 7 H 8 v W D S e f O Y M / c D 5 / A M m N j z s = &lt; / l a t e x i t &gt; . . . &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b 1 L K h H 1 V 4 n f j d g T 1 g q E S 0 n c g N 4 g = " &gt; A A A B 7 H i c b V B N S w M x E J 3 U r 1 q / q h 6 9 B I v g q e y W o h 4 L X j x J R b c t t G v J p t k 2 N J t d k q x Q l v 4 G L x 4 U 8 e o P 8 u a / M W 3 3 o K 0 P B h 7 v z T A z L 0 g E 1 8 Z x v l F h b X 1 j c 6 u 4 X d r Z 3 d s / K B 8 e t X S c K s o 8 G o t Y d Q K i m e C S e Y Y b w T q J Y i Q K B G s H 4 + u Z 3 3 5 i S v N Y P p h J w v y I D C U P O S X G S t 7 9 Y 3 Y 7 7 Z c r T t W Z A 6 8 S N y c V y N H s l 7 9 6 g 5 i m E Z O G C q J 1 1 3 U S 4 2 d E G U 4 F m 5 Z 6 q W Y J o W M y Z F 1 L J Y m Y 9 r P 5 s V N 8 Z p U B D m N l S x o 8 V 3 9 P Z C T S e h I F t j M i Z q S X v Z n 4 n 9 d N T X j l Z 1 w m q W G S L h a F q c A m x r P P 8 Y A r R o 2 Y W E K o 4 v Z W T E d E E W p s P i U b g r v 8 8 i p p 1 a r u R b V + V 6 8 0 a n k c R T i B U z g H F y 6 h A T f Q B A 8 o c H i G V 3 h D E r 2 g d / S x a C 2 g f O Y Y / g B 9 / g D A R o 6 c &lt; / l a t e x i t &gt; S N &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l h D h h e c j i q M a U p C 8 c s D V A f 4 g s a c = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k p 6 r H g x W M F + w F t K J v N p l 2 7 y Y b d S a G U / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f z s b m 1 v b O b m G v u H 9 w e H R c O j l t G Z V p x p t M S a U 7 A T V c i o Q 3 U a D k n V R z G g e S t 4 P R 3 d x v j 7 k 2 Q i W P O E m 5 H 9 N B I i L B K F q p 1 R u H C k 2 / V H Y r 7 g J k n X g 5 K U O O R r / 0 1 Q s V y 2 K e I J P U m K 7 n p u h P q U b B J J 8 V e 5 n h K W U j O u B d S x M a c + N P F 9 f O y K V V Q h I p b S t B s l B / T 0 x p b M w k D m x n T H F o V r 2 5 + J / X z T C 6 9 a c i S T P k C V s u i j J J U J H 5 6 y Q U m j O U E 0 s o 0 8 L e S t i Q a s r Q B l S 0 I X i r L 6 + T V r X i X V d q D 7 V y v Z r H U Y B z u I A r 8 O A G 6 n A P D W g C g y d 4 h l d 4 c 5 T z 4 r w 7 H 8 v W D S e f O Y M / c D 5 / A M m N j z s = &lt; / l a t e x i t &gt; . . . &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " l h D h h e c j i q M a U p C 8 c s D V A f 4 g s a c = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S J 4 K k k p 6 r H g x W M F + w F t K J v N p l 2 7 y Y b d S a G U / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f z s b m 1 v b O b m G v u H 9 w e H R c O j l t G Z V p x p t M S a U 7 A T V c i o Q 3 U a D k n V R z G g e S t 4 P R 3 d x v j 7 k 2 Q i W P O E m 5 H 9 N B I i L B K F q p 1 R u H C k 2 / V H Y r 7 g J k n X g 5 K U O O R r / 0 1 Q s V y 2 K e I J P U m K 7 n p u h P q U b B J J 8 V e 5 n h K W U j O u B d S x M a c + N P F 9 f O y K V V Q h I p b S t B s l B / T 0 x p b M w k D m x n T H F o V r 2 5 + J / X z T C 6 9 a c i S T P k C V s u i j J J U J H 5 6 y Q U m j O U E 0 s o 0 8 L e S t i Q a s r Q B l S 0 I X i r L 6 + T V r X i X V d q D 7 V y v Z r H U Y B z u I A r 8 O A G 6 n A P D W g C g y d 4 h l d 4 c 5 T z 4 r w 7 H 8 v W D S e f O Y M / c D 5 / A M m N j z s = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " + g y f o l e q U p / G b u I W e J / j W z 5 l x t E = " &gt; A A A C M X i c b V B N a 9 t A E F 3 l o 3 W d t F G T Y y 9 L T M C G Y i Q T k h 4 D v u R U X F L b A c s x q / X I X r z a F b u j U i P 0 l 3 r J P w m 9 5 J A Q e s 2 f 6 N r x o b X z Y O D x 3 g w z 8 + J M C o t B c O 9 t b e / s v n l b e V f d 2 3 / / 4 c D / e N i z O j c c u l x L b a 5 j Z k E K B V 0 U K O E 6 M 8 D S W E I / n r U X f v 8 H G C u 0 + o 7 z D I Y p m y i R C M 7 Q S S P / M k L 4 i U q b l M m i I z W W k Y Q E 6 x E K O Y b i q r w p v p b 1 9 q g I y 8 Z n u q G 2 y k Z k x G S K j Z F f C 5 r B E n S T h C t S I y t 0 R v 5 d N N Y 8 T 0 E h l 8 z a Q R h k O C y Y Q c E l l N U o t 5 A x P m M T G D i q W A p 2 W C w / L u m J U 8 Y 0 0 c a V Q r p U / 5 0 o W G r t P I 1 d Z 8 p w a t e 9 h f i a N 8 g x + T I s h M p y B M V f F i W 5 p K j p I j 4 6 F g Y 4 y r k j j B v h b q V 8 y g z j 6 E K u u h D C 9 Z c 3 S a / V D M + a p 9 9 O a x e t V R w V 8 o k c k z o J y T m 5 I J e k Q 7 q E k 1 / k N 3 k g j 9 6 t d + 8 9 e X 9 e W r e 8 1 c w R + Q / e 8 1 9 V Y q r G &lt; / l a t e x i t &gt; Plot ?S N (C1),S N (C2) ? &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " q k G C u d T m g j Y U Q m x I 9 0 8 D w E X 6 3 M U = " &gt; A A A B 9 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l K U Y 8 F L 5 6 k o v 2 A N p b N Z t M u 3 W z i 7 q Z Q Q n 6 H F w + K e P X H e P P f u G 1 z 0 N Y H A 4 / 3 Z p i Z 5 8 W c K W 3 b 3 1 Z h b X 1 j c 6 u 4 X d r Z 3 d s / K B 8 e t V W U S E J b J O K R 7 H p Y U c 4 E b W m m O e 3 G k u L Q 4 7 T j j a 9 n f m d C p W K R e N D T m L o h H g o W M I K 1 k d y + Z t y n 6 X 3 2 m N 5 m g 3 L F r t p z o F X i 5 K Q C O Z q D 8 l f f j 0 g S U q E J x 0 r 1 H D v W b o q l Z o T T r N R P F I 0 x G e M h 7 R k q c E i V m 8 6 P z t C Z U X w U R N K U 0 G i u / p 5 I c a j U N P R M Z 4 j 1 S C 1 7 M / E / r 5 f o 4 M p N m Y g T T Q V Z L A o S j n S E Z g k g n 0 l K N J 8 a g o l k 5 l Z E R l h i o k 1 O J R O C s / z y K m n X q s 5 F t X 5 X r z R q e R x F O I F T O A c H L q E B N 9 C E F h B 4 g m d 4 h T d r Y r 1 Y 7 9 b H o r V g 5 T P H 8 A f W 5 w 8 r H Z J S &lt; / l a t e x i t &gt;S N &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q 7 6 7 a d P b 1 J b c Z j j S 5 a j I k V b j o W s = " &gt; A A A C M X i c b V B N S 8 N A E N 3 4 b f 2 q e v S y W I Q W p C R F 1 K M g g h f F r 6 r Q 1 L L Z T t r F z S b s T s Q S 8 p e 8 + E / E i w d F v P o n 3 N Y e 1 P p g 4 P H e D D P z g k Q K g 6 7 7 4 o y N T 0 x O T c / M F u b m F x a X i s s r l y Z O N Y c 6 j 2 W s r w N m Q A o F d R Q o 4 T r R w K J A w l V w u 9 / 3 r + 5 A G x G r C + w l 0 I x Y R 4 l Q c I Z W a h U P f Y R 7 V L G O m M z O j s 4 P c l 9 C i G U f h W x D d p 7 f Z M d 5 e b + V e X l l k 4 6 o t b z i a 9 H p Y q V V L L l V d w A 6 S r w h K Z E h T l r F J 7 8 d 8 z Q C h V w y Y x q e m 2 A z Y x o F l 5 A X / N R A w v g t 6 0 D D U s U i M M 1 s 8 H F O N 6 z S p m G s b S m k A / X n R M Y i Y 3 p R Y D s j h l 3 z 1 + u L / 3 m N F M P d Z i Z U k i I o / r 0 o T C X F m P b j o 2 2 h g a P s W c K 4 F v Z W y r t M M 4 4 2 5 I I N w f v 7 8 i i 5 r F W 9 7 e r W 6 V Z p b 3 M Y x w x Z I + u k T D y y Q / b I I T k h d c L J A 3 k m r + T N e X R e n H f n 4 7 t 1 z B n O r J J f c D 6 / A J 7 R q l g = &lt; / l a t e x i t &gt; RMSE ?S N (C1),S N (C2) ? &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F X t e V L Z / y T u / W Q j E J P O e / h F G 7 3 o = " &gt; A A A C M H i c b V B N a 9 t A E F 0 l a e u 6 H 1 G T Y y 5 L T M E G Y 6 R g 2 h 5 T Q k g u C S 6 N P 8 B y z W o 9 s h e v V m J 3 V G q E f l I u + S n J p Y W G 0 m t + R d Y f h 9 T u g 4 H H e z P M z A t T K Q x 6 3 i 9 n a 3 v n 2 f M X p Z f l V 6 / f v N 1 1 3 + 1 1 T J J p D m 2 e y E T 3 Q m Z A C g V t F C i h l 2 p g c S i h G 0 5 P 5 n 7 3 O 2 g j E n W F s x Q G M R s r E Q n O 0 E p D 9 y x A + I E q 0 T G T + c X n 0 y K Q E G E 1 Q C F H k H 8 t v u W X R f V k m P t F r U 4 3 1 K O i F m g x n m B t 6 F a 8 h r c A 3 S T + i l T I C q 2 h e x u M E p 7 F o J B L Z k z f 9 1 I c 5 E y j 4 B K K c p A Z S B m f s j H 0 L V U s B j P I F w 8 X 9 L 1 V R j R K t C 2 F d K E + n c h Z b M w s D m 1 n z H B i 1 r 2 5 + D + v n 2 H 0 a Z A L l W Y I i i 8 X R Z m k m N B 5 e n Q k N H C U M 0 s Y 1 8 L e S v m E a c b R Z l y 2 I f j r L 2 + S z l H D / 9 B o f m l W j u u r O E r k g B y S K v H J R 3 J M z k m L t A k n 1 + S O / C b 3 z o 3 z 0 / n j / F 2 2 b j m r m X 3 y D 5 y H R 8 W W q e o = &lt; / l a t e x i t &gt; MAE ?S N (C1),S N (C2) ? Visual explanation of the use ofS N to analyze GAN convergence. Samples are resized at 64 ? 64 and transformed to grayscale previous to the computation of the signatures. The procedure used for log-signature logS N is analogous.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 :</head><label>8</label><figDesc>Spectrum of the element-wise mean of the signatures (left) and logsignatures (right) of order 3 and size 64 ? 64 of original ('o') against synthetic ('x') samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 9 :</head><label>9</label><figDesc>Spectrum of the element-wise mean of the signaturesS 3 (top) and logsignatures logS 3 (bottom) of order 3 and size 64 ? 64 of original ('o') against synthetic ('x') samples. (a,d): AFHQcat, (b,e): AFHQdog, (c,f): AFHQwild.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 10 :</head><label>10</label><figDesc>Spectrum comparison of the element-wise mean of the signaturesS 3 (top) and log-signatures logS 3 (bottom) of order 3 and size 64 ? 64 of original ('o') against synthetic ('x') samples from MetFaces. (a,d): Stylegan2-ada, (b,e): r-Stylegan3-ada, (c,f): t-Stylegan3-ada.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 11 :</head><label>11</label><figDesc>Segmentation of a given sample without re-training on samples from Mars using Deeplab-v3 trained on ADE20K.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Definition 2 .</head><label>2</label><figDesc>Let x = (x 1 , . . . , x n ) ? S(R d ) be a stream of data. Let X be a linear interpolation of x. Then the signature of x is defined as S(x) = S(X) and the truncated signature of order N of x is defined as S N (x) = S N (X).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Definition 3 .</head><label>3</label><figDesc>Given a set of truncated signatures of order N , S N c (x c ) m c=1 , the element-wise mean is defined b? S N (x (z)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Definition 4 .</head><label>4</label><figDesc>Given n components of the element-wise mean of the signatures {y (c) } n c=1 ? T (R d ) from the model chosen as a source of synthetic samples and the same number of components of the element-wise mean of the signatures {x (c) } n c=1 ? T (R d ) from the original distribution, then we define the Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) by RMSE x (c) ) ? x (c) |.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 13 :</head><label>13</label><figDesc>Visualization of PCA Adaptive t-SNE on original (left) versus synthetic (right) samples of AFHQ Cat (a,b), Dog (c,d) and Wild (e,f) using Stylegan2ada.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 14 :</head><label>14</label><figDesc>Visualization of PCA Adaptive t-SNE on original (top) versus synthetic (bottom) samples of MetFaces using Stylegan2-ada (b), r-Stylegan3-ada (c) and t-Stylegan3-ada (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 15 :</head><label>15</label><figDesc>Visualization of PCA Adaptive t-SNE on original (top) versus synthetic (bottom) samples of NASA Perseverance using Stylegan2-ada across several epoch iterations: 193 (b), 371 (c), 596 (d), 798 (e) and 983 (d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>RMSE and MAE Signature and log-signature across several iterations of training of Stylegan2-ada (lower is better). Our synthetic samples are generated using the model 798 which achieves the highest RMSE and MAE Signature and MAE log-signature accuracy.</figDesc><table><row><cell cols="2">Iteration Stylegan2-ada 193</cell><cell>371</cell><cell>596</cell><cell>798</cell><cell>983</cell></row><row><cell>RMSE Signature</cell><cell cols="5">15617 13336 12353 11601 25699</cell></row><row><cell>MAE Signature</cell><cell cols="5">11072 10686 9801 9086 19481</cell></row><row><cell>RMSE log-signature</cell><cell cols="5">9882 7563 7354 7397 15621</cell></row><row><cell>MAE log-signature</cell><cell cols="5">6467 5955 5724 5717 12063</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/decurtoydiaz/signatures</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">https://github.com/decurtoidiaz/drcyz</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">https://eyes.nasa.gov/curiosity/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is supported by HK Innovation and Technology Commission (InnoHK Project CIMDA) and HK Research Grants Council (Project CityU 11204821).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Edwards</surname></persName>
		</author>
		<title level="m">Data augmentation generative adversarial networks. ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bonnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kidger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">P</forename><surname>Arribas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Salvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lyons</surname></persName>
		</author>
		<title level="m">Deep signature transforms. NIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Insertion algorithm for inverting the signature of a path</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lyons</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.08423</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Rethinking atrous convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.05587</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Photographic image synthesis with cascaded refinement networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A primer on the signature method in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Chevyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kormilitzin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Stargan v2: Diverse image synthesis for multiple domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Uh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generating images with perceptual similarity metrics based on deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<title level="m">An image is worth 16x16 words: Transformers for image recognition at scale. ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning time-dependent data with the signature transform. Theses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fermanian</surname></persName>
		</author>
		<ptr target="https://tel.archives-ouvertes.fr/tel-03507274" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
		<respStmt>
			<orgName>Sorbonne Universit?</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Generative adversarial networks</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m">Variational walkback: Learning a transition operator as a stochastic recurrent net. NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Sparse arrays of signatures for online character recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Graham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">GANs trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Denoising diffusion probabilistic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">The relativistic discriminator: a key element missing from standard GAN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jolicoeur-Martineau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Adversarial score matching and improved sampling for image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jolicoeur-Martineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pich?-Taillefer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Des Combes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mitliagkas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Progressive growing of GANs for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Training generative adversarial networks with limited data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aittala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>H?rk?nen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hellsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<title level="m">Alias-free generative adversarial networks. NIPS</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kidger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lyons</surname></persName>
		</author>
		<title level="m">Signatory: differentiable computations of the signature and logsignature transforms, on both CPU and GPU. ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Kernels for sequentially ordered data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Kiraly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Oberhauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">31</biblScope>
			<biblScope unit="page" from="1" to="45" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Use of ranks in one-criterion variance analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Kruskal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Wallis</surname></persName>
		</author>
		<idno type="DOI">10.1080/01621459.1952.10483441</idno>
		<ptr target="https://doi.org/10.1080/01621459.1952.10483441" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">260</biblScope>
			<biblScope unit="page" from="583" to="621" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.08286</idno>
		<title level="m">Learning stochastic differential equations using RNN with log signature features</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Differential equations driven by rough signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lyons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Revista Matem?tica Iberoamericana</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="310" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rough paths, signatures and the modelling of functions on streams</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lyons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Congress of Mathematicians</title>
		<meeting>the International Congress of Mathematicians</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Differential equations driven by rough paths</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lyons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>L?vy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>De Probabilit?s De Saint-Flour</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<title level="m">The numerics of GANs. NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Which training methods for GANs do actually converge?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mildenhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tancik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ng</surname></persName>
		</author>
		<title level="m">NeRF: Representing scenes as neural radiance fields for view synthesis. ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Neural CDEs for long time series via the log-ode method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Morrill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kidger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Salvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Lyons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Conditional image synthesis with auxiliary classifier gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Exponential convergence of Langevin distributions and their discrete approximations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">O</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Tweedie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bernoulli</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="363" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Improved techniques for training GANs. NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Generative modeling by estimating gradients of the data distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Improved techniques for training score-based generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Visualizing data using t-SNE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">86</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<title level="m">Attention is all you need. NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Improving the improved training of wasserstein gans: a consistency term and its dual effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<title level="m">Bayesian learning via stochastic gradient langevin dynamics. ICML</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Decentralized visual-inertial-UWB Fusion for relative state estimation of aerial swarm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICRA</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Energy-based generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Improved transformer for high-resolution gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NIPS</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barriuso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<title level="m">Semantic understanding of scenes through the ADE20K dataset. IJCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
