<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Training Multi-bit Quantized and Binarized Networks with A Learnable Symmetric Quantizer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phuoc</forename><surname>Pham</surname></persName>
							<email>phuocphn@inu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution">Incheon National Univeristy</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><forename type="middle">A</forename><surname>Abraham</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Texas at Austin</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaeyong</forename><surname>Chung</surname></persName>
							<email>jychung@inu.ac.kr</email>
							<affiliation key="aff2">
								<orgName type="institution">Incheon National Univeristy</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Training Multi-bit Quantized and Binarized Networks with A Learnable Symmetric Quantizer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Quantizing weights and activations of deep neural networks is essential for deploying them in resourceconstrained devices, or cloud platforms for at-scale services. While binarization is a special case of quantization, this extreme case often leads to several training difficulties, and necessitates specialized models and training methods. As a result, recent quantization methods do not provide binarization, thus losing the most resource-efficient option, and quantized and binarized networks have been distinct research areas. We examine binarization difficulties in a quantization framework and find that all we need to enable the binary training are a symmetric quantizer, good initialization, and careful hyperparameter selection. These techniques also lead to substantial improvements in multibit quantization. We demonstrate our unified quantization framework, denoted as UniQ, on the ImageNet dataset with various architectures such as ResNet-18,-34 and Mo-bileNetV2. For multi-bit quantization, UniQ outperforms existing methods to achieve the state-of-the-art accuracy. In binarization, the achieved accuracy is comparable to existing state-of-the-art methods even without modifying the original architectures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep neural networks have achieved tremendous success in various fields including computer vision <ref type="bibr" target="#b30">[31]</ref>, natural language processing <ref type="bibr" target="#b49">[50]</ref>, and speech recognition <ref type="bibr" target="#b7">[8]</ref>, having demonstrated unprecedented predictive performance. However, the computational complexity and memory access count required by the existing models pose a challenge in deploying them to resource-constrained devices, and applying to latency-critical services. To address this challenge, efficient network architectures, manually designed <ref type="bibr" target="#b43">[44]</ref> or automatically searched <ref type="bibr" target="#b45">[46]</ref>, and model compression techniques such as pruning <ref type="bibr" target="#b16">[17]</ref> and quantization <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b53">54]</ref> have been studied. In practical model deployment, quanti-R zation is a necessary step, and often the last means to control the performance and efficiency trade-off once the model architecture is fixed <ref type="bibr" target="#b23">[24]</ref>. Quantizing weights and activations to a lower precision not only reduces the computational complexity but also the model size, memory footprint, and memory access count but at cost of degraded performance. Recent quantization methods <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b28">29]</ref> can overcome accuracy degradation from their full-precision counterparts even with 4-bit weights and activations. However, most of these methods do not present 1-bit results, possibly due to their severely degraded performance or because 1-bit training does not converge, ditching the most efficient option.</p><p>While Zhou et al. <ref type="bibr" target="#b54">[55]</ref> considered binarized neural networks together with multi-bit quantization, binarized neural networks have been a distinct research topic from the quantized models. Most studies on binarized models <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b41">42]</ref> focused on the 1-bit case solely. Binarized networks have gained attention because of the expensive floatingpoint multiplications and additions being replaced by efficient XNOR and POPCOUNT operations. However, this is not specific to binarized networks, and any low-precision networks can be executed efficiently by such operations as  <ref type="figure">Figure 2</ref>: The overview about our method. A unified framework is used for both model quantization and binarization.</p><p>shown in <ref type="bibr" target="#b54">[55]</ref>. Thus, a binary kernel can execute any bitwidth networks seamlessly depending on the accuracy and efficiency requirements.</p><p>In contrast, the process of building binarized networks is different from building quantized networks. Binarized network researchers often modify a base architecture to improve performance. Several studies increased the representation capacity by using more weight and activation bases <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b55">56]</ref>. Most studies incorporate changes to improve training efficiency such as dual skip connections <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b52">53]</ref>. In addition, more aggressive changes are sought for via neural architecture search <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b52">53]</ref>. In addition to model changes, binarized networks use a quantizer specialized for binary such as the sign function.</p><p>The distinct creation process for binarized networks causes several difficulties in practice. First, modifications of a base model often affect the number of floating-point operations and memory access count <ref type="bibr" target="#b9">[10]</ref>. Thus, the actual latency and power consumption can differ from the expected results, and a binarized model cannot be guaranteed to be better than the 2-bit counterpart. Second, training binarized networks requires additional skilled workforce because it needs special expertise, especially a deep understanding of the model itself. Finally, given a model, binarization provides only one option for accuracy and efficiency, and the limited exploration of the trade-off may lead to a suboptimal solution.</p><p>This paper proposes a unified quantization framework, denoted as UniQ, for multi-bit quantized networks and binarized networks. UniQ achieves up to 4.8% and 2.7% accuracy improvements on the ImageNet dataset over the existing state-of-the-art quantization and binarization methods, respectively, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. <ref type="figure">Figure 2</ref> illustrates UniQ in contrast to the conventional approach. This paper first considers two popular weight quantizers in quantized networks. A weight quantizer, first proposed in <ref type="bibr" target="#b54">[55]</ref> and adopted in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b25">26]</ref> later, maps weight values into the range [0, 1] first and then performs quantization and re-maps the quantized values to the range <ref type="bibr">[-1,1]</ref>. This method implies the importance of the symmetry; however, the weight mapping becomes an impediment to taking advantage of pre-trained models. The other weight quantizer, used in <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11]</ref>, maps inputs to a real value represented by the product of a scaling factor and a signed integer. The signed integer is assumed to be represented by two's complement, which has asymmetric ranges. This quantization method does not transform the weights of the pre-trained models. However, we hypothesize that the asymmetry has a negative impact on extremely low-precision training. Thus, we design a symmetric quantizer, where the step size can be learned via the gradient descent procedure.</p><p>While the step size is learnable with the task loss, we observe that the initialization of the learnable parameter has a significant impact on the final solution. For the initialization of this parameter, prior works used a heuristic <ref type="bibr" target="#b10">[11]</ref> or a numerical method <ref type="bibr" target="#b1">[2]</ref>. In contrast, we propose an analytic initialization method that is optimal in the mean squared sense. According to our ablation study, our proposed framework shows significant improvements over prior works as a combined result of the symmetric quantizer and the optimal initialization.</p><p>The proposed quantizer and init method can be applied to the binary case seamlessly, but the significant improvements demonstrated in multi-bit are not shown in 1-bit. We scrutinize the training dynamics of the binary case and find that the binary case receives strong gradient signals at the beginning of training and the distribution of quantizer input changes extremely fast compared to multi-bit cases. We hypothesize that this difference is caused as the initial point after binarization is too far from the pre-trained model solution. As a simple yet effective solution, we suggest to use warm-up strategy, which has been used widely for largebatch training. However, we empirically show that in 1-bit training, this improves accuracy substantially even when a small batch size is used.</p><p>Our major contributions are summarized as follows:</p><p>? In multi-bit quantization, the proposed unified method outperforms existing methods consistently to achieve the state-of-the-art accuracy of ResNet-18,-34 and Mo-bileNetV2 on ImageNet.</p><p>? In binarization, the proposed method achieves comparable results to the state-of-the-art methods. These results have been achieved only by enhancing the training process without modifying the original network architectures, meaning that our method can be used in conjunction with network modification techniques.</p><p>? We propose an optimal, analytic initialization for step sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Modern neural networks have increased their computational complexity and memory requirements. Therefore, recent works have proposed efficient architectures <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b46">47]</ref> and model compression techniques such as network binarization <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b41">42]</ref>, low-bit quantization <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b53">54]</ref>, and knowledge distillation <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b39">40]</ref> to reduce the model size and amount of computation. Among these, lowbit quantization is one of the most popular methods and is widely used in the research literatures and real-life applications <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b48">49]</ref>.</p><p>Efficient Models. Recently optimized networks such as EfficientNet <ref type="bibr" target="#b46">[47]</ref>, MobileNet-v1 <ref type="bibr" target="#b21">[22]</ref>, -v2 <ref type="bibr" target="#b43">[44]</ref>, -v3 <ref type="bibr" target="#b20">[21]</ref> have achieved high accuracy by replacing the standard convolutional layers with depth-wise separable convolutions, thereby significantly reducing the number of parameters. Even for such efficient architectures, quantization is necessary to deploy them in specialized hardware <ref type="bibr" target="#b12">[13]</ref> and provides further reductions in its size and number of calculations. Recent works <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b28">29]</ref> attempted to quantize these models, but at the expense of the significant loss in prediction accuracy. Compared to DSQ <ref type="bibr" target="#b15">[16]</ref> and QKD <ref type="bibr" target="#b28">[29]</ref>, our method yields consistently higher results for all bit-widths when tested with MobileNet-V2, which again, demonstrates its effectiveness even for highly optimized networks.</p><p>Model Binarization. As a special case of quantization, model binarization has been studied extensively and has received much attention owing to its efficiency for deployment in edge devices. Using binarized weights and activations resulted in ?32? memory saving over the fullprecision counterpart and brought ?58? computational efficiency on CPUs by taking advantage of bitwise operations <ref type="bibr" target="#b41">[42]</ref>. Unfortunately, these networks usually lead to severe accuracy degradation. To mitigate this problem, many existing methods proposed the idea of modifying the original architecture. In <ref type="bibr" target="#b41">[42]</ref>, the order of layers within a block was changed to improve the information flow. In <ref type="bibr" target="#b35">[36]</ref>, an additional skip connection was added to each block in the residual networks. In <ref type="bibr" target="#b27">[28]</ref>, the input and output widths of each layer were adjusted. Rather than modifying the original architecture, this study focuses only on improving the quantizer itself and the training process. Our proposed method is orthogonal to the aforementioned model modification methods.</p><p>Multi-bit Quantization. In contrast, recent works on quantization <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b53">54]</ref> have achieved substantial efficiency improvements without the need to re-design or develop the whole new architecture. Thus, it can substantially reduce the design effort. PACT <ref type="bibr" target="#b4">[5]</ref> and LQ-Nets <ref type="bibr" target="#b53">[54]</ref> first proposed the idea of learning quantizer parameters. LQ-Net parameterizes quantization levels for a non-uniform quantizer. In QIL <ref type="bibr" target="#b13">[14]</ref>, a non-uniform quantizer was constructed using a non-linear transformer fol-lowed by a uniform quantizer. While these non-uniform quantizers provide a higher degree of freedom, they usually require more computation and memory than uniform quantizers. PACT <ref type="bibr" target="#b4">[5]</ref> parameterized the clipping level in a uniform activation quantizer. LSQ <ref type="bibr" target="#b10">[11]</ref> showed better accuracy by making the step size learnable. SAT <ref type="bibr" target="#b10">[11]</ref> studied efficient training for quantized networks. Both PACT <ref type="bibr" target="#b4">[5]</ref> and SAT <ref type="bibr" target="#b4">[5]</ref> adopted the weight quantizer of DoReFaNet <ref type="bibr" target="#b54">[55]</ref>, which is symmetric but transforms the weights into a new range. This makes it difficult to take advantage of pretrained models. In contrast, we design a uniform, symmetric quantizer that does not require the transformation and can leverage pre-trained models fully. Besides, none of the recent methods reports their results for binarized neural networks, due to severe performance degradation, or their quantizers are not properly designed to support binarized networks. In contrast, we propose a unified framework that can support all bit-widths including 1-bit binarization. We obtain new state-of-the-art results for multi-bit quantization and promising results for model binarization by using the new quantizer design without any modifications in the original architecture needed.</p><p>Knowledge Distillation. Another popular method is knowledge distillation that is widely used in many computer vision tasks. The basic idea is that the knowledge from the teacher networks is transferred to the student networks, providing an additional guidance signal to the training process of the smaller-sized student network. Applying distillation methods to low-precision networks was performed by <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b51">52]</ref> where a real-valued network is used as the teacher and a low-precision bit network as a student. QKD <ref type="bibr" target="#b28">[29]</ref> reported competitive results in multi-bit quantization using knowledge distillation. LSQ <ref type="bibr" target="#b10">[11]</ref> also showed that knowledge distillation provided additional improvements in their quantization results. However, we outperform these methods even without resorting to the idea of transferring knowledge, by focusing more on the fundamental issues. In addition, our method is orthogonal to knowledge distillation, and can be used in conjunction to further boost the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Preliminaries</head><p>In this section, we first review the weight quantizers commonly used in the literature. In <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b31">32]</ref>, a weight w ? R is approximately represented by</p><formula xml:id="formula_0">w ?? ? ?<label>(1)</label></formula><p>where ? is a scaling factor, called the step size, and? is a signed integer, which is assumed to be represented by two's complement. This is often referred to as the fixed-point representation. This representation has asymmetric ranges; it can represent one more negative number than positive numbers. For example, when ? = 1, it can represent -2, -1, 0, and 1 for 2-bit weights. We hypothesize that this asymmetry has a negative impact on low-precision training. While it has an asymmetric range in the strict sense, it is considered symmetric in <ref type="bibr" target="#b1">[2]</ref>. Thus, to avoid confusion, we refer to this as semi-symmetric.</p><p>In <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b54">55]</ref>, a weight w ? R is quantized into a k-bit value by</p><formula xml:id="formula_1">2 Quantize k tanh (w) 2 max (|tanh (w)|) + 1 2 ? 1<label>(2)</label></formula><p>where Quantize k (x) = round(x(2 k ? 1))/(2 k ? 1). In this quantizer, the weights are first mapped into the range [0,1] and quantized into a k-bit value in the range <ref type="bibr">[-1,1]</ref>. This quantizer has the symmetric property, but is problematic for two reasons. First, it transforms the weights into a new range and loses the knowledge of pretrained models. Second, the transformed range may cause the vanishing or exploding gradient problem because the variance of weights becomes substantially different from that suggested in Xavier <ref type="bibr" target="#b14">[15]</ref> or Kaiming initialization <ref type="bibr" target="#b17">[18]</ref>. Thus, SAT <ref type="bibr" target="#b25">[26]</ref> proposed to scale the transformed weights again using the constant in Xavier initialization. However, the first problem remains. We address these two problems by using a new symmetric quantizer and optimal initialization that minimizes the mean square quantization error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Unified Quantization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Learnable Symmetric Quantizer</head><p>A quantizer Q : R ? R is a piecewise constant function and each interval is mapped to a corresponding output. The end points of the intervals are referred to as decision levels and the output is called the reconstruction level. A uniform quantizer has evenly spaced decision levels and reconstruction levels. The length of the intervals is called the step size, denoted as ?. The total number of reconstruction levels is denoted by N . We denote the clip function to be used by quantizers by clip N (x) = min(max(x, 0), N ? 1). The round function is denoted by ? . In practice, N is usually even, and thus a symmetric quantizer in the strict sense do not include the value of zero as a reconstruction level. For example, when N = 4 and ? = 1, the symmetric quantizer has -1.5, -0.5, 0.5, and 1.5 as the reconstruction levels. We quantize weights by the uniform symmetric quantizer</p><formula xml:id="formula_2">Q w (x) = clip N ((x + ?) /?) ? ? ?<label>(3)</label></formula><p>where ? = ? ? (N ? 1)/2. Eq. (3) can be rewritten as</p><formula xml:id="formula_3">Q w (x) =q w (?/2)<label>(4)</label></formula><p>whereq w = 2 clip N ((x + ?)/?) ? N + 1;q w can be encoded into log 2 N bits using ?1 encoding.</p><p>We consider the ReLU non-linearity, wihch is widely used in the deep learning literature, as the activation function. Because almost half of the ReLU responses are zero, we fix the zero value as a reconstruction level instead of parameterizing an offset. Thus, for activations, we use</p><formula xml:id="formula_4">Q a (x) = clip N (x/?) ?.<label>(5)</label></formula><p>Designing a uniform quantizer usually boils down to deciding one parameter, the step size ?. Instead of designing the quantizers manually, we make ? a learnable parameter as in recent prior works <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b1">2]</ref>, and optimize it with the task loss via the gradient descent procedure. The round function has a zero derivative almost everywhere, and the exact derivative is not useful in learning. Thus, we adopt the straight-through estimator (STE), which assumes a unit derivative for the entire input range of the round function. Then, we have</p><formula xml:id="formula_5">?Q w ?? = ? x ? + x ? ? 1 2 + 1 2 if |x| &lt; ? sign(x)? otherwise.<label>(6)</label></formula><p>We can also find ?Qa ?? similarly. While this allows us to learn the step size, the initialization of this parameter is necessary and in our experience, careful initialization improves accuracy substantially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Optimal MSE Initialization</head><p>The quantized networks are usually initialized with a pre-trained model, and the learnable step sizes are also initialized depending on the statistics of the pre-trained model. Let X be the random variable for a quantizer input and its pdf is denoted by p(x). The optimal step size for Q w is defined in the mean squared error (MSE) sense by</p><formula xml:id="formula_6">? * w = arg min ? D w (?)<label>(7)</label></formula><p>where D w (?) = E[(x ? Q w (x; ?)) 2 ]. Using Leibniz integral rule, we take the derivative of D w and obtain</p><formula xml:id="formula_7">dD w d? = ? N 2 ?1 i=1 (2i ? 1) i? (i?1)? 2 x ? 2i ? 1 2 ? p(x)dx ?(N ? 1) ? ( N 2 ?1)? 2 x ? N ? 1 2 ? p(x)dx.<label>(8)</label></formula><p>By setting <ref type="bibr" target="#b7">(8)</ref> to zero, we can find the optimal step size. In general, this equation does not have a closed-form solution and a numerical method is required. However, for common probability distributions such as Gaussian and Laplace, the step size for each N of interest can be pre-computed assuming a unit variance, and can be scaled by the standard deviation of the quantizer input. In our implementation, a Gaussian distribution is assumed for weights. For the activation quantizer Q a , we also define the optimal step size ? * a and the mean squared error D a , and derive dDa d? similarly. However, in the case of the activation quantizer, a Gaussian distribution is assumed for pre-activations (activations prior to the non-linearity). The activations after the ReLU non-linearity follow a rectified Gaussian, a modification of Gaussian where the negative elements are reset to zero. While a rectified Gaussian is a mixture of a discrete distribution for zero and a continuous distribution for the positive elements, we pre-compute the step size using the continuous part only because Q a is designed to include zero as a reconstruction level by construction. When we pre-compute the step sizes, the standard Gaussian is assumed for pre-activations. We denote the pre-computed step sizes for activations and weights by ? u a and ? u w , respectively. The constants for each N are summarized in <ref type="table" target="#tab_1">Table 1</ref>, which also shows the optimal signal-to-quantizationnoise (SQNR) ratio. We use it later to analyze the training dynamics of quantized models. Even if the step size is set optimally, the MSE is proportional to the signal energy (the variance of the quantizer input) and it is not useful to see the optimality of the step size during training where the signal energy varies substantially over time. Using the precomputed step sizes, we finally obtain</p><formula xml:id="formula_8">? * w = ? u w Std(X),<label>(9)</label></formula><p>and</p><formula xml:id="formula_9">? * a = ? u a 2 E[X 2 ].<label>(10)</label></formula><p>Note that 2 E[X 2 ] is the standard deviation of the preactivations because they were assumed to have a symmetric distribution around zero. The statistics of the quantizer input are estimated by the sample statistics. For activations, we use a given number of batches to estimate the standard deviation. For a simple implementation, we calculate the sample standard deviation of each batch and use its maximum values over the batches. In order to accurately estimate the input statistics of an activation quantizer using multiple batches, we need to forward-propagate multiple batches for each layer in a layer-wise manner. In our experience, this adds unnecessary complexity to the implementation and the simple method provides similar performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Training Instability in 1-bit</head><p>While our symmetric weight quantizer and MSE init support all bits seamlessly to 1-bit, in our experience, the binary training is not effective in the same setup as that for other bits. We investigate the training dynamics,can which leads to the following observations. First, 1-bit SGD training receives strong gradient signals initially because the initial point after binarization is far from the solution of the pre-trained model, which we use for init, in contrast to 2-bit or higher training. Second, the step sizes are not adapted to maximize the signal-to-quantization-noise ratio (SQNR) or maintain the initial SQNR during the initial fast learning. While the objective of the learnable quantizer is not to maximize the SQNR, we observe that the step size usually changes along with the standard deviation of the quantizer input in 2-bit or higher training, maintaining a reasonable SQNR. Thus, a SQNR significantly lower than the optimal level is not considered as desirable. We hypothesize that abrupt changes in the quantizer input distribution get the step size stuck in a local minimum. We show empirical evidence that warm-up training mitigates this issue. In addition, we empirically find that Adam is more robust to this problem than SGD. This appears to be owing to the gradient normalization in Adam.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experimental Results</head><p>To demonstrate the effectiveness of our proposed method, we evaluate it on the CIFAR-100 <ref type="bibr" target="#b29">[30]</ref> and the Im-ageNet datasets <ref type="bibr" target="#b42">[43]</ref>. The CIFAR-100 dataset consists of 60,000 32x32 color images from 100 classes with a total of 50,000 training and 10,000 test images. The ImageNet dataset consists of more than 1.2M training images from 1000 classes and 50K validation images. We use various popular network architectures such as ResNet-18, -32, -34 <ref type="bibr" target="#b18">[19]</ref> and MobieNet-V2 <ref type="bibr" target="#b43">[44]</ref> for evaluation. The experiment results are compared with various recent works on multi-bit quantization and neural network binarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">ImageNet Results</head><p>Implementation details. In the following experiments, we quantize all convolutional and fully connected layers to ultra-low precision except the first and last layers, which are represented by 8-bit precision as was done in <ref type="bibr" target="#b10">[11]</ref>. In case of binarized networks, we leave the first, last, and downsampling layers the full-precision as were done in prior works <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b35">36]</ref>. We quantize weights and activations to the same bit-width for all experiments. For multi-bit and binarized networks, we use SGD and Adam, respectively. For SGD, we use 0.01 as the initial learning rate and decay it using the cosine learning rate schedule without restarts <ref type="bibr" target="#b36">[37]</ref>. For Adam, the learning rate is fixed to 0.001 for 5 epochs as the warm-up and then increase to 0.004 and then follow   <ref type="bibr" target="#b50">[51]</ref>. The dash symbol "-" indicates no data available and "FP" represents the full precision network accuracy in our implementation.</p><p>the cosine schedule. For all experiments, we use layer-wise and kernel-wise quantizations for activations and weights, respectively, with an exception of MobileNetV2, in which layer-wise quantization is used for both weights and activations considering the relative parameter overhead. In addition, weight decay is not used for step size parameters. Our implementation is based on PyTorch. We use original ResNet-18, ResNet-34, and Mo-bileNetV2 architectures, without any changes in their structure. For ResNets, we use the pre-activation version. We follow the commonly used data augmentation strategy as in <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b10">11]</ref>, where the training images are randomly cropped and resized to 224 ? 224, and horizontally flipped half the time. For testing, the single-center crop of size 224?224 is applied. The transformed images are finally normalized by the mean and standard deviation. All networks are trained for 90 epochs with a batch size of 256 (2 GPUs), a momentum of 0.9, and a weight decay of 10 ?4 , 0.5 ? 10 ?4 , 0.25 ? 10 ?4 , 0 for 4-bit, 3-bit, 2-bit and 1-bit quantized models, respectively. We use the pre-trained models available at PytorchCV 1 for weight initialization. For multi-bit and binarized networks, we use the floating-point and 2-bit models for initialization, respectively. For step size initialization, the first 1000 training batches are used to estimate the statistics of activations.</p><p>Comparison with prior works on multi-bit quantization. We compare our method to existing methods in <ref type="table" target="#tab_3">Table 2</ref>. For the existing methods, the results are directly cited from the original papers unless mentioned otherwise. By looking at the reported table, we can observe that our method outperforms all the previous quantization methods in top-1 accuracy. Specifically, we can achieve significant performance gain over the recent state-of-the-art methods  <ref type="bibr" target="#b35">[36]</ref> 56.4 XNOR-Net++ <ref type="bibr" target="#b2">[3]</ref> 57.1 IR-Net <ref type="bibr" target="#b40">[41]</ref> 58.1 ProxyBNN <ref type="bibr" target="#b19">[20]</ref> 58.7 RBNN <ref type="bibr" target="#b32">[33]</ref> 59.9 BinaryDuo <ref type="bibr" target="#b27">[28]</ref> 60.4 UniQ (Ours) 60.5  <ref type="table">Table 3</ref>: Top-1 accuracy comparison to the existing stateof-the-art binarization methods on ImageNet. "Original" is used to denote methods not requiring architecture modification. ?DoReFa-Net uses 2-bit for activations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ResNet</head><p>LSQ, QKD, and SAT on all comparing architectures. The improvements range from 0.1% to 4.8% compared to the second-best method (QKD). Note that QKD and SAT need a total of 120 and 150 training epochs, respectively, while our method only requires 90 epochs to obtain better accuracy. In addition, it is worth to mention that QKD uses knowledge distillation but UniQ does not. Knowledge distillation is known to provide additional improvements on quantization results as shown in LSQ <ref type="bibr" target="#b10">[11]</ref>. MobileNetV2 has an architecture already optimized for efficiency such as depthwise convolutions and the accuracy is known to be sensitive to quantization <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b28">29]</ref>. For MobileNetV2, UniQ outperforms the existing state-of-the-art method, QKD, by significant margins of 2.4% and 4.8% for 2-bit and 3-bit quantized models, respectively. A substantial increase in prediction accuracy can be seen in other 2-bit models. With ResNet-18, UniQ achieves 67.8% top-1 accuracy, with 0.2% and 0.4% improvements over LSQ and QKD, respectively. With ResNet-34, it achieves a top-1 accuracy of 72.1%, which is a 0.4% improvement over QKD and LSQ.</p><p>Comparison with prior works on binarized neural networks. We further compare our method with the stateof-the-art binarization methods in <ref type="table">Table 3</ref>. As shown in the last column, many existing methods modify a base architecture and it is difficult to be compared. While the model size and the number of operations are the same, the memory access count can be different. For example, the dual skip connection employed in Bi-Real does not affect the model size and the number of operations for convolutions but the memory access count. Nonetheless, to our best knowledge, UniQ outperforms the previous state-of-the-art accuracy for binarized ResNet-34 by a significant margin of 2.69%. For ResNet-18, UniQ even achieves a comparable accuracy to BinaryDuo, which requires to increase the width of the skip connections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">CIFAR-100 Results</head><p>Implementation details. We use the pre-activation variant of ResNet-32 for all the experiments on CIFAR-100. We train for 350 epochs with a mini-batch size of 128. All quantized models are initialized from the pre-trained fullprecision counterparts, which we train from scratch. For simplicity, we use the same weight decay of 5?10 ?4 across all CIFAR-100 experiments. The standard data augmentation includes random cropping and horizontal flipping is applied for each training image. The first 100 training batches are used for step size initialization. We use layer-wise quantization for both weights and activations. For other settings, we follow the same settings as described in Section 5.1</p><p>Comparison with LSQ. For a fair comparison, we compare LSQ to our method in our setting. We implement LSQ carefully and cross-check the correctness with <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b1">2]</ref>. Our final results are summarized in <ref type="table" target="#tab_7">Table 4</ref>. When using ResNet-32, we can observe that, for 4-bit quantized models, LSQ can match the accuracy of the full-precision baseline, which is in line with the results reported in the original paper <ref type="bibr" target="#b10">[11]</ref>. It is worth noting that when the bit-width is reduced to 3, our method can still archive the same accuracy of 71.4% compared to the 4-bit LSQ quantized model. For 2-bit, the accuracy drops by only 2.1% when using our method compared to 2.9% for LSQ. For the most aggressive 1-bit quantization, we can achieve 62.4%, while no data is reported for LSQ as its quantizer is not suitable for binarization.   Imbalanced weight distribution. For UniQ and LSQ, we show the distributions of the trained weights in <ref type="figure" target="#fig_1">Figure 3</ref>, for two different layers. We can see that the trained weights of LSQ have the form of negatively-skewed distribution, with a long tail on the negative side, and many weights values around the maximum reconstruction level. In contrast, UniQ has a symmetric distribution around the zero value, and the weights are relatively evenly distributed. The higher entropy of the balanced distribution may suggest that UniQ allows the network to retain more knowledge on weights than LSQ.</p><p>Step size initialization. To show how important the initialization of the step sizes is, we also compare the results when the step size of the proposed quantizer is initialized with 0.1, 0.2, LSQ's heuristic, and the proposed optimal method. In LSQ, the step size is initialized to</p><formula xml:id="formula_10">2 E[X] ? Q P</formula><p>where X is the quantizer input and Q P = 2 bit ? 1 (Q P = 2 bit?1 ? 1) for activations (weights). The results are summarized in <ref type="table" target="#tab_9">Table 5</ref>. The accuracy values vary substantially depending on initialization. It is interesting to see that, our proposed quantizer with LSQ init performs poorly for all bit-widths. In contrast, by replacing LSQ init with our init, a significant performance boost can be seen for all bit-widths. The 1.0% performance boost over LSQ init is seen in 2-bit. These results suggest that the step size parameters need to be initialized properly, otherwise it will lead to performance degradation.</p><p>Training dynamics. While our quantizer and init method are general to all bit-widths, the binarized networks     <ref type="table">Table 6</ref>: Results of ResNet-32 on CIFAR-100 with different learning rate schedules. For the warm-up period, the initial learning rate is set to 0.001, and then increases to 0.01 (0.004) for SGD (Adam).</p><p>trained by UniQ do not provide a satisfactory performance at the same hyperparameter setting for 2-bit or higher. We thus investigate the activation quantizer of a convolutional layer. Specifically, we observe the evolution of the step size, the standard deviation (SD) of the quantizer input, and SQNR during 30 epochs of training. <ref type="figure" target="#fig_3">Figure (4a)</ref> and (4b) show 2-bit and 1-bit training, respectively, at the same setting, where we use SGD and the learning rate of 0.01. In 2-bit, the step size shrinks as the SD decreases, which maintains the initial SQNR not very far from the optimal level, shown in the dotted orange line. However, in 1-bit, the SD jumps sharply at the beginning, whereas the step size does not change accordingly, dropping the SQNR substantially, suggesting that the step size might be trapped at a local minimum. <ref type="figure" target="#fig_3">Figure (4c)</ref> shows how the warm-up can help mitigate this problem. We use 5 epochs of warm-up with a learning rate of 0.001 and observe that the SD changes smoothly and the step size seems to be adapted to that, maintaining a better SQNR. <ref type="figure" target="#fig_3">Figure (4d)</ref> shows an evidence that Adam is more robust to this issue. While we use the learning rate of 0.004, which is a high rate for Adam, we do not observe the issue, and the SQNR approximately stays at the optimal level in this case. Warm-up for 1-bit Training. We further perform experiments to find the best optimizer and warm-up strategy for binary training. The empirical results from <ref type="table">Table 6</ref> are in line with our analysis on the training dynamics. The results indicate that initially training a binarized model with a small learning rate for some epochs can improve the prediction accuracy substantially. In contrast, the models trained with a higher rate at the beginning can be easily trapped in a saddle point or bad local minimum; without increasing the learning rate at some point, the training may converge too slow. The results also suggest that Adam may perform better than SGD, but SGD also provides a decent performance in contrast to the common belief that SGD gives severely degraded results than Adam in binary training <ref type="bibr" target="#b0">[1]</ref>. It is also shown that warm-up training helps Adam as well as SGD. Moreover, we observe that increasing the number of warm-up epochs does not improve the accuracy significantly. Thus, we choose the 5 epoch warm-up period.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper, we have proposed a quantization method generalized for both multi-bit quantized and binarized models. We have designed a symmetric quantizer with a trainable step size and proposed an analytic, optimal initialization of the step size. In addition, we have investigated the difficulties in the 1-bit training and suggested practical methods to overcome them. For multi-bit quantization, the proposed method have achieved new record accuracies of ResNet-18,-34, MobileNetV2 on ImageNet. For binarization, without modifying original network architectures, we have achieved better or comparable accuracy to that of recent binarized networks by focusing on the fundamental training problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The proposed unified quantization method outperforms the existing state-of-the-art methods both in binarization and multi-bit quantization by significant margins.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Weight distribution from two different layers of trained, 2-bit quantized ResNet-32 with LSQ (green) and UniQ (red) quantization scheme. Two networks are trained with the same hyperparameters on CIFAR-100 for 350 epochs. The dashed lines are the reconstruction levels of each method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Training dynamics of an activation quantization layer in ResNet32. The abrupt change of the standard deviation (std) of the quantizer input may get the step size (?) stuck in a poor local minimum. The highlighted area indicates the warm-up period and the dashed orange line indicates the optimal SQNR value.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>The optimal unit step size and optimal SQNR for weights and activations.</figDesc><table><row><cell>N</cell><cell>? u w</cell><cell>Weight SQNR( dB)</cell><cell>? u a</cell><cell cols="2">Activation SQNR( dB)</cell></row><row><cell cols="2">2 1.596</cell><cell>4.4</cell><cell cols="2">1.224</cell><cell>5.5</cell></row><row><cell cols="2">4 0.996</cell><cell>9.3</cell><cell cols="2">0.651</cell><cell>11.6</cell></row><row><cell cols="2">8 0.586</cell><cell>14.3</cell><cell cols="2">0.353</cell><cell>17.2</cell></row><row><cell cols="2">16 0.335</cell><cell>19.4</cell><cell cols="2">0.193</cell><cell>22.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Top-1 accuracy (%) on ImageNet dataset. Comparison with the existing state-of-the-art DSQ, QIL, LSQ, LSQ+, QKD and SAT. The result of PACT for MobileNet-V2 is cited from HAQ paper</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell>Comparison of LSQ and our method (UniQ) with</cell></row><row><cell>ResNet32 and CIFAR-100 (FP Acc: 71.4%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">Comparison of different methods for step size ini-</cell></row><row><cell cols="4">tialization with ResNet32 and CIFAR-100 (FP Acc: 71.4%)</cell></row><row><cell></cell><cell>No warm-up</cell><cell cols="2">Constant warm-up</cell></row><row><cell></cell><cell>Learning rate</cell><cell cols="2">Warm-up epochs</cell></row><row><cell>SGD</cell><cell>0.01 0.005 0.001 57.0 59.1 59.5</cell><cell>5 61.3</cell><cell>10 61.1</cell></row><row><cell>Adam</cell><cell>0.004 0.001 0.0005 60.9 59.9 61.0</cell><cell>5 62.4</cell><cell>10 62.1</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">An empirical study of binary neural networks&apos; optimisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fern?ndez-Marqu?s</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Lsq+: Improving low-bit quantization through learnable offsets and better initialization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bhalgat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Blankevoort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="696" to="697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.13863</idno>
		<title level="m">Xnor-net++: Improved binary neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Accurate and efficient 2-bit quantized neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkataramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd SysML Conference</title>
		<meeting>the 2nd SysML Conference</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkataramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.-J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.06085</idno>
		<title level="m">Pact: Parameterized clipping activation for quantized neural networks</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Xnor neural engine: A hardware accelerator ip for 21.6-fj/op binary neural network inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Conti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Schiavone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Benini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2940" to="2951" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Binaryconnect: Training deep neural networks with binary weights during propagations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>David</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Contextdependent pre-trained deep neural networks for largevocabulary speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Acero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on audio, speech, and language processing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="42" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Darabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belbahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">P</forename><surname>Nia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.11800</idno>
		<title level="m">Bnn+: Improved binary network training</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Regularizing activation distribution for training binarized deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-W</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marculescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11408" to="11417" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learned step size quantization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mckinstry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bablani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Appuswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Modha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learned step size quantization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Esser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mckinstry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bablani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Appuswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Modha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.08153</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Gemmini: An agile systolic array generator enabling systematic evaluations of deep-learning architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Genc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Haj-Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Amid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Banister</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09925</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning to quantize deep networks by optimizing quantization intervals with task loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR 2019)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note>Conference on Computer Vision and Pattern Recognition (CVPR)</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth international conference on artificial intelligence and statistics</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Differentiable soft quantization: Bridging fullprecision and low-bit neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning both weights and connections for efficient neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1135" to="1143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Proxybnn: Learning binarized neural networks via proxy matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Searching for mobilenetv3</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1314" to="1324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Binarized neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Hubara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Courbariaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Soudry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Quantization and training of neural networks for efficient integer-arithmetic-only inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kligys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Trained quantization thresholds for accurate and efficient fixedpoint inference of deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gural</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Dick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.08066</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Neural network quantization with scale-adjusted training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning architectures for binary networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="575" to="591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Binaryduo: Reducing gradient mismatch in binary activation network by coupling binary activations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bhalgat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kwak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.12491</idno>
		<title level="m">Qkd: Quantization-aware knowledge distillation</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="84" to="90" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Fixed point quantization of deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Talathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Annapureddy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2849" to="2858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Rotated binary neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Advances in Neural Information Processing Systems (NeurIPS)</title>
		<meeting>the Advances in Neural Information Processing Systems (NeurIPS)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Towards accurate binary convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Aqd: Towards accurate quantized object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.06919,2020.3</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bi-real net: Enhancing the performance of 1-bit cnns with improved representational capability and advanced training algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-T</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="722" to="737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">SGDR: stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Apprentice: Using knowledge distillation techniques to improve low-precision network accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.05852</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Binarizing mobilenet via evolution-based searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Savvides</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13420" to="13429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Model compression via distillation and quantization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Polino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Alistarh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05668</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Forward and backward information retention for accurate binary neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2250" to="2259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Xnornet: Imagenet classification using binary convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rastegari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ordonez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="525" to="542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Efficient processing of deep neural networks: A tutorial and survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Emer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2820" to="2828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
		<idno>PMLR. 3</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="9" to="15" />
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Uhlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mauch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yoshiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cardinaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nakamura</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11452</idno>
		<idno>2019. 3</idno>
		<title level="m">Differentiable quantization of deep neural networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Finn: A framework for fast, scalable binarized neural network inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Umuroglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jahre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vissers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</title>
		<meeting>the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Haq: Hardwareaware automated quantization with mixed precision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.03058</idno>
		<title level="m">Binarized neural networks on the imagenet classification task</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Distillation guided residual learning for binary convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.05223</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Lq-nets: Learned quantization for highly accurate and compact deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="365" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06160</idno>
		<title level="m">Dorefa-net: Training low bitwidth convolutional neural networks with low bitwidth gradients</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Structured binary neural networks for accurate image classification and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="413" to="422" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
