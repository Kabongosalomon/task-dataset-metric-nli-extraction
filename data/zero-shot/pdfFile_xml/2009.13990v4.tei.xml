<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MCW-Net: Single Image Deraining with Multi-level Connections and Wide Regional Non-local Blocks ?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeachan</forename><surname>Park</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematical Sciences</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<addrLine>1 Gwanak-ro, Gwanak-gu</addrLine>
									<postCode>08826</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computational Science and Technology</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<addrLine>1 Gwanak-ro, Gwanak-gu</addrLine>
									<postCode>08826</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myeongho</forename><surname>Jeon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junho</forename><surname>Lee</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myungjoo</forename><surname>Kang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Mathematical Sciences</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<addrLine>1 Gwanak-ro, Gwanak-gu</addrLine>
									<postCode>08826</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computational Science and Technology</orgName>
								<orgName type="institution">Seoul National University</orgName>
								<address>
									<addrLine>1 Gwanak-ro, Gwanak-gu</addrLine>
									<postCode>08826</postCode>
									<settlement>Seoul</settlement>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MCW-Net: Single Image Deraining with Multi-level Connections and Wide Regional Non-local Blocks ?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A R T I C L E I N F O</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Keywords:</head><p>Single image deraining multi-level connection adaptive non-local operation low-level vision A B S T R A C T A recent line of convolutional neural network-based works has succeeded in capturing rain streaks. However, difficulties in detailed recovery still remain. In this paper, we present a multi-level connection and wide regional non-local block network (MCW-Net) to properly restore the original background textures in rainy images. Unlike existing encoder-decoder-based image deraining models that improve performance with additional branches, MCW-Net improves performance by maximizing information utilization without additional branches through the following two proposed methods. The first method is a multi-level connection that repeatedly connects multi-level features of the encoder network to the decoder network. Multi-level connection encourages the decoding process to use the feature information of all levels. In multi-level connection, channel-wise attention is considered to learn which level of features is important in the decoding process of the current level. The second method is a wide regional non-local block. As rain streaks primarily exhibit a vertical distribution, we divide the grid of the image into horizontally-wide patches and apply a non-local operation to each region to explore the rich rain-free background information. Experimental results on both synthetic and real-world rainy datasets demonstrate that the proposed model significantly outperforms existing state-of-the-art models. Furthermore, the results of the joint deraining and segmentation experiment prove that our model contributes effectively to other vision tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Adverse weather conditions such as rain, haze, and snow can produce complex visual effects on natural images and videos. In particular, rain streaks, which is one of the most commonly occurring phenomena in outdoor imaging, can potentially degrade the performance in several computer vision applications. Therefore, it is imperative to develop algorithms that effectively remove rain streaks and restore pristine background scenes in vision-related tasks.</p><p>Over the past few decades, several research works have studied the removal of rain streaks from captured images. Several traditional deraining methods have suggested separating rain streaks from the clean background image based on the physical characteristics or texture appearance patterns of the rain streaks. Recently, convolutional neural network (CNN)-based methods have achieved great success in solving this problem <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>Many of the CNN-based methods utilize encoder-decoder structures, and for the most part, they add subnetworks without fully utilizing the information generated during the encoding-decoding process. For example, to remove finegrained rain streaks and recover rain-free backgrounds more clearly, Yu et al. <ref type="bibr" target="#b43">[44]</ref> consider the encoder-decoder as a coarse deraining stage and use an additional simple network ? * corresponding author ychpark@snu.ac.kr (Y. Park); andyjeon@snu.ac.kr (M. Jeon); joon2003@snu.ac.kr (J. Lee); mkang@snu.ac.kr (M. <ref type="bibr">Kang)</ref> ncia.snu.ac.kr (M. Kang) ORCID(s): 0000-0002-4211-6226 (Y. Park); 0000-0002-4509-582X (M. Jeon); 0000-0001-7643-1024 (J. Lee) <ref type="bibr" target="#b0">1</ref> Equal Contribution as a fine deraining stage. Wang et al. <ref type="bibr" target="#b30">[31]</ref> add a residual learning branch parallel to the encoder part to form a better conditional embedding and eventually generate a much better deraining result in the decoder part. Adding these subnetworks can easily improve performance, but there is a limitation that a model becomes heavier without leveraging enough information of an original model. There is also an effort to utilize the information that is generated within the model. In order to obtain and leverage information from other pixels for the degraded background pixels, Li et al. <ref type="bibr" target="#b17">[18]</ref> and Yu et al. <ref type="bibr" target="#b43">[44]</ref> exploit non-local operations. These models use a square grid with the same aspect ratio in non-local operations. However, the operations with the square grid lack an understanding of the unique properties of the rain streaks because of their vertical distribution in the rainy image, which we explore (see <ref type="figure">Figure 3</ref>). Consequently, these methods have difficulties in recovering details in extremely adverse weather conditions.</p><p>To address these limitations of the prior works, we present a multi-level connection and wide regional non-local block network (MCW-Net) to carefully remove rain streaks and recover background details efficiently leveraging information generated during the encoding-decoding process. The proposed MCW-Net is based on an encoder-decoder structure consisting of down-sampling and up-sampling components as depicted in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>We construct multi-level connection (MLC) between multiple-scale features to efficiently utilize information across various scales without additional subnetworks in the recovery of the background. We implement an interactive multiconnection that considers the interconnections between different scales. Because the features at multiple levels show different scale characteristics, direct connections rather cause adverse effects in the model. To adaptively rescale the channel-wise features in MLC, we apply a channel-wise attention layer <ref type="bibr" target="#b12">[13]</ref> after MLC, which helps the network to focus on the useful channels. We demonstrate the importance of the channel-wise attention, and we validate that MLC plays an effective role by comparing the qualitative and quantitative results of models with and without MLC in Section 4.4.2.</p><p>In addition, we implement a non-local operation <ref type="bibr" target="#b34">[35]</ref> to capture long-range spatial dependencies between distant pixels. We propose a wide regional non-local block (WRNL), which divides feature maps into grids of wide regions (see <ref type="figure" target="#fig_1">Figure 2</ref>) before performing the region-wise non-local operation. This wide grid provides a relatively more even distribution of the rain streaks by region, which facilitates the retrieval of rich long-range background information during the recovery of the original rain-free image (see Section. 3.2.1).</p><p>Additionally, as described in <ref type="bibr" target="#b39">[40]</ref>, to prevent information loss during the sampling operation, we adopt the discrete wavelet transform (DWT) and inverse DWT (IWT) in place of the simple pooling and de-convolution operations. Unlike the pooling operation, the DWT operation is invertible via IWT, which helps to avoid information loss. In addition, rain streaks can be captured with rich frequency information via wavelet transform.</p><p>We evaluate the proposed MCW-Net on various synthetic and real-world deraining datasets and compare its performance with existing state-of-the-art methods. In particular, for real-world images, we measure the performance of the proposed method using B-FEN <ref type="bibr" target="#b38">[39]</ref> metric dedicated to deraining quality measurement. We conduct an experiment on raindrop data, another degradation phenomenon caused by rain from the perspective of the generalization ability of the model. In addition, we validate in RainCityscape experiments that the proposed method can also help with other vision tasks such as semantic segmentation. In summary, the contributions of this work may be summarized as follows. 1) We propose MLC to fully leverage information generated in encoding-decoding process for detail recovery without additional subnetworks. Feature information of all the scales in the down-sampling part is aggregated at each stage of the up-sampling part of the network, so it helps to recover details by preventing information loss that occurs during the sampling process. We also analyze that channelwise attention plays an key role in the MLC.</p><p>2) We propose the WRNL, which effectively restores the background by using sufficient rain-free information in each region of widely divided grids in the input feature maps. We experimentally demonstrated that the distribution of even rain streaks by grid helps the deraining performance.</p><p>3) We perform experiments on both synthetic and realworld rain datasets and demonstrate that the proposed method significantly outperforms existing state-of-the-art methods. We also demonstrate the excellence of the proposed method for real-world images using B-FEN, a metric dedicated to measuring deraining quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4)</head><p>We construct joint image deraining and semantic segmentation models on the RainCityscape dataset. In addition to conventional comparisons such as the peak signal-tonoise ratio (PSNR) and structural similarity index measure (SSIM), we comprehensively evaluate the contribution of the deraining model to other vision tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>The single image deraining problem begins with the assumption that a rainy image consists of a background layer and a rainy layer. Several traditional training methods based on single images and videos have been proposed. Barnum et al. <ref type="bibr" target="#b0">[1]</ref> reconstruct rainy images by combining the appearance model with the streak model. The appearance model identifies individual rain streaks and the streak model utilizes the statistical characteristics of rain. Chen and Hsu <ref type="bibr" target="#b4">[5]</ref> use the low-rank model to separate the layers in a rainy image. As noted by Yang et al. <ref type="bibr" target="#b41">[42]</ref>, sparse coding is applied during this process to separate the rainy layer from the rainy image <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b50">51]</ref>. Further, Li et al. <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b20">21]</ref> approach this problem using the Gaussian mixture model.</p><p>Because of the remarkable performance exhibited by deep learning-based methods, especially CNN-based ones, the potential use of deep learning in deraining has been extensively researched. Yang et al. <ref type="bibr" target="#b40">[41]</ref> apply a CNN-based method for the first time and express natural images by adding atmospheric light as a component to rainy images. Fu et al. <ref type="bibr" target="#b10">[11]</ref> and Fan et al. <ref type="bibr" target="#b9">[10]</ref> use a single primary network that restores input images using the residual network. Based on the residual network, Li et al. <ref type="bibr" target="#b19">[20]</ref> attempt to further eliminate overlapping rain streaks by organizing the context aggregate network into multiple stages. Shen et al. <ref type="bibr" target="#b26">[27]</ref> consider rain streaks to be high-frequency and attempt to remove rain streaks by utilizing DWT. Yang et al. <ref type="bibr" target="#b39">[40]</ref> divide the deraining process into several stages and reconstruct the image recurrently, beginning with a small portion of the image to eventually obtain the entire image.</p><p>Wang et al. <ref type="bibr" target="#b33">[34]</ref> capture the spatial contextual information using a four-directional recurrent neural network with the identity matrix initialization model. Ren et al. <ref type="bibr" target="#b25">[26]</ref> propose progressive ResNet to effectively remove the rain via recursive computation. Yu et al. <ref type="bibr" target="#b43">[44]</ref> propose GraNet, which is designed to identify rain masks in the coarse stage using a region-aware non-local block. Subsequently, the process uses the rain masks to create the final image using another reconstruction network. To achieve pixel-wise deraining in image recovery, encoder-decoder structures have been used in certain methods. Wang et al. <ref type="bibr" target="#b30">[31]</ref> propose the residual learning branch as a component of the encoder. Li et al. <ref type="bibr" target="#b17">[18]</ref> enhance the performance by introducing non-local blocks into the encoder-decoder network. Among the methods that reconstruct the rainy layer to be identical to the background layer, the generative adversarial network is widely used to remove raindrops and rain streaks <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b47">48]</ref>.</p><p>Yang et al. <ref type="bibr" target="#b42">[43]</ref> propose the fractal band learning network based on frequent band recovery. Wang et al. <ref type="bibr" target="#b31">[32]</ref> propose an interpretable deep network based on a convolutional dictionary network. Jiang et al. <ref type="bibr" target="#b15">[16]</ref> use the images of various sizes as the input to the model. A multiscale pyramid structure is used to promote cooperative representation. Deng et al. <ref type="bibr" target="#b7">[8]</ref> propose two-branch parallel networks, in which one branch performs rain removal and the other branch detail recovery. In <ref type="bibr" target="#b36">[37]</ref>, newly formulated rain streaks transmission maps, vapor transmission maps, and atmospheric lights are respectively learned by three different networks. Zhang et al. <ref type="bibr" target="#b48">[49]</ref> propose a paired rain removal network, which exploits both stereo images and semantic information. Zamir et al. <ref type="bibr" target="#b45">[46]</ref> propose a multi-stage progressive architecture with a supervised attention module for image restoration.</p><p>Chen et al. <ref type="bibr" target="#b2">[3]</ref> present an image processing transformer (IPT). IPT covers different several tasks such as superresolution, denoising, and deraining based on the transformer method. The authors augment ImageNet images to low-resolution, noised, and rainy images via corresponding filters and then pre-train the IPT with each set. Yue et al. <ref type="bibr" target="#b44">[45]</ref> propose a dynamic rain generator to mimic the rain streaks in the video. The rain streaks in generated videos are removed by a deep learning-based model called derainer.</p><p>Zhang et al. <ref type="bibr" target="#b49">[50]</ref> exploit the low to high-level features and attention operation to restore the hazed images. Their intuition is that the low-level features contribute to recovering finer details and the high-level features represent the shape of the object or abstract semantic information. The utilization of hierarchical features and the attention mechanism are similar to one of our strategies, multi-level connection. However, their work fuses the lower-level features only in the most-down-sampled features, whereas we consider all the features captured in the down-sampling phase on every up-sampling phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Network</head><p>In this section, we describe the architecture of the proposed MCW-Net, which is is based on a U-Net-like structure whose overview is depicted in <ref type="figure" target="#fig_0">Figure 1</ref>. As is apparent from the figure, we divide the levels according to the size of the feature map and define a set of blocks as a stage.</p><p>The proposed MCW-Net consists of an encoder part and a decoder part. The first three stages form the encoder part, and the remaining four stages the decoder part. We propose MLC, which connect all outputs of the encoder to all inputs of the decoder. MLC enables more diverse scale features to be used during the restoration process. Each stage of MCW-Net is composed of two densely connected residual (DCR) blocks, each of which consists of three convolution layers followed by PReLU <ref type="bibr" target="#b29">[30]</ref> (refer <ref type="figure" target="#fig_0">Figure 1(b)</ref>) and one WRNL block. To adaptively rescale channel-wise features after concatenating the multi-level features, a squeeze-andexcitation (SE) block is added in front of each decoder stage. A 1?1 convolutional layer follows the SE block to adjust the number of channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Multi-Level Connection</head><p>In the usual U-Net-like network, connections exist only between features corresponding to the same level. Such a structure cannot make use of multiple scale information during the recovery of low-level features in the decoder. However, single image deraining is a low-level vision task that requires richer range scale features to restore the details in the image. Inspired by <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b32">33]</ref>, we formulate MLC to aggregate the features of all the levels. At each stage of the up-sampling part of the network, features from all scales in the down-sampling part is aggregated. These multi-scale features provide a wider range of information from simple patterns (e.g., corners or edge/color conjunctions) in its lower-level to more complex high-level features (e.g., significant variation and object-specific features). They encourage more delicate deraining because rainy pixels in the image are recovered referencing semantic context and details from other intact pixels. However, simply fusing various features might cause necessary information weighted insufficiently in conjunction with more weight on less helpful information at the current up-sampling stage. The attention mechanism allows the model to focus more on significant channels among several channels, and for this reason, it is essential when connecting features of multiple levels. Formally, let be the output features at level ( = 1, 2, 3) in the encoder part. At each level ( = 1, 2, 3, 4) in the decoder part, the input feature is given as:</p><formula xml:id="formula_0">= ( 3 ? =1 ( )) ? ( +1 ) (1) = 1?1 ( ( ))<label>(2)</label></formula><p>where ? denotes the concatenation operation, (?) denotes the up-sampling operation, denotes the output feature of the decoder part at level , 1?1 denotes the 1 ? 1 convolution layer, and (?) denotes the SE block discussed above. (?) denotes the sampling operation from level to . In other words, is the down-sampling by ? times, identity, and up-sampling by ? times operations if &gt; , = , and &lt; , respectively. We set 5 = 0 for convenience.</p><p>Without MLC, high-level features cannot be used during the processing of low-level features and vice versa. This approach helps the network to exploit various scale representations in recovering large-scale features. To find the correct correspondence between the feature shapes at different scales, we apply discrete wavelet transforms (DWT or IWT), as described in Section 3.3, for the down-sampling and up-sampling operations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Wide Regional Non-Local Block</head><p>We denote the input feature to the WRNL as</p><formula xml:id="formula_1">? ? ? ? . We divide into a ? grid of patches { }, ( = 1, ..., = )</formula><p>where is the number of patches. The grid division is illustrated in <ref type="figure" target="#fig_1">Figure 2</ref>. The linear embedding processes for to generate the output are formulated as follows.</p><formula xml:id="formula_2">?( ) = ( , ) = exp{ ( ) ( ) } (3) ( ) = , ( ) = , ( ) =<label>(4)</label></formula><p>where denotes the feature at position = 1, ..., ? . The learnable weight matrices , , and have the dimensions of ? , ? , and ? , respectively. In practice, = ?2 is used. The regional non-local operation can be expressed as follows:</p><formula xml:id="formula_3">= 1 ( ) ? ? ?( ) ( ) , ? ,<label>(5)</label></formula><p>where ( ) = ? ? ( , ) denotes the correlation between and each in , and denotes the output feature at position . denotes a set of patch positions. If &gt; , then the patch is wider than when = . Therefore, we call the patch a wide rectangular patch, a square patch, and a tall rectangular patch if &gt; , = , and &lt; , respectively. In the WRNL block, we set the ? grids to 16 ? 4 , 8 ? 2, 4 ? 1, and 4 ? 1 at levels 1, 2, 3, and 4, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Analysis</head><p>Given that the non-local block recovers a specific pixel based on the information of other pixels in the patch, it is necessary to have sufficient background information in each patch. The regional non-local block uses the background information sufficiently if the rain streaks are evenly distributed between the patches. However, we observe that the rain streaks are not evenly distributed between square patches in the images used in the previous deraining research <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b43">44]</ref>. Because of the predominantly vertical distribution of rain steaks, we expect that wide rectangular patches have a more even distribution of the streaks than square and tall rectangular patches.</p><p>The distribution of the rain streaks is confirmed through experiments. Wide rectangular, square, and tall rectangular patches are prepared by dividing the height and width of the (a) Rain200H <ref type="bibr" target="#b40">[41]</ref> (b) Rain200L <ref type="bibr" target="#b40">[41]</ref> (c) SPA-data <ref type="bibr" target="#b33">[34]</ref> Figure 3: Analysis of rain streak distributions in various region types. The x-axis represents the standard deviation between the number of rain pixels in the patches in each image. The y-axis represents the number of images and vertical bars are the means of each dataset standard deviation. The distribution of the images according to the standard deviation is represented by histograms. We approximate the probability density function of the histogram by using kernel density estimation. As can be seen in the figures, the wide region has the smallest standard deviation mean on all the datasets, so it can be interpreted that each patch of the wide region has the evenest background information. We consider pixels as rain streaks if the difference between the pixels in and exceeds a certain threshold. The standard deviation between the number of rain pixels in the patches included in each image is depicted in <ref type="figure">Figure 3</ref>. Wide rectangular patches are observed to exhibit smaller standard deviation values compared to square and tall rectangular patches, which implies an even distribution of rain across all patches. This results in the effective recovery of the image because the usable background information within each patch is also distributed evenly as shown in <ref type="table">Table 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Discrete Wavelet Transform</head><p>To prevent information loss, we adopt the discrete wavelet transform for the sampling operation. In particular, We use 2D Haar wavelet which is widely used in image processing.</p><p>The proposed network uses DWT and IWT for downsampling and up-sampling, respectively. In particular, we adopt the Haar transform, which is simple and widely used method in image processing <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b39">40]</ref>. The Haar transform is calculated based on the filter , , and as follows:</p><formula xml:id="formula_4">= 1 4 1 1 1 1 , = 1 4 ?1 ?1 1 1 , = 1 4 ?1 1 ?1 1 , = 1 4 1 ?1 ?1 1 .<label>(6)</label></formula><p>Given that is identical to average pooling, achieves local translation invariance by reducing the size of the feature map (Equation 6).</p><p>, , and contain edge information. In particular, as contains vertical edge information, the features of the rain streaks can be effectively obtained from it. The IWT operation during the up-sampling process is the inverse operation of the DWT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Loss Function</head><p>We define the loss function as follows.</p><formula xml:id="formula_5">? = ? ? ( )? 1 + ? ? ( )? 2<label>(7)</label></formula><p>where denotes the input rainy image, denotes the corresponding rain-free image, and denotes the return of the MCW-Net output with respect to . We use L1+L2 loss because it shows the slightly better performance, but our method does not appear to be sensitive to the loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we present the dataset used in this study and describe the details of the experimental setting. We present two versions of the proposed MCW-Net: a small model and a large model. The architecture of the two models is same except for the number of channels. The small model has eight times fewer channels than the large model. We conduct a quantitative and qualitative evaluation of the proposed method and compare its performance with state-ofthe-art methods. An ablation study is conducted to confirm the significance of each component introduced in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and Evaluation Metrics</head><p>Five synthetic datasets (Rain200H, Rain200L, Rain800, Rain1200, RainCityscapes) and three real-world datasets (SPA-Data, Yang et al. <ref type="bibr" target="#b40">[41]</ref>, DQA <ref type="bibr" target="#b38">[39]</ref>) are used to evaluate the performance of the proposed method. As pointed out by Ren et al. <ref type="bibr" target="#b25">[26]</ref>, certain overlaps of background exist between the training and test datasets in the Rain100H and Rain100L datasets. Therefore, we evaluate our model using the updated Rain200H and Rain200L datasets, which do not share backgrounds with the corresponding training datasets. Because the absence of ground truth data makes quantitative evaluation impossible, the real-world dataset of <ref type="bibr" target="#b40">[41]</ref> is evaluated qualitatively using the Rain200H-trained weights. In addition, Raindrop <ref type="bibr" target="#b24">[25]</ref> dataset is used to evaluate the raindrop removal performance of the proposed method. We compare the performance of the proposed method with nine state-of-the-art single-image deraining methods. We employ PSNR and SSIM <ref type="bibr" target="#b37">[38]</ref> metrics for quantitative quality assessment. All the PSNRs reported in the following experimental results are calculated for RGB channels. Some <ref type="table">Table 1</ref> Average PSNR and SSIM comparison on the synthetic datasets Rain200H <ref type="bibr" target="#b40">[41]</ref>, Rain200L <ref type="bibr" target="#b40">[41]</ref>, Rain800 <ref type="bibr" target="#b47">[48]</ref>, Rain1200 <ref type="bibr" target="#b46">[47]</ref>, and real-world dataset SPA-Data <ref type="bibr" target="#b33">[34]</ref>. The highest values are indicated in red and the second-highest values are indicated in blue. Note that IPT uses rainy-augmented ImageNet pre-trained weight, but proposed methods and other comparable models do not. So we manually train the IPT from sketch only with the provided dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>JORDER <ref type="bibr" target="#b40">[41]</ref> RESCAN <ref type="bibr" target="#b19">[20]</ref> SPANet <ref type="bibr" target="#b33">[34]</ref> PReNet <ref type="bibr" target="#b25">[26]</ref> ReHEN <ref type="bibr" target="#b41">[42]</ref> RCDNet <ref type="bibr">[</ref>  previous works filter the derained RGB images into YCbCr space and then evaluate PSNR only for the Y channel to focus on the luminance. However, because most of the highlevel vision algorithms commonly receive the RGB image as an input, we consider evaluation of well-recovered rainy image in RGB space is more appropriate and helpful for other vision tasks. Additionally, we employ the dedicated B-FEN metric <ref type="bibr" target="#b38">[39]</ref> to measure the deraining quality of deraining algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Datasets and Experiment Details</head><p>For all the datasets, we randomly crop 256 ? 256 patch from each input image. During the training, we set the batch size to 4 and use the Adam optimizer. For the large model, we set the learning rate to be 10 ?4 and train our model for 200 epochs on the Rain200H, Rain200L, and Rain800 datasets, 100 epochs on the Rain1200 and the RainCityscapes datasets, 3 epochs on the SPA-Data dataset, and 500 epochs on the Raindrop dataset. For the small model, we set the learning rate to be 5 ? 10 ?4 and train our model for 500 epochs on the Rain200H, Rain200L, and Rain800 datasets, 100 epochs on the Rain1200 and the RainCityscapes datasets, 5 epochs on the SPA-Data dataset, and 750 epochs on the Raindrop dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Evaluations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Results on Synthetic Datasets</head><p>As mentioned in Section 4, the proposed MCW-Net is evaluated on four synthetic datasets, and the performance is compared to eight state-of-the-art methods. The quantitative results on the synthetic datasets are presented in <ref type="table">Table 1</ref>.</p><p>For other models to be compared, if a metric is not provided in the original paper, we train the models with their default settings and report the results to the comparison table. Otherwise, we report the better result between the provided metric in the original paper and the result obtained by our re-trained model. If reproduction is not possible, we directly copy the provided result to the comparison table.</p><p>As is evident from the data, the proposed MCW-Net (large) achieves remarkable improvement over existing stateof-the-art methods with respect to the PSNR and SSIM metrics across all synthetic datasets, and MCW-Net (small) follows right behind.</p><p>The original inputs, the ground truth, and the qualitative results for Rain200H are shown in <ref type="figure">Figure 4</ref>. As shown in the yellow boxes of <ref type="figure">Figure 4</ref>, MCW-Net (small) clearly restores the number compared to other methods, and MCW-Net (large) restores the digits surprisingly similar to ground truth. In the red boxes of <ref type="figure">Figure 4</ref>, MCW-Net (small) restores the sky and spokes of the windmill cleanly compared to other methods but failed to recover lines, while MCW-Net (large) restores some of the lines.</p><p>(a) Rainy image (b) JORDER <ref type="bibr" target="#b40">[41]</ref> (c) RESCAN <ref type="bibr" target="#b19">[20]</ref> (d) SPANet <ref type="bibr" target="#b33">[34]</ref> (e) PReNet <ref type="bibr" target="#b25">[26]</ref> (f) ReHEN <ref type="bibr" target="#b41">[42]</ref> (g) RCDNet <ref type="bibr" target="#b31">[32]</ref> (h) MPRNet <ref type="bibr" target="#b45">[46]</ref> (h) IPT <ref type="bibr" target="#b2">[3]</ref> (i) MCW-Net(small) (j) MCW-Net(large) (k) GT (a) Rainy image (b) JORDER <ref type="bibr" target="#b40">[41]</ref> (c) RESCAN <ref type="bibr" target="#b19">[20]</ref> (d) SPANet <ref type="bibr" target="#b33">[34]</ref> (e) PReNet <ref type="bibr" target="#b25">[26]</ref> (f) ReHEN <ref type="bibr" target="#b41">[42]</ref> (g) RCDNet <ref type="bibr" target="#b31">[32]</ref> (h) MPRNet <ref type="bibr" target="#b45">[46]</ref> (h) IPT <ref type="bibr" target="#b2">[3]</ref> (i) MCW-Net(small) (j) MCW-Net(large) (k) GT <ref type="figure">Figure 4</ref>: Results obtained via several state-of-the-art methods on the Rain200H <ref type="bibr" target="#b40">[41]</ref> images. The outputs of MCW-Net exhibit no traces of rain streaks on both image samples. MCW-Net also recovers the most detailed images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2.">Results on Real-world Datasets</head><p>For further general verification of the proposed method, additional experiments are conducted on two real-world datasets. To estimate the performance of the other stateof-the-art models, we employ the same way as quantitative evaluation of synthetic data. On the SPA-Data, MCW-Net exhibits quantitatively outstanding performance compared to the other state-of-the-art methods.</p><p>To confirm the effectiveness of the method trained using synthetic rainy images in removing real rain streaks, qualitative experiments are conducted on images presented by Yang et al. <ref type="bibr" target="#b40">[41]</ref>. To compare the model performances under fair conditions, only Rain200H is used during the training process. As shown in <ref type="figure">Figure 5</ref>, MCW-Net generates satisfactory results with respect to both the removal of the rain streaks and the restoration of the details in the background. The small and large versions of MCW-Net recover the details of the columns in the red box and remove the rain streaks in the yellow box better compared to other models. Although detail recovery and rain removal are the trade-off for other models, MCW-Net succeeds in both. MCW-Net also recovers the cleanest background for another image sample. The yellow box shows the output of MCW-Net exhibits no traces of rain streaks while they are left in the result of the other models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3.">Results on Authentic Rain Images with the Dedicated Metric</head><p>PSNR and SSIM estimate how the recovered output image closes to the target image. Therefore, several lowlevel vision tasks (e.g., denoising, super-resolution, deraining) conventionally exploit these metrics as an evaluation tool. Nonetheless, one might argue that PSNR and SSIM are general-purpose quality metrics so they are limited to (a) Rainy image (b) JORDER <ref type="bibr" target="#b40">[41]</ref> (c) RESCAN <ref type="bibr" target="#b19">[20]</ref> (d) SPANet <ref type="bibr" target="#b33">[34]</ref> (e) PReNet <ref type="bibr" target="#b25">[26]</ref> (f) ReHEN <ref type="bibr" target="#b41">[42]</ref> (g) RCDNet <ref type="bibr" target="#b31">[32]</ref> (h) MPRNet <ref type="bibr" target="#b45">[46]</ref> (i) MCW-Net (small) (j) MCW-Net (large) (a) Rainy image (b) JORDER <ref type="bibr" target="#b40">[41]</ref> (c) RESCAN <ref type="bibr" target="#b19">[20]</ref> (d) SPANet <ref type="bibr" target="#b33">[34]</ref> (e) PReNet <ref type="bibr" target="#b25">[26]</ref> (f) ReHEN <ref type="bibr" target="#b41">[42]</ref> (g) RCDNet <ref type="bibr" target="#b31">[32]</ref> (h) MPRNet <ref type="bibr" target="#b45">[46]</ref> (i) MCW-Net (small) (j) MCW-Net (large) <ref type="figure">Figure 5</ref>: Results obtained via several state-of-the-art methods on the Yang et al. <ref type="bibr" target="#b40">[41]</ref> images. Among state-of-the-art methods, MCW-Net is the only one that restore the detail of the images while removing the rain streaks.</p><p>concentrating only on the deraining ability. Besides, they need target images to be calculated and thus cannot be applied on target-absent authentic rainy images.</p><p>To handle this issue, we additionally evaluate the proposed method via a measurement called B-FEN <ref type="bibr" target="#b38">[39]</ref>, which accurately evaluates the deraining quality using a bi-directional feature embedding network. A higher B-FEN score represents better perceptual quality, which indicates that the model not only effectively removes rain streaks but also well preserves the original rain-free image. We train all the comparable models and the proposed method on SPA-Data and evaluate the DQA dataset <ref type="bibr" target="#b38">[39]</ref>. Since DQA is a realworld testing image set, real-world SPA-Data can guide the model to capture the properties of authentic rain streaks. As shown in <ref type="table" target="#tab_2">Table 3</ref>, our model achieves the highest B-FEN score. One thing to note is that the small version of MCW-Net has a higher B-FEN score than the large version of MCW-Net. B-FEN is a subjective opinion-aware metric, and (a) Rainy image (b) MPRNet <ref type="bibr" target="#b45">[46]</ref> (c) RCDNet <ref type="bibr" target="#b31">[32]</ref> (d) PReNet <ref type="bibr" target="#b25">[26]</ref> (e) SPANet <ref type="bibr" target="#b33">[34]</ref> (g) MCW-Net (small) (j) MCW-Net (large) <ref type="figure">Figure 6</ref>: Results obtained via several state-of-the-art methods on the DQA images. Among state-of-the-art methods, MCW-Net is the only one that restore the detail of the images while removing the rain streaks. Based on the area of left-most person in (g) and (j), the small version removed rain better than the larger version, consistent with the results of the B-FEN score. However, the small version remove all the wrinkles on clothes, and the large version preserve them, so the large version achieves a better restoration of details. opinion-making participants may tend to focus more on rain streaks removal than background restoration. From this point of view, it may lead to possible inconsistent results different from that of other objective opinion-unaware metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4.">Results on Raindrop data</head><p>Raindrops, which are a commonly observed phenomenon in conjunction with rain, also might degrade the performance in computer vision applications. Even though we design the proposed method to remove rain streaks in images, we explore the model's generalizability with the raindrop image dataset. The experimental results are reported in <ref type="table" target="#tab_3">Table  4</ref> and <ref type="figure" target="#fig_4">Figure 7</ref>. In the evaluation, we use the weight of the AGAN model provided by the author. We calculate PSNR and SSIM metrics in RGB channels as in other experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Study</head><p>We conduct an ablation study to demonstrate the significance of all the methods used in the MCW-Net architecture. MCW-Net (large) and Rain200H dataset are used for the  <ref type="table">Table 5</ref> Ablation study on types of regional non-local blocks. ablation study. We conduct three experiments and report the average values. All the evaluations are dedicated to the proposed method without Cutmix. Because Cutmix is the data augmentation strategy and hence is not directly related to ablation about the model structure.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1.">Ablation study on strategies employed</head><p>An ablation investigation is conducted to evaluate the performance of the proposed strategies. The baseline model is constructed with two DCR blocks corresponding to each stage and the 2?2 max pooling and pixel shuffle operation are adopted as the down-sampling and up-sampling operations, respectively. As evident from <ref type="table" target="#tab_5">Table 6</ref>, each strategy contributes to the performance improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2.">Ablation study on MLC</head><p>To show the importance of channel-wise attention to MLC, we evaluate the performance using MLC with channelwise attention and MLC with other commonly used fusing operations, addition and concatenation. As shown in <ref type="table">Table  8</ref>, MLC with addition or concatenation rather degrade the performance. We analyze that this result occurs because additional information which is messy and unorganized rather interferes with the decoding process. Considering channel-wise attention serves as an indication of which information should be referenced more importantly at the current level decoding process, so MLC with channel-wise attention improves the performance of the model.</p><p>In addition, we conduct a qualitative ablation study to see if MLC actually helps to restore the details as intended, and the results are shown in <ref type="figure">Figure 8</ref>. The results confirm that MLC effectively does detail recovery as well as quantitative improvement. Details of the results are described in the caption of <ref type="figure">Figure 8</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3.">Ablation study on non-local block region types</head><p>We evaluate the performance using square, tall, and wide-type regional non-local blocks on Rain200H, Rain200L, and SPA-DATA datasets. The results presented in <ref type="table">Table  5</ref> demonstrate that the wide-type regional non-local block achieves the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.4.">Ablation study on various sampling operations</head><p>To compare the performance of various sampling operations, we evaluate the performance using mean pooling, 1x1 convolution, and the discrete wavelet transform. The results presented in <ref type="table">Table 7</ref> demonstrate that the discrete wavelet transform has the best performance.  <ref type="figure">Figure 8</ref>: Qualitative ablation study on MLC. MCW-Net (large) is used for the study. In the first row, we can see that the zebra pattern in the red and green box is not well restored without MLC. However, model with MLC restored the pattern in the red and green box well. In the second row, we can also see that the model with MLC better restored the tone and texture of the tree than the model without MLC. As a result, we can confirm that MLC plays a certain role in recovering detail as intended.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 9</head><p>Comparison results of joint deraining and semantic segmentation on RainCityscape dataset comprising three rain intensities ( ? {0.01, 0.02, 0.03} where denotes the intensity of the rain streaks). We use DeepLabV3+ <ref type="bibr" target="#b3">[4]</ref> for semantic segmentation. We compare the models that show an improvement in the semantic segmentation performance which is measured as mIOU metric. avg. in the metric column denotes average value of all .   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metric</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Applications for Other Tasks</head><p>We investigate the effect of the deraining model on improving the performance of high-level vision applications such as semantic segmentation. Because rain streaks can degrade the visibility of objects under complex weather conditions, the incorporation of effective image enhancement would be helpful in several vision models. To this end, we apply the public semantic segmentation model DeepLabV3+ <ref type="bibr" target="#b3">[4]</ref> on the Cityscape dataset <ref type="bibr" target="#b5">[6]</ref>. Hu et al. <ref type="bibr" target="#b13">[14]</ref> synthesized rain streaks on the Cityscape dataset with different rain intensities ( ? {0.01, 0.02, 0.03}). Quantitative results for the improvement of the semantic segmentation accuracy in addition to the deraining performance are reported in <ref type="table">Table 9</ref>. The qualitative comparison is shown in <ref type="figure" target="#fig_7">Figure 9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Analysis on multi-level features</head><p>To achieve insight as to how much each level contributes in deraining process for each connection, we measure the feature importance of channel-wise attention in SE layer at each connection.We measure the feature importance as follows: As presented in Section 3.1, the features of each level in the encoder part are aggregated at level in the decoder part,</p><formula xml:id="formula_6">= ( 3 ? =1 ( )) ? ( +1 )<label>(8)</label></formula><formula xml:id="formula_7">=? 1 ?? 2 ?? 3 ?? ,<label>(9)</label></formula><p>where? and? are the results of ( ) and ( +1 ), respectively. Note that +1 means the output of previous layer. Afterwards, is fed into SE layer as</p><formula xml:id="formula_8">( ) = ([? 1 ,? 2 ,? 3 ,? ])<label>(10)</label></formula><formula xml:id="formula_9">= [? 1 ,? 2 ,? 3 ,? ],<label>(11)</label></formula><p>where, each? can be considered as corresponding output of? because is channel-wise attention operation. Now, we obtain the feature importance by applying 2 norm and normalization to each of them.</p><formula xml:id="formula_10">= ?? ? 2 ? ?? ? 2 , = 1, 2, 3,<label>(12)</label></formula><formula xml:id="formula_11">= ?? ? 2 ? ?? ? 2 , = 1, 2, 3, ,<label>(13)</label></formula><p>where? and? denote the feature importance before and after SE layer, respectively. We calculate the feature importance before and after the SE layer for Rain200H and SPA-DATA datasets as described above, and we report the results in <ref type="figure" target="#fig_0">Figure 10</ref>. We find that feature importance is evenly distributed before the SE layer, but more diversely distributed after the SE layer. Combining such results with <ref type="table">Table 8</ref> and <ref type="figure">Figure 8</ref>, we assume that the channel-wise attention guided via SE operation has a crucial contribution to deraining. Furthermore, unspecified distribution of feature importance before the SE layer could cause performance degradation, implying that simple connections such as addition and concatenation could be detrimental to the performance. In this respect, we suggest that the SE layer emphasizes more meaningful features for recovering rainy images at each level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this study, we present the multi-level connections and an adaptive regional attention network structure for single-image deraining. The proposed MCW-Net adaptively aggregates features via connections between multiple levels and the SE block in the background recovery. To utilize rich long-range rain-free background information in the deraining process, we propose a novel WRNL. The proposed method outperforms existing state-of-the-art methods. In particular, the network restores the details of the input image and almost completely removes rain streaks on both the synthesized and the real-world datasets. Furthermore, additional experiments demonstrate that MCW-Net contributes to other vision tasks by enhancing images degraded under bad weather conditions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Overview of the proposed MCW-Net structure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Examples of patches of the input feature of the regional non-local block. (a) Square patch, (b) Wide rectangular patch. Every pixel in a patch refers to every pixel in the patch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>image into 16 ?</head><label>16</label><figDesc>4, 8 ? 8 and 4 ? 16 grids respectively. It should be noted that (a) in Figure 2 contains an 8 ? 8 grid of patches, and (b) in Figure 2 contains 16 ? 4 grid of patches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Results obtained via several state-of-the-art methods on the Raindrop images. Images in the first ans second rows are from testset A and testset B, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>(a) Input (b) MCW-Net (w.o. MLC) (c) MCW-Net (w. MLC) (d) GT</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 9 :</head><label>9</label><figDesc>Examples of joint deraining and semantic segmentation. The first row denotes the deraining results on the RainCityscape dataset. The second row denotes the semantic segmentation results obtained by DeepLabV3+<ref type="bibr" target="#b3">[4]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Intensity analysis of channel-wise attentions at each MLC on Rain200H and SPA-DATA datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Synthetic and real-world datasets</figDesc><table><row><cell>Datasets</cell><cell>Train</cell><cell>Test</cell><cell>Type</cell></row><row><cell>Rain200L [41]</cell><cell>1,800</cell><cell>200</cell><cell>synthetic</cell></row><row><cell>Rain200H [41]</cell><cell>1,800</cell><cell>200</cell><cell>synthetic</cell></row><row><cell>Rain800 [48]</cell><cell>700</cell><cell>100</cell><cell>synthetic</cell></row><row><cell>Rain1200 [47]</cell><cell cols="2">12,000 1,200</cell><cell>synthetic</cell></row><row><cell cols="2">RainCityscapes [6, 14] 9,432</cell><cell>1,188</cell><cell>synthetic</cell></row><row><cell>SPA-Data [34]</cell><cell>640k</cell><cell>1,000</cell><cell>real-world</cell></row><row><cell>Yang et al. [41]</cell><cell>-</cell><cell>15</cell><cell>real-world</cell></row><row><cell>DQA [39]</cell><cell>-</cell><cell>206</cell><cell>real-world</cell></row><row><cell>Raindrop [25]</cell><cell>861</cell><cell cols="2">58 (A)/249 (B) real-world</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Comparison results of the various methods on DQA dataset in B-FEN [39] metric (higher is better).</figDesc><table><row><cell>Methods</cell><cell>B-FEN</cell></row><row><cell>original</cell><cell>0.2997</cell></row><row><cell>MPRNet</cell><cell>0.3051</cell></row><row><cell>RCDNet</cell><cell>0.3101</cell></row><row><cell>PreNet</cell><cell>0.3139</cell></row><row><cell>SPANet</cell><cell>0.3154</cell></row><row><cell>MCW-Net (ours-small)</cell><cell>0.3287</cell></row><row><cell>MCW-Net (ours-large)</cell><cell>0.3222</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Average PSNR and SSIM comparision on Raindrop dataset.</figDesc><table><row><cell>Dataset</cell><cell>Testset A</cell><cell></cell><cell>Testset B</cell></row><row><cell></cell><cell>PSNR SSIM</cell><cell cols="2">PSNR SSIM</cell></row><row><cell>Eigen13 [9]</cell><cell>23.74 0.788</cell><cell>-</cell><cell>-</cell></row><row><cell>Pix2Pix [15]</cell><cell>28.15 0.855</cell><cell>-</cell><cell>-</cell></row><row><cell>PreNet [26]</cell><cell>28.58 0.913</cell><cell>-</cell><cell>-</cell></row><row><cell>AGAN [25]</cell><cell>30.55 0.910</cell><cell cols="2">24.43 0.795</cell></row><row><cell cols="2">MCW-Net (ours-small) 29.96 0.906</cell><cell cols="2">24.91 0.800</cell></row><row><cell cols="2">MCW-Net (ours-large) 30.77 0.918</cell><cell cols="2">25.17 0.809</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell cols="6">Ablation study on the various strategies presented in Section</cell></row><row><cell>3.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>WRNL</cell><cell>DWT</cell><cell>MLC</cell><cell>Cutmix</cell><cell>PSNR</cell><cell>SSIM</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>28.12</cell><cell>0.906</cell></row><row><cell>?</cell><cell></cell><cell></cell><cell></cell><cell>29.49</cell><cell>0.911</cell></row><row><cell>?</cell><cell>?</cell><cell></cell><cell></cell><cell>30.22</cell><cell>0.917</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell></cell><cell>30.62</cell><cell>0.921</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>?</cell><cell>30.70</cell><cell>0.922</cell></row><row><cell>Table 7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Ablation study on various sampling methods. Note that three</cell></row><row><cell cols="6">different sampling operations are compared on the proposed</cell></row><row><cell cols="4">method without MLP and Cutmix.</cell><cell></cell><cell></cell></row><row><cell cols="2">Sampling Operation</cell><cell></cell><cell>PSNR</cell><cell></cell><cell>SSIM</cell></row><row><cell cols="2">Mean Pooling</cell><cell></cell><cell>29.50</cell><cell></cell><cell>0.909</cell></row><row><cell>1?1 conv.</cell><cell></cell><cell></cell><cell>29.80</cell><cell></cell><cell>0.911</cell></row><row><cell cols="2">DWT &amp; IWT</cell><cell></cell><cell>30.62</cell><cell></cell><cell>0.921</cell></row><row><cell>Table 8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Ablation study on MLC, where C.A. denotes channel-wise</cell></row><row><cell cols="6">attention. The experiments are conducted on the proposed</cell></row><row><cell cols="3">method without Cutmix.</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>PSNR</cell><cell></cell><cell>SSIM</cell></row><row><cell>No MLC</cell><cell></cell><cell></cell><cell>30.22</cell><cell></cell><cell>0.917</cell></row><row><cell cols="3">MLC with concatenation</cell><cell>30.07</cell><cell></cell><cell>0.913</cell></row><row><cell cols="2">MLC with addition</cell><cell></cell><cell>30.26</cell><cell></cell><cell>0.916</cell></row><row><cell cols="2">MLC with C.A. (SE)</cell><cell></cell><cell>30.62</cell><cell></cell><cell>0.921</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Analysis of rain and snow in frequency space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Barnum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page">256</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Rain or snow detection in image sequences through use of a histogram of orientation of streaks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bossu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hauti?re</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Tarel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="348" to="367" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pre-trained image processing transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="12299" to="12310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A generalized low-rank appearance model for spatio-temporally correlated rain streaks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Hsu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A directional global sparse model for single image rain removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">X</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematical Modelling</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="page" from="662" to="679" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Detail-recovery image deraining via context aggregation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Restoring an image taken through a window covered with dirt or rain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="633" to="640" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Residual-guide network for single image deraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ACM MM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Removing rain from single images via a deep detail network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Paisley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Deep wavelet prediction for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Seyed Mousavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Monga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR Workshops</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Depth-attentional features for single-image rain removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1125" to="1134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Multi-scale progressive fusion network for single image deraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Automatic single-imagebased rain streaks removal via image decomposition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">W</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">H</forename><surname>Fu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Non-locally enhanced encoder-decoder network for single image deraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ACM MM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Heavy rain image restoration: Integrating physics model and conditional adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Cheong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Recurrent squeezeand-excitation context aggregation net for single image deraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Rain streak removal using layer priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Brown</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Multi-level wavelet-cnn for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR Workshops</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Removing rain from a single image via discriminative sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The haar-wavelet transform in digital image processing: its status and achievements. Machine graphics and vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Porwik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lisowska</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="79" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Attentive generative adversarial network for raindrop removal from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Progressive image deraining networks: a better and simpler baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Deep joint rain and haze removal from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>IEEE</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09070</idno>
		<title level="m">Efficientdet: Scalable and efficient object detection</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Parametric exponential linear unit for deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Trottier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gigu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chaib-Draa</surname></persName>
		</author>
		<editor>ICMLA, IEEE</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Erl-net: Entangled representation learning for single image de-raining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sowmya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">A model-driven deep neural network for single image rain removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Deep highresolution representation learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.07919</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Spatial attentive single-image deraining with a high quality real rain dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Lau</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A hierarchical approach for rain or snow removing in a single color image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3936" to="3950" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zeng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.00823</idno>
		<title level="m">Rethinking image deraining via rain streaks and vapors</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Ngan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<title level="m">Subjective and objective de-raining quality assessment towards authentic rain image. IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3883" to="3897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Scale-free single image deraining via visibility-enhanced recurrent wavelet learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Deep joint rain detection and removal from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Single image deraining: From model-based to data-driven and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.07150</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Towards scalefree rain streak removal via self-supervised fractal band learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Gradual network for single image de-raining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ACM MM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Semi-supervised video deraining with dynamical rain generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="642" to="652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multi-stage progressive image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="14821" to="14831" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Density-aware single image de-raining using a multi-stream dense network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Image de-raining using a conditional generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sindagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on circuits and systems for video technology</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Beyond monocular deraining: Stereo image deraining via semantic understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Multi-level fusion and attention-guided cnn for image dehazing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Joint bi-layer optimization for single-image rain streak removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>ICCV</publisher>
			<biblScope unit="page" from="2526" to="2534" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
