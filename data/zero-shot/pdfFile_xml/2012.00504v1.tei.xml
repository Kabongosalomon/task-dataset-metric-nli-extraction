<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Boosting the Performance of Semi-Supervised Learning with Unsupervised Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boaz</forename><surname>Lerner</surname></persName>
							<email>boaz.lerner@mail.huji.ac.il</email>
							<affiliation key="aff0">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guy</forename><surname>Shiran</surname></persName>
							<email>guy.shiran@mail.huji.ac.il</email>
							<affiliation key="aff1">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphna</forename><surname>Weinshall</surname></persName>
							<email>daphna@cs.huji.ac.il</email>
							<affiliation key="aff2">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Boosting the Performance of Semi-Supervised Learning with Unsupervised Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recently, Semi-Supervised Learning (SSL) has shown much promise in leveraging unlabeled data while being provided with very few labels. In this paper, we show that ignoring the labels altogether for whole epochs intermittently during training can significantly improve performance in the small sample regime. More specifically, we propose to train a network on two tasks jointly. The primary classification task is exposed to both the unlabeled and the scarcely annotated data, whereas the secondary task seeks to cluster the data without any labels. As opposed to hand-crafted pretext tasks frequently used in self-supervision, our clustering phase utilizes the same classification network and head in an attempt to relax the primary task and propagate the information from the labels without overfitting them. On top of that, the self-supervised technique of classifying image rotations is incorporated during the unsupervised learning phase to stabilize training. We demonstrate our method's efficacy in boosting several state-of-the-art SSL algorithms, significantly improving their results and reducing running time in various standard semi-supervised benchmarks, including 92.6% accuracy on CIFAR-10 and 96.9% on SVHN, using only 4 labels per class in each task. We also notably improve the results in the extreme cases of 1,2 and 3 labels per class, and show that features learned by our model are more meaningful for separating the data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years we have seen huge improvement in the performance of deep learning methods in various computer vision tasks. However, most models require large amounts of annotated data. Collecting this data is a tedious and expensive process. Moreover, learning from so many labels is  <ref type="figure">Figure 1</ref>: Our method iterates between two phases. In the first phase we train our model with the available labeled and unlabeled data points using a semi-supervised learning algorithm. In the second phase we train the same model to cluster all the data points, without using any labels. very different from the way that we as humans learn, and from the way we perceive intelligence. Therefore, it seems desirable, in our journey towards strong AI, to develop models that rely less on data annotated by humans, and are capable of extracting features in an unsupervised manner.</p><p>Semi-Supervised Learning (SSL) is an attempt to tackle this issue and bridge the gap between supervised and unsupervised learning. The typical setting of the problem is that we are given a small amount of labeled data and a possibly large amount of unlabeled data, where both are sampled from the same or similar distributions. Most techniques derive an objective which is split into two separate terms for labeled and unlabeled data <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b29">29]</ref>. In this way, every gradient step is influenced by the labels. <ref type="bibr" target="#b25">[25]</ref> is unusual in that respect, as their method iterates between supervised learning with only labeled data, and unsupervised learning with only unlabeled data. However, their unsupervised stage relies exclusively on fixed pseudo-labels obtained in the su-pervised stage. Hence, this stage can be considered 'supervised learning with noisy labels'.</p><p>In this paper, we wish to benefit from real unsupervised learning, undistracted by a small number of possibly uncharacteristic training points, within the SSL framework. The approach is illustrated in <ref type="figure">Fig. 1</ref>. We start by describing a clustering algorithm that can be easily integrated with any deep SSL method. This algorithm serves as a secondary task to the principal classification task. Unlike <ref type="bibr" target="#b25">[25]</ref>, the pseudo labels (targets) may be propagated from the real labels seen during classification, but they are likely to change during this clustering phase. Also differing from some selfsupervised auxiliary tasks used in <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b32">32]</ref>, we use the exact same architecture (network and head) for clustering. Our main goal is to add to the learning protocol a phase which does not depend on the labels. When learning the secondary task, the goal is to separate the data into clusters without assigning names to those clusters. At the same time, selfsupervision <ref type="bibr" target="#b14">[15]</ref> is used to stabilize and accelerate training during the clustering phase.</p><p>Our main contributions in this paper are the following:</p><p>? Devise a new approach for semi-supervised learning, which is based on solving an unsupervised clustering task together with a classification task.</p><p>? Show how realizing this approach by integrating a new deep clustering algorithm with three existing SSL algorithms can boost their performance and surpass state-ofthe-art results on 3 benchmark datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In this work we employ several methods from various fields, including deep clustering, self-supervision and semisupervised learning. We therefore review the most significant recent developments in each of those fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Deep Clustering</head><p>The task of unsupervised clustering is a long-standing problem and a highly challenging one, especially when it meets the high-dimensionality of images. Classical algorithms, such as k-means <ref type="bibr" target="#b17">[18]</ref> and Gaussian Mixture Models (GMM) <ref type="bibr" target="#b3">[4]</ref>, struggle in this domain as the raw data is not very informative, and thus the need for succinct and meaningful representation of images is critical. In recent years, deep clustering frameworks have become increasingly competent in solving this task. Typically, these models jointly learn image features alongside cluster assignments by training a deep network with some clustering loss in an end-toend fashion. The coupling of learning image features and clusters together allows the deep network to better adapt its image features to the task of clustering.</p><p>In Deep Embedded Clustering (DEC) <ref type="bibr" target="#b26">[26]</ref>, an encoder network is first initialized by pre-training on a reconstruc-tion task alongside a decoder (i.e an auto-encoder) which is afterwards discarded. Then, cluster centroids in the embedding space are iteratively computed and refined until convergence. Joint Unsupervised Learning (JULE) <ref type="bibr" target="#b30">[30]</ref> trains a model in an end-to-end fashion by iteratively merging clusters of deep representations and updating the network's parameters in a hierarchical fashion. Recently, Invariant Information Clustering (IIC) <ref type="bibr" target="#b16">[17]</ref> proposed a novel informationtheory approach for clustering, in which they maximize the mutual information between deep embeddings obtained by two different random augmentations applied to the same image, and rely on the natural characteristics of the mutual information loss to produce a clustering of the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Self-Supervised Learning</head><p>Self-supervised learning is an approach to learning in an unsupervised manner by solving a pretext supervised task. The supervisory signals are gathered automatically from the data without the need for manual labeling. The task is designed in a way that implicitly requires learning of useful image representation, e.g. predicting the relative position of patches in an image <ref type="bibr" target="#b12">[13]</ref>, or solving jigsaw puzzles <ref type="bibr" target="#b23">[24]</ref>. A more recent method <ref type="bibr" target="#b14">[15]</ref> predicts image rotations (RotNet) and has also been used as an auxiliary task to stabilize and improve training in semi-supervised <ref type="bibr" target="#b32">[32]</ref> and image generation tasks <ref type="bibr" target="#b7">[8]</ref>. Similalry, our method also employs RotNet for this purpose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Semi-Supervised Learning</head><p>Semi-supervised learning (SSL) refers to a family of algorithms aimed at learning from both labeled and unlabeled data. Thanks to the relative simplicity of collecting big unlabeled datasets without manual labeling, the field has seen an increasing interest in the last few years. As a result, the performance gap between supervised and unsupervised methods has been consistently diminishing, with the number of labels used to achieve comparable results getting considerably smaller. Given the vast amount of techniques proposed in the literature, we review only the latest and most influential works using deep networks, and refer the reader to <ref type="bibr" target="#b6">[7]</ref> for a comprehensive survey.</p><p>Most deep learning approaches revolve around the two fundamental concepts of entropy minimization and consistency regularization. An intuitive assumption is that the decision boundaries of a classifier should not pass in highly dense areas. Minimizing the entropy of a model's prediction on unlabeled data is a common approach to facilitate this heuristic. It can be done explicitly <ref type="bibr" target="#b15">[16]</ref> or quite often implicitly by psuedo-labeling <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b28">28]</ref>, a method that assigns an artificial label to an unlabeled image and trains the network to predict that label. Consistency regularization refers to the assumption that small perturbations to the data should not affect its semantics, and hence the label.</p><p>It is reasonable then to force the model to output consistent predictions to all perturbed versions of the same sample. Consequently, a lot of recent research makes use of complex augmentation strategies <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b29">29]</ref>. FixMatch <ref type="bibr" target="#b28">[28]</ref>, which is the most relevant to our work, combines both approaches and will be thoroughly discussed in Section 3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>In this section we present an SSL algorithm that alternates between two phases: unsupervised clustering and semi-supervised classification. The method is designed especially to perform well in the very-few-labels scenario.</p><p>As the SSL building block we use in our experiments a variety of recent state-of-the-art algorithms, including Fix-Match <ref type="bibr" target="#b28">[28]</ref> which is used in most of the experiments, as well as MixMatch <ref type="bibr" target="#b2">[3]</ref> and UDA <ref type="bibr" target="#b29">[29]</ref>. Our main goal is to equip them with an additional unsupervised mechanism, in order to reduce their susceptibility to outliers in the small labeled sample. To this end we describe an effective unsupervised deep clustering method. This building block can also be replaced in order to improve performance.</p><p>We start by describing each component separately, and then describe their integration into a single coherent model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Unsupervised Clustering</head><p>In a typical supervised classification setting we are given pairs of images and labels {x i , y i } n i=1 , and train a parameterized model f ? by solving:</p><formula xml:id="formula_0">min ? 1 n n i=1 (f ? (x i ), y i ),<label>(1)</label></formula><p>where is some loss function. In the setting of unsupervised clustering, where ground truth labels y 1 , ..., y n are not available, we can attempt to learn them alongside the model's parameters:</p><formula xml:id="formula_1">min ?,y1,...,yn 1 n n i=1 (f ? (x i ), y i ).<label>(2)</label></formula><p>Without additional constraints, this optimization procedure is prone to suffer from mode collapse, where all images are assigned the same label y 1 = ? ? ? = y n . To overcome this susceptibility, we add a constraint to the optimization formulation that explicitly prevents this from happening:</p><formula xml:id="formula_2">?k ? [K] n i=1 1 yi=k ? ? n K , 0 &lt; ? ? 1.<label>(3)</label></formula><p>Here K denotes the number of classes in the dataset and ? is a hyper-parameter. Eq. 3 guarantees that each cluster has a minimal number of images assigned to it.</p><p>In order to solve this optimization problem, we adapt a similar approach to the one taken in <ref type="bibr" target="#b4">[5]</ref>, where the task of representation learning is addressed. In <ref type="bibr" target="#b4">[5]</ref>, the problem of feature collapse is tackled by fixing static feature vectors {y i } n i=1 at the beginning of training. Throughout the training, the algorithm learns the model's parameters and a one-to-one mapping P :</p><formula xml:id="formula_3">[n] ? [n] from images {x i } n i=1 to those fixed targets.</formula><p>In our case, we are interested in clustering the data, and hence it is reasonable to set the targets to be one-hot vectors in R k , which we denote by e 1 , . . . , e k . To enforce (3), the targets are set to T = {y i |?k ? [K], n i=1 1 yi=e k = ? n K }, with ? n K target instances per cluster. Before training begins, each target is randomly assigned to an image in the dataset. Note that some images may not be paired up with a target as there might be more images than targets.</p><p>The optimization problem is solved stochastically one mini-batch at a time, where each iteration consists of two steps. Given a mini-batch</p><formula xml:id="formula_4">X b = {x 1 , . . . , x b } ? X of b images and their current targets T c = {t 1 , . . . , t c } ? T (b ? c)</formula><p>, the first step finds the best assignment of targets to images, denoted by P * : [c] ? [b], while the network's parameters are kept fixed. This is accomplished by minimizing the following objective with the Hungarian method <ref type="bibr" target="#b19">[20]</ref>:</p><formula xml:id="formula_5">P * = arg min P c i=1 ||f ? (x P (i) ) ? t i || 2 2 .<label>(4)</label></formula><p>Recall that not all images are necessarily assigned a target. Among the unassigned images, only those with confidence exceeding a certain threshold are assigned to pseudotargets. A similar approach is adopted in <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b5">6]</ref>. For an unassigned image x k to be considered confident, we require that ||f ? (x k ) ? e arg max f ? (x k ) || 2 2 &lt; ?, where ? is a hyperparameter. In this case, the pseudo-target assigned to x k is y k = e arg max f ? (x k ) .</p><p>In the second step of the optimization scheme, we update the model's parameters with a gradient step, which minimizes the distance of the model's outputs from the targets or pseudo-targets found in the first step. Specifically, if we denote the unassigned confident images by C, and the batch images being processed by S = Im(P * ) ? C, then in the second step each image in S is augmented r times with a stochastic function g, where all r versions of the same image are matched to the same target. This is formulated as minimizing the following objective w.r.t. ?:</p><formula xml:id="formula_6">L c = 1 |S|r i?S r j=1 ||f ? (g(x i )) ?? i )|| 2 2 ,<label>(5)</label></formula><p>where? i is either the target or the pseudo-target of image x i . The objective is minimized via stochastic gradient descent. Note that unassigned images with low confidence are ignored and do not influence the optimization. As in <ref type="bibr" target="#b4">[5]</ref>, we implement f ? as a ConvNet and normalize its output such that ||f ? (x)|| 2 = 1.</p><p>To further enhance the representation capabilities of the model, which may in turn facilitate better clustering, we train the same model on an additional auxiliary task. Specifically, we employ the self-supervised task of predicting image rotations (RotNet) <ref type="bibr" target="#b14">[15]</ref>, as it has a proven record of efficiently improving ConvNets representations in a variety of tasks <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b13">14]</ref>. We do this by feeding the penultimate layer of f ? into another head, which is used to generate the rotation predictions for the RotNet task.</p><p>The full clustering algorithm is detailed below in Alg. 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Unsupervised Clustering</head><formula xml:id="formula_7">INPUT: X = {x i } n i=1</formula><p>-unlabeled dataset f ? -convnet with two heads and parameters ? K -number of clusters g -stochastic augmentation function ? i -learning rate at epoch i r -number of times g is applied to an image ? -ratio of dataset that will have targets ? -maximal distance to be considered confident</p><formula xml:id="formula_8">T ? [ ] for k=1 to K do initialize targets for i=1 to ? n K do append e k to T e k is the kth unit vector in R K end for end for ?i ? [?n] A(x i ) = T [i] initialize assignments for i=1...epochs do for j=1...iters do sample a batch ({x i } b i=1 , {t i } c i=1 ) b ? c compute P * with Eq. 4 ?i ? [c] A(x P * (i) ) = t i</formula><p>update assignments update the parameters with gradient step of Eq. 5: </p><formula xml:id="formula_9">? ? ? ? ? i ? ? L c end for for j=1...iters do sample a batch X b ?d ? {0 ? , 90 ? , 180 ? , 270 ? }, rotate X b d</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Semi-Supervised Classification</head><p>Semi-supervised classification is carried out in most of our experiments by adopting the FixMatch method, as it currently yields state-of-the-art results when relying on a small labeled sample. FixMatch combines two heuristics that are commonly used in SSL, consistency regularization and pseudo-labelling. These two heuristics are expressed as part of the loss function applied to unlabeled data during the training of a neural network, while labeled data is used to optimize the standard cross-entropy loss.</p><p>Formally, given a batch of b images X = {x 1 , . . . , x b } and their labels Y = {y 1 , . . . , y b }, and another batch of b unlabeled images U = {u 1 , . . . , u b }, FixMatch predicts the class distribution of the network's output on a weaklyaugmented expansion of the unlabeled batch, and uses these predictions as hard pseudo-labels for a strongly-augmented expansion of the same images. Thus, if we denote the network by f ? and the stochastic weak and strong augmentation functions by g and q respectively, the pseudo-label of image u i becomes y i = max(f ? (g(x i )), and the loss term on the unlabeled batch can be written as:</p><formula xml:id="formula_10">L u = 1 |{i ? [b ] | y i ? ? }| b i=1 1(y i ? ? )H(f ? (q(u i )), y i ).</formula><p>Above, H denotes the cross-entropy loss and ? denotes a hyper-parameter that determines the threshold confidence above which the image will be considered in the update of the network's parameters (similar to ? defined above). The loss on labeled data is simply:</p><formula xml:id="formula_11">L s = 1 b b i=1 H(f ? (g(x i )), y i ),<label>(6)</label></formula><p>and the total loss is a combination of them both: L s +? u L u , where ? u denotes a hyper-parameter balancing the weights of the two terms.</p><p>The weak augmentations used in the algorithm include the standard flip and shift transformations. First, the images are flipped horizontally with 50% probability, and then they are randomly translated by up to 12.5% vertically and horizontally. As strong augmentations, two variants of Au-toAugment <ref type="bibr" target="#b9">[10]</ref> are used, RandAugment <ref type="bibr" target="#b10">[11]</ref> and CTAugment <ref type="bibr" target="#b1">[2]</ref>. Both are followed by Cutout <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Integrated Method</head><p>The basic idea underlying our method is that if the number of labels is small, it benefits a classification algorithm to occasionally refrain from taking the labels into account. To achieve this goal, our method alternates traditional semisupervised training epochs with full epochs that optimize the unsupervised loss in (5) while ignoring the labels. This</p><formula xml:id="formula_12">Algorithm 2 Boosted SSL INPUT: U = {u i } n i=1 -unlabeled dataset (X, Y ) = {x i , y i } m i=1</formula><p>-labeled dataset SSL ALGO -some deep SSL algorithm C ALGO -our clustering algorithm from 1 f ? -convnet with two heads and parameters ? g -stochastic augmentation function ? i,j -learning rate at iteration i, epoch j r -number of times g is applied to an image ? -ratio of dataset that will have targets ? -maximal distance to be considered confident for i=1...iters do for j=1...e 1 do run SSL ALGO(X, Y, U, f ? ) for one epoch end for for j=1...e 2 do run C ALGO(U, c, f ? , g, ? i,j , r, ?, ?) for one epoch c is the number of classes end for end for design aims to learn meaningful features, which can compensate for the shortage of labels and help the model generalize better. As a result, the model is less susceptible to overfitting the few labeled datapoints, especially when they do not agree well with the total data distribution.</p><p>Specifically, we use the same network architecture and weights to solve the two different tasks described above jointly. To this end the algorithm alternates between Fix-Match epochs and clustering epochs. We also perform several RotNet warmup epochs, as this has proven useful for accelerating the learning.</p><p>Given the information propagated from the labels during the semi-supervised phase, clustering can be seen as a surprisingly easier task that attempts to separate the data without giving names to the different clusters thus created. Along the way, the mini-batch permutation optimization gives the network a chance to swiftly switch the targets of images whose confidence level is too low. Then, in the next supervised phase, the algorithm tries again to give those clusters names and refine the boundaries between them. This cycle is repeated until convergence.</p><p>Alg. 2 summarizes the method. We make the code available in the Supplementary Material. In the next section, we show its effectiveness in semi-supervised learning with a small labeled sample. In these experiments, the semisupervised step is realized with more out-of-the-box SSL algorithms for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We evaluated our method on three common SSL benchmarks, see <ref type="table">Table 1</ref>. Unless stated otherwise, the experiments were performed with FixMatch as the SSL module. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Details</head><p>In all of the experiments we used the WideResNet (WRN) architecture <ref type="bibr" target="#b31">[31]</ref>, replicating the setup described in <ref type="bibr" target="#b28">[28]</ref>. More specifically, for the CIFAR-10 and SVHN datasets we used WRN-28-2, and for STL-10 we used WRN-37-2. In the SSL phase, we kept the exact same hyper-parameters as in the original SSL algorithm being employed, while for the clustering phase, the learning rate and weight decay were reduced to 0.01 and 0.0001 respectively (from 0.03 and 0.0005 in FixMatch). The clustering hyper-parameter ? was set to 0.2, and the ? hyper-parameter was set to 1 for Cifar-10, and 0.6 for SVHN and STL-10. As in most other contemporary SSL methods, we stored and evaluated the model with exponential moving average of the weights over the training and a decay of 0.999.</p><p>Image augmentation: during the SSL phase, we took care to always apply the exact same augmentations as used in the original SSL method used to realize the SSL phase. Specifically in the experiments with FixMatch, we used Control Theory Augment <ref type="bibr" target="#b1">[2]</ref> that achieved the best results in most scenarios. In the unsupervised phase, we used the customary flip followed by crop, after the application of random color jitter to each pixel. We used the same flip and crop transformation in both phases: horizontal flip with probability 0.5, followed by cropping the mirror padded image to the original size.</p><p>Unless otherwise mentioned, we trained our model for 200 iterations, each comprising multiple passes over the data in the SSL phase (10 for Cifar-10 and 5 for all other datasets), followed by one pass in the clustering phase.</p><p>In all the experiments whose results are reported below, in order to ensure a fair comparison, we used the exact same partitions into labeled and unlabeled data as used in <ref type="bibr" target="#b28">[28]</ref>. Therefore, whenever we present results while replicating experiments reported in <ref type="bibr" target="#b28">[28]</ref>, we use the results reported there for all the methods but our own. When using different existing algorithms, we first made sure that our implementation of those methods yielded comparable results to those reported in the original manuscripts, in order to avoid running all the various experiments anew.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classification Results with FixMatch</head><p>In <ref type="table">Table 2</ref>, we report the results of our method when applied to the three datasets used in our study, with various amounts of labels. We ran the algorithm with 5 different partitions, the exact same partitions used in <ref type="bibr" target="#b28">[28]</ref>. Due to the large variance in the 40 labels setting, we repeated the experiment 3 times for each partition. Hence, the standard deviation reported in our results is the standard deviation (STD) of the means over the different partitions. As expected for such small partitions, it is rather large.</p><p>As can be seen in <ref type="table">Table 2</ref>, our method is very effective in the very small sample regime with 4 labels per class, where its relative advantage over the alternative methods is quite high. Its added value is less pronounced when using a total of 250 labels. Still, when learning to classify the more challenging STL-10 dataset with a setting identical to the one described in <ref type="bibr" target="#b28">[28]</ref>-we used the same 5 folds of 1000 labeled images each, and the additional 100K unlabeled imagesour method once again outperforms all the results reported in <ref type="bibr" target="#b28">[28]</ref>.</p><p>Finally, in order to push our method to its limit, we experimented with even fewer labels: 10, 20, 30, and also 100 -an intermediate number between 40 and 250. This very small sample regime is not systematically investigated in <ref type="bibr" target="#b28">[28]</ref>. The results for these experiments are presented in <ref type="figure" target="#fig_1">Fig. 2</ref>, as well as a detailed per-partition results for the 20-labels CIFAR-10 experiment in <ref type="figure" target="#fig_2">Fig. 3</ref>. Clearly, as long as the number of labeled points is smaller than 250, our method is quite beneficial.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clustering Accuracy Score</head><p>An interesting advantage of our method is demonstrated in <ref type="figure" target="#fig_4">Fig. 4</ref>. The accuracy shown there is the clustering accuracy score, which is traditionally computed as the classification accuracy of the best permutation of class labels, when uniquely matched with the different clusters. More precisely, if our test images and their corresponding labels are given by</p><formula xml:id="formula_13">({x i } m i=1 , {y i } m i=1 )</formula><p>, and the model's predictions are given by {? i } m i=1 , then the clustering accuracy score is defined as:</p><formula xml:id="formula_14">max P : [c]?[c] 1 m m i=1 1(y i = P (? i )),<label>(7)</label></formula><p>where P denotes a permutation over the c possible classes.</p><p>Note that while the classification accuracy for the experiments with 10 and 20 labels may seem low, the data is still clustered very well by our model. Even with one label per class, the model reaches a mean clustering accuracy of over 85%, and the best partition achieves mean accuracy of over 90%. At the same time, we see in <ref type="figure" target="#fig_1">Fig. 2</ref> that the mean classification accuracy is only 54.3%. The gap in accuracy may be large, but it resides solely in the naming of the clusters. Conversely, this cannot be said about the predictions obtained by FixMatch alone. There, the gap between classification accuracy and clustering accuracy is considerably smaller, which means that FixMatch doesn't succeed in separating the classes in the extreme small sample regime. With 100 labeled examples, the classification and clustering accuracy converge to the same value for both methods.</p><p>In <ref type="figure" target="#fig_5">Fig. 5</ref> we show two partitions from CIFAR-10, each with 10 labels. In one partition there is a big gap between classification accuracy and clustering accuracy, because the model confused the labels of 3 clusters as shown by the arrows. In the other partition, the model succeeded in finding the right permutation, and hence achieved 91% accuracy in both classification and clustering.</p><p>Bridging this gap between classification accuracy and clustering accuracy with so few labels is a hard problem. We investigated a few heuristics in order to identify "good" permutations during or after training, but more effort is needed. In <ref type="figure" target="#fig_7">Fig. 6</ref> we show the results when employing one such heuristic. After training is completed, we rotate the labeled images (in four orientations as in RotNet) and use the average prediction in order to find the k best permutations with Murty's algorithm <ref type="bibr" target="#b21">[22]</ref>. We use rotated images because the trained model is already (over-)fitted to the small labeled sample. Note that the permutation which achieves the best performance, and which defines the clustering accuracy, always lies within the 100 best permutations (out of 10! possible permutations) according to this score in the experiments with 20 and 30 labeled examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Running Time Comparison</head><p>Another advantage of our method is its efficiency with respect to running time. As mentioned in Section 4.1, the reported results are obtained after 200 iterations of our method. This implies 2000 passes through the whole data, plus another 200 passes for clustering and 200 passes for RotNet. In FixMatch, with randomly sampled batches, the total number of semi-supervised batches processed to achieve the published results approaches ?1M batches, while our method processes ?220K batches to achieve the results shown above. Even though each clustering epoch takes a bit longer than a FixMatch epoch, due to the expensive assignment problem, the total running time of our method adds up to roughly 30% of the running time needed by FixMatch when left on its own. Similar observations hold for the other SSL algorithms, which are compared with our method next.   <ref type="table">Table 2</ref>: Error rates for the 3 datasets used in our study: CIFAR-10, STL-10 and SVHN. Results are reported for varying amounts of labels, denoting the total number of labeled points from all classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other SSL algorithms</head><p>As explained in Section 3, our approach is general in the sense that it can use any clustering algorithm and any SSL method to address the challenging SSL problem of classification with small labeled sample. In this section we show that interlacing our proposed clustering method with two other successful SSL methods improves their outcome, in a similar way to the previous results with FixMatch. Thus, in <ref type="table" target="#tab_4">Table 3</ref> we show how our approach boosts the performance of MixMatch <ref type="bibr" target="#b2">[3]</ref> and UDA <ref type="bibr" target="#b29">[29]</ref>. These experiments were conducted on CIFAR-10 with 40 labels, using the same 5 partitions as in all the other experiments. Each partition was evaluated once. As can be seen, UDA combined with our clustering mechanism almost closes its initial gap against FixMatch, when both methods use RandAugment as the generator of strong augmentations (this was the augmen-tation used by the original method).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>We test the contribution of two major components of the proposed method: clustering and RotNet, using CIFAR-10 with 40 labeled examples. <ref type="table">Table 4</ref> summarizes the results.    As before, each of the 5 partitions used in the initial experiments is learned 3 times independently. We can see that  RotNet alone does not improve the results, nor does it degrade them. However, without RotNet the clustering phase is far less stable, with a detrimental effect on the final classification outcome. In both cases, we observed a much higher variance in performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Error Rate FixMatch 11.39 ? 3.35 FixMatch + RotNet 11.55 ? 2.98 FixMatch + Clustering 12.15 ? 3.08 Our Method 7.39 ? 0.61 <ref type="table">Table 4</ref>: Ablation study on CIFAR-10 with 40 labeled examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Summary and Discussion</head><p>Motivated by the desire to reduce the reliance on annotated data as much as possible, we propose a new approach to semi-supervised learning, which is designed to reduce overfit when very few labels are available. The proposed method alternates between an unsupervised clustering phase that ignores the labels in the training data, and a semi-supervised classification phase that makes full use of the training labels. To this end, we propose a new deep clustering algorithm. We then demonstrate the effectiveness of the general approach by plugging into it existing SSL algorithms, achieving significantly improved performance and reduced running time. When the recent FixMatch algorithm is plugged in as the SSL module, we improve stateof-the-art results on 3 benchmarks typically used to evaluate SSL algorithms. The proposed approach is general, in that both the SSL and the clustering modules can be replaced, although in this work we experimented with a single clustering method.</p><p>From a broader perspective, our approach can take advantage of curriculum learning <ref type="bibr" target="#b0">[1]</ref>, as one might look for means to schedule the supervised and unsupervised phases in a more sophisticated manner during training. It can also benefit from active learning <ref type="bibr" target="#b27">[27]</ref>, when seeking the best permutation between labels and clusters in the course of learning, which is especially tricky when the number of labeled points per class is very small. Under the active learning framework, where the learner can opt for a specific label of interest, we can adjust the permutation gradually by clustering the data first, subsequently asking the user to provide labels for each cluster's centroid. This way, in each round of communication the permutation can be tuned with less than one additional label per class, as only labels from uncertain clusters will be requested.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Classification accuracy, comparing our method to FixMatch with CTA, using identical protocols. Left: CIFAR-10, right: SVHN. The numbers inside the columns denote the mean accuracy across different partitions and runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The classification accuracy for CIFAR-10 with 20 labels (2 per class), presented separately for each partition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Clustering accuracy for the same experiment, the results of which are reported inFig. 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Two different partitions of CIFAR-10 with one label per class are shown above. Given the top partition, our model found the wrong permutation as illustrated with blue arrows. This error led to the gap between classification accuracy of 67.6% and clustering accuracy of 92.5%. Given the bottom partition, our model found the optimal permutation and achieved 91.0% accuracy in both classification and clustering.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Top-k classification accuracy for CIFAR-10 with 10, 20 and 30 labels. k denotes the number of permutations considered.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>MixMatch 47.54 ? 11.50 11.05 ? 0.86 10.41 ? 0.61 42.55 ? 14.53 3.98 ? 0.23</figDesc><table><row><cell></cell><cell cols="2">CIFAR-10</cell><cell>STL-10</cell><cell cols="2">SVHN</cell></row><row><cell>Method</cell><cell>40 labels</cell><cell>250 labels</cell><cell>1000 labels</cell><cell>40 labels</cell><cell>250 labels</cell></row><row><cell>?-Model</cell><cell>-</cell><cell cols="2">54.26 ? 3.97 26.23 ? 0.82</cell><cell>-</cell><cell>18.96 ? 1.92</cell></row><row><cell>Pseudo-Labeling</cell><cell>-</cell><cell cols="2">49.78 ? 0.43 27.99 ? 0.80</cell><cell>-</cell><cell>20.21 ? 1.09</cell></row><row><cell>Mean Teacher</cell><cell>-</cell><cell cols="2">32.32 ? 2.30 21.43 ? 2.39</cell><cell>-</cell><cell>3.57 ? 0.11</cell></row><row><cell>UDA</cell><cell>29.05 ? 5.93</cell><cell>8.82 ? 1.08</cell><cell cols="3">7.66 ? 0.56 52.63 ? 20.51 5.69 ? 2.76</cell></row><row><cell>ReMixMatch</cell><cell>19.10 ? 9.64</cell><cell>5.44 ? 0.05</cell><cell>5.23 ? 0.45</cell><cell>3.34 ? 0.20</cell><cell>2.92 ? 0.48</cell></row><row><cell>FixMatch (RA)</cell><cell>13.81 ? 3.37</cell><cell>5.07 ? 0.65</cell><cell>7.98 ? 1.50</cell><cell>3.96 ? 2.17</cell><cell>2.48 ? 0.38</cell></row><row><cell>FixMatch (CTA)</cell><cell>11.39 ? 3.35</cell><cell>5.07 ? 0.33</cell><cell>5.17 ? 0.63</cell><cell>7.65 ? 7.65</cell><cell>2.64 ? 0.64</cell></row><row><cell>Ours</cell><cell>7.39 ? 0.61</cell><cell>5.51 ? 0.25</cell><cell>4.78 ? 0.29</cell><cell>3.09 ? 0.54</cell><cell>2.30 ? 0.03</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Error rates of MixMatch (top) and UDA (bottom), with and without clustering, trained on CIFAR-10 with 40 labeled examples.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?r?me</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual international conference on machine learning</title>
		<meeting>the 26th annual international conference on machine learning</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Remixmatch: Semi-supervised learning with distribution alignment and augmentation anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09785</idno>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Unsupervised learning by predicting noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05310</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Shiming Xiang, and Chunhong Pan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaofeng</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5880" to="5888" />
		</imprint>
	</monogr>
	<note>Deep adaptive image clustering</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schlkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Zien</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
	<note>1st edition</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Self-supervised gans via auxiliary rotation loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics</title>
		<meeting>the fourteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Autoaugment: Learning augmentation strategies from data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1422" to="1430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Boosting few-shot visual learning with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8059" to="8068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.07728</idno>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jo?o</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9865" to="9874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An efficient k-means clustering algorithm: Analysis and implementation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapas</forename><surname>Kanungo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mount</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><forename type="middle">D</forename><surname>Netanyahu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruth</forename><surname>Piatko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><forename type="middle">Y</forename><surname>Silverman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="881" to="892" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harold W Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Naval Research Logistics (NRL)</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="21" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Letter to the editor-an algorithm for ranking all the assignments in order of increasing cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Katta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Operations research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="682" to="687" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with scarce annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastien</forename><surname>Sylvestre-Alvise Rebuffi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Ehrhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="762" to="763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semi-supervised deep embedded clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhou</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kangrong</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyi</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zenglin</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">325</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="130" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Active learning literature survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Burr</forename><surname>Settles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison Department of Computer Sciences</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semisupervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12848</idno>
		<title level="m">Unsupervised data augmentation for consistency training</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5147" to="5156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Wide residual networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">S4l: Self-supervised semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avital</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="1476" to="1485" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
