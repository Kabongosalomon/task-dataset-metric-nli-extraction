<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Under review as a conference paper at ICLR 2017 LEARNING TO DRAW SAMPLES: WITH APPLICATION TO AMORTIZED MLE FOR GENERATIVE ADVERSAR- IAL LEARNING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilin</forename><surname>Wang</surname></persName>
							<email>dilin.wang.gr@dartmouth.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Dartmouth College</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
							<email>qiang.liu@dartmouth.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Dartmouth College</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Under review as a conference paper at ICLR 2017 LEARNING TO DRAW SAMPLES: WITH APPLICATION TO AMORTIZED MLE FOR GENERATIVE ADVERSAR- IAL LEARNING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a simple algorithm to train stochastic neural networks to draw samples from given target distributions for probabilistic inference. Our method is based on iteratively adjusting the neural network parameters so that the output changes along a Stein variational gradient (Liu &amp; Wang, 2016) that maximumly decreases the KL divergence with the target distribution. Our method works for any target distribution specified by their unnormalized density function, and can train any black-box architectures that are differentiable in terms of the parameters we want to adapt. As an application of our method, we propose an amortized MLE algorithm for training deep energy model, where a neural sampler is adaptively trained to approximate the likelihood function. Our method mimics an adversarial game between the deep energy model and the neural sampler, and obtains realisticlooking images competitive with the state-of-the-art results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Modern machine learning increasingly relies on highly complex probabilistic models to reason about uncertainty. A key computational challenge is to develop efficient inference techniques to approximate, or draw samples from complex distributions. Currently, most inference methods, including MCMC and variational inference, are hand-designed by researchers or domain experts. This makes it difficult to fully optimize the choice of different methods and their parameters, and exploit the structures in the problems of interest in an automatic way. The hand-designed algorithm can also be inefficient when it requires to make fast inference repeatedly on a large number of different distributions with similar structures. This happens, for example, when we need to reason about a number of observed datasets in settings like online learning, or need fast inference as inner loops for other algorithms such as maximum likelihood training. Therefore, it is highly desirable to develop more intelligent probabilistic inference systems that can adaptively improve its own performance to fully the optimize computational efficiency, and generalize to new tasks with similar structures. Specifically, denote by p(x) a probability density of interest specified up to the normalization constant, which we want to draw sample from, or marginalize to estimate its normalization constant. We want to study the following problem:</p><p>Problem 1. Given a distribution with density p(x) and a function f (?; ?) with parameter ? and random input ?, for which we only have assess to draws of the random input ? (without knowing its true distribution q 0 ), and the output values of f (?; ?) and its derivative ? ? f (?; ?) given ? and ?. We want to find an optimal parameter ? so that the density of the random output variable x = f (?; ?) with ? ? q 0 closely matches the target density p(x).</p><p>Because we have no assumption on the structure of f (?; ?) and the distribution of random input, we can not directly calculate the actual distribution of the output random variable x = f (?; ?); this 1 arXiv:1611.01722v2 <ref type="bibr">[stat.ML] 26 Nov 2016</ref> Under review as a conference paper at ICLR 2017 makes it difficult to solve Problem 1 using the traditional variational inference (VI) methods. Recall that traditional VI approximates p(x) using simple proposal distributions q ? (x) indexed by parameter ?, and finds the optimal ? by minimizing KL divergence KL(q ? || p) = E q? [log(q ? /p)], which requires to calculate the density q ? (x) or its derivative that is not computable by our assumption (even when the Monte Carlo gradient estimation and the reparametrization trick <ref type="bibr" target="#b15">(Kingma &amp; Welling, 2013)</ref> are applied).</p><p>In fact, it is this requirement of calculating q ? (x) that has been the major constraint for the designing of state-of-the-art variational inference methods with rich approximation families; the recent successful algorithms (e.g., <ref type="bibr" target="#b33">Rezende &amp; Mohamed, 2015b;</ref><ref type="bibr" target="#b37">Tran et al., 2015;</ref><ref type="bibr" target="#b31">Ranganath et al., 2015</ref>, to name only a few) have to handcraft special variational families to ensure the computational tractability of q ? (x) and simultaneously obtain high approximation accuracy, which require substantial mathematical insights and research effects. Methods that do not require to explicitly calculate q ? (x) can significantly simplify the design and applications of VI methods, allowing practical users to focus more on choosing proposals that work best with their specific tasks. We will use the term wild variational inference to refer to new variants of variational methods that require no tractability q ? (x), to distinguish with the black-box variational inference <ref type="bibr" target="#b30">(Ranganath et al., 2014)</ref> which refers to methods that work for generic target distributions p(x) without significant model-by-model consideration (but still require to calculate the proposal density q ? (x)).</p><p>A similar problem also appears in importance sampling (IS), where it requires to calculate the IS proposal density q(x) in order to calculate the importance weight w(x) = p(x)/q(x). However, there exist methods that use no explicit information of q(x), which, seemingly counter-intuitively, give better asymptotic variance or converge rates than the typical IS that uses the proposal information (e.g., <ref type="bibr" target="#b2">Briol et al., 2015;</ref><ref type="bibr" target="#b11">Henmi et al., 2007;</ref><ref type="bibr" target="#b5">Delyon &amp; Portier, 2014)</ref>. Discussions on this phenomenon dates back to <ref type="bibr" target="#b25">O'Hagan (1987)</ref>, who argued that "Monte Carlo (that uses the proposal information) is fundamentally unsound" for violating the Likelihood Principle, and developed Bayesian Monte Carlo <ref type="bibr" target="#b26">(O'Hagan, 1991)</ref> as an example that uses no information on q(x), yet gives better convergence rate than the typical Monte Carlo O(n ?1/2 ) rate <ref type="bibr" target="#b2">(Briol et al., 2015)</ref>. Despite the substantial difference between IS and VI, these results intuitively suggest the possibility of developing efficient variational inference without calculating q(x) explicitly.</p><p>In this work, we propose a simple algorithm for Problem 1 by iteratively adjusting the network parameter ? to make its output random variable changes along a Stein variational gradient direction (SVGD) <ref type="bibr" target="#b19">(Liu &amp; Wang, 2016</ref>) that optimally decreases its KL divergence with the target distribution. Critically, the SVGD gradient includes a repulsive term to ensure that the generated samples have the right amount of variability that matches p(x). In this way, we "amortize SVGD" using a neural network, which makes it possible for our method to adaptively improve its own efficiency by leveraging fast experience, especially in cases when it needs to perform fast inference repeatedly on a large number of similar tasks. As an application, we use our method to amortize the MLE training of deep energy models, where a neural sampler is adaptively trained to approximate the likelihood function. Our method, which we call SteinGAN, mimics an adversarial game between the energy model and the neural sampler, and obtains realistic-looking images competitive with the state-of-the-art results produced by generative adversarial networks (GAN) <ref type="bibr" target="#b9">(Goodfellow et al., 2014;</ref><ref type="bibr" target="#b28">Radford et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related Work</head><p>The idea of amortized inference <ref type="bibr" target="#b7">(Gershman &amp; Goodman, 2014)</ref> has been recently applied in various domains of probabilistic reasoning, including both amortized variational inference (e.g., <ref type="bibr" target="#b15">Kingma &amp; Welling, 2013;</ref><ref type="bibr" target="#b32">Rezende &amp; Mohamed, 2015a)</ref>, and data-driven proposals for (sequential) Monte Carlo methods (e.g., <ref type="bibr" target="#b27">Paige &amp; Wood, 2016)</ref>, to name only a few. Most of these methods, however, require to explicitly calculate q(x) (or its gradient). One exception is a very recent paper <ref type="bibr" target="#b29">(Ranganath et al., 2016)</ref> that avoids calculating q(x) using an idea related to Stein discrepancy <ref type="bibr" target="#b10">(Gorham &amp; Mackey, 2015;</ref><ref type="bibr" target="#b24">Oates et al., 2014;</ref><ref type="bibr" target="#b3">Chwialkowski et al., 2016)</ref>. There is also a raising interest recently on a similar problem of "learning to optimize" (e.g., <ref type="bibr" target="#b0">Andrychowicz et al., 2016;</ref><ref type="bibr" target="#b4">Daniel et al., 2016;</ref><ref type="bibr" target="#b16">Li &amp; Malik, 2016)</ref>, which is technically easier than the more general problem of "learning to sample". In fact, we show that our algorithm reduces to "learning to optimize" when only one particle is used in SVGD.</p><p>Generative adversarial network (GAN) and its variants have recently gained remarkable success on generating realistic-looking images <ref type="bibr" target="#b9">(Goodfellow et al., 2014;</ref><ref type="bibr" target="#b34">Salimans et al., 2016;</ref><ref type="bibr" target="#b28">Radford et al., 2015;</ref><ref type="bibr" target="#b17">Li et al., 2015;</ref><ref type="bibr" target="#b6">Dziugaite et al., 2015;</ref><ref type="bibr" target="#b23">Nowozin et al., 2016)</ref>. All these methods are set up to train latent variable models (the generator) under the assistant of the discriminator. Our SteinGAN instead performs traditional MLE training for a deep energy model, with the help of a neural sampler that learns to draw samples from the energy model to approximate the likelihood function; this admits an adversarial interpretation: we can view the neural sampler as a generator that attends to fool the deep energy model, which in turn serves as a discriminator that distinguishes the real samples and the simulated samples given by the neural sampler. This idea of training MLE with neural samplers was first discussed by <ref type="bibr" target="#b13">Kim &amp; Bengio (2016)</ref>; one of the key differences is that the neural sampler in <ref type="bibr" target="#b13">Kim &amp; Bengio (2016)</ref> is trained with the help of a heuristic diversity regularizer based on batch normalization, while SVGD enforces the diversity in a more principled way. Another method by <ref type="bibr" target="#b40">Zhao et al. (2016)</ref> also trains an energy score to distinguish real and simulated samples, but within a non-probabilistic framework (see Section 5 for more discussion). Other more traditional approaches for training energy-based models (e.g., <ref type="bibr" target="#b22">Ngiam et al., 2011;</ref><ref type="bibr" target="#b38">Xie et al., 2016)</ref> are often based on variants of MCMC-MLE or contrastive divergence <ref type="bibr" target="#b8">(Geyer, 1991;</ref><ref type="bibr" target="#b12">Hinton, 2002;</ref><ref type="bibr" target="#b36">Tieleman, 2008)</ref>, and have difficulty generating realistic-looking images from scratch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">STEIN VARIATIONAL GRADIENT DESCENT (SVGD)</head><p>Stein variational gradient descent (SVGD) <ref type="bibr" target="#b19">(Liu &amp; Wang, 2016</ref>) is a general purpose Bayesian inference algorithm motivated by Stein's method <ref type="bibr" target="#b35">(Stein, 1972;</ref><ref type="bibr" target="#b1">Barbour &amp; Chen, 2005</ref>) and kernelized Stein discrepancy <ref type="bibr" target="#b3">Chwialkowski et al., 2016;</ref><ref type="bibr" target="#b24">Oates et al., 2014)</ref>. It uses an efficient deterministic gradient-based update to iteratively evolve a set of particles {x i } n i=1 to minimize the KL divergence with the target distribution. SVGD has a simple form that reduces to the typical gradient descent for maximizing log p when using only one particle (n = 1), and hence can be easily combined with the successful tricks for gradient optimization, including stochastic gradient, adaptive learning rates (such as adagrad), and momentum.</p><p>To give a quick overview of the main idea of SVGD, let p(x) be a positive density function on R d which we want to approximate with a set of particles {x i } n i=1 . SVGD initializes the particles by sampling from some simple distribution q 0 , and updates the particles iteratively by</p><formula xml:id="formula_0">x i ? x i + ?(x i ), ?i = 1, . . . , n,<label>(1)</label></formula><p>where is a step size, and ?(x) is a "particle gradient direction" chosen to maximumly decrease the KL divergence between the distribution of particles and the target distribution, in the sense that</p><formula xml:id="formula_1">? = arg max ??F ? d d KL(q [ ?] || p) =0 ,<label>(2)</label></formula><p>where q <ref type="bibr">[ ?]</ref> denotes the density of the updated particle x = x + ?(x) when the density of the original particle x is q, and F is the set of perturbation directions that we optimize over. We choose F to be the unit ball of a vector-valued reproducing kernel Hilbert space (RKHS) H d = H ? ? ? ? ? H with each H associating with a positive definite kernel k(x, x ); note that H is dense in the space of continuous functions with universal kernels such as the Gaussian RBF kernel.</p><p>Critically, the gradient of KL divergence in (2) equals a simple linear functional of ?, allowing us to obtain a closed form solution for the optimal ?. <ref type="bibr" target="#b19">Liu &amp; Wang (2016)</ref> showed that</p><formula xml:id="formula_2">? d d KL(q [ ?] || p) =0 = E x?q [T p ?(x)],<label>(3)</label></formula><formula xml:id="formula_3">with T p ?(x) = ? x log p(x) ?(x) + ? x ? ?(x),<label>(4)</label></formula><p>Algorithm 1 Amortized SVGD for Problem 1 Set batch size m, step-size scheme { t } and kernel k(x, x ). Initialize ? 0 .</p><formula xml:id="formula_4">for iteration t do Draw random {? i } m i=1 , calculate x i = f (? t ; ? i )</formula><p>, and the Stein variational gradient ?x i in <ref type="formula" target="#formula_8">(7)</ref>. Update parameter ? using (8), (9) or (10). end for where T p is considered as a linear operator acting on function ? and is called the Stein operator in connection with Stein's identity which shows that the RHS of (3) equals zero if p = q:</p><formula xml:id="formula_5">E p [T p ?] = E p [? x log p ? + ? x ? ?] = 0.<label>(5)</label></formula><p>This is a result of integration by parts assuming the value of p(x)?(x) vanishes on the boundary of the integration domain.</p><p>Therefore, the optimization in (2) reduces to</p><formula xml:id="formula_6">D(q || p) def = max ??H d {E x?q [T p ?(x)] s.t. ||?|| H d ? 1},<label>(6)</label></formula><p>where D(q || p) is the kernelized Stein discrepancy defined in , which equals zero if and only if p = q under mild regularity conditions. Importantly, the optimal solution of (6) yields a closed form</p><formula xml:id="formula_7">? * (x ) ? E x?q [? x log p(x)k(x, x ) + ? x k(x, x )].</formula><p>By approximating the expectation under q with the empirical average of the current particles {x i } n i=1 , SVGD admits a simple form of update:</p><formula xml:id="formula_8">x i ? x i + ?x i , ?i = 1, . . . , n, where ?x i =? x?{xi} n i=1 [? x log p(x)k(x, x i ) + ? x k(x, x i )],<label>(7)</label></formula><p>and? x?{xi} n i=1 [f (x)] = i f (x i )/n. The two terms in ?x i play two different roles: the term with the gradient ? x log p(x) drives the particles toward the high probability regions of p(x), while the term with ? x k(x, x i ) serves as a repulsive force to encourage diversity; to see this, consider a stationary kernel k(x, x ) = k(x ? x ), then the second term reduces to? x ? x k(x, x i ) = ?? x ? xi k(x, x i ), which can be treated as the negative gradient for minimizing the average similarity? x k(x, x i ) in terms of x i . Overall, this particle update produces diverse points for distributional approximation and uncertainty assessment, and also has an interesting "momentum" effect in which the particles move collaboratively to escape the local optima.</p><p>It is easy to see from <ref type="formula" target="#formula_8">(7)</ref> that ?x i reduces to the typical gradient ? x log p(x i ) when there is only a single particle (n = 1) and ? x k(x, x i ) when x = x i , in which case SVGD reduces to the standard gradient ascent for maximizing log p(x) (i.e., maximum a posteriori (MAP)).</p><p>3 AMORTIZED SVGD: TOWARDS AN AUTOMATIC NEURAL SAMPLER SVGD and other particle-based methods become inefficient when we need to repeatedly infer a large number different target distributions for multiple tasks, including online learning or inner loops of other algorithms, because they can not improve based on the experience from the past tasks, and may require a large memory to restore a large number of particles. We propose to "amortize SVGD" by training a neural network f (?; ?) to mimic the SVGD dynamics, yielding a solution for Problem 1.</p><p>One straightforward way to achieve this is to run SVGD to convergence and train f (?; ?) to fit the SVGD results. This, however, requires to run many epochs of fully converged SVGD and can be slow in practice. We instead propose an incremental approach in which ? is iteratively adjusted so that the network outputs x = f (?; ?) changes along the Stein variational gradient direction in <ref type="formula" target="#formula_8">(7)</ref> in order to decrease the KL divergence between the target and approximation distribution.</p><p>To be specific, denote by ? t the estimated parameter at the t-th iteration of our method; each iteration of our method draws a batch of random inputs {? i } m i=1 and calculate their corresponding output x i = f (?; ? i ) based on ? t ; here m is a mini-batch size (e.g., m = 100). The Stein variational gradient ?x i in (7) would then ensure that x i = x i + ?x i forms a better approximation of the target distribution p. Therefore, we should adjust ? to make its output matches {x i }, that is, we want to update ? by</p><formula xml:id="formula_9">? t+1 ? arg min ? m i=1 ||f (?; ? i ) ? x i || 2 2 , where x i = x i + ?x i .<label>(8)</label></formula><p>See Algorithm 1 for the summary of this procedure. If we assume is very small, then (8) reduces to a least square optimization. To see this, note that f (?;</p><formula xml:id="formula_10">? i ) ? f (? t ; ? i ) + ? ? f (? t ; ? i )(? ? ? t ) by Taylor expansion. Since x i = f (? t ; ? i ), we have ||f (?; ? i ) ? x i || 2 2 ? ||? ? f (? t ; ? i )(? ? ? t ) ? ?x i || 2 2 .</formula><p>As a result, (8) reduces to the following least square optimization:</p><formula xml:id="formula_11">? t+1 ? ? t + ?? t , where ?? t = arg min ? m i=1 ||? ? f (? t ; ? i )? ? ?x i || 2 2 .<label>(9)</label></formula><p>Update <ref type="formula" target="#formula_11">(9)</ref> can still be computationally expensive because of the matrix inversion. We can derive a further approximation by performing only one step of gradient descent of (8) (or <ref type="formula" target="#formula_11">(9)</ref>), which gives</p><formula xml:id="formula_12">? t+1 ? ? t + m i=1 ? ? f (? t ; ? i )?x i .<label>(10)</label></formula><p>Although update <ref type="formula" target="#formula_0">(10)</ref> is derived as an approximation of (8)-(9), it is computationally faster and we find it works very effectively in practice; this is because when is small, one step of gradient update can be sufficiently close to the optimum.</p><p>Update (10) also has a simple and intuitive form: (10) can be thought as a "chain rule" that backpropagates the Stein variational gradient to the network parameter ?. This can be justified by considering the special case when we use only a single particle (n = 1) in which case ?x i in (7) reduces to the typical gradient ? x log p(x i ) of log p(x), and update (10) reduces to the typical gradient ascent for maximizing</p><formula xml:id="formula_13">E ? [log p(f (?; ?))],</formula><p>in which case f (?; ?) is trained to maximize log p(x) (that is, learning to optimize), instead of learning to draw samples from p for which it is crucial to use Stein variational gradient ?x i to diversify the network outputs.</p><p>Update (10) also has a close connection with the typical variational inference with the reparameterization trick <ref type="bibr" target="#b15">(Kingma &amp; Welling, 2013)</ref>. Let q ? (x) be the density function of x = f (?; ?), ? ? q 0 . Using the reparameterization trick, the gradient of KL(q ? || p) w.r.t. ? can be shown to be</p><formula xml:id="formula_14">? ? KL(q ? || p) = ?E ??q0 [? ? f (?; ?)(? x log p(x) ? ? x log q ? (x))].</formula><p>With {? i } i.i.d. drawn from q 0 and x i = f (?; ? i ), ?i, the standard stochastic gradient descent for minimizing the KL divergence is</p><formula xml:id="formula_15">? t+1 ? ? t + i ? ? f (? t ; ? i )?x i , where?x i = ? x log p(x i ) ? ? x log q ? (x i ).<label>(11)</label></formula><p>This is similar with (10), but replaces the Stein gradient ?x i defined in (7) with?x i . The advantage of using ?x i is that it does not require to explicitly calculate q ? , and hence admits a solution to Problem 1 in which q ? is not computable for complex network f (?; ?) and unknown input distribution q 0 . Further insights can be obtained by noting that</p><formula xml:id="formula_16">?x i ? E x?q [? x log p(x)k(x, x i ) + ? x k(x, x i )] = E x?q [(? x log p(x) ? ? x log q(x))k(x, x i )] (12) = E x?q [(?x)k(x, x i )],</formula><p>where <ref type="formula" target="#formula_0">(12)</ref> is obtained by using Stein's identity (5). Therefore, ?x i can be treated as a kernel smoothed version of?x i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">AMORTIZED MLE FOR GENERATIVE ADVERSARIAL TRAINING</head><p>Our method allows us to design efficient approximate sampling methods adaptively and automatically, and enables a host of novel applications. In this paper, we apply it in an amortized MLE method for training deep generative models.</p><p>Maximum likelihood estimator (MLE) provides a fundamental approach for learning probabilistic models from data, but can be computationally prohibitive on distributions for which drawing samples or computing likelihood is intractable due to the normalization constant. Traditional methods such as MCMC-MLE use hand-designed methods (e.g., MCMC) to approximate the intractable likelihood function but do not work efficiently in practice. We propose to adaptively train a generative neural network to draw samples from the distribution during MLE training, which not only provides computational advantage, and also allows us to generate realistic-looking images competitive with, or better than the state-of-the-art generative adversarial networks (GAN) <ref type="bibr" target="#b9">(Goodfellow et al., 2014;</ref><ref type="bibr" target="#b28">Radford et al., 2015)</ref> (see <ref type="figure">Figure 1</ref>-5).</p><p>To be specific, denote by {x i,obs } a set of observed data. We consider the maximum likelihood training of energy-based models of form</p><formula xml:id="formula_17">p(x|?) = exp(??(x, ?) ? ?(?)), ?(?) = log exp(??(x, ?))dx,</formula><p>where ?(x; ?) is an energy function for x indexed by parameter ? and ?(?) is the log-normalization constant. The log-likelihood function of ? is</p><formula xml:id="formula_18">L(?) = 1 n n i=1</formula><p>log p(x i,obs |?), whose gradient is </p><formula xml:id="formula_19">? ? L(?) = ?? obs [? ? ?(x; ?)] + E ? [? ? ?(x; ?)],<label>where?</label></formula><formula xml:id="formula_20">? ? ? + ? ? L(?),? ? L(?) = ?? obs [? ? ?(x; ?)] +? ? [? ? ?(x; ?)],<label>(13)</label></formula><p>where? ? denotes the empirical average on {x i } where x i = f (?; ? i ), {? i } ? q 0 . As ? is updated by gradient ascent, ? is successively updated via Algorithm 1 to follow p(x|?). See Algorithm 2.</p><p>We call our method SteinGAN, because it can be intuitively interpreted as an adversarial game between the generative network f (?; ?) and the energy model p(x|?) which serves as a discriminator: The Algorithm 2 Amortized MLE as Generative Adversarial Learning Goal: MLE training for energy model p(x|?) = exp(??(x, ?) ? ?(?)). Initialize ? and ?. for iteration t do Updating ?: Draw ? i ? q 0 , x i = f (?; ? i ); update ? using (8), (9) or (10) with p(x) = p(x|?).</p><p>Repeat several times when needed.</p><p>Updating ?: Draw a mini-batch of observed data {x i,obs }, and simulated data x i = f (?; ? i ), update ? by (13). end for MLE gradient update of p(x|?) effectively decreases the energy of the training data and increases the energy of the simulated data from f (?; ?), while the SVGD update of f (?; ?) decreases the energy of the simulated data to fit better with p(x|?). Compared with the traditional methods based on MCMC-MLE or contrastive divergence, we amortize the sampler as we train, which gives much faster speed and simultaneously provides a high quality generative neural network that can generate realistic-looking images; see <ref type="bibr" target="#b13">Kim &amp; Bengio (2016)</ref> for a similar idea and discussions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EMPIRICAL RESULTS</head><p>We evaluated our SteinGAN on four datasets, MNIST, CIFAR-10, CelebA <ref type="bibr" target="#b21">(Liu et al., 2015)</ref>, and Large-scale Scene Understanding (LSUN) <ref type="bibr" target="#b39">(Yu et al., 2015)</ref>, on which we find our method tends to generate realistic-looking images competitive with, sometimes better than DCGAN <ref type="bibr" target="#b28">(Radford et al., 2015)</ref> (see <ref type="figure">Figure 2 -Figure 3</ref>). Our code is available at https://github.com/DartML/ SteinGAN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Setup</head><p>In order to generate realistic-looking images, we define our energy model based on an autoencoder:</p><formula xml:id="formula_21">p(x|?) ? exp(?||x ? D(E(x; ?); ?)||),<label>(14)</label></formula><p>where x denotes the image. This choice is motivated by Energy-based GAN <ref type="bibr" target="#b40">(Zhao et al., 2016)</ref> in which the autoencoder loss is used as a discriminator but without a probabilistic interpretation. We assume f (?; ?) to be a neural network whose input ? is a 100-dimensional random vector drawn by Uniform([?1, 1]). The positive definite kernel in SVGD is defined by the RBF kernel on the hidden representation obtained by the autoencoder in <ref type="formula" target="#formula_0">(14)</ref>, that is,</p><formula xml:id="formula_22">k(x, x ) = exp(? 1 h 2 ||E(x; ?) ? E(x ; ?)|| 2 )</formula><p>. As it is discussed in Section 3, the kernel provides a repulsive force to produce an amount of variability required for generating samples from p(x). This is similar to the heuristic repelling regularizer in <ref type="bibr" target="#b40">Zhao et al. (2016)</ref> and the batch normalization based regularizer in <ref type="bibr" target="#b13">Kim &amp; Bengio (2016)</ref>, but is derived in a more principled way. We take the bandwidth to be h = 0.5 ? med, where med is the median of the pairwise distances between E(x) on the image simulated by f (?; ?). This makes the kernel change adaptively based on both ? (through E(x; ?)) and ? (through bandwidth h).</p><p>Some datasets include both images x and their associated discrete labels y. In these cases, we train a joint energy model on (x, y) to capture both the inner structure of the images and its predictive relation with the label, allowing us to simulate images with a control on which category it belongs to. Our joint energy model is defined to be</p><formula xml:id="formula_23">p(x, y|?) ? exp ? ||x ? D(E(x; ?); ?)|| ? max[m, ?(y, E(x; ?))] ,<label>(15)</label></formula><p>where ?(?, ?) is the cross entropy loss function of a fully connected output layer. In this case, our neural sampler first draws a label y randomly according to the empirical counts in the dataset, and then passes y into a neural network together with a 100 ? 1 random vector ? to generate image x. This allows us to generate images for particular categories by controlling the value of input y.</p><p>Stabilization In practice, we find it is useful to modify (13) to be</p><formula xml:id="formula_24">? ? ? ? ? obs [? ? ?(x, ?)] + (1 ? ?)? ? [? ? ?(x, ?)].<label>(16)</label></formula><p>where ? is a discount factor (which we take to be ? = 0.7). This is equivalent to maximizing a regularized likelihood: max</p><formula xml:id="formula_25">? {log p(x|?) + ??(?)}</formula><p>where ?(?) is the log-partition function; note that exp(??(?)) is a conjugate prior of p(x|?).</p><p>We initialize the weights of both the generator and discriminator from Gaussian distribution N (0, 0.02), and train them using Adam <ref type="bibr" target="#b14">(Kingma &amp; Ba, 2014)</ref> with a learning rate of 0.001 for the generator and 0.0001 for the energy model (the discriminator). In order to keep the generator and discriminator approximately aligned during training, we speed up the MLE update (16) of the discriminator (by increasing its learning rate to 0.0005) when the energy of the real data batch is larger than the energy of the simulated images, while slow down it (by freezing the MLE update of ? in <ref type="formula" target="#formula_0">(16)</ref>) if the magnitude of the energy difference between the real images and the simulated images goes above a threshold of 0.5. We used the bag of architecture guidelines for stable training suggested in DCGAN <ref type="bibr" target="#b28">(Radford et al., 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The MNIST dataset has a training set of 60, 000 examples. Both DCGAN and our model produce high quality images, both visually indistinguishable from real images; see figure 1.</p><p>CIFAR-10 is very diverse, and with only 50,000 training examples. <ref type="figure">Figure 2</ref> shows examples of simulated images by DCGAN and SteinGAN generated conditional on each category, which look equally well visually. We also provide quantitively evaluation using a recently proposed inception score <ref type="bibr" target="#b34">(Salimans et al., 2016)</ref>, as well as the classification accuracy when training ResNet using 50, 000 simulated images as train sets, evaluated on a separate held-out testing set never seen by the GAN models. Besides DCGAN and SteinGAN, we also evaluate another simple baseline obtained by subsampling 500 real images from the training set and duplicating them 100 times. We observe that these scores capture rather different perspectives of image generation: The inception score favors images that look realistic individually and have uniformly distributed labels; as a result, the inception score of the duplicated 500 images is almost as high as the real training set. We find that the inception score of SteinGAN is comparable, or slightly lower than that of DCGAN. On the other hand, the classification accuracy measures the amount information captured in the simulated image sets; we find that SteinGAN achieves the highest classification accuracy, suggesting that it captures more information in the training set. <ref type="figure">Figure 3</ref> and 4 visualize the results on CelebA (with more than 200k face images) and LSUN (with nearly 3M bedroom images), respectively. We cropped and resized both dataset images into 64 ? 64.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DCGAN SteinGAN</head><p>Figure 1: MNIST images generated by DCGAN and our SteinGAN. We use the joint model in <ref type="formula" target="#formula_0">(15)</ref> to allow us to generate images for each digit. We set m = 0.2.  <ref type="formula" target="#formula_0">(15)</ref>) conditional on each category. Middle: inception scores for samples generated by various methods (all with 50,000 images) on inception models trained on ImageNet and CIFAR-10, respectively. Lower: testing accuracy on real testing set when using 50,000 simulated images to train ResNets for classification. SteinGAN achieves higher testing accuracy than DCGAN. We set m = 1 and ? = 0.8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We propose a new method to train neural samplers for given distributions, together with a new SteinGAN method for generative adversarial training. Future directions involve more applications and theoretical understandings for training neural samplers.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DCGAN SteinGAN</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Results on CelebA. Upper: images generated by DCGAN and our SteinGAN. Lower: images generated by SteinGAN when performing a random walk ? ? ? + 0.01 ? Uniform([?1, 1]) on the random input ?; we can see that a man with glasses and black hair gradually changes to a woman with blonde hair. SeeFigure 5for more examples.DCGANSteinGAN Images generated by DCGAN and our SteinGAN on LSUN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 :</head><label>5</label><figDesc>More images generated by SteinGAN on CelebA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>obs [?] and E ? [?] denote the empirical average on the observed data {x i,obs } and the expectation under model p(x|?), respectively. The key computational difficulty is to approximate the model expectation E ? [?]. To address this problem, we use a generative neural network x = f (?; ?) trained by Algorithm 1 to approximately sample from p(x|?), yielding a gradient update for ? of form</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Results on CIFAR-10. "500 Duplicate" denotes 500 images randomly subsampled from the training set, each duplicated 100 times. Upper: images simulated by DCGAN and SteinGAN (based on joint model</figDesc><table><row><cell>airplane</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>automobile</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>bird</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cat</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>deer</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>dog</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>frog</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>horse</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ship</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>truck</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DCGAN</cell><cell></cell><cell></cell><cell>SteinGAN</cell><cell></cell></row><row><cell></cell><cell cols="2">Inception Score</cell><cell></cell><cell></cell></row><row><cell cols="5">Real Training Set 500 Duplicate DCGAN SteinGAN</cell></row><row><cell>Model Trained on ImageNet</cell><cell>11.237</cell><cell>11.100</cell><cell>6.581</cell><cell>6.351</cell></row><row><cell>Model Trained on CIFAR-10</cell><cell>9.848</cell><cell>9.807</cell><cell>7.368</cell><cell>7.428</cell></row><row><cell></cell><cell cols="2">Testing Accuracy</cell><cell></cell><cell></cell></row><row><cell cols="4">Real Training Set 500 Duplicate DCGAN SteinGAN</cell><cell></cell></row><row><cell>92.58 %</cell><cell>44.96 %</cell><cell>44.78 %</cell><cell>63.81 %</cell><cell></cell></row><row><cell>Figure 2:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning to learn by gradient descent by gradient descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Andrychowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Misha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sergio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">W</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando</forename><surname>De Freitas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04474</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An introduction to Stein&apos;s method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">D</forename><surname>Barbour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis</forename><forename type="middle">Hsiao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Scientific</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois-Xavier</forename><surname>Briol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Oates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Girolami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dino</forename><surname>Sejdinovic</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1512.00933" />
		<title level="m">Probabilistic integration: A role for statisticians in numerical analysis? arXiv preprint</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A kernel test of goodness of fit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chwialkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kacper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Strathmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Gretton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning step size controllers for robust neural network training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Delyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Portier</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.0733</idno>
		<title level="m">Integral approximation by kernel smoothing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Training generative neural networks via maximum mean discrepancy optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gintare</forename><surname>Dziugaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Karolina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Amortized inference in probabilistic reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th Annual Conference of the Cognitive Science Society</title>
		<meeting>the 36th Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Markov chain Monte Carlo maximum likelihood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">J</forename><surname>Geyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computing Science and Statistics: Proc. 23rd Symp. Interface</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="156" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mehdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Warde</forename><forename type="middle">-</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sherjil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measuring sample quality with Stein&apos;s method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Gorham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lester</forename><surname>Mackey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="226" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Importance sampling via the estimated sampler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayuki</forename><surname>Henmi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryo</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shinto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="985" to="991" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Training products of experts by minimizing contrastive divergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1800" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Deep directed generative models with energy-based probability estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03439</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Auto-encoding variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.01885</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Learning to optimize. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generative moment matching networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Black-box importance sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1610.05247" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Stein variational gradient descent: A general purpose bayesian inference algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilin</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.04471</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A kernelized Stein discrepancy for goodness-of-fit tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ping</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning deep energy models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiquan</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhenghao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1105" to="1112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00709</idno>
		<title level="m">Training generative neural samplers using variational divergence minimization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Control functionals for Monte Carlo integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Oates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Girolami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Chopin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Monte Carlo is fundamentally unsound</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>O&amp;apos;hagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series D (The Statistician)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2/3</biblScope>
			<biblScope unit="page" from="247" to="249" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Bayes-hermite quadrature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>O&amp;apos;hagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of statistical planning and inference</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="245" to="260" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Inference networks for sequential monte carlo in graphical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooks</forename><surname>Paige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wood</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.06701</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soumith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Operator variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Altosaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Black box variational inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<meeting>the International Conference on Artificial Intelligence and Statistics (AISTATS)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.02386</idno>
		<title level="m">Hierarchical variational models</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Variational inference with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.05770</idno>
		<title level="m">Variational inference with normalizing flows</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wojciech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vicki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03498</idno>
		<title level="m">Improved techniques for training gans</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A bound for the error in the normal approximation to the distribution of a sum of dependent random variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Berkeley Symposium on Mathematical Statistics and Probability</title>
		<meeting>the Sixth Berkeley Symposium on Mathematical Statistics and Probability</meeting>
		<imprint>
			<publisher>Probability Theory</publisher>
			<date type="published" when="1972" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="583" to="602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Training restricted boltzmann machines using approximations to the likelihood gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tijmen</forename><surname>Tieleman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1064" to="1071" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajesh</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06499</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Variational gaussian process. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Song-Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.03264</idno>
		<title level="m">A theory of generative convnet</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yinda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shuran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Funkhouser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Lsun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03365</idno>
		<title level="m">Construction of a large-scale image dataset using deep learning with humans in the loop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Energy-based generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03126</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
