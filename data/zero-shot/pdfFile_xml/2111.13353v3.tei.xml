<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Contrastive Vicinal Space for Unsupervised Domain Adaptation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaemin</forename><surname>Na</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Ajou University</orgName>
								<address>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
							<email>dongyoon.han@navercorp.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">NAVER AI Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyung</forename><forename type="middle">Jin</forename><surname>Chang</surname></persName>
							<email>h.j.chang@bham.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Birmingham</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonjun</forename><surname>Hwang</surname></persName>
							<email>wjhwang@ajou.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="institution">Ajou University</orgName>
								<address>
									<country key="KR">Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Contrastive Vicinal Space for Unsupervised Domain Adaptation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Unsupervised Domain Adaptation</term>
					<term>Equilibrium Collapse</term>
					<term>Contrastive Vicinal Space</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent unsupervised domain adaptation methods have utilized vicinal space between the source and target domains. However, the equilibrium collapse of labels, a problem where the source labels are dominant over the target labels in the predictions of vicinal instances, has never been addressed. In this paper, we propose an instance-wise minimax strategy that minimizes the entropy of high uncertainty instances in the vicinal space to tackle the stated problem. We divide the vicinal space into two subspaces through the solution of the minimax problem: contrastive space and consensus space. In the contrastive space, inter-domain discrepancy is mitigated by constraining instances to have contrastive views and labels, and the consensus space reduces the confusion between intra-domain categories. The effectiveness of our method is demonstrated on public benchmarks, including Office-31, Office-Home, and VisDA-C, achieving state-of-the-art performances. We further show that our method outperforms the current state-of-the-art methods on PACS, which indicates that our instance-wise approach works well for multi-source domain adaptation as well. Code is available at https: //github.com/NaJaeMin92/CoVi.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Unsupervised domain adaptation (UDA) aims to adapt a model trained on a labeled source domain to an unlabeled target domain. One of the most important problems to solve in UDA is the domain shift <ref type="bibr" target="#b47">[48]</ref> (i.e., distribution shift) problem. The domain shift arises from the change in the data distribution between the training domain (i.e., source domain) of an algorithm and the test domain encountered in a practical application (i.e., target domain). Although recent UDA studies <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b54">55]</ref> have shown encouraging results, a large domain shift is still a significant obstacle.</p><p>One recent paradigm to address the large domain shift problem is to leverage intermediate domains between the source and target domains instead of direct <ref type="figure">Fig. 1</ref>: Overview. Vicinal space between the source and target domains is divided into contrastive space and consensus space. Our methodology alleviates inter-domain discrepancy in the contrastive space and simultaneously resolves intra-domain categorical confusion in the consensus space.</p><p>domain adaptation. Recent studies <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b5">6]</ref> inspired by generative adversarial networks <ref type="bibr" target="#b16">[17]</ref> (GANs) generate instances of intermediate domains to bridge the source and target domains. Moreover, <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b2">3]</ref> learn domain-invariant representations by borrowing only the concept of adversarial training. Meanwhile, with the development of data augmentation techniques, many approaches have emerged built on data augmentation to construct the intermediate spaces. Recent studies <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b53">54]</ref> have shown promising results by grafting Mixup augmentation <ref type="bibr" target="#b61">[62]</ref> to the domain adaptation task. These studies use inter-domain mixup to efficiently overcome the domain shift problem by utilizing vicinal instances between the source and target domains. However, none of them consider leveraging the predictions of the vicinal instances in the perspective of self-training <ref type="bibr" target="#b26">[27]</ref>.</p><p>Self-training is the straightforward approach that uses self-predictions of a model to train itself. Semi-supervised learning methods <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b41">42]</ref> leverage a model's predictions on unlabeled data to obtain additional information used during training as their supervision. In particular, unsupervised domain adaptation methods <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b43">44]</ref> have shown that pseudo-label for the target domain can play an important role in alleviating the domain shift problem.</p><p>In this work, we introduce a new Contrastive Vicinal space-based (CoVi) algorithm that leverages vicinal instances from the perspective of self-training <ref type="bibr" target="#b26">[27]</ref>. In vicinal space, we observe that the source label is generally dominant over the target label before applying domain adaptation. In other words, even if vicinal instances consist of a higher proportion of target instances than source instances (i.e., target-dominant instances), their one-hot predictions are more likely to be source labels (i.e., source-dominant labels). We define this phenomenon as an equilibrium collapse of labels between vicinal instances. We also discover that the entropy of the predictions is maximum at the points where the equilibrium collapse of labels occurs. Hence, we aim to find and address the points where the entropy is maximized between the vicinal instances. Inspired by the minimax strategy <ref type="bibr" target="#b12">[13]</ref>, we present EMP-Mixup, which minimizes the entropy for the entropy maximization point (EMP). Our EMP-Mixup adaptively adjusts the Mixup ratio according to the combinations of source and target instances through training.</p><p>As depicted in <ref type="figure">Figure 1</ref>, we further leverage the EMP as a boundary (i.e., EMP-boundary) to divide the vicinal space into source-dominant and targetdominant spaces. Here, the vicinal instances of the source-dominant space have source labels as their predicted top-1 label. Similarly, the vicinal instances of target-dominant space have target labels as their top-1 label. Taking advantage of these properties, we configure two specialized subspaces to reduce interdomain and intra-domain discrepancy simultaneously.</p><p>First, we construct a contrastive space around the EMP-boundary to ensure that the vicinal instances have contrastive views: source-dominant and target-dominant views. Since the contrastive views share the same combination of source and target instances, they should have the same top-2 labels containing the source and target labels. In addition, under our constraints, the two contrastive views have opposite order of the first and second labels in the top-2 labels. Inspired by consistency training <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b0">1]</ref>, we propose to impose consistency on predictions of the two contrastive views. Specifically, we mitigate inter-domain discrepancy by solving a "swapped" prediction problem where we predict the top-2 labels of a contrastive view from the other contrastive view.</p><p>Second, we constrain a consensus space outside of the contrastive space to alleviate the categorical confusion within the intra-domain. In this space, we generate target-dominant vicinal instances utilizing multiple source instances as a perturbation to a single target instance. Here, the role of the source instances is not to learn classification information of the source domain but to confuse the predictions of the target instances. We can ensure consistent and robust predictions for target instances by enforcing label consensus among the multiple target-dominant vicinal instances to a single target label.</p><p>We perform extensive ablation studies for a detailed analysis of the proposed methods. In particular, we achieve comparable performance to the recent stateof-the-art methods in standard unsupervised domain adaptation benchmarks such as Office-31 <ref type="bibr" target="#b42">[43]</ref>, Office-Home <ref type="bibr" target="#b51">[52]</ref>, and VisDA-C <ref type="bibr" target="#b40">[41]</ref>. Furthermore, we validate the superiority of our instance-wise approach on the PACS <ref type="bibr" target="#b28">[29]</ref> dataset for multi-source domain adaptation. Overall, we make the following contributions:</p><p>-This is the first study in UDA to leverage the vicinal space from the perspective of self-training. We shed light on the problem of the equilibrium collapse of labels in the vicinal space and propose a minimax strategy to handle it. -We alleviate inter-domain and intra-domain confusions simultaneously by dividing the vicinal space into contrastive and consensus spaces. -Our method achieves state-of-the-art performance and is further validated through extensive ablation studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Unsupervised domain adaptation. One of the representative domain adaptation approaches <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b55">56]</ref> is learning a domain-invariant representation by aligning the global distribution between the source and target domains. Of particular interest, Xie et al. <ref type="bibr" target="#b55">[56]</ref> presented a moving semantic transfer network that aligns labeled source centroids and pseudo-labeled target centroids to learn semantic representations for unlabeled target data. Following <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b17">18]</ref>, we adopt this simple but efficient method as our baseline.</p><p>Our work is also related to the domain adaptation approaches that consider the inter-domain and intra-domain gap together. Kang et al. <ref type="bibr" target="#b24">[25]</ref> proposed to minimize the intra-class discrepancy and maximize the inter-class discrepancy to perform class-aware domain alignment. Pan et al. <ref type="bibr" target="#b39">[40]</ref> presented a semantic segmentation method that minimizes both inter-domain and intra-domain gaps. Unlike these methods, we introduce a practical approach that uses two specialized spaces to reduce inter-domain and intra-domain discrepancy for each.</p><p>Mixup augmentation. Mixup <ref type="bibr" target="#b61">[62]</ref> is a data-agnostic and straightforward augmentation using a linear interpolation between two data instances. The Mixup has been applied to various tasks and shown to improve the robustness of neural networks. The recent semi-supervised learning methods [2,50,1] efficiently utilized Mixup to leverage unlabeled data. Meanwhile, several domain adaptation methods <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b37">38]</ref> with Mixup were proposed to alleviate the domain-shift problem successfully. Xu et al. <ref type="bibr" target="#b56">[57]</ref> and Wu et al. <ref type="bibr" target="#b53">[54]</ref> showed promising results using inter-domain Mixup between source and target domains. Recently, Na et al. <ref type="bibr" target="#b37">[38]</ref> achieved a significant performance gain by using two networks trained with two fixed Mixup ratios. Moreover, the latest studies <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b35">36]</ref> suggested adaptive Mixup techniques instead of using manually designed interpolation policies. For example, Zhu et al. <ref type="bibr" target="#b62">[63]</ref> introduced a more advanced interpolation technique that seeks the Wasserstein barycenter between two instances and proposed an adaptive Mixup. Mai et al. <ref type="bibr" target="#b35">[36]</ref> introduced a meta-learning-based optimization strategy for dynamically learning the interpolation policy in semi-supervised learning. However, unsupervised domain adaptation methods still count on hand-tuned or random interpolation policies. In this work, we derive the Mixup ratio according to the convex combinations of source and target instances.</p><p>Consistency training. Consistency training is one of the promising components for leveraging unlabeled data, which enforces a model to produce similar predictions of original and perturbed instances. The recent semi-supervised learning methods <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b1">2]</ref> utilize unlabeled data by assuming that the model should output similar predictions when fed perturbed versions of the same instance. Berthelot et al. <ref type="bibr" target="#b1">[2]</ref> applied augmentations several times for each unlabeled instance and averaged them to produce guessed labels. In ReMixMatch [1], Berthelot et al. used the model's prediction for a weakly-augmented instance as the guessed label for multiple strongly-augmented variants of the same instance. Recently, Sohn et al. <ref type="bibr" target="#b49">[50]</ref> encouraged predictions from strongly-augmented instances to match pseudo-labels generated from weakly-augmented instances. Although effective, these methods rely on augmentation techniques such as random augmentation, AutoAugment <ref type="bibr" target="#b8">[9]</ref>, RandAugment <ref type="bibr" target="#b9">[10]</ref>, and CTAugment <ref type="bibr" target="#b0">[1]</ref>. By contrast, our method is free from these augmentation techniques and does not require carefully selected combinations of augmentations. We solely leverage The EMP-Mixup finds the most confusing point (i.e., EMP) among vicinal instances. CoVi then learns through top-k contrastive predictions from contrastive views in the contrastive space determined by the EMP. In the consensus space, we achieve a target-label consensus with perturbations of the source instances.</p><p>mixup augmentation <ref type="bibr" target="#b61">[62]</ref> to generate the vicinal spaces and achieve the effect of consistency training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>CoVi introduces three techniques to leverage the vicinal space between the source and target domains: i) EMP-Mixup, ii) contrastive views and labels, and iii) a label-consensus. An overall depiction of CoVi is in <ref type="figure" target="#fig_0">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminaries</head><p>Notation. We denote a mini-batch of m-images as X , corresponding labels as Y, and extracted features from X as Z. Specifically, X S ? R m?i and Y S ? {0, 1} m?n denote the mini-batches of source instances and their corresponding one-hot labels, respectively. Here, n denotes the number of classes and i = c?h?w, where c denotes the channel size, and h and w denote the height and width of the image instances, respectively. Similarly, the mini-batch of unlabeled target instances is X T ? R m?i . Our model consists of the following subcomponents: an encoder f ? , a classifier h ? , and an EMP-learner g ? . Mixup. The Mixup augmentation <ref type="bibr" target="#b61">[62]</ref> based on the Vicinal Risk Minimization (VRM) <ref type="bibr" target="#b7">[8]</ref> principle exploits virtual instances constructed with the linear interpolation of two instances. These vicinal instances can benefit unsupervised domain adaptation, which has no target domain labels. We define the inter-domain Mixup applied between the source and target domains as follows:</p><formula xml:id="formula_0">X ? = ? ? X S + (1 ? ?) ? X T Y ? = ? ? Y S + (1 ? ?) ?? T ,<label>(1)</label></formula><p>where? T denotes the pseudo labels of the target instances and ? ? [0, 1] is the Mixup ratio. Then, the empirical risk for vicinal instances in the inter-domain Mixup is defined as follows:</p><formula xml:id="formula_1">R ? = 1 m m i=1 H[h(f (X (i) ? )),? (i) ? ],<label>(2)</label></formula><p>where H is a standard cross-entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">EMP-Mixup</head><p>In the vicinal space between the source and target domains, we make interesting observations on unsupervised domain adaptation. Observation 1. "The labels of the target domain are relatively recessive to the source domain labels."</p><p>We investigate the dominance of the predicted top-1 labels between the source and target instances in vicinal instances. We find that the label dominance is balanced when the labels of both the source and target domains are provided (i.e., supervised learning). In this case, the top-1 label of the vicinal instance is determined by the instance occupying a relatively larger proportion. However, in the UDA, where the label of the target domain is not given, the balance of label dominance is broken (i.e., equilibrium collapse of labels). Indeed, we discover that source labels frequently represent vicinal instances even with a higher proportion of target instances than source instances. Observation 2. "Depending on the convex combinations of source and target instances, the label dominance is changed."</p><p>Next, we observe that the label dominance is altered according to the convex combinations of instances. It implies that an instance-wise approach can be a key to solving the label equilibrium collapse problem. In addition, we discover that the entropy of the prediction is maximum at the point where the label dominance changes because the source and target instances become most confusing at this point (see <ref type="bibr">Figures 4 and 5)</ref>.</p><p>Based on these observations, we aim to capture and mitigate the most confusing points, which vary with the combination of instances. Inspired by <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b16">17]</ref>, we introduce a minimax strategy to break through the worst-case risk <ref type="bibr" target="#b12">[13]</ref> among the vicinal instances between the source and target domains. We minimize the worst risk by finding the entropy maximization point (EMP) among the vicinal instances. In order to estimate the EMPs, we introduce a small network, EMP-learner. This network aims to generate Mixup ratios that maximize the entropy of the encoder f ? (e.g., ResNet) followed by a classifier h ? .</p><p>Given X S and X T , we obtain the instance features Z S = f ? (X S ) and Z T = f ? (X T ) from the encoder f ? . Then, we pass the concatenated features Z S ?Z T to the EMP-learner g ? . Then, the EMP-learner produces the entropy maximization ratio ? * that maximizes the entropy of the encoder f ? . Formally, the Mixup ratios for our EMP-Mixup are defined as follows:</p><formula xml:id="formula_2">? * = arg max ??[0,1] H[h ? (f ? (X ? ))],<label>(3)</label></formula><p>where ? = g ? (Z S ? Z T ) and H is the entropy loss. Finally, we design the objective function for EMP-learner to maximize the entropy as follows:</p><formula xml:id="formula_3">R ? (?) = 1 m m i=1 H[h(f (X (i) ? ))],<label>(4)</label></formula><p>where H is the entropy loss. Note that we only update the parameter ? of the EMP-learner, not the parameter ? of the encoder and the classifier. With the worst-case ratio ? * , EMP-Mixup minimizes the worst-case risk on vicinal instances as follows:</p><formula xml:id="formula_4">R ? * (?) = 1 m m i=1 H[h(f (X (i) ? * )),? (i) ? * ],<label>(5)</label></formula><p>where H is the standard cross-entropy loss. It is noteworthy that our ? * = [? 1 , ..., ? m ] has different optimized ratios according to the combinations of the source and target instances within a minibatch. Finally, EMP-Mixup minimizes the risk of vicinal instances from the viewpoint of the worst-case risk. The overall objective functions are defined as follows:</p><formula xml:id="formula_5">R emp = R ? * (?) ? R ? (?).<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Contrastive Views and Labels</head><p>Observation 3. "The dominant/recessive labels of the vicinal instances are switched at the EMP." Looking back to the previous observations, the label dominance depends on the convex combination of instances, and the point of change is the EMP. In other words, with the EMP as a boundary (i.e., EMP-boundary), the dominant/recessive label is switched between the source and target domains. It means that vicinal instances around the EMP-boundary should have source and target labels as their top-2 labels.</p><p>These observations and analyses lead us to design the concepts of contrastive views and contrastive labels. Owing to the EMP-boundary, we can divide the vicinal space into source-dominant and target-dominant space, as described in <ref type="figure" target="#fig_1">Figure 3</ref>. Specifically, we constrain the source-dominant and target-dominant spaces of the contrastive space to ? * ? ? &lt; ? sd &lt; ? * and ? * &lt; ? td &lt; ? * + ?, respectively. Here, ? is the margin of the ratio from the EMP-boundary, which is manually designed. Consequently, the source-dominant instancesX sd and targetdominant instancesX td have contrastive views of each other.</p><p>From the contrastive views, we focus on the top-2 labels for each prediction because we are only interested in the classes that correspond to the source and target instances, not the other classes. Here, we define a set of top-2 one-hot labels within a mini-batch as? <ref type="bibr">[k=1]</ref> and? <ref type="bibr">[k=2]</ref> . Unlike a general Mixup that uses pure source and target labels (see Eq.1), we directly exploit the predicted labels from vicinal instances. In this case, for example, the labels for the instances of the target-dominant space are constructed as follows:</p><formula xml:id="formula_6">Y td = ? td ?? td[k=1] + (1 ? ? td ) ?? td[k=2] .<label>(7)</label></formula><p>Furthermore, we expand on this and propose a new concept of contrastive labels. We constrain the top-2 labels from the contrastive views as follows: In other words, the dominant label? sd[k=1] ofX sd and the recessive label Y td[k=2] ofX td must be the same as the source labels and vice versa. Note that our contrastive constraints are instance-level constraints that must be satisfied between any instances, regardless of the class category.</p><p>Consequently, we swap the top-2 contrastive labels between two contrastive views to learn from the predictions of the other view. By solving a "swapped" prediction problem, we enforce consistency to the top-2 contrastive labels obtained from contrastive views of the same source and target instance combinations.</p><p>According to the constraints, Eq.7 still holds when we swap the contrastive labels. Finally, the objective for our contrastive loss in target-dominant space is defined as follows:</p><formula xml:id="formula_7">R td (?) = 1 m m i=1 H[h(f (X (i) td )),? (i) td ],<label>(8)</label></formula><formula xml:id="formula_8">where? td = ? td ?? sd[k=2] + (1 ? ? td ) ?? sd[k=1] .</formula><p>Similarly, we define R sd (?) in the source-dominant space and omit it for clarity. The overall objective functions for contrastive loss are defined as follows:</p><formula xml:id="formula_9">R ct = R td (?) + R sd (?).<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Label Consensus</head><p>Even though the confusion between the source and target instances is crucial in the contrastive space, outside of the contrastive space (i.e., consensus space), we pay more attention to the uncertainty of predictions within the intra-domain than inter-domain instances (see <ref type="figure">Figure 6</ref>). Here, we exploit multiple source instances to impose perturbations to target predictions rather than classification information for the source domain. It makes a model more robust to the target predictions by enforcing consistent predictions on the target instances even with the source perturbations. We construct two randomly shuffled versions of the source instances within a mini-batch. We then apply Mixup with a single target mini-batch to obtain two different perturbed views v 1 and v 2 . Here, we set the mixup ratio for the source instances sufficiently small since too strong perturbations can impair the target class semantics. We compute two softmax probabilities from the perturbed instancesX v1 andX v2 using an encoder, followed by a classifier. Finally, we aggregate the softmax probabilities and yield a one-hot prediction?.</p><p>We accomplish target-label consensus by assigning the label? to both versions of the perturbed target-dominant instancesX v1 andX v2 . Imposing consistency to differently perturbed instances for a single target label allows us to focus on categorical information for the target domain. The objective for label consensus on target instances can be defined as follows:</p><formula xml:id="formula_10">Rcs(?) = 1 m m i=1 [H(h(f (X (i) v 1 ),? (i) )) + H(h(f (X (i) v 2 ),? (i) ))],<label>(10)</label></formula><p>where H is the cross-entropy loss. Note that this approach is also applicable to source-dominant space, but we exclude it from the final loss as it does not significantly affect the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate our method on four popular benchmarks, including Office-31, Office-Home, VisDA-C, and PACS. Moreover, we validate our method in a multi-source domain adaptation scenario using the PACS dataset.   <ref type="table" target="#tab_8">Table 1</ref>: Accuracy (%) on Office-31 for unsupervised domain adaptation (ResNet-50). The best accuracy is indicated in bold, and the second-best accuracy is underlined. * Reproduced by <ref type="bibr" target="#b6">[7]</ref>.</p><p>-VisDA-C <ref type="bibr" target="#b40">[41]</ref> is a large-scale dataset for synthetic-to-real domain adaptation across 12 categories. It contains 152,397 synthetic images for the source domain and 55,388 real-world images for the target domain.</p><p>-PACS <ref type="bibr" target="#b28">[29]</ref> is organized into seven categories with 9,991 images in four domains: Photo (P), Art Painting (A), Cartoon (C), and Sketch (S).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setups</head><p>Following the standard UDA protocol <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b13">14]</ref>, we utilize labeled source data and unlabeled target data. We exploit ResNet-50 <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b19">20]</ref> for Office-31 and Office-Home, and ResNet-101 for VisDA-C. For multi-source domain adaptation, we use ResNet-18 in the PACS dataset. We use stochastic gradient descent (SGD) with a momentum of 0.9 in all experiments and follow the same learning rate schedule as in <ref type="bibr" target="#b13">[14]</ref>. For the contrastive loss and label consensus loss, we follow the confidence masking policy of <ref type="bibr" target="#b37">[38]</ref> that adaptively changes according to the sample mean and standard deviation across all mini-batches. Meanwhile, we design the EMP-learner by using four convolutional layers, regardless of the dataset. More detailed information is provided in the supplementary materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparison with the State-of-the-Art Methods</head><p>We validate our method compared with the state-of-the-art methods on three public benchmarks, including Office-31, Office-Home, and VisDA-C. Office-31. In <ref type="table" target="#tab_8">Table 1</ref>, we show the comparative performance on ResNet-50. We achieve an accuracy of 91.8%, which is 5.3% higher than the baseline MSTN <ref type="bibr" target="#b55">[56]</ref>, surpassing other state-of-the-art methods. Our method performs best in four out of six situations, e.g., A?W, D?W, W?D, and A?D tasks. In particular, in A?W and A?D, although the performance improvement of the recent methods has stagnated, our method achieves a significant performance gain. We also attain better performance than the Mixup-based methods, i.e., DMRL <ref type="bibr" target="#b53">[54]</ref> and FixBi <ref type="bibr" target="#b37">[38]</ref>.</p><p>Office-Home.    <ref type="table" target="#tab_8">Table 3</ref>: Accuracy (%) on VisDA-C for unsupervised domain adaptation (ResNet-101). The best accuracy is indicated in bold, and the second-best accuracy is underlined. * Reproduced by <ref type="bibr" target="#b6">[7]</ref>.</p><formula xml:id="formula_11">[54] - - - - - - - - - - - -75.5 TCM (ICCV'21) [61] - - - - - - - - - - - -</formula><p>in half of the tasks and is the first to break the 73% barrier. In particular, we attain over 10% higher performance from the baseline in Cl?Pr and Pr?Cl. In addition, our method outperforms MetaAlign <ref type="bibr" target="#b52">[53]</ref>, which uses meta-learning schemes, and FixBi <ref type="bibr" target="#b37">[38]</ref>, which operates two backbone networks (i.e., ResNet). VisDA-C. In <ref type="table" target="#tab_8">Table 3</ref>, we validate our method on a large visual domain adaptation challenge dataset with ResNet-101. Our method outperforms the state-of-the-art methods with an accuracy of 88.5%. Compared to the baseline MSTN <ref type="bibr" target="#b55">[56]</ref>, our method achieves a performance improvement of over 23%. In addition, our method shows better performance than the mixup-based DMRL <ref type="bibr" target="#b53">[54]</ref> and FixBi <ref type="bibr" target="#b37">[38]</ref>. We could not achieve the best accuracy across all categories due to the poor accuracy of the baseline (65.0%), yet the overall score supports the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation Studies and Discussions</head><p>Analysis of EMP. We provide visual examples of the predictions of vicinal instances using Grad-CAM <ref type="bibr" target="#b44">[45]</ref> in <ref type="figure">Figure 4</ref>. Grad-CAM highlights classdiscriminative region in an instance; hence, we can identify the most dominant label in each vicinal instance. Now we demonstrate our crucial observations based on the EMP. First, we observe that the EMP is formed differently depending on the convex combinations of the source and target instances. Second, the dominant labels are switched between the source and target labels at the <ref type="figure">Fig. 4</ref>: Grad-CAM visualization. Our key observations in the vicinal space are as follows: (i) EMPs vary depending on the convex combination of instances.</p><p>(ii) The top-1 prediction is switched between the source and target labels (e.g., Tape dispenser ? File cabinet) around the EMP. (iii) Grad-CAM highlights the same category as our top-1 prediction as the most class-discriminative region.</p><p>EMP. Lastly, because the EMP is the highest entropy point, Grad-CAM fails to highlight one specific category at this point adequately. We claim that this outcome is due to the uncertainty arising from the confusion between the source and target instances. Furthermore, we discover that the source and target classes are highlighted in instances on both sides of the EMP.</p><p>Equilibrium collapse. In <ref type="figure">Figure 5</ref>, we analyze the dominance of labels between the source and target domains. Before adaptation (i.e., source-only), the equilibrium of the labels is broken by the dominant-source and recessivetarget domains. In this case, even if the proportion of the target instances in the mixed-up instance is more than half (i.e., target-dominant instance), the top-1 predicted label is determined by the source label (i.e., source-dominant label). In other words, the EMP is formed where it is biased towards the source domain. By contrast, after applying our method, we achieve equilibrium at around 50%, which is similar to the results of the supervised learning method. Consequently, our method alleviates the equilibrium collapse so that the target-dominant instance is properly predicted as a target label rather than a source label.</p><p>Analysis of the vicinal space. Our method leverages the vicinal spaces by dividing them into a contrastive space and a consensus space. In <ref type="figure">Figure 6</ref>, we observe that the top-5 predictions of the two spaces have different characteristics. In the contrastive space, the top-2 predictions consist of the target label (i.e., mobile phone) and source label (i.e., backpack). In other words, the uncertainty between inter-domain categories is the most critical factor in the predictions. By contrast, in the top-2 predictions of the consensus space, the second label is not the source label but another category (i.e., trash can) in the target domain that looks similar to the target label (i.e., mobile phone). Hence, mitigating the intra-domain confusion of the target domain in the consensus space can be another starting point to improve performance further. <ref type="figure">Fig. 5</ref>: Equilibrium collapse of labels. We compare the change of entropy maximization point according to the methods. Before adaptation, the source domain is dominant over the target domain. Contrarily, applying our method equilibrates around 50%, similar to supervised learning. <ref type="figure">Fig. 6</ref>: Predictions in the contrastive space vs. consensus space. Top: The first and second predicted labels consist of source and target labels in the contrastive space. Bottom: In the consensus space, the second predicted label is not the source label but a label of another category.  Effect of the components. We conduct ablation studies to investigate the effectiveness for each component of our method in <ref type="table" target="#tab_5">Table 4</ref>. We observe that our EMP-Mixup improves the accuracy by an average of 3.9% compared to the baseline <ref type="bibr" target="#b55">[56]</ref>. In addition, our contrastive loss shows a substantial improvement in the tasks A?W and A?D. Meanwhile, in the tasks of D?A and W?A, our label-consensus loss significantly impacts the performance gain. Overall, our proposed method improves the baseline by an average of 5.3%. This experiment verifies that each component contributes positively to performance improvement.</p><p>Multi-source domain adaptation. To demonstrate the generality of our instance-wise approach, we experiment with a multi-source domain adaptation task, as shown in <ref type="table" target="#tab_8">Table 5</ref>. Our method achieves a performance improvement of over 6% on the PACS dataset compared to the baseline MSTN <ref type="bibr" target="#b55">[56]</ref>. In terms of the average accuracy, our method shows a significant performance improvement compared to the state-of-the-art methods. In particular, our method outperforms three out of four tasks when compared with the recent methods.</p><p>Feature visualization. We visualize the embedded features on task A?D of the Office-31 dataset using t-SNE <ref type="bibr" target="#b34">[35]</ref> in <ref type="figure" target="#fig_4">Figure 7</ref>. Before adaptation, the source embeddings are naturally more cohesive than that of target features because only Method C,S,P?A A,S,P?C A,C,P?S A,C,S?P Avg. MSTN* (Baseline) <ref type="bibr" target="#b55">[56]</ref> 85  <ref type="table" target="#tab_8">Table 5</ref>: Accuracy (%) on PACS for multi-source unsupervised domain adaptation (ResNet-18). The best accuracy is indicated in bold, and the second-best accuracy is underlined. * Reproduced by ourselves. source supervision is accessible. After applying the baseline (i.e., MSTN <ref type="bibr" target="#b55">[56]</ref>), we observe that the cohesion of the target features is improved but still fails to form tight clusters. By contrast, in our method, the target features construct compact clusters comparable to the source features. These results prove that our method works successfully in the unsupervised domain adaptation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this study, we investigated the vicinal space between the source and target domains from the perspective of self-training. We raised the problem of the equilibrium collapse of labels and proposed three novel approaches. Our EMP-Mixup efficiently minimized the worst-case risk in the vicinal space. In addition, we reduce inter-domain and intra-domain confusions by dividing the vicinal space into contrastive and consensus space. The competitiveness of our approach suggests that self-predictions in vicinal space can play an important role in solving the UDA problem.</p><p>Acknowledgement. This work was partially supported by the IITP grant funded by the MSIT, Korea [2014-3-00123, 2021-0-02130] and the BK21 FOUR program (NRF-5199991014091).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Additional Experimental Results</head><p>A.1. Effects of our components with a different baseline.</p><p>In the main paper, we provided the effect of our components with baseline, MSTN <ref type="bibr" target="#b55">[56]</ref>. We further investigate our method using DANN (Ganin et al., JMLR 2016) <ref type="bibr" target="#b13">[14]</ref> as a baseline, which is one of the simplest methods in unsupervised domain adaptation. As in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Empirical visualization of vicinal space.</head><p>We computed the entropy of vicinal instances in task A?W on Office-31 to support the demo <ref type="figure">Figure 1</ref> in the main paper. As in <ref type="figure" target="#fig_0">Figure A.2</ref>.a, we observed that the entropy maximization point (i.e., EMP) is biased toward the target domain before adaptation. Here, we define contrastive space within a certain margin from EMP. On the other hand, after applying our method, we observed that the EMP is formed near the center of the source and target domains (see <ref type="figure">Figure A.</ref>2.b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. A.2. Empirical visualization of vicinal space.</head><p>A.3. The equilibrium collapse of labels in other scenarios.</p><p>As discussed in Section 4.3, the equilibrium collapse of labels problem occurs before adaptation by dominant-source and recessive-target vicinal instances. We analyzed whether this problem still exists after applying other UDA methods in <ref type="figure">Figure A.</ref>3.a. In this experiment, we use DANN as a baseline, which has relatively low accuracy (82.2%). We observe that there is still the problem of the equilibrium collapse of labels in some tasks. On the other hand, FixBi (Na et al., CVPR 2021) (91.4%) achieved an equilibrium similar to the supervised learning method in all tasks. In addition, we experimented on both single-source and multi-source scenarios in Office-Home and PACS datasets, respectively. As shown in <ref type="figure">Figure A.</ref>3.b, we discovered that the problem of equilibrium collapse of labels occurs in both cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Network Architectures</head><p>We describe the details of network architectures according to the dataset. As introduced in the main paper, our model consists of three subcomponents: an encoder, a classifier, and an EMP-learner. Encoder. Following the standard architecture of previous studies on unsupervised domain adaptation <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b50">51]</ref>, we adopt an ImageNet <ref type="bibr" target="#b25">[26]</ref>-pretrained ResNet <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b19">20]</ref> for the encoder. We use ResNet-50 for Office-31 <ref type="bibr" target="#b42">[43]</ref> and Office-Home <ref type="bibr" target="#b51">[52]</ref>, and ResNet-101 for VisDA-C <ref type="bibr" target="#b40">[41]</ref> dataset. For multi-source domain adaptation, we use ResNet-18 for PACS <ref type="bibr" target="#b28">[29]</ref> dataset.</p><p>EMP-learner. We introduce a small network to produce entropy maximization points (EMPs) according to the convex combinations of the source and target instances. We design the EMP-learner with four convolutional layers, regardless of the dataset. We construct the EMP-learner with three 3x3 convolutional layers with stride one followed by Batch Normalization <ref type="bibr" target="#b22">[23]</ref> and ReLU <ref type="bibr" target="#b38">[39]</ref>. For the last layer, instead of the fully connected layer, we adopt 1x1 convolution <ref type="bibr" target="#b31">[32]</ref>. The output channel of the last 1x1 convolutional layer is 11, yielding a ratio ? ? {0.0, 0.1, ..., 1.0}.</p><p>Classifier. We adopt only one fully connected layer for the classifier. The input feature size of the fully connected layer is decided by the output feature size of the encoder. The output feature size of the fully connected layer depends on the number of categories in each dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Data Configurations</head><p>We implement our algorithm using PyTorch. The code runs with Python 3.7+, PyTorch 1.7.1, and Torchvision 0.8.2. In this section, we provide our training recipes for Office-31, Office-Home, VisDA-C, and PACS dataset in Configs 1,2, and 3.</p><p>Office-31 and Office-Home. In Configs 1, we describe our default configuration for Office-31 and Office-Home. The default configs for Office-Home are almost identical to Office-31, except for the resize factor of test transform that uses a scaling factor of 256 instead of 224. VisDA-C. We provide the configurations for VisDA-C in Configs 2. We use a stochastic gradient descent optimization (SGD) with a training batch size of 128, a momentum of 0.9, and a learning rate of 1e-4. The end-to-end pipeline is trained for 100 epochs. We use the center crop instead of the random crop for image transformations in the training process. It is worth noting that we do not use the ten-crops ensemble technique used in <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b32">33]</ref> during evaluation for a fair comparison. PACS. Following the previous protocols <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b45">46]</ref> for multi-source domain adaptation, we train on any three of the four domains (i.e., source domains) and then test on the remaining one domain (i.e., target domain). The total epoch is 100, with a batch size of 32 for the PACS dataset. The training details are described in Configs 3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Configs 3</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 :</head><label>2</label><figDesc>Schematic illustration of CoVi.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>Contrastive views and labels. (i) The contrastive views consist of a source-dominant viewX sd and a target-dominant viewX td . (ii) The contrastive labels comprise the source-dominant label and target-recessive label from the top-2 predictions in the contrastive viewX sd (and vice versa).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>-</head><label></label><figDesc>? sd[k=1] fromX sd and? td[k=2] fromX td must be equal, as the predictions of the source instances. -Similarly,? sd[k=2] must be equal to? td[k=1] , as for the predictions of the target instances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>-Office-31<ref type="bibr" target="#b42">[43]</ref> contains 31 categories and 4,110 images in three domains: Amazon (A), Webcam (W), and DSLR (D). We verify our methodology in six domain adaptation tasks.-Office-Home<ref type="bibr" target="#b51">[52]</ref> consists of 64 categories and 15,500 images in four domains: Art (Ar), Clipart (Cl), Product (Pr), and Real-World (Rw).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 7 :</head><label>7</label><figDesc>t-SNE visualization. Visualization of embedded features on task A?D. Blue and orange points denote the source and target domains, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. A. 3 .</head><label>3</label><figDesc>Ablation studies on the 'equilibrium collapse of labels'.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>7?0.2 99.2?0.1 100.0?0.0 95.8?0.2 76.7?0.3 77.1?0.1 90.8 RSDA (CVPR'20) [18] 96.1?0.2 99.3?0.2 100.0?0.0 95.8?0.3 77.4?0.8 78.9?0.3 91.1 FixBi (CVPR'21) [38] 96.1?0.2 99.3?0.2 100.0?0.0 95.0?0.4 78.7?0.5 79.4?0.</figDesc><table><row><cell>Method</cell><cell>A?W</cell><cell>D?W</cell><cell>W?D</cell><cell>A?D</cell><cell>D?A</cell><cell cols="2">W?A Avg.</cell></row><row><cell>MSTN* (Baseline) [56]</cell><cell>91.3</cell><cell>98.9</cell><cell>100.0</cell><cell>90.4</cell><cell>72.7</cell><cell>65.6</cell><cell>86.5</cell></row><row><cell>DWL (CVPR'21) [55]</cell><cell>89.2</cell><cell>99.2</cell><cell>100.0</cell><cell>91.2</cell><cell>73.1</cell><cell>69.8</cell><cell>87.1</cell></row><row><cell cols="8">DMRL (ECCV'20) [54] 90.8?0.3 99.0?0.2 100.0?0.0 93.4?0.5 73.0?0.3 71.2?0.3 87.9</cell></row><row><cell cols="2">ILA-DA (CVPR'21) [47] 95.72</cell><cell>99.25</cell><cell>100.0</cell><cell>93.37</cell><cell>72.10</cell><cell>75.40</cell><cell>89.3</cell></row><row><cell cols="8">MCC (ECCV'20) [24] 95.5?0.2 98.6?0.1 100.0?0.0 94.4?0.3 72.9?0.2 74.9?0.3 89.4</cell></row><row><cell>GSDA (CVPR'20) [22]</cell><cell>95.7</cell><cell>99.1</cell><cell>100</cell><cell>94.8</cell><cell>73.5</cell><cell>74.9</cell><cell>89.7</cell></row><row><cell cols="8">SRDC (CVPR'20) [51] 95.3 91.4</cell></row><row><cell>CoVi (Ours)</cell><cell cols="7">97.6?0.2 99.3?0.1 100.0?0.0 98.0?0.3 77.5?0.3 78.4?0.3 91.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>demonstrates the comparison results on the Office-Home dataset based on ResNet-50. Our method achieves the highest accuracyMethodAr?Cl Ar?Pr Ar?Rw Cl?Ar Cl?Pr Cl?Rw Pr?Ar Pr?Cl Pr?Rw Rw?Ar Rw?Cl Rw?Pr Avg.</figDesc><table><row><cell>MSTN* (Baseline) [56]</cell><cell>49.8</cell><cell>70.3</cell><cell>76.3</cell><cell>60.4</cell><cell>68.5</cell><cell>69.6</cell><cell>61.4</cell><cell>48.9</cell><cell>75.7</cell><cell>70.9</cell><cell>55</cell><cell cols="2">81.1 65.7</cell></row><row><cell>AADA (ECCV'20) [59]</cell><cell>54.0</cell><cell>71.3</cell><cell>77.5</cell><cell>60.8</cell><cell>70.8</cell><cell>71.2</cell><cell>59.1</cell><cell>51.8</cell><cell>76.9</cell><cell>71.0</cell><cell>57.4</cell><cell cols="2">81.8 67.0</cell></row><row><cell>ETD (CVPR'20) [30]</cell><cell>51.3</cell><cell>71.9</cell><cell>85.7</cell><cell>57.6</cell><cell>69.2</cell><cell>73.7</cell><cell>57.8</cell><cell>51.2</cell><cell>79.3</cell><cell>70.2</cell><cell>57.5</cell><cell cols="2">82.1 67.3</cell></row><row><cell>GSDA (CVPR'20) [22]</cell><cell>61.3</cell><cell>76.1</cell><cell>79.4</cell><cell>65.4</cell><cell>73.3</cell><cell>74.3</cell><cell>65</cell><cell>53.2</cell><cell>80</cell><cell>72.2</cell><cell>60.6</cell><cell cols="2">83.1 70.3</cell></row><row><cell>GVB-GD (CVPR'20) [11]</cell><cell>57</cell><cell>74.7</cell><cell>79.8</cell><cell>64.6</cell><cell>74.1</cell><cell>74.6</cell><cell>65.2</cell><cell>55.1</cell><cell>81</cell><cell>74.6</cell><cell>59.7</cell><cell cols="2">84.3 70.4</cell></row><row><cell>TCM (ICCV'21) [61]</cell><cell>58.6</cell><cell>74.4</cell><cell>79.6</cell><cell>64.5</cell><cell>74.0</cell><cell>75.1</cell><cell>64.6</cell><cell>56.2</cell><cell>80.9</cell><cell>74.6</cell><cell>60.7</cell><cell cols="2">84.7 70.7</cell></row><row><cell>RSDA (CVPR'20) [18]</cell><cell>53.2</cell><cell>77.7</cell><cell>81.3</cell><cell>66.4</cell><cell>74</cell><cell>76.5</cell><cell>67.9</cell><cell>53</cell><cell>82</cell><cell>75.8</cell><cell>57.8</cell><cell cols="2">85.4 70.9</cell></row><row><cell>SRDC (CVPR'20) [51]</cell><cell>52.3</cell><cell>76.3</cell><cell>81</cell><cell>69.5</cell><cell>76.2</cell><cell>78</cell><cell>68.7</cell><cell>53.8</cell><cell>81.7</cell><cell>76.3</cell><cell>57.1</cell><cell>85</cell><cell>71.3</cell></row><row><cell cols="2">MetaAlign (CVPR'21) [53] 59.3</cell><cell>76.0</cell><cell>80.2</cell><cell>65.7</cell><cell>74.7</cell><cell>75.1</cell><cell>65.7</cell><cell>56.5</cell><cell>81.6</cell><cell>74.1</cell><cell>61.1</cell><cell cols="2">85.2 71.3</cell></row><row><cell>FixBi (CVPR'21) [38]</cell><cell>58.1</cell><cell>77.3</cell><cell>80.4</cell><cell>67.7</cell><cell>79.5</cell><cell>78.1</cell><cell>65.8</cell><cell>57.9</cell><cell>81.7</cell><cell>76.4</cell><cell>62.9</cell><cell cols="2">86.7 72.7</cell></row><row><cell>CoVi (Ours)</cell><cell>58.5</cell><cell>78.1</cell><cell>80.0</cell><cell>68.1</cell><cell>80.0</cell><cell>77.0</cell><cell>66.4</cell><cell>60.2</cell><cell>82.1</cell><cell>76.6</cell><cell>63.6</cell><cell cols="2">86.5 73.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell cols="2">Accuracy (%) on Office-Home for unsupervised domain adaptation</cell></row><row><cell cols="2">(ResNet-50). The best accuracy is indicated in bold, and the second-best ac-</cell></row><row><cell cols="2">curacy is underlined. * Reproduced by [18].</cell></row><row><cell>Method</cell><cell>aero bicycle bus car horse knife motor person plant skate train truck Avg.</cell></row><row><cell cols="2">MSTN* (Baseline) [56] 89.3 49.5 74.3 67.6 90.1 16.6 93.6 70.1 86.5 40.4 83.2 18.5 65.0</cell></row><row><cell>DMRL (ECCV'20)</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>97 87.2 82.5 74.3 97.8 96.2 90.8 80.7 96.6 96.3 87.5 59.9 87.2 FixBi (CVPR'21) [38] 96.1 87.8 90.5 90.3 96.8 95.3 92.8 88.7 97.2 94.2 90.9 25.7 87.2 CoVi (Ours) 96.8 85.6 88.9 88.6 97.8 93.4 91.9 87.6 96.0 93.8 93.6 48.1 88.5</figDesc><table><row><cell></cell><cell>75.8</cell></row><row><cell cols="2">DWL (CVPR'21) [55] 90.7 80.2 86.1 67.6 92.4 81.5 86.8 78.1 90.6 57.1 85.6 28.7 77.1</cell></row><row><cell cols="2">CGDM (ICCV'21) [12] 93.4 82.7 73.2 68.4 92.9 94.5 88.7 82.1 93.4 82.5 86.8 49.2 82.3</cell></row><row><cell>STAR (CVPR'20) [34] 95</cell><cell>84 84.6 73 91.6 91.8 85.9 78.4 94.4 84.7 87 42.2 82.7</cell></row><row><cell>CAN (CVPR'19) [25]</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Baseline R emp R ct R cs A?W D?W W?D A?D D?A W?A Avg.</figDesc><table><row><cell>?</cell><cell></cell><cell></cell><cell>91.3 98.9 100.0 90.4 72.7 65.6 86.5</cell></row><row><cell>?</cell><cell>?</cell><cell></cell><cell>95.9 99.1 100.0 95.6 76.3 75.4 90.4</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>97.1 99.2 100.0 97.2 76.4 76.4 91.1</cell></row><row><cell>?</cell><cell>?</cell><cell cols="2">? ? 97.6 99.3 100.0 98.0 77.5 78.4 91.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Ablation results (%) of investigating the effects of our components on Office-31.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Table A.1., we observed that each component is still effective even with the light baseline DANN. Note that we only obtain the initial weights from the baseline and do not use any losses from the baseline when training our method.Baseline R emp R ct R cs A?W D?W W?D A?D D?A W?A Avg.</figDesc><table><row><cell>?</cell><cell></cell><cell></cell><cell>82.0 96.9 99.1 79.7 68.2 67.4 82.2</cell></row><row><cell>?</cell><cell>?</cell><cell></cell><cell>94.5 99.0 100.0 94.2 75.6 75.2 89.8</cell></row><row><cell>?</cell><cell>?</cell><cell>?</cell><cell>95.5 99.2 100.0 94.4 76.0 76.3 90.2</cell></row><row><cell>?</cell><cell>?</cell><cell cols="2">? ? 95.6 99.2 100.0 95.8 76.9 78.3 91.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table A .</head><label>A</label><figDesc></figDesc><table /><note>1. Ablation results (%) of investigating the effects of our components with baseline DANN on Office-31.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Configs 1PyTorch-style configs for Office-31 and Office-Home.</figDesc><table><row><cell>train_transforms = torch . nn . Sequential (</cell></row><row><cell>transforms . Resize ( 256 ) ,</cell></row><row><cell>transforms . RandomCrop ( 224 ) ,</cell></row><row><cell>transforms . RandomHorizontalFlip () ,</cell></row><row><cell>transforms . ToTensor () ,</cell></row><row><cell>transforms . Normalize (</cell></row><row><cell>mean = [ 0 . 485 , 0 . 456 , 0 . 406 ] ,</cell></row><row><cell>std = [ 0 . 229 , 0 . 224 , 0 . 225 ] ) )</cell></row><row><cell>test_transforms = torch . nn . Sequential (</cell></row><row><cell>transforms . Resize ( 224 ) ,</cell></row><row><cell>transforms . CenterCrop ( 224 ) ,</cell></row><row><cell>transforms . ToTensor () ,</cell></row><row><cell>transforms . Normalize (</cell></row><row><cell>mean = [ 0 . 485 , 0 . 456 , 0 . 406 ] ,</cell></row><row><cell>std = [ 0 . 229 , 0 . 224 , 0 . 225 ] ) )</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Configs 2PyTorch-style configs for VisDA-C.</figDesc><table><row><cell>train_transforms = torch . nn . Sequential (</cell></row><row><cell>transforms . Resize ( 256 ) ,</cell></row><row><cell>transforms . CenterCrop ( 224 ) ,</cell></row><row><cell>transforms . RandomHorizontalFlip () ,</cell></row><row><cell>transforms . ToTensor () ,</cell></row><row><cell>transforms . Normalize (</cell></row><row><cell>mean = [ 0 . 485 , 0 . 456 , 0 . 406 ] ,</cell></row><row><cell>std = [ 0 . 229 , 0 . 224 , 0 . 225 ] ) )</cell></row><row><cell>test_transforms = torch . nn . Sequential (</cell></row><row><cell>transforms . Resize ( 256 ) ,</cell></row><row><cell>transforms . CenterCrop ( 224 ) ,</cell></row><row><cell>transforms . ToTensor () ,</cell></row><row><cell>transforms . Normalize (</cell></row><row><cell>mean = [ 0 . 485 , 0 . 456 , 0 . 406 ] ,</cell></row><row><cell>std = [ 0 . 229 , 0 . 224 , 0 . 225 ] ) )</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>PyTorch-style configs for PACS.</figDesc><table><row><cell>train_transforms = torch . nn . Sequential (</cell></row><row><cell>transforms . Resize ( 256 ) ,</cell></row><row><cell>transforms . RandomCrop ( 224 ) ,</cell></row><row><cell>transforms . RandomHorizontalFlip () ,</cell></row><row><cell>transforms . ToTensor () ,</cell></row><row><cell>transforms . Normalize (</cell></row><row><cell>mean = [ 0 . 485 , 0 . 456 , 0 . 406 ] ,</cell></row><row><cell>std = [ 0 . 229 , 0 . 224 , 0 . 225 ] )</cell></row><row><cell>test_transforms = torch . nn . Sequential (</cell></row><row><cell>transforms . Resize ( 224 ) ,</cell></row><row><cell>transforms . CenterCrop ( 224 ) ,</cell></row><row><cell>transforms . ToTensor () ,</cell></row><row><cell>transforms . Normalize (</cell></row><row><cell>mean = [ 0 . 485 , 0 . 456 , 0 . 406 ] ,</cell></row><row><cell>std = [ 0 . 229 , 0 . 224 , 0 . 225 ] ) )</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.09785</idno>
		<title level="m">Remixmatch: Semi-supervised learning with distribution alignment and augmentation anchoring</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02249</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Domain separation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bousmalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Trigeorgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Silberman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="343" to="351" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Partial adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Domain generalization by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Carlucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>D&amp;apos;innocente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">All about structure: Adapting structural information across domains for boosting semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Chiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1900" to="1909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Domain-specific batch normalization for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Vicinal risk minimization. Advances in neural information processing systems pp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.09501</idno>
		<title level="m">Autoaugment: Learning augmentation policies from data</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Gradually vanishing bridge for adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cross-domain gradient discrepancy minimization for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Minimax theorems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dlow: Domain flow for adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2477" to="2486" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Spherical space domain adaptation with robust pseudolabel loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Mixup as locally linear out-of-manifold regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation with hierarchical gradient synchronization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Minimum class confusion for versatile domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Contrastive adaptation network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">896</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Online meta-learning for multi-source and semi-supervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deeper, broader and artier domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="5542" to="5550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Enhanced transport distance for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">X</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">T-svdnet: Exploring high-order prototypical correlations for multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.4400</idno>
		<title level="m">Network in network</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10667</idno>
		<title level="m">Conditional adversarial domain adaptation</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stochastic classifiers for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Metamixup: Learning adaptive interpolation policy of mixup with metalearning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Mai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fixbi: Bridging domain spaces for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note>2021) 1, 2, 4</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Icml</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unsupervised intra-domain adaptation for semantic segmentation through self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rameau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Usman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.06924</idno>
		<title level="m">Visda: The visual domain adaptation challenge</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Meta pseudo labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="11557" to="11568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Asymmetric tri-training for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ushiku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2988" to="2997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Gradcam: Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning to optimize domain specific normalization for domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings, Part XXII 16</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Instance level affinity-based transfer for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kalluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Improving predictive inference under covariate shift by weighting the log-likelihood function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shimodaira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of statistical planning and inference</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Two-phase pseudo label densification for self-training based domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="532" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<title level="m">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation via structurally regularized deep clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="8725" to="8735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Deep hashing network for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Venkateswara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eusebio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="5018" to="5027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Metaalign: Coordinating domain alignment and classification for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Dual mixup regularized learning for adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>El-Roby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Dynamic weighted learning for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Learning semantic representations for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Adversarial domain adaptation with domain mixup</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Larger norm more transferable: An adaptive feature norm approach for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Mind the discriminability: Asymmetric adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Curriculum manager for source selection in multi-source domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings, Part XIV 16</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Transporting causal mechanisms for unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Automix: Mixup networks for sample interpolation via cooperative barycenter learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">In Pseudo-code 1, 2, and 3, we provide PyTorch-like pseudo-codes for the EMP-Mixup, contrastive loss, and consensus loss, respectively. The entire code has been</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pseudocode</surname></persName>
		</author>
		<ptr target="https://github.com/NaJaeMin92/CoVi" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
