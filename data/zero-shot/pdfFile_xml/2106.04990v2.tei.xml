<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IT TAKES TWO TO TANGO: MIXUP FOR DEEP METRIC LEARNING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashanka</forename><surname>Venkataramanan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inria</orgName>
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<region>IRISA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Psomas</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">National Technical University of Athens</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewa</forename><surname>Kijak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inria</orgName>
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<region>IRISA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Amsaleg</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Inria</orgName>
								<orgName type="institution" key="instit1">Univ Rennes</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<region>IRISA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Karantzalos</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">National Technical University of Athens</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Avrithis</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Athena RC</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">IT TAKES TWO TO TANGO: MIXUP FOR DEEP METRIC LEARNING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Metric learning involves learning a discriminative representation such that embeddings of similar classes are encouraged to be close, while embeddings of dissimilar classes are pushed far apart. State-of-the-art methods focus mostly on sophisticated loss functions or mining strategies. On the one hand, metric learning losses consider two or more examples at a time. On the other hand, modern data augmentation methods for classification consider two or more examples at a time. The combination of the two ideas is under-studied. In this work, we aim to bridge this gap and improve representations using mixup, which is a powerful data augmentation approach interpolating two or more examples and corresponding target labels at a time. This task is challenging because unlike classification, the loss functions used in metric learning are not additive over examples, so the idea of interpolating target labels is not straightforward. To the best of our knowledge, we are the first to investigate mixing both examples and target labels for deep metric learning. We develop a generalized formulation that encompasses existing metric learning loss functions and modify it to accommodate for mixup, introducing Metric Mix, or Metrix. We also introduce a new metricutilization-to demonstrate that by mixing examples during training, we are exploring areas of the embedding space beyond the training classes, thereby improving representations. To validate the effect of improved representations, we show that mixing inputs, intermediate representations or embeddings along with target labels significantly outperforms state-of-the-art metric learning methods on four benchmark deep metric learning datasets. Code at: https</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Classification is one of the most studied tasks in machine learning and deep learning. It is a common source of pre-trained models for transfer learning to other tasks <ref type="bibr" target="#b6">(Donahue et al., 2014;</ref><ref type="bibr" target="#b22">Kolesnikov et al., 2020)</ref>. It has been studied under different supervision settings <ref type="bibr" target="#b2">(Caron et al., 2018;</ref><ref type="bibr" target="#b39">Sohn et al., 2020)</ref>, knowledge transfer <ref type="bibr" target="#b15">(Hinton et al., 2015)</ref> and data augmentation <ref type="bibr" target="#b4">(Cubuk et al., 2018)</ref>, including the recent research on mixup <ref type="bibr" target="#b56">(Zhang et al., 2018;</ref>, where embeddings and labels are interpolated.</p><p>Deep metric learning is about learning from pairwise interactions such that inference relies on instance embeddings, e.g. for nearest neighbor classification (Oh <ref type="bibr">Song et al.,</ref> Unlike classification, classes (and distributions) at training and inference are different in metric learning. Thus, one might expect interpolation-based data augmentation like mixup to be even more important in metric learning than in classification. Yet, recent attempts are mostly limited to special cases of embedding interpolation and have trouble with label interpolation . This raises the question: what is a proper way to define and interpolate labels for metric learning?</p><p>In this work, we observe that metric learning is not different from classification, where examples are replaced by pairs of examples and class labels by "positive" or "negative", according to whether class labels of individual examples are the same or not. The positive or negative label of an example, or a pair, is determined in relation to a given example which is called an anchor. Then, as shown in <ref type="figure" target="#fig_0">Figure 1</ref>, a straightforward way is to use a binary (two class) label per pair and interpolate it linearly as in standard mixup. We call our method Metric Mix, or Metrix for short.</p><p>To show that mixing examples improves representation learning, we quantitatively measure the properties of the test distributions using alignment and uniformity <ref type="bibr" target="#b47">(Wang &amp; Isola, 2020)</ref>. Alignment measures the clustering quality and uniformity measures its distribution over the embedding space; a well clustered and uniformly spread distribution indicates higher representation quality. We also introduce a new metric, utilization, to measure the extent to which a test example, seen as a query, lies near any of the training examples, clean or mixed. By quantitatively measuring these three metrics, we show that interpolation-based data augmentation like mixup is very important in metric learning, given the difference between distributions at training and inference.</p><p>In summary, we make the following contributions:</p><p>1. We define a generic way of representing and interpolating labels, which allows straightforward extension of any kind of mixup to deep metric learning for a large class of loss functions. We develop our method on a generic formulation that encapsulates these functions (section 3). 2020; <ref type="bibr">Zhu et al., 2020b)</ref>. Pair-based losses capture data-to-data relations, but they are sensitive to noisy labels and outliers. They often involve terms where given constraints are satisfied, which produce zero gradients and do not contribute to training. This necessitates mining of hard examples that violate the constraints, like semi-hard <ref type="bibr" target="#b37">(Schroff et al., 2015)</ref> and distance weighted . By contrast, proxy-based losses use data-to-proxy relations, assuming proxies can capture the global structure of the embedding space. They involve less computations that are more likely to produce nonzero gradient, hence have less or no dependence on mining and converge faster.</p><p>Mixup Input mixup <ref type="bibr" target="#b56">(Zhang et al., 2018)</ref> linearly interpolates between two or more examples in the input space for data augmentation. Numerous variants take advantage of the structure of the input space to interpolate non-linearly, e.g. for images <ref type="bibr" target="#b54">(Yun et al., 2019;</ref><ref type="bibr" target="#b17">Kim et al., 2020a;</ref><ref type="bibr" target="#b13">Hendrycks et al., 2020;</ref><ref type="bibr" target="#b5">DeVries &amp; Taylor, 2017;</ref><ref type="bibr" target="#b32">Qin et al., 2020;</ref><ref type="bibr">Uddin et al., 2021)</ref>. Manifold mixup  interpolates intermediate representations instead, where the structure is learned. This can be applied to or assisted by decoding back to the input space <ref type="bibr" target="#b1">(Berthelot et al., 2018;</ref><ref type="bibr" target="#b25">Liu et al., 2018;</ref><ref type="bibr" target="#b58">Zhu et al., 2020a;</ref><ref type="bibr" target="#b42">Venkataramanan et al., 2021)</ref>. In both cases, corresponding labels are linearly interpolated too. Most studies are limited to cross-entropy loss for classification. Pairwise loss functions have been under-studied, as discussed below.</p><p>Interpolation for pairwise loss functions As discussed in subsection 3.3, interpolating target labels is not straightforward in pairwise loss functions. In deep metric learning, embedding expansion , HDML <ref type="bibr" target="#b57">(Zheng et al., 2019)</ref> and symmetrical synthesis  interpolate pairs of embeddings in a deterministic way within the same class, applying to pair-based losses, while proxy synthesis <ref type="bibr" target="#b76">(Gu et al., 2021)</ref> interpolates between classes, applying to proxy-based losses. None performs label interpolation, which means that <ref type="bibr" target="#b76">(Gu et al., 2021)</ref> risks synthesizing false negatives when the interpolation factor ? is close to 0 or 1.</p><p>In contrastive representation learning, MoCHi <ref type="bibr" target="#b16">(Kalantidis et al., 2020)</ref> interpolates anchor with negative embeddings but not labels and chooses ? ? [0, 0.5] to avoid false negatives. This resembles thresholding of ? at 0.5 in OptTransMix <ref type="bibr" target="#b58">(Zhu et al., 2020a)</ref>. Finally, i-mix <ref type="bibr">(Lee et al., 2021)</ref> and MixCo <ref type="bibr" target="#b19">(Kim et al., 2020b)</ref> interpolate pairs of anchor embeddings as well as their (virtual) class labels linearly. There is only one positive, while all negatives are clean, so it cannot take advantage of interpolation for relative weighting of positives/negatives per anchor .</p><p>By contrast, Metrix is developed for deep metric learning and applies to a large class of both pairbased and proxy-based losses. It can interpolate inputs, intermediate features or embeddings of anchors, (multiple) positives or negatives and the corresponding two-class (positive/negative) labels per anchor, such that relative weighting of positives/negatives depends on interpolation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MIXUP FOR METRIC LEARNING</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">PRELIMINARIES</head><p>Problem formulation We are given a training set X ? X , where X is the input space. For each anchor a ? X, we are also given a set P (a) ? X of positives and a set N (a) ? X of negatives.</p><p>The positives are typically examples that belong to the same class as the anchor, while negatives belong to a different class. The objective is to train the parameters ? of a model f : X ? R d that maps input examples to a d-dimensional embedding, such that positives are close to the anchor and negatives are far away in the embedding space. Given two examples x, x ? X , we denote by s(x, x ) the similarity between x, x in the embedding space, typically a decreasing function of Euclidean distance. It is common to 2 -normalize embeddings and define s(x, x ) := f (x), f (x ) , which is the cosine similarity. To simplify notation, we drop the dependence of f, s on ?.</p><p>Pair-based losses <ref type="bibr" target="#b46">Wang et al., 2014;</ref> use both anchors and positives/negatives in X, as discussed above. Proxy-based losses define one or more learnable proxies ? R d per class, and only use proxies as anchors  or as positives/negatives . To accommodate for uniform exposition, we extend the definition of similarity as s(v, x) := v, f (x) for v ? R d , x ? X (proxy anchors) and s(x, v) := f (x), v for x ? X , v ? R d (proxy positives/negatives). Finally, to accommodate for mixed embeddings in subsection 3.5, we define</p><formula xml:id="formula_0">s(v, v ) := v, v for v, v ? R d .</formula><p>Thus, we define s : (X ? R d ) 2 ? R over pairs of either inputs in X or embeddings in R d . We discuss a few representative loss functions below, before deriving a generic form.</p><p>Contrastive The contrastive loss  encourages positive examples to be pulled towards the anchor and negative examples to be pushed away by a margin m ? R. This loss is additive over positives and negatives, defined as:</p><formula xml:id="formula_1">cont (a; ?) := p?P (a) ?s(a, p) + n?N (a) [s(a, n) ? m] + .<label>(1)</label></formula><p>Multi-Similarity The multi-similarity loss  introduces relative weighting to encourage positives (negatives) that are farthest from (closest to) the anchor to be pulled towards (pushed away from) the anchor by a higher weight. This loss is not additive over positives and negatives:</p><formula xml:id="formula_2">MS (a; ?) := 1 ? log ? ? 1 + p?P (a) e ??(s(a,p)?m) ? ? + 1 ? log ? ? 1 + n?N (a) e ?(s(a,n)?m) ? ? .<label>(2)</label></formula><p>Here, ?, ? ? R are scaling factors for positives, negatives respectively.</p><p>Proxy Anchor The proxy anchor loss ) defines a learnable proxy in R d for each class and only uses proxies as anchors. For a given anchor (proxy) a ? R d , the loss has the same form as <ref type="formula" target="#formula_2">(2)</ref>, although similarity s is evaluated on R d ? X .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">GENERIC LOSS FORMULATION</head><p>We observe that both additive (1) and non-additive (2) loss functions involve a sum over positives P (a) and a sum over negatives N (a). They also involve a decreasing function of similarity s(a, p) for each positive p ? P (a) and an increasing function of similarity s(a, n) for each negative n ? N (a). Let us denote by ? + , ? ? this function for positives, negatives respectively. Then, non-additive functions differ from additive by the use of a nonlinear function ? + , ? ? on positive and negative terms respectively, as well as possibly another nonlinear function ? on their sum:</p><formula xml:id="formula_3">(a; ?) := ? ? ? ? + ? ? p?P (a) ? + (s(a, p)) ? ? + ? ? ? ? n?N (a) ? ? (s(a, n)) ? ? ? ? .<label>(3)</label></formula><p>With the appropriate choice for ?, ? + , ? ? , ? + , ? ? , this definition encompasses contrastive (1), multi-similarity (2) or proxy-anchor as well as many pair-based or proxy-based loss functions, as shown in <ref type="table" target="#tab_0">Table 1</ref>. It does not encompass the triplet loss <ref type="bibr" target="#b46">(Wang et al., 2014)</ref>, which operates on pairs of positives and negatives, forming triplets with the anchor. The triplet loss is the most challenging in terms of mining because there is a very large number of pairs and only few contribute to the loss. We only use function ? to accommodate for lifted structure (Oh <ref type="bibr" target="#b14">Hermans et al., 2017)</ref>, where ? (x) := [x] + is reminiscent of the triplet loss. We observe that multi-similarity  differs from binomial deviance <ref type="bibr" target="#b53">(Yi et al., 2014)</ref>  This generic formulation highlights the components of the loss functions that are additive over positives/negatives and paves the way towards incorporating mixup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">IMPROVING REPRESENTATIONS USING MIXUP</head><p>To improve the learned representations, we follow <ref type="bibr" target="#b56">(Zhang et al., 2018;</ref> in mixing inputs and features from intermediate network layers, respectively. Both are developed for classification.</p><p>Input mixup <ref type="bibr" target="#b56">(Zhang et al., 2018)</ref> augments data by linear interpolation between a pair of input examples. Given two examples x, x ? X we draw ? ? Beta(?, ?) as interpolation factor and mix</p><p>x with x using the standard mixup operation mix ? (x,</p><formula xml:id="formula_4">x ) := ?x + (1 ? ?)x . LOSS ANCHOR POS/NEG ? (x) ? + (x) ? ? (x) ? + (x) ? ? (x)</formula><p>Contrastive ) <ref type="bibr" target="#b14">(Hermans et al., 2017)</ref> X <ref type="bibr" target="#b53">(Yi et al., 2014)</ref> X  X X x 1 ? log(1 + x) 1 ? log(1 + x) e ??(x?m) e ?(x?m) Proxy anchor  proxy <ref type="bibr" target="#b7">(Goldberger et al., 2005)</ref> X For manifold mixup, we follow <ref type="bibr" target="#b42">(Venkataramanan et al., 2021)</ref> and mix either features of intermediate layer m or the final embeddings. Thus, we define three mixup types in total:</p><formula xml:id="formula_5">X X x x x ?x [x ? m]+ Lifted structure</formula><formula xml:id="formula_6">X [x]+ log(x) log(x) e ?x e x?m Binomial deviance</formula><formula xml:id="formula_7">X x log(1 + x) log(1 + x) e ??(x?m) e ?(x?m) Multi-similarity</formula><formula xml:id="formula_8">X x 1 ? log(1 + x) 1 ? log(1 + x) e ??(x?m) e ?(x?m) NCA</formula><formula xml:id="formula_9">X x ? log(x) log(x) e x e x ProxyNCA (Movshovitz-Attias et al., 2017) X proxy x ? log(x) log(x) e x e x ProxyNCA++ (Teh et al., 2020) X proxy x ? log(x) log(x) e x/T e x/T</formula><formula xml:id="formula_10">f ? (x, x ) := ? ? ? f (mix ? (x, x )), input mixup f m (mix ? (g m (x), g m (x ))), feature mixup mix ? (f (x), f (x )),</formula><p>embedding mixup.</p><p>(4) Function f ? : X 2 ? R d performs both mixup and embedding. We explore different mixup types in subsection B.4 of the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">LABEL REPRESENTATION</head><p>Classification In supervised classification, each example x ? X is assigned an one-hot encoded label y ? {0, 1} C , where C is the number of classes. Label vectors are also linearly interpolated: given two labeled examples (x, y), (x , y ), the interpolated label is mix ? (y, y ). The loss (crossentropy) is a continuous function of the label vector. We extend this idea to metric learning.</p><p>Metric learning Positives P (a) and negatives N (a) of anchor a are defined as having the same or different class label as the anchor, respectively. To every example in P (a) ? N (a), we assign a binary (two-class) label y ? {0, 1}, such that y = 1 for positives and y = 0 for negatives:</p><formula xml:id="formula_11">U + (a) := {(p, 1) : p ? P (a)} (5) U ? (a) := {(n, 0) : n ? N (a)}<label>(6)</label></formula><p>Thus, we represent both positives and negatives by U (a) := U + (a) ? U ? (a). We now rewrite the generic loss function (3) as:</p><formula xml:id="formula_12">(a; ?) := ? ? ? ? + ? ? (x,y)?U (a) y? + (s(a, x)) ? ? + ? ? ? ? (x,y)?U (a) (1 ? y)? ? (s(a, x)) ? ? ? ? . (7)</formula><p>Here, every labeled example (x, y) in U (a) appears in both positive and negative terms. However, because label y is binary, only one of the two contributions is nonzero. Now, in the presence of mixup, we can linearly interpolate labels exactly as in classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">MIXED LOSS FUNCTION</head><p>Mixup For every anchor a, we are given a set M (a) of pairs of examples to mix. This is a subset of (S(a) ? U (a)) ? U (a) where S(a) := (a, 1). That is, we allow mixing between positive-negative, positive-positive and negative-negative pairs, where the anchor itself is also seen as positive. We define the possible choices of mixing pairs M (a) in subsection 4.1 and we assess them in subsection B.4 of the Appendix. Let V (a) be the set of corresponding labeled mixed embeddings</p><formula xml:id="formula_13">V (a) := {(f ? (x, x ), mix ? (y, y )) : ((x, y), (x , y )) ? M (a), ? ? Beta(?, ?)},<label>(8)</label></formula><p>where f ? is defined by (4). With these definitions in place, the generic loss function over mixed examples takes exactly the same form as <ref type="formula">(7)</ref>, with only U (a) replaced by V (a):</p><formula xml:id="formula_14">(a; ?) := ? ? ? ? + ? ? (v,y)?V (a) y? + (s(a, v)) ? ? + ? ? ? ? (v,y)?V (a) (1 ? y)? ? (s(a, v)) ? ? ? ? ,<label>(9)</label></formula><p>where similarity s is evaluated on X ? R d for pair-based losses and on R d ? R d for proxy anchor. Now, every labeled embedding (v, y) in V (a) appears in both positive and negative terms and both contributions are nonzero for positive-negative pairs, because after interpolation, y ? [0, 1].</p><p>Error function Parameters ? are learned by minimizing the error function, which is a linear combination of the clean loss (3) and the mixed loss (9), averaged over all anchors</p><formula xml:id="formula_15">E(X; ?) := 1 |X| a?X (a; ?) + w (a; ?),<label>(10)</label></formula><p>where w ? 0 is the mixing strength. At least for manifold mixup, this combination comes at little additional cost, since clean embeddings are readily available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">ANALYSIS: MIXED EMBEDDINGS AND POSITIVITY</head><p>Let Pos(a, v) be the event that a mixed embedding v behaves as "positive" for anchor a, i.e., minimizing the loss (a; ?) will increase the similarity s(a, v). In subsection A.2 of the Appendix, we explain that this "positivity" is equivalent to ? (a; ?)/?s(a, v) ? 0. Under positive-negative mixing, i.e., M (a) ? U + (a) ? U ? (a), we then estimate the probability of Pos(a, v) as a function of ? in the case of multi-similarity (2) with a single mixed embedding v:</p><formula xml:id="formula_16">P(Pos(a, v)) = F ? 1 ? + ? ln ? 1 ? ? + m ,<label>(11)</label></formula><p>where F ? is the CDF of similarities s(a, v) between anchors a and mixed embeddings v with interpolation factor ?. In <ref type="figure">Figure 2</ref>, we measure the probability of Pos(a, v) as a function of ? in two ways, both purely empirically and theoretically by (11). Both measurements are increasing functions of ? of sigmoidal shape, where a mixed embedding is mostly positive for ? close to 1 and mostly negative for ? close to 0.  , we combine adaptive average pooling with max pooling, followed by a fully-connected layer to obtain the embedding of d = 512 dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss functions</head><p>We reproduce contrastive (Cont) , multi-similarity (MS) , proxy anchor (PA)  and Methods We compare our method, Metrix, with proxy synthesis (PS) <ref type="bibr" target="#b76">(Gu et al., 2021)</ref>, i-mix <ref type="bibr">(Lee et al., 2021)</ref> and MoCHi <ref type="bibr" target="#b16">(Kalantidis et al., 2020)</ref>. For PS, we adapt the official code 1 to PA on all datasets, and use it with PA only, because it is designed for proxy-based losses. PS has been shown superior to , although in different networks. MoCHi and i-mix are meant for contrastive representation learning. We evaluate using Recall@K :</p><p>For each test example taken as a query, we find its K-nearest neighbors in the test set excluding itself in the embedding space. We assign a score of 1 if an example of the same class is contained in the neighbors and 0 otherwise. Recall@K is the average of this score over the test set. ?. We measure P(Pos(a, v)) empirically as P(? MS (a; ?)/?s(a, v) ? 0) and theoretically by <ref type="formula" target="#formula_1">(11)</ref>, where F ? is again measured from data. We use embedding mixup on MS (2) on CUB200 at epoch 0, based on the setup of subsection 4.1.</p><p>Mixup settings For input mixup, we use the k hardest negative examples for each anchor (each example in the batch) and mix them with positives or with the anchor. We use k = 3 by default. For manifold mixup, we focus on the last few layers instead, where features and embeddings are compact, and we mix all pairs. We use feature mixup by default and call it Metrix/feature or just Metrix, while input and embedding mixup are called Metrix/input and Metrix/embed, respectively. For all mixup types, we use clean examples as anchors and we define a set M (a) of pairs of examples to mix for each anchor a, with their labels (positive or negative). By default, we mix positive-negative or anchornegative pairs, by choosing uniformly at random between M (a) :</p><formula xml:id="formula_17">= U + (a) ? U ? (a) and M (a) := S(a) ? U ? (a), respectively, where U ? (a)</formula><p>is replaced by hard negatives only for input mixup. More details are in subsection B.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">RESULTS</head><p>Improving the state of the art As shown in <ref type="table" target="#tab_3">Table 2</ref>, Metrix consistently improves the performance of all baseline losses (Cont, MS, PA, ProxyNCA++) across all datasets. More results in subsection B.3 of the Appendix reveal that the same is true for Metrix/input and Metrix/embed too. Surprisingly, MS outperforms PA and ProxyNCA++ under mixup on all datasets but SOP, where the three losses are on par. This is despite the fact that baseline PA outperforms MS on CUB200 and Cars-196, while ProxyNCA++ outperforms MS on SOP and In-Shop. Both contrastive and MS are significantly improved by mixup. By contrast, improvements on PA and ProxyNCA++ are marginal, which may be due to the already strong performance of PA, or further improvement is possible by employing different mixup methods that take advantage of the image structure.</p><p>In terms of Recall@1, our MS+Metrix is best overall, improving by 3.6% (67.8 ? 71.4) on CUB200, 1.8% (87.8 ? 89.6) on Cars196, 4.1% (76.9 ? 81.0) on SOP and 2.1% (90.1 ? 92.2) on In-Shop. The same solution sets new state of the art, outperforming the previously best PA by 1.7% (69.7 ? 71.4) on CUB200, MS by 1.8% (87.8 ? 89.6) on Cars196, ProxyNCA++ by 0.3% (80.7 ? 81.0) on SOP and SoftTriple by 1.2% (91.0 ? 92.2) on In-Shop. Importantly, while the previous state of the art comes from a different loss per dataset, MS+Metrix is almost consistently best across all datasets.</p><p>Alternative mixing methods In <ref type="table" target="#tab_5">Table 3</ref>, we compare Metrix/input with i-Mix <ref type="bibr">(Lee et al., 2021)</ref> and Metrix/embed with MoCHi <ref type="bibr" target="#b16">(Kalantidis et al., 2020)</ref> using contrastive loss, and with PS <ref type="bibr" target="#b76">(Gu et al., 2021)</ref> using PA. MoCHi and PS mix embeddings only, while labels are always negative. For i-Mix, we mix anchor-negative pairs (S(a) ? U ? (a)). For MoCHi, the anchor is clean and we mix negative-negative (U ? (a) 2 ) and anchor-negative (S(a) ? U ? (a)) pairs, where U ? (a) is replaced by k = 100 hardest negatives and ? ? (0, 0.5) for anchor-negative. PS mixes embeddings of different classes and treats them as new classes. For clean anchors, this corresponds to positive-negative (U + (a) ? U ? (a)) and negative-negative (U ? (a) 2 ) pairs, but PS also supports mixed anchors.  Computational complexity We study the computational complexity of Metrix in subsection B.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ablation study</head><p>We study the effect of the number k of hard negatives, mixup types (input, feature and embedding), mixing pairs and mixup strength w in subsection B.4 of the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">HOW DOES MIXUP IMPROVE REPRESENTATIONS?</head><p>We analyze how Metrix improves representation learning, given the difference between distributions at training and inference. As discussed in section 1, since the classes at inference are unseen at training, one might expect interpolation-based data augmentation like mixup to be even more important than in classification. This is so because, by mixing examples during training, we are exploring areas of the embedding space beyond the training classes. We hope that this exploration would possibly lead the model to implicitly learn a representation more appropriate for the test classes, if the distribution of the test classes lies near these areas.  By training with contrastive loss on CUB200 and then measuring on the test set, we achieve an alignment (lower the better) of 0.28 for contrastive loss, 0.28 for i-Mix <ref type="bibr">(Lee et al., 2021)</ref> and 0.19 for Metrix/input. MoCHi <ref type="bibr" target="#b16">(Kalantidis et al., 2020)</ref> and Metrix/embed achieve an alignment of 0.19 and 0.17, respectively. We also obtain a uniformity (lower the better) of ?2.71 for contrastive loss, ?2.13 for i-Mix and ?3.13 for Metrix/input. The uniformity of MoCHi and Metrix/embed is ?3.18 and ?3.25, respectively. This indicates that Metrix helps obtain a test distribution that is more uniform over the embedding space, where classes are better clustered and better separated.</p><p>Utilization The measures proposed by <ref type="bibr" target="#b47">(Wang &amp; Isola, 2020)</ref>  Because X ?X, we expect u(Q,X) &lt; u(Q, X), that is, the embedding space is better explored in the presence of mixup.</p><p>By using contrastive loss on CUB200, utilization drops from 0.41 to 0.32 when using Metrix. This indicates that test samples are indeed closer to mixed examples than clean in the embedding space. This validates our hypothesis that a representation more appropriate for test classes is implicitly learned during exploration of the embedding space in the presence of mixup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>Based on the argument that metric learning is binary classification of pairs of examples into "positive" and "negative", we have introduced a direct extension of mixup from classification to metric learning. Our formulation is generic, applying to a large class of loss functions that separate positives from negatives per anchor and involve component functions that are additive over examples.</p><p>Those are exactly loss functions that require less mining. We contribute a principled way of interpolating labels, such that the interpolation factor affects the relative weighting of positives and negatives. Other than that, our approach is completely agnostic with respect to the mixup method, opening the way to using more advanced mixup methods for metric learning.</p><p>We consistently outperform baselines using a number of loss functions on a number of benchmarks and we improve the state of the art using a single loss function on all benchmarks, while previous state of the art was not consistent in this respect. Surprisingly, this loss function, multisimilarity , is not the state of the art without mixup. Because metric learning is about generalizing to unseen classes and distributions, our work may have applications to other such problems, including transfer learning, few-shot learning and continual learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">ACKNOWLEDGEMENT</head><p>Shashanka's work was supported by the ANR-19-CE23-0028 MEERQAT project and was performed using the HPC resources from GENCI-IDRIS Grant 2021 AD011011709R1. Bill's work was partially supported by the EU RAMONES project grant No. 101017808 and was performed using the HPC resources from GRNET S.A. project pr011028. This work was partially done when Yannis was at Inria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A MORE ON THE METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 MIXED LOSS FUNCTION</head><p>Interpretation To better understand the two contributions of a labeled embedding (v, y) in V (a) to the positive and negative terms of (9), consider the case of positive-negative mixing pairs, <ref type="figure">Then, for ((x, y)</ref>, (x , y )) ? M (a), the mixed label is mix ? (y, y ) = mix ? (1, 0) = ? and <ref type="formula" target="#formula_14">(9)</ref> becomes</p><formula xml:id="formula_18">M (a) ? U + (a) ? U ? (a).</formula><formula xml:id="formula_19">(a; ?) = ? ? ? ? + ? ? (v,?)?V (a) ?? + (s(a, v)) ? ? + ? ? ? ? (v,?)?V (a) (1 ? ?)? ? (s(a, v)) ? ? ? ? . (13)</formula><p>Thus, the mixed embedding v is both positive (with weight ?) and negative (with weight 1 ? ?). Whereas for positive-positive mixing, that is, for M (a) ? U + (a) 2 , the mixed label is 1 and the negative term vanishes. Similarly, for negative-negative mixing, that is, for M (a) ? U ? (a) 2 , the mixed label is 0 and the positive term vanishes.</p><p>In the particular case of contrastive (1) loss, positive-negative mixing (13) becomes cont (a; ?) :=</p><formula xml:id="formula_20">(v,?)?V (a) ??s(a, v) + (v,?)?V (a) (1 ? ?)[s(a, v) ? m] + .<label>(14)</label></formula><p>Similarly, for multi-similarity (2),</p><formula xml:id="formula_21">MS (a; ?) := 1 ? log ? ? 1 + (v,?)?V (a) ?e ??(s(a,v)?m) ? ? + 1 ? log ? ? 1 + (v,?)?V (a) (1 ? ?)e ?(s(a,v)?m) ? ? .<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 ANALYSIS: MIXED EMBEDDINGS AND POSITIVITY</head><p>Positivity Under positive-negative mixing, (13) shows that a mixed embedding v with interpolation factor ? behaves as both positive and negative to different extents, depending on ?: mostly positive for ? close to 1, mostly negative for ? close to 0. The net effect depends on the derivative of the loss with respect to the similarity ? (a; ?)/?s(a, v): if the derivative is negative, then v behaves as positive and vice versa. This is clear from the chain rule</p><formula xml:id="formula_22">? (a; ?) ?v = ? (a; ?) ?s(a, v) ? ? s(a, v) ?v ,<label>(16)</label></formula><p>because ? s(a, v)/?v is a vector pointing in a direction that makes a, v more similar and the loss is being minimized. <ref type="figure">Let Pos(a, v)</ref> be the event that v behaves as "positive", i.e., ? (a; ?)/?s(a, v) ? 0 and minimizing the loss will increase the similarity s(a, v). Given a query q, the distance d to its nearest training embedding (clean or mixed) is smaller with mixup (b) than without (a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multi-similarity</head><p>By letting t := s(a, v) ? m, this condition is equivalent to</p><formula xml:id="formula_23">(1 ? ?)e ?t (1 + (1 ? ?)e ?t ) ? ?e ??t (1 + ?e ??t )<label>(19)</label></formula><p>(</p><formula xml:id="formula_24">1 ? ?)e ?t (1 + ?e ??t ) ? ?e ??t (1 + (1 ? ?)e ?t )<label>(20)</label></formula><p>(</p><formula xml:id="formula_25">1 ? ?)e ?t + ?(1 ? ?)e (???)t ? ?e ??t + ?(1 ? ?)e (???)t (21) e (?+?)t ? ? 1 ? ? (22) (? + ?)(s(a, v) ? m) ? ln ? 1 ? ? (23) s(a, v) ? 1 ? + ? ln ? 1 ? ? + m.<label>(24)</label></formula><p>Finally, the probability of Pos(a, v) as a function of ? is</p><formula xml:id="formula_26">P(Pos(a, v)) = F ? 1 ? + ? ln ? 1 ? ? + m ,<label>(25)</label></formula><p>where F ? is the CDF of similarities s(a, v) between anchors a and mixed embeddings v with interpolation factor ?.</p><p>In <ref type="figure">Figure 2</ref>, we measure the probability of Pos(a, v) as a function of ? in two ways. First, we measure the derivative ? MS (a; ?)/?s(a, v) for anchors a and mixed embeddings v over the entire dataset and we report the empirical probability of this derivative being non-positive versus ?. Second, we measure P <ref type="figure">(Pos(a, v)</ref>) theoretically using <ref type="formula" target="#formula_2">(25)</ref>, where the CDF of similarities s(a, v) is again measured empirically for a and v over the dataset, as a function of ?. Despite the simplifying assumption of a single positive and a single negative in deriving (25), we observe that the two measurements agree in general. They are both increasing functions of ? of sigmoidal shape, they roughly yield P <ref type="figure">(Pos(a, v)</ref>) ? 0.5 for ? ? 0.5 and they confirm that a mixed embedding is mostly positive for ? close to 1 and mostly negative for ? close to 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 MORE ON UTILIZATION</head><p>In subsection 4.3, we discuss that a representation more appropriate for test classes is implicitly learned during exploration of the embedding space in the presence of mixup. We provide an illustration of this exploration in <ref type="figure" target="#fig_4">Figure 3,</ref>   Training We train R-50 using AdamW <ref type="bibr" target="#b27">(Loshchilov &amp; Hutter, 2019)</ref> optimizer for 100 epochs with a batch size 100. The initial learning rate per dataset is shown in <ref type="table" target="#tab_8">Table 4</ref>. The learning rate is decayed by 0.1 for Cont and by 0.5 for MS and PA on CUB200 and Cars196. For SOP and In-Shop, we decay the learning rate by 0.25 for all losses. The weight decay is set to 0.0001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 MIXUP SETTINGS</head><p>In mixup for classification, given a batch of n examples, it is standard to form n pairs of examples by pairing the batch with a random permutation of itself, resulting in n mixed examples, either for input or manifold mixup. In metric learning, it is common to obtain n embeddings and then use all 1 2 n(n ? 1) pairs of embeddings in computing the loss. We thus treat mixup types differently.</p><p>Input mixup Mixing all pairs would be computationally expensive in this case, because we would compute 1 2 n(n ? 1) embeddings. A random permutation would not produce as many hard examples as can be found in all pairs. Thus, for each anchor (each example in the batch), we use the k hardest negative examples and mix them with positives or with the anchor. We use k = 3 by default.</p><p>Manifold mixup Originally, manifold mixup  focuses on the first few layers of the network. Mixing all pairs would then be even more expensive than input mixup, because intermediate features (tensors) are even larger than input examples. Hence, we focus on the last few layers instead, where features and embeddings are compact, and we mix all pairs. We use feature mixup by default and call it Metrix/feature or just Metrix, while input and embedding mixup are called Metrix/input and Metrix/embed, respectively. All options are studied in subsection B.4. Improving the state of the art <ref type="table">Table 5</ref> is an extension of <ref type="table" target="#tab_3">Table 2</ref> that includes all three mixup types (input, feature, embedding). It shows that not just feature mixup but all mixup types consistently improve the performance of all baseline losses (Cont, MS, PA, ProxyNCA++) across all datasets. It also shows that across all baseline losses and all datasets, feature mixup works best, followed by embedding and input mixup. This result confirms the findings of <ref type="table" target="#tab_10">Table 6</ref> on Cars196.</p><p>Qualitative results of retrieval <ref type="figure" target="#fig_5">Figure 4</ref> shows qualitative results of retrieval on CUB200 using Contrastive loss, with and without mixup. This dataset has large intra-class variations such as pose variation and background clutter. Baseline Contrastive loss may fail to retrieve the correct images due to these challenges. The ranking is improved in the presence of mixup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visualization of embedding space</head><p>We visualize CUB200 test examples for 10, 15 and 20 classes in the embedding space using Contrastive loss, with and without mixup in <ref type="figure" target="#fig_6">Figure 5</ref>. We observe that in the presence of mixup, the embeddings are more tightly clustered and more uniformly spread, despite the variations in pose and background in the test set. This finding validates our quantitative analysis of alignment and uniformity in subsection 4.3. Mixing pairs We study the effect of mixing pairs M (a), in particular, U + (a) 2 (positive-positive), U + (a) ? U ? (a) (positive-negative) and S(a) ? U ? (a) (anchor-negative), again using different mixup types. As shown in <ref type="table" target="#tab_10">Table 6</ref>, when using a single set of mixing pairs during training, positivenegative and anchor-negative consistently outperform the baseline, while positive-positive is actually outperformed by the baseline. This may be due to the lack of negatives in the mixed loss (9), despite the presence of negatives in the clean loss (3). Hence, we only use positive-negative and anchornegative by default, combined by choosing uniformly at random in each iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mixup types</head><p>We study the effect of mixup type (input, feature, embedding), when used alone. The set of mixing pairs is chosen from (positive-negative, anchor-negative) uniformly at random per iteration. As shown in both "hard negatives" and "mixing pairs" parts of <ref type="table" target="#tab_10">Table 6</ref>, our default feature mixup works best, followed by embedding and input mixup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mixup type combinations</head><p>We study the effect of using more than one mixup type (input, feature, embedding), chosen uniformly at random per iteration. The set of mixing pairs is also chosen from (positive-negative, anchor-negative) uniformly at random per iteration. As shown in <ref type="table" target="#tab_10">Table 6</ref>, mixing inputs, features and embeddings works best. Although this solution outperforms feature mixup alone by 0.2% Recall@1 (85.1 ? 85.3), it is computationally expensive because of using input mixup. The next best efficient choice is mixing features and embeddings, which however is worse than mixing features alone (84.7 vs. 85.1). This is why we chose feature mixup by default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mixup strength w</head><p>We study the effect of the mixup strength w in the combination of the clean and mixed loss (10) for different mixup types. As shown in <ref type="figure">Figure 6</ref>, mixup consistently improves the baseline and the effect of w is small, especially for input and embedding mixup. Feature mixup works best and is slightly more sensitive.</p><p>Ablation on CUB200 We perform additional ablations on CUB200 using R-50 with d = 128 by applying contrastive loss. All results are shown in <ref type="table">Table 7</ref>. One may draw the same conclusions as from <ref type="table" target="#tab_10">Table 6</ref> on Cars196 with d = 512, which confirms that our choice of hard negatives and mixup pairs is generalizable across different datasets and embedding sizes.</p><p>In particular, following the settings of subsection B.4, we observe in <ref type="table">Table 7</ref> that using k = 3 hard negatives for input mixup and all pairs for feature/embedding mixup achieves the best performance in terms of Recall@1. Similarly, using a single set of mixing pairs, positive-negative and anchornegative consistently outperform the baseline, whereas positive-positive is inferior than the baseline. Furthermore, combining positive-negative and anchor-negative pairs by choosing uniformly at random in each iteration achieves the best overall performance.   <ref type="table">Table 7</ref>: Ablation study of our Metrix using contrastive loss and R-50 with embedding size d = 128 on CUB200. R@K (%): Recall@K; higher is better.</p><p>We also study the effect of using more than one mixup type (input, feature,embedding), chosen uniformly at random per iteration. The set of mixing pairs is also chosen from (positive-negative, anchor-negative) uniformly at random per iteration in this study. From <ref type="table">Table 7</ref>, we observe that although mixing input, features and embedding works best with an improvement of 0.8% over feature mixup alone (64.5 ? 65.3), it is computationally expensive due to using input mixup. The next best choice is mixing features and embeddings, which is worse than using feature mixup alone (64.2 vs. 64.5). This confirms our choice of using feature mixup as default.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Metrix (= Metric Mix) allows an anchor to interact with positive (same class), negative (different class) and interpolated examples, which also have interpolated labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>only in the weights of the positive and negative terms. Proxy anchor (Kim et al., 2020c) is a proxy version of multi-similarity (Wang et al., 2019) on anchors and ProxyNCA (Movshovitz-Attias et al., 2017) is a proxy version of NCA (Goldberger et al., 2005) on positives/negatives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>ProxyNCA++ (Teh et al., 2020) and we evaluate them under different mixup types. For MS (2), following Musgrave et al. (2020), we use ? = 18, ? = 75 and m = 0.77. For PA, we use ? = ? = 32 and m = 0.1, as reported by the authors. Details on training are in subsection B.1 of the Appendix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(a, v)) empirical theoretical Figure 2: "Positivity" of mixed embeddings vs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>We estimate the probability of Pos(a, v) as a function of ? in the case of multisimilarity with a single embedding v obtained by mixing a positive with a negative:MS (a; ?) = 1 ? log 1 + ?e ??(s(a,v)?m) + 1 ? log 1 + (1 ? ?)e ?(s(a,v)?m) .(17)In this case, Pos(a, v) occurs if and only if ? MS (a; ?) ?s(a, v) = ??e ??(s(a,v)?m) (1 + ?e ??(s(a,v)?m) ) + (1 ? ?)e ?(s(a,v)?m) (1 + (1 ? ?)e ?(s(a,v)?m) ) Exploring the embedding space when using (a) only clean examples (b) clean and mixed examples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Mixing pairs Whatever the mixup type, we use clean examples as anchors and we define a set M (a) of pairs of examples to mix for each anchor a, with their labels (positive or negative). By default, we mix positive-negative or anchor-negative pairs, according to M (a) := U + (a) ? U ? (a) Retrieval results on CUB200 using Contrastive loss, with and without mixup. For each query, the top-5 retrieved images are shown. Images highlighted in green (red) are correctly (incorrectly) retrieved images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Embedding space visualization of CUB200 test examples of a given number of classes using Contrastive loss, with and without mixup.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Loss functions. Anchor/positive/negative: X: embedding of input example from training set X by f ; proxy: learnable parameter in R d ; T : temperature. All loss functions are encompassed by (3) using the appropriate definition of functions ?, ? + , ? ? , ? + , ? ? as given here. Manifold mixup (Verma et al., 2019) linearly interpolates between intermediate representations (features) of the network instead. Referring to 2D images, we define g m : X ? R c?w?h as the mapping from the input to intermediate layer m of the network and f m : R c?w?h ? R d as the mapping from intermediate layer m to the embedding, where c is the number of channels (feature dimensions) and</figDesc><table /><note>w ? h is the spatial resolution. Thus, our model f can be expressed as the composition f = f m ? g m .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc><ref type="bibr" target="#b23">Krause et al., 2013)</ref>, Stanford Online Products (SOP) and In-Shop Clothing retrieval (In-Shop)<ref type="bibr" target="#b26">(Liu et al., 2016)</ref> image datasets. More details are in subsection B.1.Network, features and embeddings We use Resnet-50<ref type="bibr" target="#b12">(He et al., 2016</ref>) (R-50) pretrained on Im-ageNet<ref type="bibr" target="#b35">(Russakovsky et al., 2015)</ref> as a backbone network. We obtain the intermediate representation (feature), a 7 ? 7 ? 2048 tensor, from the last convolutional layer. Following</figDesc><table><row><cell>4.1 SETUP</cell></row><row><cell>Datasets We experiment on Caltech-UCSD Birds (CUB200) (Wah et al., 2011), Stanford Cars</cell></row><row><cell>(Cars196) (</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Attias et al., 2017) 65.2 75.6 83.8 81.2 87.9 92.6 73.2 87.0</figDesc><table><row><cell></cell><cell>CUB200</cell><cell>CARS196</cell><cell></cell><cell>SOP</cell><cell></cell><cell></cell><cell>IN-SHOP</cell></row><row><cell>METHOD</cell><cell cols="8">R@1 R@2 R@4 R@1 R@2 R@4 R@1 R@10 R@100 R@1 R@10 R@20</cell></row><row><cell>Triplet (Weinberger &amp; Saul, 2009)</cell><cell cols="4">63.5 75.6 84.4 77.3 85.4 90.8 70.5 85.6</cell><cell>94.3</cell><cell cols="2">85.3 96.6</cell><cell>97.8</cell></row><row><cell>LiftedStructure (Oh Song et al., 2016)</cell><cell cols="4">65.9 75.8 84.5 81.4 88.3 92.4 76.1 88.6</cell><cell>95.2</cell><cell cols="2">88.6 97.6</cell><cell>98.4</cell></row><row><cell cols="6">ProxyNCA (Movshovitz-94.4</cell><cell cols="2">86.2 95.9</cell><cell>97.0</cell></row><row><cell>Margin (Wu et al., 2017)</cell><cell cols="4">65.0 76.2 84.6 82.1 88.7 92.7 74.8 87.8</cell><cell>94.8</cell><cell cols="2">88.6 97.0</cell><cell>97.8</cell></row><row><cell>SoftTriple (Qian et al., 2019)</cell><cell cols="4">67.3 77.7 86.2 86.5 91.9 95.3 79.8 91.2</cell><cell>96.3</cell><cell cols="2">91.0 97.6</cell><cell>98.3</cell></row><row><cell>D&amp;C (Sanakoyeu et al., 2019)  *</cell><cell cols="4">65.9 76.6 84.4 84.6 90.7 94.1 75.9 88.4</cell><cell>94.9</cell><cell cols="2">85.7 95.5</cell><cell>96.9</cell></row><row><cell>EPSHN (Xuan et al., 2020)  *</cell><cell cols="4">64.9 75.3 83.5 82.7 89.3 93.0 78.3 90.7</cell><cell>96.3</cell><cell cols="2">87.8 95.7</cell><cell>96.8</cell></row><row><cell>Cont (Hadsell et al., 2006)</cell><cell cols="4">64.7 75.9 84.6 81.6 88.2 92.7 74.9 87.0</cell><cell>93.9</cell><cell cols="2">86.4 94.7</cell><cell>96.2</cell></row><row><cell>+Metrix</cell><cell cols="4">67.4 77.9 85.7 85.1 91.1 94.6 77.5 89.1</cell><cell>95.5</cell><cell cols="2">89.1 95.7</cell><cell>97.1</cell></row><row><cell></cell><cell cols="4">+2.7 +2.0 +1.1 +3.5 +2.9 +1.9 +2.6 +2.1</cell><cell>+1.5</cell><cell cols="2">+2.7 +1.0</cell><cell>+0.9</cell></row><row><cell>MS (Wang et al., 2019)</cell><cell cols="4">67.8 77.8 85.6 87.8 92.7 95.3 76.9 89.8</cell><cell>95.9</cell><cell cols="2">90.1 97.6</cell><cell>98.4</cell></row><row><cell>+Metrix</cell><cell cols="4">71.4 80.6 86.8 89.6 94.2 96.0 81.0 92.0</cell><cell>97.2</cell><cell cols="2">92.2 98.5</cell><cell>98.6</cell></row><row><cell></cell><cell cols="4">+3.6 +2.8 +1.2 +1.8 +1.5 +0.7 +4.1 +2.2</cell><cell>+1.3</cell><cell cols="2">+2.1 +0.9</cell><cell>+0.2</cell></row><row><cell>PA (Kim et al., 2020c)  *</cell><cell cols="2">69.7 80.0 87.0 87.7 92.9 95.8</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PA (Kim et al., 2020c)</cell><cell cols="4">69.5 79.3 87.0 87.6 92.3 95.5 79.1 90.8</cell><cell>96.2</cell><cell cols="2">90.0 97.4</cell><cell>98.2</cell></row><row><cell>+Metrix</cell><cell cols="4">71.0 81.8 88.2 89.1 93.6 96.7 81.3 91.7</cell><cell>96.9</cell><cell cols="2">91.9 98.2</cell><cell>98.8</cell></row><row><cell></cell><cell cols="4">+1.3 +1.8 +1.2 +1.4 +0.7 +0.9 +2.2 +0.9</cell><cell>+0.7</cell><cell cols="2">+1.9 +0.8</cell><cell>+0.6</cell></row><row><cell>ProxyNCA++ (Teh et al., 2020)  *</cell><cell cols="4">69.0 79.8 87.3 86.5 92.5 95.7 80.7 92.0</cell><cell>96.7</cell><cell cols="2">90.4 98.1</cell><cell>98.8</cell></row><row><cell>ProxyNCA++ (Teh et al., 2020)</cell><cell cols="4">69.1 79.5 87.7 86.6 92.1 95.4 80.4 91.7</cell><cell>96.7</cell><cell cols="2">90.2 97.6</cell><cell>98.4</cell></row><row><cell>+Metrix</cell><cell cols="4">70.4 80.6 88.7 88.5 93.4 96.5 81.3 92.7</cell><cell>97.1</cell><cell cols="2">91.9 98.1</cell><cell>98.8</cell></row><row><cell></cell><cell cols="4">+1.3 +0.8 +1.0 +1.9 +0.9 +0.8 +0.6 +0.7</cell><cell>+0.4</cell><cell cols="2">+1.5 +0.0</cell><cell>+0.0</cell></row><row><cell>Gain over SOTA</cell><cell cols="4">+1.7 +1.8 +0.5 +1.8 +1.3 +0.9 +0.6 +0.7</cell><cell>+0.5</cell><cell cols="2">+1.2 +0.4</cell><cell>+0.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Improving the SOTA with our Metrix (Metrix/feature) using Resnet-50 with embedding size d = 512. R@K (%): Recall@K; higher is better.* : reported by authors. Bold black: best baseline (previous SOTA, one per column). Red: Our new SOTA. Gain over SOTA is over best baseline.MS: Multi-Similarity, PA: Proxy Anchor. Additional results are in subsection B.3 of the Appendix. In terms of Recall@1, Metrix/input outperforms i-Mix with anchor-negative pairs by 0.5% (65.8 ? 66.3) on CUB200, 0.9% (82.0 ? 82.9) on Cars196, 0.6% (75.2 ? 75.8) and 0.6% (87.1 ? 87.7) on In-Shop. Metrix/embed outperforms MoCHI with anchor-negative pairs by 1.2% (65.2 ? 66.4) on CUB200, 1.4% (82.5 ? 83.9) on Cars196, 0.9% (75.8 ? 76.7) and 1.2% (87.2 ? 88.4) on In-Shop. The gain over MoCHi with negative-negative pairs is significantly higher. Metrix/embed also outperforms PS by 0.4% (70.0 ? 70.4) on CUB200, 1% (87.9 ? 88.9) on Cars196, 1% (79.6 ? 80.6) on SOP and 1.3% (90.3 ? 91.6) on In-Shop.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Alignment and Uniformity In terms of quantitative measures of properties of the training and test distributions, we follow<ref type="bibr" target="#b47">Wang &amp; Isola (2020)</ref>. This work introduces two measures -alignment and uniformity (the lower the better) to be used both as loss functions (on the training set) and as evaluation metrics (on the test set). Alignment measures the expected pairwise distance between</figDesc><table><row><cell></cell><cell></cell><cell>CUB200</cell><cell>CARS196</cell><cell>SOP</cell><cell>IN-SHOP</cell></row><row><cell>METHOD</cell><cell cols="4">MIXING PAIRS R@1 R@2 R@4 R@1 R@2 R@4 R@1 R@10 R@100 R@1 R@10 R@20</cell></row><row><cell>Cont (Hadsell et al., 2006)</cell><cell>-</cell><cell cols="3">64.7 75.9 84.6 81.6 88.2 92.7 74.9 87.0</cell><cell>93.9 86.4 94.7 96.3</cell></row><row><cell>+ i-Mix (Lee et al., 2021)</cell><cell>anc-neg</cell><cell cols="3">65.8 76.2 84.9 82.0 88.5 93.2 75.2 87.3</cell><cell>94.2 87.1 95.4 96.1</cell></row><row><cell>+ Metrix/input</cell><cell cols="4">pos-neg / anc-neg 66.3 77.1 85.2 82.9 89.3 93.7 75.8 87.8</cell><cell>94.6 87.7 95.9 96.5</cell></row><row><cell>+MoCHi (Kalantidis et al., 2020)</cell><cell>neg-neg</cell><cell cols="3">63.1 74.3 83.8 76.3 84.0 89.3 68.9 83.1</cell><cell>91.8 81.8 91.9 93.9</cell></row><row><cell>+MoCHi (Kalantidis et al., 2020)</cell><cell>anc-neg</cell><cell cols="3">65.2 75.8 84.2 82.5 88.0 92.9 75.8 87.1</cell><cell>94.8 87.2 92.8 94.9</cell></row><row><cell>+Metrix/embed</cell><cell cols="4">pos-neg / anc-neg 66.4 77.6 85.4 83.9 90.3 94.1 76.7 88.6</cell><cell>95.2 88.4 95.4 96.9</cell></row><row><cell>PA (Kim et al., 2020c)</cell><cell>-</cell><cell cols="3">69.7 80.0 87.0 87.6 92.3 95.5 79.1 90.8</cell><cell>96.2 90.0 97.4 98.2</cell></row><row><cell>+PS (Gu et al., 2021)</cell><cell cols="4">pos-neg / neg-neg 70.0 79.8 87.2 87.9 92.8 95.6 79.6 90.9</cell><cell>96.4 90.3 97.4 98.0</cell></row><row><cell>+Metrix/embed</cell><cell cols="4">pos-neg / anc-neg 70.4 81.1 87.9 88.9 93.3 96.4 80.6 91.7</cell><cell>96.6 91.6 98.3 98.3</cell></row></table><note>positive examples in the embedding space. A small value of alignment indicates that the positive examples are clustered together. Uniformity measures the (log of the) expected pairwise similarity between all examples regardless of class, using a Gaussian kernel as similarity. A small value of uniformity indicates that the distribution is more uniform over the embedding space, which is particularly relevant to our problem. Meant for contrastive learning, (Wang &amp; Isola, 2020) use the same training and test classes, while in our case they are different.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Comparison of our Metrix/embed with other mixing methods using R-50 with embedding size d = 512. R@K (%): Recall@K; higher is better. PA: Proxy Anchor, PS: Proxy Synthesis.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>are limited to a single distribution or dataset, either the training set (as loss functions) or the test set (as evaluation metrics). It is more interesting to measure the extent to which a test example, seen as a query, lies near any of the training examples, clean or mixed. For this, we introduce the measure of utilization u(Q, X) of the training set X by the test set Q asUtilization measures the average, over the test set Q, of the minimum distance of a query q to a training example x ? X in the embedding space of the trained model f (lower is better). A low value of utilization indicates that there are examples in the training set that are similar to test examples. When using mixup, we measure utilization as u(Q,X), whereX is the augmented training set including clean and mixed examples over a number of epochs and f remains fixed.</figDesc><table><row><cell>u(Q, X) =</cell><cell>1 |Q|</cell><cell>q?Q</cell><cell>min x?X</cell><cell>f (q) ? f (x)</cell><cell>2</cell><cell>(12)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc><ref type="bibr" target="#b45">Wah et al., 2011)</ref> CARS196<ref type="bibr" target="#b23">(Krause et al., 2013</ref>) SOP (Oh Song et al., 2016 IN-SHOP<ref type="bibr" target="#b26">(Liu et al., 2016)</ref> </figDesc><table><row><cell cols="2">DATASET CUB200 (Objects birds</cell><cell>cars</cell><cell>household furniture</cell><cell>clothes</cell></row><row><cell># classes</cell><cell>200</cell><cell>196</cell><cell>22, 634</cell><cell>7, 982</cell></row><row><cell># training images</cell><cell>5, 894</cell><cell>8, 092</cell><cell>60, 026</cell><cell>26, 356</cell></row><row><cell># testing images</cell><cell>5, 894</cell><cell>8, 093</cell><cell>60, 027</cell><cell>26, 356</cell></row><row><cell># training classes</cell><cell>100</cell><cell>98</cell><cell>11, 318</cell><cell>3991</cell></row><row><cell># testing classes</cell><cell>100</cell><cell>98</cell><cell>11, 318</cell><cell>3991</cell></row><row><cell>sampling</cell><cell>random</cell><cell>random</cell><cell>balanced</cell><cell>balanced</cell></row><row><cell>samples per class</cell><cell>-</cell><cell>-</cell><cell>5</cell><cell>5</cell></row><row><cell>classes per batch</cell><cell>65  ?</cell><cell>70  ?</cell><cell>20</cell><cell>20</cell></row><row><cell>learning rate</cell><cell>1 ? 10 ?4</cell><cell>1 ? 10 ?4</cell><cell>3 ? 10 ?5</cell><cell>1 ? 10 ?4</cell></row><row><cell></cell><cell></cell><cell cols="3">where we visualize the embedding space using (a) only clean</cell></row><row><cell cols="5">train examples and (b) clean and mixed train examples. In case (a), the model is trained using only</cell></row><row><cell cols="5">clean examples, exploring a smaller area of the embedding space. In case (b), it is trained using both</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Statistics and settings for the four datasets we use in our experiments. ? : average. Dataset statistics are summarized inTable 4. Since the number of classes is large compared to the batch size in SOP and In-Shop, batches would rarely contain a positive pair when sampled uniformly at random. Hence, we use balanced sampling<ref type="bibr" target="#b55">(Zhai &amp; Wu, 2018)</ref>, i.e., a fixed number of classes and examples per class, as shown inTable 4. For fair comparison with baseline methods, images are randomly flipped and cropped to 224 ? 224 at training. At inference, we resize to 256 ? 256 and then center-crop to 224 ? 224.</figDesc><table><row><cell>mixed and clean examples, exploring a larger area. It is clear that the distance between a query and</cell></row><row><cell>its nearest training example (clean or mixup) is smaller in the presence of mixup. Utilization is the</cell></row><row><cell>average of this distance over the test set. This shows that the model implicitly learns a representation</cell></row><row><cell>closer the test example in the presence of mixup during training and it partially explains why mixup</cell></row><row><cell>leads to better performance.</cell></row><row><cell>B MORE ON EXPERIMENTS</cell></row><row><cell>B.1 SETUP</cell></row><row><cell>Datasets and sampling</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Ablation study of our Metrix using contrastive loss and R-50 with embedding size d = 512 on Cars196. R@K (%): Recall@K; higher is better. Effect of mixup strength for different mixup types using contrastive loss and R-50 with embedding size d = 512 on Cars196. Recall@K (%): higher is better.</figDesc><table><row><cell></cell><cell>90</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>baseline</cell><cell>input</cell></row><row><cell></cell><cell>88</cell><cell></cell><cell>embedding</cell><cell>feature</cell></row><row><cell>Recall@1</cell><cell>84 86</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>82</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>80</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell cols="2">mixup strength w</cell><cell></cell></row><row><cell>Figure 6:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/navervision/proxy-synthesis</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 ABLATIONS</head><p>We perform ablations on Cars196 using R-50 with d = 512, applying mixup on contrastive loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hard negatives</head><p>We study the effect of the number k of hard negatives using different mixup types. The set of mixing pairs is chosen from (positive-negative, anchor-negative) uniformly at random per iteration. We choose k = 3 for input mixup. For feature/embedding mixup, we mix all pairs in a batch by default, but also study k ? {20, 40}. As shown in <ref type="table">Table 6</ref>, k = 3 for input and all pairs for feature/embedding mixup works best. Still, using few hard negatives for feature/embedding mixup is on par or outperforms input mixup. All choices significantly outperform the baseline.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Beckham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sina</forename><surname>Honari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Farnoosh</forename><surname>Ghadiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Pal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.02709</idno>
		<title level="m">On adversarial mixup resynthesis</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Understanding and improving interpolation in autoencoders via an adversarial regularizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.07543</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Beyond triplet loss: a deep quadruplet network for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandelion</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Mane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autoaugment</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.09501</idno>
		<title level="m">Learning augmentation policies from data</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<title level="m">Improved regularization of convolutional neural networks with cutout</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Decaf: A deep convolutional activation feature for generic visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neighbourhood components analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep image retrieval: Learning global representations for image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Almaz?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Revaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Larlus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Symmetrical synthesis for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geonmo</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byungsoo</forename><surname>Ko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Proxy synthesis: Learning with synthetic classes for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geonmo</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byungsoo</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han-Gyu</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Augmix: A simple data processing method to improve robustness and uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lakshminarayanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07737</idno>
		<title level="m">defense of the triplet loss for person reidentification</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Hard negative mixing for contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bulent</forename><surname>Mert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noe</forename><surname>Sariyildiz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Pion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diane</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Larlus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Puzzle mix: Exploiting saliency and local statistics for optimal mixup</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jang-Hyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonho</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hosan Jeong, and Hyun Oh Song. Co-mixup: Saliency guided joint mixup with supermodular diversity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jang-Hyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonho</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Mixco: Mix-up contrastive learning for visual representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungnyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gihun</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangmin</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Se-Young</forename><surname>Yun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
		<respStmt>
			<orgName>NeurIPS Workshop on Self-Supervised Learning</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Proxy anchor loss for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Embedding expansion: Augmentation in embedding space for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byungsoo</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geonmo</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Big transfer (bit): General visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Puigcerver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>ICCVW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">I-mix: A domain-agnostic strategy for contrastive representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kibok</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Site Li, Ping Jia, and Jane You. Data augmentation via latent space interpolation for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingsheng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihui</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junliang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deepfashion: Powering robust clothes recognition and retrieval with rich annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Decoupled weight decay regularization. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">No fuss distance metric learning using proxies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A metric learning reality check</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Musgrave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Softtriple loss: Deep metric learning without triplet sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baigui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiemin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.11101</idno>
		<title level="m">Resizemix: Mixing data with preserved object information and true labels</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Sentence-bert: Sentence embeddings using siamese bertnetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Yao</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suvrit</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<title level="m">Contrastive learning with hard negative samples. ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Imagenet large scale visual recognition challenge. IJCV</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Divide and conquer the embedding space for metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artsiom</forename><surname>Sanakoyeu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vadim</forename><surname>Tschernezki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uta</forename><surname>Buchler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Improved deep metric learning with multi-class n-pair loss objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07685</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Proxynca++: Revisiting and revitalizing proxy neighborhood component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Eu Wern Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham W</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Saliencymix: A saliency guided data augmentation strategy for better regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F M</forename><surname>Shahab Uddin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sirazam</forename><surname>Monira Mst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wheemyung</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taechoong</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung-Ho</forename><surname>Bae</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Alignmix: Improving representation by interpolating aligned features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashanka</forename><surname>Venkataramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Avrithis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ewa</forename><surname>Kijak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Amsaleg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.15375</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Manifold mixup: Better representations by interpolating hidden states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Beckham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Najafi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Mitliagkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.04080</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<idno>CNS-TR-2011-001</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning fine-grained image similarity with deep ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuck</forename><surname>Rosenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingbin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multi-similarity loss with general pair weighting for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengke</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Sampling matters in deep embedding learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chao-Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kr?henb?hl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Distance metric learning with application to clustering with side-information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stuart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Improved embeddings with easy positive triplet mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Xuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abby</forename><surname>Stylianou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Pless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Deep metric learning for practical person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07737</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao-Yu</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.12649</idno>
		<title level="m">Classification is a strong baseline for deep metric learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Hardness-aware deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaodong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Automix: Mixup networks for sample interpolation via cooperative barycenter learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangliang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Fewer is more: A deep graph metric learning perspective using fewer proxies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuehua</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muli</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS, 2020b. Triplet</title>
		<imprint>
			<publisher>Weinberger &amp; Saul</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liftedstructure (oh</forename><surname>Song</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">65</biblScope>
		</imprint>
	</monogr>
	<note>9 75.8 84.5 81.4 88.3 92.4 76.1 88.6 95.2 88.6 97.6 98.4</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><surname>Proxynca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Movshovitz-Attias</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">65</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Margin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Softtriple (qian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">67</biblScope>
		</imprint>
	</monogr>
	<note>3 77.7 86.2 86.5 91.9 95.3 79.8 91.2 96.3 91.0 97.6 98.3</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>D&amp;amp;c (sanakoyeu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Epshn (xuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Proxynca++</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Cont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hadsell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ms (wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pa (kim</surname></persName>
		</author>
		<idno>69.7 80.0 87.0 87.7 92.9</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pa (kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Proxynca++</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">(</forename><surname>Proxynca++</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Teh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Red: Our new SOTA. Gain over SOTA is over best baseline. MS: Multi-Similarity, PA: Proxy Anchor and M (a) := S(a) ? U ? (a), respectively, where U ? (a) is replaced by hard negatives only for input mixup. The two options are combined by choosing uniformly at random in each iteration</title>
	</analytic>
	<monogr>
		<title level="m">Table 5: Improving the SOTA with our Metrix (Metrix/feature) using Resnet-50 with embedding size d = 512. R@K (%): Recall@K; higher is better</title>
		<imprint/>
	</monogr>
	<note>* : reported by authors. Bold black: best baseline (previous SOTA, one per column). More options are studied in subsection B.4.</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Hyper-parameters For any given mixup type or set of mixup pairs, the interpolation factor ? is drawn from Beta(?, ?) with ? = 2. We empirically set the mixup strength (10) to w = 0.4 for positive-negative pairs and anchor-negative pairs</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">MORE RESULTS Computational complexity On CUB200 dataset, using a batch size of 100 on an NVIDIA RTX</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">The 39% increase in complexity is reasonable for 3.6% increase in R@1. Furthermore, the average training time in ms/batch is 483 for baseline PA, 965 for PA+Metrix and 1563 for PS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gpu ;</forename><surname>Ti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Metrix outperform PS by 0.4% and 1.3% in terms of R@1 and R@2 respectively</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>the average training time in ms/batch is 586 for MS and 817 for MS+Metrix. Table 3). At inference, the computational cost is equal for all methods</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
