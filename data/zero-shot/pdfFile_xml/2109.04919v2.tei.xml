<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">EmoWOZ: A Large-Scale Corpus and Labelling Scheme for Emotion Recognition in Task-Oriented Dialogue Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shutong</forename><surname>Feng</surname></persName>
							<email>fengs@hhu.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Heinrich Heine University D?sseldorf Universit?tsstra?e 1</orgName>
								<address>
									<postCode>40225</postCode>
									<settlement>D?sseldorf</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nurul</forename><surname>Lubis</surname></persName>
							<email>lubis@hhu.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Heinrich Heine University D?sseldorf Universit?tsstra?e 1</orgName>
								<address>
									<postCode>40225</postCode>
									<settlement>D?sseldorf</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Geishauser</surname></persName>
							<email>geishaus@hhu.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Heinrich Heine University D?sseldorf Universit?tsstra?e 1</orgName>
								<address>
									<postCode>40225</postCode>
									<settlement>D?sseldorf</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsien-Chin</forename><surname>Lin</surname></persName>
							<email>linh@hhu.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Heinrich Heine University D?sseldorf Universit?tsstra?e 1</orgName>
								<address>
									<postCode>40225</postCode>
									<settlement>D?sseldorf</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Heck</surname></persName>
							<email>heckmi@hhu.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Heinrich Heine University D?sseldorf Universit?tsstra?e 1</orgName>
								<address>
									<postCode>40225</postCode>
									<settlement>D?sseldorf</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carel</forename><surname>Van Niekerk</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Heinrich Heine University D?sseldorf Universit?tsstra?e 1</orgName>
								<address>
									<postCode>40225</postCode>
									<settlement>D?sseldorf</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milica</forename><surname>Ga?i?</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Heinrich Heine University D?sseldorf Universit?tsstra?e 1</orgName>
								<address>
									<postCode>40225</postCode>
									<settlement>D?sseldorf</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">EmoWOZ: A Large-Scale Corpus and Labelling Scheme for Emotion Recognition in Task-Oriented Dialogue Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.5281/zenodo.5865437</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Emotion Recognition in Conversations, Task-oriented Dialogues</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The ability to recognise emotions lends a conversational artificial intelligence a human touch. While emotions in chit-chat dialogues have received substantial attention, emotions in task-oriented dialogues remain largely unaddressed. This is despite emotions and dialogue success having equally important roles in a natural system. Existing emotion-annotated task-oriented corpora are limited in size, label richness, and public availability, creating a bottleneck for downstream tasks. To lay a foundation for studies on emotions in task-oriented dialogues, we introduce EmoWOZ, a large-scale manually emotion-annotated corpus of task-oriented dialogues. EmoWOZ is based on MultiWOZ, a multi-domain task-oriented dialogue dataset. It contains more than 11K dialogues with more than 83K emotion annotations of user utterances. In addition to Wizard-of-Oz dialogues from MultiWOZ, we collect human-machine dialogues within the same set of domains to sufficiently cover the space of various emotions that can happen during the lifetime of a data-driven dialogue system. To the best of our knowledge, this is the first large-scale open-source corpus of its kind. We propose a novel emotion labelling scheme, which is tailored to task-oriented dialogues. We report a set of experimental results to show the usability of this corpus for emotion recognition and state tracking in task-oriented dialogues.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Incorporating human intelligence into conversational artificial intelligence (AI) has been a challenging and long-term goal <ref type="bibr" target="#b36">(Picard, 1997)</ref>. Emotional intelligence, defined as the ability to regulate, perceive, assimilate, and express emotions, is a key component of general intelligence <ref type="bibr" target="#b31">(Mayer et al., 1999)</ref>. Such emotion awareness can help the conversational AI generate more emotionally and semantically appropriate responses . Dialogue systems generally fall into two classes. Taskoriented systems converse with users to help complete tasks determined by user goals. Chit-chat systems are set up to mimic the unstructured conversations or 'chats' characteristic of human-human interaction <ref type="bibr" target="#b20">(Jurafsky and Martin, 2009</ref>). Chat-oriented systems are typically modelled in a supervised fashion with large available corpora <ref type="bibr" target="#b44">(Vinyals and Le, 2015)</ref>. In contrast, task-oriented systems track the user goal throughout the dialogue and a policy is typically trained via some form of reinforcement learning (RL) to conduct dialogue towards successful goal completion <ref type="bibr" target="#b46">(Young, 2002)</ref>. Moreover, the scope of the dialogue can also be extended during this process, e.g. by adding new domains to the dialogue system <ref type="bibr" target="#b28">(Madotto et al., 2021)</ref>. Consequently, the distribution of data from which a task-oriented system learns can change. Emotions appear in both chit-chat and task-oriented dialogues. However, the cause of emotion may differ as well as their role. Chit-chat dialogues are a means to express emotion. Speakers may discuss emotional ex-periences <ref type="bibr" target="#b23">(Li et al., 2017)</ref>, or topics that induce emotions such as news broadcasts <ref type="bibr" target="#b27">(Lubis et al., 2017)</ref>. In task-oriented dialogues, the user is primarily interested in achieving their goal. While an emotional situation may be a reason to interact with the system, e.g. the user just missed a flight and needs to rebook one, the emotion the user exhibits is more often a reaction to potential goal completion or failure. Since the emotion is centred around the user goal, it is more contextual and subtle. Therefore, besides inferring emotional states from dialogue utterances, an agent also needs to reason about emotion-generating situations <ref type="bibr" target="#b37">(Poria et al., 2021)</ref>. Substantial research efforts in emotion recognition in conversations (ERC) have been invested in chit-chat dialogues <ref type="bibr" target="#b15">Ghosal et al., 2020)</ref>. There are several public ERC corpora containing chitchat dialogues <ref type="bibr" target="#b23">(Li et al., 2017;</ref><ref type="bibr" target="#b47">Zahiri and Choi, 2018)</ref> and conversational data from social media <ref type="bibr" target="#b48">(Zhou and Wang, 2018)</ref>. These corpora can tremendously accelerate the building of emotional chatbots using data-driven approaches . In task-oriented dialogues, recognising emotions is equally important but remains largely unaddressed. Using RL to optimise a dialogue policy necessitates a feedback signal. While it is accepted that the feedback signal needs to correlate with user satisfaction <ref type="bibr" target="#b43">(Ultes et al., 2017)</ref>, this feedback signal is often based on hand-coded rules. Could an emotional model instead be directly used to provide such a feedback signal? Could it also be used to support emotion-aware natural language generation <ref type="bibr" target="#b29">(Mairesse and Walker, 2007)</ref>, or even improve dialogue state tracking through multi-task learning <ref type="bibr" target="#b18">(Heck et al., 2020a)</ref>? Existing corpora are small in size, and labels are limited to sentiment polarity, creating a bottleneck, so these questions remain largely unexplored. In this work, we present EmoWOZ, a largescale manually labelled corpus for emotion in taskoriented dialogues. EmoWOZ is derived from Multi-WOZ <ref type="bibr" target="#b3">(Budzianowski et al., 2018)</ref>, one of the largest multi-domain corpora and the benchmark dataset for various dialogue modelling tasks, from dialogue state tracking <ref type="bibr" target="#b19">(Heck et al., 2020b;</ref><ref type="bibr" target="#b25">Lin et al., 2021)</ref> to policy optimisation <ref type="bibr" target="#b17">(He et al., 2022)</ref>. We also collected and annotated human-machine dialogues as a complement. Our contributions are as follows:</p><p>? We construct a corpus containing task-oriented dialogues with emotion labels, comprising more than 11K dialogues and 83K annotated user utterances. To the best of our knowledge, this is the first large-scale open-source corpus &amp; code 1 for emotion recognition in task-oriented dialogues.</p><p>? We propose a novel labelling scheme, containing 7 emotion classes, adapted from the Ortony, Clore and Collins (OCC) model <ref type="bibr" target="#b32">(Ortony et al., 1988)</ref>, specifically tailored to capture an array of emotions in relation to user goals in task-oriented dialogue.</p><p>? We report a series of emotion recognition baseline results to show the usability of this corpus. We also empirically show that the emotion labels can be used to improve the performance of other task-oriented dialogue system modules, in this case, a dialogue state tracker (DST).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Emotion Models</head><p>Within the area of affective computing, emotion models are commonly grouped into two types: dimensional models and categorical models. Dimensional models describe emotions as a combination of values across a set of dimensions. The longest established dimensions are valence and arousal, as proposed by <ref type="bibr" target="#b39">Russell (1980)</ref> in the circumplex model of emotion. Valence measures the positivity, while arousal measures the activation. Happiness, for example, is an emotion with positive valence and high activation. Additional dimensions, namely dominance and expectancy <ref type="bibr" target="#b14">(Fontaine et al., 2007)</ref>, have also been proposed to further describe and distinguish complex emotions.</p><p>Categorical models group emotions into distinct categories. The "Big six" theory is one of the most wellknown theories on universal emotions. Based on studies of facial expressions, <ref type="bibr" target="#b11">Ekman (1992)</ref> proposed six 1 https://doi.org/10.5281/zenodo.5865437 basic human emotions which are influenced neither by culture nor other social influences: happiness, anger, sadness, disgust, fear, surprise. <ref type="bibr" target="#b33">Parrott (2001)</ref> conceptualised over a hundred emotions into a tree-structured list and identified six primary emotions from it. <ref type="bibr" target="#b32">Ortony et al. (1988)</ref> proposed the Ortony, Clore and Collins (OCC) emotion model, which is explicitly developed for implementation in computers. In the OCC model, 22 emotion types are described as a valenced reaction to one of three cognitive elicitors: consequences of events, actions of agents, or aspects of objects. For example, dissatisfied is specified as disapproving of someone else's blameworthy action. These cognitive aspects are in line with the cognitive process of a computational agent, making the OCC model suitable for building emotional artificial agents. However, the use of this model for dialogue agents is not yet widespread. In a similar spirit, <ref type="bibr" target="#b16">Gross and Thompson (2007)</ref> formulated the process of emotion regulation as the attention, appraisal, and response originated from various situations.</p><p>Although there are corpora with real-valued annotation of multiple emotion dimensions <ref type="bibr" target="#b37">(Preo?iuc-Pietro et al., 2016;</ref><ref type="bibr" target="#b4">Buechel and Hahn, 2017)</ref>, researchers often focus on the valence dimension and annotate with discrete classes <ref type="bibr" target="#b42">(Socher et al., 2013)</ref>, often called sentiment polarity. Emotion datasets also consider emotions from various categorical models in the annotation scheme <ref type="bibr" target="#b23">(Li et al., 2017;</ref>, but some datasets have domain-specific labels. For instance, <ref type="bibr" target="#b48">Zhou and Wang (2018)</ref> leverage common emojis in social media posts. The Topical-Chat dataset <ref type="bibr" target="#b15">(Gopalakrishnan et al., 2019)</ref> introduces curious to dive deeper in addition to other basic emotions.</p><p>In this work, we propose a novel set of 7 emotions and motivate it using OCC model as the basis. We aim for this scheme to capture the cognitive context of emotions while retaining the simplicity of labels that facilitates large-scale crowd-sourcing of emotion annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Emotion Dialogue Datasets</head><p>Early works on ERC focus on speech signals <ref type="bibr" target="#b7">(Cowie et al., 2001;</ref><ref type="bibr" target="#b38">Riccardi and Hakkani-T?r, 2005;</ref><ref type="bibr" target="#b5">Carri?n and L?pez-C?zar, 2008)</ref>. More recently, there are increasing number of text-based ERC datasets focusing on chit-chat dialogue. Chit-chat dialogue lends itself well to affective computing research due to its open-domain set-up, where conversation topics are diverse and not restricted to a particular task. One of the largest such corpora is DailyDialog <ref type="bibr" target="#b23">(Li et al., 2017)</ref>, which contains conversations between English learners on various topics ranging from relationships to money. Other similar datasets include EmoryNLP <ref type="bibr" target="#b47">(Zahiri and Choi, 2018)</ref> and MELD . They contain multiparty dialogues from the TV show Friends. TV recordings in talk show format have also been utilised to collect emotion-rich and topic-specific dialogues (Lubis  <ref type="table">Table 1</ref>: Comparison of our corpus to similar corpora. Values in bold indicate the best value for each metric. For label type, "Emo" stands for emotion categories and "Sent" stands for sentiment polarities. For corpora providing both emotion and sentiment labels, agreement metrics are measured for emotion labels. DSTC1, SentiVA, and TML refer to works by <ref type="bibr" target="#b41">Shi and Yu (2018)</ref>, <ref type="bibr" target="#b40">Saha et al. (2020)</ref>, and <ref type="bibr" target="#b45">Wang et al. (2020</ref><ref type="bibr">Wang et al. ( ), respectively. et al., 2015</ref>. Unfortunately, existing data suitable for task-oriented corpora, such as customer service chat logs, are typically not within the public domain. There also exist a few corpora concerning the affective aspect of task-oriented dialogues. <ref type="bibr" target="#b45">Wang et al. (2020)</ref> proposed a large-scale sentiment classification corpus containing customer service dialogues in Chinese. However, this dataset is not publicly available. <ref type="bibr" target="#b40">Saha et al. (2020)</ref> annotated dialogues from bAbI <ref type="bibr" target="#b0">(Bordes et al., 2017)</ref> with sentiment for policy optimisation. Since dialogues are machine-generated, it is unclear how well these emotions match real human emotions and whether sentiment on its own sufficiently captures emotional nuances in task-oriented dialogue. In a similar spirit, <ref type="bibr" target="#b41">Shi and Yu (2018)</ref> annotated the DSTC1 dataset with user sentiment. Unfortunately, containing only 50 dialogues, the dataset is very limited in terms of coverage and application in machine learning. To summarise, existing corpora are either limited in size or not publicly available, limiting further works on emotions in task-oriented dialogue systems. Furthermore, their annotation schemes focus on sentiment polarities, overlooking the effect of goals on users' emotional states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Dataset Construction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Task-oriented Dialogues</head><p>MultiWOZ: Our dataset covers the entirety of Multi-WOZ, which was constructed using the Wizard-of-Oz framework <ref type="bibr" target="#b21">(Kelley, 1984)</ref>. It contains over 10k dialogues. Each dialogue was completed by two workers, each acting as the user or the operator, to achieve specified goals such as information retrieval or making reservations. There are 7 domains in total. A single dialogue or even a single turn can span multiple domains. Complementary Dialogues: We envisage emotions as learning signal for dialogue system optimisation. Since emotions in task-oriented dialogue systems can be a direct effect of the user perception of the ability of the system to fulfill their goal, the policy performance can largely influence emotion distribution. During the life span of a data-driven task-oriented dialogue system, the distributions of dialogues and emotions may change as the policy learns and improves over time. An immediate impact of such a distributional shift is the increase in the number of negative emotions due to failed dialogues during the early stages of learning. Therefore, in addition to the human wizard policy in MultiWOZ, it is important that EmoWOZ covers a variety of dialogues which represent the emotions throughout such a dialogue system life span. We complement MultiWOZ with human-machine dialogues from a machine-generated policy (DialMAGE). To elicit more genuine reactions, we let subjects directly interact with a machinegenerated policy instead of human wizards trying to make machine-like mistakes. We launched a dialogue interactive task on Amazon Mechanical Turk, where workers are asked to retrieve information by interacting with the learning policy. We start with a policy trained in a supervised fashion on MultiWOZ that achieved a task success rate of 55% when evaluated with the ConvLab-2 <ref type="bibr" target="#b50">(Zhu et al., 2020)</ref> rule-based user simulator. Throughout the task, the policy learned and improved as user feedback on task success is used for further training using RL. The policy reached a final human-rated success rate of 73%. Similar to , the policy uses a recurrent neural network (RNN) based model to produce multiple actions in a single turn, followed by the ConvLab-2 template-based NLG module for response generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Emotion Annotation Scheme</head><p>EmoWOZ focuses on user emotions rather than system ones. We believe recognising user emotions is the starting point for building emotion-aware task-oriented dialogue systems. We use the OCC model to arrive at  specific emotion categories. For that, we consider the following aspects: 1. Elicitor or cause: The OCC model defines three main elicitors of emotion: events, agents, and objects.</p><p>In task-oriented dialogues, events describe the situation which brings the user to interact with the system. For example, a user may be looking for a hotel for an upcoming trip or asking for the police information after a robbery. Agents are participants of the dialogue: the user and the system. Objects are equal to entities being talked about in the dialogue, such as the recommended hotel or the nearest police station. In our dataset, an object is always associated with either the operator, who proposes it, or an event, which drives the need for it. For this reason, we do not consider the object as an elicitor alone. On the other hand, within the agent category, it is important to distinguish between the user and the system. Therefore, we arrive at three elicitors for our annotation scheme: 1) the system, 2) the user, and 3) events (or facts).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Valence:</head><p>In essence, the OCC model describes emotion as a valenced reaction towards an elicitor. Valence is a dimension which expresses the positivity or negativity of emotion. For example, successfully achieving a goal is likely to bring positive valence, while a misunderstanding with an agent is likely to cause negative valence. As EmoWOZ will demonstrate in a later section, valence is highly related to task success or failure, making it an important signal for a task-oriented system. We distinguish neutral and emotional utterances, and further separate emotional utterances into those with negative and positive valence. 3. Conduct: Conduct is not a part of the OCC model, but given the rising concern of how humans behave when interacting with virtual assistants (Cercas Curry and Rieser, 2018), we decided to include it. Conduct describes the politeness of users and is usually associated with emotional acts. Politeness can indicate the degree of valence. For example, the user can express very strong dissatisfaction through rudeness. It also helps distinguish emotions such as those associ-ated with apology or abuse, which are both intrinsically negative.</p><p>Considering all combinations of these three aspects for annotation leads to a large number of classes. When choosing the final set of classes we were guided by whether or not a particular emotion category occurs in the database and the potential impact of that emotion category on the dialogue policy. We also carried out several trials and considered the ease of communicating to the annotator how to label such instances. We finally arrive at a set of 6 non-neutral emotion categories: An emotion elicited by the operator is defined as satisfied if it is positive, and dissatisfied if it is negative. Positive emotion caused by an event gives us excited, and negative fearful. In terms of negative emotions expressed towards the system, we consider user conduct to distinguish between dissatisfied and abusive, since they require very different responses from the system <ref type="bibr" target="#b8">(Curry and Rieser, 2019)</ref>. In terms of the negative emotions that users may direct toward themselves, we single out apologetic behaviours since it features in human-human information-seeking dialogues. Emotion categories and their attributes in the abovementioned aspects and their relation to the original OCC model are shown in <ref type="table" target="#tab_2">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Emotion Annotation Setup</head><p>We crowd-source the emotion annotation on Amazon Mechanical Turk in a controlled manner. As suggested by <ref type="bibr" target="#b5">Carri?n and L?pez-C?zar (2008)</ref> to improve the annotation quality, workers are shown the dialogue history up to the utterance they are required to label. Each emotion category is followed by a list of emotion words that best fit into the category and an explanation. Due to the high subjectivity in the emotion annotation <ref type="bibr" target="#b9">(Devillers et al., 2005)</ref>, each dialogue is annotated by three different workers. We also implement several measures to ensure the quality of the emotion labels:</p><p>Qualification tests: The test contains fifteen questions, seven are straight-forward and eight are more complex. The test also serves as a tutorial. For diffi-cult questions, hints are provided to guide the workers to identify implicit emotions and use contextual information (see Appendix B).</p><p>Hidden tests: We pre-label more than 1000 utterances containing obvious emotions and use them as sanity checks. The hidden tests serve as an indicator of worker reliability. If a worker scores above 80% on the hidden tests, we assume that the worker is reliable. Otherwise, the workers' submission is subject to manual review.</p><p>Review for outliers: We use a simple lexicon-based recogniser and manually annotate a small batch to have an estimate of the overall emotion distribution. If the label distribution in a worker's submissions deviates substantially from our prior belief, we mark them for manual review.</p><p>Annotation limit: We limit each worker to annotate at most 500 dialogues to ensure a diversity of workers and to avoid that workers adapt to our approval policy. Overall, we had 215 workers, each annotating 160 dialogues on average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">EmoWOZ Characteristics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Linguistic Style</head><p>Dialogues from MultiWOZ and DialMAGE differ linguistically. As seen in <ref type="table" target="#tab_4">Table 3</ref>, DialMAGE has longer dialogues than MultiWOZ as it takes longer for the machine-generated policy to accomplish user goals. Meanwhile, users use simpler and shorter sentences when talking to a machine. Especially when the system under-performs, users are discouraged to converse with it (see sample dialogues with annotations in Appendix C). We will analyse the impact of these differences on emotion recognition in Section 5.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Emotion Distribution</head><p>According to <ref type="table" target="#tab_6">Table 4</ref>, the most common non-neutral emotion in EmoWOZ is satisfied, followed by dissatisfied. This is expected in task-oriented dialogues as users mainly express emotion in relation to their goals. While MultiWOZ contains more neutral utterances, it has a more diverse emotion distribution than DialMAGE. MultiWOZ contributes most satisfied utterances whereas DialMAGE contributes most dissatisfied utterances. This is in line with their respective dialogue-generating setup.</p><p>Sometimes users also express emotion to engage or provoke the operator. MultiWOZ contains more apologetic and less abusive utterances than DialMAGE, suggesting that users tend to be more polite when talking to human operators. Dialogues from MultiWOZ also contain more event-elicited emotions (fearful and excited) than DialMAGE. Users are more talkative when conversing with human operators. Users may describe a miserable situation they were experiencing, hoping to be helped and comforted. A human operator would naturally show empathy. In MultiWOZ, the operator sometimes asks if the user is alright when the user is looking for help from a robbery. When talking to machines, users tend not to express such chit-chat-style emotions due to the expected incapability of the machine to reciprocate. This indicates that an emotionally intelligent agent will allow dialogues that are emotionally richer and more nuanced, even in a task-oriented setting.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Inter-annotator Agreement</head><p>We measure the inter-annotator agreement by computing Fleiss' Kappa <ref type="bibr" target="#b13">(Fleiss, 1971</ref>). Fleiss' Kappa for EmoWOZ is 0.602, suggesting a substantial agreement. Fleiss' Kappa for MultiWOZ is 0.611, higher than 0.465 for DialMAGE. Emotions in DialMAGE are more challenging to annotate because users express emotion less explicitly when they know that they are talking to a machine that does not react to emotions. Annotators often have to infer the user's implicit emotions from dialogue history, for example, based on repetitions or misunderstanding. Among all utterances, 72.1% see a full agreement among three annotators, 26.4% see a partial agreement, and 1.5% see no agreement. The count of each case in each subset can be found in Appendix D. Utterances for which no agreement is reached are resolved manually. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the confusion matrix between annotators' labels and the golden labels. Most disagreements occur between non-neutral emotions and neutral, as well as abusive and dissatisfied. A reasonable explanation is that workers adopt different valence or impoliteness thresholds when they make decisions. Note that dissatisfied is rarely confused with abusive, but rather with neutral, suggesting that the ambiguity lies in when an expression of dissatisfaction is considered  <ref type="table">Table 5</ref>: Comparison of baseline models. We report the F1 for each emotion label (Neutral, Fearful, Dissatisfied, Apologetic, Abusive, Excited, Satisfied) on EmoWOZ as well as Macro and Weighted F1 (excluding neutral) on EmoWOZ and its subsets. "Ctx." stands for "context". * indicates statistically significant difference with p &lt; 0.05 between the best and the second best values in each column. Please refer to Appendix F.1 for more detailed results. to be rude or abusive, and not due to the similarity between abuse and dissatisfaction. On the other hand, confusions between fearful and dissatisfied suggest workers may also interpret elicitors differently. For example, a user may express negative emotions after the agent informed that there is no attraction meeting the user's criteria. While the emotion is caused by the fact that there is no match, one can also argue that the operator failed to suggest alternative options. We believe differences on interpretations are natural to a certain extent, as emotion appraisal may differ across individuals <ref type="bibr" target="#b22">(Kuppens et al., 2007)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Emotion Recognition in Dialogue</head><p>Emotion recognition aims to recognise emotion within an utterance. Unlike utterances in isolation, emotion recognition in dialogues is highly contextual with respect to the dialogue history. As baselines, we compare two models originally developed for chit-chat emotion recognition as well as various BERT-based models. We believe emotion recognition is the first step towards an emotion-aware task-oriented agent, as a means for a deployed agent to obtain emotion information during an interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">Baselines</head><p>BERT <ref type="bibr" target="#b10">(Devlin et al., 2019)</ref>: BERT is used as the utterance encoder. Each user turn is encoded in isolation without any dialogue context. The [CLS] token from a bert-base-cased model is used as the feature representation, which is then fed into a linear output layer for classification.</p><p>ContextBERT: The set-up is identical to that of BERT, except that the entire dialogue history and the current user utterance are concatenated in the reversed order to form one long sequence. We add "User:" and "System:" to mark the speaker of each turn. DialogueRNN : The model combines gated recurrent units (GRUs) with an attention mechanism to capture the long-term trajectory of the dialogue. We experiment with using GloVe embeddings <ref type="bibr" target="#b35">(Pennington et al., 2014)</ref> or the [CLS] representation from BERT as input features. When GloVe is used, a convolutional neural network (CNN) layer is used as a feature extractor to generate utterance representations. This CNN layer is dropped when using BERT features. COSMIC <ref type="bibr" target="#b15">(Ghosal et al., 2020)</ref>: This model also combines GRUs with the attention mechanism. In addition to utterance representations from a pretrained language model (LM), it supplements input features with common-sense knowledge extracted from a pre-trained commonsense transformer model called COMET <ref type="bibr" target="#b1">(Bosselut et al., 2019)</ref>. Although the original paper uses RoBERTa as input features, we found that BERT results in a better sequence representation for emotion recognition on our data. Therefore we use BERT as the utterance encoder in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">Experimental Setup</head><p>We perform a recognition task on the 7 emotions proposed in our annotation scheme 2 . All models are implemented in PyTorch <ref type="bibr" target="#b34">(Paszke et al., 2019)</ref>. For COS-MIC and DialogueRNN, we use the code provided by the respective papers. We include more details on the hyperparameters of each model in Appendix E. To split EmoWOZ into training, validation, and testing sets, we   <ref type="table" target="#tab_10">Table 6</ref>: Performance of ContextBERT in cross-dataset experiments. We report the F1 for each emotion label (Neutral, Fearful, Dissatisfied, Apologetic, Abusive, Excited, Satisfied), as well as Macro and Weighted F1 (excluding neutral). * indicates statistically significant difference with p &lt; 0.05 between the best and the second best values in each column. For detailed results, please refer to Appendix F.1.</p><p>keep the original split of MultiWOZ and further divide DialMAGE with a ratio of 8:1:1, leading to 9,234, 1,100, and 1,100 dialogues in each set. We run each task on 5 different seeds and report the average performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3.">Results and Discussion</head><p>Recognition on emotion classes. <ref type="table">Table 5</ref> summarises the performance of baseline models. Since almost 70% of the annotations are neutral, we exclude it when calculating average F1 scores. In general, models that take into account context information perform better on the full EmoWOZ. This shows the importance of context or dialogue-level features in emotion recognition in task-oriented dialogues. An exception is DialogueRNN with GloVe feature, which underperforms in EmoWOZ macro F1, likely due to the non-contextual embedding used. On the other hand, BERT scores very well on MultiWOZ dialogues but performs poorly on DialMAGE for both setups. This suggests that emotions in MultiWOZ are less contextdependent. BERT, the only non-contextual model among our baselines, performs well for apologetic, excited, and satisfied, potentially due to the existence of distinguishable keywords associated with these emotions such as "thank you" for satisfied and "sorry" for apologetic. These emotion labels do not benefit much from context. In contrast, BERT produces a significantly worse F1 on dissatisfied, probably because users tend to express dissatisfaction more implicitly, for instance via repetition or correction, making dialogue-level features necessary. <ref type="figure" target="#fig_1">Figure 2</ref> shows two dialogues with implicit emotions and predictions made by respective baseline models. In example 1, the system gives the wrong time of arrival, eliciting mild annoyance from the user. BERT predicts neutral because in isolation, the utterance has no words suggesting dissatisfaction. All other models correctly recognise dissatisfied, as they capture the misunderstanding occurs in previous dialogue turns. Example 2 presents a similar but more implicit case, where all models fail. This shows that EmoWOZ contains contextualised emotions that are more implicit and subtle, requiring more sophisticated features and models. Complementarity between MultiWOZ and Dial-MAGE. Due to different linguistic features and emotion distributions in MultiWOZ and DialMAGE, one concern is that the models learn to predict emotion based on these statistical artifacts. According to Table 3, the most obvious difference is the average utterance length (5.8 in DialMAGE and 11.8 in MultiWOZ). A naive model may simply recognise the data source from word count and predict the most likely emotion from that source. <ref type="table">Table 7</ref> presents how ContextBERT trained on EmoWOZ predicts emotion in long Dial-MAGE and short MultiWOZ utterances. The emotion distribution in model prediction is vastly different from that in the complementing subset. Clearly, the model does not simply count words to decide on the underlying emotion.  <ref type="table">Table 7</ref>: Emotion distribution in labels and Con-textBERT prediction. See Appendix F.5 for full results. Recall and precision on satisfied and dissatisfied for task-oriented dialogue. We further investigate the change in F1 of each emotion on MultiWOZ by looking at the change in recall and precision after complementing MultiWOZ with DialMAGE. We believe it is necessary to distinguish recall and precision, as for some emotions, one may be more important than the other. The relative importance of recall and precision for each emotion class depends on its implication to a task-oriented dialogue system and the consequence of false recognition. Most importantly for task-oriented dialogue system, a high recall of dissatisfied is desirable because the system should not miss any failure in dialogues. Failing to recognise dissatisfaction can trigger more anger from the user and therefore impair task completion (see <ref type="figure">Figure C.</ref>2). On the other hand, a high precision may be more desirable for all other emotions to ensure proper affective response from the system. When the relative importance of recall and precision of the emotion is taken into account, complementing Mul-tiWOZ with DialMAGE is beneficial to {dissatisfied} for higher recall and {fearful, excited, satisfied} for higher precision, see <ref type="table" target="#tab_11">Table 8</ref>. Detailed results can be found in Appendix F.4.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Emotions for Dialogue State Tracking</head><p>In task-oriented dialogues, dialogue state tracking (DST) aims to continuously track the user's goal and intent as the dialogue progresses <ref type="bibr" target="#b45">(Young et al., 2010)</ref>. We hypothesise that the user emotion can help inform the system about their goal. To investigate this, we train a dialogue state tracker that incorporates an additional task to predict one of 7 emotional classes on MultiWOZ 2.1 <ref type="bibr" target="#b12">(Eric et al., 2020)</ref>. We utilise the outof-task training approach and the available code presented in <ref type="bibr" target="#b18">(Heck et al., 2020a)</ref>. We follow the multitask learning (MTL) algorithm, where on each training step, the same model is trained on two different batches, one from the main task (DST) and one from the auxiliary task (emotion recognition). Since neutral emotion provides limited information on the user goal, we remove a half of the neutral utterances when performing MTL. We show that additional emotion labels can lead to a significant improvement (p &lt; 0.02) in the joint goal accuracy (JGA) of DST (see <ref type="table">Table 9</ref>).  <ref type="table">Table 9</ref>: JGA of DST on MultiWOZ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this work, we examined emotions and their expression in the context of task-oriented dialogues, where emotions are centred around a user goal. We used the OCC model as a starting point to derive a comprehensive annotation scheme beyond sentiment polarity for emotions in relation to user goals. We designed a set of 7 emotions that differ in terms of valence, conduct and elicitor to capture the cognitive context of emotions, while maintaining labeling simplicity. With EmoWOZ, we present a publicly available, large-scale human-annotated emotion corpus consisting of Wizard-of-Oz style as well as dialogues with a machine-generated policy.</p><p>Our intention with EmoWOZ is to overcome the lack of large emotionlabelled corpora to support research towards emotionaware task-oriented dialogue systems, for dialogues closer to human-human interactions. We apply various emotion recognition models to EmoWOZ and examined the effect of context for different emotions. In cross-dataset experiments we analysed the complementarity of WOZ-style data and machine-generated policy data. Our results show that recognising context-dependent and implicit emotions from task-oriented dialogues is a challenging task that will benefit from further research. EmoWOZ provides an ideal test bed for that. Lastly, we leveraged emotion recognition in the dialogue state tracking task to exemplify the utility of emotion labels in dialogue modeling. We hope this dataset can offer insights beyond the scope of emotion recognition and push the performance of downstream tasks in task-oriented dialogue modelling. In future work, we plan to investigate tailored models for emotion recognition in task-oriented dialogues that take advantage of high-level features such as dialogue acts or belief states. We are also interested in using emotion as a feedback signal within reinforcement learning policy optimisation. A. The OCC Model         <ref type="table">Table F1</ref>: Performance of baseline models on emotion classification including cross-dataset experiments. For cross-dataset experiments, the "X ? Y"s in the 'Set-up' column represents the training and evaluation set-up, where X is the training set and Y is the test set. E stands for EmoWOZ, M stands for MultiWOZ, and D stands for DialMAGE. M ? D, for example, means to train on MultiWOZ and test on DialMAGE. Extreme values for "Apologetic" and "Abusive" in DialMAGE ("* ? D"s) are caused by their rarity in the test set (1 and 5 occurrences respectively).    <ref type="table">Table F5</ref>: Emotion distribution in model predictions (trained on EmoWOZ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgements</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2. Confusion Matrix of ContextBERT</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Confusion matrix of emotion annotations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Example dialogues and the emotion prediction for the last utterance by each model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>S</head><label></label><figDesc>. Feng, N.Lubis, M. Heck, and C. van  Niekerk are supported by funding provided by the Alexander von Humboldt Foundation in the framework of the Sofja Kovalevskaja Award endowed by the Federal Ministry of Education and Research, while C. Geishauser and H-C. Lin are supported by funds from the European Research Council (ERC) provided under the Horizon 2020 research and innovation programme (Grant agreement No. STG2018 804636). Computing resources were provided by Google Cloud.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure A. 1</head><label>1</label><figDesc>summarises definitions of emotion groups in the OCC model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure</head><label></label><figDesc>one example from our qualification test. Hints are provided for difficult questions containing implicit emotions as shown in the example.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure B. 1 :</head><label>1</label><figDesc>One of fifteen questions in our qualification test B.2. Main Task PageFigure B.2 shows the task page for workers. Before arriving at this page, they will be prompted with a consent form and a message asking if they would like to go through a tutorial.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure B. 2 :</head><label>2</label><figDesc>Amazon Mechanical Turk main task page C. Dialogue Examples Figure C.1 shows examples of how emotions are expressed by the user in EmoWOZ. Figure C.2 shows examples of annotated dialogues.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure C. 1 :</head><label>1</label><figDesc>Example for each emotion label Figure C.2: Annotation examples from EmoWOZ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure F. 1 :</head><label>1</label><figDesc>Confusion matrix between Golden Labels and (the best) ContextBERT Prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Polite Satisfied, liking, appreciative Satisfied with the operator because the goal is fulfilled. Positive Impolite Admiration, gratitude, love Not applicable to the dataset Polite Dissatisfied, disliking Dissatisfied with the operator's suggestion or mistake. Operator Negative Impolite Reproach, anger, hate Abusive Insulting the operator when the goal is not fulfilled.</figDesc><table><row><cell cols="3">Elicitor Valence Conduct</cell><cell>OCC Emotion</cell><cell>Our Emotion</cell><cell>Implication of User</cell></row><row><cell>User</cell><cell>Positive Negative</cell><cell>Polite Impolite Polite Impolite</cell><cell>Pride, gratification Shame, remorse, hate</cell><cell>Not applicable to the dataset Apologetic Not modelled</cell><cell>Apologising for causing confusion to the operator. Insulting the operator for no reason.</cell></row><row><cell>Events,</cell><cell>Positive</cell><cell>Polite Impolite</cell><cell>Happy-for, gloating, love, satisfaction, relief, joy</cell><cell cols="2">Excited, happy, anticipating Looking forward to a good event (e.g. birthday party). Not applicable to the dataset</cell></row><row><cell>facts</cell><cell>Negative</cell><cell>Polite Impolite</cell><cell cols="2">Fearful, sad, disappointed confirmed, pity, disappointment Not applicable to the dataset Distress, resentment, hate, fears-</cell><cell>Encountered a bad event (e.g. robbery).</cell></row><row><cell>NA</cell><cell>Neutral</cell><cell>Polite Impolite</cell><cell>NA</cell><cell>Neutral Not modelled</cell><cell>Describing situations and needs. No emotion but rude (e.g. using imperative sentences).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Comparison between the OCC model and our labelling scheme. Emotions that do not occur in our dataset are marked as "not applicable to our dataset". {User, negative, impolite} has too few instances and {neutral, impolite} is not strong enough to be considered as abusive and therefore are not modelled for now. For simplicity, emotion words in blue are used to represent each emotion category. The OCC model is illustrated in Appendix A.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>1.3.</figDesc><table><row><cell></cell><cell cols="3">MultiWOZ DialMAGE EmoWOZ</cell></row><row><cell># Dialogues</cell><cell>10,438</cell><cell>996</cell><cell>11,438</cell></row><row><cell># Unique tokens</cell><cell>27,833</cell><cell>3,133</cell><cell>28,417</cell></row><row><cell>Avg. turns / dialogue</cell><cell>13.7</cell><cell>24.3</cell><cell>14.6</cell></row><row><cell>Avg. tokens / user turn</cell><cell>11.6</cell><cell>5.7</cell><cell>10.6</cell></row><row><cell>Avg. unique user tokens / dialogue</cell><cell>57.8</cell><cell>36.5</cell><cell>55.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Comparison of linguistic features inEmoWOZ and its subsets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table /><note>Count and prop(ortion) of emotion labels.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Fea. Dis. Apo. Abu. Exc. Sat. Mac. Wgt. Mac. Wgt. Mac. Wgt. BERT BERT No 89.8 36.2 35.1 70.4 27.5 42.9 88.8 50.1 73.5 48.4 83.2 42.7 43.8 ContextBERT BERT Yes 92.1* 30.1 61.7* 62.4 41.7 40.8 89.1 54.3 79.7* 45.1 83.1 50.0 73.5* DialogueRNN GloVe Yes 83.5 12.7 51.4 57.7 0.0 32.7 86.4 40.1 74.6 34.1 79.2 43.2 61.2 DialogueRNN BERT Yes 86.9 41.3 47.5 71.5 25.6 39.4 87.6 52.1 75.5 44.5 81.9 51.4 60.6 COSMIC BERT+COMET Yes 89.8 52.0* 50.7 70.9 31.6 44.4 88.4 56.3 77.1 46.7 82.7 57.2 61.7</figDesc><table><row><cell>Model</cell><cell>Feature</cell><cell>Ctx.</cell><cell>F1 of Each Emotion in EmoWOZ Neu.</cell><cell>EmoWOZ MultiWOZ DialMAGE</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Fea. Dis. Apo. Abu. Exc. Sat. Mac. Wgt. Neu. Fea. Dis. Apo. Abu. Exc. Sat. Mac. Wgt. MultiWOZ 95.1* 35.7 36.4* 70.3* 19.4 34.1 90.0 47.7 83.9 80.2 11.7 7.7 43.7 11.9 60.1 66.</figDesc><table><row><cell>Training</cell><cell></cell><cell cols="3">Test on MultiWOZ</cell><cell cols="3">Test on DialMAGE</cell></row><row><cell>Data</cell><cell cols="7">Neu. 3 33.6 14.5</cell></row><row><cell cols="2">DialMAGE 89.4 0</cell><cell>11.2 0</cell><cell>0</cell><cell>13.9 77.3 17.0 67.8 72.1 0</cell><cell>75.7 0</cell><cell>5.0</cell><cell>58.6 71.7 35.2 72.9</cell></row><row><cell cols="8">EmoWOZ 93.5 33.7 30.4 62.4 17.3 37.1 89.8 45.1 83.1 81.6 5.0 75.5 40.0 52.8* 57.3 69.2 50.0* 73.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6</head><label>6</label><figDesc>MAGE leads to a slight improvement in the F1 score of excited, other F1 scores decrease to various extent.</figDesc><table><row><cell>presents cross-data experiments with Con-</cell></row><row><cell>textBERT, examining how well the two subsets com-</cell></row><row><cell>plement each other. Complementing DialMAGE with</cell></row><row><cell>dialogues from MultiWOZ improves the macro F1 and</cell></row><row><cell>the F1 score of abusive significantly. On the other</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 :</head><label>8</label><figDesc></figDesc><table><row><cell>Change in precision and recall for each emo-</cell></row><row><cell>tion label (Fearful, Dissatisfied, Apologetic, Abusive,</cell></row><row><cell>Excited, Satisfied) on MultiWOZ by ContextBERT, af-</cell></row><row><cell>ter adding DialMAGE to training. ** and * indicate</cell></row><row><cell>statistically significant changes with p &lt; 0.05 and</cell></row><row><cell>p &lt; 0.1 respectively.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table D1 :</head><label>D1</label><figDesc>Inter-annotator agreement and agreement count of EmoWOZ and its subsets. NA means no agreementthree annotators annotate with three different emotions. PA means partial agreement-only two annotators annotate with the same emotion. FA means full agreement-three annotators annotate with the same emotion.</figDesc><table><row><cell></cell><cell cols="3">E. Hyperparameters for Model Training</cell><cell></cell></row><row><cell>Model</cell><cell cols="4">Optimiser Learning Rate L2 Reguliser Weight Training Epochs</cell></row><row><cell>BERT</cell><cell>Adam</cell><cell>2e-5</cell><cell>0</cell><cell>10</cell></row><row><cell>ContextBERT</cell><cell>Adam</cell><cell>2e-5</cell><cell>0</cell><cell>10</cell></row><row><cell>DialogueRNN(GloVe)</cell><cell>Adam</cell><cell>1e-4</cell><cell>1e-5</cell><cell>60</cell></row><row><cell>DialogueRNN(BERT)</cell><cell>Adam</cell><cell>1e-4</cell><cell>1e-4</cell><cell>60</cell></row><row><cell>COSMIC</cell><cell>Adam</cell><cell>1e-4</cell><cell>3e-4</cell><cell>20</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table E1 :</head><label>E1</label><figDesc>Hyperparameters for model training Neutral Average F1 w Neutral Neutral Fearful Dissatisfied Apologetic Abusive Excited Satisfied Micro Macro Weighted Micro Macro Weighted</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="7">F. Detailed Cross-dataset Experiment Results</cell><cell></cell><cell></cell></row><row><cell cols="6">F.1. Emotion Classification (7 classes)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="10">Model Average F1 w/o BERT Set-up F1 for each Emotion Label D ? D 59.75 0 50.34 0 12.99 61.42 72.43 52.50 32.86 M ? D 71.57 11.67 1.36 100 6.15 64.30 68.85 16.97 42.05 E ? D 69.94 0 41.43 60.0 29.41 56.01 69.13 45.47 42.66 D ? M 71.09 0 6.02 0 11.11 15.60 88.07 62.63 20.13</cell><cell>51.45 9.36 43.82 77.16</cell><cell>59.08 36.70 56.94 46.27 61.09 46.56 70.58 27.41</cell><cell>55.94 43.02 57.95 72.77</cell></row><row><cell></cell><cell cols="2">M ? M 95.34</cell><cell>43.00</cell><cell>40.87</cell><cell>73.03</cell><cell>19.05</cell><cell>40.45</cell><cell>90.39</cell><cell>85.19 51.13</cell><cell>84.82</cell><cell>92.57 57.45</cell><cell>92.43</cell></row><row><cell></cell><cell cols="2">E ? M 92.67</cell><cell>41.43</cell><cell>27.76</cell><cell>70.35</cell><cell>21.43</cell><cell>39.98</cell><cell>89.44</cell><cell>79.79 48.4</cell><cell>83.19</cell><cell>88.88 54.72</cell><cell>90.05</cell></row><row><cell></cell><cell>E ? E</cell><cell>89.75</cell><cell>36.17</cell><cell>35.10</cell><cell>70.38</cell><cell>27.50</cell><cell>42.89</cell><cell>88.79</cell><cell>73.67 50.14</cell><cell>73.55</cell><cell>84.82 55.80</cell><cell>84.83</cell></row><row><cell></cell><cell cols="2">D ? D 80.16</cell><cell>0</cell><cell>75.69</cell><cell>0</cell><cell>5</cell><cell>58.58</cell><cell>71.69</cell><cell>73.91 35.16</cell><cell>72.85</cell><cell>77.19 41.59</cell><cell>76.81</cell></row><row><cell></cell><cell cols="2">M ? D 72.11</cell><cell>11.67</cell><cell>7.73</cell><cell>43.71</cell><cell>11.87</cell><cell>60.07</cell><cell>66.29</cell><cell>21.29 33.56</cell><cell>14.49</cell><cell>57.80 39.06</cell><cell>45.67</cell></row><row><cell></cell><cell>E ? D</cell><cell>81.58</cell><cell>5.00</cell><cell>75.46</cell><cell>40.00</cell><cell>52.81</cell><cell>57.31</cell><cell>69.23</cell><cell>73.71 49.97</cell><cell>73.49</cell><cell>77.89 54.48</cell><cell>77.87</cell></row><row><cell>ContextBERT</cell><cell cols="2">D ? M 89.37</cell><cell>0</cell><cell>11.18</cell><cell>0</cell><cell>0</cell><cell>13.86</cell><cell>77.07</cell><cell>59.43 17.02</cell><cell>67.81</cell><cell>80.44 27.35</cell><cell>83.40</cell></row><row><cell></cell><cell cols="2">M ? M 95.09</cell><cell>35.71</cell><cell>36.35</cell><cell>70.34</cell><cell>19.44</cell><cell>34.05</cell><cell>90.01</cell><cell>84.36 47.65</cell><cell>83.87</cell><cell>92.14 54.43</cell><cell>91.98</cell></row><row><cell></cell><cell cols="2">E ? M 93.45</cell><cell>33.70</cell><cell>30.39</cell><cell>62.42</cell><cell>17.27</cell><cell>37.06</cell><cell>89.75</cell><cell>80.44 45.10</cell><cell>83.14</cell><cell>89.65 52.00</cell><cell>90.60</cell></row><row><cell></cell><cell>E ? E</cell><cell>92.10</cell><cell>30.08</cell><cell>61.69</cell><cell>62.36</cell><cell>41.73</cell><cell>40.83</cell><cell>89.14</cell><cell>78.99 54.30</cell><cell>79.67</cell><cell>87.93 59.70</cell><cell>88.33</cell></row><row><cell></cell><cell cols="2">D ? D 40.13</cell><cell>0</cell><cell>64.01</cell><cell>0</cell><cell>0</cell><cell>52.05</cell><cell>65.59</cell><cell>62.56 30.28</cell><cell>62.03</cell><cell>54.88 31.68</cell><cell>50.18</cell></row><row><cell></cell><cell cols="2">M ? D 67.00</cell><cell>0</cell><cell>22.91</cell><cell>100</cell><cell>0</cell><cell>54.45</cell><cell>55.96</cell><cell>31.03 38.89</cell><cell>26.23</cell><cell>54.07 42.90</cell><cell>48.30</cell></row><row><cell>DialogueRNN (GloVe)</cell><cell cols="2">E ? D D ? M 59.78 23.83 M ? M 87.25</cell><cell>0 0 21.57</cell><cell>61.75 5.34 21.53</cell><cell>60 0 52.16</cell><cell>0 0 0</cell><cell>63.72 13.80 26.21</cell><cell>73.57 85.57 85.51</cell><cell>62.06 43.17 50.51 17.45 72.78 34.50</cell><cell>61.23 74.87 78.12</cell><cell>50.24 40.41 55.46 23.50 82.21 42.03</cell><cell>40.99 63.96 84.72</cell></row><row><cell></cell><cell cols="2">E ? M 88.24</cell><cell>13.59</cell><cell>18.67</cell><cell>57.56</cell><cell>0</cell><cell>27.92</cell><cell>86.73</cell><cell>74.04 34.08</cell><cell>79.22</cell><cell>83.41 41.81</cell><cell>85.74</cell></row><row><cell></cell><cell>E ? E</cell><cell>83.46</cell><cell>12.71</cell><cell>51.38</cell><cell>57.67</cell><cell>0</cell><cell>32.75</cell><cell>86.35</cell><cell>70.93 40.14</cell><cell>74.56</cell><cell>78.56 46.33</cell><cell>80.76</cell></row><row><cell></cell><cell cols="2">D ? D 65.24</cell><cell>0</cell><cell>58.24</cell><cell>0</cell><cell>27.69</cell><cell>54.51</cell><cell>68.35</cell><cell>58.45 34.80</cell><cell>57.97</cell><cell>61.95 39.15</cell><cell>61.90</cell></row><row><cell></cell><cell cols="2">M ? D 66.63</cell><cell>0</cell><cell>4.24</cell><cell>43.52</cell><cell>2.86</cell><cell>41.48</cell><cell>53.87</cell><cell>17.33 24.33</cell><cell>9.64</cell><cell>50.73 30.37</cell><cell>40.48</cell></row><row><cell>DialogueRNN (BERT)</cell><cell cols="2">E ? D D ? M 85.48 49.81 M ? M 92.11</cell><cell>0 0 34.83</cell><cell>61.01 8.17 34.49</cell><cell>91.67 0 58.59</cell><cell>28.14 6.71 0</cell><cell>60.92 20.48 26.32</cell><cell>66.70 87.46 87.48</cell><cell>60.95 51.41 65.74 20.47 79.18 40.28</cell><cell>60.56 76.91 80.84</cell><cell>56.58 51.18 78.71 29.76 88.13 47.69</cell><cell>54.74 83.11 88.99</cell></row><row><cell></cell><cell cols="2">E ? M 90.54</cell><cell>47.12</cell><cell>18.08</cell><cell>71.22</cell><cell>15.48</cell><cell>33.92</cell><cell>88.28</cell><cell>76.26 45.68</cell><cell>81.52</cell><cell>86.10 52.09</cell><cell>88.04</cell></row><row><cell></cell><cell>E ? E</cell><cell>86.85</cell><cell>41.32</cell><cell>47.51</cell><cell>71.48</cell><cell>25.56</cell><cell>39.42</cell><cell>87.58</cell><cell>72.48 52.15</cell><cell>75.50</cell><cell>81.78 57.10</cell><cell>83.41</cell></row><row><cell></cell><cell cols="2">D ? D 69.34</cell><cell>0</cell><cell>59.68</cell><cell>0</cell><cell>0</cell><cell>64.30</cell><cell>72.25</cell><cell>60.31 32.71</cell><cell>59.25</cell><cell>65.07 37.94</cell><cell>64.71</cell></row><row><cell></cell><cell cols="2">M ? D 71.56</cell><cell>33.33</cell><cell>2.67</cell><cell>100</cell><cell>15.38</cell><cell>67.04</cell><cell>70.80</cell><cell>19.98 48.21</cell><cell>11.03</cell><cell>57.16 51.54</cell><cell>43.79</cell></row><row><cell></cell><cell>E ? D</cell><cell>66.59</cell><cell>0</cell><cell>61.47</cell><cell>100</cell><cell>43.71</cell><cell>69.74</cell><cell>68.19</cell><cell>62.09 57.18</cell><cell>61.67</cell><cell>64.47 58.53</cell><cell>64.33</cell></row><row><cell>COSMIC</cell><cell cols="2">D ? M 86.68</cell><cell>0</cell><cell>8.78</cell><cell>0</cell><cell>0</cell><cell>20.91</cell><cell>88.90</cell><cell>67.85 19.77</cell><cell>78.19</cell><cell>80.32 29.32</cell><cell>84.33</cell></row><row><cell></cell><cell cols="2">M ? M 94.86</cell><cell>50</cell><cell>40.97</cell><cell>67.12</cell><cell>0</cell><cell>41.77</cell><cell>89.93</cell><cell>84.22 48.30</cell><cell>84.27</cell><cell>91.81 54.95</cell><cell>91.93</cell></row><row><cell></cell><cell cols="2">E ? M 92.61</cell><cell>58.18</cell><cell>24.68</cell><cell>70.52</cell><cell>0</cell><cell>37.92</cell><cell>89.10</cell><cell>79.84 46.73</cell><cell>82.74</cell><cell>88.81 53.29</cell><cell>89.88</cell></row><row><cell></cell><cell>E ? E</cell><cell>89.80</cell><cell>51.98</cell><cell>50.69</cell><cell>70.93</cell><cell>31.62</cell><cell>44.42</cell><cell>88.42</cell><cell>75.89 56.34</cell><cell>77.09</cell><cell>85.26 61.12</cell><cell>85.94</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>F.4. Change in precision and recall on MultiWOZ after Complementing MultiWOZ with DialMAGE in Training ? 91.5 34.7 ? 28.0 31.4 ? 60.4 69.7 ? 61.9 16.0 ? 24.0 33.5 ? 34.1 90.4 ? 90.0 Precision 94.9 ? 95.5 37.3 ? 44.8 43.7 ? 20.9 71.4 ? 63.5 25.0 ? 13.7 35.5 ? 42.6 89.5 ? 89.6 F1 95.1 ? 93.5 35.7 ? 33.7 36.4 ? 30.4 70.3 ? 62.4 19.4 ? 17.3 34.0 ? 37.1 90.0 ? 89.7</figDesc><table><row><cell></cell><cell>Neutral</cell><cell>Fearful</cell><cell>Dissatisfied Apologetic</cell><cell>Abusive</cell><cell>Excited</cell><cell>Satisfied</cell></row><row><cell>Recall</cell><cell>95.3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ContextBERT</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table F4 :</head><label>F4</label><figDesc>Precision, recall and F1 score of ContextBERT for all emotions when trained on MultiWOZ and EmoWOZ respectively, and tested on MultiWOZ. A ? B represents how the value change after complementing MultiWOZ with DialMAGE in training. A is the value when trained on MultiWOZ and B is the value when trained on EmoWOZ. Values with statistical significance (p &lt; 0.1) are bolded and colored where red indicates a drop and green indicates an improvement.For recognising user emotions in task-oriented dialogues, a high precision is more desirable for neutral, fearful, apologetic, abusive, excited, and satisfied where as a high recall is more desirable for dissatisfied.F.5. Emotion Distribution in Model Predictions</figDesc><table><row><cell>Test Set</cell><cell>Model</cell><cell cols="7">Neutral Fearful Dissatisfied Apologetic Abusive Excited Satisfied</cell></row><row><cell>MultiWOZ Label</cell><cell></cell><cell>72.31</cell><cell>0.2</cell><cell>1.47</cell><cell>0.98</cell><cell>0.07</cell><cell>1.0</cell><cell>23.97</cell></row><row><cell cols="2">DialMAGE (#token&gt;11.8) Label</cell><cell>61.96</cell><cell>0.61</cell><cell>28.83</cell><cell>0.61</cell><cell>0.0</cell><cell>6.75</cell><cell>1.23</cell></row><row><cell></cell><cell>BERT</cell><cell>89.57</cell><cell>0.0</cell><cell>2.45</cell><cell>0.0</cell><cell>0.0</cell><cell>6.75</cell><cell>1.23</cell></row><row><cell>DialMAGE</cell><cell>ContextBERT</cell><cell>58.13</cell><cell>0.0</cell><cell>35.47</cell><cell>0.0</cell><cell>0.0</cell><cell>4.93</cell><cell>1.48</cell></row><row><cell>(#token &gt; 11.8)</cell><cell>DialogueRNN-GloVe</cell><cell>6.52</cell><cell>0.0</cell><cell>74.97</cell><cell>1.28</cell><cell>0.0</cell><cell>6.05</cell><cell>11.18</cell></row><row><cell>Prediction</cell><cell>DialogueRNN-BERT</cell><cell>55.65</cell><cell>0.12</cell><cell>23.05</cell><cell>8.61</cell><cell>0.0</cell><cell>5.01</cell><cell>7.57</cell></row><row><cell></cell><cell>COSMIC</cell><cell>61.93</cell><cell>0.23</cell><cell>18.63</cell><cell>7.57</cell><cell>0.0</cell><cell>3.84</cell><cell>7.8</cell></row><row><cell>DialMAGE Label</cell><cell></cell><cell>54.12</cell><cell>0.24</cell><cell>39.3</cell><cell>0.08</cell><cell>0.95</cell><cell>1.35</cell><cell>3.96</cell></row><row><cell cols="2">MultiWOZ (#token&lt;5.8) Label</cell><cell>60.76</cell><cell>0.0</cell><cell>1.21</cell><cell>0.0</cell><cell>0.0</cell><cell>0.3</cell><cell>37.73</cell></row><row><cell></cell><cell>BERT</cell><cell>60.91</cell><cell>0.15</cell><cell>0.45</cell><cell>0.3</cell><cell>0.0</cell><cell>0.45</cell><cell>37.73</cell></row><row><cell>MultiWOZ</cell><cell>ContextBERT</cell><cell>57.43</cell><cell>0.0</cell><cell>2.97</cell><cell>0.0</cell><cell>0.0</cell><cell>0.66</cell><cell>38.94</cell></row><row><cell>(#token &lt; 5.8)</cell><cell>DialogueRNN-GloVe</cell><cell>46.54</cell><cell>0.0</cell><cell>2.1</cell><cell>0.7</cell><cell>0.0</cell><cell>0.88</cell><cell>49.78</cell></row><row><cell>Prediction</cell><cell>DialogueRNN-BERT</cell><cell>46.28</cell><cell>0.0</cell><cell>8.94</cell><cell>0.26</cell><cell>0.09</cell><cell>1.67</cell><cell>42.77</cell></row><row><cell></cell><cell>COSMIC</cell><cell>49.43</cell><cell>0.09</cell><cell>5.0</cell><cell>0.18</cell><cell>0.09</cell><cell>1.58</cell><cell>43.65</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We also performed the same experiments on 3 sentiment labels. Results can be found in Appendix F.3.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning end-to-end goal-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bibliographical References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weston</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<editor>ICLR. OpenReview.net</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">COMET: Commonsense transformers for automatic knowledge graph construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Malaviya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Celikyilmaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th</title>
		<meeting>the 57th</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="4762" to="4779" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">MultiWOZ -a large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-H</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ramadan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ga?i?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10" />
			<biblScope unit="page" from="5016" to="5026" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">EmoBank: Studying the impact of annotation perspective and representation format on dimensional emotion analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Buechel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter</title>
		<meeting>the 15th Conference of the European Chapter<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2017-04" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="578" to="585" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Influence of contextual information in emotion annotation for spoken dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Carri?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>L?pez-C?zar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Commun</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="416" to="433" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">#MeToo Alexa: How conversational systems respond to sexual harassment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cercas</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second ACL Workshop on Ethics in Natural Language Processing</title>
		<meeting>the Second ACL Workshop on Ethics in Natural Language Processing<address><addrLine>New Orleans, Louisiana, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-06" />
			<biblScope unit="page" from="7" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Emotion recognition in human-computer interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cowie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Douglas-Cowie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tsapatsoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Votsis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kollias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fellenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="80" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A crowd-based evaluation of abuse response strategies in conversational agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rieser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue</title>
		<meeting>the 20th Annual SIGdial Meeting on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="361" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Challenges in real-life emotion annotation and machine learning based detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Devillers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vidrascu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lamel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks : the official journal of the International Neural Network Society</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="407" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An argument for basic emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Emotion</title>
		<imprint>
			<biblScope unit="page" from="169" to="200" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">MultiWOZ 2.1: A consolidated multi-domain dialogue dataset with state corrections and state tracking baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sethi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-Tur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France, May</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="422" to="428" />
		</imprint>
	</monogr>
	<note>European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Measuring nominal scale agreement among many raters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Fleiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">378</biblScope>
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The world of emotions is not two-dimensional</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Roesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Ellsworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1050" to="1057" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">COSMIC: COmmonSense knowledge for eMotion identification in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hedayatnia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gottardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-T?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1891" to="1895" />
		</imprint>
	</monogr>
	<note>Proc. Interspeech</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Emotion regulation: Conceptual foundations. Handbook of Emotion Regulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Thompson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Galaxy: A generative pre-trained model for taskoriented dialog with semi-supervised learning and explicit policy injection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Outof-task training for dialog state tracking models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Geishauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lubis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Niekerk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12" />
			<biblScope unit="page" from="6767" to="6774" />
		</imprint>
	</monogr>
	<note>International Committee on Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">TripPy: A triple copy strategy for value independent neural dialog state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Niekerk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lubis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Geishauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moresi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gasic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="35" to="44" />
		</imprint>
	</monogr>
	<note>1st virtual meeting. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
		<title level="m">Speech and Language Processing</title>
		<imprint>
			<publisher>Prentice-Hall, Inc., USA</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>2nd Edition</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An iterative design methodology for user-friendly natural language office information applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Kelley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="26" to="41" />
			<date type="published" when="1984-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Individual differences in patterns of appraisal and anger experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuppens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Van Mechelen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Smits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>De Boeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ceulemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Emotion</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="689" to="713" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">DailyDialog: A manually labelled multiturn dialogue dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017-11" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="986" to="995" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rethinking supervised learning and reinforcement learning in task-oriented dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kiseleva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3537" to="3546" />
		</imprint>
	</monogr>
	<note>Online, November. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Knowledge-aware graph-enhanced GPT-2 for dialogue state tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-H</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Byrne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Dominican Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021-11" />
			<biblScope unit="page" from="7871" to="7881" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Construction and analysis of social-affective interaction corpus in english and indonesian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lubis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Toda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 International Conference Oriental COCOSDA held jointly with 2015 Conference on Asian Spoken Language Research and Evaluation (O-COCOSDA/CASLRE)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="202" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Processing negative emotions through social communication: Multimodal database construction and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lubis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yoshino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="79" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Continual learning in task-oriented dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Madotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Crook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2021 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2021-11" />
			<biblScope unit="page" from="7452" to="7467" />
		</imprint>
		<respStmt>
			<orgName>Online and Punta Cana, Dominican Republic</orgName>
		</respStmt>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">PERSONAGE: Personality generation for dialogue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mairesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics</title>
		<meeting>the 45th Annual Meeting of the Association of Computational Linguistics<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-06" />
			<biblScope unit="page" from="496" to="503" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dialoguernn: An attentive rnn for emotion detection in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019-07" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6818" to="6825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Emotional intelligence meets traditional standards for an intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Caruso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Salovey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="267" to="298" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The Cognitive Structure of Emotions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ortony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Clore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Collins</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Emotions in social psychology: essential readings. Key readings in social psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G</forename><surname>Parrott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Psychology Press</publisher>
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">PyTorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>De-Vito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, et al.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">GloVe: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar,</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>October. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">MELD: A multimodal multi-party dataset for emotion recognition in conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Cambridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="page" from="527" to="536" />
		</imprint>
	</monogr>
	<note>Affective Computing. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Modelling valence and arousal in Facebook posts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Majumder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ghosal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bhardwaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y B</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chhaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Preo?iuc-Pietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shulman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
		<meeting>the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis<address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="9" to="15" />
		</imprint>
	</monogr>
	<note>California. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Grounding emotions in human-machine conversational systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Riccardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Z</forename><surname>Hakkani-T?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTETAIN</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A circumplex model of affect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of personality and social psychology</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1161" to="1178" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Towards sentiment aided dialogue policy learning for multi-intent conversations using hierarchical reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Sentiment adaptive end-toend dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1509" to="1519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Recursive deep models for semantic compositionality over a sentiment treebank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perelygin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2013 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-10" />
			<biblScope unit="page" from="1631" to="1642" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Domainindependent user satisfaction reward estimation for dialogue policy learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ultes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Budzianowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Casanueva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mrksic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Rojas-Barahona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ga?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">INTERSPEECH</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<title level="m">A neural conversational model. ICML Deep Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The hidden information state model: A practical framework for POMDP-based spoken dialogue management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Apr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ga?i?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Keizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mairesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schatzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="150" to="174" />
		</imprint>
	</monogr>
	<note>Sentiment classification in customer service dialogue with topic-aware multi-task learning</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Talking to machines (statistically speaking)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Seventh International Conference on Spoken Language Processing</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Emotion Detection on TV Show Transcripts with Sequence-based Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zahiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Workshop on Affective Content Analysis, AF-FCON&apos;18</title>
		<meeting>the AAAI Workshop on Affective Content Analysis, AF-FCON&apos;18<address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="44" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">MojiTalk: Generating emotional responses at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-07" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1128" to="1137" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Emotional chatting machine: Emotional conversation generation with internal and external memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence, AAAI&apos;18/IAAI&apos;18/EAAI&apos;18</title>
		<meeting>the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth Innovative Applications of Artificial Intelligence Conference and Eighth AAAI Symposium on Educational Advances in Artificial Intelligence, AAAI&apos;18/IAAI&apos;18/EAAI&apos;18</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Takanobu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">ConvLab-2: An open-source toolkit for building, evaluating, and diagnosing dialogue systems</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, ACL 2020</title>
		<editor>Asli Celikyilmaz et al.</editor>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="142" to="149" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Ctx.&quot; stands for &quot;context&quot;. Model Set-up F1 for each Sentiment Label Average F1 w/o Neutral Average F1 w Neutral Neutral Negative Positive Micro Macro Weighted Micro Macro Weighted</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F2</forename><surname>Table</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Summarised performance of baseline models on sentiment classification</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Detailed results of baseline models on sentiment classification including cross-dataset experiments. For cross-dataset experiments, the &quot;X ? X&quot;s in the &apos;Set-up&apos; column represents the training and evaluation set-up</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F3</forename><surname>Table</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">E stands for EmoWOZ, M stands for MultiWOZ, and D stands for DialMAGE. M ? D, for example, means to train on MultiWOZ and test on DialMAGE</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
