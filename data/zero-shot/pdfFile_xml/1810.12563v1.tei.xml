<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Shorten Spatial-spectral RNN with Parallel-GRU for Hyperspectral Image Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haowen</forename><surname>Luo</surname></persName>
							<email>luohw3@mail2.sysu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">School of Geography and Planning Sun Yat-sen University Guangzhou</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Shorten Spatial-spectral RNN with Parallel-GRU for Hyperspectral Image Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Convolutional neural networks (CNNs) attained a good performance in hyperspectral sensing image (HSI) classification, but CNNs consider spectra as orderless vectors. Therefore, considering the spectra as sequences, recurrent neural networks (RNNs) have been applied in HSI classification, for RNNs is skilled at dealing with sequential data. However, for a longsequence task, RNNs is difficult for training and not as effective as we expected. Besides, spatial contextual features are not considered in RNNs. In this study, we propose a Shorten Spatial-spectral RNN with Parallel-GRU (St-SS-pGRU 1 ) for HSI classification. A shorten RNN is more efficient and easier for training than bandby-band RNN. By combining converlusion layer, the St-SSpGRU model considers not only spectral but also spatial feature, which results in a better performance. An architecture named parallel-GRU is also proposed and applied in St-SS-pGRU. With this architecture, the model gets a better performance and is more robust.</p><p>Index Terms-deep learning, gated recurrent unit (GRU), long short-term memory (LSTM), recurrent neural networks (RNN), hyperspectral image classification</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Hyperspectral image (HSI) has attracted considerable attention in the remote sensing community and been widely used in various areas <ref type="bibr" target="#b0">[1]</ref>. With the rich spectral information in HSI, different land cover categories can potentially be differentiated precisely.</p><p>In recent years, deep learning has been widely used in various fields, including HSI classification <ref type="bibr" target="#b1">[2]</ref>. Convolutional neural networks (CNNs) and residual networks (ResNets) have obtained a successful result for HSI classification <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. Recurrent neural networks (RNNs) are also applied in HSI classification <ref type="bibr" target="#b4">[5]</ref>.</p><p>Because of the ability to extract the spatial contextual information, CNNs and ResNets can achieve a high accuracy in the classification task. However, CNNs and ResNets consider spectra as orderless vectors in d-dimensional feature space where d represents the number of bands. However, spectra can be seen as orderly and continuing sequences in the spectral space. In other words, CNNs and ResNets ignore the continuity of spectra <ref type="bibr" target="#b4">[5]</ref>.</p><p>RNNs have proved effective in solving many challenging problems involving sequential data, such as Natural Language Processing (NLP) <ref type="bibr" target="#b5">[6]</ref> and prediction of time series <ref type="bibr" target="#b6">[7]</ref>. Considering the spectrum as a sequential sequence, the application of RNNs is reasonable as it can take full advantage of the high spectral resolution characteristics of HSI. However, for a longsequence task, RNNs is not as effective as we expected. Long distance dependence, gradient vanish and overfitting are prone to occur <ref type="bibr" target="#b7">[8]</ref>. Even if the long short-term memory network (LSTM) <ref type="bibr" target="#b8">[9]</ref> is used to solve the long-distance dependence problem, RNNs is still hard for training and easily overfitting in a long-sequence task.</p><p>In previous work, 3D-CNN is applied in HSI classification and obtained a good behavior <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref>. For RNNs, Convolutional-LSTM (CLSTM) <ref type="bibr" target="#b11">[12]</ref> also achieved a good performance in HSI classification <ref type="bibr" target="#b12">[13]</ref>. 3D-CNNs and CLSTM consider both spatial contextual information and spectral continuity, which result in a high accuracy. Nevertheless, it takes a long time to train these two models.</p><p>In <ref type="bibr" target="#b4">[5]</ref>, LSTM and its variant, GRU <ref type="bibr" target="#b13">[14]</ref>, are applied in HIS classification, and it is proved that GRU has a better performance in HIS classification. To solve the problem that RNNs are easily over-fitting and difficult for training, <ref type="bibr" target="#b14">[15]</ref> proposed band-group LSTM, which can effectively make training easier by reducing the number of timestep in LSTM.</p><p>In this study, a Shorten Spatial-spectral RNN with Parallel-GRU (St-SS-pGRU) is proposed. This study contributes to the literature in 2 major respects: 1) A shorten RNN with GRU is applied in HIS classification. The model is more efficient and easier for training than band-by-band RNN. By combining converlusion layer, an advanced model Shorten Spatialspectral RNN with GRU is proposed. The model considers not only spectral but also spatial feature, which leads to a better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2)</head><p>An architecture named parallel-GRU is proposed and the model with this architecture has a better performance and is more robust. The remainder of this paper is organized as follows. In the methodology section, firstly the structure of traditional RNN, LSTM and GRU are introduced and then the architecture of the proposed models are described. In the experimental section, the network setup, the experimental results, and the comparison of different models are provided. Finally, the conclusion section concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. METHODOLOGY</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Recurrent neural networks (RNN)</head><p>Different from Artificial neural network (ANN), RNN <ref type="bibr" target="#b8">[9]</ref>, a neural network with recurrent unit, has a better performance in solving many challenging problems involving sequential data analysis. The state of each time step of the recurrent unit is not only related to the input of the current step, but also related to the state of the previous step. Thus, the state of the preceding step can effectively influence the next step.</p><p>Given a sequence sample</p><formula xml:id="formula_0">x = x (1) , x (2) , ..., x (m) , in which x (t)</formula><p>is the data at tth timestep. For the tth recurrent unit, its hidden state can be described as:</p><formula xml:id="formula_1">h (t) = h (0) t = 0 h(h (t?1) , x (t) ) t &gt; 0 ,<label>(1)</label></formula><p>where h (0) is the initial state of the recurrent unit, h is a nonlinear function. Normally, h (0) is set as a zero vector. Optionally, in tth timestep, the recurrent unit may have an output y (t) . For some task, the RNN model will finally have an output vector y = y <ref type="bibr" target="#b0">(1)</ref> , y <ref type="bibr" target="#b1">(2)</ref> , ..., y (m) , while for classification tasks, only one output is needed. Generally, The last output is adopted:</p><formula xml:id="formula_2">y (t) = y(h (t) )<label>(2)</label></formula><p>The recurrent unit in a traditional RNN is shown in <ref type="figure" target="#fig_0">Fig.  1</ref>. In the traditional RNN model, the update rule of the recurrent hidden state and output in Eq. <ref type="formula" target="#formula_1">(1)</ref> and <ref type="formula" target="#formula_2">(2)</ref> is usually implemented as follows:</p><formula xml:id="formula_3">h(h (t?1) , x (t) ) = ?(W h x (t) + U h h (t?1) + b h ), (3) y(h (t) ) = W y h (t) + b y ,<label>(4)</label></formula><p>where W h , U h and W y are the weight matrices. b h and b y are the bias vectors, and ? is an activation function, such as the sigmoid function or the hyperbolic tangent function. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Long short-term memory (LSTM)</head><p>The traditional RNN has the problem of long-distance dependence <ref type="bibr" target="#b7">[8]</ref>. The RNN has the capability to connect different timesteps related information. However, when the sequence is too long, the RNN becomes unable to connect related information as the distance increases, because the information losses when propagating through multi-time-step recurrent units.</p><p>By using long short-term memory (LSTM) <ref type="bibr" target="#b15">[16]</ref>, the problems have been solved. As <ref type="figure" target="#fig_1">Fig. 2</ref> shows, LSTM contains a forget gate, an input gate and an output gate. 'Gate' structure is actually a logistic regression model so that part of the information is filtered selectively, while the rest is reserved and passes through the gate. LSTM can simulate the process of forgetting and memory and calculate the probability of forgetting and memory, so information flow could be preserved in long-distance propagation. The structure of LSTM can be described as:</p><formula xml:id="formula_4">f (t) = ?(W f x (t) + U f h (t?1) + b f ),<label>(5)</label></formula><formula xml:id="formula_5">i (t) = ?(W i x (t) + U i h (t?1) + b i ),<label>(6)</label></formula><formula xml:id="formula_6">o (t) = ?(W o x (t) + U o h (t?1) + b o ),<label>(7)</label></formula><formula xml:id="formula_7">c (t) = tanh(W c x (t) + U c h (t?1) + b c ),<label>(8)</label></formula><formula xml:id="formula_8">c (t) = i (t) * c (t) + f (t) * c (t?1) ,<label>(9)</label></formula><formula xml:id="formula_9">h (t) = o (t) * tanh(c (t) ),<label>(10)</label></formula><p>where Eq. <ref type="formula" target="#formula_4">(5)</ref>, <ref type="formula" target="#formula_5">(6)</ref> and <ref type="formula" target="#formula_6">(7)</ref> represent forget gate, input gate and output gate.</p><formula xml:id="formula_10">W f , W i , W o , W c , U f , U i , U o and U c are the weight matrices. b f , b i , b o</formula><p>and b c are the bias vectors. ? refers to sigmoid function and tanh refers to the hyperbolic tangent function: </p><formula xml:id="formula_11">?(x) = 1 1 + e ( ? x) ,<label>(11)</label></formula><formula xml:id="formula_12">tanh(x) = e x ? e ( ? x) e x + e ( ? x) ,<label>(12)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Gated recurrent unit (GRU)</head><p>Over the years, there have been many variants of LSTM, but there is no evidence to show that there is not a superior variant. Any variant may have advantages in a particular problem <ref type="bibr" target="#b16">[17]</ref>.</p><p>GRU <ref type="bibr" target="#b13">[14]</ref> is a variant of LSTM. With fewer parameters, it is much easier for training than LSTM, and usually achieves the same performance as LSTM in some tasks <ref type="bibr" target="#b17">[18]</ref>. It is considered that using GRU in a HSI classification task is more appropriate than using LSTM <ref type="bibr" target="#b4">[5]</ref>.</p><p>The main difference between LSTM and GRU is that an update gate and a reset gate are adopted in GRU, instead of using a forget gate, an input gate and an output gate. The structure of the GRU is shown in <ref type="figure" target="#fig_2">Fig. 3</ref>, which can be defined as follows:</p><formula xml:id="formula_13">z (t) = ?(W z x (t) + U z h (t?1) + b z ),<label>(13)</label></formula><formula xml:id="formula_14">r (t) = ?(W r x (t) + U r h (t?1) + b r ),<label>(14)</label></formula><formula xml:id="formula_15">h (t) = tanh(W h x (t) + U h (r (t) * h (t?1) ) + b h ),<label>(15)</label></formula><formula xml:id="formula_16">h (t) = (1 ? z (t) )h (t?1) + z (t)h(t) ,<label>(16)</label></formula><p>where Eq. <ref type="formula" target="#formula_1">(13)</ref> and <ref type="formula" target="#formula_1">(14)</ref>   D. The proposed model 1) Shorten Spatial-spectral RNN with GRU(St-SS-GRU): A Shorten Spatial-spectral RNN with GRU (St-SS-GRU) model for HSI classification is shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. For each pixel, a square subgraph composed of 5?5 pixels centered on it is used as a training sample.</p><p>The first part of St-SS-GRU is actually a 3D-Convolutional layer but both the depth and stride of the kernels are 1. Three different convolution kernels <ref type="bibr" target="#b10">(11,</ref><ref type="bibr">33,</ref><ref type="bibr">55)</ref> were used to convolve different bands. The output of this part is a sequence with the same length as the original input. The output sequence is a 'spectra' with the spatial contextual feature. Every timestep of the sequence is a feature vector.</p><p>The second part is a Shorten RNN with GRU (St-GRU). The structure of St-GRU is shown in <ref type="figure" target="#fig_4">Fig. 5</ref>. The 1D converlusion layer before GRU is used to reduce the number of timesteps so that the network is easier for training.</p><p>2) Parallel-GRU Architecture: In order to make the model more robust, a Parallel-GRU (pGRU) architecture is proposed. The architecture of Shorten Parallel-GRU (St-pGRU) is shown in <ref type="figure" target="#fig_4">Fig. 5</ref>. The architecture is actually a combination of several GRU units. The output of the architecture is the summation of every unit.</p><p>The Shorten Spatial-spectral RNN with parallel-GRU (St-SS-pGRU) is similar to St-SS-GRU, except that St-GRU is replaced by St-SS-pGRU.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENT A. Data</head><p>In the experiment, two HSI datasets, including the Pavia University and Indian Pines, are used to evaluate the performance of the proposed model.</p><p>The Pavia University dataset was acquired by the Reflective Optics System Imaging Spectrometer(ROSIS) sensor over Pavia, northern Italy in 2001. The corrected data, with a spatial resolution of 1.3 m per pixel, contains 103 spectral bands ranging from 0.43 to 0.86 ?m. The image, with 610?340 pixels, is differentiated into 9 ground truth classes. <ref type="table" target="#tab_1">Table I</ref> provides information about all classes of the dataset with their corresponding training and test sample.</p><p>The Indian Pines dataset was acquired by the TAirborne Visible/Infrared Imaging Spectrometer (AVIRIS) sensor over the Indian Pines test site in north-western Indiana in 1992. The corrected data with a moderate spatial resolution of 20m contains 200 spectral bands ranging from 0.4 to 2.5 ?m. The image consists of 145?145 pixels, which are differentiated into 16 ground truth classes. <ref type="table" target="#tab_1">Table II provides</ref>   Corn <ref type="table" target="#tab_1">-notill  150  1278  3  Corn-min  150  680  4  Corn  100  137  5  Grass-pasture  150  333  6</ref> Grass-trees 150 580 7</p><p>Grass-pasture-mowed 20 8 8</p><p>Hay <ref type="table" target="#tab_1">-windrowed  150  328  9  Oats  15  5  10  Soybean-notill  150  822  11  Soybean-mintill  150  2305  12  Soybean-clean  150  443  13  Wheat  150  55  14  Woods  150  1115  15</ref> Building-grass-trees 50 336 16</p><p>Stone-stell-towers 50 43 TOTAL 1765 8484</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Result</head><p>Table III and IV list the results obtained by the experiment, and <ref type="figure">Fig. 6 and 7</ref> show the classification maps on the Pavia University dataset and the Indian Pines dataset. Note that the accuracies list in <ref type="table" target="#tab_1">Table III</ref> and IV are overall accuracies (OA) along with the standard deviation, from 10 independent runs on each dataset. The experiment is implemented with an Intel i7-7700K 4.20GHz processor with 16GB of RAM and an NVIDIA GTX1050Ti graphic card under Python3.6 with tensorflow1.8.0.</p><p>First of all, for all the datasets, GRU outperforms LSTM. In addition, it is observed that LSTM is difficult to converge in the experiment, while GRU is not. Thus, it is reasonable to indicate that GRU is a better choice for a HSI classification task. Furthermore, it is apparent that St-GRU increases the accuracy significantly by 5.33% and 3.52% in the Pavia University dataset and the Indian Pines correspondingly. With converlusion layers, St-SS-GRU has a better than St-GRU. The accuracy of St-SS-GRU is 4.55% and 6.63% higher than that in St-GRU. After parallel-GRU is adopted, the model gains the best performance in this experiment. The accuracy of St-SS-pGRU is 1.64% and 3.19% higher than St-SS-GRU. What is more, the standard deviation of St-SS-pGRU is smaller than other models, which indicate that St-SS-pGRU is more robust.</p><p>Comparing the processing time of different methods, st-GRU is significantly faster in training than band-by-band GRU. St-SS-GRU and St-SS-pGRU are as slow as LSTM and GRU in training, but they have higher accuracies than LSTM and GRU.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>In the study, a St-SS-pGRU model is proposed for HSI classification. What is more, an architecture named parallel-GRU is proposed to promote the performance and robustness. Then an experiment is conducted to compare the performance of different models. From the experiment, it is confirmed that GRU performs better than LSTM in HSI classification task. Moreover, it is apparent that the proposed models are a lot more accurate, more robust and faster than the traditional GRU network. Specifically, St-GRU effectively reduced the training time and promoted the accuracy. St-SS-GRU needs more time for training but gains a better performance than St-GRU. The proposed architecture parallel-GRU also provided a satisfactory result in the experiment.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Graphic model of traditional recurrent unit.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Graphic model of LSTM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Graphic model of GRU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>St-SS-GRU: (1) The first row shows a flowchart of the network. FC refers to fully connected layer and Conv refers to Convolutional layers. (2) The second row illustrates the shapes of input and output tensors of each layer and their connection. (3) N is the number of filters in the 3D-Convolutional layer, D is the number of bands in the input image, T is the number of GRU timestep, and H is the number of neurons in hidden layer in a GRU. For the Pavia University dataset, D=103, and in the experiment the hyperparameters are set as: N=16, T=5, H=128.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>St-GRU and St-pGRU: (1) The first two rows show the architecture of St-GRU and St-pGRU, Conv refers to convolutional layers. (2) The third row illustrates the shapes of input and output tensors of each layer and their connection. (3) D is the number of bands in the input image, N is the dimension of the vector in each band of input, M is the number of filters in the 1D-Convolutional layer, T is the number of GRU timestep, and H is the number of neurons in hidden layer in a GRU. L and S, which are determined by T, refer to the size and stride of filters in the 1D-Convolutional layer. For the Pavia University dataset, D=103, and in the experiment the hyperparameter is set as: N=M=16, T=5, H=128.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>information about all classes of the dataset with their corresponding training and test sample.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .Fig. 7 .</head><label>67</label><figDesc>(a) False color map (b) Ground truth (c) GRU(87.79%) (e) St-GRU(92.38%) (f) St-SS-GRU(98.04%) (g) St-SS-pGRU(99.01%) The classification maps of the Pavia University dataset. (a) False color map (b) Ground truth (c) GRU(77.07%) (e) St-GRU(80.50%) (f) St-SS-GRU(86.28%) (g) St-SS-pGRU(89.61%) The classification maps of the Indian Pines dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>represent update gate and reset gate. W z , W r , W h , U z , U r and U h are the weight matrices. b z , b r and b h are the bias vectors.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I NUMBER</head><label>I</label><figDesc>OF TRAINING AND TEST SAMPLES USED IN THE PAVIA UNIVERSITY DATASET</figDesc><table><row><cell cols="4">No. Class Name Training Samples Test Samples</cell></row><row><cell>1</cell><cell>Asphalt</cell><cell>548</cell><cell>6083</cell></row><row><cell>2</cell><cell>Meadows</cell><cell>540</cell><cell>18109</cell></row><row><cell>3</cell><cell>Gravel</cell><cell>392</cell><cell>1707</cell></row><row><cell>4</cell><cell>Trees</cell><cell>542</cell><cell>2522</cell></row><row><cell>5</cell><cell>Metal sheet</cell><cell>256</cell><cell>1089</cell></row><row><cell>6</cell><cell>Bare Soil</cell><cell>532</cell><cell>4497</cell></row><row><cell>7</cell><cell>Bitumen</cell><cell>375</cell><cell>955</cell></row><row><cell>8</cell><cell>Bricks</cell><cell>514</cell><cell>3168</cell></row><row><cell>9</cell><cell>Shadows</cell><cell>231</cell><cell>716</cell></row><row><cell></cell><cell>TOTAL</cell><cell>3921</cell><cell>38846</cell></row><row><cell></cell><cell></cell><cell>TABLE II</cell><cell></cell></row><row><cell cols="4">NUMBER OF TRAINING AND TEST SAMPLES USED IN THE INDIAN PINES</cell></row><row><cell></cell><cell></cell><cell>DATASET</cell><cell></cell></row><row><cell>No.</cell><cell>Class Name</cell><cell cols="2">Training Samples Test Samples</cell></row><row><cell>1</cell><cell>Alfalfa</cell><cell>30</cell><cell>16</cell></row><row><cell>2</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III CLASSIFICATION</head><label>III</label><figDesc>ACCURACIES AND TRAINING TIME FOR THE PAVIA UNIVERSITY DATASET The best performance in each column is shown in bold.</figDesc><table><row><cell>Model</cell><cell>Overall accuracy</cell><cell>Training Time (s)</cell></row><row><cell>LSTM</cell><cell>84.68?1.40%</cell><cell>434.22</cell></row><row><cell>GRU</cell><cell>86.92?1.29%</cell><cell>232.15</cell></row><row><cell>St-GRU</cell><cell>92.25?0.78%</cell><cell>7.31*</cell></row><row><cell>St-SS-GRU</cell><cell>96.80?0.37%</cell><cell>104.56</cell></row><row><cell>St-SS-pGRU</cell><cell>98.44?0.26%*</cell><cell>128.91</cell></row><row><cell>*</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV CLASSIFICATION</head><label>IV</label><figDesc>ACCURACIES AND TRAINING TIME FOR THE INDIAN PINES DATASET The best performance in each column is shown in bold.</figDesc><table><row><cell>Model</cell><cell>Overall accuracy</cell><cell>Training Time (s)</cell></row><row><cell>LSTM</cell><cell>71.65?1.05%</cell><cell>838.85</cell></row><row><cell>GRU</cell><cell>77.01?1.82%</cell><cell>442.67</cell></row><row><cell>St-GRU</cell><cell>80.53?0.90%</cell><cell>7.63*</cell></row><row><cell>St-SS-GRU</cell><cell>87.16?1.06%</cell><cell>287.54</cell></row><row><cell>St-SS-pGRU</cell><cell>90.35?0.86%*</cell><cell>300.90</cell></row><row><cell>*</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The sources are now available at: https://github.com/codeRimoe/DL for RSIs/tree/master/StSSpGRU</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Hyperspectral remote sensing data analysis and future challenges. IEEE Geoscience and remote sensing magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jos?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Camps-Valls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasser</forename><surname>Scheunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jocelyn</forename><surname>Nasrabadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chanussot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep learning in remote sensing: A comprehensive review and list of resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Xiang Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devis</forename><surname>Tuia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangpei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Friedrich</forename><surname>Fraundorfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Magazine</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="8" to="36" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Going deeper with contextual cnn for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyungtae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heesung</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4843" to="4855" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deep residual networks for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingfei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>Institute of Electrical and Electronics Engineers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep recurrent neural networks for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lichao</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedram</forename><surname>Ghamisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><forename type="middle">Xiang</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3639" to="3655" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">From feedforward to recurrent lstm neural networks for language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sundermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schl?ter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="517" to="529" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Applying lstm to time series predictable through time-window approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Felix</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Gers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Eck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Nets WIRN Vietri-01</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="193" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning long-term dependencies with gradient descent is difficult</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrice</forename><surname>Simard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Frasconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="157" to="166" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A learning algorithm for continually running fully recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ronald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zipser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="270" to="280" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Spectral-spatial classification of hyperspectral imagery with 3d convolutional neural network. Remote Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haokui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Shen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">67</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Spectral-spatial residual network for hyperspectral image classification: A 3-d deep learning framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiming</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Chapman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="847" to="858" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Convolutional lstm network: A machine learning approach for precipitation nowcasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhourong</forename><surname>Shi Xingjian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dit-Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wai-Kin</forename><surname>Yeung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang-Chun</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Woo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="802" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Bidirectional-convolutional lstm based spectral-spatial feature learning for hyperspectral image classification. Remote Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingshan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renlong</forename><surname>Hang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotong</forename><surname>Yuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1330</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaisheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katerina</forename><surname>Vylomova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.03790</idno>
		<title level="m">Depth-gated recurrent neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A band grouping based lstm algorithm for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangpei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CCF Chinese Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="421" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Lstm: A search space odyssey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rupesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koutn?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Steunebrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="2222" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An empirical exploration of recurrent network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2342" to="2350" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
