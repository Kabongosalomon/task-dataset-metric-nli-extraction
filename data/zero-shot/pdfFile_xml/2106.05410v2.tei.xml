<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DASVDD: Deep Autoencoding Support Vector Data Descriptor for Anomaly Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadi</forename><surname>Hojjati</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narges</forename><surname>Armanfard</surname></persName>
						</author>
						<title level="a" type="main">DASVDD: Deep Autoencoding Support Vector Data Descriptor for Anomaly Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>PREPRINT 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Anomaly Detection</term>
					<term>Deep Learning</term>
					<term>Deep Autoencoder</term>
					<term>Support Vector Data Descriptor !</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Semi-supervised anomaly detection aims to detect anomalies from normal samples using a model that is trained on normal data. With recent advancements in deep learning, researchers have designed efficient deep anomaly detection methods. Existing works commonly use neural networks to map the data into a more informative representation and then apply an anomaly detection algorithm. In this paper, we propose a method, DASVDD, that jointly learns the parameters of an autoencoder while minimizing the volume of an enclosing hyper-sphere on its latent representation. We propose an anomaly score which is a combination of autoencoder's reconstruction error and the distance from the center of the enclosing hypersphere in the latent representation. Minimizing this anomaly score aids us in learning the underlying distribution of the normal class during training. Including the reconstruction error in the anomaly score ensures that DASVDD does not suffer from the common hypersphere collapse issue since the DASVDD model does not converge to the trivial solution of mapping all inputs to a constant point in the latent representation. Experimental evaluations on several benchmark datasets show that the proposed method outperforms the commonly used state-of-the-art anomaly detection algorithms while maintaining robust performance across different anomaly classes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A NOMALY detection (AD), also referred to as novelty detection and outlier detection, is the task of identifying samples of a dataset that deviate from the "normal" pattern <ref type="bibr" target="#b0">[1]</ref> (the term "normal" is unrelated to the Gaussian distribution here and elsewhere in the paper, unless otherwise specified). Anomaly detection has been an active field of research in recent years due to its application in a wide variety of domains, including fraud detection <ref type="bibr" target="#b1">[2]</ref>, medical care <ref type="bibr" target="#b2">[3]</ref>, time series anomaly detection <ref type="bibr" target="#b3">[4]</ref>, video surveillance <ref type="bibr" target="#b4">[5]</ref>, machine vision applications <ref type="bibr" target="#b5">[6]</ref>, and industrial monitoring <ref type="bibr" target="#b6">[7]</ref>. Typically, in most AD problems, we are given samples from the normal class. It is called semi-supervised AD, where the goal is to train a model that describes pattern of the given normal data and thus identify the instances that deviate from the normal pattern as anomalies <ref type="bibr" target="#b7">[8]</ref>. This procedure is also known as one-class classification. A long line of literature, such as one-class support vector machines (OCSVMs) <ref type="bibr" target="#b8">[9]</ref>, kernel density estimation (KDE) <ref type="bibr" target="#b9">[10]</ref>, and more recently, Isolation Forests (IFs) <ref type="bibr" target="#b10">[11]</ref>, has addressed the semi-supervised anomaly detection problem with classical (i.e., non deep learning) machine learning methods. These methods commonly suffer from issues such as the curse of dimensionality that significantly downgrades their performance in high-dimensional tasks.</p><p>In the past decade, deep anomaly detection algorithms have become popular thanks to the development of Au-  <ref type="bibr" target="#b12">[12]</ref>, <ref type="bibr" target="#b13">[13]</ref> and Generative Adversarial Networks (GANs) <ref type="bibr" target="#b14">[14]</ref>. Deep AD methods can be divided into two categories: the first group of algorithms train an AE or GAN on normal data and uses the reconstruction error of new samples for identifying anomalies <ref type="bibr" target="#b15">[15]</ref>. The second group uses neural networks to extract a lower-dimensional representation of input data and feed it to a classical AD algorithm such as OCSVM <ref type="bibr" target="#b16">[16]</ref>. Another line of research in deep anomaly detection focuses on developing domain-specific AD algorithms. This research area has attracted a lot of attention from the community, especially from computer vision researchers, and have show to significantly improve the results of other methods <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b17">[17]</ref>. While they have achieved an unprecedented success in image anomaly detection, these models commonly use a domain-specific transformation in their pipeline which makes them unsuitable for other input types.</p><formula xml:id="formula_0">?</formula><p>Recently, Ruff et al. <ref type="bibr" target="#b18">[18]</ref> proposed a deep AD method, called Deep SVDD (DSVDD), which is suitable for AD. In contrast to other state-of-the-art domain-specific models, DSVDD is suitable for general AD and does not depend on the input type. It combines two widely-used anomaly detection approaches: it trains a single neural network for simultaneously extracting a lower-dimensional representation of data and a support vector data descriptor (SVDD) that minimizes the volume of the enclosing hyper-sphere on this lower-dimensional representation. The performance of DSVDD on image anomaly detection benchmarks is considerably weaker than the SOTA domain-specific methods but since it is a general algorithm, DSVDD has emerged as an efficient anomaly detection method. Although DSVDD is a promising algorithm and produces encouraging outcomes, it suffers from a vital problem during training which is called "hyper-sphere collapse" <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b19">[19]</ref>. Hypersphere collapse occurs when the network converges to the trivial arXiv:2106.05410v2 [cs.</p><p>LG] 17 Nov 2021 solution of all-zero weights. This phenomenon will be discussed in more detail in the next section. To prevent this problem, <ref type="bibr" target="#b18">[18]</ref> imposed several constraints on the architecture of their deep network, which limit the performance and effectiveness of the algorithm. Few studies, <ref type="bibr" target="#b19">[19]</ref>, <ref type="bibr" target="#b20">[20]</ref>, have attempted to address the hyper-sphere collapse in DSVDD, by adding more regularizers or changing some parts of the model. However, unlike the original DSVDD, they cannot be trained in an end-to-end fashion and, similar to DSVDD, cannot consider the hyper-sphere center as a trainable parameter.</p><p>In this paper, we propose a novel anomaly detection algorithm inspired by DSVDD and Autoencoders. Our method, deep autoencoding support vector data descriptor (DASVDD), trains an autoencoder, instead of a simple neural network, through simultaneously minimizing the volume of the enclosing hyper-sphere in the learned latent representation of the encoder and the reconstruction error of the decoder's output. Therefore, the autoencoder learns to map the normal data into a hyper-sphere with a minimum volume while can still reconstruct the original input. We propose a customized anomaly score which is a combination of the AE's reconstruction error and the distance of the sample from the center of the hyper-sphere. Block diagram of the proposed DASVDD is shown in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>We show that our model does not encounter the hypersphere collapse problem since it considers the hyper-sphere center and network biases as parameters that are trained during the training phase. We present extensive experiments of DASVDD on the benchmark datasets and compare its performance against state-of-the-art algorithms. The benchmark datasets include three computer vision datasets and two datasets of speech and medical data. Effective performance of DASVDD on these datasets shows robustness of the proposed method across a wide variety of anomaly detection applications.</p><p>In summary, the main contributions of our paper are as follows:</p><p>1) We propose an anomaly detection approach based on the popular deep SVDD algorithm which prevents its hypersphere collapse problem. We propose to use the autoencoder reconstruction error as a term in the loss function. This prevents the trivial all-zero solution for the parameters.</p><p>2) In our model, unlike the original DSVDD and its extensions, the hypersphere center is a free optimization parameter, and can be optimized during training. DSVDD and other similar models commonly fix the hypersphere center prior to the training in order to prevent the network from converging to the trivial solution. This may lead to a suboptimal solutions because of forcing the hypersphere center to be equal to a predefined value. 3) We propose an iterative training strategy for jointly minimizing the network's reconstruction loss and the DSVDD loss. Our strategy prevents the total loss function from collapsing to either of the mentioned losses, and provides a stable training procedure. 4) Our approach requires a hyperparamter which balances the contribution of the two loss functions.</p><p>Finding an appropriate value for this parameter is challenging because it might lead to the collapse of the model to either of the two loss terms. In this paper, we also propose an effective approach for tuning this hyperparameter prior to the training, and experimentally show that the resulting value lead to a stable training procedure. 5) Unlike domain-specific models, our proposed approach does not use any input-specific transformations and is thus suitable for general anomaly detection. We test our model on different types of datasets, including images, speech, and biomedical data.</p><p>The remainder of this paper is organized as follows: In section 2, we review the state-of-art algorithms in anomaly detection, with a focus on Deep SVDD. In the third section, we describe our proposed method, DASVDD, and its properties. Section 4 presents an extensive evaluation of DASVDD on several benchmarking datasets. We also discuss some of the properties and possible expansions of our model. Finally, section 5 offers some concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORKS</head><p>In this section, we briefly review the existing methods in semi-supervised anomaly detection. One can refer to <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b21">[21]</ref> for a recent and detailed review of past literature in the AD field.</p><p>Deep autoencoders <ref type="bibr" target="#b22">[22]</ref> are one the most commonlyused deep models for anomaly detection. AEs can be used for extracting a lower-dimensional representation of the data while retaining their common factors of variation. AEbased AD algorithms either feed this latent representation to a conventional anomaly detection algorithm, such as Gaussian Mixture Model (GMM) or one-class SVM (OCSVM) <ref type="bibr" target="#b23">[23]</ref>, or directly use the reconstruction error as their anomaly measure <ref type="bibr" target="#b24">[24]</ref>  <ref type="bibr" target="#b25">[25]</ref>. Several variants of autoencoders, including variational AEs <ref type="bibr" target="#b24">[24]</ref> and convolutional AEs <ref type="bibr" target="#b25">[25]</ref>, have been used for anomaly detection in different applications <ref type="bibr" target="#b26">[26]</ref>. These methods assume that the autoencoder can extract the common factors of variation from normal data and thus can reconstruct them with fair accuracy, but cannot reconstruct the anomalies because they do not possess the common factors associated to the normal data. This assumption, however, does not always hold. In some cases, an autoencoder which is trained on the normal data can also reconstruct anomalies accurately <ref type="bibr" target="#b27">[27]</ref>. To prevent this problem, it is important to adopt an appropriate network architecture and latent representation size. Choosing the right size for the latent space often depends on the data and the task that we would like to carry out. Since we usually do not have access to all anomaly classes, it is tough to find an optimal size for the bottleneck of the AE network.</p><p>Recently, several studies have developed AD algorithms based on GANs <ref type="bibr" target="#b28">[28]</ref>. In most GAN-based approaches, the goal is to train the latent representation of the generator network so that it captures the underlying pattern of the normal data. These methods assume that the generative network can generate normal instances from the latent space better than anomalies. The residual between the generated sample and the input is then used as the anomaly measure. Methods such as AnoGAN <ref type="bibr" target="#b29">[29]</ref>, EGBAD <ref type="bibr" target="#b30">[30]</ref>, and fast AnoGAN <ref type="bibr" target="#b31">[31]</ref> have been developed based on this approach. GAN-based methods also suffer from issues such as time inefficiency, failure to converge during training, and mode collapse <ref type="bibr" target="#b32">[32]</ref>.</p><p>Both AE-based and GAN-based anomaly detection methods employ reconstruction error as their anomaly measure, and their objective during the training phase has no direct relevance to the anomaly detection task. There are very few approaches that, similar to DSVDD discussed before, realize the AD task by directly minimizing an anomaly score, rather than samples reconstruction error, during the training phase. Although DSVDD has shown superior performance to other algorithms on several AD tasks, it suffers from the hyper-sphere collapse problem. To better understand this issue, let's take a close look at the objective function of DSVDD shown below:</p><formula xml:id="formula_1">min W 1 n n i=1 ||?(x i , W ) ? c|| 2 + ? 2 L l=1 ||W l || 2 F (1)</formula><p>where c is the center of hyper-sphere, ?(.) denotes the output of the neural network, W represents the network weights, and ? is a hyperparameter that controls contribution of the regularization term. As can be seen, the above equation has a trivial solution with W = 0 and c = 0.</p><p>To avoid this solution, c must be excluded from the set of optimization problem variables, i.e. it must be considered as a non-trainable hyperparameter, and be set to a non-zero value prior to the training phase. In addition, the network biases must be set to zero otherwise all the data points will be mapped to the hyper-sphere center c. Furthermore, activation functions with non-zero upper or lower bounds cannot be employed. This is because a network unit with bounded activation function can be saturated for all inputs having at least one feature with common sign, thereby emulating a bias term in the subsequent layer, which again leads to a hyper-sphere collapse. All these constraints limit the performance of deep SVDD in many applications. See <ref type="bibr" target="#b18">[18]</ref> for more details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">PROPOSED METHOD</head><p>Let D be our dataset, and X ? D be the set of normal samples. Given a subset of normal samples X train ? X, we would like to learn an anomaly scoring function S(x) : D ? R such that a lower score denotes a higher probability of sample x being in X, or equivalently, sample x being normal.</p><p>As is shown in <ref type="figure">Figure ,</ref> the proposed DASVDD method consists of two major components: a deep autoencoder and a support-vector data descriptor (SVDD). The autoencoder first maps the input data to a lower-dimensional latent representation space and then attempts to reconstruct it. Simultaneously, the SVDD finds a data enclosing hypersphere with the minimum volume on the latent space of the AE. Therefore, the autoencoder learns to map the data into a hyper-sphere with minimum volume while still can reconstruct the original input. The anomaly score is calculated by combining the reconstruction error and the euclidean distance between the lower-dimensional latent representation of the sample from the center of the enclosing hypersphere. The AE network and SVDD are trained using only the normal samples, i.e. X train . Therefore, the bottleneck of the autoencoder learns a representation that models the underlying representation of the normal data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">DASVDD Anomaly Score and Objective Function</head><p>Let h(.) and g(.) be the encoding and decoding functions of the AE respectively, and let ? e and ? d denote their corresponding parameters (weights and biases). Given an input sample x, the encoder calculates its latent representation z = h(x; ? e ). Then the reconstructed output isx = g(z; ? d ).</p><p>We define the anomaly score as a combination of reconstruction error and the distance of the latent representation from the center of the hyper-sphere. Formally, given a sample x, the anomaly score S(x) can be written as:</p><formula xml:id="formula_2">S(x) = ||x ? x|| 2 + ?||z ? c * || 2 = ||g(h(x; ? * e ); ? * d ) ? x|| 2 + ?||h(x; ? * e ) ? c * || 2 (2)</formula><p>where c denotes the center of the enclosing hyper-sphere and ? is a hyperparameter balancing contribution of the two terms. The star symbol ' * ' denotes the optimum value of the corresponding parameter, that is obtained after completing the algorithm training phase. From now on, we refer to the first term of equation <ref type="formula" target="#formula_12">(2)</ref> as reconstruction error term and to the second term as SVDD term.</p><p>The objective of the network is to minimize the anomaly score on the normal data. Therefore, we can set the objective function equal to the anomaly score, and define the objective of our method as is shown below in <ref type="formula" target="#formula_12">(3)</ref> where n denotes the batch size.</p><formula xml:id="formula_3">min ?e,? d ,c 1 n n i=1 ||g(h(x i ; ? e ); ? d ) ? x|| 2 + ?||h(x i ; ? e ) ? c|| 2 (3)</formula><p>Including the reconstruction error, i.e. the first term, in the objective function is to avoid converging to a latent representation that the decoder cannot reconstruct the normal samples from. The second term corresponds to the SVDD term which is to penalize the radius of the hyper-sphere. By minimizing the second term, we in fact minimize average of the samples distance from the hyper-sphere centre c; hence minimizing the volume of the hyper-sphere enclosing the normal data points.</p><p>Since the objective function of DASVDD has a reconstruction error term, the all-zero weights solution do not reduce the value of the objective function to the minimum possible error value, i.e. zero; therefore, no hyper-sphere collapse happens. Obviously, ? should not be set to a very high value to ensure effective contribution of the reconstruction error term, hence avoiding the all-zero weights and zero hyper-sphere center solution. A simple heuristic approach for choosing an appropriate ? value is presented in Section 3.3.</p><p>Note that unlike the DSVDD algorithm, the proposed model treats the center of the hyper-sphere c as a trainable parameter that can be trained during training.</p><p>By mapping the data into a lower-dimensional representation and close to the center c, the network learns to extract the common factors of variation from normal data. Since anomalies have intrinsic differences from the normal data, we expect our network to be unable to reconstruct them correctly and/or map them close to the hyper-sphere center.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Optimization and Training</head><p>One of the challenges of jointly training the network parameters with hyper-sphere center c is that they are from different numerical ranges. As a result, using a single optimizer for both sets of parameters might be inefficient, and can lead to the loss function collapsing to either of the two loss terms.</p><p>To jointly train the AE and SVDD, we propose the following strategy: at each training epoch, first, use ? (0 &lt; ? &lt; 1) percent of each data batch to train the network parameters ? e and ? d while the hyper-sphere center c is fixed; then, use the remaining samples to train the hypersphere center c while keeping the network parameters fixed. This training procedure is summarized in Algorithm 1. We suggest to use stochastic gradient descent (SGD) or its variants such as Adam <ref type="bibr" target="#b33">[33]</ref> as the optimizer for the autoencoder's parameters. For training the hyper-sphere center c, we recommend to use an algorithm with an adaptive learning rate, such as AdaGrad <ref type="bibr" target="#b34">[34]</ref>. This usually results in a faster convergence of the training procedure since it allows to assign higher weights to tuning c in the first few training epochs. Experimental evaluations in the Section 4.7 demonstrate that this strategy results in a stable training process.</p><p>Moreover, if we fix the network parameters prior to training c, we can easily prove that the optimal c can be calculated by averaging over the latent representation of the batch samples:</p><formula xml:id="formula_4">c = 1 |B| |B| i=1 h(x i ; ? e )<label>(4)</label></formula><p>where |B| is the batch size in the above equation. This shows that jointly training c with the network parameters does not add any complexity to the optimization process. To prove the equation 4, we start by writing the loss function as:</p><formula xml:id="formula_5">L = L RE + L DSV DD</formula><p>if the batch size is equal to |B|, the total loss of a batch can be written as:</p><formula xml:id="formula_6">? L = |B| i=1 ( x i ?x i 2 + h(x i ; ? e ) ? c 2 )</formula><p>now, we take the derivative of L, and set it equal to zero.</p><formula xml:id="formula_7">?L ?c = ? ?c |B| i=1 ( x i ?x i 2 + h(x i ; ? e ) ? c 2 ) = 0</formula><p>since we assume that the network parameters, i.e. ? e , ? d are fixed during tuning c, the derivative of the L RE will be zero:</p><formula xml:id="formula_8">? ? ?c |B| i=1 ( h(x i ; ? e ) ? c 2 ) = 0 ? |B| i=1 ? ?c ( h(x i ; ? e ) ? c 2 ) = 0 ? |B| i=1 ?2(h(x i ; ? e ) ? c) = 0 ? |B| i=1 h(x i ; ? e ) ? |B| i=1 c = 0 ? |B| i=1 h(x i ; ? e ) ? |B|c = 0 ? c = 1 |B| |B| i=1 h(x i ; ? e )</formula><p>Algorithm 1 Training procedure of DASVDD</p><formula xml:id="formula_9">Input: X train , c (0) , ? (0) = {? (0) e , ?<label>(0)</label></formula><p>d }, max epochs, n, ? Output: c * and ? * = {? * e , ? * d } 1: Initialize Network Parameters ? = {? e , ? d } and hyper-sphere center c 2: for j &lt; max epochs do <ref type="bibr">3:</ref> Pick ? percent of the samples batch <ref type="bibr">4:</ref> Optimize ? (j+1) to minimize</p><formula xml:id="formula_10">[?n] i=1 x i ?x i 2 + ? [?n] i=1 h(x i ; ? (j+1) e</formula><p>) ? c (j) 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Pick the remaining (1 ? ?) percent of the samples <ref type="bibr">6:</ref> Optimize</p><formula xml:id="formula_11">c (j+1) to minimize n i=[?n]+1 h(x i ; ? (j+1) e</formula><p>) ? c (j+1) 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Choice of Hyperparameter ?</head><p>DASVDD uses hyperparameter ? for balancing the two terms of the anomaly score (which is also our objective function). In this section, we present a heuristic for choosing a suitable value of ?.</p><p>Depending to the dataset characteristics, network architecture and initial parameter values, the reconstruction error and SVDD terms might have different numerical ranges. Therefore, a reasonable choice for ? is a value proportional to the ratio of these two terms as below: <ref type="bibr" target="#b4">5)</ref> where N is the total number of training samples. Because the DASVDD anomaly score is also the method objective function, we do not have access to the trained optimal parameters prior to the the training outset. As such, we suggest to use initial values of the network parameters (i.e. ? e and ? d ) and initial value of the hyper-sphere center c instead of their optimum values, when computing ? in <ref type="bibr" target="#b4">(5)</ref>. We suggest to randomly initialize ? e and ? d and initialize c to zero. Because of the random initialization of the network parameters, we suggest to repeat this procedure T times, with T different random initial values (where c is set to zero), and use the average value as the final ? to be used in the algorithm training phase. This approach is mathematically described in <ref type="bibr" target="#b5">(6)</ref> where the superscript (0) denotes the initial value of the corresponding parameter.</p><formula xml:id="formula_12">? = 1 N N i=1 ||x i ? x i || 2 ||z i ? c * || 2 = 1 N N i=1 ||g(h(x i ; ? * e ), ? * d ) ? x i || 2 ||h(x i ; ? * e ) ? c * || 2<label>(</label></formula><formula xml:id="formula_13">? = 1 T T t=1 1 N N i=1 ||g(h(x i ; ? (0) e ), ? (0) d ) ? x i || 2 ||h(x i ; ? (0) e ) ? c (0) || 2<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we test the effectiveness of our proposed anomaly detection method on five publicly available benchmark datasets, and compare its performance against a variety of state-of-art AD algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We employ three publicly available computer vision benchmark dataset as well as two datasets from Outlier Detection DataSets (ODDS) repository <ref type="bibr" target="#b35">[35]</ref>. Previous AD works, such as <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b36">[36]</ref>, commonly use computer vision datasets as benchmark because these are usually high-dimensional and let us assess results visually. The employed datasets are as follows. (1) MNIST <ref type="bibr" target="#b37">[37]</ref> which consists of 70,000 28?28 handwritten digits monochrome images. (2) CIFAR10 <ref type="bibr" target="#b38">[38]</ref> which consists of 60,000 color images of size 32 ? 32 from 10 different objects. (3) Fashion MNIST (FMNIST) <ref type="bibr" target="#b39">[39]</ref> which has 70,000 grey scale images of size 28 ? 28 from 10 fashion products. These datasets are from different domains of application, and can help us to gain better understanding of the DASVDD performance under different circumstances. The MNIST, CIFAR10, and Fashion MNIST datasets all have 10 classes. The full list of CIFAR10 and FMNIST classes is included in the <ref type="table" target="#tab_1">Table 1</ref>. In each experiment, we pick one of the classes as normal and label the rest as anomalies. Using this approach, we create ten one-class classifiers for each dataset. This approach is common in image anomaly detection and was previously used by similar studies <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b36">[36]</ref>. We use the original training and test data and only employ normal samples for training the models. No preprocessing step is performed on the MNIST and Fashion MNIST datasets. However, similar to <ref type="bibr" target="#b18">[18]</ref>, we pre-processed the CIFAR10 images with global contrast normalization <ref type="bibr" target="#b42">[42]</ref>. Same pre-processing is employed for our comparison algorithms. The Speech and PIMA datasets are already labeled as being normal or anomaly, and can be directly used for AD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Competing Methods</head><p>We compare performance of DASVDD against three commonly-used traditional baselines, i.e. one class SVM (OCSVM) <ref type="bibr" target="#b8">[9]</ref>, kernel density estimation (KDE) <ref type="bibr" target="#b9">[10]</ref>, and isolation forest (IF) <ref type="bibr" target="#b10">[11]</ref>, as well as six state-of-the-art deep anomaly detection algorithms, i.e. deep autoencoder (AE) <ref type="bibr" target="#b12">[12]</ref>, deep variational autoencoder (VAE) <ref type="bibr" target="#b24">[24]</ref>, deep autoencoding Gaussian mixture model (DAGMM) <ref type="bibr" target="#b44">[43]</ref>, AnoGAN <ref type="bibr" target="#b29">[29]</ref>, autoregressive novelty detector (AND) <ref type="bibr" target="#b36">[36]</ref> and deep SVDD (DSVDD) <ref type="bibr" target="#b18">[18]</ref>. Ankle Boot OCSVM is a popular classic kernel-based anomaly detection algorithm. In our experiments, we used it with its default kernel, i.e. radial basis function (RBF) with the corresponding hyperparameter ? = 0.5. KDE is a classic, yet effective anomaly detection method that has shown promising results even in challenging anomaly detection problems. The bandwidth parameter of the Gaussian kernel is tuned using 5-fold cross validation. IF is an ensemble non-deeplearning method. We set its hyperparametrs, i.e. the number of trees and sub-sampling size, to respectively 100 and 256, as suggested in the original paper. AE with mean squared error loss is used as one of our deeplearningbased baselines. We choose the same network architecture as of our proposed method's autoenco der. The reconstruction error is used as anomaly score. VAE is another autoencoderbased method that employs a variational autoencoder instead of a simple AE for data reconstruction. DAGMM is a model that uses an autoencoder along with a Gaussian mixture model on the autoencoder latent representation. It has shown competitive results on several anomaly detection datasets. AnoGAN is a relatively recent anomaly detection method, and one of the first GAN-based algorithms for AD.</p><p>AND is a recent anomaly detection algorithm that jointly learns the autoencoder parameters along with an autoregressive model on its latent representation.</p><p>The goal of our approach is to detect anomalies regardless of their input type. Therefore, for the sake of fair comparison, we do not compare our algorithm to imagespecific AD models such as GT <ref type="bibr" target="#b5">[6]</ref> and CSI <ref type="bibr" target="#b17">[17]</ref>.</p><p>DSVDD is the closest algorithm to our proposed method. We use DSVDD as one of the baselines to assess if our modifications and proposed method can yield a better performance. In terms of the compared deeplearning-based methods, If the results of a method on some datasets are not reported, we run the released code with hyper-parameters mentioned in the original paper and report the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">DASVDD Implementation Details</head><p>For all datasets, we use autoencoder with fully connected layers. For both MNIST and FMNIST, we use one hidden layer of size 1,024. For CIFAR10 and Speech datasets, we used an encoder with 2 hidden layers of sizes 1,024 and 512 respectively. For all datasets, except PIMA, the latent space size is set to 256. Since PIMA dataset has only a few attributes, we use a model with two hidden layers of size 10 and set the latent size to 4. In all datasets, we use leaky ReLU as the activation function, and set the training batch size to 200. For optimizing the network parameters, we use Adam optimizer with initial learning rate 0.001. For optimizing c, we employ AdaGrad <ref type="bibr" target="#b34">[34]</ref> optimizer with initial learning rate of 1 and decay of 0.1. The center of hypersphere c is randomly initialized from a normal distribution. In all our experiments, we set ? = 0.9, the weight decay hyperparameter ? = 10 ?7 , and run the training for 300 epochs. The ? value for every dataset is calculated, prior to training, as is discussed in Section 3.3 where T is set to 10. The obtained ? , see <ref type="bibr" target="#b5">(6)</ref>, for datasets MNIST, CIFAR10, FMNIST, Speech and PIMA are respectively 0.75, 5.22, 0.28, 2.56 and 713.64. All algorithms were implemented in Python using PyTorch framework. All codes are run on Google Colaboratory GPU (Tesla K80) with 12GB RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Evaluation Metric</head><p>A widely used metric for performance evaluation in the AD task is the area under receiver operator curve (ROC) <ref type="bibr" target="#b18">[18]</ref>, <ref type="bibr" target="#b36">[36]</ref>, which is known as AUC. We use AUC to measure the performance of our model and compare with other AD methods. To achieve more reliable results, we repeat each experiment for 10 runs and report the average and standard deviation of the calculated AUCs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results and Analysis</head><p>Results of our method along with the baselines are shown in <ref type="table" target="#tab_2">Table 2</ref>. In each case, the result of the best performing algorithm is denoted in boldface. Several observations can be made from this table: (1) The average performance of the proposed DASVDD method is better than baselines in all five datasets. (2) In most classes of MNIST and FMINST datasets, all baselines except DAGMM can achieve a high average accuracy. Even in these cases, DASVDD has a slight edge over all baselines. On average, the performance of our model, along with other baselines, are better on MNIST rather than FMINST. This can stem from the fact that the FMINST is slightly more challenging due to the considerable amount of intra-class variances. If we inspect the results of the class 1, which corresponds to 'Trouser', we can see that DASVDD significantly performs better than the baselines. Interestingly, this class is one of the only classes that has no visual similarity to any of the other nine classes. Other classes such as 'Sandal' and 'Sneaker' or 'Shirt' and 'Tshirt' have similar samples which can make it difficult to identify some close out of class instances as anomalies. (3) Unlike MNIST and FMINST datasets, all models have a poor performance on CIFAR10. Yet, DASVDD beats other baselines in terms of the average performance. It also performs better in several individual classes. CIFAR10 is considerably more challenging because of its complexity. Unlike  FMINST and MNIST, CIFAR10 images are not well aligned and they usually contain other objects in their background. Therefore, they are more complex and challenging. This can explain why all models have poorer performance on this dataset. (4) On PIMA and Speech datasets of ODDS repository, DASVDD still performs better than baselines. On the speech dataset, some baselines such as OCSVM and IF cannot perform better than a chance-level classifier.</p><p>In general, the performance of all models in this dataset, including ours, is lower than the performance in computer vision datasets. Given the inherent difficulty of the task, the results are justifiable. (5) Overall, DASVDD shows a robust performance accross all datasets and classes. Some models, such as DAGMM, completely fail in several cases, such as in image datsets, particularly because they are not designed for these types of data. However, DASVDD can achieve an acceptable performance comparing to other baselines in all tasks regardless of the type of data or complexity of the problem. (6) <ref type="figure" target="#fig_2">Figure 2</ref> shows the most normal samples (i.e. samples with the lowest anomaly score) and the most anamolous samples (i.e. those with the most anomaly score) of the test set of the MNIST and FMNIST obtained using the proposed DASVDD method. We can see that the samples that our model detect as most anomalous are also deceptive and hard to detect for even human eyes.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Analysis of Biases and Hypersphere Center</head><p>As is discussed before, despite the conventional DSVDD method, the proposed DASVDD method doesn't run into the hyper-sphere collapse issue, and the hyper-sphere centre and the network biases are trainable parameters. We plot the value of c vs. iteration as well as the values of biases during training where the training data is class 8 of CIFAR-10. <ref type="figure" target="#fig_4">Figure 3</ref> shows the resulting plot. We can readily confirm that c is getting trained and converges to its final value after almost 150 iterations. <ref type="figure" target="#fig_4">Figure 3 (a)</ref> shows that the biases are non-zero. Yet, our model converges to a non-trivial solution (i.e., no hyper-sphere collapse is happening). This shows that without fixing c and without setting biases to zero, our end-to-end trained network converges to a proper solution; which is the great advantage of DASVDD over all other DSVDD-based methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Effect of Hyperparameter ?</head><p>In this section, we investigate the the effect of hyperparameter ? and demonstrate the effectiveness of the proposed ? selection strategy discussed in Section 3.3. To this end, in <ref type="figure" target="#fig_1">Figure 4</ref>-a, we plotted the ROC curve of our proposed anomaly detection method for ? ? {10 ?5 , 10 ?3 , 10 ?1 , 10, 10 3 } along with the ROC curve obtained with our proposed automatic selection strategy shown in <ref type="formula" target="#formula_12">(6)</ref>, where class 8 of CIFAR10 is used as the normal class. We can observe that the choice of ? can affect the performance of our anomaly detection model. For large values of ?, such as ? = 10 3 , which could be considered as a case equivalent to removing the effect of the reconstruction error loss in <ref type="formula" target="#formula_12">(3)</ref>, the area under the curve (AUC) decreases significantly. Also, we can confirm that the value of ? that we calculated using our proposed ? selection method (shown as Auto) yields a ROC curve with at least similar performance comparing to other values. This observation, combined with the results of <ref type="table" target="#tab_2">Table 2</ref> shows that our strategy for automatic selection of ? yields an acceptable performance. Though the proposed ? selection strategy is a great way to avoid the tedious manual tuning of the method's hyperparameter, we cannot claim that it finds the most optimal value for ? in every task. Hence, finding a more efficient method for choice of ? can be subject to further studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Convergence Analysis</head><p>To gain better insight to the behavior of our model, we plotted the value of the total loss, i.e. the objective function of (3), along with the value of its sub components, i.e. the SVDD and reconstruction losses, versus iteration during training in <ref type="figure">Figure 5</ref>. We plotted the figure for class 8 of each dataset. From <ref type="figure">Figure 5</ref>, we can confirm that the total loss converges during training. In addition, in all three datasets, the value of the total loss is close to the SVDD loss in the first few iterations and after that, it becomes almost similar to the reconstruction loss. This stems from the way we train our model. We use an optimizer with large initial learning rate and a large decay parameter for training the hypersphere center c during training. As a result, in the first few iterations, the SVDD loss abruptly decreases but then, due to the learning rate decay, it changes more slowly. This is also reflected in the total loss. After first few iterations, the AE-related loss term, i.e. the reconstruction error, dominates the loss function. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Effect of the Latent Representation Size</head><p>To gain better insights into the effect of the latent dimension on the performance of our models, we ran the experiments and changed the size of the latent representation from d h = 32 to d h = 2048. <ref type="figure">Figure 6</ref> depicts the average accuracy against the size of the latent layer for MNIST, CIFAR-10, and Fashion MNIST datasets. One interesting observation is that the performance of the network is not greatly influenced by the size of the latent representation. Even with an overcomplete autoencoder, our network can achieve good results.</p><p>An autoencoder learns to extract the most informative features from the input data by passing it through a bottleneck which commonly has fewer dimensions than the original input. In case of an overcomplete autoencoder, in which the size of the latent representation is equal or bigger than the dimension of the input data, the network might learn to copy the input to the output, without learning any meaningful representation. However, if we regularize the latent representation, for instance by adding the sparsity constraint, the network can still learn meaningful representation even if the latent size is equal or bigger than input dimension. The regularization term prevents the network from converging to the trivial solution of copying the input to the output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we proposed DASVDD, a semi-supervised anomaly detection method that jointly trains an autoencoder and an SVDD on the autoencoder latent representation so that the autoencoder learns to map the normal data to the minimum volume enclosing hyper-sphere, during the training phase. Previous works have used autoencoders as a means for feature reduction to feed it into a classical oneclass classifier such as SVDD. We defined a customized anomaly score which is a combination of reconstruction error of the autoencoder and the distance of the lowerdimensional mapping from the hyper-sphere center. The objective of our model is to minimize this anomaly score on the normal data during training. We also proposed an effective heuristic for finding a suitable value for the hyperparameter of DASVDD prior to training. Our empirical results on five benchmark datasets have shown that DASVDD outperforms several state-of-the-art anomaly detection algorithms. We also showed that DASVDD does not suffer from problems such as hypersphere collapse that other algorithms may encounter. Future studies can explore the efficiency of our method on other domains of application as well as ways to improve its performance by proposing new schemes for hyperparameter tuning and network architecture.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Overview of the proposed method DASVDD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 4 )</head><label>4</label><figDesc>ODDS Speech<ref type="bibr" target="#b40">[40]</ref> which contains 3,686 segments of English speech spoken with different accents where segments are represented by a 400-dimensional feature vector called I-vector. The majority of samples are from American English accent which are labeled as normal and the rest of data which is equal to 1.65% of samples are labeled as anomalies. (5) PIMA<ref type="bibr" target="#b41">[41]</ref> which is from the ODDS repository and is a subset of "Pima Indians diabetes dataset" of the UCI repository. It contains data from female patients of at least 21 years old. The dataset has 765 samples of which 268 (35%) are anomaly. Each sample has 8 attributes. The CIFAR10 and FMNIST datasets are available under MIT licence, and the MNIST and ODDS datasets under CC BY-SA 3.0 and Affero GPL 3.0 licences respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Samples with the lowest (top row) and highest (bottom row) anomaly scores in MNIST (10 left columns) and FMNIST (10 right columns).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 3 .</head><label>3</label><figDesc>(a) Visualization of the DASVDD encoder's weights where biases vector are reshaped and concatenated together for better visualization. Training data is class 8 of CIFAR-10. (b) Hypersphere Center versus iterations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Receiver Operator Curve (ROC) for different values of ? in class 8 of the CIFAR-10 dataset. The area under the curver (AUC) denotes is an indicator of the performance of each model. The ? value which we obtained using the approach described in Section 3.3 is denoted by the thick blue curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>10 Fig. 5 .Fig. 6 .</head><label>1056</label><figDesc>Total Loss, Reconstruction (AE) Loss, and Deep SVDD Loss for the class 8 of (a) MNIST, (b) Fashion MNIST, and (c) CIFAR-10 Datasets Performance of model as a function of latent representation's size on MNIST (28 ? 28), CIFAR-10 (32 ? 32), and Speech (400) Datasets. The reported performance is normalized with respected to the average performance in order to ease the comparison between different datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Both authors are with the Department of Electrical and Computer Engineering, McGill University, and Mila -Quebec AI Institute, Montreal, QC, Canada. E-mail: hadi.hojjati@mcgill.ca narges.armanfard@mcgill.ca</figDesc><table /><note>? This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible toencoders (AEs)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1</head><label>1</label><figDesc>List of Classes for CIFAR-10 and Fashion MNIST datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Class Single Class Name</cell></row><row><cell></cell><cell>0</cell><cell>Airplane</cell></row><row><cell></cell><cell>1</cell><cell>Car</cell></row><row><cell></cell><cell>2</cell><cell>Bird</cell></row><row><cell></cell><cell>3</cell><cell>Cat</cell></row><row><cell>CIFAR-10</cell><cell>4 5</cell><cell>Deer Dog</cell></row><row><cell></cell><cell>6</cell><cell>Frog</cell></row><row><cell></cell><cell>7</cell><cell>Horse</cell></row><row><cell></cell><cell>8</cell><cell>Ship</cell></row><row><cell></cell><cell>9</cell><cell>Truck</cell></row><row><cell></cell><cell>0</cell><cell>TShirt</cell></row><row><cell></cell><cell>1</cell><cell>Trouser</cell></row><row><cell></cell><cell>2</cell><cell>Pullover</cell></row><row><cell></cell><cell>3</cell><cell>Dress</cell></row><row><cell>Fashion MNIST</cell><cell>4 5</cell><cell>Coat Sandal</cell></row><row><cell></cell><cell>6</cell><cell>Shirt</cell></row><row><cell></cell><cell>7</cell><cell>Sneaker</cell></row><row><cell></cell><cell>8</cell><cell>Bag</cell></row><row><cell></cell><cell>9</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 2 AUC</head><label>2</label><figDesc>(%) on benchmark datasets. Best performing method is denoted in boldface. The reported results are the average AUC over 10 runs. Standard deviations are reported for DASVDD</figDesc><table><row><cell>.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell cols="3">Class OCSVM KDE</cell><cell>IF</cell><cell>AE</cell><cell cols="6">VAE DAGMM AnoGAN AND DSVDD Our Method (DASVDD)</cell></row><row><cell></cell><cell>0</cell><cell>98.6</cell><cell>97.1</cell><cell cols="2">98.0 98.8</cell><cell>99.7</cell><cell>50.0</cell><cell>96.6</cell><cell>98.4</cell><cell>98.0</cell><cell>99.7 ?0.1</cell></row><row><cell></cell><cell>1</cell><cell>99.5</cell><cell>98.9</cell><cell cols="2">97.3 99.3</cell><cell>99.9</cell><cell>76.6</cell><cell>99.2</cell><cell>99.5</cell><cell>99.6</cell><cell>99.9?0.0</cell></row><row><cell></cell><cell>2</cell><cell>82.5</cell><cell>79.0</cell><cell cols="2">88.6 91.7</cell><cell>93.6</cell><cell>32.6</cell><cell>85.0</cell><cell>94.7</cell><cell>91.7</cell><cell>95.4?0.6</cell></row><row><cell></cell><cell>3</cell><cell>88.1</cell><cell>86.2</cell><cell cols="2">89.9 88.5</cell><cell>95.9</cell><cell>31.9</cell><cell>88.7</cell><cell>95.2</cell><cell>91.9</cell><cell>96.2?0.4</cell></row><row><cell>MNIST</cell><cell>4 5</cell><cell>94.9 77.1</cell><cell>87.9 73.8</cell><cell cols="2">92.7 86.2 85.5 85.8</cell><cell>97.3 96.4</cell><cell>36.8 49.0</cell><cell>89.4 88.3</cell><cell>96.0 97.1</cell><cell>94.9 88.5</cell><cell>98.1?0.1 97.2?0.6</cell></row><row><cell></cell><cell>6</cell><cell>96.5</cell><cell>87.6</cell><cell cols="2">95.6 95.4</cell><cell>99.3</cell><cell>51.5</cell><cell>94.7</cell><cell>99.1</cell><cell>98.3</cell><cell>99.6?0.1</cell></row><row><cell></cell><cell>7</cell><cell>93.7</cell><cell>91.4</cell><cell cols="2">92.0 94.0</cell><cell>97.6</cell><cell>50.0</cell><cell>93.5</cell><cell>97.0</cell><cell>94.6</cell><cell>98.1?0.3</cell></row><row><cell></cell><cell>8</cell><cell>88.9</cell><cell>79.2</cell><cell cols="2">89.9 82.3</cell><cell>92.3</cell><cell>46.7</cell><cell>84.9</cell><cell>92.2</cell><cell>93.9</cell><cell>94.2?1.2</cell></row><row><cell></cell><cell>9</cell><cell>93.1</cell><cell>88.2</cell><cell cols="2">93.5 96.5</cell><cell>97.6</cell><cell>81.3</cell><cell>92.4</cell><cell>97.9</cell><cell>96.5</cell><cell>98.3?0.5</cell></row><row><cell></cell><cell>avg:</cell><cell>91.3</cell><cell>86.9</cell><cell cols="2">92.3 91.9</cell><cell>96.9</cell><cell>50.6</cell><cell>91.3</cell><cell>96.7</cell><cell>94.8</cell><cell>97.7</cell></row><row><cell></cell><cell>0</cell><cell>61.6</cell><cell>61.2</cell><cell cols="2">60.1 59.9</cell><cell>62.0</cell><cell>41.4</cell><cell>67.1</cell><cell>67.8</cell><cell>61.7</cell><cell>68.6?0.7</cell></row><row><cell></cell><cell>1</cell><cell>63.8</cell><cell>64.0</cell><cell cols="2">50.8 63.8</cell><cell>66.4</cell><cell>57.1</cell><cell>54.7</cell><cell>58.2</cell><cell>65.9</cell><cell>64.3?0.6</cell></row><row><cell></cell><cell>2</cell><cell>50.0</cell><cell>50.1</cell><cell cols="2">49.2 50.9</cell><cell>38.2</cell><cell>53.8</cell><cell>52.9</cell><cell>51.7</cell><cell>50.8</cell><cell>55.8?0.8</cell></row><row><cell></cell><cell>3</cell><cell>55.9</cell><cell>56.4</cell><cell cols="2">55.1 59.4</cell><cell>58.6</cell><cell>51.2</cell><cell>54.5</cell><cell>57.9</cell><cell>59.1</cell><cell>58.6?0.2</cell></row><row><cell>CIFAR10</cell><cell>4 5</cell><cell>66.0 62.4</cell><cell>66.2 62.4</cell><cell cols="2">49.8 59.8 58.5 63.2</cell><cell>38.6 58.6</cell><cell>52.2 49.3</cell><cell>65.1 60.3</cell><cell>65.4 64.3</cell><cell>60.9 65.7</cell><cell>64.0?0.2 62.6?0.5</cell></row><row><cell></cell><cell>6</cell><cell>74.7</cell><cell>74.9</cell><cell cols="2">42.9 65.2</cell><cell>56.5</cell><cell>64.9</cell><cell>58.5</cell><cell>61.3</cell><cell>67.7</cell><cell>71.0?0.1</cell></row><row><cell></cell><cell>7</cell><cell>62.6</cell><cell>62.6</cell><cell cols="2">55.1 65.1</cell><cell>62.2</cell><cell>55.3</cell><cell>62.5</cell><cell>63.0</cell><cell>67.3</cell><cell>64.6?0.2</cell></row><row><cell></cell><cell>8</cell><cell>74.9</cell><cell>75.1</cell><cell cols="2">74.2 76.9</cell><cell>66.3</cell><cell>51.9</cell><cell>75.8</cell><cell>73.9</cell><cell>75.9</cell><cell>81.1?0.4</cell></row><row><cell></cell><cell>9</cell><cell>75.9</cell><cell>76.0</cell><cell cols="2">58.9 72.7</cell><cell>73.7</cell><cell>54.2</cell><cell>66.5</cell><cell>69.7</cell><cell>73.1</cell><cell>73.7?0.3</cell></row><row><cell></cell><cell>avg:</cell><cell>64.8</cell><cell>64.9</cell><cell cols="2">55.5 63.7</cell><cell>58.1</cell><cell>53.1</cell><cell>61.8</cell><cell>63.3</cell><cell>64.8</cell><cell>66.5</cell></row><row><cell></cell><cell>0</cell><cell>90.6</cell><cell>88.3</cell><cell cols="2">86.8 71.6</cell><cell>87.4</cell><cell>51.9</cell><cell>89.0</cell><cell>88.3</cell><cell>79.1</cell><cell>91.2?0.1</cell></row><row><cell></cell><cell>1</cell><cell>97.5</cell><cell>94.3</cell><cell cols="2">97.7 96.9</cell><cell>97.7</cell><cell>34.0</cell><cell>97.1</cell><cell>96.4</cell><cell>94.0</cell><cell>99.0?0.0</cell></row><row><cell></cell><cell>2</cell><cell>88.1</cell><cell>87.7</cell><cell cols="2">87.1 72.9</cell><cell>81.6</cell><cell>26.9</cell><cell>86.5</cell><cell>86.8</cell><cell>83.0</cell><cell>89.3?0.1</cell></row><row><cell></cell><cell>3</cell><cell>91.3</cell><cell>88.4</cell><cell cols="2">90.1 78.5</cell><cell>91.2</cell><cell>57.0</cell><cell>91.2</cell><cell>92.2</cell><cell>82.9</cell><cell>93.7?0.1</cell></row><row><cell>FMNIST</cell><cell>4 5</cell><cell>88.5 87.6</cell><cell>86.3 85.9</cell><cell cols="2">89.8 82.9 88.7 93.1</cell><cell>87.2 91.6</cell><cell>50.4 70.5</cell><cell>87.6 89.6</cell><cell>88.0 86.8</cell><cell>87.0 80.3</cell><cell>90.7?0.4 93.8?1.3</cell></row><row><cell></cell><cell>6</cell><cell>81.4</cell><cell>74.7</cell><cell cols="2">79.7 66.7</cell><cell>73.8</cell><cell>48.3</cell><cell>74.3</cell><cell>76.9</cell><cell>74.9</cell><cell>82.8?0.1</cell></row><row><cell></cell><cell>7</cell><cell>98.4</cell><cell>96.1</cell><cell cols="2">98.0 95.4</cell><cell>97.6</cell><cell>83.5</cell><cell>97.2</cell><cell>98.0</cell><cell>94.2</cell><cell>98.6?0.1</cell></row><row><cell></cell><cell>8</cell><cell>86.0</cell><cell>84.6</cell><cell cols="2">88.3 70.0</cell><cell>79.5</cell><cell>55.1</cell><cell>81.9</cell><cell>87.5</cell><cell>79.1</cell><cell>89.4?0.4</cell></row><row><cell></cell><cell>9</cell><cell>97.7</cell><cell>94.2</cell><cell cols="2">97.9 80.7</cell><cell>96.5</cell><cell>34.0</cell><cell>89.9</cell><cell>96.8</cell><cell>93.2</cell><cell>97.9?0.1</cell></row><row><cell></cell><cell>avg:</cell><cell>90.7</cell><cell>88.0</cell><cell cols="2">90.6 80.9</cell><cell>88.4</cell><cell>51.8</cell><cell>88.4</cell><cell>89.8</cell><cell>84.8</cell><cell>92.6</cell></row><row><cell>Speech</cell><cell>-</cell><cell>49.2</cell><cell>52.2</cell><cell cols="2">50.0 61.3</cell><cell>62.1</cell><cell>59.3</cell><cell>56.2</cell><cell>57.4</cell><cell>58.3</cell><cell>62.4?1.1</cell></row><row><cell>PIMA</cell><cell>-</cell><cell>56.0</cell><cell>64.7</cell><cell cols="2">65.0 57.0</cell><cell>61.0</cell><cell>67.3</cell><cell>62.4</cell><cell>64.5</cell><cell>55.2</cell><cell>72.2?1.2</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Anomaly detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2009-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A state of the art survey of data mining-based fraud detection and credit scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sicong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chengkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weishi</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MATEC Web Conf</title>
		<imprint>
			<biblScope unit="volume">189</biblScope>
			<biblScope unit="page">3002</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Sparse neural networks for anomaly detection in high-dimensional time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gugulothu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">M</forename><surname>Shroff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deepad: A generic framework based on deep learning for time series anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caglayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Assem</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>PAKDD</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">An overview of deep learning based methods for unsupervised and semi-supervised anomaly detection in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Kiran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Parakkal</surname></persName>
		</author>
		<idno>abs/1801.03149</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep anomaly detection using geometric transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Golan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Evaluation of deep learning approaches based on convolutional neural networks for corrosion detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Atha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Jahanshahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Structural Health Monitoring</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1110" to="1128" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep learning for anomaly detection: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V D</forename><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Support vector method for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Neural Information Processing Systems, ser. NIPS&apos;99</title>
		<meeting>the 12th International Conference on Neural Information Processing Systems, ser. NIPS&apos;99<address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="page" from="582" to="588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On Estimation of a Probability Density Function and Mode</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Parzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1065" to="1076" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Isolation forest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<title level="m">Eighth IEEE International Conference on Data Mining</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="413" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Anomaly detection with robust deep autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Paffenroth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD &apos;17</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="665" to="674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Autoencoder-based network anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 Wireless Telecommunications Symposium (WTS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Survey on applying gan for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Beula Rani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sumathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 International Conference on Computer Communication and Informatics (ICCCI)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Anomaly detection using autoencoders with nonlinear dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sakurada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yairi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the MLSDA 2014 2nd Workshop on Machine Learning for Sensory Data Analysis, ser. MLSDA&apos;14</title>
		<meeting>the MLSDA 2014 2nd Workshop on Machine Learning for Sensory Data Analysis, ser. MLSDA&apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="4" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep-anomaly: Fully convolutional neural network for fast anomaly detection in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Moayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="88" to="97" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Csi: Novelty detection via contrastive learning on distributionally shifted instances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tack</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep one-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goernitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4393" to="4402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Flow-based anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Maziarka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Smieja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sendera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Struski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tabor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Spurek</surname></persName>
		</author>
		<idno>abs/2010.03002</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Simple and effective prevention of mode collapse in deep one-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<idno>abs/2001.08873</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Deep learning for anomaly detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chalapathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chawla</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.03407</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reducing the dimensionality of data with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">313</biblScope>
			<biblScope unit="issue">5786</biblScope>
			<biblScope unit="page" from="504" to="507" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Highdimensional and large-scale anomaly detection using a linear oneclass svm with deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajasegarar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karunasekera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Leckie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">C</biblScope>
			<biblScope unit="page" from="121" to="134" />
			<date type="published" when="2016-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Variational autoencoder based anomaly detection using reconstruction probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Stacked convolutional auto-encoders for hierarchical feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<editor>ICANN</editor>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A multimodal anomaly detector for robot-assisted feeding using an lstm-based variational autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hoshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Kemp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1544" to="1551" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Mansour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V D</forename><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A survey on gans for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Mattia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Galeone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Simoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ghelfi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="1906" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised anomaly detection with generative adversarial networks to guide marker discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schlegl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Seeb?ck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Waldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schmidt-Erfurth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Information Processing in Medical Imaging, M. Niethammer</title>
		<editor>M. Styner, S. Aylward, H. Zhu, I. Oguz, P.-T. Yap, and D. Shen</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="146" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Efficient gan-based anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zenati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Foo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lecouat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Manek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">R</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">f-anogan: Fast unsupervised anomaly detection with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schlegl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Seeb?ck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Waldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schmidt-Erfurth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Unrolled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<editor>Bengio and Y. LeCun</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">61</biblScope>
			<biblScope unit="page" from="2121" to="2159" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Odds library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rayana</surname></persName>
		</author>
		<ptr target="http://odds.cs.stonybrook.edu" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Latent space autoregression for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Abati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Porrello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Calderara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">2019</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">MNIST handwritten digit database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Cifar-10 (canadian institute for advanced research)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="http://www.cs.toronto.edu/?kriz/cifar.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Learning outlier ensembles: The best of both worlds -supervised and unsupervised</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Micenkov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcwilliams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Assent</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">UCI Machine Learning Repository</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Asunci?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Newman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<title level="m">Deep Learning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Cambridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Usa</surname></persName>
		</author>
		<ptr target="http://www.deeplearningbook.org" />
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep autoencoding gaussian mixture model for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lumezanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
