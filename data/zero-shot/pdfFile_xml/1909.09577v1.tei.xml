<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NeMo: a toolkit for building AI applications using Neural Modules</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
							<email>okuchaiev@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Li</surname></persName>
							<email>jasoli@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huyen</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksii</forename><surname>Hrinchuk</surname></persName>
							<email>ohrinchuk@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Leary</surname></persName>
							<email>rleary@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
							<email>bginsburg@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Kriman</surname></persName>
							<email>skriman@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislav</forename><surname>Beliaev</surname></persName>
							<email>stanislavv@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Lavrukhin</surname></persName>
							<email>vlavrukhin@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Cook</surname></persName>
							<email>jocook@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrice</forename><surname>Castonguay</surname></persName>
							<email>pcastonguay@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariya</forename><surname>Popova</surname></persName>
							<email>mpopova@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jocelyn</forename><surname>Huang</surname></persName>
							<email>jocelynh@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
							<email>jocohen@nvidia.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NVIDIA</orgName>
								<address>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">NeMo: a toolkit for building AI applications using Neural Modules</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>NeMo (Neural Modules) is a Python framework-agnostic toolkit for creating AI applications through re-usability, abstraction, and composition. NeMo is built around neural modules, conceptual blocks of neural networks that take typed inputs and produce typed outputs. Such modules typically represent data layers, encoders, decoders, language models, loss functions, or methods of combining activations. NeMo makes it easy to combine and re-use these building blocks while providing a level of semantic correctness checking via its neural type system. The toolkit comes with extendable collections of pre-built modules for automatic speech recognition and natural language processing. Furthermore, NeMo provides built-in support for distributed training and mixed precision on latest NVIDIA GPUs. NeMo is open-source. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Deep Learning (DL) has made huge progress from academia to industry in the last decade. However, the process for developing, debugging, and deploying DL software is significantly more cumbersome than other complex software systems. The primary abstraction in all DL frameworks is a multidimensional tensor, typically without any dimensional semantics, e.g. whether the first dimension represents the batch size or something else. The lack of semantics and a type system complicates models' re-use and makes it difficult to build DL systems [6]. It can be challenging to reuse components of a complex DL model across different use cases or developers. The typical approach for reusing and sharing components is based on open-source pre-trained models. Combining and chaining these models together usually requires making changes to the code, which, in turn, requires debugging. This is especially tricky when the models come from different developers or use cases.</p><p>Another complicating factor is that model configurations are usually defined via a Python script instead of a data model. This leads to a blurring of lines between what would otherwise be separate concerns -computational performance, architecture definition, training procedure, visualization and analysis -all mixed together into the same Python script that is difficult to disentangle, debug, or reuse in other contexts.</p><p>All of these challenges -separation of concerns, system decomposition with well-defined verifiable interfaces, and code re-usability -are already well-explored in the world of software engineering. Many of the modern techniques any software developer takes for granted were originally invented in order to address precisely these issues.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We seek to translate common software engineering practices developed to address those issues into the context of developing AI-based applications. Specifically, we focus on the problems of:</p><p>? decomposition of a complex system into functional blocks with well-defined interfaces;</p><p>? static type checking to ensure API compliance and to catch type-mismatch bugs;</p><p>? separation of concerns between model architecture, training procedure, DL framework, optimization algorithm;</p><p>? high performance training by supporting modern efficient hardware features; and</p><p>? reusable pre-built components that can be easily combined in novel ways.</p><p>NeMo consists of: (1) NeMo Core: fundamental building blocks for all neural models and type system and (2) NeMo collections: pre-built neural modules for particular domains such as automatic speech recognition (ASR), and natural language processing (NLP).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>In recent years, there have been a number of high-level toolkits aimed to help users to achieve certain goals easier then by purely using DL frameworks such as TensorFlow <ref type="bibr" target="#b3">[8]</ref> and PyTorch <ref type="bibr" target="#b12">[17]</ref>.</p><p>These toolkits could be loosely classified into two main groups: <ref type="bibr" target="#b0">(1)</ref> higher-level neural network APIs such as Keras <ref type="bibr" target="#b6">[11]</ref>, Sonnet <ref type="bibr" target="#b13">[18]</ref>, PyTorch Ignite [3], PyTorch Lightning [4] and (2) configurationdriven tookits such as Tensor2Tensor <ref type="bibr" target="#b15">[20]</ref>, Ludwig <ref type="bibr" target="#b2">[5]</ref>, OpenSeq2Seq <ref type="bibr" target="#b8">[13]</ref>, FairSeq <ref type="bibr" target="#b11">[16]</ref>, OpenNMT <ref type="bibr" target="#b7">[12]</ref>, Seq2Seq <ref type="bibr" target="#b4">[9]</ref> and many others.</p><p>Conceptually, NeMo Core is closer to the first group. It allows users to express models with arbitrary sets of components and hides away details of training and evaluation loops while still retaining a lot of flexibility. NeMo collections, on the other hand, are closer to the second group. They contain common modules that can be re-used in various scenarios. For example, it is straightforward in NeMo to define templates for fixed patterns, such as an encoder-decoder network.</p><p>NeMo differs from toolkits in the first group in two ways: (1) NeMo's core abstraction is a neural module rather than a layer or a tensor and (2) NeMo contains a neural type system that performs various semantic checks.</p><p>The main difference between NeMo and toolkits in the second group is that NeMo does not impose any particular structure, e.g. many toolkits require models to follow the encoder-decoder-loss structure. NeMo also does not require configuration files to be in any particular format -users can define models directly using NeMo API. Some toolkits from the second group enforce input-output compatibility between blocks <ref type="bibr" target="#b0">[1]</ref>, but NeMo does this using a consistent, generic, and extensible type system.</p><p>Conceptually, NeMo is similar to PyTorchPipe [1], which follows the task-oriented approach, but allows for arbitrary, flexible sets of components, and also performs compatibility checks. It is essentially an application framework, while NeMo allows developer to use its underlying type and composition system, but not otherwise adopt any of the NeMo run-time functionality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">NeMo</head><p>The core building block in NeMo is called Neural Module (NM). A Neural Nodule represents a logical part of a neural network such as a language model, an encoder, a decoder, a data augmentation algorithm, a loss function, or other sets of layers and functions. As the primary abstraction in NeMo, NMs form the basis for describing a model and the process by which that model is trained. Formally, a Neural Module is a component that computes a set of typed outputs given a set of typed inputs. Inputs and outputs are collections of multidimensional tensors. In the same way that a programmer in an object-oriented language can choose at what level of granularity to define an object, a NeMo user can choose the level of granularity of a Neural Module. A basic rule is that inputs and outputs should "make sense" to expose via an interface. This suggests that a Neural Module is not typically a single neural network layer, but rather a collection of connected layers that "do something useful" such as an encoder, a concatenation operation, a loss function, or a data augmentation.</p><p>In our implementation, a NM is a Python class that describes its input ports and output ports using the type system described below. The current implementation relies on PyTorch, but the abstractions and code does not make any reference to the underlying framework, allowing for applications to be framework-agnostic and for the addition of new backends in the future (see <ref type="figure">Figure 1</ref>).</p><p>A NM can compute its output port values given provided input port values. For NMs that contain trainable weights, they should also be able to compute the gradient flows. Implementations of the forward and backward passes are provided by the underlying DL framework. One way to think of a NM is that it is able to "lower" itself into either another set of NMs (recursively), a set of well-defined neural network layers implemented in PyTorch, or in the case of non-trainable NMs, by directly evaluating the output values given the input values.</p><p>A NM may be parameterized. For example, an image encoder NM can be parameterized by the number of convolutional layers, filter sizes, dropout values, etc. In this way, a NM defines a parametric family of neural networks, where the variation is explicitly determined by parameter values. Parameters are passed to the NM at construction time via named parameters, and the code that defines how lowering occurs only depends on constructor-time values of these parameters 2 .</p><p>Similar to functional programming languages, the evaluation of a NM's outputs or gradients cannot effect the evaluation of any other NM's inputs or gradients, except via explicitly linked inputs and outputs which follow standard neural network forward and backward propagation rules. This decoupling helps enforce clean and correct decomposition of complex models according to welldefined interfaces because evaluations cannot have side effects. Furthermore, explicitly defined parameters allow experiment tracking and integration with hyperparameter search tools to be greatly simplified.</p><p>This illustrates a major principle of NeMo: the structure of a neural network and its forward and backward data flows should be determined by values in data structures, not by logic encoded in Python source code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">NeMo Core</head><p>An application built with NeMo typically consists of 3 required stages and 1 optional stage: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Neural types system</head><p>NeMo Core defines the interface and functionality of the NeuralModule base class. Each input and output of a NM has a Neural Type. Neural Types describe the semantics, axis order, and dimensions of a tensor. The purpose of this type system is to catch semantic and dimensionality errors during model creation and facilitate module re-use. If the output type of one NM output port matches the input type of another NM input port, it is legal to connect these two NMs together, regardless of where they came from or how they are implemented. Because we use static type checking, NeMo can catch semantic and dimensionality errors during the DAG creation stage.</p><p>A Neural Type is a mapping from each tensor axis ID to an Axis Type. An Axis Type contains semantic and dimensional information of a tensor's axis. Semantic information is represented with the help of "semantic tags" -Python classes related by "is-a" kind of inheritance. A NeuralType is constructed from a dictionary, axis2type, which maps an axis index to its AxisType. For example, the input and output ports of a typical ResNet encoder can be described as follows: NeMo defines binary comparison operation for any pair of NeuralType objects with various comparison results, such as SAME, LESS, GREATER, DIM_INCOMPATIBLE, TRANSPOSE_SAME, and INCOMPATIBLE. This type system also allows for non-tensor objects (such as scalars) and the root type which is somewhat analogous to void* in C++: a port of root type can accept any tensor 3 .</p><p>Examples of errors that NeMo's type system can catch at model definition time include: "Ranks match but semantics don't", "Concatenating along the semantically wrong dimensions", and "Dimensions mismatch". For example, consider an encoder-decoder model where the decoder expects input in the form of [batch_dim, time_dim, channel_dim] and the encoder, written by another developer, outputs a [time_dim, batch_dim, channel_dim] tensor. Time and batch dimensions are often dynamic, and if channel_dim remains constant, standard frameworks will run smoothly but the model will fail to converge, forcing the developer to find and fix this silent error. However, NeMo will throw a semantic type error at the moment these modules are connected. In this case, the result of type comparison operation will be TRANSPOSE_SAME instead of SAME. 4 . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Output port type</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">High performance training</head><p>NeMo is built to take full advantage of the latest DL hardware such as NVIDIA's Volta and Turing GPUs. It automatically supports mixed precision training, using float16 for computationally intensive operations such as matrix multiplies and convolutions while keeping some things in float32, and employing dynamic loss scaling <ref type="bibr" target="#b10">[15]</ref>.</p><p>NeMo also supports gradient accumulation, a technique that accumulates gradients on workers and updates weights only after a certain number of batches have been processed. This allows very large batch simulations on cards with limited RAM and facilitates distributed multi-GPU runs by reducing the amount of inter-worker communication. NeMo also supports multi-GPU and multi-node training using NVIDIA's APEX library <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NeMo collections</head><p>A NeMo collection is the DL equivalent of a software collection of related functions. Common NMs for particular domains are pre-built and packaged into "collections". Currently, NeMo provides collections for automatic speech recognition (ASR) and natural language processing (NLP), but users can easily add new collections. Some of those NMs may come with pre-trained weights. A NeMo collection is the DL equivalent of a software library containing a collection of related functions. In practice, a collection is simply a Python module that defines NM classes, neural types, and associated helper routines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Automatic Speech Recognition</head><p>nemo_asr is a collection of neural modules and helper functions that can be used to train and evaluate Automatic Speech Recognition (ASR) models. It currently supports two model types: CTC-based and sequence-to-sequence attention-based.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">CTC-based speech recognition</head><p>As an example, we describe the steps necessary to train a Jasper-like ASR model <ref type="bibr" target="#b9">[14]</ref> using nemo_asr.</p><p>First, we create a Neural Module Factory object which manages training and instantiation of neural modules. Jasper uses a JasperEncoder, a JasperDecoderForCTC, and a CTCLossNM. Each of these NMs is passed parameters at construction time -we omit them here to make the code simpler to read. a n s c r i p t , i n p u t _ l e n g t h = e n c o d e d _ l e n , t a r g e t _ l e n g t h = t r a n s c r i p t _ l e n )</p><p>In the first line, the data_layer produces 4 output ports, which are returned as a tuple. The jasper_encoder has two named input ports, which are connected to two of the data_layer output ports.</p><p>During the definition of this DAG neural type system checks are performed to ensure the correct usage of various modules together. Finally, once the DAG is described, we should call a neural factory's action, such as train to trigger the training procedure and data flow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Neural modules re-use: attention-based speech recognition</head><p>As an illustration of model reuse, we show how to build a different ASR model using attention-based sequence learning, but reusing the same data layer and the Jasper encoder. The model we'll build is conceptually similar to LAS <ref type="bibr" target="#b5">[10]</ref> . . . / / i n s t a n t In this example, we switch out JasperDecoderForCTC for a DecoderRNN, and CTCLoss for a SequenceLoss NM. Note, that we use a JasperRNNConnector NM to correct for the dimensionality mismatch between JasperEncoder and DecoderRNN. Notice that DecoderRNN comes from a different collection, and could be first pre-trained as a stand-alone language model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Natural Language Processing</head><p>nemo_nlp is a collection of neural modules and callback functions which can be used for various NLPrelated tasks such as neural machine translation (NMT), language modeling, sentence classification, asr correction, joint intent classification and slot filling. It also supports BERT pre-training and finetuning for each task. For BERT, we rely on the implementation from pytorch-transformers <ref type="bibr">[7]</ref>. We plan to extend this collection in future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Neural Machine Translation</head><p>Here we show how to build Tranformer-BIG <ref type="bibr" target="#b14">[19]</ref> using nemo_nlp. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and future work</head><p>NeMo addresses many of the issues often encountered in developing DL applications by transferring best practices from software engineering. It operates with a higher level abstraction, the neural module, and introduces a neural type system capable of semantic checks. It also comes with collections of pre-built modules for conversational AI -nemo_asr and nemo_nlp to make building and re-using deep neural networks easier.</p><p>We are working on expanding existing NeMo collections and adding new ones. Also, exploring the right design for a neural type system and the most useful levels of abstractions for modules is an ongoing research direction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>i n p u t _ p o r t s = { " x " : N e u r a l T y p e ( { 0 : AxisType ( B a t c h T a g ) , 1 : AxisType ( C h a n n e l T a g ) , 2 : AxisType ( H e i g h t T a g , 2 2 4 ) , 3 : AxisType ( WidthTag , 2 2 4 ) } ) } o u t p u t _ p o r t s = { " o u t p u t " : N e u r a l T y p e ( { 0 : AxisType ( B a t c h T a g ) , 1 : AxisType ( ImageEmbeddingTag ) } ) }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>n f = nemo . c o r e . N e u r a l M o d u l e F a c t o r y ( . . . ) d a t a _ l a y e r = n e m o _ a s r . A u d i o T o T e x t D a t a L a y e r ( . . . ) j a s p e r _ e n c o d e r = n e m o _ a s r . J a s p e r E n c o d e r ( . . . ) j a s p e r _ d e c o d e r = n e m o _ a s r . J a s p e r D e c o d e r F o r C T C ( . . . ) c t c _ l o s s = n e m o _ a s r . CTCLossNM ( . . . ) Next, we define the Directed Acyclic Graph (DAG) of how activations flow from output ports to input ports. s p e c , s p e c _ l e n , t r a n s c r i p t , t r a n s c r i p t _ l e n = d a t a _ l a y e r ( ) encoded , e n c o d e d _ l e n = j a s p e r _ e n c o d e r ( a u d i o _ s i g n a l = s p e c , l e n g t h = s p e c _ l e n ) l o g _ p r o b s = j a s p e r _ d e c o d e r ( e n c o d e r _ o u t p u t = e n c o d e d ) l o s s = c t c _ l o s s ( l o g _ p r o b s = l o g _ p r o b s , t a r g e t s = t r</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>i a t e most m o d u l e s a s b e f o r e c o n n e c t o r = n e m o _ a s r . J a s p e r R N N C o n n e c t o r ( . . . ) d e c o d e r = nemo . common . DecoderRNN ( . . . ) s e q _ l o s s = nemo . common . S e q u e n c e L o s s ( . . . ) s p e c , s p e c _ l e n , t r a n s c r i p t , t r a n s c r i p t _ l e n = d a t a _ l a y e r ( ) encoded , e n c o d e d _ l e n = j a s p e r _ e n c o d e r ( a u d i o _ s i g n a l = s p e c , l e n g t h = s p e c _ l e n ) e n c o d e d = c o n n e c t o r ( t e n s o r = e n c o d e d ) l o g _ p r o b s , _ = d e c o d e r ( t a r g e t s = t r a n s c r i p t s , e n c o d e r _ o u t p u t s = e n c o d e d ) t r a i n _ l o s s = s e q _ l o s s ( l o g _ p r o b s = l o g _ p r o b s , t a r g e t s = t r a n s c r i p t s )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>First, we instantiate</head><label></label><figDesc>the NMs representing logical parts of the model: TranslationDataLayer, TransformerEncoderNM, TransformerDecoderNM, TransformerLogSoftmaxNM, and PaddedSmoothedCrossEntropyLossNM. Then we construct the DAG of activation flow that looks like this: s r c , s r c _ m a s k , t g t , t g t _ m a s k , l a b e l s , s e n t _ i d s = t r a i n _ d a t a _ l a y e r ( ) s r c _ h i d d e n s = e n c o d e r ( i n p u t _ i d s = s r c , i n p u t _ m a s k _ s r c = s r c _ m a s k ) t g t _ h i d d e n s = d e c o d e r ( i n p u t _ i d s _ t g t = t g t , h i d d e n _ s t a t e s _ s r c = s r c _ h i d d e n s , i n p u t _ m a s k _ s r c = s r c _ m a s k , i n p u t _ m a s k _ t g t = t g t _ m a s k ) l o g _ s o f t m a x = l o g _ s o f t m a x ( h i d d e n _ s t a t e s = t g t _ h i d d e n s ) t r a i n _ l o s s = l o s s ( l o g _ p r o b s = l o g _ s o f t m a x , t a r g e t _ i d s = l a b e l s ) The code for training and callbacks is similar to the previous examples. NeMo retains underlying framework's efficiency. In our experiment, this model achieves 29.2 BLEU / 28.5 SacreBLEU on newstest2014 after training for about 15 hours on WMT16 English-German using single machine with 8 GPUs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>1. Instantiate a NeuralFactory object and the necessary NMs. 2. Define the activation flow DAG by connecting NMs together. 3. (optional) Define callbacks for logging, checkpointing, visualization, and evaluation. 4. Invoke an action such as train, eval, or infer.NeMo follows a lazy execution model: no computation is done until an action is called. During the definition of the activation flow directed acyclic graph (DAG), NeMo does type checking for the inputs and outputs of connected NMs. This helps catch and debug various errors prior to doing any computations. Once the DAG of modules is defined and action is called, NeMo invokes the DL framework, which we call a backend. NeMo is designed to be framework-agnostic, but it currently only supports PyTorch as backend.Users can create their own NMs by combining existing NMs or providing an implementation in a particular framework. In practice, any PyTorch nn.Module can be easily converted into a NeMo's NM by adding input and output port definitions -i.e. what is expected by and returned from the forward function.</figDesc><table><row><cell>Figure 1: NeMo is a framework-agnostic</cell></row><row><cell>toolkit which serves as abstraction level</cell></row><row><cell>between application and DL frameworks</cell></row><row><cell>backend.</cell></row></table><note>Similar to scikit-learn and Keras, NeMo allows users to create callbacks for routines performed during training such as evaluation, logging, and performance monitoring.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Examples of NeMo Neural Types. {} denotes "root" neural type. These examples assume the following: (1) Spectrogram and Encoded types are inherited from the Channel type (2) Module's A output port is connected to module's B input port.</figDesc><table><row><cell></cell><cell>Input port type</cell><cell>Comparison Result</cell></row><row><cell>{0: Batch, 1: Channel}</cell><cell cols="2">{0: Batch, 1: Spectrogram} GREATER (INCOMPATIBLE)</cell></row><row><cell>{0: Batch, 1: Spectrogram}</cell><cell>{0: Batch, 1: Channel}</cell><cell>LESS (COMPATIBLE)</cell></row><row><cell>{0: Batch, 1: Spectrogram}</cell><cell>{0: Batch, 1: Encoded}</cell><cell>INCOMPATIBLE</cell></row><row><cell>{0: Batch, 1: Spectrogram}</cell><cell>{0: Spectrogram, 1: Batch}</cell><cell>TRANSPOSE_SAME</cell></row><row><cell cols="2">{0: Batch, 1: Spectrogram:64} {0: Batch, 1: Channel:40}</cell><cell>DIM_INCOMPATIBLE</cell></row><row><cell cols="2">{0: Batch, 1: Spectrogram:64} {}</cell><cell>SAME</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">This is enforced via convention for now.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">In the future, we plan to add a template type system modeled on a simplified version of C++ templates to support type-safe generics for operations such as concatenation.4  It is possible to add implicit casts where the system automatically inserts simple operations such as transposition to "fix" simple type mismatches, similar to how C++ can automatically promote int to float.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">n f . t r a i n ( t e n s o r s _ t o _ o p t i m i z e = [ l o s s ] , c a l l b a c k s = [ t r a i n _ c b , s a v e r _ c b ] , . . . )</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pytorchpipe</surname></persName>
		</author>
		<ptr target="https://github.com/ibm/pytorchpipe" />
		<imprint>
			<biblScope unit="page" from="2019" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A pytorch extension: Tools for easy mixed precision and distributed training in pytorch</title>
		<ptr target="https://github.com/NVIDIA/apex" />
		<imprint>
			<biblScope unit="page" from="2019" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ludwig</surname></persName>
		</author>
		<ptr target="http://ludwig.ai" />
		<imprint>
			<biblScope unit="page" from="2019" to="2027" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">TensorFlow: Largescale machine learning on heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjunath</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Levenberg</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/.Softwareavailablefromtensorflow.org" />
		<editor>Man?, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi?gas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Massive Exploration of Neural Machine Translation Architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Britz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Goldie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017-03" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Listen, attend and spell: A neural network for large vocabulary conversational speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4960" to="4964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">OpenNMT: Open-source toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/P17-4012" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACL 2017, System Demonstrations</title>
		<meeting>ACL 2017, System Demonstrations<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-07" />
			<biblScope unit="page" from="67" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Openseq2seq: extensible toolkit for distributed and mixed precision training of sequence-to-sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Gitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Lavrukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Case</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paulius</forename><surname>Micikevicius</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10387</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lavrukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Gaddei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jasper</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03288</idno>
		<title level="m">An end-to-end convolutional neural acoustic model</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paulius</forename><surname>Micikevicius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonah</forename><surname>Alben</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">F</forename><surname>Diamos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>Elsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Garc?a</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Houston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>Mixed precision training. ICLR</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">fairseq: A fast, extensible toolkit for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of NAACL-HLT 2019: Demonstrations</title>
		<meeting>NAACL-HLT 2019: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Open sourcing Sonnet -a new library for constructing neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malcolm</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Barth-Maron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Besse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>De Las</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Fidjeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adri?</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Puigdom?nech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Racani?re</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Viola</surname></persName>
		</author>
		<ptr target="https://deepmind.com/blog/open-sourcing-sonnet/" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Tensor2tensor for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Sepassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<idno>abs/1803.07416</idno>
		<ptr target="http://arxiv.org/abs/1803.07416" />
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
