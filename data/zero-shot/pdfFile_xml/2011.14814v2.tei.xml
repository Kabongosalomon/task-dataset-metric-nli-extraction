<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cost Function Unrolling in Unsupervised Optical Flow</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Lifshitz</surname></persName>
							<email>lifshitz@mail.tau.ac.il</email>
							<affiliation key="aff0">
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Raviv</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Tel Aviv University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Cost Function Unrolling in Unsupervised Optical Flow</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Steepest descent algorithms, which are commonly used in deep learning, use the gradient as the descent direction, either as-is or after a direction shift using preconditioning. In many scenarios calculating the gradient is numerically hard due to complex or non-differentiable cost functions, specifically next to singular points. In this work we focus on the derivation of the Total Variation semi-norm commonly used in unsupervised cost functions. Specifically, we derive a differentiable proxy to the hard L 1 smoothness constraint in a novel iterative scheme which we refer to as Cost Unrolling. Producing more accurate gradients during training, our method enables finer predictions of a given DNN model through improved convergence, without modifying its architecture or increasing computational complexity. We demonstrate our method in the unsupervised optical flow task. Replacing the L 1 smoothness constraint with our unrolled cost during the training of a well known baseline, we report improved results on both MPI Sintel and KITTI 2015 unsupervised optical flow benchmarks. Particularly, we report EPE reduced by up to 15.82% on occluded pixels, where the smoothness constraint is dominant, enabling the detection of much sharper motion edges. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The L 1 norm of the gradients of a given function, also known as Total Variation (TV) semi-norm, and more specifically its estimation, has been a significant field of study in robust statistics <ref type="bibr" target="#b10">[11]</ref>. Even prior to the sweeping AI era, many approaches to Computer Vision problems, such as image restoration, denoising and registration <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b33">34]</ref>, have used a TV regularizer, as it represents the prior distribution of pixel intensities of natural images <ref type="bibr" target="#b9">[10]</ref>. Its main advantage is its robustness to small oscillations such as noise while preserving sharp discontinuities such as edges.</p><p>Historically, solving the TV problem has been a challenging task, mainly due to the non-differenetiabilty of the <ref type="bibr" target="#b0">1</ref> Under review. Our code will be publicly available upon publication. L 1 norm at zero. As a result, differentiable relaxations have been proposed, such as the Huber <ref type="bibr" target="#b11">[12]</ref> and Charbonnier <ref type="bibr" target="#b6">[7]</ref> loss functions. Further approaches involved iterative variational methods and have shown superior results in many tasks <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b33">34]</ref>. Introducing trainable Deep Neural Networks (DNNs) to Computer Vision has brought a significant performance boost, and specifically the commonly used auto-derivation frameworks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b23">24]</ref> have provided quick and easy tools to solve complex functions. Indeed, these frameworks commonly bypass the L 1 non-differentiability either by a differentiable proxy or using its sub-gradients. We claim that non-differentiable cost functions should be dealt with greater care, as was done for many years before the deep learning era.</p><p>Proximal iterative methods for learning complex functions have shown superiority in many Image Processing, as well as Computer Vision tasks <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b34">35]</ref>. In these works, axiomatic optimization algorithms are unrolled and each iteration is mapped to a sub-network having its own learnable parameters. The resulting network architectures con-sist of task specific stacked modules which may be trained end-to-end in both supervised and unsupervised manners. Performance boost has been achieved either by increasing the number of stacked modules <ref type="bibr" target="#b32">[33]</ref> or introducing intermediate modules <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b31">32]</ref>, both resulting in increased model complexity and size.</p><p>In this paper, we shift unrolling to the cost function, improving DNN model optimization while preserving its architecture as opposed to standard unrolling. Specifically, we present a novel pipeline we refer to as Cost Unrolling, in which we unroll the commonly used unsupervised cost function consisting of a data term and TV smoothness regularization, to obtain an iterative proxy. Following the well known Alternating Direction Method of Multiplies (ADMM) <ref type="bibr" target="#b2">[3]</ref> algorithm, our initial optimization problem is iteratively decomposed into a set of sub-problems, each one featuring a differentiable cost function. Gradients computed using all sub-cost functions at each training step are shown to be more accurate in the regions where the gradients of the original cost function are hard to evaluate or undefined, improving convergence.</p><p>We demonstrate the effectiveness of our unrolled cost function in synthetic experiments, as well as the unsupervised optical flow domain. The lack of available labeled data has made unsupervised optical flow learning a significant field of interest. Used cost functions commonly consist of a measure for image consistency and TV smoothness regularization. The occluded pixels, pixels within a reference image with no correspondence at the target image, are masked out when measuring image consistency. As a result, occluded regions, which are highly correlated to motion boundaries, are mostly dominated by the gradients of the smoothness constraint.</p><p>Our unrolled cost function is introduced to the recently published unsupervised optical flow pipeline ARFlow <ref type="bibr" target="#b17">[18]</ref>. Replacing their used TV smoothness constraint with our unrolled cost during all phases of training produces improved results on both MPI Sintel <ref type="bibr" target="#b3">[4]</ref> and KITTI 2015 <ref type="bibr" target="#b21">[22]</ref> unsupervised optical flow benchmarks. Particularly, we report EPE reduced by up to 15.82% on occluded pixels, where the smoothness constraint is dominant, allowing the detection of much sharper motion edges, as is highly visible in figures 1 and 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Contributions</head><p>We summarize our contributions as follows:</p><p>? Present the first unrolled cost function in deep learning for TV regularized problems.</p><p>? Demonstrate our proposed pipeline in the real-life unsupervised optical flow domain.</p><p>? Report improved results on unsupervised optical flow benchmarks, achieved without modifying model architecture or increasing complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Total Variation (TV) minimization has been a significant field of research in robust statistics <ref type="bibr" target="#b10">[11]</ref>. It was introduced to Image Processing and Computer Vision tasks by <ref type="bibr" target="#b24">[25]</ref> and showed superior performance over previous methods mainly due to its edge preserving property. However, solving TV regularized problems has shown to be non-trivial, mainly as the L 1 norm is non-differentiable at zero. Differentiable relaxations were proposed by <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12]</ref>, however iterative variational methods have proven more effective <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b33">34]</ref>.</p><p>Introducing trainable DNN models to Computer Vision tasks has brought a significant performance boost. The lack of labeled data available for training has pushed many DNN algorithms towards unsupervised learning. Not surprisingly, the TV smoothness regularization can be found in the cost functions of many unsupervised works both past and recent. As DNN algorithms use gradient descent algorithms for optimization, the non-differentiability of the L 1 norm at zero has been commonly bypassed either by differentiable approximations <ref type="bibr" target="#b20">[21]</ref> or by using its subgradients <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20]</ref>.</p><p>Algorithm unrolling is an iterative structured approach for learning complex functions, in which iterative operations derived from axiomatic algorithms determine the model architecture. A vast review of the topic is presented in <ref type="bibr" target="#b22">[23]</ref>. Axiomatic algorithms, such as the Alternating Direction Method of Multipliers (ADMM) <ref type="bibr" target="#b2">[3]</ref>, Half Quadratic Splitting (HQS) <ref type="bibr" target="#b1">[2]</ref> or Primal-Dual method <ref type="bibr" target="#b5">[6]</ref>, have inspired many deep algorithm unrolling frameworks. Indeed, ADMM-Net <ref type="bibr" target="#b28">[29]</ref> introduced a DNN model for compressed sensing with architecture derived from ADMM, USRNet <ref type="bibr" target="#b34">[35]</ref> learned Single Image Super-Resolution (SISR) using a deep framework inspired by HQS and <ref type="bibr" target="#b32">[33]</ref> demonstrated an iterative structure derived from a Primal-Dual solver, aimed to refine the optical flow predicted by a FlowNet <ref type="bibr" target="#b7">[8]</ref> model. However, these frameworks feature closed form update steps derived from the learned objective function, which are mapped into task specific sub-networks trained in a supervised manner, increasing model size and complexity. As opposed to standard unrolling, we demonstrate improving the optimization of a given DNN model while preserving its architecture. We unroll the commonly used unsupervised cost function consisting of a data term and TV smoothness regularization, to obtain an iterative differentiable proxy which produces more accurate gradients during training (demonstrated in the experimentation section). While previous works designed dedicated unrolled learnable units, we present a pipeline that can be applied to any model architecture. </p><formula xml:id="formula_0">t ? {0, ..., T ? 1} to produce {Q (t) , ? (t) } T ?1</formula><p>t=0 , which are then used together with C to construct the unrolled loss function in <ref type="bibr" target="#b9">(10)</ref>. As our unrolled cost is computed only during training, our method does not affect inference.</p><p>Learning in iterations has shown to be very effective at both image registration and optical flow tasks. While FlowNet and FlowNet 2.0 <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b12">13]</ref> were the first to learn optical flow, they were surpassed in both supervised and unsupervised settings, by the well known PWC-Net <ref type="bibr" target="#b27">[28]</ref> which featured a course-to-fine iterative scheme. RAFT <ref type="bibr" target="#b29">[30]</ref> introduced a fully iterative architecture which enabled a significant performance boost, as well as its expansion to the unsupervised settings <ref type="bibr" target="#b26">[27]</ref>. Further approaches, such as <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>, managed to improve the results of existing frameworks by adding intermediate modules and parameters for better flow refinement, which increase model size and complexity.</p><p>Here we demonstrate that unlike all other methods, improving the ability of a model to predict a finer flow can be achieved simply through improving the computed gradients during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Cost Function Unrolling</head><p>A general formulation of the cost function used for unsupervised learning consists of a data term, measuring the likelihood of a given prediction over the given data, as well as a prior term, constraining probable predictions. In this work we consider the TV regularized unsupervised cost function case and unroll it to obtain our novel smoothness regularizer. Denote by ? the set of trainable parameters of a DNN model, its predicted output F and the set of unlabeled training data I. The unsupervised TV regularized cost function takes the form:</p><formula xml:id="formula_1">L(I, ?) = ? (F, I) + ? ?F 1<label>(1)</label></formula><p>where ?(?) is a differentiable function measuring the likelihood of F over the training data I, ?F are its spatial gradients, ? 1 is the L 1 norm and ? is a hyperparameter controlling regularization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Unrolling the Unsupervised Cost Function</head><p>Our goal is to minimize the objective function in <ref type="bibr" target="#b0">(1)</ref>. Following the ADMM <ref type="bibr" target="#b2">[3]</ref> algorithm, we derive the iterative update steps minimizing <ref type="bibr" target="#b0">(1)</ref>, which are then used to construct our unrolled cost function. Let us examine the following optimization problem:</p><formula xml:id="formula_2">F = arg min F {? (F, I) + ? ?F 1 }<label>(2)</label></formula><p>We rewrite (2), introducing an auxiliary variable Q:</p><formula xml:id="formula_3">F,Q = arg min F,Q {? (F, I) + ? Q 1 } s.t. Q = ?F<label>(3)</label></formula><p>The augmented Lagrangian is then constructed as follows:</p><formula xml:id="formula_4">L ? (F, Q, ?) = ? (F, I) + ? Q 1 + ?, Q ? ?F 2 + ? 2 Q ? ?F 2 2<label>(4)</label></formula><p>where ? is the Lagrange Multipliers matrix and ? is a penalty parameter. Substituting ? = ? ? for simplicity, we iteratively optimize {F, Q, ?} through solving the subproblems (5a), (5b) and update the multipliers (5c) in each iteration:</p><formula xml:id="formula_5">F = min F ? (F, I) + ? 2 Q ? ?F + ? 2 2 (5a) Q = min Q ? Q 1 + ? 2 Q ? ?F + ? 2 2 (5b) ? ?? + ?(Q ? ?F)<label>(5c)</label></formula><p>with ? an update rate. The solutions to the problems in (5a) and (5b) are referred to as the ADMM update steps for F and Q, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Solving the Sub-Optimization Problems</head><p>Solutions to the sub-optimization problems in equations (5a) and (5b) are now discussed. While the problem in equation (5b) has a closed form solution, deriving a closed form solution for the problem in (5a) is not trivial, as ? can be any function. Substituting C = ?F, (5b) reduces to:</p><formula xml:id="formula_6">min Q ? Q 1 + ? 2 Q ? C + ? 2 2 = min Q ? i |Q i | + ? 2 i |Q i ? C i + ? i | 2 = i min Qi ?|Q i | + ? 2 |Q i ? C i + ? i | 2<label>(6)</label></formula><p>where A i are the matrix elements of A, i.e. the problem is separable and we may solve independently for each matrix element. The objective in <ref type="formula" target="#formula_6">(6)</ref> is convex and its solution is the well known Soft Thresholding</p><formula xml:id="formula_7">operatorQ i = S ?/? (C i ? ? i ), defined: S ?/? (x) = 0, |x| &lt; ?/? x ? ? ? sign(x), |x| ? ?/?<label>(7)</label></formula><p>The Soft Thresholding operator performs shrinkage of the input signal, thus it promotes sparse solutions. We now consider the sub-problem in equation (5a). Using the same substitution as in <ref type="formula" target="#formula_6">(6)</ref>, we wish to optimize:</p><formula xml:id="formula_8">min F ? (F, I) + ? 2 Q ? C + ? 2 2<label>(8)</label></formula><p>Deriving a closed form solution is not trivial, as we wish to optimize for any ?(?). However, note that the problem in (8) consists of the same data term as in <ref type="formula" target="#formula_2">(2)</ref> with the TV smoothness regularizer replaced by a softer, differentiable constraint. Re-substituting into eq. (8), the constraint takes the form:</p><formula xml:id="formula_9">? 2 S ?/? (?F ? ?) ? (?F ? ?) 2 2<label>(9)</label></formula><p>Recall that minimizing the TV of a function promotes sparse output gradients. In fact, (9) yields a differentiable alternative for TV minimization, as it suggests minimizing the L 2 distance between the true and sparsified output gradients in each ADMM iteration. This realization stands in the core of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Unrolled Cost Function</head><p>Our unrolled cost function is inspired by the ADMM update steps given in equations (5a),(5b),(5c). However, instead of explicitly refining F in each iteration as in standard unrolling, we aim to solve the iterative sub-problems given in (5a) simultaneously, updating Q, ? alone given a fixed model prediction F.</p><p>Our proposed unrolled cost function takes the form:</p><formula xml:id="formula_10">L F (I, ?) =? (F, I) + ? 2 1 T T ?1 t=0 Q (t) + ? (t) ? C 2 2<label>(10)</label></formula><p>where:</p><formula xml:id="formula_11">Q (t) = S ?/? ?F ? ? (t?1) (11a) ? (t) = ? (t?1) + ? Q (t) ? ?F (11b)</formula><p>C = ?F and T is a hyperparameter stating the number of update steps carried. Thus, at each training iteration, given a model prediction F, its spatial gradients C are calculated and used to iteratively compute {Q (t) , ? (t) } T ?1 t=0 . All update terms are then accumulated to construct the smoothness constraint in <ref type="bibr" target="#b9">(10)</ref>, which is used for model training. A block diagram for the unsupervised optical flow setting (described in section 4.2) is shown in <ref type="figure" target="#fig_1">figure 2</ref>. Being fully differentiable, specifically around its optimum, our unrolled smoothness constraint produces more accurate gradients, converges more efficiently and improves performance, as is shown in the experimentation section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimentation</head><p>We demonstrate the effectiveness of our method through conducting experiments in two domains: piece-wise constant (PC) signal prediction (section 4.1) and unsupervised optical flow (section 4.2).</p><p>We further compare our unrolled cost to standard TV smoothness regularization, as well as L 1 relaxation baselines: Huber <ref type="bibr" target="#b11">[12]</ref> and Charbonnier <ref type="bibr" target="#b6">[7]</ref> loss functions. The Huber regularizer over a prediction x is defined as R H (x; k) = i r H (x i ; k), where: <ref type="figure">Figure 3</ref>. PC signal prediction -training. We train a simple model to predict a full PC 1D function given a small set of sampled points and TV regularization, using our unrolled cost, as well as TV cost function and common TV relaxation methods. From right to left: displayed are the validation errors and gradient norms, recorded during training, as well as gradients measured at x = ?1 and x = 1, respectively. As can be seen, our unrolled cost not only achieves the best results, but it also converges the fastest and the smoothest. Displayed are the generated target signal, its samples and signals predicted by models trained using either standard TV regularization or our unrolled cost function. As can be seen, our unrolled cost overcomes the staircasing effect, promoting a solution which is both smooth and edge preserving. and x i are the elements of x. It aims to take advantage of the L 1 norm robustness to outliers, but suggests better convergence replacing L 1 by L 2 for points near its optimum. The Charbonnier regularizer is defined as</p><formula xml:id="formula_12">r H (x i ; k) = 1 2 x 2 i , |x i | &lt; k k|x i | ? 1 2 k 2 |x i | ? k<label>(12)</label></formula><formula xml:id="formula_13">R C (x) = i r C (x i ), where: r C (x i ) = x 2 i + 2<label>(13)</label></formula><p>We show that our iterative approach is superior to these L 1 relaxations, achieving improved results and faster convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">PC Signal Prediction</head><p>We our training data {(x i , y i )} N ?1 i=0 where y i = y(x i ). We overfit a small NN model, consisting of 4 FC layers to predict the full signal given its samples, using GD iterations (see <ref type="figure" target="#fig_2">figure 4</ref>). We define our data term:</p><formula xml:id="formula_14">? (f , I) = 1 N N ?1 i=0 (f i ? y i ) 2<label>(14)</label></formula><p>where {f i } N ?1 i=0 are the corresponding samples of the predicted output. We train our model using our unrolled cost and compare to standard TV, Huber <ref type="bibr" target="#b11">[12]</ref> and Charbonnier <ref type="bibr" target="#b6">[7]</ref> baselines, measuring the prediction error as the mean absolute difference between target and predicted signals. We perform independent hyperparameter optimization prior to comparing both methods. We present here results of one scenario, further results as well as implementation details are available in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Prediction Error</head><p>We compare the signals predicted by our models. Prediction errors are given in table 1. The target, its samples and predicted signals are shown in <ref type="figure" target="#fig_2">figure 4</ref>. We find that training using our unrolled cost decreases TV prediction error <ref type="figure">Figure 5</ref>. Qualitative benchmark results. We compare qualitative flow benchmark results of ours, the ARFlow <ref type="bibr" target="#b17">[18]</ref> and UFlow <ref type="bibr" target="#b15">[16]</ref> baselines. Both ARFlow and UFlow are methods adopting a PWC-Net <ref type="bibr" target="#b27">[28]</ref> based backbone, reporting the best results on the MPI Sintel <ref type="bibr" target="#b3">[4]</ref> and KITTI 2015 <ref type="bibr" target="#b21">[22]</ref> benchmarks, respectively. We find adapting our unrolled cost to a PWC-Net based backbone outperforms both baselines, particularly at the motion boundaries. by 28.2%, enabling a smoother but edge preserving solution (see <ref type="figure" target="#fig_2">fig. 4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Convergence</head><p>We study the convergence of all methods. <ref type="figure">Figure 3</ref> displays prediction errors and gradient norms recorded during training, as well as gradients recorded at selected points (other points may be viewed in the supplementary material). We find our method not only achieves better results, but it also converges nearly two times faster than TV. Further inspecting the gradients generated during training reveals that gradients of the TV suffer from severe oscillations as a result of its non-differentiabilty at zero. These oscillations cause the measured gradient norms to increase rather than decrease, suggesting an unstable optimum. While L 1 relaxation baselines feature improved results and convergence compared to TV, our method achieves the best results and converges the fastest with its gradients smoothly decreasing to zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Unsupervised Optical Flow</head><p>We next test our proposed unrolled cost on the real-world unsupervised optical flow problem. We introduce our unrolled cost to the recently published ARFlow <ref type="bibr" target="#b17">[18]</ref> baseline, rigorously following their proposed training scheme and model architecture, yet replacing their used TV regularization with our method. Optical flow is defined as a mapping F : R 2 ? R 2 , which aligns pixels given a pair of images I 1 , I 2 . In the unsupervised optical flow setting, our data term takes the form:</p><formula xml:id="formula_15">? (F, I) = ? I 1 ,? F 2<label>(15)</label></formula><p>i.e. ? is a differetiable photometric loss, measuring the consistency of a reference image and a target image warped using F. In order to remain consistent with the ARFlow baseline, we use masked TV regularization, substituting C = W ?F into equation <ref type="formula" target="#formula_1">(10)</ref>, where W is a deterministic importance matrix, aiming to increase the penalty on the boundaries, defined:</p><formula xml:id="formula_16">W = exp {??|?I 1 |} = exp ?? ?I 1 ?x , ?I 1 ?y<label>(16)</label></formula><p>and ? is an hyperparameter controlling the masking operation. A block diagram of our method for the unsupervised optical flow setting is shown in figure 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Model</head><p>Following the ARFlow <ref type="bibr" target="#b17">[18]</ref> baseline, we use a PWC-Net based model consisting of a 7 level multi-resolution pyramid. The model is trained end-to-end in a fully unsupervised manner. The photometric loss term is evaluated on non-occluded regions only, thus occluded regions are optimized using only the smoothness regularization. The training scheme consists of both pre-training and finetuning. During finetuning, self-supervision is acquired through appearance, spatial and occlusion pseudo-random deformations, as elaborated next. Further implementation details are available in the supplementary material.</p><p>Self-supervision from Augmentations As carried by ARFlow, self-supervision from pseudo-random augmentations is applied during finetunine. Image and corresponding flow augmentations, T img : I k ?? k and T flow : F ?F respectively, perform a combination of appearance, spatial and occlusion pseudo-random deformations. An initial flow  <ref type="table">Table 2</ref>. Unrolled cost vs. TV relaxations -unsupervised optical flow. Our method outperforms all tested L 1 relaxation baselines. Furthermore, our method decreases the TV EPE averaged over the occluded regions, which are highly affected by the smoothness constraint, by up to 15.82%, enabling the detection of sharper motion boundaries without any modification to the model architecture or complexity.</p><p>estimate F 1 is computed given a pair of images I 1 , I 2 . The image pair then undergoes an image augmentation T img resulting in a deformed pair of images? 1 ,? 2 . A second flow estimate F 2 is generated next over the deformed images I 1 ,? 2 . Finally, we acquire self-supervision obtainingF 1 through applying the flow augmentation T flow over F 1 and measuring the error F 2 ?F 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Datasets</head><p>We evaluate our method on well-known optical flow benchmarks: the synthetic MPI Sintel <ref type="bibr" target="#b3">[4]</ref> and real-world autonomous driving KITTI 2015 <ref type="bibr" target="#b21">[22]</ref>. We follow the ARFlow <ref type="bibr" target="#b17">[18]</ref> training scheme. For the MPI Sintel benchmark, we first pretrain our model on the raw Sintel movie. 12, 466 image pairs are extracted and split according to scene shots. We then finetune our model on the official training set, consisting of 1, 041 image pairs, each rendered with 2 levels of difficulty. For the KITTI 2015 benchmark, we first pretrain our model on the KITTI raw dataset <ref type="bibr" target="#b8">[9]</ref>, which consists of real road scenes captured by a car-mounted stereo camera rig. We then use the KITTI 2015 multi-view extension for finetuning. We exclude frames related to validation from our training set, i.e. use only frames below 9 or above 12 in each scene. Further details regarding the train-test data splitting used in our experiments are given in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Flow in Occluded Regions</head><p>Occluded pixels, i.e. pixels with no correspondence, are highly correlated with motion boundaries. Although crucial to many CV applications, performance on the occluded regions minorly affects the errors averaged over full images. We test our method particularly on occluded pixels as they are mostly affected by the gradients of the smoothness constraint during training. As official benchmark results don't report errors in occluded regions, we validate our models on the available official training data using train-test splitting (see supplementary). Measured validation AEPE rates of our unrolled cost, as well as the standard TV, Huber <ref type="bibr" target="#b11">[12]</ref> and Charbonnier <ref type="bibr" target="#b6">[7]</ref> baselines are given in <ref type="table">table 2</ref>. Our method outperforms all tested baselines. As expected, modifying the smoothness regularizer has little effect on the performance in the non-occluded regions (Noc.). However, measuring the performance on the occluded regions, our method reduces TV EPE rates by up to 15.82% enabling the detection of sharper motion boundaries with no added complexity. Qualitative flow visualizations are displayed in figures 1 and 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Comparison with State of the Art</head><p>We compare our trained model with recently published unsupervised methods on the MPI Sintel and KITTI 2015 optical flow benchmarks in table 3. The used measures are the Average End-Point-Error (AEPE) and F1 score, measuring outliers percentage (error &gt; 3px). Our method managed to improve the reported results of the ARFlow <ref type="bibr" target="#b17">[18]</ref> baseline on both MPI Sintel and the KITTI 2015 unsupervised optical flow benchmarks, particularly at the motion boundaries, as is highly visible in figures 5 and 1. Moreover, our method reports the best results using a PWC-Net based backbone on dual images at the time of submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.5">Number of Cost Function Update Steps</head><p>We study the effective number of cost function update steps T required for training. We use a model which has been pretrained on the MPI Sintel raw movie and set various T values during finetuning. Several T values are compared in table 4 and a qualitative example is shown in <ref type="figure">figure 6</ref>. We find that increasing T brings a performance boost, enabling our flow estimator to capture finer motion details. However, further investigating the convergence of the cost function update steps during training shows that convergence is achieved at T = 2 making the gain for setting setting T &gt; 2 relatively small. Additional study regarding update steps convergence is given in the supplementary material. Substituting T = 2 in eq. (10), we conclude that our effective TV regularization proxy consists of the L 2 norm of the spatial gradients, as well as one update step.   <ref type="table">Table 4</ref>. Number of cost function update steps. Finetuning using several T values, we find that increasing the number of update steps brings a performance boost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Memory Runtime</head><p>Standard TV 4.326Gi 51ms Unrolled Cost (Ours) 4.285Gi 51ms <ref type="table">Table 5</ref>. Computational complexity. Our method consumes slightly less memory during training and preserves runtime, hence replacing TV regularization with our unrolled cost enables improved results with no added complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.6">Computational Complexity</head><p>As our method deals with model training alone, it does not affects inference. We compare both memory consumption and training time of our method to the ARFlow <ref type="bibr" target="#b17">[18]</ref> baseline in table 5. All measurements are carried using a batch size of 4 image pairs and an image size of 384?832 over an RTX2080 GPU. Our method does not increase model size, as no learned parameters are added. Furthermore, as we set our unrolled cost unit to operate at flow original resolution, which is 1/4 image resolution, our method consumes <ref type="figure">Figure 6</ref>. Qualitative example -number of update steps. We find increasing the number of update steps improves the ability of our model to capture finer flow details.</p><p>slightly less memory and preserves training time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We introduced the concept of Cost Unrolling, shifting algorithm unrolling to the cost function, while preserving model architecture. Our method enables improved training of a TV regularized model as a result of more accurate gradients, thanks to its differentiability around its optimum, preserving complexity. We have demonstrated the effectiveness of our method in a synthetic signal prediction problem as well as real-world unsupervised optical flow. Our unrolled cost achieved superior results in all tested scenarios. We believe that the proposed framework can be applied on top of other model architectures for boosting their results next to non-differentiable optimum solutions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Sintel Final benchmark qualitative example. Introducing our method to the unsupervised optical flow domain, our unrolled cost function enables the detection of sharper motion boundaries through improved convergence, without modifying the model's architecture or increasing complexity. Displayed are the predicted Sintel Final benchmark 'Market 1' flows (bottom) and errors (top) of both our method and the ARFlow [18] baseline, with close-ups on specific regions. White regions feature measured high errors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Unrolled cost block diagram for unsupervised optical flow. In each training iteration, given a flow prediction, its weighted spatial gradients C are computed. Once obtained, the Soft Thresholding and Multipliers Update operations are carried for update steps</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>PC signal prediction -target vs. predicted signals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>MPI Sintel &amp; KITTI 2015 official unsupervised optical flow benchmark results. We report AEPE and F1 rates for recently published unsupervised methods on both the MPI Sintel<ref type="bibr" target="#b3">[4]</ref> and KITTI 2015<ref type="bibr" target="#b21">[22]</ref> optical flow benchmarks. Methods featuring a different backbone are marked with . Brackets "()" indicate results of models trained using their validation set. Best methods in each category are in bold. Missing results are marked as "-". By adapting our unrolled cost to the ARFlow<ref type="bibr" target="#b17">[18]</ref> baseline we not only achieve improved results, but also report the best results for a PWC-Net based backbone on both benchmarks at the time of submission. Moreover, we find our method highly effective on the motion boundaries, as shown in the qualitative results (figures 1,5).</figDesc><table><row><cell cols="3"># Update Steps Sintel Clean Sintel Final</cell></row><row><cell>T = 1</cell><cell>2.43</cell><cell>3.25</cell></row><row><cell>T = 2</cell><cell>2.35</cell><cell>3.19</cell></row><row><cell>T = 4</cell><cell>2.35</cell><cell>3.16</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensor-Flow: Large-scale machine learning on heterogeneous systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Harp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafal</forename><surname>Jozefowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manjunath</forename><surname>Kudlur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Levenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oriol Vinyals</title>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Fernanda Vi?gas</publisher>
		</imprint>
	</monogr>
	<note>Dandelion Man?. Software available from tensorflow.org. 1</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Fast image recovery using variable splitting and constrained optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Afonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A T</forename><surname>Figueiredo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2345" to="2356" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Distributed optimization and statistical learning via the alternating direction method of multipliers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neal</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borja</forename><surname>Peleato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Eckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A naturalistic open source movie for optical flow evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Butler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">editor, European Conf. on Computer Vision (ECCV), Part IV</title>
		<editor>A. Fitzgibbon et al.</editor>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">7577</biblScope>
			<biblScope unit="page" from="611" to="625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Image recovery via total variation minimization and related problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chambolle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lions</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numerische Mathematik</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="188" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A first-order primaldual algorithm for convex problems with applications to imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonin</forename><surname>Chambolle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of mathematical imaging and vision</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="120" to="145" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deterministic edge-preserving regularization in computed imaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Charbonnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laure</forename><surname>Blanc-F?raud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Aubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Barlaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="298" to="311" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Flownet: Learning optical flow with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eddy</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Hausser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caner</forename><surname>Hazirbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Smagt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Vision meets robotics: The kitti dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Robotics Research (IJRR)</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Statistics of natural images and models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinggang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)</title>
		<meeting>1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="541" to="547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Robust statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Interscience</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981" />
			<publisher>Wiley</publisher>
			<biblScope unit="volume">1</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Robust estimation of a location parameter: Annals mathematics statistics, 35</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Flownet 2.0: Evolution of optical flow estimation with deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eddy</forename><surname>Ilg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaus</forename><surname>Mayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tonmoy</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margret</forename><surname>Keuper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2462" to="2470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Unsupervised learning of optical flow with deep feature similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Woobin</forename><surname>Im</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae-Kyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung-Eui</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="172" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Karayev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergio</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><forename type="middle">Darrell</forename><surname>Caffe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1408.5093</idno>
		<title level="m">Convolutional architecture for fast feature embedding</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Jonschkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Konolige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anelia</forename><surname>Angelova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.04902</idno>
		<title level="m">What matters in unsupervised optical flow</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Unsupervised learning of image segmentation based on differentiable feature clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonjik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asako</forename><surname>Kanezaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayuki</forename><surname>Tanaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="8055" to="8068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning by analogy: Reliable supervision from transformations for unsupervised optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangning</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yabiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jilin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feiyue</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition(CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Ddflow: Learning optical flow with unlabeled data distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengpeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Michael R Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8770" to="8777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Upflow: Upsampling pyramid for unsupervised optical flow learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunming</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuaicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqiang</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1045" to="1054" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Unflow: Unsupervised learning of optical flow with a bidirectional census loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Meister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junhwa</forename><surname>Hur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.07837</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Object scene flow for autonomous vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Menze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Algorithm unrolling: Interpretable, efficient deep learning for signal and image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Monga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuelong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonina</forename><forename type="middle">C</forename><surname>Eldar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.10557</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Nonlinear total variation based noise removal algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><forename type="middle">I</forename><surname>Rudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emad</forename><surname>Fatemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physica D: Nonlinear Phenomena</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="259" to="268" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An improved and accelerated non-linear multigrid method for total-variation denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Savage</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Mathematics</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1001" to="1015" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Smurf: Self-teaching multiframe unsupervised raft with full-image warping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austin</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alper</forename><surname>Ayvaci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anelia</forename><surname>Angelova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Jonschkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="3887" to="3896" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">PWC-Net: CNNs for optical flow using pyramid, warping, and cost volume</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep admm-net for compressive sensing mri</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huibin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Teed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.12039,2020.3</idno>
		<title level="m">Raft: Recurrent allpairs field transforms for optical flow</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Unsupervised learning of optical flow with cnn-based non-local filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dejun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="8429" to="8442" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Cot-amflow: Adaptive modulation network with co-teaching strategy for unsupervised optical flow estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengli</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.02156</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Proximal deep structured models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS&apos;16</title>
		<meeting>the 30th International Conference on Neural Information Processing Systems, NIPS&apos;16<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc. 1</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">865873</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A duality based approach for realtime tv-l 1 optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint pattern recognition symposium</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="214" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep unfolding network for image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3217" to="3226" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
