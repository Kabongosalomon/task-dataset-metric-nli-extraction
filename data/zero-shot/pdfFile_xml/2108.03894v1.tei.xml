<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FIFA: Fast Inference Approximation for Action Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Souri</surname></persName>
							<email>souri@iai.uni-bonn.de</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Bonn</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazan</forename><forename type="middle">Abu</forename><surname>Farha</surname></persName>
							<email>abufarha@iai.uni-bonn.de</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Bonn</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabien</forename><surname>Despinoy</surname></persName>
							<email>fabien.despinoy@toyota-motor.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Toyota Motor Europe</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianpiero</forename><surname>Francesca</surname></persName>
							<email>gianpiero.francesca@toyota-motor.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Toyota Motor Europe</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
							<email>gall@iai.uni-bonn.de</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Bonn</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">FIFA: Fast Inference Approximation for Action Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Action Segmentation ? Approximate Inference</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We introduce FIFA, a fast approximate inference method for action segmentation and alignment. Unlike previous approaches, FIFA does not rely on expensive dynamic programming for inference. Instead, it uses an approximate differentiable energy function that can be minimized using gradient-descent. FIFA is a general approach that can replace exact inference improving its speed by more than 5 times while maintaining its performance. FIFA is an anytime inference algorithm that provides a better speed vs. accuracy trade-off compared to exact inference. We apply FIFA on top of state-of-the-art approaches for weakly supervised action segmentation and alignment as well as fully supervised action segmentation. FIFA achieves state-of-the-art results on most metrics on two action segmentation datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Action segmentation is the task of predicting the action label for each frame in the input video. Action segmentation is usually studied in the context of activities performed by a single person, where temporal smoothness of actions are assumed. Fully supervised approaches for action segmentation <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b39">40]</ref> already achieve good performance on this task. Most approaches for fully supervised action segmentation make frame-wise predictions <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b29">30]</ref> while trying to model the temporal relationship between the action labels. These approaches usually suffer from over-segmentation. Recent works <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b14">15]</ref> try to overcome the over-segmentation problem by finding the action boundaries and temporally smoothing the predictions inside each action segment. But these post-processing approaches still can not guarantee temporal smoothness.</p><p>Action segmentation inference is the problem of making segment-wise smooth predictions from frame-wise probabilities given a known grammar of the actions and their average lengths <ref type="bibr" target="#b34">[35]</ref>. The typical inference in action segmentation involves solving an expensive Viterbi-like dynamic programming problem that finds the best action sequence and its corresponding lengths. In the literature arXiv:2108.03894v1 [cs.CV] 9 Aug 2021 usually weakly supervised action segmentation approaches <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37]</ref> use inference at test time. Despite being very useful for action segmentation, the inference problem remains the main computational bottleneck in the action segmentation pipeline <ref type="bibr" target="#b36">[37]</ref>.</p><p>In this paper, we propose FIFA, a fast anytime approximate inference procedure that achieves comparable performance with respect to the dynamic programming based Viterbi decoding inference at a fraction of the computational time. Instead of relying on dynamic programming, we formulate the energy function as an approximate differentiable function of segment lengths parameters and use gradient-descent-based methods to search for a configuration that minimizes the approximate energy function. Given a transcript of actions and the corresponding initial lengths configuration, we define the energy function as a sum over segment level energies. The segment level energy consists of two terms: a length energy term that penalizes the deviations from a global length model and an observation energy term that measures the compatibility between the current configuration and the predicted frame-wise probabilities. A naive approach to model the observation energy would be, to sum up the negative log probabilities of the action labels that are defined based on the length configuration. Nevertheless, such an approach is not differentiable with respect to the segment lengths. In order to optimize the energy using gradient descent-based methods, the observation energy has to be differentiable with respect to the segment lengths. To this end, we construct a plateau-shaped mask for each segment which temporally locates the segment within the video. This mask is parameterized by the segment lengths, the position in the video, and a sharpness parameter. The observation energy is then defined as a product of a segment mask and the predicted framewise negative log probabilities, followed by a sum pooling operation. Finally, a gradient descent-based method is used to find a configuration for the segment lengths that minimizes the total energy.</p><p>FIFA is a general inference approach and can be applied at test time on top of different action segmentation approaches for fast inference. We evaluate our approach on top of the state-of-the-art methods for weakly supervised temporal action segmentation, weakly supervised action alignment, and fully supervised action segmentation. Results on the Breakfast <ref type="bibr" target="#b18">[19]</ref> and Hollywood extended <ref type="bibr" target="#b3">[4]</ref> datasets show that FIFA achieves state-of-the-art results on most metrics. Compared to the exact inference using the Viterbi decoding, FIFA is at least 5 times faster. Furthermore, FIFA is an anytime algorithm which can be stopped after each step of the gradient-based optimization, therefore it provides a better speed vs. accuracy trade-off compared to exact inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>In this section we highlight relevant works addressing fully and weakly supervised action segmentation that have been recently achieved.</p><p>Fully Supervised Action Segmentation. In fully supervised action segmentation, frame-level labels are used for training. Initial attempts for action segmenta-tion applied action classifiers on a sliding window over the video frames <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b16">17]</ref>. However, these approaches did not capture the dependencies between the action segments. With the objective of capturing the context over long video sequences, context free grammars <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b32">33]</ref> or hidden Markov models (HMMs) <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b22">23]</ref> are typically combined with frame-wise classifiers. Recently, temporal convolutional networks showed good performance for the temporal action segmentation task using encoder-decoder architectures <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b27">28]</ref> or even multi-stage architectures <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">30]</ref>. Many approaches further improve the multi-stage architectures by applying post-processing based on boundary-aware pooling operation <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b14">15]</ref> or graph-based reasoning <ref type="bibr" target="#b13">[14]</ref>. Without any inference most of the fully-supervised approaches suffer from oversegmentation at test time.</p><p>Weakly Supervised Action Segmentation. To reduce the annotation cost, many approaches that rely on a weaker form of supervision have been proposed. Earlier approaches apply discriminative clustering to align video frames to movie scripts <ref type="bibr" target="#b7">[8]</ref>. Bojanowski et al . <ref type="bibr" target="#b4">[5]</ref> proposed to use as supervision the transcripts in the form of ordered lists of actions. Indeed, many approaches rely on this form of supervision to train a segmentation model using connectionist temporal classification <ref type="bibr" target="#b12">[13]</ref>, dynamic time warping <ref type="bibr" target="#b5">[6]</ref> or energy-based learning <ref type="bibr" target="#b28">[29]</ref>. In <ref type="bibr" target="#b6">[7]</ref>, an iterative training procedure is used to refine the transcript. A soft labeling mechanism is further applied at the boundaries between action segments. Kuehne et al . <ref type="bibr" target="#b21">[22]</ref> applied a speech recognition system based on a HMM and Gaussian mixture model (GMM) to align video frames to transcripts. The approach generates pseudo ground truth labels for the training videos and iteratively refine them. A similar idea has been recently used in <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b22">23]</ref>. Richard et al . <ref type="bibr" target="#b34">[35]</ref> combined the frame-wise loss function with the Viterbi algorithm to generate the target labels. At inference time, these approaches iterate over the training transcripts and select the one that matches best the testing video. By contrast, Souri et al . <ref type="bibr" target="#b36">[37]</ref> predict the transcript besides the frame-wise scores at inference time. State of the art weakly supervised action segmentation approaches require time consuming dynamic programming based inference at test time.</p><p>Energy-Based Inference. In energy-based inference methods, gradient descent is used at inference time as described in <ref type="bibr" target="#b26">[27]</ref>. The goal is to minimize an energy function that measures the compatibility between the input variables and the predicted variables. This idea has been exploited for many structured prediction tasks such as image generation <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16]</ref>, machine translation <ref type="bibr" target="#b11">[12]</ref> and structured prediction energy networks <ref type="bibr" target="#b2">[3]</ref>. Belanger and McCallum <ref type="bibr" target="#b1">[2]</ref> relaxed the discrete output space for multi-label classification tasks to a continuous space and used gradient descent to approximate the solution. Gradient-based methods have also been used for other applications such as generating adversarial examples <ref type="bibr" target="#b10">[11]</ref> and learning text embeddings <ref type="bibr" target="#b23">[24]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head><p>The following sections introduce all the concepts and notations required to understand the proposed FIFA methodology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Action Segmentation</head><p>In action segmentation, we want to temporally localize all the action segments occurring in a video. In this paper, we consider the case where the actions are from a predefined set of M classes (a background class is used to cover uninteresting parts of a video). The input video of length T is usually represented as a set of d dimensional features vectors x 1:T = (x 1 , . . . , x T ). These features are extracted offline and are assumed to be the input to the action segmentation model. The output of action segmentation can be represented in two ways:</p><p>-Frame-wise representation y 1:T = (y 1 , . . . , y T ) where y t represents the action label at time t. -Segment-wise representation s 1:N = (s 1 , . . . , s N ) where segment s n is represented by both the action label of the segment c n and its corresponding length n i.e. s n = (c n , n ). The ordered list of actions c 1:N is usually referred to as the transcript.</p><p>These two representations are equal and redundant i.e. it is possible to compute one from the other. In order to transfer from the segment-wise to the frame-wise representation, we introduce a mapping ?(t; c 1:N , 1:N ) which outputs the action label at frame t given the segment-wise labeling. The target labels to train a segmentation model, depend on the level of supervision. In fully supervised action segmentation <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b39">40]</ref>, the target label for each frame is provided. However, in weakly supervised approaches <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37]</ref> only the ordered list of action labels are provided during training while their lengths are unknown.</p><p>Recent fully supervised approaches for action segmentation like MSTCN [1] and its variants directly predict the frame-wise representation y 1:T by choosing the action label with the highest probability for each frame independently. This results in predictions that are sometimes oversegmented.</p><p>Conversely, recent weakly supervised action segmentation approaches like NNV <ref type="bibr" target="#b34">[35]</ref> and follow-up work include an inference stage during testing where they explicitly predict the segment-wise representation. This inference stage involves a dynamic programming algorithm for solving an optimization problem which is a computational bottleneck for these approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Inference in Action Segmentation</head><p>During testing, the inference stage involves an optimization problem to find the most likely segmentation for the input video i.e.,  </p><p>Given the transcript c 1:N , the inference stage boils down to finding the segment lengths 1:N by aligning the transcript to the input video i.e., </p><p>In approaches like NNV <ref type="bibr" target="#b34">[35]</ref> and CDFL <ref type="bibr" target="#b28">[29]</ref>, the transcript is found by iterating over the transcripts seen during training and selecting the transcript that achieves the most likely alignment by optimizing <ref type="bibr" target="#b1">(2)</ref>. In MuCon <ref type="bibr" target="#b36">[37]</ref>, the transcript is predicted by a sequence to sequence network. The probability defined in (2) is broken down by making independences assumption between frames</p><formula xml:id="formula_2">p(? 1:N |x 1:T , c 1:N ) = T t=1 p ?(t; c 1:N ,? 1:N )|x t ? N n=1 p ? n |c n<label>(3)</label></formula><p>where p ?(t)|x t is referred to as the observation model and p n |c n as the length model. Here ?(t) is the mapping from time t to the action label given the segmentwise labeling. The observation model estimates the frame-wise action probabilities and is implemented using a neural network. The length model is used to constrain the inference defined in <ref type="bibr" target="#b1">(2)</ref> with the assumption that the length of segments for the same action follow a particular probability distribution. The segment length is usually modelled by a Poisson distribution with a class dependent mean parameter ? cn i.e.,</p><formula xml:id="formula_3">p n |c n = ? n cn exp(?? cn ) n ! .<label>(4)</label></formula><p>This optimization is solved using an expensive dynamic programming based Viterbi decoding <ref type="bibr" target="#b34">[35]</ref>. For details on how to solve this optimization problem using Viterbi decoding please refer to the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">FIFA: Fast Inference Approximation</head><p>Our goal is to introduce a fast inference algorithm for action segmentation. We want the fast inference to be applicable in both weakly supervised and fully supervised action segmentation. We also want the fast inference to be flexible enough to work with different action segmentation methods. To this end, we introduce FIFA, a novel approach for fast inference for action segmentation.</p><p>In the following for brevity we write the mapping ?(t; c 1:N , 1:N ) simply as ?(t). Maximizing probability (2) can be rewritten as minimizing the negative log of that probability argmax p(? 1:N |x 1:T , c 1:N ) = argmin ? log p(? 1:N |x 1:T , c 1:N ) (5)</p><formula xml:id="formula_4">X + Length Model Fig. 1.</formula><p>Overview of the FIFA optimization process. At each step in the optimization, using the current length estimates a set of masks are generated. Using the generated masks and the frame-wise negative log probabilities, the observation energy is calculated in an approximate but differentiable manner. The length energy is calculated from the current length estimate and added to the observation energy to calculate the total energy value. Taking the gradient of the total energy with respect to the length estimates we can update it using a gradient step.</p><p>which we refer to as the energy E( 1:N ). Using (3) the energy is rewritten as</p><formula xml:id="formula_5">E( 1:N ) = ? log p( 1:N |x 1:T , c 1:N ) = ? log T t=1 p ?(t)|x t ? N n=1 p n |c n = T t=1 ? log p ?(t)|x t E o + N n=1 ? log p n |c n E .</formula><p>(6) The first term in <ref type="bibr" target="#b5">(6)</ref>, E o is referred to as the observation energy. This term calculates the cost of assigning the labels for each frame and will be calculated from the frame-wise probability estimates. The second term E is referred to as the length energy. This term is the cost of each segment having a length given that we assume some average length for actions of a specific class.</p><p>We proposed to optimize the energy defined in (6) using gradient based optimization in order to avoid the need for time-consuming dynamic programming. We start with an initial estimate of the lengths (obtained from the length model of each approach or calculated from training data when available) and update our estimate to minimize the energy function.</p><p>As the energy function E( 1:N ) is not differentiable with respect to the lengths, we have to calculate a relaxed and approximate energy function E * ( 1:N ) that respects this mathematical property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Approximate Differentiable Energy E *</head><p>The energy function E as defined in <ref type="formula">(6)</ref> is not differentiable in two parts. First the observation energy term E o is not differentiable because of the ?(t) function.</p><p>Second, the length energy term E is not differentiable because it expects natural numbers as input and cannot be computed on real values which are dealt with in gradient-based optimization. Below we describe how we approximate and make each of the terms differentiable.</p><p>Approximate Differentiable Observation Energy Consider a N ?T matrix P containing negative log probabilities, i.e.</p><formula xml:id="formula_6">P [n, t] = ? log p(c n |x t ).<label>(7)</label></formula><p>Imagine a mask matrix M with the same size</p><formula xml:id="formula_7">N ? T where M [n, t] = 0 if ?(t) = c n 1 if ?(t) = c n .<label>(8)</label></formula><p>Using the mask matrix we can rewrite the observation energy term as</p><formula xml:id="formula_8">E o = T t=1 N n=1 M [n, t] ? P [n, t].<label>(9)</label></formula><p>In order to make the observation energy term differentiable with respect to the length, we propose to construct an approximate differentiable mask matrix M * . We use the following smooth and parametric plateau function</p><formula xml:id="formula_9">f (t|? c , ? w , ? s ) = 1 (e ? s (t?? c ?? w ) + 1)(e ? s (?t+? c ?? w ) + 1)<label>(10)</label></formula><p>from <ref type="bibr" target="#b30">[31]</ref>. This plateau function has three parameters and it is differentiable with respect to them: ? c controls the center of the plateau, ? w is the width and ? s is the sharpness of the plateau function. While the sharpness of the plateau functions ? s used to construct the approximate mask M * is fixed as a hyper-parameter of our approach, the center ? c and the width ? w are computed from the lengths 1:N . First we calculate the starting position of each plateau function b n as</p><formula xml:id="formula_10">b 1 = 0, b n = n?1 n =1 n .<label>(11)</label></formula><p>We can then define both the center and the width parameters of each plateau function as</p><formula xml:id="formula_11">? c n = b n + n /2, ? w n = n /2<label>(12)</label></formula><p>and define each row of the approximate mask as</p><formula xml:id="formula_12">M * [n, t] = f (t|? c n , ? w n , ? s ).<label>(13)</label></formula><p>Now we can calculate a differentiable approximate observation energy similar to <ref type="bibr" target="#b8">(9)</ref> as</p><formula xml:id="formula_13">E * o = T t=1 N n=1 M * [n, t] ? P [n, t].<label>(14)</label></formula><p>Approximate Differentiable Length Energy For the gradient-based optimization, we must relax the length values to be positive real values instead of natural numbers. As the Poisson distribution <ref type="formula" target="#formula_3">(4)</ref> is only defined on natural numbers, we propose to use a substitute distribution defined on real numbers. As a replacement, we experiment with a Laplace distribution and a Gaussian distribution. In both cases, the scale or the width parameter of the distribution is assumed to be fixed. We can rewrite the length energy E as the approximate length energy</p><formula xml:id="formula_14">E * ( 1:N ) = N n=1 ? log p( n |? cn ),<label>(15)</label></formula><p>where ? cn is the expected value for the length of a segment from the action c n . In case of the Laplace distribution this length energy will be</p><formula xml:id="formula_15">E * ( 1:N ) = 1 Z N n=1 | n ? ? cn |,<label>(16)</label></formula><p>where Z is the constant normalization factor. This means that the length energy will penalize any deviation from the expected average length linearly. Similarly, for the Gaussian distribution, the length energy will be</p><formula xml:id="formula_16">E * ( 1:N ) = 1 Z N n=1 | n ? ? cn | 2 ,<label>(17)</label></formula><p>which means that the Gaussian length energy will penalize any deviation from the expected average length quadratically.</p><p>With the objective to maintain a positive value for the length during the optimization process, we estimate the length in log space and convert it to absolute space only in order to compute both the approximate mask matrix M * and the approximate length energy E * .</p><p>Approximate Energy Optimization The total approximate energy function is defined as a weighted sum of both the approximate observation and the approximate length energy functions</p><formula xml:id="formula_17">E * ( 1:N ) = E * o ( 1:N , Y ) + ?E * ( 1:N )<label>(18)</label></formula><p>where ? is the multiplier for the length energy. Given an initial length estimate 0 1:N , we iteratively update this estimate to minimize the total energy. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the optimization step for our approach. During each optimization step, we first calculate the energy E * and then calculate the gradients of the energy with respect to the length values. Using the calculated gradients, we update the length estimate using a gradient descent update rule such as SGD or Adam. After a certain number of gradient steps (50 steps in our experiments) we will finally predict the segment length.   During testing, if the transcript is provided then it is used (e.g. using the MuCon <ref type="bibr" target="#b36">[37]</ref> approach or in a weakly supervised action alignment setting). However, if the latter is not known (e.g. in a fully supervised approach or CDFL <ref type="bibr" target="#b28">[29]</ref> for weakly supervised action segmentation) we perform the optimization for each of the transcripts seen during training and select the most likely one based on the final energy value at the end of the optimization.</p><p>The initial length estimates are calculated from the length model of each approach in case of weakly supervised setting whereas in fully supervised setting the average length of each action class is calculated from the training data and used as the initial length estimates. The initial length estimates are also used as the expected length parameters for the length energy calculations.</p><p>The hyper-parameters like the choice of the optimizer, number of steps, learning rate, and the mask sharpness, remain as the hyper-parameters of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Evaluation Protocols and Datasets</head><p>We evaluate FIFA on 3 different tasks: weakly supervised action segmentation, fully supervised action segmentation, and weakly supervised action alignment. Results for action alignment are included in the supplementary material. We obtain the source code for the state-of-the-art approaches on each of these tasks and train a model using the standard training configuration of each model. Then we apply FIFA as a replacement for an existing inference stage or as an additional inference stage.</p><p>We </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results and Discussions</head><p>In this section, we study the speed-accuracy trade-off and the impact of the length model. Additional ablation experiments are included in the supplementary material.</p><p>Speed vs. Accuracy Trade-off. One of the major benefits of FIFA is the flexibility of choosing the number of optimization steps. The number of steps of the optimization can be a tool to trade-off speed vs. accuracy. In exact inference, we can use frame-sampling i.e. lowering the resolution of the input features, or hypothesis pruning i.e. beam search for speed vs. accuracy trade-off. <ref type="figure" target="#fig_4">Figure 2</ref> plots the speed vs. accuracy trade-off of exact inference compared to FIFA. We observe that FIFA provides a much better speed-accuracy trade-off as compared to frame-sampling for exact inference. The best performance after 50 steps with 5.9% improvement on the MoF accuracy compared to not performing any inference.</p><p>Impact of the Length Energy. For the length energy, we assume that the segment lengths follow a Laplace distribution. <ref type="figure" target="#fig_5">Figure 3</ref> shows the impact of the length energy multiplier on the performance. While the best accuracy is achieved with a multiplier of 0.05, our approach is robust to the choice of these hyper-parameters. We further experimented with a Gaussian length energy. However, as shown in the figure, the performance is much worse compared to the Laplace energy. This is due to the quadratic penalty that dominates the total energy, which makes the optimization biased towards the initial estimate and ignores the observation energy.</p><p>Impact of Length Model Initialization. Since FIFA starts with an initial estimate for the lengths, the choice of initialization might have an impact on the performance. <ref type="table" target="#tab_0">Table 1</ref> shows the effect of initializing the lengths with equal values compared to using the length model of MuCon <ref type="bibr" target="#b36">[37]</ref> for the weakly supervised action segmentation on the Breakfast dataset. As shown in the table, FIFA is more robust to initialization compared to the exact inference as the drop in performance is approximately half of the exact inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Comparison to State of the Art</head><p>In this section, we compare FIFA to other state-of-the-art approaches.  <ref type="figure">Fig. 4</ref>. Visualization of the FIFA optimization process. On the right the values of the total approximate energy is plotted. On the left, negative log probability values, ground truth segmentation, optimization initialization, the masks and the segmentation after inference is ploted.</p><p>Weakly Supervised Action Segmentation. We apply FIFA on top of two stateof-the-art approaches for weakly supervised action segmentation namely Mu-Con <ref type="bibr" target="#b36">[37]</ref> and CDFL <ref type="bibr" target="#b28">[29]</ref> on the Breakfast dataset <ref type="bibr" target="#b18">[19]</ref> and report the results in Table2. FIFA applied on CDFL achieves a 12 times faster inference speed while obtaining results comparable to exact inference. FIFA applied to MuCon achieves a 5 times faster inference speed and obtains a new state-of-the-art performance on the Breakfast dataset on most of the metrics.  Similarly for the Hollywood extended dataset <ref type="bibr" target="#b3">[4]</ref> we apply FIFA to Mu-Con <ref type="bibr" target="#b36">[37]</ref> and report the results in <ref type="table" target="#tab_4">Table 4</ref>. FIFA applied on MuCon achieves a 4 times faster inference speed while obtaining results comparable to exact inference.</p><p>Fully Supervised Action Segmentation. In the fully supervised action segmentation we apply FIFA on top of MS-TCN <ref type="bibr" target="#b0">[1]</ref> and its variant MS-TCN++ <ref type="bibr" target="#b29">[30]</ref> on the Breakfast dataset <ref type="bibr" target="#b18">[19]</ref> and report the results in <ref type="table" target="#tab_2">Table 3</ref>. MS-TCN and MS-TCN++ are approaches that do not perform any inference at test time. This usually results in over-segmentation and low F1 and Edit scores. Applying FIFA on top of these approaches improves the F1 and Edit scores significantly. FIFA applied on top of MS-TCN achieves state-of-the-art performance and sets new state-of-the-art performance on most metrics.</p><p>For the Hollywood extended dataset <ref type="bibr" target="#b3">[4]</ref>, we train MS-TCN <ref type="bibr" target="#b0">[1]</ref> and report results comparing exact inference (EI) compared to FIFA in <ref type="table">Table 5</ref>. We observe that MS-TCN using an inference algorithm achieves new state-of-the-art results on this dataset. FIFA is comparable or better than exact inference on this dataset.   <ref type="table">Table 5</ref>. Results for fully supervised action segmentation on the Hollywood extended dataset. EI stands for Exact Inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Qualitative Example</head><p>A qualitative example of the FIFA optimization process is depicted in <ref type="figure">Figure 4</ref>. For further qualitative examples, failure cases, and details please refer to the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we proposed FIFA a fast approximate inference procedure for action segmentation and alignment. Unlike previous methods, the proposed method does not rely on any expensive Viterbi decoding for inference. Instead, FIFA optimizes a differentiable energy function that can be minimized using gradientdescent which allows for a fast but also accurate inference during testing. We evaluated FIFA on top of fully and weakly supervised methods trained on the Breakfast dataset. The results show that FIFA is able to achieve comparable or better performance, while being at least 5 time faster than exact inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Detials of Exact Inference</head><p>The NNV approach <ref type="bibr" target="#b34">[35]</ref> proposes an exact solution to the inference problem using a Viterbi-like dynamic programming method. This dynamic programming approach was later adopted by CDFL <ref type="bibr" target="#b28">[29]</ref> and MuCon <ref type="bibr" target="#b36">[37]</ref>. First an auxiliary function Q(t, , n) is defined that yields the best probability score for a segmentation up to frame t satisfying the following conditions:</p><p>the length of the last segment is , the last segment was the nth segment with label c n .</p><p>The function Q can be computed recursively. The following two cases are distinguished. The first case defines when no new segment is hypothesized, i.e &gt; 1. Then,</p><formula xml:id="formula_18">Q(t, , n) = Q(t ? 1, ? 1, n) ? p(c n |x t ),<label>(19)</label></formula><p>with the current frame probability being multiplied with the value of the auxiliary function at the previous frame. The second case is a new segment being hypothesized at frame t, i.e. = 1. Then,</p><formula xml:id="formula_19">Q(t, = 1, n) = max Q(t ? 1,? , n ? 1) ? p(c n |x t ) ? p(? |c n?1 )) ,<label>(20)</label></formula><p>where the optimization being calculated over all possible previous segments with length? and label c n?1 . Here the probability of the previous segment having length? and label c n?1 is being multiplied to the previous value of the auxiliary function.</p><p>The most likely alignment is given by max Q(T, , N ) ? p( |c N ) .</p><p>The optimal lengths can be obtained by keeping track of the maximizing argu-ments? from <ref type="bibr" target="#b19">(20)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Time Complexity Comparison</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1 Time Complexity of Exact Inference</head><p>The time complexity of the above exact inference is quadratic in the length of the video T and linear in the number of segments N . As input videos for action segmentation are usually long, it becomes computationally expensive to calculate. In practice, <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b36">37]</ref> limit the maximum size of each segment to a fixed value of L = 2000. The final time complexity of exact inference is O(LN T ). Furthermore, this optimization process is inherently not parallelizable. This is due to the max operation in <ref type="bibr" target="#b19">(20)</ref>. Experiments have shown <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref> that this inference stage is the main computational bottleneck of action segmentation approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Time Complexity of FIFA</head><p>At each optimization step, the time complexity is O(N T ), where N is the number of segments and T is the length of the video because we must create the M * matrix and calculate the element-wise multiplication. Overall, the FIFA time complexity is O(M N T ), where M is the number of optimization steps. Compared to the exact inference which has a time complexity of O(LN T ), where L is the fixed value of 2000, our time complexity is lower since M is usually 50 steps and N is on average 10. We also want to mention that the proposed approach is inherently a parallelizable optimization method (i.e. values of the mask, the element-wise multiplication, and the calculation of the gradient for each time step can be calculated in parallel) and is independent of any other time step values. This is in contrast to the dynamic programming approaches where the intermediate optimization values for each time step depend on the value of the previous time steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Details of the Datasets</head><p>The Breakfast dataset <ref type="bibr" target="#b18">[19]</ref> is the most popular and largest dataset typically used for action segmentation. It contains more than 1.7k videos of different cooking activities. The dataset consists of 48 different fine-grained actions. In our experiments, we follow the 4 train/test splits provided with the dataset and report the average.</p><p>The Hollywood extended dataset <ref type="bibr" target="#b3">[4]</ref> contains 937 videos taken from Hollywood movies. The videos contain 16 different action classes. We follow the train/test split strategy of <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b28">29]</ref>.</p><p>The main performance metrics used for weakly supervised action segmentation and alignment are the same as the previous approaches. The input features are also kept the same depending on the approach we use FIFA with.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Implementation Details</head><p>We implement our approach using the PyTorch <ref type="bibr" target="#b31">[32]</ref> library. For all experiments we set the number of FIFA's gradient-based optimization steps to 50 and we use the Adam <ref type="bibr" target="#b17">[18]</ref> optimizer. Mask sharpness and the optimization learning rate is chosen depending on the approach that FIFA is applied on top of. When applying FIFA on top of MuCon <ref type="bibr" target="#b36">[37]</ref> we use 0.3 as the learning rate and set the mask sharpness to 1.75. For CDFL <ref type="bibr" target="#b28">[29]</ref>, we set the mask sharpness to 0.1 and the learning rate to 0.15. Looking at the visualization in <ref type="figure">Figure G</ref>.9 it is clear that CDFL provides noisy framewize probability estimates. For this reason a lower mask sharpness is prefered. When applying FIFA on top of fully supervised approaches like MS-TCN <ref type="bibr" target="#b0">[1]</ref> we use mask sharpness value of 15 and learning rate of 0.02. Looking at the visualization in <ref type="figure">Figure G</ref>.15 we see that fully supervised approaches provide clean smooth framewise probabilities and having a sharp mask is recommented in these settings.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Ablation Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1 Number of Optimization Steps</head><p>In <ref type="table">Table E</ref>.1 we report the results for weakly supervised action segmentation on the Breakfast dataset <ref type="bibr" target="#b18">[19]</ref> using the MuCon <ref type="bibr" target="#b36">[37]</ref> approach. The proposed approach achieves the best performance after 50 steps with 5.9% improvement on the MoF accuracy compared to not performing any inference. Moreover, it is more than 5 times faster than the exact inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Optimizer and Its Learning Rate</head><p>The choice of the optimizer used to update the length estimates using the calculated gradients is one of the hyper-parameters of our approach. We have experimented with two optimizers SGD and Adam. As shown in <ref type="figure">Figure E</ref>.1, the best performing value for the learning rate hyper-parameter depends on the optimizer used. For SGD a low value of 0.001 achieves the best performance with higher values causing major drops in performance. On the other hand, Adam optimizer works well with a range of learning rate values as it has an internal mechanism to adjust the learning rate. The best performance for Adam is observed at 0.3. We further investigate and notice that the reason SGD performs so poorly for large values of the learning rate is that it fluctuates and is not able to optimize the energy effectively. <ref type="figure" target="#fig_4">Figure E.2</ref> shows the value of the approximate energy during the optimization for Adam and SGD for the same inference. We observe that a large learning rate causes SGD to fluctuate while Adam is stable and achieves a lower energy value at the end of the optimization. dataset and report the results in <ref type="table">Table F</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Weakly Supervised Action Alignment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Qualitative Examples</head><p>In this section we show various qualitative results of applying FIFA for action segmentation. In each figure on the right, the approximate total energy value is plotted as a function of number of steps. On the left, at the top, the framewise negative log probabilities (P ) are visualized. The ground truth segmentation,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>MoF  optimization initialization, the generated masks and the segmentation obtained after approximate inference using FIFA is visualized in rows 2 to 5. The MoF metric is also calculated for a single video and reported for the optimization initialization and the approximate decoding.</p><p>An animation form of the same figures is also provided in the supplementary material as a single video file.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>c 1 :</head><label>1</label><figDesc>N , 1:N = argmax</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>c 1 :</head><label>1</label><figDesc>N ,? 1:N p(? 1:N ,? 1:N |x 1:T ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>1:N |x 1:T , c 1:N ) .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Speed vs. accuracy trade-off of different inference approaches applied to the MuCon method. Using FIFA we can achieve a better speed vs. accuracy tradeoff compared to frame sampling or hypothesis pruning in exact inference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 .</head><label>3</label><figDesc>Effect of the length energy multiplier for Laplace and Gaussian length energy. Accuracy is calculated on the breakfast dataset using FIFA applied to the MuCon approach trained in the weakly supervised action segmentation setting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. E. 1 .</head><label>1</label><figDesc>Similar to weakly supervised action segmentation, we apply FIFA on top of CDFL and MuCon for weakly supervised action alignment task on the Breakfast Effect of the learning rate on the performance of weakly supervised action segmentation using FIFA applied on the MuCon approach. Accuracy is calculated on the Breakfast dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>. 2 .</head><label>2</label><figDesc>Our experiments show that FIFA applied on top of CDFL achieves state-of-the-art or better than state-of-the-art results on MoF and Mof-BG metrics, whereas FIFA applied on top of MuCon achieves state-of-the-art results for IoD and IoU metrics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. E. 2 .</head><label>2</label><figDesc>The value of the approximate energy during FIFA optimization for SGD and Adam optimizer for the same inference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figures G. 3 -</head><label>3</label><figDesc>G.7 show qualitative examples of applying FIFA on top of Mu-Con [37] for weakly supervised action segmentation. Figures G.9-G.13 show qualitative examples of applying FIFA on top of CDFL [29] for weakly supervised action segmentation. Figures G.15-G.19 show qualitative examples of applying FIFA on top of MSTCN [1] for fully supervised action segmentation. G.1 Failure Cases Figures G.8, G.14 and, G.20 show failure cases for FIFA + MuCon, FIFA + CDFL and, FIFA + MSTCN respectively. We observe that the major failure case is when the optimization is initialized with an incorrect transcript (Figures G.8 and G.14). Another failure mode is when the predicted negative log probabilities are not correct (Figure G.20) which causes the boundaries of actions to be in the wrong location.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. G. 3 .Fig. G. 4 .Fig. G. 5 .Fig. G. 6 .Fig. G. 7 .Fig. G. 8 .Fig. G. 9 .Fig. G. 10 .Fig. G. 11 .Fig. G. 12 .Fig. G. 13 .Fig. G. 14 .Fig. G. 15 .Fig. G. 16 .Fig. G. 17 .Fig. G. 18 .Fig. G. 19 .Fig. G. 20 .</head><label>34567891011121314151617181920</label><figDesc>Qualitativ Result: Weakly supervised action segmentation, FIFA + MuCon Qualitativ Result: Weakly supervised action segmentation, FIFA + MuCon Qualitativ Result: Weakly supervised action segmentation, FIFA + MuCon Qualitativ Result: Weakly supervised action segmentation, FIFA + MuCon Qualitativ Result: Weakly supervised action segmentation, FIFA + MuCon Qualitativ Result: Weakly supervised action segmentation, FIFA + MuCon, Qualitativ Result: Weakly supervised action segmentation, FIFA + CDFL Qualitativ Result: Weakly supervised action segmentation, FIFA + CDFL Qualitativ Result: Weakly supervised action segmentation, FIFA + CDFL Qualitativ Result: Weakly supervised action segmentation, FIFA + CDFL Qualitativ Result: Weakly supervised action segmentation, FIFA + CDFL Qualitativ Result: Weakly supervised action segmentation, FIFA + CDFL, Qualitativ Result: Fully supervised action segmentation, FIFA + MSTCN Qualitativ Result: Fully supervised action segmentation, FIFA + MSTCN Qualitativ Result: Fully supervised action segmentation, FIFA + MSTCN Qualitativ Result: Fully supervised action segmentation, FIFA + MSTCN Qualitativ Result: Fully supervised action segmentation, FIFA + MSTCN Qualitativ Result: Fully supervised action segmentation, FIFA + MSTCN, Failure Case</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>evaluate our model using the Breakfast<ref type="bibr" target="#b18">[19]</ref> and Hollywood extended<ref type="bibr" target="#b3">[4]</ref> datasets on the 3 different tasks. Details of the datasets are included in the supplementary material. Impact of the Length Model initialization for MuCon using exact inference and FIFA for weakly supervised action segmentation on the Breakfast dataset.</figDesc><table><row><cell cols="2">Inference Method initialization</cell><cell>MoF</cell></row><row><cell>Exact</cell><cell>MuCon [37]</cell><cell>50.7</cell></row><row><cell></cell><cell>Equal</cell><cell>48.8 (-1.9)</cell></row><row><cell>FIFA</cell><cell>MuCon [37]</cell><cell>51.3</cell></row><row><cell></cell><cell>Equal</cell><cell>50.2 (-1.1)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Results for weakly supervised action segmentation on the Breakfast dataset. * indicates results obtained by running the code on our machine.</figDesc><table><row><cell>Method</cell><cell cols="5">MoF MoF-BG IoU IoD Time (min)</cell><cell></cell><cell></cell></row><row><cell>ISBA [7] NNV [35]</cell><cell>38.4 43.0</cell><cell>38.4 -</cell><cell cols="2">24.2 40.6 --</cell><cell>0.01 234</cell><cell>Method</cell><cell>F1@{10, 25, 50} Edit MoF</cell></row><row><cell>D3TW [6]</cell><cell>45.7</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>BCN [40]</cell><cell>68.7 65.5 55.0 66.2 70.4</cell></row><row><cell>CDFL [29]</cell><cell>50.2</cell><cell>48.0</cell><cell cols="2">33.7 45.4</cell><cell>-</cell><cell>ASRF [15]</cell><cell>74.3 68.9 56.1 72.4 67.6</cell></row><row><cell cols="2">CDFL  *  FIFA + CDFL  *  47.9 49.4</cell><cell>47.5 46.3</cell><cell cols="3">35.2 46.4 34.7 48.0 20.4 (?12.8) 260</cell><cell cols="2">MS-TCN++ [30] FIFA + MS-TCN++ 74.3 69.0 54.3 77.3 67.9 64.1 58.6 45.9 65.6 67.6</cell></row><row><cell>MuCon [37] MuCon  *</cell><cell>47.1 50.7</cell><cell>-50.3</cell><cell cols="2">-40.9 54.0 -</cell><cell>-4.1</cell><cell>MS-TCN [1]</cell><cell>52.6 48.1 37.9 61.7 66.3</cell></row><row><cell cols="6">FIFA + MuCon  *  51.3 50.7 41.1 53.3 0.8 (?5.1)</cell><cell>FIFA + MS-TCN</cell><cell>75.5 70.2 54.8 78.5 68.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Results for fully supervised action segmentation setup on the Breakfast dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Results for weakly supervised action segmentation on the Hollywood extended dataset. Time is reported in seconds.</figDesc><table><row><cell>Method</cell><cell cols="2">MoF MoF-BG IoU IoD</cell></row><row><cell>HTK [19]</cell><cell>39.5</cell><cell>8.4</cell></row><row><cell>ED-TCN [6]</cell><cell>36.7</cell><cell>27.3 10.9 13.1</cell></row><row><cell>ISBA [6]</cell><cell>54.8</cell><cell>33.1 20.4 28.8</cell></row><row><cell cols="2">MSTCN [1] (+ EI) 64.9</cell><cell>35.0 22.6 33.2</cell></row><row><cell cols="2">MSTCN + FIFA 66.2</cell><cell>34.8 23.9 35.8</cell></row></table><note>* indicates results obtained by run- ning the code on our machine.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Num. Steps MoF MoF-BG IoU IoD Time (min)</figDesc><table><row><cell cols="2">No inference 45.4</cell><cell>44.7</cell><cell>37.3 51.2</cell><cell>1.0</cell></row><row><cell>2 steps</cell><cell>47.9</cell><cell>47.1</cell><cell>39.8 53.0</cell><cell>1.2</cell></row><row><cell>5 steps</cell><cell>49.1</cell><cell>48.3</cell><cell>40.0 52.8</cell><cell>1.5</cell></row><row><cell>10 steps</cell><cell>50.1</cell><cell>49.4</cell><cell>40.2 52.9</cell><cell>2.0</cell></row><row><cell>30 steps</cell><cell>51.2</cell><cell>50.6</cell><cell>41.0 53.2</cell><cell>4.2</cell></row><row><cell>50 steps</cell><cell cols="3">51.3 50.7 41.1 53.3</cell><cell>6.5</cell></row><row><cell>60 steps</cell><cell cols="3">51.3 50.7 41.1 53.3</cell><cell>7.7</cell></row><row><cell cols="2">Exact Inference 50.7</cell><cell>50.3</cell><cell>40.9 54.0</cell><cell>32.85</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Table E.1. Impact of the number of optimization steps for FIFA+MuCon for weakly supervised action segmentation on the Breakfast dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Table F.2. Results for weakly supervised action alignment on the Breakfast dataset.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">MoF-BG IoU IoD</cell></row><row><cell>ISBA [7]</cell><cell>53.5</cell><cell>51.7</cell><cell>35.3 52.3</cell></row><row><cell>D 3 TW [6]</cell><cell>57.0</cell><cell>-</cell><cell>-56.3</cell></row><row><cell>CDFL [29]</cell><cell>63.0</cell><cell>61.4</cell><cell>45.8 63.9</cell></row><row><cell>ADP [10]</cell><cell cols="3">64.1 65.5 43.0 -</cell></row><row><cell cols="3">FIFA + CDFL  *  65.3 64.3</cell><cell>46.3 61.3</cell></row><row><cell cols="2">FIFA + MuCon  *  61.4</cell><cell cols="2">61.2 48.4 64.1</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Ms-tcn: Multi-stage temporal convolutional network for action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abu</forename><surname>Farha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Structured prediction energy networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">End-to-end learning for structured prediction energy networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Weakly supervised action labeling in videos under ordering constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lajugie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Weakly supervised action labeling in videos under ordering constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lajugie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">D 3 TW: Discriminative differentiable dynamic time warping for weakly supervised action alignment and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Weakly-supervised action segmentation with iterative soft boundary assignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Automatic annotation of human actions in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Duchenne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Gatys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.06576</idno>
		<title level="m">A neural algorithm of artistic style</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Action duration prediction for segmentlevel alignment of weakly-labeled videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ghoddoosian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sayed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Athitsos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>WACV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Explaining and harnessing adversarial examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Towards decoding as continuous optimization in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D V</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Haffari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>EMNLP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Connectionist temporal modeling for weakly supervised action labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Niebles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Improving action segmentation via graph-based temporal reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sugano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sato</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Alleviating over-segmentation errors by detecting action boundaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ishikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kasai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Aoki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kataoka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>WACV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Perceptual losses for real-time style transfer and super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fast saliency based pooling of fisher encoded dense trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karaman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seidenari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Del Bimbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV THUMOS Workshop</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The language of actions: Recovering the syntax and semantics of goal-directed human activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">An end-to-end generative framework for video segmentation and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Serre</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>WACV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Weakly supervised learning of actions from transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Weakly supervised learning of actions from transcripts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">163</biblScope>
			<biblScope unit="page" from="78" to="89" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A Hybrid RNN-HMM approach for weakly supervised temporal action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page" from="765" to="779" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Distributed representations of sentences and documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Temporal convolutional networks for action segmentation and detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Segmental spatiotemporal cnns for fine-grained action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">A tutorial on energybased learning. Predicting structured data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Temporal deformable residual networks for action segmentation in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Todorovic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Weakly supervised energy-based learning for action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Todorovic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">MS-TCN++: Multi-stage temporal convolutional network for action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Abu Farha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>PAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Action recognition from single timestamp supervision in untrimmed videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Moltisanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Damen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>NeurIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Parsing videos of actions with segmental grammars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Weakly supervised action learning with rnn based fine-to-coarse modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Neuralnetwork-viterbi: A framework for weakly supervised video learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A database for fine grained activity detection of cooking activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Fast weakly supervised action segmentation using mutual consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Souri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fayyaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Minciullo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Francesca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">arXiv</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">On evaluating weakly supervised action segmentation methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Souri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Minciullo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">arXiv</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">From stochastic grammar to bayes network: Probabilistic parsing of complex activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">N</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Bobick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Boundary-aware cascade networks for temporal action segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
