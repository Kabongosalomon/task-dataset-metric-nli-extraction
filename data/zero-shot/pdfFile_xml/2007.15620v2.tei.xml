<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neural Modeling for Named Entities and Morphology (NEMO 2 )</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Bareket</surname></persName>
							<email>dbareket@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Bar Ilan University</orgName>
								<address>
									<settlement>Ramat-Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Open Media and Information Lab (OMILab)</orgName>
								<orgName type="institution">The Open University of Israel</orgName>
								<address>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
							<email>reut.tsarfaty@biu.ac.il</email>
							<affiliation key="aff0">
								<orgName type="institution">Bar Ilan University</orgName>
								<address>
									<settlement>Ramat-Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Neural Modeling for Named Entities and Morphology (NEMO 2 )</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T02:13+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Named Entity Recognition (NER) is a fundamental NLP task, commonly formulated as classification over a sequence of tokens. Morphologically-Rich Languages (MRLs) pose a challenge to this basic formulation, as the boundaries of Named Entities do not necessarily coincide with token boundaries, rather, they respect morphological boundaries. To address NER in MRLs we then need to answer two fundamental questions, namely, what are the basic units to be labeled, and how can these units be detected and classified in realistic settings, i.e., where no gold morphology is available. We empirically investigate these questions on a novel NER benchmark, with parallel tokenlevel and morpheme-level NER annotations, which we develop for Modern Hebrew, a morphologically rich-and-ambiguous language. Our results show that explicitly modeling morphological boundaries leads to improved NER performance, and that a novel hybrid architecture, in which NER precedes and prunes morphological decomposition, greatly outperforms the standard pipeline, where morphological decomposition strictly precedes NER, setting a new performance bar for both Hebrew NER and Hebrew morphological decomposition tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named Entity Recognition (NER) is a fundamental task in the area of Information Extraction (IE), in which mentions of Named Entities (NE) are extracted and classified in naturally-occurring texts. This task is most commonly formulated as a sequence labeling task, where extraction takes the form of assigning each input token with a label that marks the boundaries of the NE (e.g., B,I,O), and classification takes the form of assigning labels to indicate entity type (PER, ORG, LOC, etc.).</p><p>Despite a common initial impression from latest NER performance, brought about by neural models on the main English <ref type="bibr">NER benchmarks -CoNLL 2003</ref><ref type="bibr" target="#b45">(Tjong Kim Sang, 2003</ref> and OntoNotes <ref type="bibr" target="#b51">(Weischedel et al., 2013)</ref> -the NER task in real-world settings is far from solved. Specifically, NER performance is shown to greatly diminish when moving to other domains <ref type="bibr" target="#b27">(Luan et al., 2018;</ref><ref type="bibr" target="#b44">Song et al., 2018)</ref>, when addressing the long tail of rare, unseen, and new usergenerated entities <ref type="bibr" target="#b11">(Derczynski et al., 2017)</ref>, and when handling languages with fundamentally different structure than English. In particular, there is no readily available and empirically verified neural modeling strategy for Neural NER in those languages with complex word-internal structure, also known as morphologically-rich languages.</p><p>Morphologically-rich languages (MRL) <ref type="bibr" target="#b48">(Tsarfaty et al., 2010;</ref><ref type="bibr" target="#b38">Seddah et al., 2013;</ref> are languages in which substantial information concerning the arrangement of words into phrases and the relations between them is expressed at word level, rather than in a fixed word-order or a rigid structure. The extended amount of information expressed at word-level and the morpho-phonological processes creating these words result in high token-internal complexity, which poses serious challenges to the basic formulation of NER as classification of raw, space-delimited, tokens. Specifically, while NER in English is formulated as the sequence labeling of space-delimited tokens, in MRLs a single token may include multiple meaning-bearing units, henceforth morphemes, only some of which are relevant for the entity mention at hand.</p><p>In this paper we formulate two questions concerning neural modelling strategies for NER in <ref type="bibr">MRLs, namely: (i)</ref> what should be the granularity of the units to be labeled? Space-delimited tokens or finer-grain morphological segments? and, (ii) how can we effectively encode, and accurately de-tect, the morphological segments that are relevant to NER, and specifically in realistic settings, when gold morphological boundaries are not available?</p><p>To empirically investigate these questions we develop a novel parallel benchmark, containing parallel token-level and morpheme-level NER annotations for texts in Modern Hebrew -a morphologically rich and morphologically ambiguous language, which is known to be notoriously hard to parse <ref type="bibr" target="#b30">(More et al., 2019;</ref>.</p><p>Our results show that morpheme-based NER is superior to token-based NER, which encourages a segmentation-first pipeline. At the same time, we demonstrate that token-based NER improves morphological segmentation in realistic scenarios, encouraging a NER-first pipeline. While these two findings may appear contradictory, we aim here to offer a climax; a hybrid architecture where the token-based NER predictions precede and prune the space of morphological decomposition options, while the actual morpheme-based NER takes place only after the morphological decomposition. We empirically show that the hybrid architecture we propose outperforms all token-based and morpheme-based model variants of Hebrew NER on our benchmark, and it further outperforms all previously reported results on Hebrew NER and morphological decomposition. Our error analysis further demonstrates that morphemebased models better generalize, that is, they contribute to recognizing the long tail of entities unseen during training (out-of-vocabulary, OOV), in particular those unseen entities that turn out to be composed of previously seen morphemes.</p><p>The contribution of this paper is thus manifold. First, we define key architectural questions for Neural NER modeling in MRLs and chart the space of modeling options. Second, we deliver a new and novel parallel benchmark that allows one to empirically compare and contrast the morpheme vs. token modeling strategies. Third, we show consistent advantages for morpheme-based NER, demonstrating the importance of morphologically-aware modeling. Next we present a novel hybrid architecture which demonstrates an even further improved performance on both NER and morphological decomposition tasks. Our results for Hebrew present a new bar on these tasks, outperforming the reported state-of-the-art results on various benchmarks. The segmentation of tokens and the identification of adequate NE boundaries is however far from trivial, due to complex morpho-phonological and orthographic processes in some MRLs <ref type="bibr" target="#b50">(Vania et al., 2018;</ref>. This means that the morphemes that compose NEs are not necessarily transparent in the character sequence of the raw tokens. Consider for example phrase (2):</p><p>(2) ????? ?????? ?????? hamerotz labayit halavan the-race to-house.DEF the-white 'the race to the White House'</p><p>Here, the full form of the NE ????? ?????? / habayit halavan (the White House), is not present in the utterances, only the sub-string ????? ????? / bayit halavan ((the) White House) is present in (2) -due to phonetic and orthographic processes suppressing the definite article ?/??ha in certain environments. In this and many other cases, it is not only that NE boundaries do not coincide with token boundaries, they do not coincide with characters or substrings of the token either. This calls for accessing the more basic meaning-bearing units of the token, that is, to decompose the tokens into morphemes. Unfortunately though, the morphological decomposition of surface tokens may be very challenging due to extreme morphological ambiguity. The sequence of morphemes composing a token is not always directly recoverable from its character sequence, and is not known in advance. <ref type="bibr">4</ref> This means that for every raw space-delimited token, there are many conceivable readings which impose different segmentations, yielding different sets of potential NE boundaries. Consider for example the token ?????? (lbny) in different contexts:</p><p>(3) (a) ?????? ?????? hasara livni In (3a) the token ?????? is completely consumed as a labeled NE. In (3b) ?????? is only partly consumed by an NE, and in (3c) and (3d) the token is entirely out of an NE context. In (3c) the token is composed of several morphemes, and in (3d) it consists of a single morpheme. These are only some of the possible decompositions of this surface token, other alternatives may still be available. As shown by <ref type="bibr" target="#b15">Goldberg and Tsarfaty (2008)</ref>; <ref type="bibr" target="#b16">Green and Manning (2010)</ref>; <ref type="bibr" target="#b39">Seeker and ?etinoglu (2015)</ref>; <ref type="bibr" target="#b18">Habash and Rambow (2005)</ref>; More et al. <ref type="bibr" target="#b9">(2019)</ref>, and others, the correct morphological decomposition becomes apparent only in the larger (syntactic or semantic) context. The challenge, in a nutshell, is as follows: in order to detect accurately NE boundaries, we need to segment the raw token first, however, in order to segment tokens correctly, we need to know the greater semantic content, including, e.g., the participating entities.</p><p>How can we break out of this apparent loop? Finally, MRLs are often characterized by an extremely sparse lexicon, consisting of a long-tail of out-of-vocabulary (OOV) entities unseen during training <ref type="bibr">(Czarnowska et al., 2019)</ref>. Even in cases where all morphemes are present in the training data, morphological compositions of seen morphemes may yield tokens and entities which were unseen during training. Take for example the utterance in (4), which the reader may inspect as familiar:</p><p>(4) ????????? ????? ?????? tasnu misin lethailand flew.1PL from-China to-Thailand 'we flew from China to Thailand'</p><p>Example (4) is in fact example (1) with a switched flight direction. This subtle change creates two new surface tokens ?,???? ????????? which might not have been seen during training, even if example (1) had been observed. Morphological compositions of an entity with prepositions, conjunctions, definite markers, possessive clitics and more, cause mentions of seen entities to have unfamiliar surface forms, which often fail to be accurately detected and analyzed. Given the aforementioned complexities, in order to solve NER for MRLs we ought to answer the following fundamental modeling questions: Q1. Units: What are the discrete units upon which we need to set NE boundaries in MRLs? Are they tokens? characters? morphemes? a representation containing multiple levels of granularity? Q2. Architecture: When employing morphemes in NER, the classical approach is "segmentationfirst". However, segmentation errors are detrimental and downstream NER cannot recover from them. How is it best to set up the pipeline so that segmentation and NER could interact? Q3. Generalization: How do the different modeling choices affect NER generalization in MRLs? How can we address the long tail of OOV NEs in MRLs? Which modeling strategy best handles pseudo-OOV entities that result from a previously unseen composition of already seen morphemes?</p><p>To answer the aforementioned questions, we chart and formalize the space of modeling options for neural NER in MRLs. We cast NER as a Sequence Labelling task and formalize it as f : X ? Y, where x ? X is a sequence x 1 , ..., x n of n discrete strings from some vocabulary x i ? ?, and y ? Y is a sequence y 1 , .., y n of the same length, where y i ? Labels, and Labels is a finite set of labels composed of the BIOSE tags (a.k.a., BIOLU as described in <ref type="bibr" target="#b36">Ratinov and Roth (2009)</ref>). Every non-O label is also enriched with an entity type label. Our list of types is presented in <ref type="table" target="#tab_5">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Token-Based or Morpheme-Based?</head><p>Our first modeling question concerns the discrete units upon which to set the NE boundaries. That is, what is the formal definition of the input vocabulary ? for the sequence labeling task?</p><p>The simplest scenario, adopted in most NER studies, assumes token-based input, where each token admits a single label -hence token-single:</p><p>NER token-single : W ? L Here, W = {w * |w ? ?} is the set of all possible token sequences in the language and L = {l * |l ? Labels} is the set of all possible label sequences over the label set defined above. Each token gets assigned a single label, so the input and output sequences are of the same length. The drawback of this scenario is that since the input for token-single incorporates no morphological boundaries, the exact boundaries of the NEs remain underspecified. This case is exemplified at the top row of <ref type="table" target="#tab_3">Table 1</ref>.</p><p>There is another conceivable scenario, where the input is again the sequence of space-delimited tokens, and the output consists of complex labels (henceforth multi-labels) reflecting, for each token, the labels of its constituent morphemes; henceforth, a token-multi scenario:</p><p>NER token-multi : W ? L * Here, W = {w * |w ? ?} is the set of sequences of tokens as in token-single. Each token is assigned a multi-label, i.e., a sequence (l * ? L) which indicates the labels of the token's morphemes in order. The output is a sequence of such multi-labels, one multi-label per token. This variant incorporates morphological information concerning the number and order of labeled morphemes, but lacks the  precise morphological boundaries. This is illustrated at the middle of <ref type="table" target="#tab_3">Table 1</ref>. A downstream application may require (possibly noisy) heuristics to determine the precise NE boundaries of each individual label in the multi-label for an input token. Another possible scenario is a morpheme-based scenario, assigning a label l ? L for each segment:</p><formula xml:id="formula_0">NER morph : M ? L</formula><p>Here, M = {m * |m ? Morphemes} is the set of sequences of morphological segments in the language, and L = {l * |l ? Labels} is the set of label sequences as defined above. The upshot of this scenario is that NE boundaries are precise. An example is given in the bottom row of <ref type="table" target="#tab_3">Table 1</ref>. But, since each token may contain many meaningful morphological segments, the length of the token sequence is not the same as the length of morphological segments to be labeled, and the model assumes prior morphological segmentation -which in realistic scenarios is not necessarily available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Realistic Morphological Decomposition</head><p>A major caveat with morpheme-based modeling strategies is that they often assume an ideal scenario of gold morphological decomposition of the space-delimited tokens into morphological segments (cf. <ref type="bibr" target="#b31">Nivre et al. (2007);</ref><ref type="bibr" target="#b34">Pradhan et al. (2012)</ref>). But in reality, gold morphological decomposition is not known in advance, it has to be predicted automatically, and prediction errors may propagate to contaminate the downstream task.</p><p>Our second modeling question therefore concerns the interaction between the morphological decomposition and the NER tasks: how would it be best to set up the pipeline so that the prediction of the two tasks can interact? To answer this, we define morphological decomposition as consisting of two subtasks: morphological analysis (MA) and morphological disambiguation (MD). We view sentence-based MA as:</p><formula xml:id="formula_1">M A : W ? P(M)</formula><p>Here W = {w * |w ? ?} is the set of possible token sequences as before, M = {m * |m ? M orphemes} is the set of possible morpheme sequences, and P(M) is the set of subsets of M.</p><p>The role of M A is then to assign a token sequence w ? W with all of its possible morphological decomposition options. We represent this set of alternatives in a dense structure that we call a lattice (exemplified in <ref type="figure" target="#fig_0">Figure 1</ref>). MD is the task of picking the single correct morphological path M ? M through the MA lattice of a given sentence:</p><formula xml:id="formula_2">M D : P(M) ? M</formula><p>Now, assume x ? W is a surface sentence in the language, with its morphological decomposition initially unknown and underspecified. In a Standard pipeline, MA strictly precedes MD:</p><formula xml:id="formula_3">M D Standard : M = M D(M A(x))</formula><p>The main problem here is that MD errors may propagate to contaminate the NER output.</p><p>We propose a novel Hybrid alternative, in which we inject a task-specific signal, in this case NER, 5 to constrain the search for M through the lattice:</p><formula xml:id="formula_4">M D Hybrid : M = M D(M A(x) NER token (x))</formula><p>Here, the restriction M A(x) N ER(x) indicates pruning the lattice structure M A(x) to contain only MD options that are compatible with the token-based NER predictions, and only then apply M D to the pruned lattice.</p><p>Both M D Standard and M D Hybrid are disambiguation architectures that result in a morpheme sequence M ? M. The latter benefits from the NER signal, while the former doesn't. The sequence M ? M can be used in one of two ways. We can use M as input to a morpheme model to output morpheme labels. Or, we can rely on the output of the token-multi model and align the token's multi-label with the segments in M .</p><p>In what follows, we want to empirically assess the effect of different modeling choices (tokensingle, token-multi, morpheme) and disambiguation architectures (Standard, Hybrid) on the performance of NER in MRLs. To this end, we need a corpus that allows training and evaluating NER at both token and morpheme-level granularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The Data: A Novel NER Corpus</head><p>This work empirically investigates NER modeling strategies in Hebrew, a Semitic language known for its complex and highly ambiguous morphology. Ben-Mordecai <ref type="formula">(2005)</ref>, the only previous work on Hebrew NER to date, annotated spacedelimited tokens, basing their guidelines on the CoNLL 2003 shared task <ref type="bibr" target="#b5">(Chinchor et al., 1999)</ref>.</p><p>Popular Arabic NER corpora also label spacedelimited tokens (ANERcorp <ref type="bibr" target="#b2">(Benajiba et al., 2007)</ref>, AQMAR <ref type="bibr" target="#b29">(Mohit et al., 2012)</ref>, TWEETS <ref type="bibr" target="#b10">(Darwish, 2013)</ref>), with the exception of the Arabic portion of OntoNotes <ref type="bibr" target="#b51">(Weischedel et al., 2013)</ref> and ACE (LDC, 2008) which annotate NER labels on gold morphologically pre-segmented texts. However, these works do not provide a comprehensive analysis on the performance gaps between morpheme-based and token-based scenarios.</p><p>In agglutinative languages as Turkish, token segmentation is always performed before NER <ref type="bibr" target="#b49">(T?r et al. (2003)</ref>; <ref type="bibr" target="#b24">K???k and Can (2019)</ref>, reenforcing the need to contrast the token-based scenario, widely adopted for Semitic languages, with the morpheme-based scenarios in other MRLs.</p><p>Our first contribution is thus a parallel corpus for Hebrew NER, one version consists of goldlabeled tokens and the other consists of goldlabeled morphemes, for the same text. For this, we performed gold NE annotation of the Hebrew Treebank <ref type="bibr" target="#b43">(Sima'an et al., 2001)</ref>, based on the 6,143 morpho-syntactically analyzed sentences of the HAARETZ corpus, to create both token-level and morpheme-level variants, as illustrated at the topmost and lowest rows of <ref type="table" target="#tab_3">Table 1</ref>, respectively.</p><p>Annotation Scheme We started off with the guidelines of Ben-Mordecai <ref type="formula">(2005)</ref>, from which we deviate in three main ways. First, we label NE boundaries and their types on sequences of morphemes, in addition to the space-delimited token annotations. 6 Secondly, we use the finer-grained entity categories list of ACE <ref type="bibr" target="#b26">(LDC, 2008)</ref>. 7 Finally, we allow nested entity mentions, as in <ref type="bibr" target="#b12">Finkel and Manning (2009);</ref><ref type="bibr">Benikova et al. (2014). 8</ref> Annotation Cycle As <ref type="bibr" target="#b13">Fort et al. (2009)</ref> put it, examples and rules would never cover all possible cases because of the specificity of natural language and the ambiguity of formulation. To address this we employed the cyclic approach of agile annotation as offered by <ref type="bibr" target="#b0">Alex et al. (2010)</ref>. Every cycle consisted of: annotation, evaluation and curation, clarification and refinements. We used WebAnno <ref type="bibr" target="#b54">(Yimam et al., 2013)</ref> as our annotation interface.</p><p>The Initial Annotation Cycle was a two-stage pilot with 12 participants, divided into 2 teams of 6. The teams received the same guidelines, with the exception of the specifications of entity boundaries. One team was guided to annotate the minimal string that designates the entity. The other was guided to tag the maximal string which can still be considered as the entity. Our agreement analysis showed that the minimal guideline generally led to more consistent annotations. Based on this result (as well as low-level refinements) from the pilot, we devised the full version of the guidelines. <ref type="bibr">9</ref> Annotation, Evaluation and Curation: Every annotation cycle was performed by two annotators (A, B) and an annotation manager/curator (C). We annotated the full corpus in 7 cycles. We evaluated the annotation in two ways, manual curation and automatic evaluation. After each annotation step, the curator manually reviewed every sentence in which disagreements arose, as well as specific points of difficulty pointed out by the annotators. The inter-annotator agreement metric described below was also used to quantitatively gauge the progress and quality of the annotation. <ref type="bibr">6</ref> A single NE is always continuous. Token-morpheme discrepancies do not lead to discontinuous NEs. 7 Entity categories are listed in <ref type="table" target="#tab_5">Table 2</ref>. We dropped the NORP category, since it introduced complexity concerning the distinction between adjectives and group names. LAW did not appear in our corpus. <ref type="bibr">8</ref> Nested labels are are not modeled in this paper, but they are published with the corpus, to allow for further research. <ref type="bibr">9</ref> The complete annotation guide is publicly available at https://github.com/OnlpLab/NEMO-Corpus.  Clarifications and Refinements: In the end of each cycle we held a clarification talk between A, B and C, in which issues that came up during the cycle were discussed. Following that talk we refined the guidelines and updated the annotators, which went on to the next cycle. In the end we performed a final curation run to make sentences from earlier cycles comply with later refinements. <ref type="bibr">10</ref> Inter-Annotator Agreement (IAA) IAA is commonly measured using ?-statistic. However, <ref type="bibr" target="#b35">Pyysalo et al. (2007)</ref> show that it is not suitable for evaluating inter-annotator agreement in NER. Instead, an F 1 metric on entity mentions has in recent years been adopted for this purpose <ref type="bibr" target="#b55">(Zhang, 2013)</ref>. This metric allows for computing pair-wise IAA using standard F 1 score by treating one annotator as gold and the other as the prediction.</p><p>Our full corpus pair-wise F 1 scores are: IAA(A,B)=89, IAA(B,C)=92, IAA(A,C)=96. Table 2 presents final corpus statistics.</p><p>Annotation Costs The annotation took on average about 35 seconds per sentence, and thus a total of 60 hours for all sentences in the corpus for each annotator. Six clarification talks were held between the cycles, which lasted from thirty minutes to an hour. Giving a total of about 130 work hours of expert annotators. 11 Modeling Variants All experiments use the corpus we just described and employ a standard Bi-LSTM-CRF architecture for implementing the neural sequence labeling task <ref type="bibr" target="#b19">(Huang et al., 2015)</ref>. Our basic architecture 12 is composed of an embedding layer for the input and a 2-layer Bi-LSTM followed by a CRF inference layer -for which we test three modeling variants.</p><p>Figures 2-3 present the variants we employ. <ref type="figure" target="#fig_1">Figure 2</ref> shows the token-based variants, tokensingle and token-multi. The former outputs a single BIOSE label per token, and the latter outputs a multi-label per token -a concatenation of BIOSE labels of the morphemes composing the token. <ref type="figure" target="#fig_2">Figure 3</ref> shows the morpheme-based variant for the same input phrase. It has the same basic architecture, but now the input consists of morphological segments instead of tokens. The model outputs a single BIOSE label for each morphological segment in the input.</p><p>In all modeling variants, the input may be encoded in two ways: (a) String-level embeddings (token-based or morpheme-based) optionally initialized with pre-trained embeddings. (b) Charlevel embeddings, trained simultaneously with the main task (cf. <ref type="bibr" target="#b28">Ma and Hovy (2016)</ref>; Chiu and Nichols (2015); <ref type="bibr" target="#b25">Lample et al. (2016)</ref>). For charbased encoding (of either tokens or morphemes) <ref type="bibr">12</ref> Using the NCRF++ suite of . we experiment with CharLSTM, CharCNN or NoChar, that is, no character embedding at all.</p><p>We pre-trained all token-based or morphemebased embeddings on the Hebrew Wikipedia dump of <ref type="bibr" target="#b14">Goldberg (2014)</ref>. For morpheme-based embeddings, we decompose the input using More et al. <ref type="bibr" target="#b9">(2019)</ref>, and use the morphological segments as the embedding units. <ref type="bibr">13</ref> We compare GloVe <ref type="bibr" target="#b32">(Pennington et al., 2014)</ref> and fastText <ref type="bibr" target="#b4">(Bojanowski et al., 2017)</ref>. We hypothesize that since FastText uses sub-string information, it will be more useful for analyzing OOVs.</p><p>Hyper parameters Following Reimers and Gurevych (2017); , we performed hyper-parameter tuning for each of our model variants. We performed hyper-parameter tuning on the dev set in a number of rounds of random search, independently on every input/output and char-embedding architecture. <ref type="table" target="#tab_7">Table 3</ref> shows our selected hyper-parameters. 14 The Char CNN window size is particularly interesting as it was <ref type="bibr">13</ref> Embeddings and Wikipedia corpus also available in: https://github.com/OnlpLab/NEMO 14 A few interesting empirical observations diverging from those of <ref type="bibr" target="#b37">Reimers and Gurevych (2017)</ref>;  are worth mentioning. We found that a lower Learning Rate than the one recommended by  (0.015), led to better results and less occurrences of divergence. We further found that raising the number of Epochs from 100 to 200 did not result in over-fitting, and significantly improved NER results. We used for evaluation the weights from the best epoch.  not treated as a hyper-parameter in <ref type="bibr" target="#b37">Reimers and Gurevych (2017)</ref>, . However, given the token-internal complexity in MRLs we conjecture that the window size over characters might make a crucial effect. In our experiments we found that a larger window <ref type="formula">(7)</ref> increased the performance. For MRLs, further research into this hyper-parameter might be of interest.</p><p>Evaluation Standard NER studies typically invoke the CoNLL evaluation script that anchors NEs in token positions (Tjong Kim <ref type="bibr" target="#b45">Sang, 2003)</ref>. However, it is inadequate for our purposes because we want to compare entities across token-based vs. morpheme-based settings. To this end, we use a revised evaluation procedure, which anchors the entity in its form rather than its index. Specifically, we report F 1 scores on strict, exact-match of the surface forms of the entity mentions. I.e., the gold and predicted NE spans must exactly match in their form, boundaries, and entity type. In all experiments, we report both token-level F-scores and morpheme-level F-scores, for all models.</p><p>? Token-Level evaluation. For the sake of backwards compatibility with previous work on Hebrew NER, we first define token-level evaluation. For token-single this is a straightforward calculation of F 1 against gold spans. For token-multi and morpheme, we need to map the predicted label sequence of that token to a single label, and we do so using linguistically-informed rules we devise (as elaborated in Appendix A). 15</p><p>? Morpheme-Level evaluation. Our ultimate goal is to obtain precise boundaries of the NEs. Thus, our main metric evaluates NEs <ref type="bibr">15</ref> In the morpheme case we might encounter "illegal" label sequences in case of a prediction error. We employ similar linguistically-informed heuristics to recover from that (See Appendix A). against the gold morphological boundaries. For morpheme and token-single models, this is a straightforward F 1 calculation against gold spans. Note for token-single we are expected to pay a price for boundary mismatch. For token-multi, we know the number and order of labels, so we align the labels in the multi-label of the token with the morphemes in its morphological decomposition. <ref type="bibr">16</ref> For all experiments and metrics, we report mean and confidence interval (0.95) over ten runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input-Output Scenarios</head><p>We experiment with two kinds of input settings: token-based, where the input consists of the sequence of space-delimited tokens, and morpheme-based, where the input consists of morphological segments. For the morpheme input, there are three input variants:</p><p>(i) Morph-gold: where the morphological sequence is produced by an expert (idealistic).</p><p>(ii) Morph-standard: where the morphological sequence is produced by a standard segmentation-first pipeline (realistic). (iii) Morph-hybrid: where the morphological sequence is produced by the hybrid architecture we propose (realistic).</p><p>In the token-multi case we can perform morpheme-based evaluation by aligning individual labels in the multi-label with the morpheme sequence of the respective token. Again we have three options as to which morphemes to use:</p><p>(i) Tok-multi-gold: The multi-label is aligned with morphemes produced by an expert (idealistic).</p><p>(ii) Tok-multi-standard: The multi-label is aligned with morphemes produced by a standard pipeline (realistic). (iii) Tok-multi-hybrid: The multi-label is aligned with morphemes produced by the hybrid architecture we propose (realistic).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pipeline Scenarios Assume an input sentence x.</head><p>In the Standard pipeline we use YAP, 17 the current state-of-the-art morpho-syntactic parser for Hebrew <ref type="bibr" target="#b30">(More et al., 2019)</ref>, for the predicted segmentation M = M D(M A(x)). In the Hybrid  pipeline, we use YAP to first generate complete morphological lattices M A(x). Then, to obtain M A(x) N ER(x) we omit lattice paths where the number of morphemes in the token decomposition does not conform with the number of labels in the multi-label of NER token-multi (x). Then, we apply YAP to obtain M D(M A(x) N ER(x)) on the constrained lattice. In predicted morphology scenarios (either Standard or Hybrid), we use the same model weights as trained on the gold segments, but feed predicted morphemes as input. 18 6 Results <ref type="figure" target="#fig_3">Figure 4</ref> shows the token-level evaluation for the different model variants we defined. We see that morpheme models perform significantly better than the token-single and token-multi variants. In-  terestingly, explicit modeling of morphemes leads to better NER performance even when evaluated against token-level boundaries. As expected, the performance gaps between variants are smaller with fastText than they are with embeddings that are unaware of characters (GloVe) or with no pretraining at all. We further pursue this in Sec. 6.3. <ref type="figure" target="#fig_4">Figure 5</ref> shows the morpheme-level evaluation for the same model variants as in <ref type="table" target="#tab_9">Table 4</ref>. The most obvious trend here is the drop in the performance of the token-single model. This is expected, reflecting the inadequacy of token boundaries for identifying accurate boundaries for NER. Interestingly, morpheme and token-multi models keep a similar level of performance as in tokenlevel evaluation, only slightly lower. Their per- formance gap is also maintained, with morpheme performing better than token-multi. An obvious caveat is that these results are obtained with gold morphology. What happens in realistic scenarios?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">The Units: Tokens vs. Morphemes</head><p>6.2 The Architecture: Pipeline vs. Hybrid <ref type="figure" target="#fig_5">Figure 6</ref> shows the token-level evaluation results in realistic scenarios. We first observe a significant drop for morpheme models when Standard predicted segmentation is introduced instead of gold. This means that MD errors are indeed detrimental for the downstream task, in a non-negligible rate. Second, we observe that much of this performance gap is recovered with the Hybrid pipeline. It is noteworthy that while morph hybrid lags behind morph gold, it is still consistently better than token-based models, token-single and token-multi. <ref type="figure" target="#fig_6">Figure 7</ref> shows morpheme-level evaluation results for the same scenarios as in <ref type="table" target="#tab_12">Table 6</ref>. All trends from the token-level evaluation persist, including a drop for all models with predicted segmentation relative to gold, with the hybrid variant recovering much of the gap. Again morph gold outperforms token-multi, but morph hybrid shows great advantages over all tok-multi variants. This performance gap between morph (gold or hybrid) and tok-multi indicates that explicit morphological modeling is indeed crucial for accurate NER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Morphologically-Aware OOV Evaluation</head><p>As discussed in Section 2, morphological composition introduces an extremely sparse word-level "long-tail" in MRLs. In order to gauge this phenomenon and its effects on NER performance, we categorize unseen, out-of-training-vocabulary (OOTV) mentions into 3 categories: ? Lexical: Unknown mentions caused by an unknown token which consists of a single morpheme. This is a strictly lexical unknown with no morphological composition (most English unknowns are in this category).</p><p>? Compositional: Unknown mentions caused by an unknown token which consists of multiple known morphemes. These are unknowns introduced strictly by morphological composition, with no lexical unknowns.</p><p>? LexComp: Unknown mentions caused by an unknown token consisting of multiple morphemes, of which (at least) one morpheme was not seen during training. In such cases, both unknown morphological composition and lexical unknowns are involved.</p><p>We group NEs based on these categories, and evaluate each group separately. We consider mentions that do not fall into any category as Known. <ref type="figure" target="#fig_7">Figure 8</ref> shows the distributions of entity mentions in the dev set by entity type and OOTV category. OOTV categories that involve composition (Comp and LexComp) are spread across all categories but one, and in some they even make up more than half of all mentions. <ref type="figure" target="#fig_8">Figure 9</ref> shows token-level evaluation 19 with fastText embeddings, grouped by OOTV type. We first observe that indeed unknown NEs that are due to morphological composition (Comp and Lex-Comp) proved the most challenging for all models. We also find that in strictly Compositional OOTV mentions, morpheme-based models exhibit their most significant performance advantage, supporting the hypothesis that explicit morphology helps to generalize. We finally observe that token-multi models perform better than token-single models for these NEs (in contrast with the trend for noncompositional NEs). This corroborates the hypothesis that even partial modeling of morphology (as in token-multi compared to token-single) is better than none, leading to better generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>String-level vs. Character-level Embeddings</head><p>To further understand the generalization capacity of different modeling alternatives in MRLs, we probe into the interplay of string-based and charbased embeddings in treating OOTV NEs. <ref type="figure" target="#fig_0">Figure 10</ref> presents 12 plots, each of which presents the level of performance (y-axes) for all models (x-axes). Token-based models are on the left of each x-axes, morpheme-based are on the right. We plot results with and without character embeddings, 20 in orange and blue respectively. The plots are organized in a large grid, with the type of NE on the y-axes <ref type="bibr">(Known, Lex, Comp, Lex-Comp)</ref>, and the type of pre-training on the x-axes <ref type="bibr">(No pre-training, GloVe, fastText)</ref> .</p><p>At the top-most row, plotting the accuracy for Known NEs, we see a high level of performance for all pre-training methods, with not much differences between the type of pre-training, with or without the character embeddings. Moving further down to the row of Lexical unseen NEs, char-based representations lead to significant advantages when we assume no pre-training, but with GloVe pre-training the performance substantially increases, and with fastText the differences in performance with/without char-embeddings almost entirely diminish, indicating the char-based embeddings are somewhat redundant in this case.</p><p>The two lower rows in the large grid show the performance for Comp and LexComp unseen NEs, which are ubiquitous in MRLs. For Compositional NEs, pre-training closes only part of the gap between token-based and morpheme-based models. Adding char-based representations indeed helps the token-based models, but crucially does not close the gap with the morpheme-based variants.</p><p>Finally, for LexComp NEs at the lowest row, we again see that adding GloVe pre-training and charbased embeddings does not close the gap with  morpheme-based models, indicating that not all morphological information is captured by these vectors. For fastText with char-based embeddings the gap between token-multi and morpheme greatly diminishes, but is still well above tokensingle. This suggests biasing the model to learn about morphology (either via multi-labels or by incorporating morphological boundaries) has advantages for analysing OOTV entities, beyond the contribution of char-based embeddings alone. All in all, the biggest advantage of morphemebased models over token-based models is their ability to generalize from observed tokens to composition-related OOTV (Comp/LexComp). While character-based embeddings do help tokenbased models generalize, the contribution of modeling morphology is indispensable, above and beyond the contribution of char-based embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Setting in the Greater Context</head><p>Test Set Results <ref type="table" target="#tab_9">Table 4</ref> confirms our best results on the Test set. The trends are kept, though results on Test are lower than on Dev. The morph gold scenario still provides an upperbound of the performance, but it is not realistic. For the realistic scenarios, morph hybrid generally outperforms all other alternatives. The only divergence is that in token-level evaluation, token-multi performs on a par with morph hybrid on the Test set.</p><p>Results on MD Tasks. While the Hybrid pipeline achieves superior performance on NER, it also improves the state-of-the-art on other tasks in the pipeline. <ref type="table" target="#tab_11">Table 5</ref> shows the Seg+POS results of our Hybrid pipeline scenario, compared with the Standard pipeline which replicates the pipeline of More et al. <ref type="bibr" target="#b9">(2019)</ref>. We use the metrics defined by More et al. <ref type="bibr" target="#b9">(2019)</ref>. We show substantial improvements for the Hybrid pipeline over the results of <ref type="bibr" target="#b30">More et al. (2019)</ref>, and also outperforming the Test results of .  Comparison with Prior Art.  we performed three 75%-25% random train/test splits, and used the same seven NE categories (PER,LOC,ORG,TIME,DATE,PERCENT,MONEY). We trained a token-single model on the original space-delimited tokens and a morpheme model on automatically segmented morphemes we obtained using our best segmentation model (Hybrid MD on our trained token-multi model, as in <ref type="table" target="#tab_11">Table 5</ref>).</p><p>Since their annotation includes only token-level boundaries, all of the results we report conform with token-level evaluation. <ref type="table" target="#tab_12">Table 6</ref> presents the results of these experiments. Both models significantly outperform the previous state-of-the-art by Ben-Mordecai <ref type="formula">(2005)</ref>, setting a new performance bar on this earlier benchmark. Moreover, we again observe an empirical advantage when explicitly modeling morphemes, even with the automatic noisy segmentation that is used for the morpheme-based training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion: Joint Modeling</head><p>Alternatives and Future Work</p><p>The present study provides the motivation and the necessary foundations for comparing morphemebased and token-based modeling for NER. While our findings clearly demonstrate the advantages of morpheme-based modeling for NER in a morphologically rich language, it is clear that our proposed Hybrid architecture is not the only modeling alternative for linking NER and morphology.</p><p>For example, a previous study by <ref type="bibr" target="#b17">G?ng?r et al. (2018)</ref> addresses joint neural modeling of morphological segmentation and NER labeling, proposing a multi-task learning (MTL) approach for joint MD and NER in Turkish. They employ separate Bi-LSTM networks for the MD and NER tasks, with a shared loss to allow for joint learning.</p><p>Their results indicate improved NER performance, with no improvement in the MD results. Contrary to our proposal, they view MD and NER as distinct tasks, assuming a single NER label per token, and not providing disambiguated morpheme-level boundaries for the NER task. More generally, they test only token-based NER labeling and do not attend to the question of input/output granularity in their models.</p><p>A different approach for joint NER and morphology is jointly predicting the segmentation and labels for each token in the input stream. This is the approach taken, for instance, by the lattice-based Pointer-Network of Seker and Tsarfaty (2020). As shown in <ref type="table" target="#tab_11">Table 5</ref>, their results for morphological segmentation and POS tagging are on a par with our reported results and, at least in principle, it should be possible to extend the Seker and Tsarfaty (2020) approach to yield also NER predictions.</p><p>However, our preliminary experiments with a lattice-based Pointer-network for token segmentation and NER labeling shows that this is not a straightforward task. Contrary to POS tags, which are constrained by the MA, every NER label can potentially go with any segment, and this leads to a combinatorial explosion of the search space represented by the lattice. As a result, the NER predictions are brittle to learn, and the complexity of the resulting model is computationally prohibitive.</p><p>A different approach to joint sequence segmentation and labeling can be applying the neural model directly on the character-sequence of the input stream. Such an approach is for instance the char-based labeling as segmentation setup proposed by <ref type="bibr" target="#b42">Shao et al. (2017)</ref>. Shao et al. use a character-based Bi-RNN-CRF to output a single label-per-char which indicates both word boundary (using BIES sequence labels) and the POS tags. This method is also used in their universal segmentation paper, <ref type="bibr" target="#b41">(Shao et al., 2018)</ref>. However, as seen in the results of <ref type="bibr" target="#b41">Shao et al. (2018)</ref>, charbased labeling for segmenting Semitic languages lags far behind all other languages, precisely because morphological boundaries are not explicit in the character sequences.</p><p>Additional proposals are those of <ref type="bibr" target="#b23">Kong et al. (2015)</ref>; <ref type="bibr" target="#b21">Kemos et al. (2019)</ref>. First, <ref type="bibr" target="#b23">Kong et al. (2015)</ref> proposed to solve e.g. Chinese segmentation and POS tagging using dynamic programming with neural encoding, by using a Bi-LSTM to encode the character input, and then feed it to a semi-markov CRF to obtain probabilities for the different segmentation options. <ref type="bibr" target="#b21">Kemos et al. (2019)</ref> propose an approach similar to <ref type="bibr" target="#b23">Kong et al. (2015)</ref> for joint segmentation and tagging but add convolution layers on top of the Bi-LSTM encodings to obtain segment features hierarchically and then feed them to the semi-markov CRF.</p><p>Preliminary experiments we conducted confirm that char-based joint segmentation and NER labeling for Hebrew, either using char-based labeling or a seq2seq architecture, still lags behind our reported results. We conjecture that this is due to the complex morpho-phonological and orthographic processed in Semitic languages. Going into charbased modeling nuances and offering a sound joint solution for a language like Hebrew is an important matter that merits its own investigation. Such work is feasible now given the new corpus, however, it is out of the scope of the current study.</p><p>All in all, the design of sophisticated joint modeling strategies for morpheme-based NER poses fascinating questions -for which our work provides a solid foundation (data, protocols, metrics, strong baselines). More work is needed for investigating joint modeling of NER and morphology, in the directions portrayed in this Section, yet it is beyond the scope of this paper, and we leave this investigation for future work.</p><p>Finally, while the joint approach is appealing, we argue that the elegance of our Hybrid solution is precisely in providing a clear and well-defined interface between MD and NER through which the two tasks can interact, while still keeping the distinct models simple, robust, and efficiently trainable. It also has the advantage of allowing us to seamlessly integrate sequence labelling with any lattice-based MA, in a plug-and-play languageagnostic fashion, towards obtaining further advantages on both of these tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>This work addresses the modeling challenges of Neural NER in MRLs. We deliver a parallel tokenvs-morpheme NER corpus for Modern Hebrew, that allows one to assess NER modeling strategies in morphologically rich-and-ambiguous environments. Our experiments show that while NER benefits from morphological decomposition, downstream results are sensitive to segmentation errors. We thus propose a Hybrid architecture in which NER precedes and prunes the morphological decomposition. This approach greatly outperforms a Standard pipeline in realistic (nongold) scenarios. Our analysis further shows that morpheme-based models better recognize OOVs that result from morphological composition. All in all we deliver new state-of-the-art results for Hebrew NER and MD, along with a novel benchmark, to encourage further investigation into the interaction between NER and morphology.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Lattice for a partial list of analyses of the Hebrew tokens ????? ?????? corresponding toTable 1. Bold nodes are token boundaries. Light nodes are segment boundaries. Every path through the lattice is a single morphological analysis. The bold path is a single NE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The token-single and token-multi Models. The input and output correspond to rows 1,2 in Tab. 1. Triangles indicate string embeddings. Circles indicate char-based encoding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>The morpheme Model. The input and output correspond to row 3 in Tab. 1. Triangles indicate string embeddings. Circles indicate char-based encoding.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Token-level Eval. on Dev w/ Gold Segmentation. CharCNN for morph, CharLSTM for tok.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Morph-Level Eval. on Dev w/ Gold Segmentation. CharCNN for morph, CharLSTM for tok.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Token-Level Evaluation in Realistic Scenarios on Dev, comparing Gold, Standard and Hybrid Morphology. CharCNN for morph, CharLSTM for tok. Results for Gold, token-single and token-multi are taken from Fig 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>Morph-Level Evaluation in Realistic Scenarios on Dev, comparing Gold, Standard and Hybrid Morphology. CharCNN for morph, CharLSTM for tok. Results for Gold, token-single and token-multi are taken from Fig 5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :</head><label>8</label><figDesc>Entity Mention Counts and Ratio by Category and OOTV Category, for Dev Set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 :</head><label>9</label><figDesc>Token-Level Eval on Dev by OOTV Category. Using fastText and CharLSTM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Research Questions: NER for MRLsIn MRLs, words are internally complex, and word boundaries do not generally coincide with the boundaries of more basic meaning-bearing units.</figDesc><table><row><cell cols="3">This fact has critical ramifications for sequence</cell></row><row><cell cols="3">labeling tasks in MRLs in general, and for NER</cell></row><row><cell cols="3">in MRLs in particular. Consider, for instance, the</cell></row><row><cell cols="3">three-token Hebrew phrase in (1): 2</cell></row><row><cell cols="2">(1) ????? ????????? ??????</cell><cell></cell></row><row><cell>tasnu</cell><cell>mithailand</cell><cell>lesin</cell></row><row><cell>flew.1PL</cell><cell>from-Thailand</cell><cell>to-China</cell></row><row><cell cols="3">'we flew from Thailand to China'</cell></row><row><cell cols="3">It is clear that ?/???????thailand (Thailand) and</cell></row><row><cell cols="3">?/???sin (China) are NEs, and in English, each NE</cell></row><row><cell>1</cell><cell></cell><cell></cell></row></table><note>1 Data &amp; code: https://github.com/OnlpLab/NEMO 2is its own token. In the Hebrew phrase though, neither NE constitutes a single token. In either case, the NE occupies only one of two morphemes in the token, the other being a case-assigning preposition. This simple example demonstrates an extremely frequent phenomenon in MRLs such as Hebrew, Arabic or Turkish, that the adequate boundaries for NEs do not coincide with token boundaries, and tokens must be segmented in or- der to obtain accurate NE boundaries. 3</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Input/output for token-single, token-multi and morpheme models for example (2) in Sec. 2.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Basic Corpus Statistics. Standard HTB Splits.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Summary of Hyper-Parameter Tuning. The * indicates divergence from the NCRF++ proposed setup and empirical findings.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>? 0.5 77.11 ? 0.7 morph standard 72.79 ? 0.5 69.52 ? 0.6 token-multi hybrid 75.70 ? 0.5 74.64 ? 0.3 Tokenmorph gold 80.30 ? 0.5 79.28 ? 0.6</figDesc><table><row><cell>Eval</cell><cell>Model</cell><cell>dev</cell><cell>test</cell></row><row><cell cols="2">Morph-morph gold</cell><cell cols="2">80.03 ? 0.4 79.10 ? 0.6</cell></row><row><cell cols="4">Level 78.51 Level morph hybrid morph hybrid 79.04 ? 0.5 77.64 ? 0.7</cell></row><row><cell></cell><cell>morph standard</cell><cell cols="2">74.52 ? 0.7 73.53 ? 0.8</cell></row><row><cell></cell><cell>token-multi</cell><cell cols="2">77.59 ? 0.4 77.75 ? 0.3</cell></row><row><cell></cell><cell>token-single</cell><cell cols="2">78.15 ? 0.3 77.15 ? 0.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4 :</head><label>4</label><figDesc>Test vs. Dev: Results with fastText for all Models. morph-gold presents an ideal upper-bound.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Figure 10 :</head><label>10</label><figDesc>Token-Level Eval. on Dev for Different OOTV Types, Char-and Word-Embeddings.</figDesc><table><row><cell></cell><cell>Seg+POS</cell></row><row><cell>dev Standard (More et al., 2019)</cell><cell>92.36</cell></row><row><cell cols="2">Ptr-Network (Seker and Tsarfaty, 2020) 93.90</cell></row><row><cell>Hybrid (This work)</cell><cell>93.12</cell></row><row><cell>test Standard (More et al., 2019)</cell><cell>89.08</cell></row><row><cell cols="2">Ptr-Network (Seker and Tsarfaty, 2020) 90.49</cell></row><row><cell>Hybrid (This work)</cell><cell>90.89</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5 :</head><label>5</label><figDesc>Morphological Segmentation &amp; POS scores.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell>presents</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 6 :</head><label>6</label><figDesc>NER Comparison with Ben-Mordecai (2005).</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Glossing conventions are in accord with the Leipzig Glossing Rules<ref type="bibr" target="#b7">(Comrie et al., 2008)</ref>.3  We use the term morphological segmentation (or segmentation) to refer to splitting raw tokens into morphological segments, each carrying a single Part-Of-Speech tag. That is, we segment away prepositions, determiners, subordination markers and multiple kinds of pronominal clitics, that attach to their hosts via complex morpho-phonological processes. Throughout this work, we use the terms morphological segment, morpheme, or segment interchangeably.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">This ambiguity gets magnified by the fact that Semitic languages that use abjads, like Hebrew and Arabic, lack capitalization altogether and suppress all vowels (diacritics).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We can do this for any sequence labeling task in MRLs.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Experimental SettingsGoal We set out to empirically evaluate the representation alternatives for the input/output sequences (token-single, token-multi, morpheme) and the effect of different architectures (Standard, Hybrid) on the performance of NER for Hebrew.10  A, B and C annotations are published to enable research on learning with disagreements<ref type="bibr" target="#b33">(Plank et al., 2014)</ref>.11  The corpus is available at https://github.com/ OnlpLab/NEMO-Corpus.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16">In case of a misalignment (in the number of morphemes and labels) we match the label-morpheme pairs from the final one backwards, and pad unpaired morphemes with O labels.17  For other languages this may be done using models for canonical segmentation as in<ref type="bibr" target="#b20">(Kann et al., 2016)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18">We do not re-train the morpheme models with predicted segmentation, which might achieve better performance (e.g.. jackknifing). We leave this for future work.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19">This section focuses on token-level evaluation, which is a permissive evaluation metric, allowing us to compare the models on a more level playing field, where all models (including token-single) have an equal opportunity to perform.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20">For brevity we only show char LSTM (vs. no char representation), there was no significant difference with CNN.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We are grateful to the BIU-NLP lab members as well as 6 anonymous reviewers for their insightful remarks. We further thank Daphna Amit and Zef Segal for their meticulous annotation and profound discussions. This research is funded by an ISF Individual Grant (1739/26) and an ERC Starting Grant (677352), for which we are grateful.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Alignment Heuristics</head><p>Aligning Multi-labels to Single Labels. In order to evaluate morpheme-based labels (morph or token-multi) in token-based settings, we introduce a deterministic procedure to extend the morphological labels to token boundaries. Specifically, we use regular expressions to map the multiple sequence labels to a single label by choosing the first non-O entity category (BIES) as the single category. In case the sequence of labels is not valid (e.g., B comes after E, or there is an O between two I labels), we use a relaxed mapping that does not take the order of the labels into consideration: if there is an S or both B and E in the sequence, return an S. Otherwise, if there is an E, return an E; if there is a B, return a B; if there is an I return an I ( <ref type="figure">Figure 11</ref>).</p><p>Aligning Multi-labels to Morphemes. In order to obtain morpheme boundary labels from tokenmulti, we introduce a deterministic procedure to align the token's predicted multi-label with the list of morphemes predicted for it by the MD. Specifically, we align the multi-labels to morphemes in the order that they are both provided. In case of a mismatch between the number of labels and morphemes predicted for the token, we match labelmorpheme pairs from the final one backwards. If the number of morphemes exceeds the number of labels, we pad unpaired morphemes with O labels. If the number of labels exceeds the morphemes, we drop unmatched labels <ref type="figure">(Figure 12</ref>). </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Agile corpus annotation in practice: An overview of manual and automatic annotation of CVs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bea</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongzhou</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mijail</forename><surname>Kabadjov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Linguistic Annotation Workshop</title>
		<meeting>the Fourth Linguistic Annotation Workshop<address><addrLine>Uppsala, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="29" to="37" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Hebrew named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naama</forename><surname>Ben-Mordecai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, Ben-Gurion University</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Anersys: An arabic named entity recognition system based on maximum entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yassine</forename><surname>Benajiba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jos? Miguel</forename><surname>Bened?ruiz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Linguistics and Intelligent Text Processing</title>
		<meeting><address><addrLine>Berlin, Heidelberg; Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="143" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">NoSta-D named entity annotation for German: Guidelines and dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darina</forename><surname>Benikova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Reznicek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014)</title>
		<meeting>the Ninth International Conference on Language Resources and Evaluation (LREC-2014)<address><addrLine>Reykjavik, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2524" to="2531" />
		</imprint>
	</monogr>
	<note>European Languages Resources Association (ELRA</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Named entity recognition task definition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chinchor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Robinson</surname></persName>
		</author>
		<idno>Version 1.4</idno>
	</analytic>
	<monogr>
		<title level="m">The MITRE Corporation and SAIC</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Named entity recognition with bidirectional lstm-cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nichols</surname></persName>
		</author>
		<idno>abs/1511.08308</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">The leipzig glossing rules: Conventions for interlinear morphemeby-morpheme glosses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Comrie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Haspelmath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balthasar</forename><surname>Bickel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Department of Linguistics of the Max Planck Institute for Evolutionary Anthropology &amp; the Department of Linguistics of the University of Leipzig</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paula</forename><surname>Czarnowska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Copestake</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Don&apos;t forget the long tail! a comprehensive analysis of morphological generalization in bilingual lexicon induction</title>
		<idno type="DOI">10.18653/v1/D19-1090</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="974" to="983" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Named entity recognition using cross-lingual resources: Arabic as an example</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kareem</forename><surname>Darwish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1558" to="1567" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Results of the WNUT2017 shared task on novel and emerging entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marieke</forename><surname>Van Erp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nut</forename><surname>Limsopatham</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-4418</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Noisy User-generated Text</title>
		<meeting>the 3rd Workshop on Noisy User-generated Text<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="140" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
	<note>EMNLP &apos;09. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Towards a methodology for named entities annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kar?n</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maud</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adeline</forename><surname>Nazarenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Linguistic Annotation Workshop (LAW III)</title>
		<meeting>the Third Linguistic Annotation Workshop (LAW III)<address><addrLine>Suntec, Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="142" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Hebrew wikipedia dependency parsed corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<idno>V.1.0</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
	<note>v.1.0.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A single generative model for joint morphological segmentation and syntactic parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Columbus, Ohio. Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="371" to="379" />
		</imprint>
	</monogr>
	<note>Proceedings of ACL-08: HLT</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Better Arabic parsing: Baselines, evaluations, and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics<address><addrLine>Beijing, China. Coling</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="394" to="402" />
		</imprint>
	</monogr>
	<note>Organizing Committee</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Improving named entity recognition by jointly learning to disambiguate morphological tags</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Onur</forename><surname>G?ng?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzan</forename><surname>?sk?darli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tunga</forename><surname>G?ng?r</surname></persName>
		</author>
		<idno>abs/1807.06683</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<idno type="DOI">10.3115/1219840.1219911</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)</title>
		<meeting>the 43rd Annual Meeting of the Association for Computational Linguistics (ACL&apos;05)<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="573" to="580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Bidirectional LSTM-CRF models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno>abs/1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Neural morphological analysis: Encoding-decoding canonical segments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katharina</forename><surname>Kann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Cotterell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D16-1097</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="961" to="967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural semi-Markov conditional random fields for robust character-based part-of-speech tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apostolos</forename><surname>Kemos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heike</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1280</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2736" to="2743" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Getting the ##life out of living: How adequate are wordpieces for modelling complex morphology?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stav</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</title>
		<meeting>the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="204" to="209" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06018</idno>
		<title level="m">Segmental recurrent neural networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A tweet dataset annotated for named entity recognition and stance detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>K???k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fazli</forename><surname>Can</surname></persName>
		</author>
		<idno>abs/1901.04787</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno>abs/1603.01360</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">ACE (automatic content extraction) english annotation guidelines for entities version 6</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ldc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1360</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3219" to="3232" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">End-toend sequence labeling via bi-directional lstmcnns-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<idno>abs/1603.01354</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recall-oriented learning of named entities in Arabic Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Behrang</forename><surname>Mohit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishav</forename><surname>Bhowmick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kemal</forename><surname>Oflazer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="162" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Joint transition-based models for morpho-syntactic parsing: Parsing strategies for MRLs and a case study from modern Hebrew</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>More</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Seker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victoria</forename><surname>Basmova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00253</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="33" to="48" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The CoNLL 2007 shared task on dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>K?bler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deniz</forename><surname>Yuret</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)</title>
		<meeting>the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="915" to="932" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/D14-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Doha, Qatar</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning part-of-speech taggers with inter-annotator agreement loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>S?gaard</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/E14-1078</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 14th Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="742" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">CoNLL-2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint Conference on EMNLP and CoNLL -Shared Task</title>
		<meeting><address><addrLine>Jeju Island, Korea</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bioinfer: a corpus for information extraction in the biomedical domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sampo</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Heimonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jari</forename><surname>Bj?rne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorma</forename><surname>Boberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jouni</forename><surname>J?rvinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tapio</forename><surname>Salakoski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC bioinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">50</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009)</title>
		<meeting>the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009)<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Optimal hyperparameters for deep lstm-networks for sequence labeling tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno>abs/1707.06799</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Overview of the SPMRL 2013 shared task: A cross-framework evaluation of parsing morphologically rich languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djam?</forename><surname>Seddah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>K?bler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Candito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinho</forename><forename type="middle">D</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich?rd</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iakes</forename><surname>Goenaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Koldo Gojenola Galletebeitia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spence</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Habash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Kuhlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Przepi?rkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Seeker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronika</forename><surname>Versley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Vincze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alina</forename><surname>Woli?ski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Wr?blewska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clergerie</forename><surname>Villemonte De La</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages</title>
		<meeting>the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="146" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A graph-based lattice dependency parser for joint morphological segmentation and syntactic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Seeker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?zlem</forename><surname>?etinoglu</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00144</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="359" to="373" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A pointer network architecture for joint morphological segmentation and tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Seker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.391</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4368" to="4378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Universal word segmentation: Implementation and interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Hardmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00033</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="421" to="435" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Character-based joint segmentation and POS tagging for Chinese using bidirectional RNN-CRF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Hardmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rg</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Nivre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="173" to="183" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Building a tree-bank of modern hebrew text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalil</forename><surname>Sima&amp;apos;an</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alon</forename><surname>Itai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoad</forename><surname>Winter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>Alon Altman, and Noa Nativ</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Comparison of named entity recognition methodologies in biomedical documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hye-Jeong</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byeong-Cheol</forename><surname>Jo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chan-Young</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong-Dae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Seop</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12938-018-0573-6</idno>
	</analytic>
	<monogr>
		<title level="j">Biomedical engineering online</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">158</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tjong Kim</forename><surname>Sang</surname></persName>
		</author>
		<idno type="DOI">10.3115/1119176.1119195</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</title>
		<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL 2003<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
	<note>CONLL &apos;03. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">From SPMRL to NMRL: What did we learn (and unlearn) in a decade of parsing morphologically-rich languages (MRLs)?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Bareket</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stav</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Seker</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.660</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Online. Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7396" to="7408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">What&apos;s wrong with Hebrew NLP? and how to make it right</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoval</forename><surname>Sadde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stav</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Seker</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-3044</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="259" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Statistical parsing of morphologically rich languages (SPMRL) what, how and whither</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reut</forename><surname>Tsarfaty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Djam?</forename><surname>Seddah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandra</forename><surname>Kuebler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannick</forename><surname>Versley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie</forename><surname>Candito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ines</forename><surname>Rehbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lamia</forename><surname>Tounsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages</title>
		<meeting>the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages<address><addrLine>Los Angeles, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A statistical information extraction system for turkish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?khan</forename><surname>T?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilek</forename><surname>Hakkani-T?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kemal</forename><surname>Oflazer</surname></persName>
		</author>
		<idno type="DOI">10.1017/S135132490200284X</idno>
	</analytic>
	<monogr>
		<title level="j">Nat. Lang. Eng</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="181" to="210" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">What do character-level models learn about morphology? the case of dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clara</forename><surname>Vania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Grivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lopez</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1278</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2573" to="2583" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Kaufman</surname></persName>
		</author>
		<title level="m">Ontonotes release 5.0. Linguistic Data Consortium</title>
		<editor>Michelle Franchini, Mohammed El-Bachouti, Robert Belvin, and Ann Houston</editor>
		<meeting><address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Design challenges and misconceptions in neural sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuailong</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics (COLING)</title>
		<meeting>the 27th International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">NCRF++: An open-source neural sequence labeling toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">WebAnno: A flexible, web-based and visually supported system for distributed annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Seid Muhie Yimam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Eckart De Castilho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Named entity recognition: challenges in document annotation, gazetteer construction and disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziqi</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>University of Sheffield</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
