<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DAMSL: Domain Agnostic Meta Score-based Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Cai</surname></persName>
							<email>jjcai@alumni.princeton.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><surname>Cai</surname></persName>
							<email>billcai@alum.mit.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><forename type="middle">Sheng</forename><surname>Mei</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Pensees Pte Ltd</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DAMSL: Domain Agnostic Meta Score-based Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose Domain Agnostic Meta Scorebased Learning (DAMSL), a novel, versatile and highly effective solution that delivers significant out-performance over state-of-the-art methods for cross-domain few-shot learning. We identify key problems in previous metalearning methods over-fitting to the source domain, and previous transfer-learning methods under-utilizing the structure of the support set. The core idea behind our method is that instead of directly using the scores from a fine-tuned feature encoder, we use these scores to create input coordinates for a domain agnostic metric space. A graph neural network is applied to learn an embedding and relation function over these coordinates to process all information contained in the score distribution of the support set. We test our model on both established CD-FSL benchmarks and new domains and show that our method overcomes the limitations of previous meta-learning and transfer-learning methods to deliver substantial improvements in accuracy across both smaller and larger domain shifts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Few-shot learning methods promise to solve one of the most challenging issues in deep learning: the reliance on copious amounts of labelled examples to achieve high accuracies. By doing so, we can achieve cost savings and accurately classify rare classes of images (e.g. plane crashes) where labelled examples are limited. The problem, however, is that few-shot learning methods fail to perform well when there is a domain-shift. Hence, the practical applications of few-shot learning are severely limited as the fewshot models trained on well-labelled and well-structured research datasets cannot be applied to domains in industry.</p><p>The above problem is exacerbated under sharp domain shifts, as shown in the Broader Study of Cross-Domain Few-Shot Learning (BSCD-FSL) <ref type="bibr" target="#b6">[7]</ref>. The study found that many few-shot learning methods significantly underperformed compared to transfer-learning as few-shot learning overfitted to the source domain. While transfer-learning methods did perform better, they omitted distributional information contained in the each episode's support set is omitted. This is clearly sub-optimal given the need to maximally use information in the sparse setting <ref type="bibr" target="#b19">[20]</ref>  <ref type="bibr" target="#b16">[17]</ref>.</p><p>To solve the above issues, we propose Domain Agnostic Meta Score-based Learning (DAMSL). The fundamental idea behind our method is to apply transfer-learning to prevent over-fitting to the source domain, while using metriclearning to exploit the information in each episode's support samples. Furthermore, as metric-learners built on image features are shown to suffer greatly from overfitting to the source domain, we make our metric-learner domainagnostic by fitting to pre-softmax classification scores from fine-tuned feature encoders.</p><p>In our work, we use the BSCD-FSL benchmark <ref type="bibr" target="#b6">[7]</ref> and augment it with 4 more test domains for further comparisons. We demonstrate the superiority of our method over existing methods across these 8 distinct test domains, and show a new research direction for score-based boosting in the few-shot classification setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Relevant Work</head><p>Metric-based methods, such as prototypical networks <ref type="bibr" target="#b15">[16]</ref>, aim to learn a metric function ? m that can be used to classify query images based on their relations to the images in the support set. The key metric-based method that we use is Graph Neural Network (GNN) as graph-based convolutions can create more flexible representations <ref type="bibr" target="#b0">[1]</ref>.</p><p>Transfer learning involves reusing features learned from base classes <ref type="bibr" target="#b13">[14]</ref>, typically by fine-tuning a pre-trained model. A simple extension of fine-tuning would be to learn to fine-tune. Methods such as MAML <ref type="bibr" target="#b3">[4]</ref> learn an internal representation that can be fine-tuned in a few gradient steps. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head><p>The training process during each episode for our model is shown in <ref type="figure" target="#fig_0">Figure 1</ref>. On test domains, the same fine-tuning process occurs over the labelled support set, but with gradient updates only within episodes and not between episodes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Score-based Metric Learning</head><p>Given only a sparse support set from the test domain, it is difficult to precisely fit the feature encoder in a way that neither overfits nor underfits <ref type="bibr" target="#b11">[12]</ref>. Creating a hold-out validation set is also prohibitively costly under such conditions.</p><p>We begin by fine-tuning a feature vector to obtai? ? f (X s ) ? R 512 . Then, we take the linear classifier? c to produce a pre-softmax score vector? c (? f (X i )) ? R 5 , which corresponds to our 5-way classification problem. A typical transfer-learning approach would directly use the score vector for prediction? q = arg max(? c (? f (X q )) Instead, we post-process the score vector by using a metric-learning network ? m . Formally, this gives us:</p><formula xml:id="formula_0">? q = arg max(? m (Y s ,? c (? f (X q )),? c (? f (X s )))</formula><p>) Thus, we explicitly incorporate information contained in the predictions we can make on the support sets X s and how these predictions correspond to the labels Y s . Any biases found in the feature encoder? f and linear classifier? c can be corrected by inferring a distribution from the support set scores, and using that distribution to match the scores of our query samples. This reduces the reliance on the initial fine-tuning process as our decision boundaries from the initial feature encoder are replaced by a metric-based decision boundary constructed from the proximity of the query sample to the support classes. Moreover, the scores form a domain agnostic basis for metric learning because the way that scores relate should not differ significantly across domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Graph Neural Network</head><p>The meta-learning module we use is the Graph Neural Network (GNN). We follow the formulation of the GNN for the few-shot problem in <ref type="bibr" target="#b14">[15]</ref>. In brief, a GNN acts on local operators of a graph G = (V, E), which for the fewshot learning case is fully connected. A graph convolution layer GC(.) <ref type="bibr" target="#b14">[15]</ref> is performed with linear operations on local signals. Formally, we have:</p><formula xml:id="formula_1">GC(S k ) = f B?A BS k ? k B,q , q = d 1 , ..., d k+1 (1)</formula><p>In the few-shot learning formulation, we can learn the edfe features using the current hidden vertex <ref type="bibr" target="#b14">[15]</ref>. We apply a Multi-layer Perceptron (MLP) that takes in the absolute difference between the the output vectors of vertices in the graph <ref type="bibr" target="#b8">[9]</ref>  <ref type="bibr" target="#b4">[5]</ref>. Formally, we have:</p><formula xml:id="formula_2">A k i,j = ?(S k i , S k j ) = M LP (|S k i ? S k j |)<label>(2)</label></formula><p>These learned edge features are used to propagate information in the graph through the graph convolution in equation 1. Initial vertex features are constructed by taking the score projections and one-hot encoding of labels for the support set or a uniform distribution for the query samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Backbone Variants</head><p>We experiment with two variants of the DAMSL model with different feature backbones. In DAMSL v1, we have a ResNet10 pre-trained using supervised learning and firstorder MAML <ref type="bibr" target="#b12">[13]</ref> In DAMSL v2, we have two ResNet10 pre-trained using supervised learning but with different optimization strategies -one trained using Adam while other trained using SGD with momentum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EuroSAT</head><p>CropDisease 27.55% ? 0.44% 35.37% ? 0.57% 41.56% ? 0.56% 50.98% ? 0.65% 63.58% ? 0.61% 71.47% ? 0.54% DAMSL v1 (Aug) 28.08% ? 0.50% 37.70% ? 0.57% 43.04% ? 0.66% 53.50% ? 0.79% 70.31% ? 0.72% 78.41% ? 0.66% L-Ensem v2 (Aug) 28.26% ? 0.46%</p><p>35.91% ? 0.52% 41.00% ? 0.57% 52.76% ? 0.62% 64.99% ? 0.59% 71.92% ? 0.55% DAMSL v2 (Aug) 28.86% ? 0.52% 37.04% ? 0.61% 42.87% ? 0.65% 57.15% ? 0.76% 70.87% ? 0.72% 78.98% ? 0.62% -as reported in <ref type="bibr" target="#b6">[7]</ref>. Aug -with data augmentation during fine-tuning. Bold -Best performing in category. <ref type="table">Table 1</ref>. Results on BSCD-FSL Benchmark. Includes ablation studies and results from prior work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Setup</head><p>First, we test our model on the BSCD-FSL benchmark. We train on miniImagenet and test on CropDisease <ref type="bibr" target="#b10">[11]</ref>, EuroSAT <ref type="bibr" target="#b7">[8]</ref>, ISIC <ref type="bibr" target="#b17">[18]</ref>  <ref type="bibr" target="#b2">[3]</ref> and ChestX <ref type="bibr" target="#b18">[19]</ref> (in order of decreasing similarity). CropDisease covers plant disease, EuroSAT covers satellite images, ISIC covers dermoscopic skin lesion images and ChestX covers chest X-ray images.</p><p>4 other new datasets are also included: Places <ref type="bibr" target="#b20">[21]</ref>, Describable Textures Dataset (DTD) <ref type="bibr" target="#b1">[2]</ref>, CIFAR-100 <ref type="bibr" target="#b9">[10]</ref> and Caltech256 <ref type="bibr" target="#b5">[6]</ref>. While the images in these other datasets are all natural images, they contain very different types of classification tasks from miniImagenet. For instance, DTD requires the model to recognize textures in many contexts <ref type="bibr" target="#b1">[2]</ref>. The Github repo can be found here: Github link.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results on the BS-CDFSL Benchmark</head><p>From <ref type="table">Table 1</ref>, DAMSL with both feature backbones outperform previous methods, even without using data augmentation. We see that DAMSL v1 achieves an average accuracy of 72.13% while DAMSL v2 achieves an average accuracy of 74.34%. With data augmentation, DAMSL v1 (Aug) achieves an average accuracy of 74.06% while DAMSL v2 (Aug) achieves an average accuracy of 74.99%.</p><p>We focus on DAMSL v2 in our comparison with other methods as it has the highest performance. DAMSL v2 (Aug) outperforms TransFT by 6.86% and ProtoNet by 15.21%. From <ref type="table">Table 1</ref>, we see that DAMSL (Aug) v2 still significantly outperforms TransFT (Aug), with the exception of 5-way 5-shot Chest-X. In terms of average accuracy, DAMSL v2 (Aug) outperforms TransFT (Aug) by 3.84%.</p><p>Our method is competitive with typical supervised learning on domains closer to the source domain. Typical supervised learning models for EuroSAT and CropDisease have achieved 98.57% and 99.35% respectively <ref type="bibr" target="#b7">[8]</ref>  <ref type="bibr" target="#b10">[11]</ref>. At our 50-shot results for DAMSL v2 (Aug), we achieve 98.60% and 99.87% respectively on EuroSAT and CropDisease.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Studies on BSCD-FSL</head><p>To investigate the effect of each component of separately, we include a Linear Ensemble (L-Ensem), a Fine-Tuned en-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DTD</head><p>CIFAR-100 5-way 5-shot 5-way 20-shot 5-way 50-shot 5-way 5-shot 5-way 20-shot 5-way 50-shot TransFT (Aug) 62.17% ? 0.74% 73.49% ? 0.61% 79.25% ? 0.55% 65.89% ? 0.77% 77.60% ? 0.64% 83.64% ? 0.54% L-Ensem v1 (Aug) 55.80% ? 0.73% 69.20% ? 0.69% 76.39% ? 0.59% 62.07% ? 0.77% 77.85% ? 0.61% 84.17% ? 0.51% DAMSL v1 (Aug) 58.29% ? 0.89% 77.72% ? 0.71% 85.44% ? 0.58% 67.64% ? 0.93% 86.68% ? 0.64% 93.06% ? 0.42% L-Ensem v2 (Aug) 60.01% ? 0.74% 73.73% ? 0.65% 79.99% ? 0.55% 66.01% ? 0.42% 80.67% ? 0.59% 86.23% ? 0.46% DAMSL v2 (Aug) 68.39% ? 0.89% 81.64% ? 0.68% 87.14% ? 0.68% 76.56% ? 0.85% 88.47% ? 0.57% 93.92% ? 0.39%</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Places <ref type="formula" target="#formula_2">Caltech256</ref> 5-way 5-shot 5-way 20-shot 5-way 50-shot 5-way 5-shot 5-way 20-shot 5-way 50-shot   <ref type="table">Table 1</ref>. The L-Ensem is a simple addition of the post-softmax scores from the two fine-tuned feature encoders, to see the performance from a simple fine-tuned ensemble. FT-GNN is directly fitted to a feature vector that has been fine-tuned on the support set, to demonstrate the performance boost from score-based learning. The Scorebased ProtoNets replaces the GNN module with an embedding MLP and a nearest centroid classifier, to demonstrate the additional gains from a GNN module.</p><p>Furthermore, we see that the score-based metric delivers an improvement when used in conjunction with a simple ProtoNets. On all tasks, the S-Proto delivers a better performance compared to L-Ensem. However, it still does not match up to the performance of our proposed DASML model. We attribute this to the GNN's more flexible representations, and the fact that it exploits the full distribution of scores rather than just the mean value of scores. We also demonstrate the value of score-based metric learning as FT-GNN performs substantially worse than DAMSL. This is in line with the expectation that the GNN is trained to interpret domain-specific features, and thus fails on distant domains.</p><p>Looking at average accuracy using v1, we observe that L-Ensem yields 69.23%, FT-GNN yields 69.82%, S-Proto yields 70.12%, DAMSL v1 yields 74.06%. This shows that both parts of DAMSL are most useful when jointly applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Results on other Test Domains</head><p>From <ref type="table" target="#tab_2">Table 2</ref>, we clearly see that DAMSL v2 delivers out-performance over the previous baselines across almost all settings and all shots, with the only exception of 5-shot setting for Places. In terms of average accuracy, DAMSL v1 achieves 81.48% while DAMSL v2 achieves 85.46% . These values are considerably higher (&gt; 5%) than the linear ensembles, which yields 74.31% and 77.91% respec- <ref type="figure">Figure 2</ref>. Summary of performance on BSCD-FSL tively. The results clearly validate our method as DAMSL performs better than previous methods on data-sets other than those in the BSCD-FSL benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We propose Domain Agnostic Meta Score-based Learning (DAMSL) to address the Cross-Domain Few-Shot Learning problem. On BSCD-FSL, DAMSL v2 achieves 74.99% accuracy, which significantly outperforms previous best-performing meta-learning and transfer-learning methods by 15.21% and 6.86% respectively. From <ref type="figure">Figure 2</ref>, we also see that the performance gains from our method are substantially greater than gains from including data augmentation or adding another feature encoder. Moreover, on the 4 other test domains beyond BSCD-FSL, our method continues to consistently outperform strong baselines.</p><p>Ultimately, we not only decisively address the CD-FSL problem, but we also outline a new strand of classification boosting modules that can be attached to any existing model to self-correct initial classification scores by utilizing the distributional information of scores from labelled samples.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Episodic training on miniImagenet (source domain) for our Proposed DAMSL Model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>29% ? 0.71% 82.27% ? 0.57% 80.48% ? 0.57% 79.72% ? 0.67% 88.15% ? 0.51% 90.81% ? 0.43% TransFT 81.76% ? 0.48% 87.97% ? 0.42% 92.00% ? 0.56% 90.64% ? 0.54% 95.91% ? 0.72% 97.48% ? 0.56% L-Ensem v1 74.64% ? 0.67% 85.52% ? 0.53% 90.38% ? 0.35% 84.65% ? 0.60% 94.40% ? 0.36% 96.89% ? 0.24% 84% ? 0.54% 96.13% ? 0.29% 98.15% ? 0.18% 97.30% ? 0.32% 99.36% ? 0.14% 99.73% ? 0.09% Aug) 91.59% ? 0.49% 96.99% ? 0.24% 98.60% ? 0.15% 97.43% ? 0.31% 99.61% ? 0.10% 99.87% ? 0.05%</figDesc><table><row><cell></cell><cell>5-way 5-shot</cell><cell>5-way 20-shot</cell><cell>5-way 50-shot</cell><cell>5-way 5-shot</cell><cell>5-way 20-shot</cell><cell>5-way 50-shot</cell></row><row><cell cols="2">ProtoNet 73.DAMSL v1 85.93% ? 0.68%</cell><cell>95.18% ? 0.35%</cell><cell>97.73% ? 0.25%</cell><cell>95.03% ? 0.42%</cell><cell>99.19% ? 0.14%</cell><cell>99.75% ? 0.08%</cell></row><row><cell>L-Ensem v2</cell><cell>81.02% ? 0.62%</cell><cell>90.01% ? 0.37%</cell><cell>93.28% ? 0.30%</cell><cell>90.68% ? 0.51%</cell><cell>97.20% ? 0.26%</cell><cell>98.89% ? 0.16%</cell></row><row><cell cols="2">DAMSL v2 90.TransFT (Aug) 82.80% ? 0.60%</cell><cell>90.38% ? 0.67%</cell><cell>93.48% ? 0.57%</cell><cell>92.51% ? 0.84%</cell><cell>97.33% ? 0.43%</cell><cell>98.40% ? 0.41%</cell></row><row><cell cols="2">L-Ensem v1 (Aug) 77.98% ? 0.66%</cell><cell>89.43% ? 0.39%</cell><cell>93.56% ? 0.31%</cell><cell>88.84% ? 0.54%</cell><cell>97.11% ? 0.23%</cell><cell>98.83% ? 0.18%</cell></row><row><cell cols="2">FT-GNN v1 (Aug) 82.29% ? 0.63%</cell><cell>92.73% ? 0.63%</cell><cell>93.78% ? 0.63%</cell><cell>94.09% ? 0.46%</cell><cell>98.31% ? 0.35%</cell><cell>98.95% ? 0.25%</cell></row><row><cell>S-Proto v1 (Aug)</cell><cell>80.32% ? 0.58%</cell><cell>89.52% ? 0.40%</cell><cell>93.39% ? 0.27%</cell><cell>91.43% ? 0.47%</cell><cell>97.53% ? 0.37%</cell><cell>98.79% ? 0.26%</cell></row><row><cell cols="2">DAMSL v1 (Aug) 87.30% ? 0.68%</cell><cell>96.53% ? 0.28%</cell><cell>98.37% ? 0.18%</cell><cell cols="3">96.01% ? 0.40% 99.61% ? 0.09% 99.85% ? 0.06%</cell></row><row><cell cols="2">L-Ensem v2 (Aug) 83.68% ? 0.54%</cell><cell>91.61% ? 0.34%</cell><cell>94.75% ? 0.25%</cell><cell>92.66% ? 0.45%</cell><cell>98.08% ? 0.20%</cell><cell>99.14% ? 0.11%</cell></row><row><cell>DAMSL v2 (Methods</cell><cell></cell><cell>ChestX</cell><cell></cell><cell></cell><cell>ISIC</cell><cell></cell></row><row><cell></cell><cell>5-way 5-shot</cell><cell>5-way 20-shot</cell><cell>5-way 50-shot</cell><cell>5-way 5-shot</cell><cell>5-way 20-shot</cell><cell>5-way 50-shot</cell></row><row><cell>ProtoNet</cell><cell>24.05% ? 1.01%</cell><cell>28.21% ? 1.15%</cell><cell>29.32% ? 1.12%</cell><cell>39.57% ? 0.57%</cell><cell>49.50% ? 0.55%</cell><cell>51.99% ? 0.52%</cell></row><row><cell>TransFT</cell><cell>26.09% ? 0.96%</cell><cell>31.01% ? 0.59%</cell><cell>36.79% ? 0.53%</cell><cell>49.68% ? 0.36%</cell><cell>61.09% ? 0.44%</cell><cell>67.20% ? 0.59%</cell></row><row><cell>L-Ensem v1</cell><cell>25.20% ? 0.43%</cell><cell>30.62% ? 0.45%</cell><cell>35.82% ? 0.47%</cell><cell>46.55% ? 0.61%</cell><cell>59.14% ? 0.61%</cell><cell>65.35% ? 0.59%</cell></row><row><cell>DAMSL v1</cell><cell>25.99% ? 0.50%</cell><cell>33.47% ? 0.54%</cell><cell>38.37% ? 0.56%</cell><cell>50.68% ? 0.76%</cell><cell>68.58% ? 0.70%</cell><cell>75.55% ? 0.58%</cell></row><row><cell>L-Ensem v2</cell><cell>26.38% ? 0.45%</cell><cell>33.46% ? 0.51%</cell><cell>39.81% ? 0.53%</cell><cell>51.93% ? 0.62%</cell><cell>64.21% ? 0.60%</cell><cell>70.28% ? 0.57%</cell></row><row><cell>DAMSL v2</cell><cell cols="6">27.22% ? 0.49% 35.41% ? 0.56% 42.74% ? 0.62% 57.35% ? 0.78% 70.32% ? 0.70% 77.40% ? 0.65%</cell></row><row><cell>TransFT (Aug)</cell><cell cols="2">29.23% ? 0.46% 36.25% ? 0.55%</cell><cell>40.69% ? 0.56%</cell><cell>51.54% ? 0.64%</cell><cell>62.72% ? 0.62%</cell><cell>69.68% ? 0.59%</cell></row><row><cell cols="2">L-Ensem v1 (Aug) 26.84% ? 0.44%</cell><cell>34.62% ? 0.48%</cell><cell>40.23% ? 0.56%</cell><cell>48.97% ? 0.65%</cell><cell>62.99% ? 0.60%</cell><cell>70.32% ? 0.57%</cell></row><row><cell cols="2">FT-GNN v1 (Aug) 26.79% ? 0.50%</cell><cell>35.39% ? 0.60%</cell><cell>35.34% ? 0.54%</cell><cell>52.13% ? 0.84%</cell><cell>65.37% ? 0.73%</cell><cell>62.68% ? 0.65%</cell></row><row><cell>S-Proto v1 (Aug)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Aug) 75.42% ? 0.80% 84.74% ? 0.60% 90.43% ? 0.51% 87.44% ? 0.70% 94.53% ? 0.36% 96.89% ? 0.24% Aug -with data augmentation during fine-tuning. Bold -Best performing in category.</figDesc><table><row><cell>TransFT (Aug)</cell><cell>67.50% ? 0.75%</cell><cell>76.17% ? 0.67%</cell><cell>80.98% ? 0.57%</cell><cell>75.32% ? 0.70%</cell><cell>84.15% ? 0.58%</cell><cell>88.37% ? 0.47%</cell></row><row><cell cols="2">L-Ensem v1 (Aug) 70.78% ? 0.92%</cell><cell>74.45% ? 0.65%</cell><cell>79.85% ? 0.57%</cell><cell>70.32% ? 0.72%</cell><cell>83.20% ? 0.55%</cell><cell>87.59% ? 0.48%</cell></row><row><cell cols="2">DAMSL v1 (Aug) 71.34% ? 0.85%</cell><cell>84.30% ? 0.67%</cell><cell>89.50% ? 0.55%</cell><cell>76.63% ? 0.87%</cell><cell>91.44% ? 0.49%</cell><cell>95.06% ? 0.37%</cell></row><row><cell cols="3">L-Ensem v2 (Aug) 75.45% ? 0.80% 75.87% ? 0.65%</cell><cell>82.13% ? 0.53%</cell><cell>76.31% ? 0.68%</cell><cell>87.59% ? 0.44%</cell><cell>90.93% ? 0.35%</cell></row><row><cell>DAMSL v2 (</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc></figDesc><table><row><cell>Results on Additional Test Domains</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Geometric deep learning: going beyond euclidean data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="18" to="42" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Describing textures in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mircea</forename><surname>Cimpoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sammy</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3606" to="3613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Skin lesion analysis toward melanoma detection 2018: A challenge hosted by the international skin imaging collaboration (isic)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronica</forename><surname>Rotemberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emre</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Dusza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gutman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Helba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aadi</forename><surname>Kalloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Liopyris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Marchetti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.03368</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural message passing for quantum chemistry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Gilmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schoenholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Riley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">E</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Caltech-256 object category dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Holub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Tajana Rosing, and Rogerio Feris. A broader study of cross-domain few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhui</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Karlinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ECCV</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Helber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Bischke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Dengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damian</forename><surname>Borth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2217" to="2226" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Molecular graph convolutions: moving beyond fingerprints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mccloskey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Berndl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Pande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Riley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computer-aided molecular design</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="595" to="608" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Using deep learning for image-based plant disease detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sharada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohanty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salath?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in plant science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1419</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Revisiting fine-tuning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiro</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatsuya</forename><surname>Harada</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.00216</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">On first-order meta-learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garcia</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><forename type="middle">Bruna</forename><surname>Satorras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Estrach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4077" to="4087" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Few-shot learning through an information retrieval lens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2252" to="2262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The ham10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Rosendahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">180161</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaosong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadhadi</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2097" to="2106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Variational few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1685" to="1694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="1452" to="1464" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
