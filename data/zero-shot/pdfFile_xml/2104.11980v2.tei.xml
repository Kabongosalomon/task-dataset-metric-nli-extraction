<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">baller2vec++: A Look-Ahead Multi-Entity Transformer For Modeling Coordinated Agents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Alcorn</surname></persName>
							<email>alcorma@auburn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Software Engineering</orgName>
								<orgName type="institution">Auburn University Auburn</orgName>
								<address>
									<postCode>36849</postCode>
									<region>AL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anh</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Software Engineering Auburn University Auburn</orgName>
								<address>
									<postCode>36849</postCode>
									<region>AL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">baller2vec++: A Look-Ahead Multi-Entity Transformer For Modeling Coordinated Agents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In many multi-agent spatiotemporal systems, agents operate under the influence of shared, unobserved variables (e.g., the play a team is executing in a game of basketball). As a result, the trajectories of the agents are often statistically dependent at any given time step; however, almost universally, multi-agent models implicitly assume the agents' trajectories are statistically independent at each time step. In this paper, we introduce baller2vec++ 1 , a multi-entity Transformer that can effectively model coordinated agents. Specifically, baller2vec++ applies a specially designed self-attention mask to a mixture of location and "look-ahead" trajectory sequences to learn the distributions of statistically dependent agent trajectories. We show that, unlike baller2vec (baller2vec++'s predecessor), baller2vec++ can learn to emulate the behavior of perfectly coordinated agents in a simulated toy dataset. Additionally, when modeling the trajectories of professional basketball players, baller2vec++ outperforms baller2vec by a wide margin.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction and Related Work</head><p>Whether it is a team executing a play in a game of basketball, a family navigating to an attraction in a theme park, or friends posting about a birthday party on a social media platform, humans frequently coordinate their behavior in response to shared information. When this coordinating information is unobserved (which is often the case in many machine learning datasets), the individuals' observed behaviors become correlated, i.e., the behavior of one individual at a specific moment contains information about the behavior of another individual at the same time. In the context of modeling agent trajectories in multi-agent spatiotemporal systems, this property translates to the trajectories being statistically dependent at each time step. However, nearly all multi-agent spatiotemporal models (e.g., <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>) implicitly (through their loss functions) assume the trajectories of the agents at each time step are statistically independent given the agents' previous locations <ref type="figure">(Figure 1</ref>).</p><p>Zhan et al. <ref type="bibr" target="#b6">[7]</ref> explicitly focused on modeling coordinated multi-agent trajectories, using "macro-intents" <ref type="bibr" target="#b7">[8]</ref> that are shared across agents to do so. <ref type="figure">Figure 1</ref>: Left: most multi-agent systems implicitly assume the trajectories of the agents at each time step (?x t,k ) are conditionally independent given the agents' previous locations (x 1:t,k ). Right: however, the various decompositions of the joint probability of the trajectories, e.g., p(?x t,1 )p(?x t,2 |?x t,1 )p(?x t,3 |?x t,1 ?x t,2 ) (note, we omit the conditional x 1:t,k terms for brevity), suggest more complex statistical dependencies between the agents' trajectories can exist (i.e., the independence assumption is an extremely strong one). Indeed, there are often shared unobserved variables influencing the spatiotemporal behaviors of agents-such as the play that the players on a basketball team are executing, or events occurring in a pedestrian environment-which suggests statistical dependencies between the agents' trajectories are likely.</p><p>The macro-intents are generated from a separately trained recurrent neural network (RNN) that learns to predict a future, coarse, "stationary" location for each agent at each time step. The macro-intents for all of the agents at a specific time step are concatenated together to form a single, shared, macrointent variable, which is then provided as input to the trajectories-generating model at that time step. However, similar to the previously mentioned multiagent trajectory models, the macrointents model implicitly assumes the macro-intents for the agents at each time step are statistically independent, i.e., the macro-intent for one agent does not depend on the macro-intents of the other agents. <ref type="bibr" target="#b1">2</ref> Further, the trajectories-generating model still implicitly assumes the trajectories of the agents at each time step are independent, which is only true if the shared macro-intent variable perfectly captures all of the unobserved information that could cause the agents' trajectories to be correlated.</p><p>Notably, Social-BiGAT <ref type="bibr" target="#b8">[9]</ref> does partially account for trajectory correlations through a global adversarial loss. Specifically, the trajectories for each agent are separately passed through an encoder RNN, and the final hidden states for each agent are then processed with a graph attention network (GAT) <ref type="bibr" target="#b9">[10]</ref>. The output of the GAT is then used as an input to a discriminator that classifies whether or not the input trajectories are real or generated. This global adversarial loss, however, is only a single component of the full Social-BiGAT loss function, and other components of the loss function do implicitly make the independence assumption. Further, interestingly, adding the global discriminator to a baseline model only improved the model's performance for one out of six pedestrian datasets.</p><p>In this paper, we describe a novel multi-agent spatiotemporal model that integrates information about concurrent actions of agents to predict statistically dependent distributions of trajectories. Specifically, we extend the recently introduced multi-entity Transformer baller2vec <ref type="bibr" target="#b5">[6]</ref> by: (1) augmenting its input with a parallel sequence of "look-ahead" agent trajectories and (2) using a specially designed self-attention mask, which allows our model to exploit the chain rule of probability (Section 3). We find that:</p><p>1. baller2vec++ is an effective learning algorithm for modeling coordinated agents. Unlike baller2vec, baller2vec++ can learn to emulate perfectly coordinated agents from a simulated toy dataset (Section 5.1). Further, baller2vec++ outperforms baller2vec by a wide margin (8.9%) when modeling the trajectories of professional basketball players (Section 5.1).</p><p>2. baller2vec++ makes better predictions when conditioned on concurrent trajectory information from other agents, supporting our proposition that the commonly used independence assumption for agent trajectories is overly strong (Section 5.2). <ref type="bibr" target="#b1">2</ref> See the authors' implementation here: https://github.com/ezhan94/ multiagent-programmatic-supervision/blob/a1d9152d4c8a287474953cba093c28fef2a05979/ models/macro_vrnn.py#L101.</p><p>3. Lastly, the joint probability assigned to a sequence by baller2vec++ is approximately permutation invariant with respect to the order of the agents, i.e., baller2vec++ respects the properties of the chain rule (Section 5.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Multi-agent trajectory modelling</head><p>Our problem description closely follows Alcorn and Nguyen <ref type="bibr" target="#b5">[6]</ref>, whom we quote here:</p><p>Let A = {1, 2, . . . , B} be a set indexing B agents and P = {p 1 , p 2 , . . . , p K } ? A be the K agents involved in a particular sequence.</p><p>[Let] C t = {(x t,1 , y t,1 ), (x t,2 , y t,2 ), . . . , (x t,K , y t,K )} [be] an unordered set of K coordinate pairs such that (x t,k , y t,k ) are the coordinates for agent p k at time step t. The ordered sequence of sets of coordinates C = (C 1 , C 2 , . . . , C T ), together with P , thus defines the trajectories for the K agents over T time steps.</p><p>In multi-agent trajectory modeling, the goal is to model a joint probability of the form: p(?x t,1 , ?x t,2 , . . . , ?x t,K |x 1:t,1 , x 1:t,2 , . . . , x 1:t,K )</p><p>i.e., the joint probability of the K agents' trajectories ?x t,k at time step t given the agents' location histories x 1:t,k . We note here that the common practice of simultaneously predicting the trajectories for all of the agents at a specific time step is not required by theory. Using the chain rule of probability, the joint probability of the agents' trajectories can be factorized as, e.g.:</p><formula xml:id="formula_0">p(?x t,1 , ?x t,2 , . . . , ?x t,K ) = p(?x t,1 )p(?x t,2 |?x t,1 ) . . . p(?x t,K |?x t,1 , ?x t,2 , . . . , ?x t,K?1 )</formula><p>where we omit the conditional historical trajectories for brevity. As a result, it is perfectly acceptable to generate trajectories agent-wise, using the previously generated trajectories as additional conditioning information when generating the trajectories for later agents (see <ref type="figure">Figure 2</ref>). <ref type="figure">Figure 2</ref>: At inference time, a model is not required to simultaneously generate the trajectories for all of the agents at a specific time step. An alternative strategy is to allow the model to generate the agents' trajectories one at a time, and let the model use the previously generated trajectories to inform the trajectories it generates for the remaining agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">baller2vec is a (conditional) generative model.</head><p>baller2vec is a recently described multi-entity Transformer that can model sequences of sets (the underlying data structure for multi-agent spatiotemporal systems), as opposed to sequences of individual inputs (like words in a sentence). When used to model the game of basketball, the input at each time step for baller2vec is a set of feature vectors where each feature vector contains information about the identity and location of a player on the court. baller2vec maps each input feature vector to an output feature vector, which is then used to "classify" the binned trajectory for that specific player at that specific time step.</p><p>Here, we provide a probabilistic interpretation of baller2vec, which establishes the theoretical grounds for using the chain rule to generate trajectories agent-wise at each time step in baller2vec++. Without loss of generality, we only consider one-dimensional trajectories for a single agent here. To briefly summarize, the outputs of the softmax function over the n binned trajectories in baller2vec can be interpreted as mixture proportions for a mixture of uniform distributions with predetermined bounds that partition the Euclidean trajectory space. Further, because x t+1 = x t + ?x t , baller2vec is in fact a conditional generative model that assigns a probability to a sequence of trajectories given the initial position of the agent, i.e., p(?x 1 , ?x 2 , . . . , ?x T |x 1 ). Using the chain rule, we decompose the joint probability of the trajectories as:</p><formula xml:id="formula_1">p(?x 1 , ?x 2 , . . . , ?x T ) = p(?x 1 )p(?x 2 |?x 1 ) . . . p(?x T |?x 1 , ?x 2 , . . . , ?x T ?1 )</formula><p>to reflect their temporal structure (we omit the conditional initial position term for brevity). Therefore, new trajectories can be generated from baller2vec with the following procedure (see <ref type="figure">Figure 3</ref>):</p><p>1. First, sample one of the n different mixture components using the mixture proportions output from the classifier f (i.e., baller2vec) conditioned on the agent's current position, i.e., i ? Categorical(? 1 , ? 2 , . . . , ? n ) where [? 1 , ? 2 , . . . , ? n ] = f (x t ).</p><p>2. Next, sample a trajectory from the uniform distribution associated with the sampled component, i.e., ?x t ? U(a i , b i ).</p><p>3. Finally, add the sampled trajectory to the agent's input position to generate the agent's position at the start of the next time step, i.e., x t+1 = x t + ?x t . <ref type="figure">Figure 3</ref>: baller2vec can be viewed as a conditional generative model that assigns a probability to a sequence of trajectories given the initial positions of the agents. Here, we show a graphical model depiction of a baller2vec model that generates a sequence of one-dimensional trajectories for a single agent. Given the initial position of the agent (the circle containing x 1 ), one of n different uniform distributions (the square containing i 1 ) is sampled using the mixture proportions (? i ) output by baller2vec (f ). The agent's trajectory (the diamond containing ?x 1 ) is then sampled from the selected uniform distribution, which has bounds ?? &lt; a i &lt; b i &lt; ?. At the start of the next time step, the agent's position is</p><formula xml:id="formula_2">x 2 = x 1 + ?x 1 .</formula><p>Maximizing the likelihood of baller2vec as a classifier over the binned trajectories is thus equivalent to maximizing its likelihood when assuming the trajectories are generated from a mixture of uniform distributions that partition the Euclidean trajectory space (see Section 2.2 for details).</p><p>Let [?x min , ?x max ) be an interval on the real line such that any trajectory ?x &lt; ?x min or ?x ? ?x max has zero density (i.e., such trajectories are humanly impossible). Let</p><formula xml:id="formula_3">{[a i , b i )} n i=1 be a set of n intervals that parti- tion the interval [?x min , ?x max ) into n bins, i.e., ? n i=1 [a i , b i ) = [?x min , ?x max ) and i = j =? [a i , b i ) ? [a j , b j ) = ?.</formula><p>Recall that the probability density function (PDF) for a uniform distribution with bounds ?? &lt; a &lt; b &lt; ? is:</p><formula xml:id="formula_4">p(?x) = 1 b?a for ?x ? [a, b) 0 otherwise</formula><p>Letting c i = 1 bi?ai , the PDF for a mixture of uniforms with these bounds is thus:</p><formula xml:id="formula_5">p(?x) = n i=1 ? i U(?x; a i , b i ) = n i=1 ? i c i (1)</formula><p>where p(?x) is the density assigned to ?x by the mixture, ? i is the mixture proportion for the mixture component indexed by i (i.e., 0 ? ? i ? 1 and ? i = 1), and U(?x; a i , b i ) is the density assigned to ?x by the uniform dis-</p><formula xml:id="formula_6">tribution with bounds ?? &lt; a i &lt; b i &lt; ?.</formula><p>Because the bounds of the uniform distributions partition [?x min , ?x max ), Equation (1) reduces to:</p><formula xml:id="formula_7">p(?x) = ? i c i where ?x ? [a i , b i ) (because</formula><p>the other uniform distributions will assign a density of zero to ?x). The likelihood for data D (with |D| = N ) is then:</p><formula xml:id="formula_8">L(D) = N j=1 p(?x j ) = N j=1 ? j,i c j,i</formula><p>where ? j,i is the mixture proportion assigned to the component with ?x j ? [a i , b i ) and c j,i is the associated density. Taking the negative logarithm of the likelihood gives:</p><formula xml:id="formula_9">? ln(L(D)) = ? N j=1 ln(? j,i ) ? N j=1 ln(c j,i )<label>(2)</label></formula><p>Because the bounds are fixed, the second summation is a constant, and Equation <ref type="formula" target="#formula_9">(2)</ref>   <ref type="figure">Figure 4</ref>: A naive strategy for learning to predict statistically dependent agent trajectories is to adapt the baller2vec self-attention mask so that baller2vec can "look ahead" at future positions of agents whose trajectories are generated prior to the agent being processed in the current time step. However, this look-ahead self-attention mask cannot be used with multi-layer Transformers because doing so necessitates "seeing the future". For example, after the model attends to the blue agent's position at time step t + 1 when processing the yellow agent at time step t, the yellow agent's resultant feature vector contains information about the blue agent's future position. As a result, when the model attends to the yellow agent while processing the blue agent at the next level, the model is seeing the future.</p><p>We motivate our baller2vec++ architecture by first highlighting an issue that arises in baller2vec when trying to model agent trajectories using the chain rule. The baller2vec self-attention mask can be adapted so that baller2vec "looks ahead" at the future positions of agents whose trajectories are generated prior to the agent being processed in the current time step <ref type="figure">(Figure 4</ref>). However, this look-ahead self-attention mask can only be used with the final layer of the Transformer; otherwise, the model needs to see the future ( <ref type="figure">Figure 4)</ref>. As a result, baller2vec is severely limited in the conditional distribution functions it can learn. baller2vec++ ( <ref type="figure">Figure 5</ref>) overcomes this limitation by: (1) augmenting the baller2vec input with two other sets of feature vectors and (2) using a specially designed self-attention mask. The three sets of feature vectors in baller2vec++ take the following forms: <ref type="figure">Figure 5</ref>: To learn statistically dependent agent trajectories, baller2vec++ uses a specially designed self-attention mask to simultaneously process three different sets of features vectors in a single Transformer. The three sets of feature vectors consist of location feature vectors like those found in baller2vec (z t,k ), look-ahead trajectory feature vectors (u t,k ), and starting location feature vectors (r k ; not shown). As can be seen in these partial depictions of baller2vec++ and the baller2vec++ self-attention mask, this design allows the model to integrate information about concurrent agent trajectories through multiple Transformer layers without seeing the future.</p><formula xml:id="formula_10">1. z t,k = g z ([e(p k ), x t,k , y t,k , h t,k ]) (current location information) 2. u t,k = g u ([e(p k ), x t+1,k , y t+1,k , h t,k , ?x t,k , ?y t,k ]) ("look-ahead" information) 3. r k = g r ([e(p k ), x 1,k , y 1,k , h 1,k ]) (initial location information)</formula><p>where g z , g u , and g r are multilayer perceptrons (MLPs), e is an agent embedding layer, and h t,k is a vector of optional contextual features for agent p k at time step t. z t,k is the same location feature vector used in baller2vec and contains information about a specific agent's identity and the agent's location at time step t. u t,k is a "look-ahead" trajectory feature vector that contains information about a specific agent's identity, the agent's location at the next time step t + 1, and the agent's trajectory at time step t, i.e., (x t+1,k ? x t,k , y t+1,k ? y t,k ). Lastly, r k is a starting location feature vector that contains information about a specific agent's identity and the agent's location at time step t = 1.</p><p>The r k feature vectors are necessary so that baller2vec++ can "see" the initial locations of all the agents when processing the agents agent-wise in the first time step.</p><p>These three sets of feature vectors are combined to form a (K + 2T K) ? F matrix Z such that the first K rows consist of the K r k feature vectors, and the remaining 2T K rows consist of the T K z t,k and T K u t,k feature vectors interleaved with one another, i.e., each z t,k is followed by its corresponding u t,k in the matrix. This matrix is passed into the Transformer along with the specially designed self-attention mask, which encodes the following dependencies (see <ref type="figure">Figure 5</ref>): <ref type="bibr">k</ref> ] is the probability assigned to the trajectory bin v t,k (where v t,k = Bin(?x t,k , ?y t,k ) is an integer from one to n 2 ) by f , i.e., Equation <ref type="formula">(3)</ref> is the negative log-likelihood (NLL) of the data according to the model.</p><formula xml:id="formula_11">L = T t=1 K k=1 ? ln(f (Z) t,2k?1 [v t,k ]) (3) where f (Z) t,2k?1 [v t,</formula><p>Because any ordering of a chain rule decomposition of a joint probability produces the same value, e.g.:</p><formula xml:id="formula_12">p(?x t,1 )p(?x t,2 |?x t,1 )p(?x t,3 |?x t,1 ?x t,2 ) = p(?x t,3 )p(?x t,2 |?x t,3 )p(?x t,1 |?x t,3 ?x t,2 )</formula><p>like <ref type="bibr" target="#b10">[11]</ref>, we shuffled the order of the agents in each training sequence to encourage the model to learn joint probabilities of the agent trajectories that are approximately permutation invariant with respect to the ordering of the agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We tested baller2vec++ on two different datasets. To highlight the pathological behavior of models that assume agent trajectories are statistically independent at each time step, we trained scaled down versions of baller2vec++ and baller2vec on a toy dataset consisting of simulated trajectories for two perfectly coordinated agents. Additionally, to demonstrate the efficacy of baller2vec++ in real world settings, we trained baller2vec++ and baller2vec on a dataset of trajectories for professional basketball players. <ref type="bibr" target="#b2">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Toy dataset</head><p>Each training sample was initialized with the agents starting at (?1, 0) and (1, 0) on a grid in random order (i.e., the first agent could be placed to either the left or the right of the origin). At each time step, one of nine actions (corresponding to the 3?3 grid surrounding the agent) was sampled from a uniform distribution, and each of the agents was translated along this trajectory. This process was repeated for 20 time steps (see <ref type="figure" target="#fig_2">Figure 6</ref>(a) for a sample).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Basketball dataset</head><p>We used the same National Basketball Association (NBA) dataset 4 employed by Alcorn and Nguyen <ref type="bibr" target="#b5">[6]</ref>, whom we paraphrase here:</p><p>The NBA dataset consists of trajectories from 631 games from the 2015-2016 season, which were split into 569/30/32 training/validation/test games, respectively. During training, each sequence was sampled using the following procedure: (1) randomly select a training game, (2) randomly select a starting time from the game, (3) take the following four seconds of data and downsample it to 5 Hz from the original 25 Hz, and then (4) randomly (with a probability of 0.5) rotate the court 180 ? . This sampling procedure gave us access to on the order of ?82 million different (albeit overlapping) training sequences. For both the validation and test sets, ?1,000 different, non-overlapping sequences were selected for evaluation by dividing each game into 1,000 N non-overlapping chunks (where N is the number of games), and using the starting four seconds from each chunk as the evaluation sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model</head><p>Our baller2vec++ and baller2vec models for the basketball dataset closely followed <ref type="bibr" target="#b5">[6]</ref>, and so largely resemble the original Transformer architecture <ref type="bibr" target="#b11">[12]</ref>. Specifically, the Transformer settings were: d model = 512 (the dimension of the input and output of each Transformer layer), eight attention heads, d ff = 2048 (the dimension of the inner feedforward layers), six layers, no dropout, and no positional encoding. Each MLP (i.e., g z , g u , and g r ) had 128, 256, and 512 nodes in its three layers, respectively, and a ReLU nonlinearity following each of the first two layers. The player embeddings <ref type="bibr" target="#b12">[13]</ref> had 20 dimensions, and h t,k was a binary variable indicating the side of the frontcourt for player p k (i.e., the direction of his team's hoop) at time step t. Lastly, the 11 ft ? 11 ft 2D Euclidean trajectory space was binned into 121 1 ft ? 1 ft squares.</p><p>We used the Adam optimizer <ref type="bibr" target="#b13">[14]</ref> with an initial learning rate of 10 ?6 , ? 1 = 0.9, ? 2 = 0.999, and = 10 ?9 to update the model parameters, of which there were ?19 million. The learning rate was reduced to 10 ?7 after 20 epochs of the validation loss not improving. Models were implemented in PyTorch and trained on a single NVIDIA GTX 1080 Ti GPU for ?650 epochs (seven days) where each epoch consisted of 20,000 training samples, and the validation set was used for early stopping.</p><p>For the toy dataset, we used scaled down versions of the basketball models with d model = 128, four attention heads, d ff = 512, and two layers in the Transformer. Additionally, each MLP had two layers with 64 and 128 nodes, respectively. The models were trained for 50 epochs of 500 samples per epoch (?10.5 minutes) using a single learning rate of 10 ?5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">baller2vec++ can effectively model coordinated agents in both simulated and real settings</head><p>For the toy dataset, the training loss for baller2vec converged to ?2.2 ? ? ln( 1 9 ), i.e., the model was simply independently guessing the trajectories for both agents at every time step. In contrast, the training loss for baller2vec++ converged to ?1.1 ? ? ln( 1 9 ) ? 2, which is the expected loss for a model that perfectly learns the deterministic relationship between the agents' trajectories (because the prediction for the second agent will always contribute ? ln(1.0) = 0 to the loss).  When generating trajectories with baller2vec, the agents are completely uncoordinated, with each agent following an independent random walk around the grid <ref type="figure" target="#fig_2">(Figure 6(b)</ref>). In contrast, trajectories generated by baller2vec++ display the same coordinated agent behavior as the training data ( <ref type="figure" target="#fig_2">Figure 6(c)</ref>).</p><p>For the basketball dataset, baller2vec++ achieved an average NLL of 0.472 on the test set, 8.9% better than the average NLL for baller2vec (0.518) (see <ref type="figure">Figure S1</ref> for trajectories generated by baller2vec++ and baller2vec).</p><p>As was observed in <ref type="bibr" target="#b5">[6]</ref>, the trajectory bin distributions for baller2vec become much more certain after observing a portion of the sequence <ref type="figure">(Figure 7)</ref>, which suggests baller2vec may be inferring some of the shared hidden variables (e.g., plays) influencing the players. If that hypothesis was true, the performance gap between baller2vec++ and baller2vec should be largest at the beginning of the sequence (before any shared hidden variables can be inferred by baller2vec). Indeed, the average NLL for baller2vec++ in the first time step of each test set sequence (1.567) is 16.1% better than the average NLL for baller2vec (1.869), while the average NLL for baller2vec++ in the last time step of each test set sequence (0.420) is only 9.7% better than the average NLL for baller2vec (0.465) (see <ref type="figure">Figure 7</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>16.1%</head><p>9.7% ? = 0.997 <ref type="figure">Figure 7</ref>: Left: when modeling the trajectories of professional basketball players, the performance gap between baller2vec++ and baller2vec is largest at the beginning of the sequence, before shared unobserved variables can be inferred by baller2vec. Each bar indicates a model's average NLL over the entire test set for that particular time step. For full sequences, baller2vec++ outperforms baller2vec by 8.9%. Right: the joint probability assigned to a sequence by baller2vec++ is approximately permutation invariant with respect to the order of the agents. For each point, its x value indicates baller2vec++'s average NLL for a test set sequence using the original order of the agents in the sequence, while its y value indicates baller2vec++'s average NLL for the same sequence with the order of the agents shuffled. The shuffled average NLLs are highly correlated with their corresponding unshuffled average NLLs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">baller2vec++ makes better predictions when conditioned on concurrent trajectory information from other agents</head><p>Implicit in much of our discussion has been the intuition that providing a model with additional (relevant) information will improve its performance. To empirically test this conjecture, we compared the performance of baller2vec++ when predicting the trajectory of a specific basketball player placed in the first position of the player order (i.e., when k = 1) vs. predicting the trajectory for that same player placed in the last position (i.e., when k = 10). Specifically, for each player in each test sequence, we calculated the NLL of the player's trajectory in the first time step <ref type="bibr" target="#b4">5</ref> with the player in the first position of the player order. Next, we moved the player to the last position of the player order, and then randomly shuffled the remaining nine players 10 times, calculating the NLL for the player in the last position each time. Finally, we calculated the average percent change in the last position NLLs relative to their corresponding first position NLLs. On average, moving a player from the first to the last position improved the NLL for the player's trajectory by 14.6%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">The joint probability assigned to a sequence by baller2vec++ is approximately permutation invariant with respect to the order of the agents</head><p>To determine whether or not baller2vec++ respects the fact that any ordering of a chain rule decomposition of a joint probability produces the same value, we measured how much the average NLL for each test sequence in the basketball dataset varied when the order of the agents changed. Specifically, for each test set sequence, we shuffled the order of the agents 10 times. Then, for each permuted sequence, we calculated the percent error 6 in the average NLL relative to the original, unshuffled sequence. Across all test sequences, the average percent error was only ?1.5%. Further, as can be seen in <ref type="figure">Figure 7</ref>, the shuffled average NLLs are highly correlated with their corresponding unshuffled average NLLs (Pearson correlation coefficient = 0.997), i.e., the joint probability assigned to a sequence by baller2vec++ is approximately permutation invariant with respect to the order of the agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we have shown how the commonly used independence assumption of many multi-agent spatiotemporal models can severely limit their ability to learn to emulate coordinated agents. By relaxing this independence assumption in baller2vec, baller2vec++ was able to more accurately model the trajectories of professional basketball players. Models for other multi-agent spatiotemporal environments, such as pedestrian traffic (see <ref type="bibr" target="#b14">[15]</ref> for a survey) and vehicle traffic (e.g., <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref>), may also benefit from the look-ahead approach used by baller2vec++. Additionally, the interleaved input design of baller2vec++ could be useful when modeling other systems involving many entities interacting through time, such as social media platforms (e.g., <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>). However, confronting the quadratic complexity of the Transformer attention mechanism as the number of entities grows large in these datasets is an open problem, but recent work in sparse Transformers (e.g., <ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref><ref type="bibr" target="#b23">[24]</ref><ref type="bibr" target="#b24">[25]</ref><ref type="bibr" target="#b25">[26]</ref><ref type="bibr" target="#b26">[27]</ref>) shows encouraging progress.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Author Contributions</head><p>MAA conceived and implemented the architecture, designed and ran the experiments, and wrote the manuscript. AN partially funded MAA, provided the GPUs for the experiments, and commented on the manuscript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Acknowledgements</head><p>We would like to thank Jan Van Haaren for his helpful suggestions on how to improve the manuscript. Figure S1: While baller2vec occasionally generates realistic trajectories for the red defender (b), it also makes egregious errors (c). In contrast, the trajectories generated by baller2vec++ often seem plausible (d and e). For both the baller2vec and baller2vec++ generated trajectories, the ground truth trajectories (a) for all of the non-red players were used as input at each time step. The red player was placed last in the player order when generating his trajectory with baller2vec++. Animated versions can be found in the code repository.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>becomes: ? ln(L(D)) = ? N j=1ln(? j,i ) + C where C = ? N j=1 ln(c j,i ). Therefore, minimizing the loss of baller2vec as a classifier of binned trajectories is equivalent to minimizing the loss of the model when assuming the trajectories are generated from a mixture of uniform distributions as specified in Equation(1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a) Training sample.(b) baller2vec.(c) baller2vec++.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>When trained on a dataset of perfectly coordinated agent trajectories (a), the trajectories generated by baller2vec are completely uncoordinated (b) while the trajectories generated by baller2vec++ are perfectly coordinated (c). Animated versions can be found in the code repository.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Look-Ahead Multi-Entity Transformer For Modeling Coordinated Agents (a) Ground truth. (b) baller2vec. (c) baller2vec. (d) baller2vec++. (e) baller2vec++.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">. When processing r k1 , baller2vec++ is exclusively allowed to "look" at each r k2 (i.e., baller2vec++ cannot look at any location or look-ahead feature vectors when processing r k1 ).2. When processing z t2,k2 , baller2vec++ is allowed to "look" at:(i) each r k1 , (ii) any z t1,k1 where (a) t 1 &lt; t 2 or (b) t 1 = t 2 and k 1 ? k 2 , and (iii) any u t1,k1 where (a) t 1 &lt; t 2 or (b) t 1 = t 2 and k 1 &lt; k 2 .3. When processing u t2,k2 , baller2vec++ is allowed to "look" at: (i) each r k1 , (ii) any z t1,k1 where (a) t 1 &lt; t 2 or (b) t 1 = t 2 and k 1 ? k 2 , and (iii) any u t1,k1 where (a) t 1 &lt; t 2 or (b) t 1 = t 2 and k 1 ? k 2 .Each processed z t,k feature vector is then passed through a linear layer that is followed by a softmax, which gives a probability distribution over the trajectory bins for agent p k at time step t. Similar to baller2vec, the loss for each sample is:</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Because baller2vec outperformed a graph recurrent neural network by a wide margin on the same basketball dataset in Alcorn and Nguyen<ref type="bibr" target="#b5">[6]</ref>, we only compared baller2vec++ to baller2vec here.<ref type="bibr" target="#b3">4</ref> https://github.com/linouk23/NBA-Player-Movements</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Because, as previously discussed, the benefits of baller2vec++ were most pronounced in the first time step.<ref type="bibr" target="#b5">6</ref> See: https://en.wikipedia.org/wiki/Approximation_error#Formal_Definition.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Where will they go? predicting fine-grained adversarial multi-agent motion using conditional variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panna</forename><surname>Felsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujoy</forename><surname>Ganguly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="732" to="747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Social gan: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agrim</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sophie: An attentive gan for predicting paths compliant to social and physical constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noriaki</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1349" to="1358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Diverse generation for multi-agent sports games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4610" to="4619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph transformer networks for pedestrian trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunjun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2020-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">baller2vec: A multi-entity transformer for multi-agent spatiotemporal modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anh</forename><surname>Alcorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nguyen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.03291</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Generating multi-agent trajectories using programmatic weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisong</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lucey</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rkxw-hAcFQ" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Generating long-term trajectories using deep hierarchical networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yisong</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Hobbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1543" to="1551" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Social-bigat: Multimodal trajectory forecasting using bicycle-gan and graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineet</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Mart?n-Mart?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2019/file/d09bf41544a3365a46c9077ebb5e35c3-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJXMpikCZ.acceptedasposter" />
		<title level="m">Graph Attention Networks. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaime</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xlnet</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.08237</idno>
		<title level="m">Generalized autoregressive pretraining for language understanding</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">batter|pitcher)2vec: Statistic-free talent modeling with neural player embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michael A Alcorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MIT Sloan Sports Analytics Conference</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Human motion trajectory prediction: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Rudenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luigi</forename><surname>Palmieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kris</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><forename type="middle">O</forename><surname>Gavrila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="895" to="935" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Convolutional social pooling for vehicle trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nachiket</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1468" to="1476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Argoverse: 3d tracking and forecasting with rich maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Fang</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patsorn</forename><surname>Sangkloy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jagjeet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slawomir</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Hartnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multi-agent tensor fusion for contextual trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathew</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wongun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibiao</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying Nian</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Traphic: Trajectory prediction in dense and heterogeneous traffic using weighted interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uttaran</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aniket</forename><surname>Bera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinesh</forename><surname>Manocha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Predicting dynamic embedding trajectory in temporal interaction networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srijan</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xikun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1269" to="1278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Temporal graph networks for deep learning on dynamic graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emanuele</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabrizio</forename><surname>Frasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><surname>Eynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federico</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bronstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML 2020 Workshop on Graph Representation Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Generating long sequences with sparse transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.10509</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Big bird: Transformers for longer sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guru</forename><surname>Guruganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Kumar Avinava Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Ontanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifan</forename><surname>Ravula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amr</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ahmed</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/c8512d142a2d849725f31a9a7a361ab9-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="17283" to="17297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Longformer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<title level="m">The long-document transformer</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reformer: The efficient transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Kitaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Levskaya</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rkgNKkHtvB" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Axial attention in multidimensional transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nal</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.12180</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Is space-time attention all you need for video understanding?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gedas</forename><surname>Bertasius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Torresani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.05095</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
