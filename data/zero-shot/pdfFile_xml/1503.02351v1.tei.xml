<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fully Connected Deep Structured Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
							<email>aschwing@cs.toronto.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
							<email>urtasun@cs.toronto.edu</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Fully Connected Deep Structured Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Convolutional neural networks with many layers have recently been shown to achieve excellent results on many high-level tasks such as image classification, object detection and more recently also semantic segmentation. Particularly for semantic segmentation, a two-stage procedure is often employed. Hereby, convolutional networks are trained to provide good local pixel-wise features for the second step being traditionally a more global graphical model. In this work we unify this two-stage process into a single joint training algorithm. We demonstrate our method on the semantic image segmentation task and show encouraging results on the challenging PASCAL VOC 2012 dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the past few years, Convolutional Neural Networks (CNNs) have revolutionized computer vision. They have been shown to achieve state-of-the-art performance in a variety of vision problems, including image classification <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b30">31]</ref>, object detection <ref type="bibr" target="#b10">[11]</ref>, human pose estimation <ref type="bibr" target="#b31">[32]</ref>, stereo <ref type="bibr" target="#b35">[36]</ref>, and caption generation <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b9">10]</ref>. This is mainly due to their high representational power achieved by learning complex, non-linear dependencies.</p><p>It is only very recently that convolutional nets have proven also very effective for semantic segmentation <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b2">3]</ref>. This is perhaps due to the fact that to achieve invariance, pooling operations are performed, often reducing the dimensionality of the prediction. A Markov random field (MRF) is then used as a refinement step in order to obtain segmentations that respect well segment boundaries. The seminal work of <ref type="bibr" target="#b16">[17]</ref> showed that inference in fully connected MRFs is possible if the smoothness potentials are Gaussian. Impressive performance was demonstrated in semantic segmentation with hand craft features. Later, <ref type="bibr" target="#b2">[3]</ref> extended the unary potentials to incorporate convolutional network features. However, these current approaches train the segmentation models in a piece-wise fashion, fixing the unary weights during learning of the parameters of the pairwise terms which enforce smoothness.</p><p>In this paper we present an algorithm that is able to train jointly the parameters of the convolutional network defining the unary potentials as well as the smoothness terms taking into account the dependencies between the random variables. We demonstrate the effectiveness of our approach using the dataset of the PASCAL VOC 2012 challenge <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>We begin by describing how to learn probabilistic deep networks which take into account correlations between multiple output variables y = (y 1 , . . . , y N ) that are of interest to us. Moreover, a valid configuration y ? Y = N i=1 Y i is assumed to lie in the product space of the discrete variable domains Y i = {1, . . . |Y i |}.</p><p>For a given data sample x ? X , and a parameter vector w ? R A , the score F of a configuration y ? Y is generally modeled by the mapping F : X ? Y ? R A ? R.  The prediction task amounts to finding the configuration</p><formula xml:id="formula_0">y * = arg max y?Y F (x,?; w),<label>(1)</label></formula><p>which maximizes the score F (x,?; w). Note that the best scoring configuration y * is equivalently given as the maximizer of the probability distribution</p><formula xml:id="formula_1">p(? | x, w) ? exp F (x,?; w),</formula><p>since the exponential function is a monotone increasing function and the normalization constant is independent of the configuration? ? Y, i.e., it is constant indeed.</p><p>The learning task is concerned with finding a parameter vector</p><formula xml:id="formula_2">w * = arg max w?R A (x,y)?D p(y | x, w),<label>(2)</label></formula><p>which maximizes the likelihood of a given training set D = {(x, y)}. The training set consists of input-output pairs (x, y) which are assumed to be independent and identically distributed. Note that maximizing the likelihood is equivalent to maximizing the cross entropy between the modeled distribution p(? | x, w) and a target distribution which places all its mass on the groundtruth configuration y. Throughout this work we make no further assumptions about the dependence of the scoring function F (x,?; w) on the parameter vector w, i.e., F (x,?; w) is generally neither convex nor smooth.</p><p>For problems where the output-space size |Y| = N i=1 |Y i | is in the thousands, we can exactly solve the inference task given in Eq. (1) by searching over all possible output space configurations? ? Y. In such a setting, those different configurations are typically referred to as different classes. Similarly, we normalize the distribution p(? | x, w) by summing up the exponentiated score exp F (x,?; w) over all possibilities? ? Y. This is often referred to as a soft-max computation. Non-convexity and non-smoothness of the learning objective w.r.t. the parameters w is answered with stochastic gradient ascent. For efficiency, the gradient is often computed on a small subset of the training data, i.e., a mini-batch.</p><p>We summarize the resulting training algorithm in <ref type="figure" target="#fig_0">Fig. 1</ref>. On a high level it consists of four steps which are iterated until a stopping criterion is met: (i) the forward pass to compute the scoring function F (x,?; w) for all output space configurations? ? Y. (ii) normalizing the scoring function via a soft-max computation to obtain the probability distribution p(? | x, w). (iii) computation and back-propagation of the gradient of the loss function, i.e., often the log-likelihood or equivalently the cross-entropy. (iv) an update of the parameters.</p><p>However, solving the inference task given in Eq. (1) or the learning problem stated in Eq. (2) is computationally challenging if we consider more complex output spaces Y, e.g., those arising from tasks like image tagging. The situation is even more severe if we target image segmentation where the exponential number of possible output space configurations prevents even storage of F (x,?; w) ?? ? Y. Note that this is required in the first line of the algorithm summarized in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>Given an exponential amount of possible configurations |Y| = N i=1 |Y i |, how do we represent the scoring function F (x,?; w) efficiently? Assuming we have an efficient representation, how can we effectively normalize the probability p(? | x, w)? One possible answer to those questions was given by Chen et al. <ref type="bibr" target="#b3">[4]</ref>, who discussed extending log-linear models, i.e., those with a scoring function of In short, <ref type="bibr" target="#b3">[4]</ref> assumed the global scoring function F (x,?; w) to decompose into a sum of local scoring functions f r , each depending on a small subset r ? {1, . . . , N } of variables? r = (? i ) i?r . All restrictions r required to compute the global function via</p><formula xml:id="formula_3">F (x,?; w) = r?R f r (x,? r ; w)<label>(3)</label></formula><p>are subsumed in the set R. If the size of each and every local restriction set r ? R is small,</p><formula xml:id="formula_4">F (x,?; w) is efficiently representable.</formula><p>To compute the gradient of the log-likelihood cost function, we require a properly normalized distribution p(? | x, w), or more specifically its marginals b (x,y),r (? r ) for each restriction r ? R. To this end, message passing type algorithms were employed by <ref type="bibr" target="#b3">[4]</ref>. Such an approach is exact if the distribution p(? | x, w) is of low tree-width. Otherwise computational complexity is prohibitively large and approximations like loopy belief propagation <ref type="bibr" target="#b25">[26]</ref>, convex belief propagation <ref type="bibr" target="#b38">[39]</ref> or treereweighted message passing <ref type="bibr" target="#b36">[37]</ref> are alternatives that were successfully applied.</p><p>The resulting iterative method of <ref type="bibr" target="#b3">[4]</ref> is summarized in <ref type="figure" target="#fig_2">Fig. 2</ref>. In a first step the forward pass computes all outputs of every local scoring function. Afterwards (approximate) marginals are obtained in a second step, and utilized to compute the derivative of the (approximated) maximum likelihood cost function w.r.t. the parameters w. The following backward pass computes the gradient of the parameters by repeatedly applying the chain-rule according to the definition of the scoring function F (x,?; w). The gradient is then utilized during the final parameter update.</p><p>Not only does the approach presented by <ref type="bibr" target="#b3">[4]</ref> fail if the decomposition assumed in Eq. <ref type="formula" target="#formula_3">(3)</ref> is not available. But it is also computationally challenging to obtain the required marginals if too many local functions are required. I.e., computation is slow if the number of restrictions |R| is large, e.g., when working with densely connected image segmentation models where every pixel is possibly correlated to every other pixel in the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>Densely connected models were previously considered by <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b17">18]</ref> and shown to yield impressive results for the image segmentation task. Learning the parameters of densely connected models was considered by Kr?henb?hl and Koltun <ref type="bibr" target="#b17">[18]</ref> in the context of the log-linear setting. Following <ref type="bibr" target="#b3">[4]</ref> we aim at extending those fully connected log-linear models to the more general setting of an arbitrary function F (x,?; w), e.g., a deep convolutional neural network. Note that a similar approach has been recently discussed by <ref type="bibr" target="#b40">[41]</ref> in independent work.</p><p>Let us consider within this section how to efficiently combine deep structured prediction <ref type="bibr" target="#b3">[4]</ref> with densely connected probabilistic models <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b17">18]</ref>. Before getting into the details we note that the presented approach trades computational complexity of the general method of <ref type="bibr" target="#b3">[4]</ref> with a restriction on the pairwise functions f ij (i.e., r = {i, j}). Concretely, the local functions f ij are assumed to be mixtures of kernels in a feature space as detailed below. For simplicity we assume that local functions of order higher than two are not required to represent our global scoring function F (x,?; w). Generalizations have however been presented, e.g., by Vineet et al. <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Inference</head><p>We begin our discussion by considering the inference task. To obtain a computationally efficient prediction algorithm we use a mean field approximation of the model distribution p(? | x, w) for every sample (x, y). More formally, we assume our approximation to factor according to</p><formula xml:id="formula_5">q (x,y) (?) = N i=1 q (x,y),i (? i ).</formula><p>Given some parameters w, we employ a forward pass to obtain our local function representations f r (x,? r ; w). Next we compute the single variable marginals q (x,y),i (? i ) by minimizing the Kullback-Leibler (KL) divergence w.r.t. to the assumed factorization of the mean field distribution q (x,y) (?), i.e.,</p><formula xml:id="formula_6">q * (x,y) = arg min q?? D KL (q (x,y) (?)||p(? | x, w)).<label>(4)</label></formula><p>Hereby q ? ? requires q to be a valid probability distribution. Due to non-convexity, only convergence to a stationary point of the KL divergence cost function is guaranteed for sequential block-coordinate updates <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b15">16]</ref>. More precisely, iterating until convergence through the variables i ? {1, . . . , N } using the closed form update</p><formula xml:id="formula_7">q (x,y),i (? i ) ? exp ? ? f i (? i , x, w) + j?N (i),?j f ij (? i ,? j , x, w)q (x,y),j (? j ) ? ? ,<label>(5)</label></formula><p>which assumes all marginals but q (x,y),i to be fixed, retrieves a stationary point for the cost function of the program given in Eq. (4). The set of variables neighboring i is denoted N (i).</p><p>In the case of densely connected variables, the computational bottleneck arises from the second summand which involves j?N (i) |Y j | additions. The sum ranges over |N (i)| = N ? 1 terms for densely connected structured models. Hence the complexity of an update for a single marginal is of O(N ), and updating all N marginals therefore requires O(N 2 ) operations as also discussed by Kr?henb?hl and Koltun <ref type="bibr" target="#b17">[18]</ref>.</p><p>Importantly, Kr?henb?hl and Koltun <ref type="bibr" target="#b16">[17]</ref> observed that a high dimensional Gaussian filter can be applied to concurrently update all marginals in O(N ). This is achievable when constraining ourselves to pairwise functions being mixtures of M kernels in the feature space as mentioned before.</p><p>Formally, we require</p><formula xml:id="formula_8">f ij (? i ,? j , x, w) = M m=1 ? (m) (? i ,? j , w)k (m) (f i (x) ?f j (x)),</formula><p>where ? (m) is a label compatibility function, k (m) is a kernel function, andf i (x) are features of variable i depending on the data x.</p><p>However, to ensure convergence to a stationary point of the KL divergence cost function for this parallel update, further restrictions on the form of the pairwise functions f ij apply. Formally, if the label compatibility functions ? (m) are negative semi-definite ?m, and the kernels k (m) are positive definite ?m, the KL divergence is readily given as the difference between a concave and a convex term <ref type="bibr" target="#b17">[18]</ref>. Hence the concave-convex procedure (CCCP) <ref type="bibr" target="#b39">[40]</ref> is directly applicable. We therefore proceed iteratively by first linearizing the concave term at the current location and second minimizing the resulting linearized but convex program.</p><p>As detailed by Kr?henb?hl and Koltun <ref type="bibr" target="#b17">[18]</ref>, and as discussed above, finding the linearization is equivalently solved via filtering in time linear in N . Solving the convex program in its original form requires solving a non-linear system of equations independently for each marginal q (x,y),i (? i ), e.g., via Newton's method. A further approximation to the cross-entropy term of the KL-divergence relates the efficient filtering based mean field update of the marginals q (x,y),i (? i ) to the corresponding cost function for which a stationary point is found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning</head><p>Having observed that mean-field inference can be efficiently addressed with Gaussian filtering, given restrictions on the pairwise functions f ij , we now turn our attention to the learning task. As mentioned before we aim at finding a parameter vector w that maximizes the likelihood objective function. Since the exact likelihood is computationally expensive, we use the log-likelihood based on the mean-field marginals. Hence our surrogate loss function L (x,y) for a sample (x, y) with corresponding annotated ground truth labeling y is given by</p><formula xml:id="formula_9">L (x,y) (q (x,y) ) = ? N i=1 log q (x,y),i (y i ).<label>(6)</label></formula><p>To perform a parameter update step we need the gradient of the surrogate loss function w.r.t. the parameters, i.e.,</p><formula xml:id="formula_10">?L (x,y) ?w = ?L (x,y) ?q (x,y) ? ?q (x,y) ?w .<label>(7)</label></formula><p>The gradient of the surrogate loss function L (x,y) w.r.t. the marginals is easily obtained from Eq. (6). It is given by</p><formula xml:id="formula_11">?L (x,y) ?q (x,y),i (? i ) = ? 1 q (x,y),i (y i ) ? i = y i ,<label>(8)</label></formula><p>where the Iverson bracket ? i = y i equals one if? i = y i , and returns zero otherwise.</p><p>To perform a gradient step during learning, we additionally require the derivatives of the marginals w.r.t. the parameters, i.e.,</p><p>?q (x,y),i (?i) ?w .</p><p>More carefully investigating the mean-field update given in Eq. (5) reveals a recursive definition.</p><p>More concretely, the derivative ?q t (x,y),i (?i) ?w of the marginal q t (x,y),i (? i ) after t iterations depends on the results from earlier iterations. Hence, we obtain the desired result by successively back-tracking through the mean-field iterations from the last iteration back to the first. This direct computation is however computationally expensive. Fortunately, back-substitution into the loss gradient yields an algorithm which requires a total of T back-tracking steps, independent of the number of parameters. We refer the interested reader to <ref type="bibr" target="#b17">[18]</ref> for additional details regarding the computation of the gradient</p><formula xml:id="formula_12">?q (x,y),i (?i) ?w .</formula><p>But contrasting <ref type="bibr" target="#b17">[18]</ref>, we no longer assume the unaries to be given by a logistic regression model. Contrasting <ref type="bibr" target="#b2">[3]</ref>, we don't assume the unaries to be fixed during CRF parameter updates. Generalizing the gradient of the marginals w.r.t. parameters to arbitrary unaries is straightforward since the gradients are directly given by the marginals. Combined with the gradient of the log-likelihood loss function w.r.t. the marginals, given in Eq. (8), we obtain ?L (x,y) ?w as the difference between the ground-truth and the predicted marginals. This result is then used for back-propagation through any functional structure which provides the unary scoring functions f i , e.g., convolutional neural networks.</p><p>Derivatives w.r.t. to label compatibility and kernel shape parameters are readily given in <ref type="bibr" target="#b17">[18]</ref>. The resulting algorithm is summarized in <ref type="figure">Fig. 3</ref>. In short, we first obtain again our functional representation via a forward pass through any functional network. Subsequently we compute our meanfield marginals via filtering. Afterwards we obtain the gradient of the loss function via an efficient back-tracking. In the next step the gradient of the parameters is computed by back-propagating the gradient of the loss-function using the chain-rule dictated by the definition of the scoring function. In a final step we update the parameters. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We evaluate our approach summarized in <ref type="figure">Fig. 3</ref> on the dataset of the Pascal VOC 2012 challenge <ref type="bibr" target="#b8">[9]</ref>. The task is semantic image segmentation of 21 object classes (including background). The original dataset contains 1464 training, 1449 validation and 1456 test images. In addition to this data we make use of the annotations provided by Hariharan et al. <ref type="bibr" target="#b12">[13]</ref>, resulting in a total of 10582 training instances. The reported performance is measured using the intersection-over-union metric. Note that we conduct our tests on the 1449 validation set images which were neither used during training nor for fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model</head><p>Our model setup follows <ref type="bibr" target="#b2">[3]</ref>, i.e., we employ the 16 layer DeepNet model <ref type="bibr" target="#b30">[31]</ref>. Just like <ref type="bibr" target="#b2">[3]</ref> we first convert the fully connected layers into convolutions as first discussed in <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b29">30]</ref>. This is useful since we are not interested in a single variable output prediction, but rather aim at learning probability masks. To obtain a larger probability mask we skip downsampling during the last two max-pooling operations. To take into account the skipped downsampling during subsequent convolutions we employ the '? trous (with hole) algorithm' <ref type="bibr" target="#b22">[23]</ref>. It takes care of the fact that data is stored in an interleaved way, i.e., in our case convolutions sub-sample the input data by a factor of two or four respectively. To adapt to the 21 object classes we also replace the top layer of the DeepNet model to yield 21 classes for each pixel.</p><p>Similar to <ref type="bibr" target="#b2">[3]</ref> we assume the input size of our network to be of dimension 306 ? 306 which results in a 40 ? 40 sized spatial output of the DeepNet which is in our case an intermediate result however.</p><p>Contrasting <ref type="bibr" target="#b2">[3]</ref>, we jointly optimize for both unary and CRF parameters using the algorithm presented in <ref type="figure">Fig. 3</ref>. To this end, given images downsampled to a size of 306 ? 306, our algorithm first performs a forward pass through the convolutional DeepNet to obtain the 40 ? For the second step of our algorithm we perform 5 iterations of mean field updates to compute the marginals q (x,y),i (? i ) of the fully connected CRF. Those are then compared to the original groundtruth image segmentations, using as our loss function the sum of cross-entropy terms, i.e., the log-likelihood loss, as specified in Eq. <ref type="bibr" target="#b5">(6)</ref>. In the third step we back-track through the marginals to obtain a gradient of the loss function. Afterwards we back-propagate the derivatives w.r.t. the unary term through both the bi-linear interpolation and the 16-layer convolutional network. The shape and compatibility parameters of the CRF, detailed below, are updated directly.  <ref type="table">Table 1</ref>: Performance of our approach for individual classes. In the last two columns of the lower panel we compare our mean to the recently presented baseline by Chen et al. <ref type="bibr" target="#b2">[3]</ref>.</p><p>It was shown independently by many authors <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b3">4]</ref>, that successively increasing the number of parameters during training typically yields better performance due to better initialization of larger models. We therefore train our model in two stages. First, we assume no pairwise connections to be present, i.e., we fine-tune the weights obtained from the DeepNet ImageNet model <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b28">29]</ref> to the Pascal dataset <ref type="bibr" target="#b8">[9]</ref>. Standard parameter settings for a momentum of 0.9, a weight decay of 0.0005 and learning rates of 0.01 and 0.001 for the top and all other layers are employed respectively. Due to the 12GB memory restrictions on the Tesla K40 GPU we use a mini-batch size of 20 images.</p><p>In a second stage we jointly train the convolutional network parameters as well as the compatibility and shape parameters of the dense CRF arising from the pairwise functions</p><formula xml:id="formula_13">f ij (? i ,? j , x, w) = ?(? i ,? j ) 2 m=1 w m k (m) (f (m) i (x) ?f (m) j (x)).<label>(9)</label></formula><p>Hereby, we employ the Potts potential ?(y i , y j ) = y i = y j and the Gaussian kernels given by</p><formula xml:id="formula_14">k (m) = exp ? 1 2 (f (m) i ? f (m) i ) ? ?1 m (f (m) i ?f (m) i</formula><p>) .</p><p>As indicated in Eq. (9), we use M = 2 kernels, both with diagonal covariance matrix ? m . One containing as featuresf i (x) the two-dimensional pixel positions, the other one containing as features the two dimensional pixel positions as well as the three color channels. Hence we obtain a total of nine parameters, i.e., two compatibility parameters w 1 and w 2 and 2+5 = 7 kernel shape parameters for the diagonal covariance matrices ? m .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>As mentioned before, all our results were computed on the validation set of the Pascal VOC dataset. This part of the data was neither used for training nor for fine-tuning.</p><p>Unary performance: We first investigate the performance of the first training stage of the proposed approach, i.e., fine-tuning of the 16 layer DeepNet parameters on the Pascal VOC data. The validation set accuracy is plotted over the number of iterations in <ref type="figure" target="#fig_4">Fig. 4 (a)</ref>. We observe the performance to peak at around 4000 iterations with a mean intersection over union measure of 61.476%. The result reported by <ref type="bibr" target="#b2">[3]</ref> for this experiment is 59.80%, i.e., we outperform their unary model by 1.5%.</p><p>Joint training: Next we illustrate the performance of the second step, i.e., joint training of both convolutional network parameters and CRF compatibility and shape parameters. In <ref type="figure" target="#fig_4">Fig. 4 (b)</ref> we indicate the best obtained unary performance from the first step and visualize the validation and training set performance over the number of iterations. We observe the results to peak quickly after around 20 iterations and remain largely stable thereafter.</p><p>Details: In Tab. 1 we provide the training and test set accuracies for the 21 individual classes. We observe the 'bike' and 'chair' class to be particularly difficult. For both categories the validation set performance is roughly half of the training set accuracy.</p><p>Comparison to baseline: As provided in Tab. 1, the peak validation set performance of our approach is 64.060%, which slightly outperforms the separate training result of 63.74% reported by Chen et al. <ref type="bibr" target="#b2">[3]</ref>. Visual results: We illustrate visual results of our approach in <ref type="figure" target="#fig_6">Fig. 5</ref>. Our method successfully segments the object if the images are clearly apparent. Noisy images and objects with many variations pose challenges to the presented approach as visualized in <ref type="figure" target="#fig_7">Fig. 6</ref>. Also, we observe our learnt parameters to generally over-smooth results while being noisy on the boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>We presented a first method that jointly trains convolutional neural networks and fully connected conditional random fields for semantic image segmentation. To this end we generalize <ref type="bibr" target="#b2">[3]</ref> to joint training. Note that a method along those lines has also been recently made publicly available in independent work <ref type="bibr" target="#b40">[41]</ref>. Whereas the latter combines dense conditional random fields <ref type="bibr" target="#b16">[17]</ref> with the fully convolutional networks presented by Long et al. <ref type="bibr" target="#b20">[21]</ref>, we employ and modify the 16 layer DeepNet architecture presented in work by Simonyan and Zisserman <ref type="bibr" target="#b30">[31]</ref>.</p><p>Ideas along the lines of joint training were discussed within machine learning and computer vision as early as the 90's in work done by Bridle <ref type="bibr" target="#b1">[2]</ref> and Bottou <ref type="bibr" target="#b0">[1]</ref>. More recently <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b24">25]</ref> incorporate non-linearities into unary potentials but generally assume exact inference to be tractable. Even more recently, Li and Zemel <ref type="bibr" target="#b19">[20]</ref> investigate training with hinge-loss objectives using nonlinear unaries, but the pairwise potentials remain fixed, i.e., no joint training. Domke <ref type="bibr" target="#b6">[7]</ref> decomposes the learning objective into logistic regressors which will be computationally expensive in our setting. Tompson et al. <ref type="bibr" target="#b31">[32]</ref> propose joint training for pose estimation based on a heuristic approximation which ignores the normalization constant of the model distribution. Joint training of conditional random fields and deep networks was also discussed recently by <ref type="bibr" target="#b3">[4]</ref> for graphical models in general. Techniques based on convex and non-convex approximations were described for obtaining marginals in the general non-linear setting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We discussed a method for semantic image segmentation that jointly trains convolutional neural networks and conditional random fields. Our approach combines techniques from deep convolutional neural networks with variational mean-field approximations from the graphical model literature. We obtain good results on the challenging Pascal VOC 2012 dataset.</p><p>In the future we plan to train our method on larger datasets. Additionally we want to investigate training with weakly labeled data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Algorithm: Deep Learning Repeat until stopping criteria 1 .</head><label>1</label><figDesc>Forward pass to compute F (x,?; w) ?? ? Y 2. Normalization via soft-max to obtain p(? | x, w) 3. Backward pass through definition of function via chain rule 4. Parameter update</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Gradient descent for learning deep models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Algorithm: Learning Deep Structured Models Repeat until stopping criteria 1. Forward pass to compute f r (x,? r ; w) ?r ? R,? r ? Y r 2. Computation of marginals b (x,y),r (? r ) via loopy belief propagation, convex belief propagation or tree-reweighted message passing 3. Backward pass through definition of function via chain rule 4. Parameter update Approximated gradient descent for learning deep structured models. the form F (x,?; w) = w ?(x,?), to the more general setting, i.e., an arbitrary dependence of the scoring function F (x,?; w) on the parameter vector w.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm: Learning Fully Connected Deep Structured Models Repeat until stopping criteria 1 . 2 .Figure 3 :</head><label>123</label><figDesc>Forward pass to compute f r (x,? r ; w) ?r ? R, y r ? Y r Computation of marginals q t (x,y),i (? i ) via filtering for t ? {1, . . . , T } 3. Backtracking through the marginals q t (x,y),i (? i ) from t = T ? 1 down to t = 1 4. Backward pass through definition of function via chain rule 5. Parameter update Stochastic gradient descent for learning fully connected deep structured models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>(a) Validation set performance over the number of iterations when fine-tuning the unary parameters only. (b) Validation set performance over the number of iterations when fine-tuning all parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>40 ?</head><label>40</label><figDesc>21 sized class probability maps in an intermediate stage. These intermediate class probability maps are directly up-sampled to the original image dimension using a bi-linear interpolation layer. This yields the actual output of our augmented DeepNet network defining the scoring function F (x,?, w). Note that the number N of variables? = (? 1 , . . . ,? N ) ? Y is therefore equal to the number of pixels of the original image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Visual results of good predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :</head><label>6</label><figDesc>Failure cases</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Data bkg areo bike bird boat bottle bus car cat chair cow Valid. 90.461 77.455 30.355 76.564 60.735 65.075 81.261 74.958 81.505 23.367 66.279 Train 90.159 76.314 64.450 78.677 68.224 68.044 84.491 80.274 86.347 44.567 79.987 Data table dog horse mbike person plant sheep sofa train tv Our mean [3] Valid. 52.219 70.624 66.660 65.725 72.913 42.174 73.452 43.412 71.738 58.322 64.060 63.74 Train 62.710 82.987 76.729 76.523 75.399 63.863 79.937 55.146 80.699 70.164 73.604 -</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Global training of document processing systems using graph transformer networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Training stochastic model recognition algorithms as networks can lead to maximum mutual information estimation of parameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Bridle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Semantic ImageSegmentation with Deep Convolutional Nets and Fully Connected CRFs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.7062" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1407.2538" />
		<title level="m">Learning Deep Structured Models</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Natural language processing (almost) from scratch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Karlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kuksa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Neural conditional random fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-M.-T</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Artieres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AISTATS</title>
		<meeting>AISTATS</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Structured Learning via Logistic Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Domke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Long-term recurrent convolutional networks for visual recognition and description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Hendrikcs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guadarrama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1411.4389" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html" />
		<title level="m">The PASCAL Visual Object Classes Challenge 2012 (VOC2012) Results</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Iandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1411.4952" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast image scanning with deep max-pooling convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guisti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gambardella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICIP</title>
		<meeting>ICIP</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Semantic Contours from Inverse Detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arbel?ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Deep visual-semantic alignments for generating image descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.2306" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-modal neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salahutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Probabilistic Graphical Models: Principles and Techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Friedman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Efficient inference in fully connected CRFs with Gaussian edge potentials</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Parameter Learning and Convergent Inference for Dense Random Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">ImageNet Classification with Deep Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">High Order Regularization for Semi-Supervised Learning of Structured Output Problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Fully Convolutional Networks for Semantic Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1411.4038" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A conditional neural fields model for protein threading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">A Wavelet Tour of Signal Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6632" />
		<title level="m">Deep captioning with multimodal recurrent neural networks (m-rnn)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Conditional random fields for integrating local discriminative classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fosler-Lussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Speech, and Language Processing</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Conditional Neural Fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Backpropagation training for multilayer conditional random field based phone recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Prabhavalkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fosler-Lussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>ImageNet Large Scale Visual Recognition Challenge</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Very Deep Convolutional Networks for Large-Scale Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1409.1556" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bregler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Improved initialization and Gaussian mixture pairwise terms for dense random fields with mean-field inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Warrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sturgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Filter-based mean-field inference for random fields with higherorder terms and product label-spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Warrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Show and tell: A neural image caption generator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1411.4555" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Computing the Stereo Matching Cost with a Convolutional Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>?bontar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1409.4326" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Tree-based reparameterization framework for analysis of sum-product and related algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jaakkola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Willsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Information Theory</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Graphical models, exponential families and variational inference. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">MAP Estimation, Linear Programming and Belief Propagation with Convex Free Energies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yanover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Meltzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. UAI</title>
		<meeting>UAI</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The Concave-Convex Procedure (CCCP)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jayasumana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Romera-Paredes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vineet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1502.03240" />
		<title level="m">Conditional Random Fields as Recurrent Neural Networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
