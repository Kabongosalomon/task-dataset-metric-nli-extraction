<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Multi-Task Networks For Occluded Pedestrian Pose Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Das</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Detection Vision Systems</orgName>
								<address>
									<region>Valeo India</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudip</forename><surname>Das</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Indian Statistical Institute</orgName>
								<address>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ganesh</forename><surname>Sistu</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Valeo Vision Systems</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Horgan</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Valeo Vision Systems</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ujjwal</forename><surname>Bhattacharya</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Indian Statistical Institute</orgName>
								<address>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Jones</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Glavin</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ciar?n</forename><surname>Eising</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">National University of Ireland</orgName>
								<address>
									<settlement>Galway</settlement>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">University of Limerick</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Multi-Task Networks For Occluded Pedestrian Pose Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T17:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pedestrian Pose Estimation</term>
					<term>Unsupervised Domain Adaptation</term>
					<term>Multi-task Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Most of the existing works on pedestrian pose estimation do not consider estimating the pose of an occluded pedestrian, as the annotations of the occluded parts are not available in relevant automotive datasets. For example, CityPersons, a well-known dataset for pedestrian detection in automotive scenes does not provide pose annotations, whereas MS-COCO, a non-automotive dataset, contains human pose estimation. In this work, we propose a multi-task framework to extract pedestrian features through detection and instance segmentation tasks performed separately on these two distributions. Thereafter, an encoder learns pose specific features using an unsupervised instance-level domain adaptation method for the pedestrian instances from both distributions. The proposed framework has improved state-of-the-art performances of pose estimation, pedestrian detection, and instance segmentation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Human Pose Estimation (HPE) is a widely deployed computer vision application <ref type="bibr" target="#b0">[Chen et al., 2020]</ref>, along with semantic segmentation <ref type="bibr" target="#b1">[Das. et al., 2019]</ref>, and object tracking and trajectory prediction <ref type="bibr" target="#b10">[Sridevi et al., 2021]</ref>. Addressing HPE for occluded pedestrians was first reported in ClueNet <ref type="bibr" target="#b5">[Kishore et al., 2019]</ref> and later personto-person occlusion was investigated in <ref type="bibr" target="#b2">[Das et al., 2020]</ref>. In this paper, we propose a novel end-to-end two stage fully convolutional network for the purpose of estimating pose of occluded pedestrians, in the context of a Multi-Task Learning (MTL) architecture where object detection and segmentation are performed. The proposed framework can 1) learn pedestrian pose estimation (PPE) from a dataset that does not contain pose annotations and 2) accurately estimate the pose of the occluded parts of the human body without the annotations of the same occluded parts. To address the issue of the non-availability of pose annotations during training in the CityPersons <ref type="bibr" target="#b11">[Zhang et al., 2017]</ref> dataset, we consider a related dataset (MS-COCO <ref type="bibr" target="#b7">[Lin et al., 2014]</ref>) to get adequate supervision specific to PPE during training. To achieve this, we apply unsupervised instance level domain adaptation on each pedestrian into the target domain. Here, the dataset with human pose annotations acts as the source domain, whereas the samples with only pedestrian detection and segmentation annotations become the target domain in domain adaptation. The main contributions of this study are: 1) the proposal of a two-stage end-to-end fully convolutional network to perform occluded PPE, 2) preserving the information of detection and segmentation in an MTL architecture, and 3) in achieving state-of-the-art performance on pedestrian detection, instance segmentation and PPE tasks respectively. detection and instance segmentation respectively. Our proposed framework is illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>. Feature Pyramid Network (FPN) style encoder is used in each distribution specific MTL instance. We denote these as E C (?) and E M (?) respectively. We use a set of deconvolution layers to perform instance segmentation (D S C (?) and D S M (?)) and detection (D D C (?) and D D M (?)) in two instances of MTL. Two independent MTLs are necessary here as the distribution of the datasets considered in this work is not close. One of the main advantages of having distribution specific MTL is to exploit these two domains independently to generate strong distribution specific features. We use spatial attention in between encoder and task specific decoders. This basically applies global average pooling on feature maps to generate vector and that is multiplied with the same feature map to generate most attentive area from the features. This technique helps to preserve the spatial consistency in feature space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Distribution Invariant PPE</head><p>As the pedestrian dataset does not provide pose annotations, we apply instance level domain adaptation from another dataset that contains the details of human pose. Pedestrian instances from the detection and segmentation decoder are projected back to the last layer of encoded feature maps using ROI pooling, that are masked and fed as input to the encoder (E Pose (?)) for PPE. The motivation to apply instance-level domain adaption is to minimize the domain shift between two different distributions of the same category. In this unsupervised domain adaptation setup, when a sample from source domain passes through the pose encoder, then the weights are updated in E Pose (?), domain classifier (D C (?)) and D Pose (?) but D Pose (?) is not updated for the input from target domain. This means the features extracted by E Pose (?) are fed to D C (?) to determine the actual source distribution (i.e., CityPersons or MS COCO). In this adversarial learning setup, D C (?) promoted the accurate classification of the input domain, while E Pose (?) encourages the generation of better domain invariant features specific to human instances.</p><p>To train the proposed framework in end-to-end fashion, we express overall MTL loss function, L t ot al as the simple weighted combination of other losses from the detectors (L d et c , L d et m ), instance segmentation (L seg c , L seg m ), domain classification (L d c ) and PPE (L pe ) as,</p><formula xml:id="formula_0">L t ot al = L d et c + L d et m + ?L seg c + ?L seg m + ?L d c + ?L pe<label>(1)</label></formula><p>where L d et c , L seg c are the losses of detection and segmentation tasks trained on CityPersons dataset. Likewise, losses L d et m and L seg m are obtained from an MTL trained on MS COCO. ?, ? and ? are the weights corresponding to instance segmentation, domain classifier and PPE losses respectively. For the instance segmentation task, we use binary cross-entropy loss. For object detection task, we adopt the loss from <ref type="bibr" target="#b3">[Dasgupta et al., 2022]</ref>. We follow the loss function for PPE and L d c as described in <ref type="bibr" target="#b5">[Kishore et al., 2019]</ref> and <ref type="bibr" target="#b6">[Kocabas et al., 2018]</ref>.    3 Experimentation Details</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets and Implementation Details</head><p>The proposed method is trained and evaluated on the two publicly available datasets already mentioned -CityPersons and MS COCO. Annotations of detection and instance segmentation specific to human instances are used from both datasets, along with pose information from MS COCO. Out of 17 available key points, we use 13 (as discussed in <ref type="bibr" target="#b5">[Kishore et al., 2019]</ref>). Two MTL networks specific to detection and instance segmentation tasks were pre-trained on CityPersons and MS COCO before initiating the second stage of training for PPE. Curriculum Learning for Mask and Predict strategy was used to gradually increase the masking percentage as the training progresses. Momentum Optimizer with 0.9 and an initial learning rate of 0.01 was used. After each 15k iterations, the learning rate is reduced by a factor of 10. The weights ?, ? and ? are set to 0.5, 1, 1 respectively. Data augmentation methods, such as applying random flipping, blurring, brightness, etc., are added to make the proposed framework more robust. Training was completed on two Nvidia Tesla P6 GPUs with batch size set to 1.  <ref type="table" target="#tab_0">Table 1</ref> shows the performance of PPE of the proposed model and compares with recently published methods. Since the annotations of the occluded parts of the pedestrians are not available, we created such occluded pedestrians by masking (with different percentages) random parts of fully visible pedestrians <ref type="bibr" target="#b2">[Das et al., 2020]</ref> and compared with existing techniques as presented in <ref type="table" target="#tab_1">Table 2</ref>. The proposed approach has clearly improved the existing benchmark in estimating pose for the occluded pedestrians.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Comparison study using Miss Rate (MR) on the validation set of CityPersons for pedestrian detection task with a few existing methods is shown in <ref type="table" target="#tab_2">Table 3</ref>   <ref type="figure" target="#fig_1">Fig. 2</ref> shows the qualitative results on CityPersons and MS COCO dataset for PPE of the proposed model. <ref type="table" target="#tab_3">Table 4</ref> provides the results of instance segmentation of the proposed framework that slightly improves the SOTA performance for both categories -person and rider. As part of ablation study, different standard backbone encoders are tested using average precision metric for PPE and among these ResNeXt-101 outperformed other encoders as presented in <ref type="table" target="#tab_5">Table 5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, an end-to-end two stage network is developed that is trained in an unsupervised manner to accurately estimate the pose of pedestrians regardless the level of occlusion. We apply unsupervised domain adaptation at instance level to reduce the distribution gap between two set of features obtained from two distinct MTL setup. Experimental results demonstrate the robustness of the proposed strategy and provide strong confirmation as it improved respective state-of-the-art results on PPE, pedestrian detection, and instance segmentation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Specific Multi-task Learning Two distinct multi-task learning (MTL) networks are setup for two different data distributions -CityPersons and MS COCO. Each MTL network aims to extract domain specific features of human instances to perform human Our proposed MTL architecture for end-to-end PPE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Sample outputs of the pose estimation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison using AP for PPE task on MS COCO dataset.</figDesc><table><row><cell>Model</cell><cell>AP AP50 AP75 APM APL</cell></row><row><cell cols="2">MultiPoseNet [Kocabas et al., 2018] 69.6 86.3 76.6 65.0 76.3</cell></row><row><cell>CFN [Huang et al., 2017]</cell><cell>72.6 86.7 69.7 78.3 79.0</cell></row><row><cell>ClueNet[Kishore et al., 2019]</cell><cell>73.9 89.6 78.2 70.9 79.1</cell></row><row><cell>[Das et al., 2020]</cell><cell>74.2 89.9 74.9 79.3 76.6</cell></row><row><cell>Ours</cell><cell>75.7 90.3 76.3 80.7 79.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparative study of PPE with SOTA models having different occlusion percentages on MS-COCO dataset.</figDesc><table><row><cell>Model</cell><cell cols="2">Occlusion % 20% 30% 40% 50% 60% 70%</cell></row><row><cell cols="3">ClueNet [Kishore et al., 2019] 88.06 83.93 79.8 73.4 64.0 58.8</cell></row><row><cell>[Das et al., 2020]</cell><cell cols="2">90.3 84.31 81.2 74.06 64.9 59.1</cell></row><row><cell>Ours</cell><cell>92.0</cell><cell>85.9 82.4 75.3 65.7 59.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>MR based comparison of SOTA models for pedestrian detection on CityPersons.</figDesc><table><row><cell>Model</cell><cell>R</cell><cell cols="2">HO R+HO</cell></row><row><cell>Faster RCNN</cell><cell cols="3">15.52 64.83 41.45</cell></row><row><cell>Tao et al. [Song et al., 2018]</cell><cell>14.4</cell><cell>52.0</cell><cell>34.24</cell></row><row><cell cols="2">OR-CNN [Zhang et al., 2018] 11.0</cell><cell>51.0</cell><cell>36.11</cell></row><row><cell cols="4">ClueNet [Kishore et al., 2019] 11.87 47.68 30.84</cell></row><row><cell>[Das et al., 2020]</cell><cell cols="3">13.29 46.07 29.13</cell></row><row><cell>Ours</cell><cell cols="2">12.01 44.7</cell><cell>27.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Comparison using IoU for instance segmentation on CityPersons.</figDesc><table><row><cell>Model</cell><cell>Training Data</cell><cell cols="2">Person Rider</cell></row><row><cell>Mask-RCNN</cell><cell>CityPersons + COCO</cell><cell>34.8</cell><cell>27.0</cell></row><row><cell cols="2">PANet [Liu et al., 2018] CityPersons + COCO</cell><cell>41.5</cell><cell>33.6</cell></row><row><cell>[Das et al., 2020]</cell><cell>CityPersons + COCO</cell><cell>42.1</cell><cell>33.9</cell></row><row><cell>Ours</cell><cell>CityPersons + COCO</cell><cell>42.7</cell><cell>34.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>where a few specific scenarios such as Reasonable (R) with [.65, inf] visibility, Heavy Occlusion (HO) with [.20, .65] visibility and Reasonable+Heavy occlusion (R + HO) with [.20, inf] visibility are considered.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Ablation study on different backbone encoders for PPE on test data of MS-COCO.</figDesc><table><row><cell>Backbone</cell><cell cols="2">AP AP 50 AP 75 AP M AP L</cell></row><row><cell>ResNet-50</cell><cell cols="2">69.7 86.3 71.94 64.2 71.1</cell></row><row><cell cols="2">ResNet-101 71.4 87.8</cell><cell>72.1 76.1 74.3</cell></row><row><cell cols="2">ResNeXt-101 75.7 90.3</cell><cell>76.3 80.7 79.5</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Monocular human pose estimation: A survey of deep learning-based methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>References</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">192</biblScope>
			<biblScope unit="page">102897</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Design of real-time semantic segmentation decoder for automated driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">VISAPP</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An end-to-end framework for pose estimation of occluded pedestrians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Das</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spatiocontextual deep network-based multimodal pedestrian detection for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Dasgupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A coarse-fine network for keypoint localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cluenet: A deep framework for occluded pedestrian pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kishore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multiposenet: Fast multi-person pose estimation using pose residual network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Kocabas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Path aggregation network for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Small-scale pedestrian detection based on topological line localization and temporal feature aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Object detection, tracking and trajectory prediction for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Sridevi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Autonomous Driving and Advanced Driver-Assistance Systems (ADAS): Applications, Development, Legal Issues, and Testing</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">105</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Citypersons: A diverse dataset for pedestrian detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Occlusion-aware r-cnn: detecting pedestrians in a crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">[</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
