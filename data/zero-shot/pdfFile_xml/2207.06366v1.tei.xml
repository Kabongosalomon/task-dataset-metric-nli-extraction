<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">N-Grammer: Augmenting Transformers with latent n-grams</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
							<email>aurkor@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Anil</surname></persName>
							<email>rohananil@google.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangda</forename><surname>Lai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Zhao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyuan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shibo</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rigel</forename><surname>Swavely</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phuong</forename><surname>Dao</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Fifty</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Google Research</orgName>
								<orgName type="institution" key="instit2">Brain Team</orgName>
								<address>
									<settlement>Mountain View</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">N-Grammer: Augmenting Transformers with latent n-grams</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Transformer models have recently emerged as one of the foundational models in natural language processing, and as a byproduct, there is significant recent interest and investment in scaling these models. However, the training and inference costs of these large Transformer language models are prohibitive, thus necessitating more research in identifying more efficient variants. In this work, we propose a simple yet effective modification to the Transformer architecture inspired by the literature in statistical language modeling, by augmenting the model with n-grams that are constructed from a discrete latent representation of the text sequence. We evaluate our model, the N-Grammer on language modeling on the C4 data-set as well as text classification on the Su-perGLUE data-set, and find that it outperforms several strong baselines such as the Transformer and the Primer. We open-source our model for reproducibility purposes in Jax 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The area of generative modeling of text has witnessed rapid and impressive progress driven by the adoption of self-attention to neural networks. Attention for machine translation was proposed in <ref type="bibr" target="#b3">Bahdanau et al. (2015)</ref>; <ref type="bibr" target="#b9">Cho et al. (2014)</ref>; <ref type="bibr" target="#b44">Vaswani et al. (2017)</ref> and subsequent works such as <ref type="bibr" target="#b33">Radford et al. (2018)</ref>; <ref type="bibr" target="#b12">Devlin et al. (2019)</ref> applied the learned representations of language to several problems in natural language processing. The rapid progress has been made possible primarily by increasing the modeling capacity of these Transformer based models to billions of parameters <ref type="bibr" target="#b7">(Brown et al., 2020)</ref> which comes at a large computational cost. The computational cost of Transformer models is being addressed in the literature by exploiting sparsity in self-attention (Ainslie * * Equal contributions. 1 https://github.com/tensorflow/lingvo/ tree/master/lingvo/jax <ref type="bibr" target="#b51">Zaheer et al., 2020;</ref>, mixtures of experts <ref type="bibr" target="#b29">Lepikhin et al., 2020;</ref><ref type="bibr" target="#b14">Fedus et al., 2021)</ref> for sparsity in the feed-forward network, sparsity in the softmax computation <ref type="bibr">(Correia et al., 2019)</ref>, and combining depth-wise convolution with attention <ref type="bibr" target="#b48">(Wu et al., 2021;</ref><ref type="bibr" target="#b39">So et al., 2021)</ref>.</p><p>Motivated by the growing literature in training more efficient variants of Transformers, as well as the classical literature on statistical language modeling <ref type="bibr" target="#b26">(Koehn, 2009)</ref>, we propose a simple modification to the Transformer architecture termed the N-Grammer in this work. The N-Grammer layer improves the efficiency of language models by incorporating latent n-gram representations into the model during training. Since the N-Grammer layer only involves sparse operations during training and inference, we find that a Transformer model with the latent N-Grammer layer can match the quality of a larger Transformer while being significantly faster at inference. This is due to the fact that on most hardware platforms, the overhead of adding sparse operations such as an embedding look-up required by the N-Grammer is significantly lower than that of dense matrix multiplication operations incurred by scaling up the same Transformer model to have the same quality as the N-Grammer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Memory augmented models There has been a long line of work in augmenting sequence models with memory, e.g. the Neural Turing Machine <ref type="bibr" target="#b16">(Graves et al., 2014)</ref> and Memory Networks <ref type="bibr">(Weston et al., 2014)</ref>. More recent works have proposed combining Transformer based models with product key look-up tables <ref type="bibr" target="#b28">(Lample et al., 2019)</ref>, while <ref type="bibr" target="#b32">Panigrahy et al. (2021)</ref> propose memories based on sketches of past activations. There has also been a lot of work on augmenting language models with non-parametric memory, such as the k-nearest neighbor language models of Khandel-  <ref type="figure">Figure 1</ref>: The N-Grammer layer. It takes as input a sequence of uni-gram embeddings and outputs a parallel sequence of N-gram augmented embeddings. The input embeddings are clustered into a discrete latent representation using PQ, and n-grams (bi-grams) IDs are computed over it. For each n-gram ID, a trainable embedding is looked up from an embedding table and combined with the input embeddings to produce the output. <ref type="bibr">wal et al. (2019)</ref>, and similar retrieval augmented works such as <ref type="bibr">Lewis et al. (2020)</ref>; <ref type="bibr" target="#b17">Guu et al. (2020)</ref>; <ref type="bibr" target="#b27">Krishna et al. (2021)</ref>. In these retrieval augmented models, the model is conditioned on documents from the training corpus or a knowledge base, with the hope that information from related articles can help improve the factual accuracy of the models.</p><p>Discrete latent models for sequences Discrete latent models using Vector Quantization (VQ) have been widely used in speech <ref type="bibr" target="#b43">(van den Oord et al., 2017;</ref><ref type="bibr" target="#b46">Wang et al., 2018;</ref><ref type="bibr" target="#b37">Schneider et al., 2019)</ref> to learn unsupervised representations of audio signals. Their use for modeling text sequences were studied in <ref type="bibr" target="#b21">Kaiser et al. (2018)</ref>;  where the motivation was to reduce the inference latency for neural machine translation models by decoding in the latent space.</p><p>N-gram models for statistical language modeling N-gram models have a long history in statistical modeling of language, see e.g., <ref type="bibr" target="#b6">Brown et al. (1992</ref><ref type="bibr" target="#b5">Brown et al. ( , 1993</ref>; <ref type="bibr" target="#b22">Katz (1987)</ref>; <ref type="bibr" target="#b25">Kneser and Ney (1995)</ref>; Chen and Goodman <ref type="bibr">(1999)</ref>. Before the advent of word vectors and distributed representations of language via neural networks <ref type="bibr" target="#b31">(Mikolov et al., 2013;</ref><ref type="bibr" target="#b49">Wu et al., 2016)</ref>, n-gram language models were the standard in the field of statistical language modeling. More recent related work on combining neural sequence models with n-gram information is due to <ref type="bibr">Sun and Iyyer (2021)</ref> who propose concatenating the representations within a local context, while <ref type="bibr" target="#b19">Huang et al. (2021)</ref> propose combining RNN models with n-gram embedding tables. Our work differs from them in that we use an n-gram look-up table on a discrete latent representation of the sequence, which leads to a more meaningful assignment of shared n-gram representations.</p><p>Product Quantization There has also been a long line of work on investigating variants of Vector Quantization (VQ) that realize different trade-offs in data compression. The most related work in this domain is due to <ref type="bibr" target="#b20">Jegou et al. (2011)</ref> who introduce a multi-head version of VQ which is termed Product Quantization (PQ). PQ is widely used in computer vision, see e.g., <ref type="bibr" target="#b15">Ge et al. (2013)</ref>; <ref type="bibr" target="#b46">Yu et al. (2018)</ref>. Our approach to learning discrete latent codes use PQ over the attention heads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The N-Grammer layer</head><p>At a high level, we introduce a simple layer that augments the Transformer architecture with more memory based on latent n-grams. While the N-Grammer layer is general enough for considering arbitrary N-grams, we restrict ourselves to the use of bi-grams. We leave the exploration of higherorder n-grams for future work. The layer consists of four core operations: 1. Given a sequence of uni-gram embeddings of a text, infer a sequence of discrete latent representation via PQ.</p><p>2. Infer the bi-gram representation for the latent sequence.</p><p>3. Look up trainable bi-gram embeddings via hashing into the bi-gram vocabulary.</p><p>4. Combine the bi-gram embeddings with the input uni-gram embeddings.</p><p>We describe each of these operations in more detail in the following sections. To refer to a set of discrete items, we use the notation [m] to mean the set {0, 1, ? ? ? , m ? 1}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Discrete latent representation of a sequence</head><p>The first step of the N-Grammer layer is to obtain a parallel sequence of discrete latent representations with Product Quantization (PQ) <ref type="bibr" target="#b20">(Jegou et al., 2011)</ref> by learning a codebook from the given sequence of input embeddings. The input embedding is a sequence of uni-gram embeddings x ? R l?h?d , where l is the length of the sequence, h is the number of heads, and d is the embedding dimension per head. We learn a codebook c in R k?h?d with k code-words with mini-batch k-means <ref type="bibr" target="#b4">(Bottou and Bengio, 1995)</ref>, and in the same step, we form the parallel sequence of discrete latent representation z ? [k] l?h of the sequence x by picking the codebook IDs that have the least distance from the input embeddings:</p><formula xml:id="formula_0">z i,j = argmin l?[k] x i,j ? c l,j 2 .</formula><p>The advantage of this latent representation z is twofold. Firstly, it makes considering all k 2 bigrams tractable by mapping the uni-gram embeddings to share the same code-word embedding based on similarity, thereby allowing us to use a smaller bi-gram embedding table. Secondly, when using a fixed size bi-gram vocabulary, having this latent representation allows for a more efficient representation to be learned compared to directly using the uni-gram IDs. For instance, a uni-gram vocabulary of 32, 000 would entail a bi-gram vocabulary of roughly 1 billion, which adds a significant memory overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Bi-gram IDs from discrete latent representation</head><p>The second step is to convert the discrete latent representation z computed in Section 3.1 to bi-gram IDs b ? [k 2 ] l?h . The latent bi-gram IDs are formed at each position by combining the uni-gram latent IDs z from the previous position as</p><formula xml:id="formula_1">b i = z i if i = 0, z i + kz i?1 otherwise</formula><p>where k is the size of our codebook. This directly maps the discrete latent sequence from a vocabulary space of [k] to the latent bi-gram vocabulary space of [k 2 ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Constructing bi-gram representations</head><p>The third step is to construct bi-gram latent representations b of the sequence. We can consider all k 2 bi-grams and augment the model with an embedding for each such bi-gram. In practice, the compression for machine translation models with a uni-gram vocabulary of 32, 000 involves clustering each token into roughly k = 2 12 clusters without sacrificing quality <ref type="bibr" target="#b21">(Kaiser et al., 2018;</ref>. In this instance, to consider all bi-grams would involve constructing an embedding table with 16 million rows. Since this is still large, we map the latent bi-gram IDs to a smaller bi-gram vocabulary of size v, by using separate hash functions for each head.</p><p>More precisely, we have a latent bi-gram em-</p><formula xml:id="formula_2">bedding table B ? R v?h?d b , where v is the bi- gram vocabulary and d b is the bi-gram embed- ding dimension. The bi-gram embedding y ? R l?h?d b of the text sequence is then constructed as y i,j = B [((r j b i,j + s j ) mod p j ) mod v, j] ,</formula><p>where for each head j, we select a random prime p j greater than k 2 , and r j is chosen randomly in {1, ? ? ? , p?1} and s j is chosen randomly in [p?1]. This scheme is a universal hashing scheme and guarantees a low collision probability for the discrete latent codes of each head <ref type="bibr" target="#b42">(Thorup, 2015)</ref>. Note that the bi-gram embedding vector y i,j is a d b -dimensional vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Combining the embeddings</head><p>The final step is to form a new representation of the text sequence which is derived by combining the uni-gram embedding x ? R l?h?d with the latent bi-gram embedding y ? R l?h?d b obtained in Section 3.3. The bi-gram embedding and uni-gram embedding are both independently layer normalized (LN ), followed by simply concatenating the two along the embedding dimension to produce w = [LN (x), LN (y)] ? R l?h?(d+d b ) which is passed as input to rest of the Transformer network. Note that layer normalization <ref type="bibr">(Ba et al., 2016)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments &amp; Results</head><p>We compare the N-Grammer model with the Transformer architecture <ref type="bibr" target="#b44">(Vaswani et al., 2017)</ref> as well as with the recently proposed Primer architecture (So et al., 2021) on the C4 data-set <ref type="bibr" target="#b34">(Raffel et al., 2019)</ref> 2 . To establish a strong baseline for our experiments we use a Gated Linear Unit <ref type="bibr" target="#b11">(Dauphin et al., 2017)</ref> as the feed-forward network with a GELU activation function <ref type="bibr" target="#b18">(Hendrycks and Gimpel, 2016)</ref> in all our models, except the Primer. The Primer architecture uses a 3 ? 1 depth-wise convolution after the key, query and value projections, and the squared RELU activation function as proposed in <ref type="bibr" target="#b39">So et al. (2021)</ref>. For all experiments, we use the rotary position embedding (RoPE) from <ref type="bibr" target="#b40">Su et al. (2021)</ref>, which greatly improves the quality of all models. We compare the N-Grammer, Primer and Transformer models in <ref type="table">Table 1</ref>. The baseline Transformer model has 16 layers and 8 heads, with a model dimension of 1024. We train all the models with a batch size of 256 and a sequence length of 1024 on a TPU-v3. A more detailed exposition of the various hyper-parameter choices is given in Section 5. For the N-Grammer models, we ablate with different sizes for the bi-gram embedding dimension ranging from 128 to 512. Since adding n-gram embeddings increases the number of trainable parameters, we also train two large baselines in <ref type="table">Table 1</ref> (Transformer-L and Primer-L) which have the same order of parameters as the N-Grammer models. However, unlike the larger Transformer models, the training and inference cost of N-Grammer does not scale proportional to the number of parameters in the n-gram embedding layer, since they rely on sparse look-up operations (see column Inference Ex/sec in <ref type="table">Table 1)</ref>. Thus for example, we find from <ref type="table">Table 1</ref> that the best N-Grammer model with a n-gram vocabulary of 393K and a discrete latent vocabulary of 8K matches the quality of Transformer-L and Primer-L in perplexity (14.79 vs 14.70 vs 15.01) while having significantly higher through-put (356.94 vs 331.12 vs 284.40 examples/sec).</p><p>We also examine a simple version of N-Grammer where we compute the n-grams directly from the uni-gram vocabulary as in Section 3.3 rather than from the latent representation of Section 3.1. This is reported in <ref type="table">Table 1</ref> and corresponds to the N-Grammer without an entry in the clusters column. Note that in this case, the modulo hashing scheme of Section 3.3 is random and independent of the content of the actual uni-gram embeddings. We inspect the individual cluster assignment in Section 10 and find common themes among the groupings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Hyper-parameters for experiments</head><p>In this section we report the hyper-parameter settings for all our experiments for reproducibility purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Optimizer hyper-parameters</head><p>We use the Adam optimizer (Kingma and <ref type="bibr" target="#b24">Ba, 2015)</ref> and tune the learning rate as well as ? as reported in <ref type="bibr" target="#b0">(Agarwal et al., 2020)</ref>. We find that decreasing ? from the standard setting of 10 ?6 to 10 ?10 benefits the Transformer models while having less of an effect on the Primer (So et al., 2021). We use a learning rate of 10 ?3 for all models. We use a ? 1 = 0.9 and ? 2 = 0.99 and clip the gradient norm to 5.0. We do not use any weight decay. We train all models with a global batch size of 256 on a TPU-v3 with 32 cores and a sequence length of 1024.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">N-Grammer hyper-parameters</head><p>For the N-Grammer models, we use a discrete latent vocabulary of k = {4096, 8192} except for the baseline N-Grammer models which directly compute n-grams on the uni-gram vocabulary. For training the n-gram embedding tables we use the Adagrad optimizer <ref type="bibr" target="#b13">(Duchi et al., 2011)</ref>, which is known to be more suitable for learning sparse features. We use a learning rate of 0.1 for training the n-gram embedding table, with the same learning rate schedule as the base model. We find that using a 10? higher or lower learning rate leads to unstable training of the N-Grammer model.</p><p>We train the cluster centers for learning the discrete latent representation using mini-batch kmeans <ref type="bibr" target="#b4">(Bottou and Bengio, 1995)</ref>. We do not use any smoothing or exponential moving averages for either the counts or the centers, since we find empirically that it doesn't help in our setting. We use a learning rate of 10 ?3 for learning the discrete representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Position of the N-Grammer layer</head><p>We perform ablation experiments on the position of the latent N-Grammer layer, since potentially one may add it to any intermediate layer of the network. We take the best N-Grammer model from <ref type="table">Table 1</ref>, corresponding to an n-gram vocabulary size of 393K and a latent vocabulary of size 8K and ablate the position of the N-Grammer layer in <ref type="table">Table 2</ref>. We observe that placing the n-gram layer at the beginning of the network turns out to be the best choice, since moving the layer successively to the end of the network leads to progressively worse performance. We hypothesize that this is due to the presence of fewer attention layers to leverage the improved representations from the ngram embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model PP</head><p>N-Grammer 14.79 N-Grammer begin 14.92 N-Grammer mid 15.13 N-Grammer end 15.17 <ref type="table">Table 2</ref>: Ablation results on the position of the N-Grammer layer on the C4 data-set <ref type="bibr" target="#b34">(Raffel et al., 2019)</ref>. We use the best N-Grammer model from <ref type="table">Table 1</ref>, with a vocab size of 393K. The N-Grammer models labelled begin, middle and end refer to the latent n-gram embedding layer being placed after the first layer, the middle layer and the end layer respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Optimizing through-put</head><p>We note that there is a trade-off in computing the discrete latent representation of a text sequence, where it may be more efficient in practice to cluster the uni-gram vocabulary directly rather than clustering the embedded text sequence. This is an important consideration when serving the N-Grammer model, since the mapping from token to discrete latent is fixed after the completion of training thereby allowing us to pay a one time cost in computing this mapping for the entire vocabulary.</p><p>We formulate this more precisely as follows. Let the uni-gram vocabulary be v, the latent vocabulary k, the sequence length l, batch size b, and let the N-Grammer model serve a total of m examples. If we were to compute the latent representation for each sequence, we incur a cost of O(bkl) per sequence. On the other hand, if we were to compute the latent representation for the entire vocabulary up-front and cache the mapping from token to latent, we pay a one time cost of O(vk) for inferring the latent representations. Assuming an O(1) cost of looking up the latent representation per sequence, this cost can be amortized over the m examples to get a per sequence cost of O(vk/m + 1). As m ? ?, i.e., the model is continuously deployed, we essentially get to compute the discrete latent representation in constant time per sequence during serving.</p><p>Since computing the n-gram ID (see Section 3.2) and retrieving the n-gram representations are also constant (with respect to the number of attention layers, attention heads and model dimension) time operations per sequence, this implies that when served long enough, the N-Grammer model essentially incurs a constant overhead over the Transformer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Convergence comparisons</head><p>We have included training curve comparisons of the N-Grammer with that of the Transformer <ref type="bibr" target="#b44">(Vaswani et al., 2017)</ref> and the Primer <ref type="bibr" target="#b39">(So et al., 2021)</ref>. We compare the three models in <ref type="figure">Figures 2a and 2b</ref> where the x-axis denotes the wall clock time on a TPU-v3 while the y-axis denotes the log perplexity and top-1 accuracy respectively on the C4 dataset <ref type="bibr" target="#b34">(Raffel et al., 2019)</ref>. From <ref type="figure">Figure 2</ref> we see that the N-Grammer model is roughly 2? faster than the Primer in wall clock time to reach the same perplexity or accuracy. More precisely, the baseline Primer model after 1M steps (180 TPU hours) has a perplexity of 15.10, which the best N-Grammer model from <ref type="table">Table 1</ref> achieves at 465K steps (90 TPU hours).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Comparison on downstream tasks</head><p>We fine-tune the baseline Transformer, Primer (as well as their large variants) and the best N-Grammer model from <ref type="table">Table 1</ref> on the SuperGLUE benchmark <ref type="bibr" target="#b45">(Wang et al., 2019)</ref> to evaluate whether the perplexity gains of the N-Grammer model also result in downstream classification gains. For all models we take the checkpoint at 1M steps, and fine-tune for 100K steps with a constant learning rate of 10 ?4 . We report the downstream evaluation metrics in <ref type="table" target="#tab_3">Table 3</ref>. From <ref type="table" target="#tab_3">Table 3</ref> we observe that the N-Grammer improves on the quality of the Transformer and Primer models on most Super-GLUE tasks. More surprisingly, we see that it also substantially improves on the larger Transformer-L and Primer-L models on tasks like COPA, RTE, WiC and WSC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="10">Analysis of the latent representations</head><p>We inspect the discrete latent representations learned by the N-Grammer layer by examining the different uni-gram tokens that are assigned to the same cluster ID. We take a trained N-Grammer model with 8192 clusters, n-gram embedding dimension of 16 and n-gram vocabulary of 196K. We pass the entire set of 32, 000 uni-gram embeddings as input to the N-Grammer layer, thereby gathering the cluster assignment of every uni-gram token. We present some of these in <ref type="table">Table 4</ref>, where we find that the model learns to group related uni-gram tokens together:</p><p>1. the cluster with head ID 0 and cluster ID 6259 corresponds to sports and games, 2. the cluster with head ID 2 and cluster ID 5362 corresponds to places, 3. the cluster with head ID 0 and cluster ID 7468 corresponds to animals and fruits, 4. the cluster with head ID 2 and cluster ID 8080 corresponds to the arts, 5. the cluster with head ID 4 and cluster ID 6618 also corresponds to the arts.</p><p>We also observe that several heads independently learn a similar themed grouping, e.g., head 2 and 4 both have a cluster dedicated to arts and entertainment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="11">Conclusion</head><p>We introduced the N-Grammer layer for augmenting the Transformer architecture with latent ngrams, and find that it can match a larger Transformer and Primer in quality while being significantly faster in inference. The N-Grammer architecture is particularly suitable for devices that allow storing large embedding tables while supporting only distributed gather-scatter operations. We also showed that by caching the mapping from token to discrete latent, one can serve the N-Grammer architecture with only a constant overhead over the Transformer. This makes the N-Grammer attractive for deployment, since on most hardware platforms sparse operations such as an embedding look-up is significantly faster than dense operations such as matrix multiplications.    <ref type="table">Table 4</ref>: Mapping of uni-gram tokens to cluster IDs for the N-Grammer model. The N-Grammer model has 8 heads, 8192 clusters, an n-gram embedding dimension of 16 and a n-gram vocabulary of 196K. We report the head index (Head ID), the cluster index (Cluster ID) and the uni-gram tokens assigned to those IDs for a random subset of clusters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Log perplexity vs wall-clock time on TPU-v3 Top-1 accuracy vs wall-clock time on TPU-v3 Figure 2: Wall-clock time comparisons between Transformer with Gated GELU, Primer and N-Grammer on the C4 data-set (Raffel et al., 2019).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Fine-tuning results on SuperGLUE<ref type="bibr" target="#b45">(Wang et al., 2019)</ref> comparing the Transformer, Primer and the best N-Grammer model fromTable 1. The N-Grammer model has a discrete latent vocabulary of size 8K and a n-gram vocabulary of size 393K. For all models we take the pre-trained checkpoint at 1M steps and fine-tune for100Ksteps with a constant learning rate of 10 ?4 . Shut, coconut, grapefruit, cran, Kami, moon, spider, yogurt, perfume, Wine, Skate, antique, snail, Onion, guinea, puppy, mineral, Reagan, elbow, bark, patio, beneath, snake, lever, bunny, falcon, rail, ribbon, knob, apples, quarry, corn, nach, hiking, invoice, Pour, flora, fishing, Paint, olive, violin, octopus, horizontal, blanket, circular, army, nickel, cattle, potato, dolphin, mosquito, citrus, shutter 2 8080 Knicks, Shakespeare, SPE, nursing, spells, Alexa, arrow, vocalist, rehearsal, tunnel, eine, Critical, clar, BAN, remix, obstacle, musicians, BRO, legislature, EMS, Manga, piano, sword, vocal, bald, choir, Messi, Beta, cad, illustrator, organ, conjunction, lunar, bien, needles, musician, hiking, tad, poe, Pay, violin, Marxist, literary, Theater, gig, poetry, Illustrator, guitar, Pluto, Camaro, Fog, orbit, dancing, epub 4 6618 Wise, vocalist, actor, cheek, musicians, TION, piano, tunes, choir, filmmaker, musician, Suzuki, violin, Theater, gig, Drama, guitar, logic, Entertainment</figDesc><table><row><cell>Head ID</cell><cell>Cluster ID</cell><cell>Uni-gram Tokens</cell></row><row><cell>0</cell><cell>6259</cell><cell>Baseball, football, ceramic, Galaxy, hockey, basket-</cell></row><row><cell></cell><cell></cell><cell>ball, Cricket, Basketball, guitar, acquisition, athlete,</cell></row><row><cell></cell><cell></cell><cell>Soccer, Squid, sports</cell></row><row><cell>2</cell><cell>5362</cell><cell>Alchemist, Vegas, hanger, Seinfeld, Kenya, Heroic,</cell></row><row><cell></cell><cell></cell><cell>Kurdish, Rodgers, Bolivia, Venom, Qatar, dosage, Ar-</cell></row><row><cell></cell><cell></cell><cell>cade, Emperor, becua, Finnish, Taiwanese, Chennai,</cell></row><row><cell></cell><cell></cell><cell>hood, dub, flake, Balkan, Psalm, Bueno, Moldova,</cell></row><row><cell></cell><cell></cell><cell>flow, mosquito, Filipino, Throne, Siberia, Trout, Fist,</cell></row><row><cell></cell><cell></cell><cell>Czech, Boulevard, Azerbaijan, Peru, OW, plaster,</cell></row><row><cell></cell><cell></cell><cell>Kashmir, NZ, Priest, Palestinian, Tibetan, stencil,</cell></row><row><cell></cell><cell></cell><cell>Aragon, coils, HBO, Iceland, strains, Zimbabwe, fire-</cell></row><row><cell></cell><cell></cell><cell>wall, Nepal, Elves, Iranian, Mongol, Traffic, Camilla,</cell></row><row><cell></cell><cell></cell><cell>parade, Afghan, hose, Serpent, Tarantino, web, Khal,</cell></row><row><cell></cell><cell></cell><cell>Squid, Mala, Syrian, hood</cell></row><row><cell>0</cell><cell>7468</cell><cell>Unknown, spoon,</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.tensorflow.org/datasets/ catalog/c4</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomer</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cyril</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.11803</idno>
		<title level="m">Disentangling adaptive gradient methods from learning rates</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Ontanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vaclav</forename><surname>Cvicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Ravula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Sanghai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08483</idno>
		<title level="m">Etc: Encoding long and structured inputs in transformers</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint/>
	</monogr>
	<note type="report_type">ton. 2016. Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Convergence properties of the k-means algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="585" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The mathematics of statistical machine translation: Parameter estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen A Della</forename><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert L</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="311" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Classbased n-gram models of natural language</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent J Della</forename><surname>Peter F Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">C</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="480" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Tom B Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Askell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.14165</idno>
		<title level="m">Language models are few-shot learners</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An empirical study of smoothing techniques for language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="359" to="394" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caglar</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1724" to="1734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gon?alo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Correia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.00015</idno>
		<title level="m">Vlad Niculae, and Andr? FT Martins. 2019. Adaptively sparse transformers</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Language modeling with gated convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grangier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="933" to="941" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL-HLT</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptive subgradient methods for online learning and stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Hazan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.03961</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Optimized product quantization for approximate nearest neighbor search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiezheng</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifa</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2946" to="2953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
		<title level="m">Neural turing machines</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zora</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08909</idno>
		<title level="m">Realm: Retrievalaugmented language model pre-training</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.08415</idno>
		<title level="m">Gaussian error linear units (gelus)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Lookup-table recurrent language models for long tail speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronny</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cal</forename><surname>Peyser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shankar</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Rybach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Strohman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.04552</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Product quantization for nearest neighbor search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Jegou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Fast decoding in sequence models using discrete latent variables</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Pamar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.03382</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Estimation of probabilities from sparse data for the language model component of a speech recognizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Slava</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on acoustics, speech, and signal processing</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="401" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urvashi</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.00172</idno>
		<title level="m">Generalization through memorization: Nearest neighbor language models</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Improved backing-off for m-gram language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Kneser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1995 international conference on acoustics, speech, and signal processing</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="181" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Hurdles to progress in long-form question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalpesh</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.06332</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.05242</idno>
		<title level="m">Large memory layers with product keys</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Lepikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyoukjoong</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanzhong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dehao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanping</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.16668</idno>
		<title level="m">Gshard: Scaling giant models with conditional computation and automatic sharding</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heinrich</forename><surname>K?ttler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.11401</idno>
		<title level="m">Tim Rockt?schel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sketch based memory for neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rina</forename><surname>Panigrahy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">In International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3169" to="3177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pre-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<ptr target="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/languageunsupervised/languageunderstand-ingpaper.pdf" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10683</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Efficient content-based sparse attention with routing transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Saffar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="53" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurko</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.11063</idno>
		<title level="m">Theory and experiments on vector quantized autoencoders</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.05862</idno>
		<title level="m">wav2vec: Unsupervised pre-training for speech recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Outrageously large neural networks: The sparsely-gated mixture-of-experts layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azalia</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Maziarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06538</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Primer: Searching for efficient transformers for language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>David R So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Ma?ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.08668</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Roformer: Enhanced transformer with rotary position embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlin</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengfeng</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfeng</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.09864</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<idno type="arXiv">arXiv:2104.03474</idno>
		<title level="m">Simeng Sun and Mohit Iyyer. 2021. Revisiting simple neural probabilistic language models</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikkel</forename><surname>Thorup</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1504.06804</idno>
		<title level="m">High speed hashing for integers and strings</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Neural discrete representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A?ron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<idno>abs/1711.00937</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Superglue: A stickier benchmark for general-purpose language understanding systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yada</forename><surname>Pruksachatkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Style tokens: Unsupervised style modeling, control and transfer in end-to-end speech synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daisy</forename><surname>Stanton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rj-Skerry</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Battenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Shor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rif A</forename><surname>Saurous</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5180" to="5189" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1410.3916</idno>
		<imprint/>
	</monogr>
	<note type="report_type">Bordes. 2014. Memory networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiping</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengchen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.15808</idno>
		<title level="m">Cvt: Introducing convolutions to vision transformers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
	</analytic>
	<monogr>
		<title level="m">Bridging the gap between human and machine translation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Product quantization network for fast image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailin</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="186" to="201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Big bird: Transformers for longer sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guru</forename><surname>Guruganesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Kumar Avinava Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Alberti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Ontanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qifan</forename><surname>Ravula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
