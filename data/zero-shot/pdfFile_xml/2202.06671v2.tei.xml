<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Ostendorff</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DFKI GmbH</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of G?ttingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Rethmeier</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DFKI GmbH</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bela</forename><surname>Gipp</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of G?ttingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Rehm</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DFKI GmbH</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning scientific document representations can be substantially improved through contrastive learning objectives, where the challenge lies in creating positive and negative training samples that encode the desired similarity semantics. Prior work relies on discrete citation relations to generate contrast samples. However, discrete citations enforce a hard cutoff to similarity. This is counter-intuitive to similarity-based learning and ignores that scientific papers can be very similar despite lacking a direct citation -a core problem of finding related research. Instead, we use controlled nearest neighbor sampling over citation graph embeddings for contrastive learning. This control allows us to learn continuous similarity, to sample hard-to-learn negatives and positives, and also to avoid collisions between negative and positive samples by controlling the sampling margin between them. The resulting method SciNCL outperforms the state-of-theart on the SciDocs benchmark. Furthermore, we demonstrate that it can train (or tune) language models sample-efficiently and that it can be combined with recent training-efficient methods. Perhaps surprisingly, even training a general-domain language model this way outperforms baselines pretrained in-domain.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Large pretrained language models (LLMs) achieve state-of-the-art results through fine-tuning on many NLP tasks <ref type="bibr" target="#b14">(Rogers et al., 2020)</ref>. However, the sentence or document embeddings derived from LLMs are of lesser quality compared to simple baselines like GloVe <ref type="bibr" target="#b11">(Reimers and Gurevych, 2019)</ref>, as their embedding space suffers from being anisotropic, i.e. poorly defined in some areas <ref type="bibr" target="#b34">(Li et al., 2020)</ref>.</p><p>One approach that has recently gained attention is the combination of LLMs with contrastive finetuning to improve the semantic textual similarity between document representations <ref type="bibr" target="#b33">(Wu et al., 2020;</ref><ref type="bibr" target="#b32">Gao et al., 2021)</ref>. These contrastive methods learn sample induced margin easy negatives <ref type="figure">Figure 1</ref>: Starting from a query paper in a citation graph embedding space. Hard positives are citation graph embeddings that are sampled from a similar (close) context of , but are not so close that their gradients collapse easily. Hard (to classify) negatives (red band) are close to positives (green band) up to a sampling induced margin. Easy negatives are very dissimilar (distant) from the query paper . to distinguish between pairs of similar and dissimilar texts (positive and negative samples). As recent works show <ref type="bibr" target="#b23">(Tian et al., 2020b;</ref><ref type="bibr">Augenstein, 2022, 2021;</ref><ref type="bibr" target="#b17">Shorten et al., 2021)</ref>, the selection of these positive and negative samples is crucial for efficient contrastive learning. This paper focusses on learning scientific document representations (SDRs). The core distinguishing feature of this domain is the presence of citation information that complement the textual information. The current state-of-the-art SPECTER by <ref type="bibr" target="#b25">Cohan et al. (2020)</ref> uses citation information to generate positive and negative samples for contrastive fine-tuning of a SciBERT language model <ref type="bibr" target="#b0">(Beltagy et al., 2019)</ref>. SPECTER relies on 'citations by the query paper' as a discrete signal for similarity, i.e., positive samples are cited by the query while negative ones are not cited.</p><p>However, SPECTER's use of citations has its pitfalls. Considering only one citation direction may cause positive and negative samples to collide since a paper pair could be treated as a positive and negative instance simultaneously. Also, relying on a single citation as a discrete similarity signal is subject to noise, e.g., citations may reflect politeness and policy rather than semantic similarity <ref type="bibr" target="#b8">(Pasternack, 1969)</ref> or related papers lack a direct citation <ref type="bibr">(Gipp and Beel, 2009</ref>). This discrete cutoff to similarity is counter-intuitive to (continuous) similarity-based learning. Instead, the generation of non-colliding contrastive samples should be based on a continuous similarity function that allows us to find semantically similar papers, even without direct citations. With SciNCL, we address these issues by generating contrastive samples based on citation embeddings. The citation embeddings, which incorporate the full citation graph, provide a continuous, undirected, and less noisy similarity signal that allows the generations of arbitrary difficult-to-learn positive and negative samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contributions:</head><p>? We propose neighborhood contrastive learning for scientific document representations with citation graph embeddings (SciNCL) based on contrastive learning theory insights. ? We sample positive (similar) and negative (dissimilar) papers from the k nearest neighbors in the citation graph embedding space, such that positives and negatives do not collide but are also hard to learn. ? We compare against the state-of-the-art approach SPECTER <ref type="bibr" target="#b25">(Cohan et al., 2020)</ref> and other strong methods on the SCIDOCS benchmark and find that SciNCL outperforms SPECTER on average and on 9 of 12 metrics. ? Finally, we demonstrate that with SciNCL, using only 1% of the triplets for training, starting with a general-domain language model, or training only the bias terms of the model is sufficient to outperform the baselines. ? Our code and models are publicly available. 1 2 Related Work Contrastive Learning pulls representations of similar data points (positives) closer together, while representations of dissimilar documents (negatives) are pushed apart. A common contrastive objective 1 https://github.com/malteos/scincl is the triplet loss <ref type="bibr" target="#b16">(Schroff et al., 2015)</ref> that <ref type="bibr" target="#b25">Cohan et al. (2020)</ref> used for scientific document representation learning, as we describe below. However, as <ref type="bibr" target="#b6">Musgrave et al. (2020)</ref> and <ref type="bibr">Rethmeier and Augenstein (2022)</ref> point out, contrastive objectives work best when specific requirements are respected. (Req. 1) Views of the same data should introduce new information, i.e. the mutual information between views should be minimized <ref type="bibr" target="#b23">(Tian et al., 2020b)</ref>. We use citation graph embeddings to generate contrast label information that supplements text-based similarity. (Req. 2) For training time and sample efficiency, negative samples should be hard to classify, but should also not collide with positives <ref type="bibr" target="#b15">(Saunshi et al., 2019)</ref>. (Req. 3) Recent works like <ref type="bibr" target="#b6">Musgrave et al. (2020)</ref> and <ref type="bibr">Khosla et al. (2020)</ref> use multiple positives. However, positives need to be consistently close to each other <ref type="bibr" target="#b26">(Wang and Isola, 2020)</ref>, since positives and negatives may otherwise collide, e.g., <ref type="bibr" target="#b25">Cohan et al. (2020)</ref> consider only 'citations by the query' as similarity signal and not 'citations to the query'. Such unidirectional similarity does not guarantee that a negative paper (not cited by the query) may cite the query paper and thus could cause collisions, the more we sample (Appendix F.10). Our method treats both citing and being cited as positives (Req. 2), while it also generates hard negatives and hard positives (Req. 2+3). Hard negatives are close to but do not overlap positives (red band in <ref type="figure">Fig. 1</ref>). Hard positives are close, but not trivially close to the query document (green band in <ref type="figure">Fig. 1</ref>). The sample induced margin (space between red and green band in <ref type="figure">Fig. 1</ref>) ensures that contrast samples do not collide.</p><p>Triplet Mining remains a challenge in NLP due to the discrete nature of language which makes data augmentation less trivial as compared to computer vision <ref type="bibr" target="#b32">(Gao et al., 2021)</ref>. Examples for augmentation strategies are translation, word deletion, or word reordering <ref type="bibr">(Fang et al., 2020;</ref><ref type="bibr" target="#b33">Wu et al., 2020)</ref>. Positives and negatives can be sampled based on the sentence position within a document <ref type="bibr">(Giorgi et al., 2021)</ref>. <ref type="bibr" target="#b32">Gao et al. (2021)</ref>   <ref type="bibr" target="#b24">(Vaswani et al., 2017)</ref> and pretrained on domain-specific text dominate today's scientific document processing. There are SciBERT <ref type="bibr" target="#b0">(Beltagy et al., 2019)</ref>, <ref type="bibr">BioBERT (Lee et al., 2019) and</ref><ref type="bibr">SciGPT2 (Luu et al., 2021)</ref>, to name a few. Recent works modify these domain LLMs to support cite-worthiness detection <ref type="bibr" target="#b29">(Wright and Augenstein, 2021)</ref>, document similarity  or fact checking <ref type="bibr" target="#b25">(Wadden et al., 2020)</ref>.</p><p>Aside from text, citations are a valuable signal for the similarity of research papers. Paper (node) representations can be learned using the citation graph <ref type="bibr" target="#b31">(Wu et al., 2019;</ref><ref type="bibr" target="#b9">Perozzi et al., 2014;</ref><ref type="bibr">Grover and Leskovec, 2016)</ref>. Especially for recommendations of papers or citations, hybrid combinations of text and citation features are often employed <ref type="bibr">(Han et al., 2018;</ref><ref type="bibr">Jeong et al., 2020;</ref><ref type="bibr" target="#b3">Brochier et al., 2019;</ref><ref type="bibr">Holm et al., 2022)</ref>.</p><p>Closest to SciNCL are Citeomatic <ref type="bibr" target="#b2">(Bhagavatula et al., 2018)</ref> and <ref type="bibr">SPECTER (Cohan et al., 2020)</ref>. While Citeomatic relies on bag-of-words for its textual features, SPECTER is based on SciBERT. Both leverage citations to learn a triplet-based document embedding model, whereby positive samples are papers cited in the query. Easy negatives are random papers not cited by the query. Hard negatives are citations of citations -papers referenced in positive citations of the query, but are not cited directly by it. Citeomatic also uses a second type of hard negatives, which are the nearest neighbors of a query that are not cited by it.</p><p>Unlike our approach, Citeomatic does not use the neighborhood of citation embeddings, but instead relies on the actual document embeddings from the previous epoch. Despite being related to SciNCL, the sampling approaches employed in Citeomatic and SPECTER do not account for the pitfalls of using discrete citations as signal for paper similarity. Our work addresses this issue.</p><p>Cross-Modal Transfer. SciNCL transfers knowledge across modalities, i.e., from citations into a language model. According to <ref type="bibr" target="#b25">Cohan et al. (2020)</ref>, SciNCL can be considered as a "citation-informed Transformer". This cross-modal transfer learning is applied for various modalities (see <ref type="bibr">Kaur et al. (2021)</ref> for an overview): text-toimage <ref type="bibr" target="#b20">(Socher et al., 2013)</ref>, RGB-to-depth image <ref type="bibr" target="#b22">(Tian et al., 2020a)</ref>, or graph-to-image <ref type="bibr" target="#b27">(Wang et al., 2018)</ref>. While the aforementioned methods incorporate cross-modal knowledge through joint loss functions or latent representations, SciNCL transfers knowledge through the contrastive sample selection, which we found superior to the direct transfer approach (Appendix F.9).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>Our goal is to learn citation-informed representations for scientific documents. To do so we sample three document representation vectors and learn their similarity. For a given query paper vector d Q , we sample a positive (similar) paper vector d + and a negative (dissimilar) paper vector d ? . This produces a 'query, positive, negative' triplet (d Q , d + , d ? ) -represented by <ref type="bibr">( , , )</ref> in <ref type="figure">Fig. 1</ref>. To learn paper similarity, we need to define three components: ( ?3.1) how to calculate document vectors d for the loss over triplets L; ( ?3.2) how citations provide similarity between papers; and ( ?3.3) how negative and positive papers (d ? , d + ) are sampled as (dis-)similar documents from the neighborhood of a query paper d Q .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Contrastive Learning Objective</head><p>Given the textual content of a document d (paper), the goal is to derive a dense vector representation d that best encodes the document information and can be used in downstream tasks. A Transformer language model f (SciBERT; <ref type="bibr" target="#b0">Beltagy et al. (2019)</ref>) encodes documents d into vector representations f (d) = d. The input to the language model is the title and abstract separated by the [SEP] token. <ref type="bibr">2</ref> The final layer hidden state of the [CLS] token is then used as a document representation f (d) = d.</p><p>Training with a masked language modeling objectives alone has been shown to produce suboptimal document representations <ref type="bibr" target="#b34">(Li et al., 2020;</ref><ref type="bibr" target="#b32">Gao et al., 2021)</ref>. Thus, similar to the SDR stateof-the-art method SPECTER (Cohan et al., 2020), we continue training the SciBERT model <ref type="bibr" target="#b0">(Beltagy et al., 2019)</ref> using a self-supervised triplet margin loss <ref type="bibr" target="#b16">(Schroff et al., 2015)</ref>:</p><formula xml:id="formula_0">L = max d Q ?d + 2 ? d Q ?d ? 2 +?, 0</formula><p>Here, ? is a slack term (? = 1 as in SPECTER) and ?d 2 is the L 2 norm, used as a distance function. However, the SPECTER sampling method has significant drawbacks. We will describe these issues and our contrastive learning theory guided improvements in detail below in ?3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Citation Neighborhood Sampling</head><p>Compared to the textual content of a paper, citations provide an outside view on a paper and its relation to the scientific literature <ref type="bibr">(Elkiss et al., 2008)</ref>, which is why citations are traditionally used as a similarity measure in library science <ref type="bibr">(Kessler, 1963;</ref><ref type="bibr" target="#b19">Small, 1973)</ref>. However, using citations as a discrete similarity signal, as done in <ref type="bibr" target="#b25">Cohan et al. (2020)</ref>, has its pitfalls. Their method defines papers cited by the query as positives, while paper citing the query could be treated as negatives. This means that positive and negative learning information collides between citation directions, which <ref type="bibr" target="#b15">Saunshi et al. (2019)</ref> have shown to deteriorate performance. Furthermore, a cited paper can have a low similarity with the citing paper given the many motivations a citation can have <ref type="bibr" target="#b21">(Teufel et al., 2006)</ref>. Likewise, a similar paper might not be cited.</p><p>To overcome these limitations, we learn citation embeddings first and then use the citation neighborhood around a given query paper d Q to construct similar (positive) and dissimilar (negative) samples for contrast by using the k nearest neighbors. This builds on the intuition that nodes connected by edges should be close to each other in the embedding space <ref type="bibr" target="#b9">(Perozzi et al., 2014)</ref>. Using citation embeddings allows us to: (1) sample paper similarity on a continuous scale, which makes it possible to: (2) define hard to learn positives, as well as (3) hard or easy to learn negatives. Points (2-3) are important in making contrastive learning efficient as will describe below in ?3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Positives and Negatives Sampling</head><p>Positive samples: d + should be semantically similar to the query paper d Q , i.e. sampled close to the query embedding d Q . Additionally, as <ref type="bibr" target="#b26">Wang and Isola (2020)</ref> find, positives should be sampled from comparable locations (distances from the query) in embedding space and be dissimilar enough from the query embedding, to avoid gradient collapse (zero gradients). Therefore, we sample c + positive (similar) papers from a close neighborhood around query embedding d Q (k + ? c + , k + ], i.e. the green band in <ref type="figure">Fig. 1</ref>. When sampling with KNN search, we use a small k + to find positives and later analyze the impact of k + in <ref type="figure" target="#fig_0">Fig. 2</ref>.</p><p>Negative samples: can be divided into easy and hard negative samples (light and dark red in <ref type="figure">Fig. 1</ref>). Sampling more hard negatives is known to improve contrastive learning <ref type="bibr" target="#b4">(Bucher et al., 2016;</ref><ref type="bibr" target="#b30">Wu et al., 2017)</ref>. However, we make sure to sample hard negatives (red band in <ref type="figure">Fig. 1</ref>) such that they are close to potential positives but do not collide with positives (green band), by using a tunable 'sampling induced margin'. We do so, since <ref type="bibr" target="#b15">Saunshi et al. (2019)</ref> showed that sampling a larger number of hard negatives only improves performance if the negatives do not collide with positive samples, since collisions make the learning signal noisy. That is, in the margin between hard negatives and positives we expect positives and negatives to collide, thus we avoid sampling from this region. To generate a diverse self-supervised citation similarity signal for contrastive SDR learning, we also sample easy negatives that are farther from the query than hard negatives. For negatives, the k ? should be large when sampling via KNN to ensure samples are dissimilar from the query paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Sampling Strategies</head><p>As described in ?3.2 and ?3.3, our approach improves upon the method by <ref type="bibr" target="#b25">Cohan et al. (2020)</ref>. Therefore, we reuse their sampling parameters (5 triplets per query paper) and then further optimize our methods' hyperparameters. For example, to train the triplet loss, we generate the same amount of (d Q , d + , d ? ) triplets per query paper as SPECTER <ref type="bibr" target="#b25">(Cohan et al., 2020)</ref>. To be precise, this means we generate c + =5 positives (as explained in ?3.3). We also generate 5 negatives, three easy negatives c ? easy =3 and two hard negatives c ? hard =2, as described in ?3.3.</p><p>Below, we describe three strategies (I-III) for sampling triplets. These either sample neighboring papers from citation embeddings (I), by random sampling (II), or using both strategies (III). For each strategy, let c be the number of samples for either positives c + , easy negatives c ? easy , or hard negatives c ? hard .  <ref type="formula" target="#formula_3">(2019)</ref>, but given more computational resources, careful tuning may produce even better-performing embeddings. Nonetheless, we conducted a narrow parameter search based on link prediction -see Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Citation Graph</head><p>(I) K-nearest neighbors (KNN): Assuming a given citation embedding model f c and a search index (e.g., FAISS ?4.3), we run KN N (f c (d Q ), C) and take c samples from a range of the (k ? c , k] nearest neighbors around the query paper d Q with its neighbors N ={n 1 , n 2 , n 3 , . . . }, whereby neighbor n i is the i-th nearest neighbor in the citation embedding space. For instance, for c =3 and k=10 the corresponding samples would be the three neighbors descending from the tenth neighbor: n 8 , n 9 , and n 10 . To reduce computing effort, we sample the neighbors N only once via [0; max(k + , k ? hard )], and then generate triplets by range-selection in N ; i.e. positives = (k + ? c + ; k + ], and hard negatives</p><formula xml:id="formula_1">= (k ? hard ? c ? hard ; k ? hard ].</formula><p>(II) Random sampling: Sample any c papers without replacement from the corpus.</p><p>(III) Filtered random: Like (II) but excluding the papers that are retrieved by <ref type="bibr">KNN,</ref> i.e., all neighbors within the largest k are excluded. This is analog to SPECTER's approach of selecting random candidates that are not cited by the query.</p><p>The KNN sampling introduces the hyperparameter k that allows for the controlled sampling of positives or negatives with different difficulty (from easy to hard depending on k). Specifically, in <ref type="figure">Fig. 1</ref> the hyperparameter k defines the tunable sample induced margin between positives and negatives, as well as the width and position of the positive sample band (green) and negative sample band (red) around the query sample. Besides the strategies above, we experiment with similarity threshold, k-means clustering and sorted random sampling, neither of which performs well (Appendix F).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In the following, we introduce our experiments including the data sets and implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Dataset</head><p>We evaluate on the SCIDOCS benchmark <ref type="bibr" target="#b25">(Cohan et al., 2020)</ref>. A key difference to other benchmarks is that embeddings are the input to the individual tasks without explicit fine-tuning. The SCIDOCS benchmark consists of the following four tasks:</p><p>Document classification (CLS) with Medical Subject Headings (MeSH) <ref type="bibr">(Lipscomb, 2000)</ref> and Microsoft Academic Graph labels (MAG) <ref type="bibr" target="#b18">(Sinha et al., 2015)</ref>. Co-views and co-reads (USR) prediction based on the L2 distance between embeddings. Direct and co-citation (CITE) prediction based on the L2 distance between the embeddings. Recommendations (REC) generation based on embeddings and paper metadata.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Datasets</head><p>The experiments mainly compare SciNCL against SPECTER on the SCIDOCS benchmark. However, we found 40.5% of SCIDOCS's papers leaking into SPECTER's training data (the leakage affects only the unsupervised paper data but not the gold labels -see Appendix B). To be transparent about this leakage, we train SciNCL on two datasets: SPECTER replication (w/ leakage): We replicate SPECTER's training data including its leakage. Unfortunately, SPECTER provides neither citation data nor a mapping to S2ORC, which our citation embeddings are based on. We successfully map 96.2% of SPECTER's query papers and 83.3% of the corpus from which positives and negatives are sampled to S2ORC. To account for the missing papers, we randomly sample papers from S2ORC (without the SCIDOCS papers) such that the absolute number of papers is identical with SPECTER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S2ORC subset (w/o leakage):</head><p>We select a random subset from S2ORC that does not contain any of the mapped SCIDOCS papers. This avoids SPECTER's leakage, but also makes the scores reported in Cohan et al. (2020) less comparable. We successfully map 98.6% of the SCIDOCS papers to S2ORC. Thus, only the remaining 1.4% of the SCIDOCS papers could leak into this training set.</p><p>The details of the dataset creation are described in Appendix A and C. Both training sets yield 684K triplets (same count as SPECTER). Also, the ratio of training triplets per query remains the same ( ?3.4). Our citation embedding model is trained on the S2ORC citation graph. In w/ leakage, we include all SPECTER papers even if they are part of SCIDOCS, the remaining SCIDOCS papers are excluded (52.5 nodes and 463M edges). In w/o leakage, all mapped SCIDOCS papers are excluded (52.4M nodes and 447M edges) such that we avoid leakage also for the citation embedding model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Training and Implementation</head><p>We replicate the training setup from SPECTER as closely as possible. We implement SciNCL using Huggingface Transformers <ref type="bibr">(Wolf et al., 2020)</ref>, initialize the model with SciBERT's weights <ref type="bibr" target="#b0">(Beltagy et al., 2019)</ref>, and train via the triplet loss (Equation 3.1). The optimizer is Adam with weight decay <ref type="bibr">(Kingma and Ba, 2015;</ref><ref type="bibr">Loshchilov and Hutter, 2019)</ref> and learning rate ?=2 ?5 . To explore the effect of computing efficient fine-tuning we also train a BitFit model <ref type="bibr" target="#b1">(Ben Zaken et al., 2022)</ref> with ?=1 ?4 ( ?7.2). We train SciNCL on two NVIDIA GeForce RTX 6000 (24G) for 2 epochs (approx. 24 hours of training time) with batch size 8 and gradient accumulation for an effective batch size of 32 (same as SPECTER). The graph embedding training is performed on an Intel Xeon Gold 6230 CPU with 60 cores and takes approx. 6 hours. The KNN strategy is implemented with FAISS (Johnson et al., 2021) using a flat index (exhaustive search) and takes less than 30min for indexing and retrieval of the triplets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Baseline Methods</head><p>We compare against the following baselines (details in Appendix E): <ref type="bibr">USE (Cer et al., 2018)</ref>, <ref type="bibr">BERT (Devlin et al., 2019)</ref>, <ref type="bibr">BioBERT (Lee et al., 2019)</ref>, SciBERT <ref type="bibr" target="#b0">(Beltagy et al., 2019)</ref>, CiteBERT <ref type="bibr" target="#b29">(Wright and Augenstein, 2021)</ref>, <ref type="bibr">DeCLUTR (Giorgi et al., 2021)</ref>, the graph-convolution approach SGC <ref type="bibr" target="#b31">(Wu et al., 2019)</ref>, Citeomatic <ref type="bibr" target="#b2">(Bhagavatula et al., 2018)</ref>, and SPECTER <ref type="bibr" target="#b25">(Cohan et al., 2020)</ref>.</p><p>Also, we compare against Oracle SciDocs which is identical to SciNCL except that its triplets are generated based on SCIDOCS's validation and test set using their gold labels. For example, papers with the same MAG labels are positives and papers with different labels are negatives. Similarly, the ground truth of the other tasks is used, i.e., clicked recommendations are considered as positives etc. In total, this procedure creates 106K training triplets for Oracle SciDocs. Moreover, we under-sample triplets from the classification tasks to ensure a balanced triplet distribution over the tasks. Accordingly, Oracle SciDocs represents an estimate for the performance upper bound that can be achieved with the current setting (triplet margin loss and SciBERT encoder).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Overall Results</head><p>Tab. 1 shows the results, comparing SciNCL with the best validation performance against the baselines. With replicated SPECTER training data (w/ leakage), SciNCL achieves an average performance of 81.8 across all metrics, which is a 1.8 point absolute improvement over SPECTER (the next-best baseline). When trained without leakage, the improvement of SciNCL over SPECTER is consistent with 1.7 points but generally lower (79.4 avg. score). In the following, we refer to the results obtained through training on the replicated SPECTER data (w/ leakage) if not otherwise mentioned.</p><p>We find the best validation performance based on SPECTER's data when positives and hard negative are sampled with KNN, whereby positives are k + =25, and hard negatives are k ? hard =4000 ( ?6). Easy negatives are generated through filtered random sampling. SciNCL's scores are reported as mean over ten random seeds (seed ? [0, 9]).</p><p>For MAG classification, SPECTER achieves the best result with 82.0 F1 followed by SciNCL with 81.4 F1 (-0.6 points). For MeSH classification, SciNCL yields the highest score with 88.7 F1 (+2.3 compared to SPECTER). Both classification tasks have in common that the chosen training settings lead to over-fitting. Changing the training by using only 1% training data, SciNCL yields 82.2 F1@MAG (Tab. 2). In all user activity and citation tasks, SciNCL yields higher scores than all baselines. Moreover, SciNCL outperforms SGC on direct citation prediction, where SGC outperforms SPECTER in terms of nDCG. On the recommender task, SPECTER yields the best P@1 with 20.0, whereas SciNCL achieves 19.3 P@1 (in terms of nDCG SciNCL and SPECTER are on par).</p><p>When training SPECTER and SciNCL without leakage, SciNCL outperforms SPECTER even in 11 of 12 metrics and is on par in the other metric. This suggests that SciNCL's hyperparameters have a low corpus dependency since they were only optimized on the corpus with leakage.</p><p>Regarding the LLM baselines, we observe that the general-domain BERT, with a score of 63.4, outperforms the domain-specific BERT variants, namely SciBERT (59.6) and <ref type="bibr">BioBERT (58.8</ref> anisotropy problem of embeddings directly extracted from current LLMs and highlights the advantage of combining text and citation information.</p><p>In summary, we show that SciNCL's triplet selection leads on average to a performance improvement on SCIDOCS, with most gains being observed for user activity and citation tasks. The gain from 80.0 to 81.8 is particularly notable given that even Oracle SciDocs yields with 83.0 an only marginally higher avg. score despite using test and validation data from SCIDOCS for the triplet selection. Appendix H shows examples of paper triplets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Impact of Sample Difficulty</head><p>In this section, we present the optimization of SciNCL's sampling strategy ( ?3.3). We optimize the sampling for positives and hard or easy negatives with partial grid search on a random sample of 10% of the replicated SPECTER training data (sampling based on queries). Our experiments show that optimizations on this subset correlate with the entire dataset. The validation scores in <ref type="figure" target="#fig_0">Fig. 2 and 3</ref> are reported as the mean over three random seeds. 6.1 Positive Samples <ref type="figure" target="#fig_0">Fig. 2</ref> shows the avg. scores on the SCIDOCS validation set depending on the selection of positives with the KNN strategy. We only change k + , while negative sampling remains fixed to its best setting ( ?6.2). The performance is relatively stable for k + &lt;100 with peak at k + =25, for k + &gt;100 the performance declines as k + increases. <ref type="bibr" target="#b26">Wang and Isola (2020)</ref> state that positive samples should be semantically similar to each other, but not too similar to the query. For example, at k + =5, positives may be a bit "too easy" to learn, such that they produce less informative gradients than the optimal setting k + =25. Similarly, making k + too large leads to the sampling induced margin being too small, such that positives collide with negative samples, which creates contrastive label noise that degrades performance <ref type="bibr" target="#b15">(Saunshi et al., 2019)</ref>. Another observation is the standard deviation ?: One would expect ? to be independent of k + since random seeds affect only the negatives. However, positives and negatives interact with each other through the triplet margin loss. Therefore, ? is also affected by k + . To account for the interaction of positives and negatives, one could sample simultaneously based on the distance to the query and the distance of positives and negatives to each other.   <ref type="figure" target="#fig_1">Fig. 3</ref> presents the validation results for different k ? hard given the best setting for positives (k + =25). The performance increases with increasing k ? hard until a plateau between 2000&lt;k ? hard &lt;4000 with a peak at k ? hard =4000. This plateau can also be observed in the test set, where k ? hard =3000 yields a marginally lower score of 81.7 (Tab. 2). For k ? hard &gt;4000, the performance starts to decline again. This suggests that for large k ? hard the samples are not "hard enough" which confirms the findings of Cohan et al. (2020).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Hard Negative Samples</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Easy Negative Samples</head><p>Filtered random sampling of easy negatives yields the best validation performance compared pure random sampling (Tab. 2). However, the performance difference is marginal. When rounded to one decimal, their average test scores are identical. The marginal difference is caused by the large corpus size and the resulting small probability of randomly sampling one paper from the KNN results. But without filtering, the effect of random seeds increases, since we find a higher standard deviation compared to the one with filtering.</p><p>As a potential way to decrease randomness, we experiment with other approaches like k-means clustering but find that they decrease the performance (Appendix F). Similar to SPECTER, SciNCL's sampling based on graph embeddings could cause collisions when selecting positives and negatives from regions close to each other. To avoid this, we rely on a sample induced margin that is defined by the hyperparameter k + and k ? hard (distance between red and green band in <ref type="figure">Fig. 1</ref>). When the margin gets too small, positives and negatives are more likely to collide. A collision occurs when the paper pair (d q , d s ) is contained in the training data as positive and as negative sample at the same time. <ref type="figure" target="#fig_2">Fig. 4</ref> demonstrates the relation between the number of collisions and the size of the sample induced margin. The number of collisions increases when the sample induced margin gets smaller. The opposite is the case when the margin is large enough (k ? hard &gt; 1000), i.e., then the number of collisions goes to zero. This relation also affects the evaluation performance as <ref type="figure" target="#fig_0">Fig. 2 and Fig. 3</ref> show. Namely, for large k + or small k ? hard SciNCL's performance declines and approaches SPECTER's performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">Collisions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Ablation Analysis</head><p>Next, we evaluate the impact of language model initialization and number of parameters and triples.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Initial Language Models</head><p>Tab. 2 shows the effect of initializing the model weights not with SciBERT but with general-domain LLMs (BERT-Base and BERT-Large) or with BioBERT. The initialization with other LLMs decreases the performance. However, the decline is marginal (BERT-Base -0.6, BERT-Large -0.4, BioBERT -0.4) and all LLMs outperform the SPECTER baseline. For the recommendation task, in which SPECTER is superior over SciNCL, BioBERT outperforms SPECTER. This indicates that the improved triplet mining of SciNCL has a greater domain adaption effect than pretraining on domain-specific literature. Given that pretraining of LLMs requires a magnitude more resources than the fine-tuning with SciNCL, our approach can be a solution for resource-limited use cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Data and Computing Efficiency</head><p>The last three rows of Tab. 2 show the results regarding data and computing efficiency. When keeping the citation graph unchanged but training the language model with only 10% of the original triplets, SciNCL still yields a score of 81.1 (-0.6). Even with only 1% (6840 triplets), SciNCL achieves a score of 80.8 that is 1.0 points less than with 100% but still 0.8 points more than the SPECTER baseline. With this textual sample efficiency, one could manually create triplets or use existing supervised datasets as in <ref type="bibr" target="#b32">Gao et al. (2021)</ref>. Lastly, we evaluate BitFit training <ref type="bibr" target="#b1">(Ben Zaken et al., 2022)</ref>, which only trains the bias terms of the model while freezing all other parameters. This corresponds to training only 0.1% of the original parameters. With BitFit, SciNCL yields a considerable score of 81.2 (-0.5 points). As a result, SciNCL could be trained on the same hardware with even larger (general-domain) language models ( ?7.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We present a novel approach for contrastive learning of scientific document embeddings that addresses the challenge of selecting informative positive and negative samples. By leveraging citation graph embeddings for sample generation, SciNCL achieves a score of 81.8 on the SCIDOCS benchmark, a 1.8 point improvement over the previous best method SPECTER. This is purely achieved by introducing tunable sample difficulty and avoiding collisions between positive and negative samples, while existing LLM and data setups can be reused. This improvement over SPECTER can be also observed when excluding the SCIDOCS papers during training (see w/o leakage in Tab. 1). Furthermore, SciNCL's improvement from 80.0 to 81.8 is particularly notable given that even oracle triplets, which are generated with SCIDOCS's test and validation data, yield with 83.0 only a marginally higher score.</p><p>Our work highlights the importance of sample generation in a contrastive learning setting. We show that language model training with 1% of triplets is sufficient to outperform SPECTER, whereas the remaining 99% provide only 1.0 additional points (80.8 to 81.8). This sample efficiency is achieved by adding reasonable effort for sample generation, i.e., graph embedding training and KNN search. We also demonstrate that in-domain LLM pretraining (like SciBERT) is beneficial, while general-domain LLMs can achieve comparable performance and even outperform SPECTER. This indicates that controlling sample difficulty and avoiding collisions is more effective than indomain pretraining, especially in scenarios where training an LLM from scratch is infeasible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Limitations</head><p>SciNCL's strategy of selecting positive and negative samples requires additional computational resources for training the graph embedding model, performing the KNN search, and optimizing the hyperparameters k + , k ? hard ( ?4.3). While some of the compute resources are offset by the sampleefficient language model training ( ?7.2), we still consider the increased compute effort as the major limitation of the SciNCL method.</p><p>Especially the training of the graph embedding model accounts for most of the additional compute effort. This is also the reason for us providing only a shallow of evaluation of the graph embeddings (Appendix D). For example, we did not evaluate the effect of different graph embeddings on the actual SCIDOCS performance. Moreover, evaluations with smaller subsets of the S2ORC citation graph are missing. Such evaluations could indicate whether also less citation data can be sufficient, which would lower the compute requirements but would make SciNCL also applicable in domains where less graph data is available. A Mapping to S2ORC Neither the SPECTER training data nor the Sci-Docs test data comes with a mapping to the S2ORC dataset, which we use for the training of the citation embedding model. However, to replicate SPECTER's training data and to avoid leakage of SciDocs test data such a mapping is needed. Therefore, we try to map the papers to S2ORC based on PDF hashes and exact title matches. The remaining paper metadata is collected through the Semantic Scholar API. Tab. 3 summarizes the outcome of mapping procedure. Failed mappings can be attributed to papers being unavailable through the Semantic Scholar API (e.g., retracted papers) or papers not being part of S2ORC citation graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B SPECTER-SciDocs Leakage</head><p>When replicating SPECTER (Cohan et al., 2020), we found a substantial overlap between the papers 3 used during the model training and the papers from their SCIDOCS benchmark 4 . In both datasets, papers are associated with Semantic Scholar IDs. Thus, no custom ID mapping as in Appendix A is required to identify papers that leak from training to test data. From the 311,860 unique papers used in SPECTER's training data, we find 79,201 papers (25.4%) in the test set of SCIDOCS and 79,609 papers (25.5%) in its validation set. When combining test and validation set, there is a total overlap of 126,176 papers (40.5%). However, this overlap affects only the 'unsupervised' paper metadata <ref type="bibr">(title, abstract, citations, etc.)</ref> and not the gold labels used in SCIDOCS (e.g., MAG labels or clicked recommendations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Dataset Creation</head><p>As describe in ?4.2, we conduct our experiments on two datasets. Both datasets rely on the cita-3 https://github.com/allenai/specter/ issues/2 4 https://github.com/allenai/scidocs tion graph of S2ORC <ref type="bibr" target="#b25">(Lo et al., 2020)</ref>. More specifically, S2ORC with the version identifier 20200705v1 is used. The full citation graph consists of 52.6M nodes (papers) and 467M edges (citations). Tab. 4 presents statistics on the datasets and their overlap with SPECTER and SCIDOCS. The steps to reproduce both datasets are:</p><p>Replicated SPECTER (w/ leakage) In order to replicate SPECTER's training data and do not increase the leakage, we exclude all SCIDOCS papers which are not used by SPECTER from the S2ORC citation graph. This means that apart from the 110,538 SPECTER papers not a single other SCIDOCS paper is included. The resulting citation graph has 52.5M nodes and 463M edges and is used for training the citation graph embeddings. For the SciNCL triplet selection, we also replicate SPECTER's query papers and its corpus from which positive and negatives are sampled. Our mapping and the underlying citation graph allows us to use 227,869 of 248,007 SPECTER's papers for training. Regarding query papers, we use 131,644 of 136,820 SPECTER's query papers. To align the number training triplets with the one from SPECTER, additional papers are randomly sampled from the filtered citation graph.</p><p>Random S2ORC subset (w/o leakage) To avoid leakage, we exclude all successfully mapped SCIDOCS papers from the S2ORC citation graph. After filtering the graph has 52.3 nodes and 447M edges. The citation graph embedding model is trained on this graph.</p><p>Next, we reproduce triplet selection from SPECTER. Any random 136,820 query papers are selected from the filtered graph. For each query, we generate five positives (cited by the query), two hard negatives (citation of citation), and three random nodes from the filtered S2ORC citation graphs. This sampling produces 684,100 training triplets with 680,967 unique papers IDs (more compared to the replicated SPECTER dataset). Based on these triplets the SPECTER model for this dataset is trained with the same model settings and hyperparameters as SciNCL (second last row in Tab. 1).</p><p>Lastly, the SciNCL triplets are generated based on the citation graph embeddings of the same 680,967 unique papers IDs, i.e, the FAISS index contains only these papers and not the remaining S2ORC papers. Also, the same 136,820 query papers are used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Graph Embedding Evaluation</head><p>To evaluate the underlying citation graph embeddings, we experiment with a few of BigGraph's hyperparameters. We trained embeddings with different dimensions d={128, 512, 768} and different distance measures (cosine similarity and dot product) on 99% of the data and test the remaining 1% on the link prediction task. An evaluation of the graph embeddings with SCIDOCS is not possible since we could not map the papers used in SCIDOCS to the S2ORC corpus. All variations are trained for 20 epochs, margin m=0.15, and learning rate ?=0.1 (based on the recommended settings by Lerer et al. <ref type="formula" target="#formula_3">(2019)</ref>). Tab. 5 shows the link prediction performance measured in MRR, Hits@1, Hits@10, and AUC. Dot product is substantially better than cosine similarity as distance measure. Also, there is a positive correlation between the performance and the size of the embeddings. The larger the embedding size the better link prediction performance. Graph embeddings with d=768 were the largest possible size given our compute resources (available disk space was the limiting factor).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Baseline Details</head><p>If not otherwise mentioned, all BERT variations are used in their base-uncased versions.</p><p>The weights for BERT (bert-base-uncased), BioBERT (biobert-base-cased-v1.2), CiteBERT (citebert), DeCLUTR (declutr-sci-base) are taken from Huggingface Hub 5 . We use Universal Sentence Encoder (USE) from Tensorflow Hub 6 . For Oracle SciDocs, we use the SciNCL implementation and under-sample the triplets from the classification tasks to ensure a balanced triplet distribution over the tasks. The SPECTER version for the random S2ORC training data (w/o leakage) is also trained with the SciNCL implementation. Please see <ref type="bibr" target="#b25">Cohan et al. (2020)</ref> for additional baseline methods and their implementation details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Negative Results</head><p>We investigated additional sampling strategies and model modification of which none led to a significant performance improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.1 Undirected Citations</head><p>Our graph embedding model considers citations as directed edges by default. We also train a SciNCL model with undirected citations by first converting a single edge (a, b) into the two edges (a, b) and (b, a). This approach yields a slightly worse performance (81.7 avg. score; -0.1 points) and, therefore, was discarded for the final experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.2 KNN with interval large than c</head><p>Our best results are achieved with KNN where the size of the neighbor interval (k ? c ; k] is equal to the number of samples c that the strategy should generate. In addition to this, we also experimented with large intervals, e.g., <ref type="figure" target="#fig_0">(1000; 2000]</ref>, from which c papers are randomly sampled. This approach yields comparable results but suffers from a larger effect of randomness and is therefore more difficult to optimize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.3 K-Means Cluster for Easy Negatives</head><p>Easy negatives are supposed to be far away from the query. Random sampling from a large corpus ensures this as our results show. As an alternative approach, we tried k-means clustering whereby we selected easy negatives from the centroid that has a given distance to the query's centroid. However, this decreased the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.4 Sampling with Similarity Threshold</head><p>As alternative to KNN, we select samples based on cosine similarity in the citation embedding space. Take c papers that are within the similarity threshold t of a query paper d Q such that</p><formula xml:id="formula_2">s(f c (d Q ), f c (d i )) &lt; t,</formula><p>where s is the cosine similarity function.</p><p>For example, given the similarity scores S={0.9, 0.8, 0.7, 0.1} (ascending order, the higher the similarity is the closer the candidate embedding to the query embedding is) with c =2 and t=0.5, the two candidates with the largest similarity scores and larger than the threshold would be 0.8 and 0.7. The corresponding papers would be selected as samples. While the positive threshold t + should close to 1, the negative threshold t ? should be small to ensure samples are dissimilar from d Q . However, the empirical results suggest that this strategy is inferior compared to <ref type="bibr">KNN</ref>  Selecting hard negatives based on the similarity threshold yields a test score of 81.7 (-0.1 points). <ref type="figure" target="#fig_3">Fig. 5</ref> show the validation results for different similarity thresholds. A similar pattern as in <ref type="figure" target="#fig_1">Fig. 3</ref> can be seen. When the negatives are closer to the query paper (larger similarity threshold t), the validation score decreases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.6 Positives with Similarity Threshold</head><p>Positive sampling with SIM performs poorly since even for small t + &lt; 0.5 many query papers do not have any neighbors within this similarity threshold (more than 40%). Solving this issue would require changing the set of query papers which we omit for comparability to SPECTER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.7 Sorted Random</head><p>Simple random sampling does not ensure if a sample is far or close to the query. To integrate a distance measure in the random sampling, we first sample n candidates, then order the candidates according to their distance to the query, and lastly select the c candidates that are the closest or furthest to the query as samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.8 Mask Language Modeling</head><p>Giorgi et al. <ref type="bibr">(2021)</ref> show that combining a contrastive loss with a mask language modeling loss can improve text representation learning. However, in our experiments a combined function decreases the performance on SCIDOCS, probably due to the effects found by <ref type="bibr" target="#b34">(Li et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.9 Student-Teacher Learning</head><p>Student-teacher learning is effective in related work on cross-modal knowledge transfer <ref type="bibr">(Kaur et al., 2021;</ref><ref type="bibr" target="#b22">Tian et al., 2020a)</ref>. We also try to adopt this approach for our experiments, whereby the Transformer language model is the student, and the citation graph embedding model is the teacher. By directly learning from the citation embeddings, we could circumvent the positive and negative sampling needed for triplet loss learning, which introduces unwanted issues like collisions. Given a batch of document representations derived from text D T ext (through the language model) and the citation graph representations for the same documents D Graph , we compute the pairwise cosine similarity for both sets S T ext and S Graph . To transfer the knowledge from the citation embeddings into the language model, we devise the studentteacher loss L ST based on a mean-squared-error loss (MSE) such that the difference between the cosine similarities is minimized:</p><formula xml:id="formula_3">L ST = MSE(S T ext , S Graph )<label>(1)</label></formula><p>Despite the promising results from <ref type="bibr" target="#b22">Tian et al. (2020a)</ref>, the student-teacher approach performs poorly in our experiments. We attribute this the overfitting to the citation data (the training loss approaches zero after a few steps while the validation loss remains high). The model trained with L ST yields only a SCIDOCS average score of 64.7, slightly better than SciBERT but substantially worse than SciNCL with triplet loss.</p><p>Additionally, we experiment with a joint loss that is the sum of triplet margin loss L T riplet (see ?3.1) and the student-teacher loss L ST :</p><formula xml:id="formula_4">L Joint = L T riplet + L ST<label>(2)</label></formula><p>Training with the joint loss L Joint achieves an average score of 80.5. Even though the joint loss is not subject to overfitting, its SCIDOCS performance is slightly worse than the triplet loss L T riplet alone. Given this outcome and that the computation of the cosine similarities adds additional complexity, we discard the student-teacher approach for the final experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F.10 SPECTER &amp; Bidirectional Citations</head><p>SPECTER (Cohan et al., 2020) relies on unidirectional citations for their sampling strategy. While papers cited by the query paper are considered as positives samples, those citing the query paper (opposite citation direction) could be negative samples. We see this use of citations as a conceptional flaw in their sampling strategy.</p><p>To test the actual effect on the resulting document representation, we first replicate the original unidirectional sampling strategy from SPECTER with our training data (see w/ leakage in ?4.2). The resulting SPECTER model achieves an average score of 79.0 on SCIDOCS. 7 When changing the sampling strategy from unidirectional to bidirectional ('citations to the query' are also treated as a signal for similarity), we observe an improvement of +0.4 points to 79.4. Consequently, the use of unidirectional citations is not only a conceptional issue but also degrades learning performance. <ref type="figure" target="#fig_4">Fig. 6</ref> and 7 present the validation performance like in ?6 but on a task-level and not as an average over all tasks. The plots show that the optimal k + and k ? hard values are partially task dependent. <ref type="bibr">7</ref> The difference to the scores reported in <ref type="bibr" target="#b25">Cohan et al. (2020)</ref> is due to the difference in the underlying training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Task-specific Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Examples</head><p>Tab. 6 lists three examples of query papers with their corresponding positive and negative samples. The complete set of triplets that we use during training is available in our code repository 1 .   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>that the five positives are the (k + ? 5; k + ] nearest neighbors 80Results on the validation set w.r.t. positive sampling with KNN when using 10% training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Results on the validation set w.r.t. hard negative sampling with KNN using 10% training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Number of collisions w.r.t. size of the sample induced margin as defined through k + and k ? hard .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Results on the validation set w.r.t. hard negative sampling with SIM using 10% training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>that the five positives are the (k + ? 5; k + ] that the five positives are the (k + ? 5; k + ] that the five positives are the (k + ? 5; k + ] nearest neighbors 93that the five positives are the (k + ? 5; k + ] nearest neighbors 35Task-level validation performance w.r.t. k + with KNN strategy using 10% training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Task-level validation performance w.r.t. k ? hard with KNN strategy using 10% training data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>utilize supervised entailment datasets for the triplet generation. Language-and text-independent approaches are also applied. Kim et al. (2021) use intermediate BERT hidden state for positive sampling and Wu et al. (2021) add noise to representations to obtain negative samples. Xiong et al. (2020) present an approach similar to SciNCL where they sample hard negatives from the k nearest neighbors in the embedding space derived from the previous model checkpoint. While Xiong et al. rely only on textual data, SciNCL integrates also citation information which are especially valuable in the scientific context as Cohan et al. (2020) have shown.</figDesc><table><row><cell>Scientific Document Representations based on</cell></row><row><cell>Transformers</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>allows for training on large graphs with modest hardware requirements. The resulting graph embeddings perform well using the default training settings from Lerer et al.</figDesc><table /><note>Embeddings: We train a graph embedding model f c on citations extracted from the Semantic Scholar Open Research Corpus (S2ORC; Lo et al., 2020) to get citation embeddings C. We utilize PyTorch BigGraph (Lerer et al., 2019), which</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>F1 F1 MAP nDCG MAP nDCG MAP nDCG MAP nDCG nDCG P@1</figDesc><table><row><cell>Task ? Subtask ?</cell><cell cols="2">Classification MAG MeSH</cell><cell cols="3">User activity prediction Co-View Co-Read</cell><cell cols="3">Citation prediction Cite Co-Cite</cell><cell>Recomm.</cell><cell>Avg.</cell></row><row><cell>Model ? / Metric ?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Oracle SciDocs  ?</cell><cell>87.1</cell><cell cols="2">94.8 87.2</cell><cell>93.5 88.7</cell><cell cols="2">94.6 92.3</cell><cell>96.8 91.4</cell><cell>96.4</cell><cell>53.8 19.4 83.0</cell></row><row><cell>USE (2018)</cell><cell>80.0</cell><cell cols="2">83.9 77.2</cell><cell>88.1 76.5</cell><cell cols="2">88.1 76.6</cell><cell>89.0 78.3</cell><cell>89.8</cell><cell>53.7 19.6 75.1</cell></row><row><cell>Citeomatic* (2018)</cell><cell>67.1</cell><cell cols="2">75.7 81.1</cell><cell>90.2 80.5</cell><cell cols="2">90.2 86.3</cell><cell>94.1 84.4</cell><cell>92.8</cell><cell>52.5 17.3 76.0</cell></row><row><cell>SGC* (2019)</cell><cell>76.8</cell><cell cols="2">82.7 77.2</cell><cell>88.0 75.7</cell><cell cols="2">87.5 91.6</cell><cell>96.2 84.1</cell><cell>92.5</cell><cell>52.7 18.2 76.9</cell></row><row><cell>BERT (2019)</cell><cell>79.9</cell><cell cols="2">74.3 59.9</cell><cell>78.3 57.1</cell><cell cols="2">76.4 54.3</cell><cell>75.1 57.9</cell><cell>77.3</cell><cell>52.1 18.1 63.4</cell></row><row><cell>SciBERT* (2019)</cell><cell>79.7</cell><cell cols="2">80.7 50.7</cell><cell>73.1 47.7</cell><cell cols="2">71.1 48.3</cell><cell>71.7 49.7</cell><cell>72.6</cell><cell>52.1 17.9 59.6</cell></row><row><cell>BioBERT (2019)</cell><cell>77.2</cell><cell cols="2">73.0 53.3</cell><cell>74.0 50.6</cell><cell cols="2">72.2 45.5</cell><cell>69.0 49.4</cell><cell>71.8</cell><cell>52.0 17.9 58.8</cell></row><row><cell>CiteBERT (2021)</cell><cell>78.8</cell><cell cols="2">74.8 53.2</cell><cell>73.6 49.9</cell><cell cols="2">71.3 45.0</cell><cell>67.9 50.3</cell><cell>72.1</cell><cell>51.6 17.0 58.8</cell></row><row><cell>DeCLUTR (2021)</cell><cell>81.2</cell><cell cols="2">88.0 63.4</cell><cell>80.6 60.0</cell><cell cols="2">78.6 57.2</cell><cell>77.4 62.9</cell><cell>80.9</cell><cell>52.0 17.4 66.6</cell></row><row><cell>SPECTER* (2020)</cell><cell>82.0</cell><cell cols="2">86.4 83.6</cell><cell>91.5 84.5</cell><cell cols="2">92.4 88.3</cell><cell>94.9 88.1</cell><cell>94.8</cell><cell>53.9 20.0 80.0</cell></row><row><cell cols="5">Replicated SPECTER training data (w/ leakage):</cell><cell></cell><cell></cell><cell></cell></row><row><cell>SciNCL (ours)</cell><cell>81.4</cell><cell cols="2">88.7 85.3</cell><cell>92.3 87.5</cell><cell cols="2">93.9 93.6</cell><cell>97.3 91.6</cell><cell>96.4</cell><cell>53.9 19.3 81.8</cell></row><row><cell>? ? w/ ten seeds</cell><cell>.449</cell><cell cols="2">.422 .128</cell><cell>.08 .162</cell><cell cols="2">.118 .104</cell><cell>.054 .099</cell><cell>.066</cell><cell>.203 .356 .064</cell></row><row><cell cols="4">Random S2ORC training data (w/o leakage):</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SPECTER</cell><cell>81.3</cell><cell cols="2">88.4 83.1</cell><cell>91.3 84.0</cell><cell cols="2">92.1 86.2</cell><cell>93.9 87.8</cell><cell>94.7</cell><cell>52.2 17.5 79.4</cell></row><row><cell>SciNCL (ours)</cell><cell>81.3</cell><cell cols="2">89.4 84.3</cell><cell>91.8 85.6</cell><cell cols="2">92.8 91.4</cell><cell>96.3 90.1</cell><cell>95.7</cell><cell>54.3 19.9 81.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>).</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">LLMs without citations or contrastive objectives</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">yield generally poor results. This emphasizes the</cell></row></table><note>1 Table 1: Results on the SCIDOCS test set. With replicated SPECTER training data, SciNCL surpasses the previous best avg. score by 1.8 points and also outperforms the baselines in 9 of 12 task metrics. Our scores are reported as mean and standard deviation ? over ten random seeds. With training data randomly sampled from S2ORC, SciNCL outperforms SPECTER in terms of avg. score with 1.7 points. The scores with * are from Cohan et al. (2020). Oracle SciDocs ? is the upper bound of the performance with triplets from SCIDOCS's data.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>CLS USR CITE REC Avg. ?</figDesc><table><row><cell>SciNCL</cell><cell>85.0 88.8 94.7 36.6 81.8</cell><cell>-</cell></row><row><cell>SPECTER</cell><cell cols="2">84.2 88.4 91.5 36.9 80.0 -1.8</cell></row><row><cell>k ? hard =2000</cell><cell cols="2">84.9 88.8 94.7 36.1 81.6 -0.2</cell></row><row><cell>k ? hard =3000</cell><cell cols="2">84.5 88.7 94.6 36.9 81.7 -0.1</cell></row><row><cell cols="3">easy neg. w/ random 85.1 88.8 94.7 36.6 81.8 0.0</cell></row><row><cell cols="3">undirected citations 84.6 88.8 94.7 36.6 81.7 -0.1</cell></row><row><cell cols="3">Init. w/ BERT-Base 83.4 88.4 93.8 37.5 81.2 -0.6</cell></row><row><cell cols="3">Init. w/ BERT-Large 84.6 88.7 94.1 36.4 81.4 -0.4</cell></row><row><cell>Init. w/ BioBERT</cell><cell cols="2">83.7 88.6 93.8 37.7 81.4 -0.4</cell></row><row><cell>1% training data</cell><cell cols="2">85.2 88.3 92.7 36.1 80.8 -1.0</cell></row><row><cell>10% training data</cell><cell cols="2">85.1 88.7 93.5 36.2 81.1 -0.6</cell></row><row><cell>BitFit training</cell><cell cols="2">85.8 88.6 93.7 35.3 81.2 -0.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Ablations. Numbers are averages over tasks of the SCIDOCS test set, average score over all metrics, and rounded absolute difference to SciNCL.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>Mapping to S2ORC citation graph</figDesc><table><row><cell>S2ORC mapping</cell><cell>Success rate</cell></row><row><cell>SciDocs papers</cell><cell></cell></row><row><cell cols="2">-with S2ORC IDs 220,815 / 223,932 (98.6%)</cell></row><row><cell cols="2">-in S2ORC graph 197,811 / 223,932 (88.3%)</cell></row><row><cell>SPECTER papers</cell><cell></cell></row><row><cell cols="2">-with S2ORC IDs 311,094 / 311,860 (99.7%)</cell></row><row><cell cols="2">-in S2ORC graph 260,014 / 311,860 (83.3%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Statistics for our two datasets and their overlap with SPECTER and SciDocs respectively.</figDesc><table><row><cell></cell><cell>Replicated</cell><cell>Random</cell></row><row><cell></cell><cell>SPECTER</cell><cell>S2ORC subset</cell></row><row><cell></cell><cell>(w/ leakage)</cell><cell>(w/o leakage)</cell></row><row><cell>Training triplets</cell><cell>684,100</cell><cell>684,100</cell></row><row><cell>Unique paper IDs</cell><cell>248,007</cell><cell>680,967</cell></row><row><cell>-in SPECTER</cell><cell>227,869</cell><cell>9,182</cell></row><row><cell>-in SciDocs</cell><cell>110,538</cell><cell>0</cell></row><row><cell>-in SciDocs and in SPECTER</cell><cell>110,538</cell><cell>0</cell></row><row><cell>Query paper IDs</cell><cell>136,820</cell><cell>136,820</cell></row><row><cell>-in SciDocs</cell><cell>69,306</cell><cell>0</cell></row><row><cell>-in SPECTER queries</cell><cell>131,644</cell><cell>463</cell></row><row><cell>Citation graph</cell><cell></cell><cell></cell></row><row><cell>-Nodes</cell><cell>52,526,134</cell><cell>52,373,977</cell></row><row><cell>-Edges</cell><cell>463,697,639</cell><cell>447,697,727</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Link prediction performance of BigGraph embeddings trained on S2ORC citation graph with different dimensions and distance measures.</figDesc><table><row><cell cols="5">Dim. Dist. MRR Hits@1 Hits@10 AUC</cell></row><row><cell>128</cell><cell cols="2">Cos. 54.09 43.39</cell><cell>75.21</cell><cell>85.75</cell></row><row><cell>128</cell><cell>Dot</cell><cell>89.75 85.84</cell><cell>96.13</cell><cell>97.70</cell></row><row><cell>512</cell><cell>Dot</cell><cell>94.60 92.47</cell><cell>97.64</cell><cell>98.64</cell></row><row><cell>768</cell><cell>Dot</cell><cell>95.12 93.22</cell><cell>97.77</cell><cell>98.74</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2"><ref type="bibr" target="#b0">Cohan et al. (2019)</ref> evaluated other inputs (venue or author) but found the title and abstract to perform best.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://huggingface.co/models 6 https://tfhub.dev/google/ universal-sentence-encoder-large/5</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank Christian Schulze and his team for providing the compute infrastructure that made our experiments possible. The research presented in this article is partially funded by the German Federal Ministry of Education and Research (BMBF) through the projects QURA-TOR  (Unternehmen Region, Wachstumskern, no. 03WKDA1A) and PANQURA (no. 03COV03E).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SciB-ERT: A Pretrained Language Model for Scientific Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1371</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3613" to="3618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">BitFit: Simple parameter-efficient fine-tuning for transformer-based masked language-models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elad</forename><surname>Ben Zaken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shauli</forename><surname>Ravfogel</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-short.1</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Short Papers</publisher>
			<date type="published" when="2022" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Content-based citation recommendation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russell</forename><surname>Power</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n18-1022</idno>
	</analytic>
	<monogr>
		<title level="m">Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies -Proceedings of the Conference</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="238" to="251" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Global Vectors for Node Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Brochier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Guille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Velcin</surname></persName>
		</author>
		<idno type="DOI">10.1145/3308558.3313595</idno>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference on -WWW &apos;19</title>
		<meeting><address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2587" to="2593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Hard negative mining for metric learning based zero-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Herbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2016 Workshops</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="524" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Chris Tar, Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Matthew Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Sheng Yi Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicole</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rhomni</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>St</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Guajardo-Cespedes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.11175</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Universal sentence encoder</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A metric learning reality check</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Musgrave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-58595-2_41</idno>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020 -16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-08-23" />
			<biblScope unit="page" from="681" to="699" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XXV</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Aspect-based Document Similarity for Research Papers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Ostendorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terry</forename><surname>Ruas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Till</forename><surname>Blume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bela</forename><surname>Gipp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Rehm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics (COLING 2020</title>
		<meeting>the 28th International Conference on Computational Linguistics (COLING 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The scientific enterprise: Public knowledge. an essay concerning the social dimension of science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Pasternack</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.164.3880.669</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">164</biblScope>
			<biblScope unit="issue">3880</biblScope>
			<biblScope unit="page" from="669" to="670" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">DeepWalk: online learning of social representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
		<idno type="DOI">10.1145/2623330.2623732</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining -KDD &apos;14</title>
		<meeting>the 20th ACM SIGKDD international conference on Knowledge discovery and data mining -KDD &apos;14<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">QURATOR: Innovative Technologies for Content and Data Curation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Rehm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bourgonje</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Hegele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Kintzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jul?n</forename><forename type="middle">Moreno</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malte</forename><surname>Ostendorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karolina</forename><surname>Zaczynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armin</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?ren</forename><surname>R?uchle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Rauenbusch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisa</forename><surname>Rutenburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andr?</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikka</forename><surname>Wild</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jurica</forename><surname>Seva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Quantz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>B?ttger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josefine</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rolf</forename><surname>Fricke</surname></persName>
		</author>
		<idno>2535. 20/21</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of QURATOR 2020 -The conference for intelligent content solutions</title>
		<editor>Thomsen, Adrian Paschke, Jamal Al Qundus, Thomas Hoppe, Naouel Karam, Frauke Weichhardt, Christian Fillies, Clemens Neudecker, Mike Gerber, Kai Labusch, Vahid Rezanezhad, Robin Schaefer, David Zellh?fer, Daniel Siewert, Patrick Bunk, Lydia Pintscher, Elena Aleynikova, and Franziska Heine. 2020.</editor>
		<meeting>QURATOR 2020 -The conference for intelligent content solutions<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-01" />
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1410</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3980" to="3990" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Rethmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.12982</idno>
		<title level="m">Data-Efficient Pretraining via Contrastive Self-Supervision</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">2022. A primer on contrastive pretraining in language processing: Methods, lessons learned &amp; perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Rethmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<idno type="DOI">10.1145/3561970</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surv</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A primer in bertology: What we know about how BERT works</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Kovaleva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Rumshisky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Assoc. Comput. Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="842" to="866" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A theoretical analysis of contrastive unsupervised representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikunj</forename><surname>Saunshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orestis</forename><surname>Plevrakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Khodak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrishikesh</forename><surname>Khandeparkar</surname></persName>
		</author>
		<idno>PMLR. PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">97</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2015.7298682</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-06-07" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Text data augmentation for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Connor</forename><surname>Shorten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borko</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Furht</surname></persName>
		</author>
		<idno type="DOI">10.1186/s40537-021-00492-0</idno>
	</analytic>
	<monogr>
		<title level="j">J. Big Data</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">101</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">An overview of microsoft academic service (mas) and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnab</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihong</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrin</forename><surname>Eide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo-June Paul</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1145/2740908.2742839</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th International Conference on World Wide Web</title>
		<meeting>the 24th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Co-citation in the scientific literature: A new measure of the relationship between two documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Small</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.4630240406</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="265" to="269" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Zero-shot learning through cross-modal transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milind</forename><surname>Ganjoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Automatic classification of citation function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Advaith</forename><surname>Siddharthan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Tidhar</surname></persName>
		</author>
		<idno type="DOI">10.3115/1610075.1610091</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing -EMNLP &apos;06</title>
		<meeting>the 2006 Conference on Empirical Methods in Natural Language Processing -EMNLP &apos;06<address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page">103</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Contrastive representation distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">What makes for good views for contrastive learning?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<imprint>
			<date type="published" when="2020-12-06" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>virtual</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Attention Is All You Need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9780511809071</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fact or Fiction: Verifying Scientific Claims</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanchuan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><forename type="middle">Lu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madeleine</forename><surname>Van Zuylen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.emnlp-main.609</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7534" to="7550" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="9929" to="9939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Zero-shot recognition via semantic embeddings and knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufei</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav Kumar</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6857" to="6866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Morgan Funtowicz, and Jamie Brew. 2020. Transformers: State-ofthe-Art Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Louf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</meeting>
		<imprint>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cite-Worth: Cite-worthiness detection for improved scientific document understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dustin</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.findings-acl.157</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1796" to="1807" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Sampling Matters in Deep Embedding Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chao-Yuan Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krahenbuhl</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICCV.2017.309</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2859" to="2867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Simplifying Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amauri</forename><surname>Holanda De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="815" to="826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaochen</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangjun</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jizhong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songlin</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.04321</idno>
		<title level="m">Smoothed Contrastive Learning for Unsupervised Sentence Embedding</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuofeng</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiatao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madian</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15466</idno>
		<title level="m">Contrastive Learning for Sentence Representation</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lee</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwok-Fung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jialin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junaid</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><surname>Overwijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Network representation learning with rich text information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.5555/2832415.2832542</idno>
	</analytic>
	<monogr>
		<title level="m">Example query papers with their positive and negative samples. Query: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding Positives</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2111" to="2117" />
		</imprint>
	</monogr>
	<note>Proceedings of the 24th International Conference on Artificial Intelligence, IJCAI&apos;15</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Analysis Platform for Natural Language Understanding ? Dissecting Contextual Word Embeddings: Architecture and Representation ? Universal Transformers Negatives: ? Planning for decentralized control of multiple robots under uncertainty ? Graph-Based Relational Data Visualization ? Linked Stream Data Processing ? Topic Modeling Using Distributed Word Embeddings ? Adversarially-Trained Normalized Noisy-Feature Auto-Encoder for Text Generation Query: BioBERT: a pre-trained biomedical language representation model for biomedical text mining Positives: ? Exploring Word Embedding for Drug Name Recognition ? A neural joint model for entity and relation extraction from biomedical text ? Event Detection with Hybrid Neural Architecture ? Improving chemical disease relation extraction with rich features and weakly labeled data ? GLUE : A MultiTask Benchmark and Analysis Platform for Natural Language Understanding Negatives: ? Weakly Supervised Facial Attribute Manipulation via Deep</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">? A</forename><surname>Broad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Coverage Challenge Corpus for Sentence Understanding through Inference ? Looking for ELMo&apos;s Friends: Sentence-Level Pretraining Beyond Language Modeling ? GLUE : A MultiTask Benchmark and</title>
		<imprint/>
	</monogr>
	<note>Adversarial Network ? Applying the Clique Percolation Method to analyzing cross-market branch banking ..</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">? Perpetual environmentally powered sensor networks ? Labelling strategies for hierarchical multi-label classification techniques ? Domain Aware Neural Dialog System Query: A Context-Aware Citation Recommendation Model with BERT and Graph Convolutional Networks Positives: ? Content-based citation analysis: The next generation of citation analysis ? ScisummNet: A Large Annotated Dataset and Content-Impact Models for Scientific Paper</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<title level="m">? Citation Block Determination Using Textual Coherence ? Discourse Segmentation Of Multi-Party Conversation ? Argumentative Zoning for Improved Citation Indexing Negatives</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Adaptive Quantization for Hashing: An Information-Based Approach to Learning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<title level="m">? Trap Design for Vibratory Bowl Feeders ? Software system for the Mars 2020 mission sampling and caching testbeds ? Applications of Rhetorical Structure Theory ? Text summarization for Malayalam documents -An experience</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
